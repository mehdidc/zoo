{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 64, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.05546173661045223, 0.055911397371665686, 0.06273099753123482, 0.058023677876978756, 0.061898138057143476, 0.05634101227963764, 0.05670167568490953, 0.05007532028202912, 0.0555282616015737, 0.05393579949498679, 0.05800154293351657, 0.060447689783789414, 0.05070110024935352, 0.0498922758848016, 0.053153387101469676, 0.0519695228147471, 0.0542746609675516, 0.05234156889118624, 0.046822274447454564, 0.05862181288250585, 0.05119677460528083, 0.05663684389545392, 0.05736057781605181, 0.06054350355295723, 0.05051573371952114, 0.055292654884538946, 0.05747767679042181, 0.05858803307209022, 0.05798770430319085, 0.053021021634886485, 0.0517642400332821, 0.056365065021030905, 0.05215245796433587, 0.05148544622888483, 0.04844941172381723, 0.05647507041213294, 0.05138350230311457, 0.052890010948102834, 0.05335599940572593, 0.053443503904717526, 0.05261989397661738, 0.056272912659580565, 0.05676046372240641, 0.05272688913559481, 0.054262829978644275, 0.05480278495132669, 0.0552858808597102, 0.050756999852290374, 0.056856531214273254, 0.04843431678570088, 0.04961949840587419, 0.05256835038165959, 0.05342548035194853, 0.05388816237132012, 0.05246851053151518, 0.05048006262789508, 0.0478877301883235, 0.050906466058649825, 0.04819733555720776, 0.06016229740840986, 0.051523882809456266, 0.05348953650366874, 0.05538064180638647, 0.053796408454684724, 0.05430422716300456, 0.05271166574490924, 0.055682216621152796, 0.046282083343187196, 0.0507970409492674, 0.05209497459207133, 0.053814639188675954, 0.051945838126943755, 0.05590278415842761, 0.051892250288662414, 0.05300823794601854, 0.045504073283656035, 0.05118806491565525, 0.050680693851701965, 0.053097995020587825, 0.05491689421728656, 0.050475822802926215, 0.04902830625906004, 0.047365341768506174, 0.053268016350781364, 0.04967948717948718, 0.04445771690690301, 0.055000294176190144, 0.05463133739117074, 0.05709505567245919, 0.05147609245075651, 0.052645646849869894, 0.05148509982296245, 0.05429568747137867, 0.05926629065925107, 0.052785711603922425, 0.05146153874988111, 0.05516348286128465, 0.05099257798835493, 0.05163384001585978, 0.054583653803389774], "moving_avg_accuracy_train": [0.03225244728915662, 0.07549745858433733, 0.11430266378012045, 0.15881883942018069, 0.19884339373117466, 0.24982690074359937, 0.2995524185005647, 0.3421287090300263, 0.3854101905366622, 0.416388655669743, 0.45270065606662413, 0.48980775536960025, 0.5244536741097486, 0.5552984987168461, 0.5839365705319085, 0.6091907862196815, 0.6352681307904844, 0.6547961934644481, 0.6774260432445093, 0.695279730335721, 0.7131458649828718, 0.7270722423400063, 0.7424462492807045, 0.7553062930273329, 0.7678168911342381, 0.777643353376236, 0.7896145225566846, 0.8002215002708957, 0.8104431378944085, 0.8174612299784616, 0.8263424601432661, 0.8334907819000238, 0.8416844371437563, 0.846724389513718, 0.8531099324900571, 0.859254605656714, 0.8653801616573076, 0.8704295890156732, 0.8734351052647084, 0.8726291512141411, 0.8769889770565824, 0.8800703880858639, 0.8826248138857112, 0.8868439778284655, 0.8884927878769442, 0.8901320256555147, 0.8915979270056259, 0.8907335032809669, 0.8942994601817859, 0.8990572024166193, 0.9022755409098973, 0.9047978926924015, 0.9072797939352095, 0.9088616789995199, 0.9107395359489655, 0.9122648858179243, 0.9137553588325175, 0.9145790887625187, 0.9138379532296403, 0.9112248657380015, 0.9140453385015508, 0.9145671035971789, 0.9163991733579429, 0.9188787025582932, 0.9208702562482469, 0.921996709539085, 0.9239470762357789, 0.9263354070158155, 0.9274000967359206, 0.9279112165804008, 0.9254721280548908, 0.92678551389398, 0.9256614617515699, 0.9272618253655696, 0.925341836353109, 0.9258964140129788, 0.9266190843586689, 0.929210846856537, 0.9294632373214857, 0.929043269011024, 0.9311620031038974, 0.9323982124320619, 0.9322683309478919, 0.9324526424314159, 0.9329809098147803, 0.9347741215441456, 0.9356679443294902, 0.9373524676676255, 0.9380284596056823, 0.9390980722294514, 0.9400771957293977, 0.9395135650118797, 0.9411594411914146, 0.9416171039999839, 0.9426784734192627, 0.9428736343604689, 0.9432163537557473, 0.9438165933801725, 0.9452674829879384, 0.945191977159024], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 875196133, "moving_var_accuracy_train": [0.009361983205258438, 0.025256963902015366, 0.036283863064395336, 0.05049068580050603, 0.05985930175059879, 0.07726723346111253, 0.09179415416078576, 0.09892940338194928, 0.10589604281643776, 0.10394342625280747, 0.10541613598293458, 0.10726695375276951, 0.10734331554563327, 0.10517161283645336, 0.10203570396837004, 0.09757211226157408, 0.09393515213419615, 0.0879737440069608, 0.08378536051587794, 0.07827561174904825, 0.07332083947921451, 0.06773425140793284, 0.06308806707185327, 0.0582676868911547, 0.053849553786971746, 0.04933363265001526, 0.045690049408936055, 0.04213361625411038, 0.038860591510057066, 0.0354178149075536, 0.03258591965996033, 0.02978721422940752, 0.027412716682745083, 0.02490005509349392, 0.022777026016068583, 0.020839136489387032, 0.019092924767296012, 0.017413102740393115, 0.015753090617662727, 0.014183627613281086, 0.01293633758434075, 0.011728159671289077, 0.010614069524662501, 0.009712874671578785, 0.008766054375604588, 0.007913632842496368, 0.007141609359161052, 0.006434173478626726, 0.00590520056833054, 0.005518405512055549, 0.005059784284765818, 0.004611066182921558, 0.004205398068640871, 0.003807379504986978, 0.0034583786749915104, 0.0031334810374969552, 0.002840126522012332, 0.002562220648789318, 0.0023109421208132403, 0.0021413019448825454, 0.001998767349883599, 0.001801340764230381, 0.0016514150042820973, 0.0015416060893523955, 0.0014231420553168742, 0.0012922479229331438, 0.0011972585029039842, 0.0011288697678474165, 0.001026184868863554, 0.0009259175734359921, 0.0008868681916098618, 0.0008137062137097568, 0.0007437070313084907, 0.0006923868014507673, 0.0006563253415774142, 0.0005934608148471129, 0.0005388150052192599, 0.0005453886003055307, 0.0004914230487961509, 0.0004438681043526653, 0.0004398826013241397, 0.0004096482627190934, 0.000368835259246556, 0.00033225746982853, 0.0003015433207006174, 0.00030032946338755663, 0.0002774867895932095, 0.0002752766805243918, 0.00025186169837481184, 0.00023697216902166706, 0.0002219030975728264, 0.00020257190408711333, 0.00020669488926364622, 0.0001879104975544102, 0.00017925799319658958, 0.00016167498401368328, 0.00014656459486741494, 0.0001351507238412452, 0.00014058137734242803, 0.00012657454977998557], "duration": 40442.15749, "accuracy_train": [0.32252447289156627, 0.46470256024096385, 0.4635495105421687, 0.5594644201807228, 0.5590643825301205, 0.7086784638554217, 0.747082078313253, 0.7253153237951807, 0.7749435240963856, 0.6951948418674698, 0.7795086596385542, 0.8237716490963856, 0.8362669427710844, 0.8329019201807228, 0.8416792168674698, 0.8364787274096386, 0.8699642319277109, 0.8305487575301205, 0.8810946912650602, 0.8559629141566265, 0.8739410768072289, 0.8524096385542169, 0.8808123117469879, 0.8710466867469879, 0.8804122740963856, 0.8660815135542169, 0.8973550451807228, 0.8956842996987951, 0.9024378765060241, 0.8806240587349398, 0.906273531626506, 0.8978256777108434, 0.9154273343373494, 0.8920839608433735, 0.9105798192771084, 0.9145566641566265, 0.9205101656626506, 0.9158744352409639, 0.9004847515060241, 0.8653755647590361, 0.9162274096385542, 0.9078030873493976, 0.9056146460843374, 0.924816453313253, 0.903332078313253, 0.9048851656626506, 0.9047910391566265, 0.8829536897590361, 0.9263930722891566, 0.9418768825301205, 0.9312405873493976, 0.9274990587349398, 0.9296169051204819, 0.9230986445783133, 0.9276402484939759, 0.9259930346385542, 0.9271696159638554, 0.9219926581325302, 0.9071677334337349, 0.887707078313253, 0.939429593373494, 0.9192629894578314, 0.9328878012048193, 0.9411944653614458, 0.9387942394578314, 0.9321347891566265, 0.9415003765060241, 0.9478303840361446, 0.9369823042168675, 0.9325112951807228, 0.9035203313253012, 0.9386059864457831, 0.9155449924698795, 0.9416650978915663, 0.9080619352409639, 0.9308876129518072, 0.9331231174698795, 0.9525367093373494, 0.9317347515060241, 0.9252635542168675, 0.950230609939759, 0.9435240963855421, 0.9310993975903614, 0.9341114457831325, 0.9377353162650602, 0.9509130271084337, 0.9437123493975904, 0.9525131777108434, 0.9441123870481928, 0.9487245858433735, 0.9488893072289156, 0.9344408885542169, 0.9559723268072289, 0.9457360692771084, 0.9522307981927711, 0.9446300828313253, 0.946300828313253, 0.94921875, 0.9583254894578314, 0.9445124246987951], "end": "2016-01-21 14:46:44.482000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], "accuracy_valid": [0.3218482905982906, 0.4594017094017094, 0.4501869658119658, 0.5479433760683761, 0.5375267094017094, 0.6794871794871795, 0.7067307692307693, 0.6935096153846154, 0.7310363247863247, 0.6607905982905983, 0.7378472222222222, 0.7636217948717948, 0.7751068376068376, 0.7704326923076923, 0.781517094017094, 0.7674946581196581, 0.7908653846153846, 0.7495993589743589, 0.8035523504273504, 0.7743055555555556, 0.7857905982905983, 0.7735042735042735, 0.7771100427350427, 0.7745726495726496, 0.7868589743589743, 0.7669604700854701, 0.7840544871794872, 0.7883279914529915, 0.7909989316239316, 0.7736378205128205, 0.7875267094017094, 0.7835202991452992, 0.7958066239316239, 0.7793803418803419, 0.7860576923076923, 0.7938034188034188, 0.7919337606837606, 0.7995459401709402, 0.7824519230769231, 0.7541399572649573, 0.7920673076923077, 0.7829861111111112, 0.780982905982906, 0.7915331196581197, 0.7676282051282052, 0.7775106837606838, 0.7697649572649573, 0.7566773504273504, 0.7887286324786325, 0.8090277777777778, 0.7943376068376068, 0.7915331196581197, 0.796340811965812, 0.7918002136752137, 0.7919337606837606, 0.7893963675213675, 0.7967414529914529, 0.7873931623931624, 0.7769764957264957, 0.7665598290598291, 0.8003472222222222, 0.7799145299145299, 0.7990117521367521, 0.8024839743589743, 0.7996794871794872, 0.7951388888888888, 0.796340811965812, 0.7991452991452992, 0.7995459401709402, 0.7959401709401709, 0.766159188034188, 0.7955395299145299, 0.7779113247863247, 0.7903311965811965, 0.7821848290598291, 0.7876602564102564, 0.7856570512820513, 0.8016826923076923, 0.7895299145299145, 0.7775106837606838, 0.7970085470085471, 0.7954059829059829, 0.7895299145299145, 0.7833867521367521, 0.7932692307692307, 0.8067574786324786, 0.796073717948718, 0.7956730769230769, 0.8003472222222222, 0.797409188034188, 0.8003472222222222, 0.7928685897435898, 0.8083600427350427, 0.7931356837606838, 0.8018162393162394, 0.7955395299145299, 0.7980769230769231, 0.7905982905982906, 0.8074252136752137, 0.7930021367521367], "accuracy_test": 0.09725560897435898, "start": "2016-01-21 03:32:42.325000", "learning_rate_per_epoch": [0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676, 0.0006263283430598676], "accuracy_train_last": 0.9445124246987951, "error_valid": [0.6781517094017093, 0.5405982905982907, 0.5498130341880342, 0.45205662393162394, 0.46247329059829057, 0.3205128205128205, 0.2932692307692307, 0.3064903846153846, 0.26896367521367526, 0.3392094017094017, 0.2621527777777778, 0.23637820512820518, 0.22489316239316237, 0.2295673076923077, 0.21848290598290598, 0.2325053418803419, 0.20913461538461542, 0.2504006410256411, 0.1964476495726496, 0.22569444444444442, 0.21420940170940173, 0.22649572649572647, 0.2228899572649573, 0.2254273504273504, 0.21314102564102566, 0.23303952991452992, 0.21594551282051277, 0.21167200854700852, 0.20900106837606836, 0.22636217948717952, 0.21247329059829057, 0.2164797008547008, 0.20419337606837606, 0.2206196581196581, 0.2139423076923077, 0.20619658119658124, 0.20806623931623935, 0.20045405982905984, 0.21754807692307687, 0.2458600427350427, 0.2079326923076923, 0.21701388888888884, 0.21901709401709402, 0.20846688034188032, 0.23237179487179482, 0.22248931623931623, 0.2302350427350427, 0.2433226495726496, 0.21127136752136755, 0.1909722222222222, 0.2056623931623932, 0.20846688034188032, 0.20365918803418803, 0.2081997863247863, 0.20806623931623935, 0.21060363247863245, 0.20325854700854706, 0.21260683760683763, 0.22302350427350426, 0.2334401709401709, 0.1996527777777778, 0.22008547008547008, 0.20098824786324787, 0.19751602564102566, 0.20032051282051277, 0.20486111111111116, 0.20365918803418803, 0.2008547008547008, 0.20045405982905984, 0.2040598290598291, 0.23384081196581197, 0.20446047008547008, 0.22208867521367526, 0.20966880341880345, 0.2178151709401709, 0.2123397435897436, 0.21434294871794868, 0.1983173076923077, 0.2104700854700855, 0.22248931623931623, 0.20299145299145294, 0.20459401709401714, 0.2104700854700855, 0.21661324786324787, 0.20673076923076927, 0.1932425213675214, 0.20392628205128205, 0.20432692307692313, 0.1996527777777778, 0.20259081196581197, 0.1996527777777778, 0.20713141025641024, 0.1916399572649573, 0.20686431623931623, 0.19818376068376065, 0.20446047008547008, 0.20192307692307687, 0.20940170940170943, 0.1925747863247863, 0.2069978632478633], "accuracy_train_std": [0.057597558049332725, 0.0626746130779382, 0.06152000261468405, 0.06352098770658036, 0.06425178651994257, 0.05918880971163399, 0.059141339876837444, 0.05911934689797961, 0.05798292092033858, 0.060769900373071256, 0.05833670088797093, 0.0575744560097456, 0.05397592958196912, 0.05281645655211109, 0.053382178059739785, 0.05475873195895337, 0.050981886574273744, 0.054892253951037986, 0.047629680392690055, 0.05091804098174669, 0.05013435531488342, 0.04994366956118489, 0.047479469544241044, 0.04820334077310428, 0.04574090610481311, 0.04970984111592895, 0.044677456186123884, 0.04442396531802794, 0.044021101203154424, 0.04790294200218734, 0.04212836145812687, 0.04440574422327179, 0.040950844994587704, 0.04479825941048726, 0.040043278678033055, 0.04202497491248197, 0.0392171905765768, 0.03955390633864636, 0.04160848730836486, 0.04730083458093562, 0.04108673201940018, 0.04131068015277818, 0.04245396948180219, 0.03841456404290245, 0.04161839414426609, 0.043239298072341795, 0.040812687511017465, 0.045537947376834156, 0.03748941872567982, 0.03383671154289976, 0.03546830506824448, 0.03700817187388282, 0.03906243620939413, 0.036158670030071005, 0.035824990567306335, 0.03740299292012387, 0.038952959788000556, 0.03692854517742037, 0.040580035761818255, 0.04350172337643385, 0.034471736605641894, 0.040515358832691535, 0.03428066156653625, 0.03405323943499168, 0.03413178671846478, 0.0350421238039805, 0.03407805270903208, 0.0304077331221041, 0.033876749350743716, 0.03485592339563343, 0.04109783579879898, 0.03406292957237424, 0.03835016248581218, 0.0324722036605192, 0.041117226529182774, 0.03463247094907389, 0.03480094463639743, 0.0282078839510399, 0.03555714418526105, 0.03535061256013223, 0.030125031644686034, 0.03276237972373797, 0.03510956526977062, 0.03475269915650758, 0.03409624683625239, 0.030922921046246547, 0.03300687898900453, 0.028486256123687482, 0.03346623379737576, 0.03153307316659733, 0.03096161182414417, 0.03525571705808504, 0.028717445906061956, 0.0307489484255695, 0.030414188029180295, 0.031301335809346284, 0.03227643732962818, 0.031638794709445174, 0.027140923452460098, 0.03285739808330189], "accuracy_test_std": 0.03623905488762615, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.8212509974341189, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0006263283488047301, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.00012022708461607252, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.0689344721327573}, "accuracy_valid_max": 0.8090277777777778, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-6, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7930021367521367, "loss_train": [5.708059310913086, 3.9651153087615967, 3.1062488555908203, 2.636362314224243, 2.356358766555786, 2.1658661365509033, 2.0248308181762695, 1.9177062511444092, 1.8317680358886719, 1.7541136741638184, 1.6907118558883667, 1.6276271343231201, 1.5772802829742432, 1.5246728658676147, 1.4883103370666504, 1.4448823928833008, 1.4127779006958008, 1.3823347091674805, 1.352494239807129, 1.3278717994689941, 1.3066861629486084, 1.2797356843948364, 1.264496088027954, 1.2453703880310059, 1.2284795045852661, 1.213118076324463, 1.1964033842086792, 1.18654203414917, 1.1703959703445435, 1.1604164838790894, 1.144645094871521, 1.1336424350738525, 1.1239312887191772, 1.114861011505127, 1.105391263961792, 1.095140814781189, 1.0817326307296753, 1.0724111795425415, 1.0653746128082275, 1.0537570714950562, 1.0442866086959839, 1.0352745056152344, 1.0274847745895386, 1.0214025974273682, 1.0118696689605713, 1.0054203271865845, 0.9986445903778076, 0.9925763010978699, 0.9854542016983032, 0.9796462059020996, 0.9748334884643555, 0.965087890625, 0.9524218440055847, 0.953122615814209, 0.948718249797821, 0.9429330229759216, 0.9353470802307129, 0.9298073053359985, 0.9217362403869629, 0.92085862159729, 0.9133098125457764, 0.9097925424575806, 0.9075115323066711, 0.8962691426277161, 0.8961812853813171, 0.8930320143699646, 0.8868775367736816, 0.8865375518798828, 0.8781959414482117, 0.8770298361778259, 0.8723408579826355, 0.874309241771698, 0.8662177324295044, 0.8644568920135498, 0.861809253692627, 0.8598642945289612, 0.8543386459350586, 0.8477893471717834, 0.8485017418861389, 0.8460650444030762, 0.8378705978393555, 0.8377372622489929, 0.8354036808013916, 0.832294762134552, 0.828298807144165, 0.8235347867012024, 0.823792576789856, 0.8172188997268677, 0.8151863813400269, 0.8150697350502014, 0.8162340521812439, 0.8124980926513672, 0.8090774416923523, 0.8000010848045349, 0.8025984168052673, 0.8003590703010559, 0.7960416078567505, 0.793830931186676, 0.7955496907234192, 0.7877062559127808], "accuracy_train_first": 0.32252447289156627, "model": "residualv4", "loss_std": [0.7915303707122803, 0.37165436148643494, 0.2304781824350357, 0.17276789247989655, 0.15088289976119995, 0.1385127305984497, 0.13382109999656677, 0.12690582871437073, 0.1275503784418106, 0.12158463150262833, 0.12065200507640839, 0.11705689877271652, 0.11475911736488342, 0.10845296084880829, 0.10807958245277405, 0.10520421713590622, 0.10157608240842819, 0.09817173331975937, 0.09954594075679779, 0.08992874622344971, 0.09125614166259766, 0.08551779389381409, 0.08570156991481781, 0.08754891157150269, 0.08450327068567276, 0.08573038876056671, 0.0834907665848732, 0.08454769104719162, 0.07732139527797699, 0.07754361629486084, 0.08027148991823196, 0.0784049853682518, 0.074946328997612, 0.07586556673049927, 0.07677585631608963, 0.06947756558656693, 0.0721592903137207, 0.07270979881286621, 0.06829695403575897, 0.07041645050048828, 0.06954258680343628, 0.0685136690735817, 0.06950104236602783, 0.06693832576274872, 0.06482759118080139, 0.06540524214506149, 0.06577780097723007, 0.06309520453214645, 0.06455984711647034, 0.06875050812959671, 0.06437548995018005, 0.06618593633174896, 0.06267040222883224, 0.06411536037921906, 0.06730595976114273, 0.0637272447347641, 0.0609312579035759, 0.059199586510658264, 0.05963896960020065, 0.0633491575717926, 0.060040008276700974, 0.061813924461603165, 0.06025726720690727, 0.05891014263033867, 0.06294594705104828, 0.06382031738758087, 0.06194647401571274, 0.06256365776062012, 0.05674666166305542, 0.06124826520681381, 0.05888453871011734, 0.06031028553843498, 0.06028660014271736, 0.061291616410017014, 0.058687858283519745, 0.05839062109589577, 0.060622379183769226, 0.057561252266168594, 0.05431323125958443, 0.05645253509283066, 0.05706046521663666, 0.055582404136657715, 0.058023083955049515, 0.05780568718910217, 0.057506002485752106, 0.055198922753334045, 0.05898261442780495, 0.05853218212723732, 0.05869569256901741, 0.06092040613293648, 0.05814783647656441, 0.05821439251303673, 0.05729581043124199, 0.0538858026266098, 0.05833181366324425, 0.05711178481578827, 0.054516106843948364, 0.057281188666820526, 0.05687880143523216, 0.05506109446287155]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:06 2016", "state": "available"}], "summary": "12552d110eb45fb1a7f62c68fe5184ac"}