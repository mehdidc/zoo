{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 32, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 2, "nbg3": 2, "nbg2": 3, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.008089136596671742, 0.009959711836417846, 0.011584797645741668, 0.010708729118711279, 0.0073879457329084925, 0.012573230317083905, 0.00975793654068399, 0.01367506787281537, 0.019441078340332978, 0.016124068807188828, 0.01674336513672067, 0.018503889318345654, 0.018134630960419586, 0.01729401547818856, 0.016323060277185924, 0.01326061668559579, 0.017103102991368024, 0.01703433778265767, 0.015499252923192493, 0.013729584828539313, 0.011227039869490956, 0.010869057966819501, 0.009531830180086312, 0.010757662879124136, 0.011016638311927366, 0.010500720957514423, 0.01395695854542112, 0.01240439948555226, 0.011962511907795324, 0.010441713373777825, 0.010959167816144259, 0.006425552753602754, 0.005457675397183563, 0.004612810072337784, 0.006525688092555015, 0.00710055619552458, 0.007018208364572629, 0.007357098675185664, 0.008573882690829352, 0.009893735085190217, 0.010472513097079786, 0.011839808151361243, 0.012613262892263322, 0.013073850378260293, 0.011842478714226841, 0.011082737106605425, 0.011778888744589126, 0.010323855728509978, 0.010219922811981813, 0.01046821826565077, 0.009896030729535115, 0.011764110671799914, 0.01070410784352912, 0.010965239972495126, 0.012026454718112008, 0.012441807106892785, 0.009884863599600974, 0.011850254979991794, 0.011234777252792373, 0.009066720419607328, 0.007096509566383881, 0.008270280860194391, 0.007711382133982684, 0.00755906059067967, 0.008282512044072049, 0.008301459648367997, 0.008194130832671601, 0.00656575010757031, 0.005839769241577086, 0.007307794348931776, 0.007136619835781919, 0.007025590734603028, 0.007660337359104909, 0.007402736917340313, 0.008533084578352586, 0.007639873332599503, 0.009476341867076112, 0.009930779839655417, 0.010570096826426883, 0.010430495893155076, 0.01053026770162028, 0.009883934432875115, 0.008897576718060452, 0.009077517341936023, 0.009430898878944301, 0.010254276561822383, 0.011148683915273678, 0.011353695826586477, 0.01109266426646012, 0.011744966261544119, 0.012309514707698668, 0.012501248473698087, 0.01251078063033, 0.012000768229351803, 0.012575075774170585, 0.0134626584243124, 0.01295821794646111, 0.01385412644756121, 0.013295134373409118, 0.013316729333410361, 0.01324535471622049, 0.013187942865873563, 0.01432620485201618, 0.012662362315794887, 0.012005633764493212, 0.012421241549444706, 0.012658898297529315, 0.012763668899950955, 0.01295488963973575, 0.014023339029897039, 0.0108069826362795, 0.010699420688735849, 0.010806716831436095, 0.010938353984058274, 0.011556057799425807, 0.011938353379855557, 0.013131396110909103, 0.012644852780498067, 0.013109733619018824, 0.01416614779636941, 0.013438117910938406, 0.01437058862030596, 0.01434988526444772, 0.014143184146082257, 0.013392483127542553, 0.013396644868487483, 0.013169877470190005, 0.013936042003063578, 0.01130933057223109, 0.011253632016107754, 0.011241301371161827, 0.011340465595988605, 0.011634345780626316, 0.011963580222958946, 0.012825706548969468, 0.011521821595851939, 0.01141287979310057, 0.01093650686239895, 0.010585332149829445, 0.01035394731247274, 0.010911247221660652, 0.011865208327891147, 0.011836250148971487, 0.01159832273743018, 0.01093580916649428, 0.010703010416800824, 0.009353016648664307, 0.010681939039628434, 0.010906639169659666, 0.011042264220110613, 0.009585606391897553, 0.009654433095420535, 0.009629734151675005, 0.009544040150546098, 0.009763458428029136, 0.009409943961308783, 0.00941569451441078, 0.009435246817819593, 0.009767777583201562, 0.010670098986548847, 0.010130623887178447, 0.010925757801339654, 0.01181241570475176, 0.010836246537625948, 0.011530658973098164, 0.011541468191663358, 0.012501771000302557, 0.01242030115702303, 0.01138205916287234, 0.011455138621633401, 0.01179894582797518, 0.01172278116128956, 0.010645214635578503, 0.01060087684605363, 0.010919293460183903, 0.0108994384627199, 0.010734126891186562, 0.010822507766878991, 0.010731693076392221, 0.011019327093908677, 0.01143326661186596, 0.011905502307602336, 0.012148461338676354, 0.012563324074411247, 0.01254452135465357, 0.012188020239567355, 0.011842493782899106, 0.012099736046439123, 0.013148318601437042, 0.014164848645598612, 0.013464413703127915, 0.012968323504539544, 0.013285748504737335, 0.01169683214052694, 0.01236128702746901, 0.012286437461707024, 0.01147164218394138, 0.011411222457847446, 0.010747704932486044, 0.010569428868920304, 0.009468556833582113, 0.009197470159073988, 0.009153965165149956, 0.008974867179690364, 0.010578316778651477, 0.01079899763301305, 0.00990544950486552, 0.009770921612765757, 0.010466021466144868, 0.010839345658208842, 0.010766488618554348, 0.010526323475128052, 0.010485447273038287, 0.00928261150342277, 0.010108599928506918, 0.009641891817778603, 0.010243855155422657, 0.010234772749233375, 0.009059415361961571, 0.010208884008939207, 0.009983224836925167, 0.010020202105866658, 0.010341177685176197, 0.009942129168703663, 0.00971775112200599, 0.009807163537218208, 0.009519453219782304, 0.009516897415369437, 0.00965443544790301, 0.009767100931003442, 0.008945407841763548, 0.009689628960853774, 0.010881342596760843, 0.01105523920924857, 0.011023950045102376, 0.011197748359695258, 0.011810103186890183, 0.01206969015102021, 0.011968197371705498, 0.013015263167495784, 0.0133102896992625, 0.01417114661377095, 0.013582821091397601, 0.014057022195974492, 0.014505627525199384, 0.014185808635727316, 0.01439201608779972, 0.015479219686324697, 0.015545772426907392, 0.015141772493202798, 0.015310947923091093, 0.014931100672075436, 0.014933944085379796, 0.014697455238195663, 0.015027462954400564, 0.015101928851371918, 0.014742874390051444, 0.013957528856863468, 0.015092504653393877, 0.015028323108813316, 0.01462633127300945, 0.014699214118883606, 0.014932832032594273, 0.014697033808440648, 0.014881436972267945, 0.014714125612541899, 0.014868546864906467, 0.014899299307719053, 0.015814651180136873, 0.015330074630380577, 0.013707717718179599, 0.01348722188411092, 0.013611898032121282, 0.013433497082112477, 0.013589404798136182, 0.012808543844921213, 0.01227782053943859, 0.012490138143494959, 0.011800060755450651, 0.012636789403482592, 0.012507173977202808], "moving_avg_accuracy_train": [0.018953513606266147, 0.03914768876603451, 0.059712410995466494, 0.08034763143038828, 0.10099743607643213, 0.12121637123632306, 0.14083153736112192, 0.1597382978864992, 0.17793261997584853, 0.1953767538692751, 0.21207149386856022, 0.22824734804044358, 0.2438843055986639, 0.25909656587836005, 0.2739057083169175, 0.2882498462972874, 0.30218714205815483, 0.3156466726786129, 0.3285228629977302, 0.34076709020040274, 0.3523286904042458, 0.3631828843079427, 0.37352121213314693, 0.3833186026746311, 0.3925871888357394, 0.40128451995331904, 0.4095166578031791, 0.4171743006930347, 0.42438708587843776, 0.43123888246432046, 0.4377936910963491, 0.4440510557330227, 0.44993379997745764, 0.45550263735697283, 0.4607424195330511, 0.4657207490140852, 0.47046162616486387, 0.47493310079344025, 0.47921541133055984, 0.48331359539014873, 0.4872413792735222, 0.49107622081853064, 0.494699639220943, 0.498239589444982, 0.501672082518064, 0.5049380375933618, 0.5081377417301589, 0.5112732778711426, 0.5143603634111324, 0.5174175780101724, 0.520401549981442, 0.5232986772484325, 0.5260547571172585, 0.5287816947730114, 0.5314056384774656, 0.5340043529900457, 0.536529171907311, 0.539036312913793, 0.5415321580493702, 0.5439783814690087, 0.5463706087002455, 0.5486677724345491, 0.5508956550632795, 0.5530914476803366, 0.5552397580964115, 0.5573568881780124, 0.5594599789490816, 0.5615527234406629, 0.5636268196366483, 0.5656770848225313, 0.56771058844576, 0.569694093381638, 0.5716187567524997, 0.5735973474624472, 0.575526816527572, 0.5774168345564317, 0.5792572876133393, 0.5810926597252519, 0.5829536138235555, 0.5847470190524956, 0.5865261693240179, 0.5882948513314925, 0.5900285352644193, 0.5917585866671486, 0.5934318543212626, 0.5951306023170617, 0.5967851056466328, 0.5983949942837045, 0.5999834390344592, 0.6015362721970431, 0.6030732949231213, 0.6046077500492109, 0.6061119925495961, 0.6075820321916003, 0.6090700813372428, 0.6105348475552166, 0.611976333989479, 0.6133875319743444, 0.6147575915595327, 0.6161161671730977, 0.6174434448240973, 0.6187239891671306, 0.6199810386746516, 0.6212426276135725, 0.6224709915133448, 0.6236439122897974, 0.6248017754385862, 0.6259460867224776, 0.6270875740208371, 0.6282334230810089, 0.6293763304268394, 0.6304863993440576, 0.6315924182147921, 0.63269482809251, 0.6338009292741228, 0.6349196171756603, 0.6360101776930056, 0.6371079035502739, 0.638151660393244, 0.63917474690906, 0.6401862416256844, 0.6411686664837416, 0.6421643839012128, 0.6431372594876511, 0.6440988780213981, 0.6450177770755706, 0.6459447676231354, 0.6468720290195058, 0.6478018953774298, 0.6486991929197902, 0.6496252711995627, 0.650551603408464, 0.6515155107298084, 0.6524667326761612, 0.6534391259171737, 0.6543955879447808, 0.6553470845731987, 0.6562917871935365, 0.6572164243137455, 0.658132339127895, 0.6590495963153732, 0.6599704228364752, 0.6608642348233149, 0.6617662858126518, 0.6626502473649691, 0.6635109169287214, 0.6643436482563365, 0.6651326339809521, 0.665917125895011, 0.6666790082379112, 0.6674413962084168, 0.6682157928901775, 0.6690127313025717, 0.6698229818261074, 0.6706218896639379, 0.6714083360334614, 0.6721858201326808, 0.6729390342445973, 0.6736611047727031, 0.6743597963729984, 0.6750305075406542, 0.675701540858202, 0.6763566241178044, 0.6769950271764467, 0.6776323689470818, 0.6782757310049391, 0.6789361370653441, 0.6796095575792324, 0.6802621390179222, 0.6809029046865435, 0.6815748167430368, 0.6822330520653185, 0.6829091692125149, 0.6836036691021253, 0.6842891728718223, 0.6849642189359689, 0.6856252027675013, 0.6862665911920708, 0.6869136312872879, 0.6875773475813165, 0.6882769627447426, 0.6889972611465788, 0.6897384996117935, 0.6904544784043055, 0.6911453622937569, 0.6918462128537869, 0.6925281316316234, 0.693213866047134, 0.6938914808901411, 0.6945338142345434, 0.6951723681135531, 0.6957912444320428, 0.6964063618389216, 0.6969995310836932, 0.6975892230242349, 0.6981687738957225, 0.6987391978050613, 0.6993037325972757, 0.6998490162912212, 0.7003723236991054, 0.7009106575840398, 0.7014323604614332, 0.7019483599784591, 0.702468527066392, 0.7029971313145792, 0.703540304453424, 0.7040826026521846, 0.7046056564096683, 0.7050972950818706, 0.7055815865166053, 0.7060546511888189, 0.7065339238652489, 0.7070094110525982, 0.7074954782414505, 0.707956190199513, 0.7084196590867692, 0.7089181252448143, 0.7093969717215788, 0.7099348903959048, 0.7104584726349227, 0.7109715493286102, 0.7114658704362623, 0.7119781887486254, 0.7124741164130762, 0.7129738936848823, 0.7134376801711837, 0.7139155418779025, 0.7143874700925209, 0.7148354930225914, 0.7152828914870359, 0.7157761948597886, 0.7162387330369234, 0.716699159174907, 0.7171553953776636, 0.7176311121268113, 0.7181104104748537, 0.7185883180131011, 0.7190835029153716, 0.7195709859571677, 0.7200631991174034, 0.7205154915568535, 0.7209364695963969, 0.7213339510224622, 0.7217242724380731, 0.722154580722828, 0.7225488336255359, 0.7229687654046397, 0.7233885206355859, 0.7238128033196278, 0.7241969828840751, 0.7246055235099349, 0.7250359890910658, 0.725481500785503, 0.7259381927842875, 0.7264119946010507, 0.7268709683194708, 0.7273212470470014, 0.7277520745386836, 0.7281909725550072, 0.7286510488875463, 0.7291441005487178, 0.7296274106223528, 0.7301228435576721, 0.7306384876637451, 0.7311677075746961, 0.731697483917171, 0.7322184244039608, 0.7327430744135001, 0.7332663766470762, 0.7337838155846664, 0.7343122896463548, 0.7348483701709219, 0.7353702980751567, 0.7358772355699206, 0.7363706816961604, 0.7368636113347762, 0.7373142955535965, 0.7377640891779157, 0.7382130812671839, 0.7386613159260875, 0.7391065797976722], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 908400680, "moving_var_accuracy_train": [0.003233121102206244, 0.0065800513854362705, 0.009728216450255891, 0.012587705706810625, 0.015166665023407532, 0.017329246572065644, 0.019059114593790186, 0.02037039347648685, 0.02131265433545703, 0.021920069167537477, 0.022236491343577303, 0.0223677665329299, 0.02233161985473516, 0.022181173634616642, 0.021936852569044343, 0.021594955961738924, 0.021183694283698068, 0.02069575553603569, 0.020118346476639293, 0.019455801727091358, 0.018713256947843763, 0.01790225298075084, 0.017073956882668287, 0.016230460947202725, 0.01538057505731545, 0.014523309668703275, 0.013680891544044834, 0.012840557841297354, 0.01202472048834455, 0.011244772487598918, 0.010506984884661681, 0.009808677905962165, 0.009139270233974836, 0.008504450758412725, 0.00790110353784618, 0.007334047063857163, 0.006802925602900421, 0.006302579810796399, 0.005837365481543691, 0.005404784946665739, 0.00500315382810956, 0.004635192532376507, 0.004289835727409321, 0.00397363338296645, 0.003682308122940614, 0.003410075473631318, 0.0031612108853355135, 0.0029335740788246994, 0.002725987545123159, 0.00253750784055209, 0.0023638938550247833, 0.002203044587132566, 0.002051103914609441, 0.0019129192239537662, 0.0017835930266356893, 0.0016660135780331715, 0.0015567846153146795, 0.0014576779580206588, 0.0013679733486856496, 0.0012850320949861743, 0.001208033645620396, 0.001134722932058154, 0.0010659217879189263, 0.0010027231560811342, 0.0009439879792673628, 0.0008899293393824059, 0.0008407433225663732, 0.0007960852058731317, 0.0007551935605576283, 0.000717506490493859, 0.0006829720743156274, 0.0006500834933599382, 0.0006184141058441737, 0.0005918060860371719, 0.0005661311352929165, 0.0005416675351083548, 0.0005179861886896436, 0.0004965048869233598, 0.0004780227496349579, 0.0004591671955081702, 0.00044173885715527444, 0.0004257190958318245, 0.0004101981260622384, 0.00039611601416078676, 0.0003817028345254411, 0.00036950425385198245, 0.00035719025987483916, 0.00034479690670130775, 0.0003330256265669782, 0.0003214246813876658, 0.0003105441629932291, 0.0003006807194997471, 0.0002909773570494612, 0.0002813287702860901, 0.00027312450559610683, 0.00026512191569635045, 0.000257310672388178, 0.00024950292292175163, 0.00024144620003227374, 0.00023391312930900814, 0.00022637681004369372, 0.00021849727336959422, 0.0002108691072118634, 0.00020410665634794638, 0.0001972758915455263, 0.00018992999072147952, 0.00018300281529123983, 0.00017648756859208806, 0.00017056575100372318, 0.00016532590652161878, 0.00016054945067983567, 0.0001555847826206189, 0.00015103580404034474, 0.0001468699914827205, 0.00014319413075013543, 0.0001401378812645397, 0.00013682799331601945, 0.000133990212503856, 0.00013039604637869108, 0.00012677679591042027, 0.00012330721037521108, 0.0001196629167532493, 0.00011661970365702337, 0.00011347611545151069, 0.00011045089574636917, 0.00010700518541756398, 0.00010403847015327723, 0.00010137294641273996, 9.901751476385401e-05, 9.636204920320237e-05, 9.444443310528065e-05, 9.272281204598317e-05, 9.181258675865773e-05, 9.077473680380203e-05, 9.020720065992345e-05, 8.941985708621979e-05, 8.862598388261196e-05, 8.779555286221107e-05, 8.671058181260405e-05, 8.558962315235252e-05, 8.46029075689396e-05, 8.377391014972955e-05, 8.258661794512233e-05, 8.165122003688529e-05, 8.051859026697408e-05, 7.913350012200216e-05, 7.746112328572677e-05, 7.531749721997773e-05, 7.33245955669916e-05, 7.121631835009984e-05, 6.932580527323571e-05, 6.779043673241084e-05, 6.672739055751446e-05, 6.596320469977259e-05, 6.511116782991654e-05, 6.41665320761554e-05, 6.319021258939063e-05, 6.197717481596285e-05, 6.0471929962397316e-05, 5.881826653706529e-05, 5.698512111712348e-05, 5.533918042474311e-05, 5.366746907537147e-05, 5.196874835538814e-05, 5.0427714313216436e-05, 4.911017551930874e-05, 4.8124383448954137e-05, 4.739340180078855e-05, 4.648682442781312e-05, 4.553336776378423e-05, 4.5043223292355386e-05, 4.443836461861442e-05, 4.410873772735079e-05, 4.403883482463613e-05, 4.386419010659204e-05, 4.357895579441204e-05, 4.315315684489491e-05, 4.2540253160951664e-05, 4.205417580822307e-05, 4.181343209803332e-05, 4.203724128029175e-05, 4.250298524145242e-05, 4.319759687813273e-05, 4.3491467872262574e-05, 4.343820602336675e-05, 4.3515108988479326e-05, 4.334871706572588e-05, 4.32459305566944e-05, 4.3053794380197665e-05, 4.2461744070157016e-05, 4.188532917072601e-05, 4.1143867331939094e-05, 4.0434805416952695e-05, 3.9557972651743206e-05, 3.873180464922769e-05, 3.788153709808274e-05, 3.702183431538259e-05, 3.6187946668429686e-05, 3.5245160763531094e-05, 3.418530047549586e-05, 3.337500077296352e-05, 3.248706572619175e-05, 3.163465866770974e-05, 3.090635699525687e-05, 3.0330523356546193e-05, 2.995280454975396e-05, 2.960431012218941e-05, 2.91061462089303e-05, 2.8370908844080226e-05, 2.7644661703488604e-05, 2.689430719000874e-05, 2.627219715635953e-05, 2.5679770028723134e-05, 2.5238144834560728e-05, 2.4624629925819853e-05, 2.409539761832798e-05, 2.3922074452941512e-05, 2.3593512542434502e-05, 2.3838369789889456e-05, 2.392177806003514e-05, 2.3898829496479382e-05, 2.370812676406498e-05, 2.369954456630136e-05, 2.3543088344980475e-05, 2.3436775403207785e-05, 2.3028979006768883e-05, 2.2781247402826193e-05, 2.2507568820319676e-05, 2.20633328511087e-05, 2.1658488039883048e-05, 2.1682773194017113e-05, 2.143996996238041e-05, 2.1203903022988373e-05, 2.095687597504158e-05, 2.089794620631375e-05, 2.0875693743607848e-05, 2.0843684905270092e-05, 2.096618920167336e-05, 2.1008327725855727e-05, 2.108795910925229e-05, 2.082027925538092e-05, 2.0333253917843996e-05, 1.9721851882662268e-05, 1.912082396175664e-05, 1.8875228544939224e-05, 1.8386623852088274e-05, 1.813504575879133e-05, 1.7907291268072002e-05, 1.7736704305065774e-05, 1.729137931420968e-05, 1.706439036958952e-05, 1.702565688147593e-05, 1.710941722225077e-05, 1.72755837358098e-05, 1.75684188163419e-05, 1.770748880251207e-05, 1.7761498314459932e-05, 1.7655859431317297e-05, 1.7623956706780672e-05, 1.7766593121966705e-05, 1.817783327502617e-05, 1.8462347593017595e-05, 1.882519697430653e-05, 1.9335676874025857e-05, 1.9922772613946863e-05, 2.045646210996808e-05, 2.085322681596168e-05, 2.1245222826951996e-05, 2.1585307593249022e-05, 2.18364643211351e-05, 2.2166381393918547e-05, 2.2536184213908778e-05, 2.2734244427488872e-05, 2.2773690597116162e-05, 2.2687723252913754e-05, 2.2605767585255317e-05, 2.2173237212572528e-05, 2.177674223161905e-05, 2.1413413074486213e-05, 2.1080300552019516e-05, 2.0756609734864733e-05], "duration": 107522.380081, "accuracy_train": [0.1895351360626615, 0.2208952652039498, 0.2447949110603544, 0.2660646153446844, 0.2868456778908269, 0.30318678767534146, 0.31736803248431156, 0.3298991426148948, 0.3416815187799926, 0.35237395891011447, 0.36232415386212624, 0.37383003558739386, 0.3846169236226467, 0.3960069083956257, 0.407187990263935, 0.4173470881206165, 0.4276228039059616, 0.4367824482627353, 0.4444085758697859, 0.4509651350244555, 0.4563830922388335, 0.4608706294412145, 0.4665661625599852, 0.47149511754798823, 0.4760044642857143, 0.4795605000115356, 0.48360589845191954, 0.48609308670173496, 0.4893021525470654, 0.4929050517372647, 0.49678696878460693, 0.500367337463086, 0.5028784981773717, 0.5056221737726099, 0.5079004591177556, 0.5105257143433923, 0.5131295205218716, 0.5151763724506275, 0.5177562061646365, 0.5201972519264488, 0.5225914342238833, 0.5255897947236065, 0.5273104048426541, 0.5300991414613326, 0.5325645201758029, 0.534331633271041, 0.5369350789613326, 0.5394931031399963, 0.542144133271041, 0.5449325094015319, 0.5472572977228681, 0.5493728226513473, 0.5508594759366925, 0.5533241336747877, 0.5550211318175526, 0.5573927836032668, 0.5592525421626984, 0.5616005819721299, 0.5639947642695644, 0.5659943922457549, 0.5679006537813769, 0.5693422460432817, 0.570946598721853, 0.5728535812338501, 0.5745745518410853, 0.5764110589124216, 0.5783877958887044, 0.5803874238648948, 0.5822936854005168, 0.584129471495478, 0.5860121210548173, 0.5875456378045405, 0.5889407270902547, 0.5914046638519749, 0.5928920381136951, 0.5944269968161683, 0.5958213651255075, 0.5976110087324659, 0.5997022007082872, 0.6008876661129567, 0.6025385217677187, 0.6042129893987633, 0.6056316906607604, 0.6073290492917128, 0.6084912632082872, 0.6104193342792543, 0.6116756356127722, 0.6128839920173496, 0.6142794417912514, 0.615511770660299, 0.6169064994578258, 0.6184178461840163, 0.6196501750530639, 0.6208123889696383, 0.6224625236480251, 0.6237177435169804, 0.6249497118978405, 0.6260883138381322, 0.6270881278262275, 0.6283433476951827, 0.6293889436830934, 0.6302488882544297, 0.6312944842423404, 0.6325969280638611, 0.6335262666112956, 0.6342001992778701, 0.6352225437776855, 0.6362448882775009, 0.6373609597060723, 0.6385460646225545, 0.6396624965393134, 0.6404770195990218, 0.6415465880514027, 0.6426165169919712, 0.6437558399086379, 0.644987808289498, 0.6458252223491141, 0.6469874362656884, 0.6475454719799741, 0.6483825255514027, 0.6492896940753046, 0.6500104902062569, 0.6511258406584532, 0.6518931397655962, 0.65275344482512, 0.6532878685631229, 0.6542876825512182, 0.6552173815868402, 0.6561706925987449, 0.6567748708010336, 0.6579599757175157, 0.6588885932885751, 0.6601906766219084, 0.661027730193337, 0.6621906650862864, 0.6630037461932448, 0.663910554228959, 0.664794110776578, 0.6655381583956257, 0.6663755724552418, 0.6673049110026762, 0.6682578615263935, 0.6689085427048727, 0.6698847447166851, 0.6706059013358251, 0.6712569430024917, 0.6718382302048727, 0.6722335055024917, 0.6729775531215394, 0.6735359493240126, 0.6743028879429679, 0.6751853630260244, 0.6761851770141196, 0.6771152365379292, 0.6778120602044112, 0.6784863533591731, 0.6791831770256552, 0.6797179612518457, 0.6801597395256552, 0.6806480207756552, 0.681066908049557, 0.6817408407161315, 0.6822523734542267, 0.6827406547042267, 0.6833684448827981, 0.6840659895256552, 0.6848797916089886, 0.6856703422042267, 0.6861353719661315, 0.6866697957041344, 0.6876220252514765, 0.6881571699658545, 0.6889942235372831, 0.6898541681086194, 0.6904587067990956, 0.691039633513289, 0.691574057251292, 0.6920390870131967, 0.6927369921442414, 0.6935507942275747, 0.6945734992155776, 0.6954799467631044, 0.6964096457987264, 0.696898287536914, 0.6973633172988187, 0.6981538678940569, 0.6986654006321521, 0.6993854757867295, 0.6999900144772057, 0.7003148143341639, 0.7009193530246401, 0.7013611312984496, 0.7019424185008306, 0.7023380542866372, 0.7028964504891104, 0.7033847317391104, 0.7038730129891104, 0.7043845457272057, 0.7047565695367295, 0.7050820903700628, 0.7057556625484496, 0.7061276863579734, 0.7065923556316906, 0.7071500308577888, 0.707754569548265, 0.708428862703027, 0.7089632864410299, 0.7093131402270211, 0.7095220431316906, 0.7099402094292174, 0.7103122332387413, 0.7108473779531193, 0.7112887957387413, 0.7118700829411222, 0.7121025978220745, 0.7125908790720745, 0.7134043206672204, 0.7137065900124584, 0.7147761584648394, 0.7151707127860835, 0.7155892395717978, 0.7159147604051311, 0.716589053559893, 0.7169374653931341, 0.717471889131137, 0.7176117585478959, 0.7182162972383721, 0.7186348240240864, 0.7188676993932264, 0.7193094776670359, 0.7202159252145626, 0.720401576631137, 0.7208429944167589, 0.7212615212024732, 0.72191256286914, 0.7224240956072352, 0.7228894858573275, 0.7235401670358066, 0.7239583333333334, 0.7244931175595238, 0.7245861235119048, 0.7247252719522886, 0.7249112838570506, 0.7252371651785714, 0.726027355285622, 0.7260971097499077, 0.7267481514165743, 0.7271663177141011, 0.7276313474760059, 0.7276545989641011, 0.7282823891426725, 0.728910179321244, 0.7294911060354374, 0.7300484207733481, 0.7306762109519196, 0.7310017317852529, 0.7313737555947767, 0.7316295219638244, 0.7321410547019196, 0.7327917358803987, 0.7335815654992617, 0.7339772012850683, 0.7345817399755445, 0.7352792846184016, 0.7359306867732558, 0.7364654709994463, 0.7369068887850683, 0.737464924499354, 0.7379760967492617, 0.7384407660229789, 0.7390685562015504, 0.7396730948920266, 0.7400676492132705, 0.7404396730227943, 0.7408116968323182, 0.7412999780823182, 0.7413704535229789, 0.7418122317967885, 0.742254010070598, 0.74269542785622, 0.7431139546419343], "end": "2016-01-24 20:56:46.792000", "learning_rate_per_epoch": [0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025, 0.0008777035982348025], "accuracy_valid": [0.18899278755647592, 0.21940006118222893, 0.2396843232304217, 0.2636012801204819, 0.27976603680346385, 0.29700001176581325, 0.3115675592996988, 0.3236025155308735, 0.33246364363704817, 0.3449251105986446, 0.3574277579066265, 0.36503729762801207, 0.3750779485128012, 0.38597309158509036, 0.39661379894578314, 0.40467043957078314, 0.4149861163403614, 0.4222088549510542, 0.4301743105233434, 0.4340805605233434, 0.4427475527108434, 0.4436020448983434, 0.4478539156626506, 0.45448689288403615, 0.45815929734563254, 0.46185229198042166, 0.4653114410768072, 0.4672645660768072, 0.4695839020143072, 0.4730018707643072, 0.476318359375, 0.47774202277861444, 0.4793186417545181, 0.4816379776920181, 0.48248217479292166, 0.4841808640813253, 0.4868664109563253, 0.48846362010542166, 0.4897858033697289, 0.4903961549322289, 0.4907623658697289, 0.4949230515813253, 0.4971203172063253, 0.4998058640813253, 0.5010368622929217, 0.5032547180911144, 0.5039871399661144, 0.5062049957643072, 0.5075477692018072, 0.5092567535768072, 0.5103553863893072, 0.5121761459902108, 0.5159809158509037, 0.5164589020143072, 0.5184120270143072, 0.5191444488893072, 0.5216167403990963, 0.52392578125, 0.5264995528990963, 0.5282394225338856, 0.5319324171686747, 0.5349738798945783, 0.5376800169427711, 0.5384124388177711, 0.5401214231927711, 0.5418407026543675, 0.5438041227409638, 0.5462661191641567, 0.548229539250753, 0.549328172063253, 0.550548875188253, 0.5527564358998494, 0.5545874905873494, 0.5566729809864458, 0.5584937405873494, 0.5589820218373494, 0.5592055722891567, 0.5599379941641567, 0.5621352597891567, 0.563732468938253, 0.5655738187123494, 0.5671710278614458, 0.5687785320971386, 0.5697550945971386, 0.5706095867846386, 0.5721965008471386, 0.5728068524096386, 0.5742716961596386, 0.5750041180346386, 0.5765910320971386, 0.5783103115587349, 0.5808737881212349, 0.5808737881212349, 0.5827151378953314, 0.5832034191453314, 0.5836814053087349, 0.5852786144578314, 0.5849021084337349, 0.5855227550828314, 0.5863772472703314, 0.5871096691453314, 0.5882083019578314, 0.5890524990587349, 0.5901717220444277, 0.5912806499435241, 0.5918910015060241, 0.5918910015060241, 0.5926234233810241, 0.5939661968185241, 0.5943221126694277, 0.5958281367658133, 0.5964384883283133, 0.5968046992658133, 0.5965605586408133, 0.5979033320783133, 0.5985136836408133, 0.5985033885542168, 0.6004771037274097, 0.6013315959149097, 0.6016875117658133, 0.6024302287274097, 0.6029082148908133, 0.6026640742658133, 0.6032744258283133, 0.6036509318524097, 0.6045054240399097, 0.605858492564006, 0.6059702677899097, 0.6070997858621988, 0.6078322077371988, 0.6084425592996988, 0.6085646296121988, 0.6090529108621988, 0.6096632624246988, 0.6106398249246988, 0.6111384012612951, 0.6115046121987951, 0.6127356104103916, 0.6137224679969879, 0.6143328195594879, 0.6146990304969879, 0.6145666650978916, 0.6146887354103916, 0.6150549463478916, 0.6148108057228916, 0.6149328760353916, 0.6156858880835843, 0.6159197336219879, 0.6161638742469879, 0.6162859445594879, 0.6172830972326807, 0.6175272378576807, 0.6183817300451807, 0.6188700112951807, 0.6192362222326807, 0.6201010095067772, 0.6202230798192772, 0.6201010095067772, 0.6203451501317772, 0.6210775720067772, 0.6205892907567772, 0.6205789956701807, 0.6208128412085843, 0.6214437829442772, 0.6220541345067772, 0.6217996987951807, 0.6217894037085843, 0.6232645425451807, 0.6241293298192772, 0.6241293298192772, 0.6243734704442772, 0.6248720467808735, 0.6256147637424698, 0.6259809746799698, 0.6262251153049698, 0.6263471856174698, 0.6263471856174698, 0.6265913262424698, 0.6272016778049698, 0.6274458184299698, 0.6279340996799698, 0.6270693124058735, 0.6273134530308735, 0.6273134530308735, 0.6276899590549698, 0.6272016778049698, 0.6275678887424698, 0.6269472420933735, 0.6271810876317772, 0.6270487222326807, 0.6274252282567772, 0.6274252282567772, 0.6275472985692772, 0.6276796639683735, 0.6286562264683735, 0.6289003670933735, 0.6296430840549698, 0.6292768731174698, 0.6296533791415663, 0.6291650978915663, 0.630528461502259, 0.630650531814759, 0.630772602127259, 0.631382953689759, 0.6314947289156627, 0.6316167992281627, 0.6308843773531627, 0.6313726586031627, 0.6313726586031627, 0.6317388695406627, 0.6322271507906627, 0.6319830101656627, 0.6324712914156627, 0.632847797439759, 0.6327154320406627, 0.6325933617281627, 0.6325830666415663, 0.6328272072665663, 0.633214008377259, 0.6325830666415663, 0.6333257836031627, 0.6328375023531627, 0.6329595726656627, 0.6327154320406627, 0.633091938064759, 0.632847797439759, 0.633091938064759, 0.632725727127259, 0.633580219314759, 0.633824359939759, 0.6342008659638554, 0.634068500564759, 0.6340582054781627, 0.6340582054781627, 0.6335699242281627, 0.6338140648531627, 0.6335596291415663, 0.6335596291415663, 0.6341802757906627, 0.6336714043674698, 0.6333051934299698, 0.6331728280308735, 0.6335493340549698, 0.6329286874058735, 0.6326742516942772, 0.6323080407567772, 0.6320639001317772, 0.6320536050451807, 0.6319315347326807, 0.6319315347326807, 0.6324198159826807, 0.6313211831701807, 0.6309549722326807, 0.6314432534826807, 0.6318094644201807, 0.6316873941076807, 0.6319315347326807, 0.6331625329442772, 0.6327860269201807, 0.6322977456701807, 0.6322977456701807, 0.6324198159826807, 0.6322977456701807, 0.6320536050451807, 0.6329080972326807, 0.6325418862951807, 0.6324198159826807, 0.6325418862951807, 0.6324095208960843, 0.6320433099585843, 0.6327963220067772, 0.6335287438817772, 0.6334066735692772, 0.6330404626317772, 0.6329183923192772, 0.6330507577183735, 0.6324404061558735, 0.6323183358433735, 0.6331831231174698, 0.6326845467808735, 0.6330507577183735], "accuracy_test": 0.3590302136479592, "start": "2016-01-23 15:04:44.412000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0], "accuracy_train_last": 0.7431139546419343, "batch_size_eval": 1024, "accuracy_train_std": [0.011429036074591482, 0.012221749934376224, 0.013122583159, 0.014950112808252671, 0.013832004408189456, 0.01390564329920498, 0.013177880663459204, 0.012395689791944945, 0.012665464998218688, 0.013264342451275188, 0.012796802048613568, 0.014533086914435755, 0.013609254740205185, 0.014335039562381599, 0.014675416556269732, 0.01611180586124924, 0.016451694404529763, 0.01644985864448559, 0.01598769429084175, 0.015293746891433172, 0.014634836398548786, 0.014624214175150165, 0.014966917612043698, 0.015217962100413424, 0.015501193575079071, 0.01588528427707682, 0.015576186067022496, 0.015149465209061934, 0.015362408031296059, 0.014672512628603222, 0.014527380169754044, 0.014027334464378826, 0.013690674110516537, 0.013052910559670134, 0.01271231423970401, 0.012856201978393945, 0.013645208679880364, 0.013104786876461598, 0.013121861420170917, 0.013341575512384758, 0.01364400294986655, 0.013762417859839738, 0.013286813295825144, 0.013714296341703671, 0.013791816494125057, 0.013581011620686092, 0.013771254215697798, 0.01335422147088949, 0.01348995544259963, 0.013642981867138412, 0.013072538720125329, 0.012979841237548691, 0.013215843760134927, 0.013146502219219373, 0.012869449435370892, 0.012724475840362535, 0.012865573620190578, 0.012707911000731018, 0.012581379378652046, 0.012300890710075521, 0.012438091348207577, 0.013088097493566674, 0.012936940166747544, 0.013225817867602768, 0.012658931351677285, 0.012305702531516373, 0.012637491893683959, 0.012557841235561348, 0.012814644043345107, 0.012266334180231264, 0.01215646188298651, 0.013092702879677337, 0.012716755184592914, 0.01273346211676061, 0.012968197493480669, 0.012915879474819201, 0.013480901967380521, 0.013980778898004762, 0.014613675564520248, 0.014848345120761169, 0.014826233149046053, 0.014314638307900517, 0.014187090639274102, 0.01453318698607402, 0.014632417387789995, 0.01475375311492416, 0.014551550106065837, 0.014214280601022124, 0.014206338226445337, 0.014486302679452516, 0.014506136607369862, 0.014359676371306742, 0.014427961162258793, 0.014285160439969037, 0.01399602070885202, 0.013944043963680059, 0.013865712031539995, 0.013793557638831831, 0.013949990802933016, 0.014439593030378388, 0.014054989652885461, 0.014016177439612447, 0.014351657554129791, 0.014759911784798418, 0.014912603157371824, 0.014779851121374988, 0.01489020216841386, 0.015037119783006571, 0.015061053889010691, 0.015374805569652716, 0.014709293911685968, 0.01449931787055193, 0.014563040996727526, 0.014168748327543876, 0.013949079274092708, 0.014023822170214136, 0.013669334119880765, 0.014042827761451179, 0.014102173126306681, 0.014143100197068785, 0.01394361429477902, 0.014176184257224047, 0.01418127997551641, 0.01409888707811088, 0.014249910102736912, 0.014001489601200411, 0.013942849650409931, 0.014175744523141402, 0.014266502076846228, 0.014138440967938821, 0.01411054949214771, 0.014394577360660656, 0.014385676562735669, 0.01385550825526938, 0.013560774377698023, 0.013821276239712991, 0.01324694914031201, 0.013268738004023192, 0.013621427796134549, 0.013725410388311416, 0.014224691834810286, 0.014357870734133058, 0.01453827215632788, 0.014819720191426529, 0.014462808071436219, 0.014417291797283764, 0.014697866697348022, 0.014681945147199803, 0.014540623814504031, 0.014168195505344993, 0.014116666590427079, 0.014255119065954816, 0.014284916284196907, 0.014229823725491452, 0.014149581431848201, 0.014119349607094656, 0.014177976405630557, 0.01410746193084522, 0.013988838588479326, 0.014303596674324452, 0.013901500498672423, 0.013932024240933365, 0.014191966532598712, 0.014121545658495617, 0.014264583209575998, 0.01416427603764799, 0.013549776226476405, 0.013547200751376014, 0.013388227187188505, 0.013492197955745074, 0.013833909189208633, 0.013743818205184256, 0.013581522359662626, 0.013366920446731117, 0.013223931108976121, 0.013546814746649746, 0.013292681432163285, 0.013348595125159032, 0.012868532931184493, 0.012875982027792507, 0.013257148160251003, 0.012916860882356577, 0.012818067395989018, 0.012623013425232173, 0.012615386221647262, 0.012760055564571916, 0.012496145047350842, 0.012457017510017331, 0.012181487768374438, 0.012442027352238814, 0.012384903285338405, 0.012155651051437531, 0.01187064547369402, 0.012263571478133808, 0.011970453858170528, 0.011837243429808244, 0.011809713097343256, 0.011632234957615924, 0.01173197792771412, 0.011893971558248477, 0.012188524344621797, 0.012199420684547548, 0.012252498781761427, 0.01241215497026569, 0.01243370456344143, 0.012409956516115416, 0.012627676600309347, 0.012387484096004245, 0.012314660882241113, 0.012474154429385502, 0.012427270385858688, 0.012431082958845012, 0.012417932814296083, 0.012231980597490706, 0.011988721903723635, 0.011981514496299328, 0.012176043624717458, 0.012040365160883847, 0.012024087246426783, 0.012406543513835043, 0.012381107368558058, 0.012364552694548512, 0.012253285292047174, 0.012304518031554783, 0.012325775482474072, 0.012227347841089727, 0.012233394541233688, 0.012325813964684535, 0.012233853061673815, 0.012450780093082049, 0.012638650220295927, 0.012544723364655468, 0.012562266874886667, 0.012472591730477843, 0.01232729919527252, 0.012345690230748841, 0.012054095537599091, 0.01209105756435271, 0.012112574782057796, 0.01202893214115496, 0.011746788937396828, 0.011789781616717643, 0.011722738700783154, 0.011583932439447562, 0.012009262739656683, 0.011933463086174214, 0.011702924552966322, 0.011801973497118656, 0.01174773151046802, 0.011902105487287809, 0.011893760010085193, 0.01210807423872463, 0.01228397484378332, 0.012343060872593145, 0.01242089386046124, 0.012596416440796843, 0.012589600712822441, 0.012487946524282862, 0.01245168878833385, 0.012402547600448219, 0.012738480090458384, 0.012842491803499681, 0.012504847186193097, 0.01238796996889358, 0.012222567290878767, 0.012345605448139632, 0.012686529543374098, 0.012518823657144709, 0.012612741480568549, 0.012531066398830027, 0.012631073358684372, 0.01253904085904951, 0.012543167915229015, 0.012693754717381803, 0.01269659639850905, 0.012898572340335528, 0.012788303373600837, 0.012825711130071445, 0.012810660342308669, 0.012946781766660555, 0.013206860332225703], "accuracy_test_std": 0.013946128952699427, "error_valid": [0.8110072124435241, 0.7805999388177711, 0.7603156767695783, 0.7363987198795181, 0.7202339631965362, 0.7029999882341867, 0.6884324407003012, 0.6763974844691265, 0.6675363563629518, 0.6550748894013554, 0.6425722420933735, 0.6349627023719879, 0.6249220514871988, 0.6140269084149097, 0.6033862010542168, 0.5953295604292168, 0.5850138836596386, 0.5777911450489458, 0.5698256894766567, 0.5659194394766567, 0.5572524472891567, 0.5563979551016567, 0.5521460843373494, 0.5455131071159638, 0.5418407026543675, 0.5381477080195783, 0.5346885589231928, 0.5327354339231928, 0.5304160979856928, 0.5269981292356928, 0.523681640625, 0.5222579772213856, 0.5206813582454819, 0.5183620223079819, 0.5175178252070783, 0.5158191359186747, 0.5131335890436747, 0.5115363798945783, 0.5102141966302711, 0.5096038450677711, 0.5092376341302711, 0.5050769484186747, 0.5028796827936747, 0.5001941359186747, 0.49896313770707834, 0.49674528190888556, 0.49601286003388556, 0.4937950042356928, 0.4924522307981928, 0.4907432464231928, 0.4896446136106928, 0.4878238540097892, 0.48401908414909633, 0.4835410979856928, 0.4815879729856928, 0.4808555511106928, 0.47838325960090367, 0.47607421875, 0.47350044710090367, 0.47176057746611444, 0.4680675828313253, 0.46502612010542166, 0.4623199830572289, 0.4615875611822289, 0.4598785768072289, 0.45815929734563254, 0.4561958772590362, 0.4537338808358433, 0.451770460749247, 0.450671827936747, 0.449451124811747, 0.44724356410015065, 0.44541250941265065, 0.4433270190135542, 0.44150625941265065, 0.44101797816265065, 0.4407944277108433, 0.4400620058358433, 0.4378647402108433, 0.436267531061747, 0.43442618128765065, 0.4328289721385542, 0.4312214679028614, 0.4302449054028614, 0.4293904132153614, 0.4278034991528614, 0.4271931475903614, 0.4257283038403614, 0.4249958819653614, 0.4234089679028614, 0.4216896884412651, 0.4191262118787651, 0.4191262118787651, 0.41728486210466864, 0.41679658085466864, 0.4163185946912651, 0.41472138554216864, 0.4150978915662651, 0.41447724491716864, 0.41362275272966864, 0.41289033085466864, 0.41179169804216864, 0.4109475009412651, 0.4098282779555723, 0.40871935005647586, 0.40810899849397586, 0.40810899849397586, 0.40737657661897586, 0.40603380318147586, 0.4056778873305723, 0.40417186323418675, 0.40356151167168675, 0.40319530073418675, 0.40343944135918675, 0.40209666792168675, 0.40148631635918675, 0.4014966114457832, 0.3995228962725903, 0.3986684040850903, 0.39831248823418675, 0.3975697712725903, 0.39709178510918675, 0.39733592573418675, 0.39672557417168675, 0.3963490681475903, 0.3954945759600903, 0.39414150743599397, 0.3940297322100903, 0.3929002141378012, 0.3921677922628012, 0.3915574407003012, 0.3914353703878012, 0.3909470891378012, 0.3903367375753012, 0.3893601750753012, 0.38886159873870485, 0.38849538780120485, 0.3872643895896084, 0.38627753200301207, 0.38566718044051207, 0.38530096950301207, 0.3854333349021084, 0.3853112645896084, 0.3849450536521084, 0.3851891942771084, 0.3850671239646084, 0.38431411191641573, 0.38408026637801207, 0.38383612575301207, 0.38371405544051207, 0.3827169027673193, 0.3824727621423193, 0.3816182699548193, 0.3811299887048193, 0.3807637777673193, 0.37989899049322284, 0.37977692018072284, 0.37989899049322284, 0.37965484986822284, 0.37892242799322284, 0.37941070924322284, 0.3794210043298193, 0.37918715879141573, 0.37855621705572284, 0.37794586549322284, 0.3782003012048193, 0.37821059629141573, 0.3767354574548193, 0.37587067018072284, 0.37587067018072284, 0.37562652955572284, 0.3751279532191265, 0.3743852362575302, 0.3740190253200302, 0.3737748846950302, 0.3736528143825302, 0.3736528143825302, 0.3734086737575302, 0.3727983221950302, 0.3725541815700302, 0.3720659003200302, 0.3729306875941265, 0.3726865469691265, 0.3726865469691265, 0.3723100409450302, 0.3727983221950302, 0.3724321112575302, 0.3730527579066265, 0.37281891236822284, 0.3729512777673193, 0.37257477174322284, 0.37257477174322284, 0.37245270143072284, 0.3723203360316265, 0.3713437735316265, 0.3710996329066265, 0.3703569159450302, 0.3707231268825302, 0.37034662085843373, 0.37083490210843373, 0.36947153849774095, 0.36934946818524095, 0.36922739787274095, 0.36861704631024095, 0.3685052710843373, 0.3683832007718373, 0.3691156226468373, 0.3686273413968373, 0.3686273413968373, 0.3682611304593373, 0.3677728492093373, 0.3680169898343373, 0.3675287085843373, 0.36715220256024095, 0.3672845679593373, 0.3674066382718373, 0.36741693335843373, 0.36717279273343373, 0.36678599162274095, 0.36741693335843373, 0.3666742163968373, 0.3671624976468373, 0.3670404273343373, 0.3672845679593373, 0.36690806193524095, 0.36715220256024095, 0.36690806193524095, 0.36727427287274095, 0.36641978068524095, 0.36617564006024095, 0.3657991340361446, 0.36593149943524095, 0.3659417945218373, 0.3659417945218373, 0.3664300757718373, 0.3661859351468373, 0.36644037085843373, 0.36644037085843373, 0.3658197242093373, 0.3663285956325302, 0.3666948065700302, 0.3668271719691265, 0.3664506659450302, 0.3670713125941265, 0.36732574830572284, 0.36769195924322284, 0.36793609986822284, 0.3679463949548193, 0.3680684652673193, 0.3680684652673193, 0.3675801840173193, 0.3686788168298193, 0.3690450277673193, 0.3685567465173193, 0.3681905355798193, 0.3683126058923193, 0.3680684652673193, 0.36683746705572284, 0.3672139730798193, 0.3677022543298193, 0.3677022543298193, 0.3675801840173193, 0.3677022543298193, 0.3679463949548193, 0.3670919027673193, 0.3674581137048193, 0.3675801840173193, 0.3674581137048193, 0.36759047910391573, 0.36795669004141573, 0.36720367799322284, 0.36647125611822284, 0.36659332643072284, 0.36695953736822284, 0.36708160768072284, 0.3669492422816265, 0.3675595938441265, 0.3676816641566265, 0.3668168768825302, 0.3673154532191265, 0.3669492422816265], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.5946543549974651, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0008777035868494191, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "optimization": "adadelta", "nb_data_augmentation": 0, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0005968160292629697, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.036150088054243155}, "accuracy_valid_max": 0.6342008659638554, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.6330507577183735, "loss_train": [9.64159870147705, 9.44716739654541, 9.295610427856445, 9.160165786743164, 9.034319877624512, 8.916482925415039, 8.80608081817627, 8.702499389648438, 8.604870796203613, 8.512378692626953, 8.424440383911133, 8.34054183959961, 8.260196685791016, 8.183100700378418, 8.108930587768555, 8.037471771240234, 7.968532562255859, 7.902026176452637, 7.8377790451049805, 7.77570915222168, 7.7157745361328125, 7.657883167266846, 7.6019463539123535, 7.54787015914917, 7.495599746704102, 7.444998741149902, 7.395989894866943, 7.348457336425781, 7.302361488342285, 7.2576375007629395, 7.214206218719482, 7.171963214874268, 7.1308441162109375, 7.090816974639893, 7.051790714263916, 7.013720989227295, 6.976579189300537, 6.940313816070557, 6.904884338378906, 6.870268821716309, 6.83642578125, 6.803314208984375, 6.770909309387207, 6.73917818069458, 6.708095550537109, 6.677654266357422, 6.647822856903076, 6.618572235107422, 6.589888572692871, 6.561750411987305, 6.534116744995117, 6.506982803344727, 6.480342388153076, 6.454169750213623, 6.428445339202881, 6.4031524658203125, 6.378279209136963, 6.353823661804199, 6.329765796661377, 6.3060784339904785, 6.282771587371826, 6.259830951690674, 6.237231731414795, 6.214975357055664, 6.193055629730225, 6.17146110534668, 6.150171756744385, 6.129194259643555, 6.108519554138184, 6.08812952041626, 6.068034648895264, 6.048210620880127, 6.028656959533691, 6.009345531463623, 5.990291595458984, 5.971488952636719, 5.952943325042725, 5.934629917144775, 5.9165358543396, 5.898673057556152, 5.8810224533081055, 5.863589286804199, 5.8463664054870605, 5.829342365264893, 5.812537670135498, 5.795932769775391, 5.779515743255615, 5.763302326202393, 5.747270584106445, 5.731415748596191, 5.71575927734375, 5.700277805328369, 5.684951305389404, 5.669802188873291, 5.65481424331665, 5.639991283416748, 5.625332355499268, 5.610830783843994, 5.596480369567871, 5.582278728485107, 5.568232536315918, 5.554337501525879, 5.540581703186035, 5.526980400085449, 5.513499736785889, 5.50016450881958, 5.486957550048828, 5.473886966705322, 5.460947036743164, 5.448148250579834, 5.43546199798584, 5.422895431518555, 5.410450458526611, 5.39811897277832, 5.385913372039795, 5.3738203048706055, 5.361850738525391, 5.349987983703613, 5.338229656219482, 5.3265862464904785, 5.315025806427002, 5.303558349609375, 5.292201519012451, 5.280941963195801, 5.269785404205322, 5.258739948272705, 5.247776985168457, 5.236922264099121, 5.226142883300781, 5.2154436111450195, 5.204834938049316, 5.194310665130615, 5.183860778808594, 5.173500061035156, 5.1632232666015625, 5.153018474578857, 5.142910003662109, 5.132870197296143, 5.122908592224121, 5.1130194664001465, 5.103208541870117, 5.093475818634033, 5.083816051483154, 5.074222564697266, 5.06470251083374, 5.055239677429199, 5.045837879180908, 5.036509037017822, 5.027251243591309, 5.018049240112305, 5.008902072906494, 4.999828815460205, 4.990812301635742, 4.981851577758789, 4.9729413986206055, 4.964100360870361, 4.955333232879639, 4.946615219116211, 4.9379401206970215, 4.929319381713867, 4.920755863189697, 4.912248134613037, 4.903787612915039, 4.895386695861816, 4.887024402618408, 4.878732681274414, 4.870480060577393, 4.862272262573242, 4.85411262512207, 4.8459978103637695, 4.837942123413086, 4.8299150466918945, 4.821949481964111, 4.8140387535095215, 4.806161880493164, 4.798339366912842, 4.790559768676758, 4.78279447555542, 4.775084018707275, 4.767417907714844, 4.759790420532227, 4.752198696136475, 4.744642734527588, 4.737137317657471, 4.729661464691162, 4.722217559814453, 4.714809894561768, 4.707442760467529, 4.700126647949219, 4.692847728729248, 4.685601711273193, 4.678410053253174, 4.671233654022217, 4.664107799530029, 4.657012939453125, 4.64995002746582, 4.642914772033691, 4.635928630828857, 4.628967761993408, 4.622040748596191, 4.615147113800049, 4.608277797698975, 4.601441383361816, 4.594638347625732, 4.58787202835083, 4.581121444702148, 4.574405670166016, 4.567723751068115, 4.561065673828125, 4.554433345794678, 4.547837734222412, 4.541263580322266, 4.534718990325928, 4.528205394744873, 4.521701812744141, 4.515240669250488, 4.508800983428955, 4.5024003982543945, 4.496014595031738, 4.489670753479004, 4.483335494995117, 4.47702169418335, 4.470746994018555, 4.464482307434082, 4.458259582519531, 4.452053546905518, 4.445871829986572, 4.439724922180176, 4.433598041534424, 4.427501201629639, 4.421407699584961, 4.415344715118408, 4.409318447113037, 4.403314113616943, 4.397327423095703, 4.391346454620361, 4.385399341583252, 4.379478931427002, 4.37357759475708, 4.367701053619385, 4.361850738525391, 4.356010913848877, 4.35019063949585, 4.34441614151001, 4.338651657104492, 4.3328938484191895, 4.32716178894043, 4.321444511413574, 4.315746784210205, 4.310074329376221, 4.3044233322143555, 4.298796653747559, 4.293193817138672, 4.287611961364746, 4.282031059265137, 4.2764763832092285, 4.270938396453857, 4.265406131744385, 4.2599077224731445, 4.254401206970215, 4.248939037322998, 4.243483543395996, 4.238045692443848, 4.232621669769287, 4.22721529006958, 4.221829414367676, 4.216475009918213, 4.211119651794434, 4.205785751342773, 4.200470447540283, 4.195183277130127, 4.189897060394287, 4.184634685516357, 4.179386615753174, 4.174160957336426, 4.168937683105469, 4.1637420654296875, 4.158557415008545, 4.153383731842041, 4.148224830627441, 4.143075942993164], "accuracy_train_first": 0.1895351360626615, "model": "residualv5", "loss_std": [0.1316414326429367, 0.13165931403636932, 0.13551358878612518, 0.13830424845218658, 0.14044484496116638, 0.14247776567935944, 0.1446019858121872, 0.14681275188922882, 0.14900989830493927, 0.151129812002182, 0.1531105786561966, 0.154990091919899, 0.15680253505706787, 0.15852847695350647, 0.16016322374343872, 0.1617097407579422, 0.1631864458322525, 0.1646760255098343, 0.16618910431861877, 0.16767607629299164, 0.16919927299022675, 0.1706986129283905, 0.17219823598861694, 0.1736910194158554, 0.17518335580825806, 0.1766633540391922, 0.17811468243598938, 0.17951227724552155, 0.18087764084339142, 0.18217389285564423, 0.18343035876750946, 0.18462221324443817, 0.1857537031173706, 0.18682163953781128, 0.18784672021865845, 0.18879428505897522, 0.18969647586345673, 0.19057372212409973, 0.1914217621088028, 0.19220255315303802, 0.19296471774578094, 0.1936667561531067, 0.19431908428668976, 0.19494420289993286, 0.19556018710136414, 0.1961798518896103, 0.1967804729938507, 0.19735991954803467, 0.1978786289691925, 0.19842061400413513, 0.198928102850914, 0.19940221309661865, 0.199881449341774, 0.20034198462963104, 0.20081640779972076, 0.20127059519290924, 0.2016848921775818, 0.20211823284626007, 0.20254488289356232, 0.20295289158821106, 0.2033645063638687, 0.2037503570318222, 0.2041294276714325, 0.20449787378311157, 0.20487231016159058, 0.20524007081985474, 0.2056182324886322, 0.20598112046718597, 0.2063455432653427, 0.20669296383857727, 0.20702815055847168, 0.2073601633310318, 0.20770345628261566, 0.20803233981132507, 0.20837266743183136, 0.20870999991893768, 0.2090606391429901, 0.20939646661281586, 0.20971113443374634, 0.21005359292030334, 0.21037445962429047, 0.210699662566185, 0.21101415157318115, 0.21133531630039215, 0.21166084706783295, 0.21199189126491547, 0.21231214702129364, 0.21262526512145996, 0.2129489630460739, 0.2132836878299713, 0.2136097401380539, 0.21392260491847992, 0.2142297774553299, 0.21454215049743652, 0.21484066545963287, 0.21512553095817566, 0.21542644500732422, 0.21571390330791473, 0.21597720682621002, 0.21625585854053497, 0.2165328413248062, 0.21677672863006592, 0.21705235540866852, 0.21732421219348907, 0.217594176530838, 0.21784959733486176, 0.21811290085315704, 0.21835729479789734, 0.2185910940170288, 0.21884466707706451, 0.21908116340637207, 0.21933577954769135, 0.21957726776599884, 0.21980895102024078, 0.22003446519374847, 0.22026556730270386, 0.22049246728420258, 0.22070002555847168, 0.22089865803718567, 0.22109083831310272, 0.2212623506784439, 0.22145158052444458, 0.22162578999996185, 0.22181406617164612, 0.22201743721961975, 0.22219015657901764, 0.22237759828567505, 0.22255699336528778, 0.2227155566215515, 0.22288233041763306, 0.2230336219072342, 0.22314542531967163, 0.2232721596956253, 0.22340139746665955, 0.2235284447669983, 0.22364836931228638, 0.22377881407737732, 0.2238885462284088, 0.22399471700191498, 0.224099263548851, 0.22420352697372437, 0.2243155539035797, 0.2244158536195755, 0.22451987862586975, 0.22458812594413757, 0.22465632855892181, 0.22471989691257477, 0.22478064894676208, 0.22484749555587769, 0.22490014135837555, 0.22494421899318695, 0.22501280903816223, 0.22507278621196747, 0.2251185029745102, 0.22516430914402008, 0.22519487142562866, 0.22525550425052643, 0.2252912074327469, 0.22533102333545685, 0.2253461331129074, 0.2253945916891098, 0.2254001498222351, 0.22542200982570648, 0.2254430204629898, 0.22546504437923431, 0.22549134492874146, 0.22552219033241272, 0.22553156316280365, 0.22555124759674072, 0.22555862367153168, 0.22556272149085999, 0.22556793689727783, 0.22556139528751373, 0.22555756568908691, 0.2255430519580841, 0.2255517840385437, 0.2255314141511917, 0.22552840411663055, 0.2255188226699829, 0.22551700472831726, 0.2255067527294159, 0.22548815608024597, 0.22549007833003998, 0.22549104690551758, 0.22547079622745514, 0.22545981407165527, 0.22541828453540802, 0.22537389397621155, 0.2253463864326477, 0.22530829906463623, 0.22527529299259186, 0.22526007890701294, 0.2252400517463684, 0.22520458698272705, 0.22516460716724396, 0.22511404752731323, 0.22507110238075256, 0.22502760589122772, 0.2249809056520462, 0.22493281960487366, 0.22488543391227722, 0.22482645511627197, 0.22478026151657104, 0.22474122047424316, 0.22469502687454224, 0.2246263176202774, 0.22456426918506622, 0.22450414299964905, 0.22443529963493347, 0.22439108788967133, 0.2243330180644989, 0.2242632657289505, 0.22418972849845886, 0.2241075187921524, 0.22403909265995026, 0.22396177053451538, 0.2238437980413437, 0.22375701367855072, 0.2236659675836563, 0.2235683798789978, 0.22348512709140778, 0.22338898479938507, 0.22327545285224915, 0.2231815606355667, 0.22307008504867554, 0.2229687124490738, 0.22285999357700348, 0.22276626527309418, 0.22267262637615204, 0.22256211936473846, 0.22243861854076385, 0.22232750058174133, 0.2222174108028412, 0.22209767997264862, 0.22199060022830963, 0.22186560928821564, 0.22174790501594543, 0.22162213921546936, 0.2215023785829544, 0.22135300934314728, 0.22122883796691895, 0.22108158469200134, 0.22095417976379395, 0.22083799540996552, 0.22070522606372833, 0.22055195271968842, 0.22041866183280945, 0.22027267515659332, 0.22009386122226715, 0.2199143022298813, 0.21974237263202667, 0.2195766121149063, 0.2194185107946396, 0.2192712128162384, 0.21910609304904938, 0.21892300248146057, 0.21875250339508057, 0.21858352422714233, 0.21843229234218597, 0.21824918687343597, 0.21805524826049805, 0.21788154542446136, 0.21769820153713226, 0.21753741800785065, 0.21736034750938416, 0.2171681523323059, 0.21698801219463348, 0.21678678691387177, 0.21660056710243225, 0.21641090512275696, 0.21622492372989655, 0.21602679789066315, 0.2158370316028595, 0.21561947464942932, 0.21540063619613647, 0.2151925265789032, 0.21499228477478027, 0.2147652506828308, 0.21454459428787231, 0.2143375128507614, 0.21411223709583282]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:11 2016", "state": "available"}], "summary": "ac253e758a67d7feda0a07fc6c9d8324"}