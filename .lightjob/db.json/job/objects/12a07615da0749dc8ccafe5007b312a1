{"content": {"hp_model": {"f0": 64, "f1": 64, "f2": 32, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.9674779176712036, 1.6791775226593018, 1.5607399940490723, 1.4845023155212402, 1.4238446950912476, 1.3724743127822876, 1.3266170024871826, 1.287367343902588, 1.2506320476531982, 1.2156996726989746, 1.184447169303894, 1.1542439460754395, 1.1268737316131592, 1.103844165802002, 1.077784776687622, 1.0565065145492554, 1.0340632200241089, 1.013188362121582, 0.9952787160873413, 0.9745230674743652, 0.9598894715309143, 0.9414220452308655, 0.9243003129959106, 0.9087718725204468, 0.895281195640564, 0.8815970420837402, 0.8676397800445557, 0.8536781668663025, 0.836479902267456, 0.8269125819206238, 0.8141836524009705, 0.8001759052276611, 0.7884766459465027, 0.7777162790298462, 0.7679640650749207, 0.7538153529167175, 0.7424489855766296, 0.7321964502334595, 0.7194017171859741, 0.7125003933906555, 0.7013469934463501, 0.6934951543807983, 0.6813233494758606, 0.6716969013214111, 0.6621430516242981, 0.655227780342102, 0.6465725302696228, 0.6374809145927429, 0.6288459897041321, 0.6218080520629883, 0.6140683889389038, 0.6056217551231384, 0.5979337096214294, 0.5920045971870422, 0.5826498866081238, 0.5768324136734009, 0.5682471990585327, 0.5614230632781982, 0.5550341010093689, 0.5477318167686462, 0.5438162684440613, 0.5351722240447998, 0.5286868214607239, 0.5194118022918701, 0.5172629356384277, 0.51063072681427, 0.503218948841095, 0.496628075838089, 0.4903452694416046, 0.4870057702064514, 0.48043015599250793, 0.4758854806423187, 0.46842849254608154, 0.46357378363609314, 0.4568396806716919, 0.4531588554382324, 0.4464986026287079, 0.44156405329704285, 0.43695777654647827, 0.43292543292045593, 0.4269625246524811, 0.42197248339653015, 0.41958558559417725, 0.4120495915412903, 0.40718209743499756, 0.40194082260131836, 0.3996220827102661, 0.39501017332077026, 0.38860708475112915, 0.3863053619861603, 0.38173338770866394, 0.37693923711776733, 0.3722616732120514, 0.36922314763069153, 0.3643686771392822, 0.36106109619140625, 0.3576616942882538, 0.3519986867904663, 0.34819430112838745, 0.3447927236557007, 0.3415200710296631, 0.3373013734817505, 0.33297058939933777, 0.3324541449546814, 0.3273628056049347, 0.3232320249080658, 0.32037508487701416, 0.31633487343788147, 0.31383317708969116, 0.3087009787559509, 0.3055584728717804, 0.3008791506290436, 0.2993272840976715, 0.2965756952762604, 0.29303571581840515, 0.28821393847465515, 0.28813618421554565, 0.2583903670310974, 0.24389928579330444, 0.24135804176330566, 0.23826885223388672, 0.23794282972812653, 0.23564927279949188, 0.23566916584968567, 0.23320543766021729, 0.23290494084358215, 0.23179218173027039, 0.23192179203033447, 0.23142974078655243, 0.23002444207668304, 0.23044271767139435, 0.22683557868003845, 0.22893346846103668, 0.22661317884922028, 0.22448882460594177, 0.22528983652591705, 0.2263333797454834, 0.22320890426635742, 0.22446414828300476, 0.22311429679393768, 0.22309952974319458, 0.22283028066158295, 0.2204383760690689, 0.21910150349140167, 0.22016890347003937, 0.21936984360218048, 0.21643730998039246, 0.21606238186359406, 0.21635796129703522, 0.21772710978984833, 0.21957559883594513, 0.21592962741851807, 0.2166593223810196, 0.21720410883426666, 0.21629022061824799, 0.21663042902946472, 0.21741421520709991, 0.21712572872638702, 0.2171812802553177, 0.21715323626995087, 0.2196953147649765, 0.21711333096027374, 0.21785861253738403, 0.2165459394454956, 0.21773342788219452, 0.21722611784934998, 0.21687236428260803, 0.21741852164268494, 0.21850886940956116, 0.21719731390476227, 0.21669447422027588, 0.21654264628887177, 0.21886451542377472, 0.2183733582496643, 0.21908211708068848, 0.2187986820936203, 0.21806995570659637, 0.2169618308544159, 0.21694913506507874, 0.21527887880802155, 0.2162543535232544, 0.21954825520515442, 0.2167527973651886, 0.21812894940376282, 0.21721918880939484, 0.21747204661369324, 0.21807026863098145, 0.21732357144355774, 0.21588067710399628, 0.2179311066865921, 0.21902769804000854, 0.21716910600662231, 0.21721906960010529, 0.21634484827518463, 0.21739932894706726, 0.21675290167331696, 0.21810229122638702, 0.2171802669763565, 0.2175559401512146, 0.21762853860855103, 0.21772941946983337, 0.21746988594532013, 0.21763940155506134, 0.21618987619876862], "moving_avg_accuracy_train": [0.03959458056478404, 0.08214615560977295, 0.12395708063688166, 0.16406480081585684, 0.2024866093959083, 0.23839568150472093, 0.273122556374044, 0.30635951890985846, 0.3370119662206076, 0.3667982188418101, 0.3923530596272027, 0.4177352252291742, 0.44117873822443693, 0.46353315583794746, 0.4843522898723236, 0.5038217881829872, 0.5217743449970713, 0.539433007333143, 0.5546660019059841, 0.5695472115333536, 0.5833236974098264, 0.5964060563510143, 0.6088566895551986, 0.6204458729437171, 0.6306739581934115, 0.639760472084757, 0.6488264693345684, 0.6576065734450854, 0.6665313000349161, 0.6739963618515149, 0.6812494133220943, 0.6871705120992426, 0.6943779328462213, 0.7013876979030075, 0.7073499671838585, 0.713020604030672, 0.7181473565832619, 0.7237935836591088, 0.7298585817785246, 0.734933502630065, 0.7404889033475863, 0.745505076083841, 0.7493477356381553, 0.7532268369762869, 0.757180840940157, 0.7615250924635277, 0.7646304894441037, 0.7675905764873733, 0.7716678766678625, 0.7754516314637009, 0.7787731972763563, 0.7824761027529012, 0.7850721141438164, 0.7886010373443757, 0.7924603735843291, 0.7938692963991612, 0.796571691406255, 0.8001175931924013, 0.8035389863856196, 0.8051998634368879, 0.8063369043057315, 0.8070301420543757, 0.8083538537221847, 0.8113443547183217, 0.8129364067649465, 0.8169310268627228, 0.8185526382948982, 0.8217717575980219, 0.8249527052232326, 0.8262626831205292, 0.8289830566447166, 0.8315474700128677, 0.8357360187964646, 0.8378855886649264, 0.838592559023932, 0.8410909881529157, 0.8427585395083513, 0.8460538098769145, 0.8482500370991252, 0.8503546329300948, 0.8507213266542042, 0.8517811593415431, 0.851300680335222, 0.8535718205139091, 0.8542698018069258, 0.8561583237718589, 0.8571951819343094, 0.8576914065484181, 0.8579660558356675, 0.8601403559714622, 0.8600820430521954, 0.8630420530615293, 0.8659036636699204, 0.8673632220329949, 0.8681328118359707, 0.8702251101443448, 0.8712060929814238, 0.8713312674134401, 0.8735639193842593, 0.8762404075734173, 0.8790862667733936, 0.881033881011752, 0.8813153111668521, 0.88172670842549, 0.881345906843969, 0.8813984246694004, 0.8841099147109968, 0.8864362513591293, 0.8867771165794364, 0.8887833988133809, 0.8873993812430893, 0.8874977374905504, 0.889843256630938, 0.8919379838644389, 0.8935744835007894, 0.8941778356651991, 0.8952208677536719, 0.9012396141962818, 0.9066587750946216, 0.9117801965769461, 0.9165010109562578, 0.9206056567690853, 0.9243950609553643, 0.927865978592063, 0.9310247177460534, 0.9338420063477402, 0.9363263407178111, 0.938715773569941, 0.9408359641046966, 0.9427488579812333, 0.9444820882141639, 0.9460629578119059, 0.9476530790665217, 0.9488307830242568, 0.9501069193766853, 0.95126009239149, 0.9519677409250431, 0.9528464400814314, 0.9537466594626848, 0.9544962588414901, 0.9551569834383766, 0.9556866395553639, 0.956288852047548, 0.9568121700024, 0.9576714199641386, 0.9584749718642271, 0.9591587131421824, 0.9597694299947231, 0.9603446517989145, 0.9608460393322013, 0.9612879875169212, 0.9616926802807791, 0.9621151045861268, 0.9624766852704636, 0.9627857597470625, 0.9629686317236298, 0.963247148794207, 0.9633955076101074, 0.9635825450158556, 0.9637833947155436, 0.9639362216107298, 0.9641807226616355, 0.9643100928038791, 0.964466089510479, 0.9645250702892668, 0.9646107411223279, 0.9646762191280353, 0.9647862665581627, 0.9648597326083725, 0.9648584948357228, 0.9648643562867666, 0.9649602402986399, 0.9650279347188497, 0.9650540185137144, 0.9650938060195781, 0.9651481438676941, 0.96519007248457, 0.9652092791469196, 0.9652312154406533, 0.9652857271907002, 0.9653742792466855, 0.9653796794816237, 0.9653613242537917, 0.9653052049213435, 0.9653245240840634, 0.9653883061602455, 0.9653574625205037, 0.9653575689816316, 0.9653902168799801, 0.96538243365636, 0.965400969343188, 0.965403700568476, 0.965373606587902, 0.965332607161347, 0.9653793409369528, 0.9653539720195218, 0.9653078885057387, 0.9652733887897624, 0.9652958895656404, 0.9652765406365311, 0.9652079733265233, 0.965199777218954, 0.9652901290697792, 0.9652388762045602], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03847803322665662, 0.08073898131588854, 0.12190001117752257, 0.16155121276120102, 0.20018551284238514, 0.23585970322795083, 0.26963383738557745, 0.3021586995995799, 0.3317962570210225, 0.3604202422470076, 0.3849112681917345, 0.40919325531269657, 0.43168695688986064, 0.45332494888912755, 0.47326300887596784, 0.49192953672519335, 0.5092787281957463, 0.5260160473942439, 0.5399840903863707, 0.554000906310083, 0.5669038618481259, 0.5789346494208434, 0.5899464932136987, 0.6001999790109283, 0.609335607521733, 0.6173460356155688, 0.6254831552750209, 0.633336612855576, 0.6413955532266449, 0.6482387080414052, 0.6547383147410297, 0.6601515961716707, 0.6661730694140668, 0.6722362794624945, 0.6774581463863505, 0.682410203312098, 0.6869402967327707, 0.691804807863334, 0.6964737776135216, 0.7000735878228019, 0.7040661349140157, 0.7077967931658371, 0.7105338860160455, 0.7134743733086428, 0.7166111521392997, 0.7199825399844813, 0.7220605225730061, 0.7242776513209765, 0.7269922525292404, 0.7294964287729278, 0.7321652264547465, 0.7347767229169525, 0.7362643414761609, 0.7389043500525659, 0.7417829050698996, 0.7425018107696114, 0.744311582394081, 0.746601615560923, 0.74882339583465, 0.749353006787706, 0.7494227065795679, 0.7491243729980418, 0.7496127087121683, 0.7514692559885419, 0.7525664180685281, 0.7547501530030156, 0.7551275708728948, 0.7574286080250632, 0.7591058279360359, 0.759230783781363, 0.7606249823234075, 0.7622928881290939, 0.7648285124844827, 0.7659926750726308, 0.7661187170062562, 0.7672443088316095, 0.7681607147330871, 0.7701736801103055, 0.7712589570540942, 0.772153345610733, 0.7717680362285, 0.7721619157287675, 0.7712529060083003, 0.7725894118118377, 0.7725480322835154, 0.7731974729840042, 0.7733720780952423, 0.7729199006415163, 0.7726248632317321, 0.7736888664605166, 0.773440032289992, 0.7751092008889297, 0.776932953475112, 0.7772996520093779, 0.7772003755791479, 0.7782524577501487, 0.7790416698064592, 0.778414187690271, 0.7802910071083675, 0.7819882335812658, 0.784229922271332, 0.7852891166029338, 0.7853726037566464, 0.7852615482002588, 0.7850742370361065, 0.7847418180388211, 0.7862157489984932, 0.7878261371069271, 0.7877576964948789, 0.7893003685810838, 0.7881567704466199, 0.7881721892698044, 0.7893142606289685, 0.790583324023903, 0.7918444628658652, 0.7921483801899715, 0.7924239647989864, 0.7962457096500365, 0.7998948585645509, 0.8030702588150236, 0.8058904684380394, 0.8084683667184823, 0.8109614326257003, 0.8130932696436273, 0.8150719286073519, 0.8168394851347944, 0.8182726241119024, 0.8196458393927302, 0.8209936554440446, 0.8218729820118389, 0.8227762982214231, 0.8237856248187085, 0.8247062257875154, 0.8253516611906916, 0.8259335825622097, 0.8265793821090761, 0.8269886737550962, 0.8274313079326739, 0.8280972038713343, 0.8282916191675593, 0.8285886632466618, 0.828685104480354, 0.829116786991656, 0.8293577873681681, 0.8299185435993482, 0.83037542559107, 0.83073676174996, 0.8311341769718014, 0.8314542000690489, 0.8317055997628218, 0.8319684805809673, 0.8321827182721175, 0.8323500886229931, 0.8326960344387812, 0.8328975223917403, 0.8330056193619036, 0.8330886405864812, 0.8330809989958301, 0.8331320681945151, 0.8331780304733316, 0.8333323483314954, 0.8334702048951832, 0.833644133436162, 0.8337996396143831, 0.8337931107997821, 0.8338238559603912, 0.8337894619400299, 0.8338439565404546, 0.8339062382207465, 0.8338656649916688, 0.8340122545542489, 0.8340454994019114, 0.8340876267960576, 0.8340767133257893, 0.8340668912025477, 0.8340346667377899, 0.8341022914608482, 0.8341265326178509, 0.8341483496591532, 0.8342422566924849, 0.8341670521075737, 0.8341848171999037, 0.8342506634166603, 0.8341634406367413, 0.8342181879699044, 0.8342176029360917, 0.8342191354229795, 0.8341930120726997, 0.8342214177084267, 0.8342825743656714, 0.834238929598532, 0.8342606844643564, 0.8342802638435984, 0.8341015432762566, 0.8342255745190376, 0.8342242508303115, 0.8341996749566177, 0.8341653496390433, 0.8341700484383167, 0.8341630998350723, 0.8341191954897428, 0.8340552675164462, 0.834108625130389, 0.8340335471617778], "moving_var_accuracy_train": [0.014109577290910572, 0.028994348411103432, 0.04182829463459563, 0.052123128132730824, 0.06019693369051678, 0.06578239345890825, 0.07005775665672401, 0.07299424209851584, 0.0741509706239085, 0.07472086116844445, 0.07312622403970091, 0.07161189061154398, 0.06939708626442105, 0.06695485751953202, 0.0641602988450507, 0.061155821240766, 0.057940887782155656, 0.054953254203434686, 0.05154632589599707, 0.048384746906160785, 0.04525439628348656, 0.04226928969433262, 0.03943752512956558, 0.03670255516112345, 0.033973823195886245, 0.03131952348857615, 0.02892730189492084, 0.026728383759152406, 0.024772402085566244, 0.022796706208340393, 0.02099049638822022, 0.01920698144595692, 0.01775380552577703, 0.016420656228561387, 0.015098528500501663, 0.013878080750687445, 0.012726825001238081, 0.011741061422842517, 0.01089801310025492, 0.010040005185074016, 0.009313766960756748, 0.008608848164960575, 0.007880857640517786, 0.007228198721189463, 0.006646086175187215, 0.006151330249353278, 0.0056229886380806835, 0.005139548812006208, 0.004775213321661952, 0.004426543192691023, 0.0040831840684521295, 0.003798269242320951, 0.0034790957943647053, 0.0032432659055272465, 0.003052989600891677, 0.0027655562122859, 0.0025547270400266024, 0.002412415111316907, 0.002276526982628623, 0.002073700897580626, 0.0018779665652593472, 0.001694495115918721, 0.0015408155175422925, 0.0014672218316591316, 0.0013433113159656792, 0.0013525930918991365, 0.001241000395441883, 0.001210164917687387, 0.0011802142760676529, 0.0010776372272835364, 0.0010364773935550796, 0.0009920155975043398, 0.0010507095059670497, 0.0009872244109449307, 0.0008930002336470517, 0.0008598795432953339, 0.0007989181366729375, 0.0008167555842230182, 0.0007784907519049313, 0.0007405055892200546, 0.00066766520888376, 0.0006110078959217518, 0.000551984847009215, 0.0005432090617095154, 0.0004932727565071744, 0.0004760441177647704, 0.0004381153796296556, 0.0003965199914755163, 0.0003575468824068439, 0.0003643404238908087, 0.0003279369850707087, 0.00037399821986184423, 0.0004102977353421725, 0.000388440757344939, 0.0003549270977940454, 0.0003588337979156685, 0.00033161136406389377, 0.0002985912454033799, 0.00031359473426826543, 0.0003467075620817621, 0.0003849270371484028, 0.00038057314442666707, 0.00034322865637379776, 0.0003104290200761502, 0.0002806912066689348, 0.00025264690909993377, 0.00029355182240102453, 0.0003129032199649221, 0.0002826585998541648, 0.0002906192554889212, 0.00027879687165391115, 0.0002510042500512517, 0.0002754169653874462, 0.00028736620849363387, 0.0002827327671822483, 0.0002577357949727055, 0.00024175345891368826, 0.0005436058916861847, 0.0007535510460964109, 0.0009142565634833008, 0.0010234057027702127, 0.001072698187732054, 0.0010946646257417466, 0.0010936235863342875, 0.001074059925087429, 0.001038087968165427, 0.0009898264267097264, 0.0009422282882322936, 0.00088846233054207, 0.0008325485643338843, 0.0007763304912635965, 0.0007211897803028204, 0.0006718271727119722, 0.0006171273349493579, 0.0005700713173643279, 0.000525032457646559, 0.0004770361099052618, 0.0004362815087816726, 0.0003999469123129621, 0.0003650093141400142, 0.00033243739566238923, 0.0003017184765165096, 0.0002748105678365426, 0.00024979426618972327, 0.00023145963404148093, 0.00021412493154255614, 0.00019691995760491977, 0.00018058473751022278, 0.00016550418487535536, 0.00015121627151463898, 0.00013785250814497135, 0.0001255412434285448, 0.00011459309972942672, 0.00010431045507805285, 9.473915285901154e-05, 8.5566217011433e-05, 7.770774113771589e-05, 7.013506006824274e-05, 6.343640098175963e-05, 5.745582630036637e-05, 5.1920448209359856e-05, 4.7266430263469436e-05, 4.269041694045971e-05, 3.864038999864386e-05, 3.480765958917726e-05, 3.139294905499602e-05, 2.8292240472579186e-05, 2.557201035722019e-05, 2.3063384666299233e-05, 2.0757059988399503e-05, 1.8681663199034606e-05, 1.6896240572727543e-05, 1.524785932620271e-05, 1.3729196672773353e-05, 1.2370524416101705e-05, 1.1160045390132457e-05, 1.0059862931337307e-05, 9.05719670111107e-06, 8.155807839844888e-06, 7.366970833898986e-06, 6.700846950082195e-06, 6.031024717910477e-06, 5.430954475618311e-06, 4.916203443326354e-06, 4.427942169427475e-06, 4.021761331663589e-06, 3.6281471695099248e-06, 3.2653325545646784e-06, 2.9483922665073525e-06, 2.65409824698589e-06, 2.391780567462974e-06, 2.152669647040844e-06, 1.9455535113378955e-06, 1.7661267370046985e-06, 1.6091704753455974e-06, 1.4540456655556105e-06, 1.3277543111834254e-06, 1.2056909536870418e-06, 1.089678422554322e-06, 9.840800098179637e-07, 9.27985292851583e-07, 8.357913491800095e-07, 8.256833267897851e-07, 7.667566998491955e-07], "duration": 217183.135688, "accuracy_train": [0.3959458056478405, 0.4651103310146733, 0.50025540588086, 0.5250342824266335, 0.5482828866163714, 0.5615773304840347, 0.5856644301979512, 0.605492181732189, 0.6128839920173496, 0.634874492432632, 0.6223466266957365, 0.6461747156469178, 0.6521703551818014, 0.6647229143595423, 0.6717244961817092, 0.679047272978959, 0.683347356323828, 0.6983609683577888, 0.6917629530615541, 0.7034780981796788, 0.7073120702980804, 0.7141472868217055, 0.7209123883928571, 0.7247485234403839, 0.7227267254406607, 0.7215390971068659, 0.7304204445828719, 0.736627510439738, 0.7468538393433923, 0.7411819182009044, 0.746526876557309, 0.7404604010935769, 0.7592447195690292, 0.7644755834140827, 0.7610103907115172, 0.7640563356519934, 0.7642881295565707, 0.7746096273417312, 0.7844435648532669, 0.7806077902939276, 0.7904875098052787, 0.790650630710133, 0.7839316716269842, 0.7881387490194721, 0.7927668766149871, 0.8006233561738648, 0.7925790622692875, 0.7942313598767996, 0.8083635782922666, 0.8095054246262459, 0.8086672895902547, 0.8158022520418051, 0.8084362166620525, 0.8203613461494095, 0.8271943997439092, 0.8065496017326504, 0.8208932464700996, 0.8320307092677187, 0.8343315251245846, 0.8201477568983019, 0.8165702721253231, 0.8132692817921743, 0.8202672587324659, 0.8382588636835548, 0.8272648751845699, 0.8528826077427095, 0.8331471411844776, 0.8507438313261352, 0.8535812338501293, 0.8380524841961978, 0.853466418362403, 0.8546271903262275, 0.8734329578488372, 0.8572317174810816, 0.8449552922549834, 0.8635768503137689, 0.8577665017072721, 0.8757112431939831, 0.8680160820990217, 0.8692959954088224, 0.8540215701711886, 0.8613196535275931, 0.8469763692783315, 0.874012082122093, 0.8605516334440754, 0.8731550214562569, 0.866526905396364, 0.8621574280753967, 0.8604378994209118, 0.8797090571936139, 0.859557226778793, 0.8896821431455334, 0.8916581591454411, 0.8804992473006644, 0.8750591200627538, 0.8890557949197121, 0.8800349385151348, 0.8724578373015872, 0.8936577871216316, 0.9003288012758398, 0.904698999573182, 0.8985624091569768, 0.8838481825627538, 0.88542928375323, 0.8779186926102805, 0.8818710850982835, 0.9085133250853636, 0.907373281192322, 0.8898449035622, 0.9068399389188816, 0.8749432231104651, 0.8883829437177003, 0.910952928894426, 0.9107905289659468, 0.9083029802279439, 0.8996080051448875, 0.9046081565499261, 0.9554083321797711, 0.9554312231796788, 0.9578729899178663, 0.9589883403700628, 0.957547469084533, 0.9584996986318751, 0.9591042373223514, 0.9594533701319674, 0.9591976037629198, 0.9586853500484496, 0.9602206692391103, 0.9599176789174971, 0.9599649028700628, 0.9600811603105389, 0.9602907841915835, 0.9619641703580657, 0.9594301186438722, 0.9615921465485419, 0.9616386495247323, 0.958336577727021, 0.9607547324889257, 0.9618486338939645, 0.9612426532507383, 0.9611035048103543, 0.9604535446082503, 0.9617087644772055, 0.9615220315960686, 0.965404669619786, 0.9657069389650241, 0.9653123846437799, 0.9652658816675894, 0.9655216480366371, 0.9653585271317828, 0.9652655211794019, 0.9653349151555003, 0.9659169233342562, 0.9657309114294942, 0.9655674300364526, 0.9646144795127353, 0.9657538024294019, 0.9647307369532114, 0.9652658816675894, 0.9655910420127353, 0.9653116636674051, 0.966381232119786, 0.9654744240840717, 0.9658700598698781, 0.9650558972983574, 0.9653817786198781, 0.9652655211794019, 0.9657766934293098, 0.9655209270602622, 0.9648473548818751, 0.9649171093461609, 0.9658231964055003, 0.9656371845007383, 0.9652887726674971, 0.9654518935723514, 0.9656371845007383, 0.9655674300364526, 0.9653821391080657, 0.9654286420842562, 0.9657763329411223, 0.9661712477505537, 0.9654282815960686, 0.9651961272033037, 0.9648001309293098, 0.9654983965485419, 0.9659623448458842, 0.9650798697628276, 0.9653585271317828, 0.9656840479651162, 0.9653123846437799, 0.96556779052464, 0.9654282815960686, 0.9651027607627353, 0.9649636123223514, 0.9657999449174051, 0.9651256517626431, 0.9648931368816908, 0.9649628913459765, 0.9654983965485419, 0.9651024002745479, 0.9645908675364526, 0.9651260122508305, 0.9661032957272055, 0.9647776004175894], "end": "2016-02-01 04:03:39.708000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0], "moving_var_accuracy_valid": [0.013325031368925221, 0.028066417832639502, 0.040507849462808505, 0.05060702459979321, 0.05897980442468074, 0.06453565471920296, 0.0683483184901589, 0.07103428659950163, 0.07183632122873525, 0.07202668187781844, 0.0702223068564642, 0.0685066102577009, 0.06620964872771343, 0.06380250813478515, 0.0609999934456562, 0.058035947458603784, 0.054941302714880576, 0.05196841312896411, 0.04852752784133683, 0.045443015214956264, 0.042397090048011045, 0.03946003968978863, 0.03660538205427401, 0.033891049587792495, 0.03125308200360011, 0.028705276427458713, 0.026430663231883027, 0.024342688072420935, 0.022492937944318843, 0.02066510306025594, 0.018978796739478585, 0.017344649608156633, 0.01593650790742101, 0.014673719761501093, 0.013451758832885134, 0.012327288759759214, 0.011279255601383495, 0.010364301258099513, 0.00952406463904307, 0.008688285877024316, 0.007962921179801921, 0.007291889360748671, 0.006630125520109764, 0.006044931157760122, 0.005528992474876219, 0.005078389531412333, 0.0046094126830150085, 0.004192712353679201, 0.0038397626557904454, 0.0035122244781464365, 0.003225104359930119, 0.002963973147886141, 0.0026874929138968376, 0.0024814704300585807, 0.0023078980979430795, 0.002081759716794475, 0.001903061205109645, 0.0017599533517458038, 0.0016283847848337246, 0.0014680706962047249, 0.0013213073491331229, 0.001189977640552606, 0.001073126122424569, 0.000996834420286802, 0.000907984859925958, 0.0008601046583102747, 0.0007753761907157842, 0.0007454915194251372, 0.0006962599671504899, 0.0006267744961049737, 0.0005815911526662254, 0.0005484692253893833, 0.0005514868206952126, 0.0005085356094104847, 0.0004578250275907247, 0.0004234451374473718, 0.0003886588216890014, 0.00038626120600902147, 0.00035823551981059397, 0.000329611345841752, 0.0002979863811379073, 0.0002695840125706951, 0.00025006229936075884, 0.00024113229929068625, 0.00021703447974989523, 0.00019912699078596845, 0.00017948867421120593, 0.00016337998683700887, 0.0001478254118118573, 0.0001432317964684487, 0.00012946588282138955, 0.00014159440884436254, 0.00015736962942038704, 0.00014284287681364327, 0.0001286472914186718, 0.00012574445432764596, 0.00011877570992331297, 0.00011044174318620452, 0.00013109962902087686, 0.00014391486542154669, 0.00017474989252792792, 0.0001673719369640103, 0.00015069747421112462, 0.00013573872681945306, 0.00012248062338745288, 0.00011122708255651335, 0.00011965662656578158, 0.0001310311126472687, 0.00011797015843893952, 0.00012759167708504697, 0.0001266028596148839, 0.00011394471331437104, 0.00011428918488774127, 0.00011735496350223073, 0.00011993370776035749, 0.00010877162864334886, 9.857798766954703e-05, 0.00022017179226134788, 0.0003180012032379292, 0.0003769495836704506, 0.0004108368661631592, 0.00042956321544564445, 0.0004425452924606763, 0.00043919332485364176, 0.0004305098140208277, 0.0004155771373180871, 0.00039250440953563144, 0.00037022545044955994, 0.00034955237837822886, 0.0003215560774558667, 0.00029674429128075786, 0.0002762385237725717, 0.0002562422266892277, 0.00023436728575736368, 0.00021397824952529385, 0.00019633393806535982, 0.00017820822112234045, 0.0001621507241465456, 0.0001499264083420098, 0.0001352739432744651, 0.00012254066561138722, 0.00011037030725425324, 0.00010101042464390348, 9.143211281282396e-05, 8.511892948880809e-05, 7.848570692916441e-05, 7.181221061374024e-05, 6.605243927932708e-05, 6.036892839634179e-05, 5.490085181096923e-05, 5.003272355081213e-05, 4.544253129051545e-05, 4.11503936706339e-05, 3.811246087072177e-05, 3.4666591340338936e-05, 3.1305096800931446e-05, 2.8236619834411752e-05, 2.5413483396139695e-05, 2.2895607624014736e-05, 2.0625059641279366e-05, 1.877687968928586e-05, 1.7070231609723575e-05, 1.56354686850539e-05, 1.4289561359733058e-05, 1.2860988852540596e-05, 1.1583397351394473e-05, 1.0435704153984617e-05, 9.41886069186521e-06, 8.511885691978518e-06, 7.675512805040765e-06, 7.101358023253523e-06, 6.40116919999307e-06, 5.777024736031713e-06, 5.200394196928239e-06, 4.68122304418017e-06, 4.2224464849224876e-06, 3.841359764948716e-06, 3.462512491689232e-06, 3.1205450921409697e-06, 2.8878573611092598e-06, 2.6499731913232395e-06, 2.3878162587403497e-06, 2.1880561512167453e-06, 2.037720856126336e-06, 1.8609242049100674e-06, 1.674834864800119e-06, 1.5073725149646591e-06, 1.3627771283368033e-06, 1.2337613367726246e-06, 1.1440464336234456e-06, 1.0467855815489932e-06, 9.463664910774808e-07, 8.551800107932784e-07, 1.0571313804326296e-06, 1.0898719850614851e-06, 9.809005559219276e-07, 8.882462624400583e-07, 8.100256830353185e-07, 7.292218231632908e-07, 6.567341886303839e-07, 6.084090936166649e-07, 5.843492561832518e-07, 5.51537645255876e-07, 5.47114193067323e-07], "accuracy_test": 0.8362902582908163, "start": "2016-01-29 15:43:56.572000", "learning_rate_per_epoch": [0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 0.00043072388507425785, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.3072388507425785e-05, 4.307238668843638e-06, 4.307238725687057e-07, 4.3072386546327834e-08, 4.3072385658149415e-09, 4.307238454792639e-10, 4.307238593570517e-11, 4.307238593570517e-12, 4.3072387019907343e-13, 4.30723876975337e-14, 4.30723876975337e-15, 4.30723876975337e-16, 4.307238637404472e-17, 4.307238637404472e-18, 4.3072385340068955e-19, 4.307238663253866e-20, 4.307238501695153e-21, 4.307238602669349e-22, 4.307238602669349e-23, 4.307238523783258e-24, 4.3072387209984845e-25, 4.307238782628243e-26, 4.307238705591045e-27, 4.307238801887542e-28, 4.307238801887542e-29, 4.3072388771191806e-30, 4.307238877119181e-31, 4.3072387595697455e-32, 4.3072386861013486e-33, 4.3072385942658525e-34, 4.3072385942658525e-35, 4.307238666012334e-36, 4.307238576329232e-37, 4.3072386323811707e-38, 4.307238352121478e-39, 4.3072411547184065e-40, 4.3073112196416227e-41, 4.3075914793344877e-42, 4.3019862854771884e-43, 4.344025239406933e-44, 4.203895392974451e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_train_first": 0.3959458056478405, "accuracy_train_last": 0.9647776004175894, "batch_size_eval": 1024, "accuracy_train_std": [0.018136701341777046, 0.017705393111409503, 0.01560759920611781, 0.015956518950383986, 0.017415201084844307, 0.017264814938091087, 0.01628001454906013, 0.014953172078146709, 0.016476721331973365, 0.016323549725810967, 0.0157829404092965, 0.013981273155875329, 0.01459993869557968, 0.01450041292011866, 0.014501159623738085, 0.015335546310217165, 0.016029136384440687, 0.016071201378632268, 0.014111909418469305, 0.01588333484680845, 0.017159657780574607, 0.016577904818376964, 0.01630420143176803, 0.016690418465408214, 0.0165290994733361, 0.01765152130655121, 0.017229283449004474, 0.016904907990245813, 0.018109004117392746, 0.017866838959626683, 0.018685279985158905, 0.01818644610739763, 0.01773396326125543, 0.01711624747001659, 0.017487122732535915, 0.017451019806098984, 0.01810809056451373, 0.01740127960787939, 0.016658597186267072, 0.017233522612241092, 0.017254078863308875, 0.017623692420144176, 0.0163505563518089, 0.01741150904354196, 0.01626066953461392, 0.017312902755151675, 0.016301953072380276, 0.016017590301341096, 0.015929221218281147, 0.014910846070647495, 0.016399335829905385, 0.017360137467229766, 0.015039645653379462, 0.014588303331342286, 0.014454545863197587, 0.01663961331347803, 0.01672651562976521, 0.016361717270847217, 0.015236954179217011, 0.016242328587385325, 0.01655195591737406, 0.0175961894151594, 0.015022831021833076, 0.01569665761474827, 0.015320599074662449, 0.01585185207706775, 0.014882540742014897, 0.01480890715366905, 0.014310330791442994, 0.014346556382102542, 0.014350344785693163, 0.01549029124031403, 0.01376018188010266, 0.014158006643727046, 0.015635744454618173, 0.014358114373395075, 0.013594578716109453, 0.013888833736743947, 0.013661756448357239, 0.013751496995563547, 0.014799039385856541, 0.014478239900628182, 0.01565863784559822, 0.015624797420568309, 0.01588242947238683, 0.013126042046377665, 0.015781761552945552, 0.01463899648584713, 0.015426040802282439, 0.013619402613300371, 0.013697193655762349, 0.01470923756958501, 0.013593424708727849, 0.013957746527199395, 0.01623023193943059, 0.013104462036160898, 0.01428015038430845, 0.014722523686795531, 0.013726354164242012, 0.014698353925381933, 0.014133523586943043, 0.013592026861683202, 0.013924737355660001, 0.014798792998424739, 0.014956280989082239, 0.01465268913658026, 0.013127055051611517, 0.013846193402863666, 0.013224401208918674, 0.013105021182987186, 0.014553325566649237, 0.014314097416095354, 0.014079904369257983, 0.013434489045084042, 0.014308620351448816, 0.014197156257520957, 0.013447561462977714, 0.00921447486952065, 0.009532334613617122, 0.008703510555375195, 0.00838020868971303, 0.008158772618732948, 0.008337628586705632, 0.008211000454168997, 0.008155436907160116, 0.007970535315677638, 0.008731753534316196, 0.007339763279197847, 0.007893972248220598, 0.0078016063670515645, 0.008071069230915658, 0.0074762080110270775, 0.007347904616881525, 0.007469419713684875, 0.007235090811116416, 0.007447308566227629, 0.008682801631842395, 0.007775628976724074, 0.007129300362795347, 0.007819570942076888, 0.007656828541304228, 0.007212020911603031, 0.006679646980046556, 0.007239420251097991, 0.006384430561278127, 0.006380948225392116, 0.006059997835386233, 0.006119329455891789, 0.006168500393841891, 0.00621913787534203, 0.006193227181039963, 0.006288089448720814, 0.005844366598031105, 0.005890918331321691, 0.006359114636470071, 0.006593695912223817, 0.006007794494998349, 0.006409915751143818, 0.006108187439960146, 0.00607335121551389, 0.006374133344860969, 0.006344744066887645, 0.0062611428728330375, 0.005941448887755277, 0.006343173443824265, 0.006052463574659901, 0.006071032189614367, 0.006232399946149989, 0.006515845661115768, 0.0063877452616219995, 0.006004353077408943, 0.006276118238801711, 0.0062335053469673605, 0.006208080818678753, 0.006051344202103389, 0.006334678734227886, 0.006207333592369221, 0.005803341602613021, 0.005830080817584384, 0.006548353825772241, 0.006474037933103645, 0.006225748143036219, 0.00639401998833492, 0.0064442076638773155, 0.006213182032926073, 0.006230644931527766, 0.006144126287998407, 0.006189860370882827, 0.005859270205985118, 0.006288019056222601, 0.006316198323667074, 0.005983986202016859, 0.006244126639444683, 0.006071301806358184, 0.006164751026115028, 0.006244833148265621, 0.006422989770994799, 0.006553322199677911, 0.006016372549295526, 0.006469066865229518, 0.0066219295744630825, 0.006171788830154052, 0.005447567720188938, 0.006153843044151093], "accuracy_test_std": 0.009741822735842537, "error_valid": [0.6152196677334337, 0.5389124858810241, 0.5076507200677711, 0.4815879729856928, 0.45210578642695776, 0.44307258330195776, 0.4263989551957832, 0.40511754047439763, 0.40146572618599397, 0.3819638907191265, 0.39466949830572284, 0.3722688605986446, 0.3658697289156627, 0.3519331231174698, 0.3472944512424698, 0.34007171263177716, 0.33457854856927716, 0.32334807981927716, 0.33430352268448793, 0.31984775037650603, 0.31696953830948793, 0.3127882624246988, 0.31094691265060237, 0.30751864881400603, 0.30844373588102414, 0.3105601115399097, 0.3012827677899097, 0.2959822689194277, 0.2860739834337349, 0.290172898625753, 0.28676522496234935, 0.29112887095256024, 0.27963367140436746, 0.2731948301016567, 0.2755450512989458, 0.2730212843561747, 0.2722888624811747, 0.26441459196159633, 0.2615054946347892, 0.2675281202936747, 0.26000094126506024, 0.2586272825677711, 0.26483227833207834, 0.2600612410579819, 0.2551578383847892, 0.24967496940888556, 0.2592376341302711, 0.2557681899472892, 0.24857633659638556, 0.24796598503388556, 0.24381559440888556, 0.24171980892319278, 0.2503470914909638, 0.23733557275978923, 0.23231009977409633, 0.2510280379329819, 0.23940047298569278, 0.2327880859375, 0.23118058170180722, 0.24588049463478923, 0.24994999529367468, 0.2535606292356928, 0.24599226986069278, 0.23182181852409633, 0.23755912321159633, 0.22559623258659633, 0.24147566829819278, 0.22186205760542166, 0.22579919286521077, 0.23964461361069278, 0.22682723079819278, 0.22269595961972888, 0.2123508683170181, 0.2235298616340362, 0.23274690559111444, 0.22262536474021077, 0.22359163215361444, 0.21170963149472888, 0.21897355045180722, 0.2197971573795181, 0.23169974821159633, 0.22429316876882532, 0.23692818147590367, 0.21538203595632532, 0.22782438347138556, 0.22095756071159633, 0.22505647590361444, 0.2311496964420181, 0.23003047345632532, 0.21673510448042166, 0.22879947524472888, 0.20986828172063254, 0.20665327324924698, 0.21940006118222888, 0.22369311229292166, 0.21227880271084332, 0.21385542168674698, 0.22723315135542166, 0.2028176181287651, 0.20273672816265065, 0.1955948795180723, 0.20517813441265065, 0.21387601185993976, 0.21573795180722888, 0.2166115634412651, 0.21824995293674698, 0.20051887236445776, 0.19768036991716864, 0.2128582690135542, 0.1968155826430723, 0.2221356127635542, 0.2116890413215362, 0.2004070971385542, 0.19799510542168675, 0.19680528755647586, 0.2051163638930723, 0.20509577371987953, 0.16935858669051207, 0.1672628012048193, 0.16835113893072284, 0.1687276449548193, 0.16833054875753017, 0.16660097420933728, 0.16772019719503017, 0.1671201407191265, 0.16725250611822284, 0.1688291250941265, 0.1679952230798193, 0.1668760000941265, 0.17021307887801207, 0.1690938558923193, 0.16713043580572284, 0.16700836549322284, 0.16883942018072284, 0.1688291250941265, 0.1676084219691265, 0.16932770143072284, 0.1685849844691265, 0.16590973268072284, 0.16995864316641573, 0.16873794004141573, 0.17044692441641573, 0.1669980704066265, 0.16847320924322284, 0.16503465032003017, 0.16551263648343373, 0.16601121282003017, 0.1652890860316265, 0.16566559205572284, 0.16603180299322284, 0.16566559205572284, 0.16588914250753017, 0.1661435782191265, 0.1641904532191265, 0.1652890860316265, 0.1660215079066265, 0.1661641683923193, 0.16698777532003017, 0.1664083090173193, 0.1664083090173193, 0.16527879094503017, 0.1652890860316265, 0.16479050969503017, 0.1648008047816265, 0.1662656485316265, 0.1658994375941265, 0.16652008424322284, 0.16566559205572284, 0.1655332266566265, 0.16649949407003017, 0.16466843938253017, 0.1656552969691265, 0.1655332266566265, 0.1660215079066265, 0.1660215079066265, 0.16625535344503017, 0.1652890860316265, 0.1656552969691265, 0.1656552969691265, 0.16491258000753017, 0.1665097891566265, 0.1656552969691265, 0.16515672063253017, 0.16662156438253017, 0.1652890860316265, 0.16578766236822284, 0.16576707219503017, 0.1660420980798193, 0.16552293157003017, 0.1651670157191265, 0.16615387330572284, 0.16554352174322284, 0.16554352174322284, 0.1675069418298193, 0.16465814429593373, 0.16578766236822284, 0.1660215079066265, 0.1661435782191265, 0.16578766236822284, 0.1658994375941265, 0.16627594361822284, 0.16652008424322284, 0.1654111563441265, 0.16664215455572284], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.05607498496305579, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.0004307238967870705, "optimization": "nesterov_momentum", "nb_data_augmentation": 2, "learning_rate_decay_method": "discrete", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 4.826757444028518e-06, "rotation_range": [0, 0], "momentum": 0.647262122942774}, "accuracy_valid_max": 0.8358095467808735, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8333578454442772, "accuracy_valid_std": [0.015286516093026928, 0.01605182497826765, 0.01775970272706118, 0.01691910899170304, 0.012639350529052844, 0.012997561535194989, 0.012790756774164578, 0.009796787907674328, 0.012500664325386879, 0.011326220101410342, 0.01158396412716095, 0.012638058735076696, 0.011226466489306402, 0.012469612659591671, 0.011486023413673751, 0.012808129335665467, 0.011107834414209622, 0.017044344055952773, 0.011180379208620025, 0.01397930383228602, 0.014447253828399622, 0.01311713393617293, 0.012164833869266683, 0.012444238715381521, 0.0071975908061827154, 0.008381268363072777, 0.012252471777375014, 0.009390002545245753, 0.012609999032711686, 0.00849010220436411, 0.009365880658695067, 0.00847174491783917, 0.010072511892663328, 0.014606953809389813, 0.014433120572742071, 0.011120347676728272, 0.010344988744422396, 0.013971689516511999, 0.008486578491481893, 0.009988125186894316, 0.013828237231675797, 0.014312874557596464, 0.007751291378103918, 0.009956997058909359, 0.007480857608506013, 0.010138886951564086, 0.012506141374237447, 0.006464079737490853, 0.008380875169122544, 0.009645901239435413, 0.008992678375503887, 0.01030560616207825, 0.013085131683069717, 0.010935693555319023, 0.011700651697925333, 0.011398846149841062, 0.009547070152199199, 0.011768869669463332, 0.011032644422767557, 0.011566499752794389, 0.015610202388930726, 0.010453673364479932, 0.012286438782087792, 0.012503856131147888, 0.010720875355264486, 0.014313925972979437, 0.013176813932219589, 0.008862301558501515, 0.011164388929157701, 0.01440019277674852, 0.014597735493156046, 0.011145464219277937, 0.01180154829182284, 0.013290234432576013, 0.009827558724421256, 0.012170068821703335, 0.013336332636495626, 0.009721970773333519, 0.013069338837031314, 0.012117061208668907, 0.013642087468618374, 0.012370035532176974, 0.012873094249574803, 0.011268654664540382, 0.017390784202633836, 0.017301391287889812, 0.013667476034881774, 0.015448802281295613, 0.013124314756281567, 0.013381183878150934, 0.015523497427043995, 0.01476698089847811, 0.011703683732384956, 0.014534531022438122, 0.013654936516168859, 0.010494276044175669, 0.013516602418668562, 0.017402314978598874, 0.012003820411870808, 0.0135402812071759, 0.011625145977230503, 0.011250960105307637, 0.010953391968125965, 0.010695226178052682, 0.01676142075151093, 0.014783935141823211, 0.011854510834773693, 0.011047136521908953, 0.013923733633928606, 0.01505533132611681, 0.0164186651693383, 0.010731672114549989, 0.008604309547854284, 0.013630397585174314, 0.014257639523509296, 0.01782079993549346, 0.012926349701148076, 0.011998670034450596, 0.012515912536533776, 0.014059722227844572, 0.013979725933103447, 0.01664407133417994, 0.01723178542611213, 0.016037028373934552, 0.013604781471886651, 0.013888781854681285, 0.01577110433441168, 0.014436264198415783, 0.014553206941089188, 0.013339295542101552, 0.016189380594834227, 0.014735888177327178, 0.01422195802438658, 0.013368085624503825, 0.014940446578433715, 0.014040102282975604, 0.014794034102339102, 0.015676427277958795, 0.014024332412836031, 0.013973029536954338, 0.013593575627723651, 0.013226642385898631, 0.014091737509431655, 0.014253784336073697, 0.0155781466212673, 0.01610084454142886, 0.014865772061835987, 0.01497620698053833, 0.014389614561460451, 0.014480561578978063, 0.014870363256974823, 0.01548195914929266, 0.014545309595538647, 0.014381260019624401, 0.014191497170142937, 0.01609803948245018, 0.014434976995808063, 0.01589683828797333, 0.014957728200266685, 0.01303269097447262, 0.015530315206687469, 0.015189604246314886, 0.014604499577003088, 0.014408442664383202, 0.01451500693982373, 0.014845551224856143, 0.014578473437582128, 0.014765780096766528, 0.014476241078104574, 0.015269408478986501, 0.01480862919595965, 0.014351618014955122, 0.015057479651213705, 0.013861863310932834, 0.015563391534698146, 0.015576579195467824, 0.014670612445227556, 0.015041094337541309, 0.014857687961169506, 0.01513908927514777, 0.015424716419191742, 0.01431835414182713, 0.015326977013230061, 0.015963618074470734, 0.014840271550049158, 0.014731800105917202, 0.015157536323284693, 0.014012486822128528, 0.015167292976362686, 0.01480563797387075, 0.014881852453291305, 0.014232002848897814, 0.01434878967712808, 0.013717361167507382, 0.0163056088359849, 0.013838899753840075, 0.01510471647848187, 0.014146446176803334, 0.014860707642179328, 0.014765033199380625, 0.01406052028311786, 0.014570294066736818, 0.014475776001538192, 0.015225798560697685], "accuracy_valid": [0.38478033226656627, 0.4610875141189759, 0.4923492799322289, 0.5184120270143072, 0.5478942135730422, 0.5569274166980422, 0.5736010448042168, 0.5948824595256024, 0.598534273814006, 0.6180361092808735, 0.6053305016942772, 0.6277311394013554, 0.6341302710843373, 0.6480668768825302, 0.6527055487575302, 0.6599282873682228, 0.6654214514307228, 0.6766519201807228, 0.6656964773155121, 0.680152249623494, 0.6830304616905121, 0.6872117375753012, 0.6890530873493976, 0.692481351185994, 0.6915562641189759, 0.6894398884600903, 0.6987172322100903, 0.7040177310805723, 0.7139260165662651, 0.709827101374247, 0.7132347750376506, 0.7088711290474398, 0.7203663285956325, 0.7268051698983433, 0.7244549487010542, 0.7269787156438253, 0.7277111375188253, 0.7355854080384037, 0.7384945053652108, 0.7324718797063253, 0.7399990587349398, 0.7413727174322289, 0.7351677216679217, 0.7399387589420181, 0.7448421616152108, 0.7503250305911144, 0.7407623658697289, 0.7442318100527108, 0.7514236634036144, 0.7520340149661144, 0.7561844055911144, 0.7582801910768072, 0.7496529085090362, 0.7626644272402108, 0.7676899002259037, 0.7489719620670181, 0.7605995270143072, 0.7672119140625, 0.7688194182981928, 0.7541195053652108, 0.7500500047063253, 0.7464393707643072, 0.7540077301393072, 0.7681781814759037, 0.7624408767884037, 0.7744037674134037, 0.7585243317018072, 0.7781379423945783, 0.7742008071347892, 0.7603553863893072, 0.7731727692018072, 0.7773040403802711, 0.7876491316829819, 0.7764701383659638, 0.7672530944088856, 0.7773746352597892, 0.7764083678463856, 0.7882903685052711, 0.7810264495481928, 0.7802028426204819, 0.7683002517884037, 0.7757068312311747, 0.7630718185240963, 0.7846179640436747, 0.7721756165286144, 0.7790424392884037, 0.7749435240963856, 0.7688503035579819, 0.7699695265436747, 0.7832648955195783, 0.7712005247552711, 0.7901317182793675, 0.793346726750753, 0.7805999388177711, 0.7763068877070783, 0.7877211972891567, 0.786144578313253, 0.7727668486445783, 0.7971823818712349, 0.7972632718373494, 0.8044051204819277, 0.7948218655873494, 0.7861239881400602, 0.7842620481927711, 0.7833884365587349, 0.781750047063253, 0.7994811276355422, 0.8023196300828314, 0.7871417309864458, 0.8031844173569277, 0.7778643872364458, 0.7883109586784638, 0.7995929028614458, 0.8020048945783133, 0.8031947124435241, 0.7948836361069277, 0.7949042262801205, 0.8306414133094879, 0.8327371987951807, 0.8316488610692772, 0.8312723550451807, 0.8316694512424698, 0.8333990257906627, 0.8322798028049698, 0.8328798592808735, 0.8327474938817772, 0.8311708749058735, 0.8320047769201807, 0.8331239999058735, 0.8297869211219879, 0.8309061441076807, 0.8328695641942772, 0.8329916345067772, 0.8311605798192772, 0.8311708749058735, 0.8323915780308735, 0.8306722985692772, 0.8314150155308735, 0.8340902673192772, 0.8300413568335843, 0.8312620599585843, 0.8295530755835843, 0.8330019295933735, 0.8315267907567772, 0.8349653496799698, 0.8344873635165663, 0.8339887871799698, 0.8347109139683735, 0.8343344079442772, 0.8339681970067772, 0.8343344079442772, 0.8341108574924698, 0.8338564217808735, 0.8358095467808735, 0.8347109139683735, 0.8339784920933735, 0.8338358316076807, 0.8330122246799698, 0.8335916909826807, 0.8335916909826807, 0.8347212090549698, 0.8347109139683735, 0.8352094903049698, 0.8351991952183735, 0.8337343514683735, 0.8341005624058735, 0.8334799157567772, 0.8343344079442772, 0.8344667733433735, 0.8335005059299698, 0.8353315606174698, 0.8343447030308735, 0.8344667733433735, 0.8339784920933735, 0.8339784920933735, 0.8337446465549698, 0.8347109139683735, 0.8343447030308735, 0.8343447030308735, 0.8350874199924698, 0.8334902108433735, 0.8343447030308735, 0.8348432793674698, 0.8333784356174698, 0.8347109139683735, 0.8342123376317772, 0.8342329278049698, 0.8339579019201807, 0.8344770684299698, 0.8348329842808735, 0.8338461266942772, 0.8344564782567772, 0.8344564782567772, 0.8324930581701807, 0.8353418557040663, 0.8342123376317772, 0.8339784920933735, 0.8338564217808735, 0.8342123376317772, 0.8341005624058735, 0.8337240563817772, 0.8334799157567772, 0.8345888436558735, 0.8333578454442772], "seed": 184785410, "model": "residualv3", "loss_std": [0.27659857273101807, 0.20533403754234314, 0.22185905277729034, 0.228630930185318, 0.23440831899642944, 0.2355796992778778, 0.23640508949756622, 0.23967376351356506, 0.24034570157527924, 0.23956383764743805, 0.24134166538715363, 0.24219006299972534, 0.24299460649490356, 0.2432156652212143, 0.24222855269908905, 0.24419842660427094, 0.24490976333618164, 0.24310529232025146, 0.2440129965543747, 0.24053418636322021, 0.2424987405538559, 0.24044770002365112, 0.2427767515182495, 0.24127036333084106, 0.24142058193683624, 0.23937295377254486, 0.23917259275913239, 0.24020113050937653, 0.23945006728172302, 0.2376035898923874, 0.23448090255260468, 0.23659484088420868, 0.23579852283000946, 0.2356969714164734, 0.23378963768482208, 0.23305073380470276, 0.2314002364873886, 0.2298610359430313, 0.2296888828277588, 0.23069985210895538, 0.22786059975624084, 0.22880087792873383, 0.2236468493938446, 0.2228642702102661, 0.2224673628807068, 0.2228538990020752, 0.21876592934131622, 0.21755260229110718, 0.21897856891155243, 0.2183268964290619, 0.21634308993816376, 0.2159036099910736, 0.2103491723537445, 0.21284881234169006, 0.20836156606674194, 0.2109895795583725, 0.21017156541347504, 0.20882223546504974, 0.20766180753707886, 0.20498734712600708, 0.20299115777015686, 0.19984827935695648, 0.19944588840007782, 0.19842122495174408, 0.20041745901107788, 0.19550885260105133, 0.19660145044326782, 0.19566912949085236, 0.1929619461297989, 0.19399254024028778, 0.191806361079216, 0.1907902956008911, 0.18785522878170013, 0.18741193413734436, 0.18523825705051422, 0.18512150645256042, 0.18256732821464539, 0.18224260210990906, 0.18126222491264343, 0.18133041262626648, 0.17938318848609924, 0.1772715151309967, 0.17650553584098816, 0.17064350843429565, 0.17205055058002472, 0.17194034159183502, 0.17042291164398193, 0.17026671767234802, 0.168303444981575, 0.16736377775669098, 0.1649404615163803, 0.16406242549419403, 0.16165706515312195, 0.16216784715652466, 0.15742062032222748, 0.15939979255199432, 0.15674090385437012, 0.15545476973056793, 0.15255916118621826, 0.15410776436328888, 0.15129946172237396, 0.1546696275472641, 0.14931167662143707, 0.1470870077610016, 0.1489863097667694, 0.14691472053527832, 0.14538629353046417, 0.14317013323307037, 0.1417253315448761, 0.14071784913539886, 0.14129430055618286, 0.13766688108444214, 0.13926489651203156, 0.13745945692062378, 0.1337444931268692, 0.13289424777030945, 0.1333596259355545, 0.12475013732910156, 0.11704599857330322, 0.11573408544063568, 0.11499189585447311, 0.11389610171318054, 0.11418119072914124, 0.11289134621620178, 0.1107000783085823, 0.11289402097463608, 0.1119193360209465, 0.11161641031503677, 0.11123423278331757, 0.11138056963682175, 0.11158137023448944, 0.10956452786922455, 0.11115025728940964, 0.11045166850090027, 0.11048220843076706, 0.11075985431671143, 0.11030948907136917, 0.10851031541824341, 0.11037186533212662, 0.1099075898528099, 0.10742688179016113, 0.10722436010837555, 0.10848236083984375, 0.10805132240056992, 0.11089339852333069, 0.10812246054410934, 0.10656590759754181, 0.10678168386220932, 0.10585232824087143, 0.10684745758771896, 0.10559286177158356, 0.10658810287714005, 0.10707923769950867, 0.10447552055120468, 0.10654193162918091, 0.1053570955991745, 0.10797349363565445, 0.10798192769289017, 0.10647661238908768, 0.10536441951990128, 0.10953320562839508, 0.1070992723107338, 0.108567975461483, 0.10754791647195816, 0.1061990037560463, 0.10568872839212418, 0.10792338103055954, 0.1085374504327774, 0.10890059173107147, 0.10706266760826111, 0.10646267980337143, 0.10774131119251251, 0.10543821007013321, 0.10624520480632782, 0.1109054908156395, 0.10947275161743164, 0.10657689720392227, 0.10558997839689255, 0.10703642666339874, 0.10547471791505814, 0.10553646832704544, 0.11007032543420792, 0.10593727231025696, 0.10866888612508774, 0.10706102102994919, 0.10751078277826309, 0.10601334273815155, 0.1076037660241127, 0.1071651503443718, 0.10819563269615173, 0.10729562491178513, 0.10856757313013077, 0.10805720835924149, 0.10480061173439026, 0.10677150636911392, 0.10727658867835999, 0.10746998339891434, 0.10824001580476761, 0.10958722978830338, 0.10710757225751877, 0.1074042022228241, 0.10812082141637802, 0.10594014823436737, 0.10502921789884567]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:27 2016", "state": "available"}], "summary": "0f0c27f4a16ba6bd06ed6985e2984af5"}