{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 64, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.63811194896698, 1.2108511924743652, 1.0153450965881348, 0.8820160031318665, 0.782192587852478, 0.7002424001693726, 0.6277554631233215, 0.5592564344406128, 0.4921131432056427, 0.4267619550228119, 0.36365219950675964, 0.3076583445072174, 0.26575326919555664, 0.22927851974964142, 0.19845810532569885, 0.17989519238471985, 0.15683303773403168, 0.1325893998146057, 0.11630219221115112, 0.10879594832658768, 0.09323659539222717, 0.09032689034938812, 0.08356624096632004, 0.07757220417261124, 0.07195078581571579, 0.0691211074590683, 0.06936076283454895, 0.06471245735883713, 0.05911590903997421, 0.05260629206895828, 0.057455845177173615, 0.054515380412340164, 0.05157851427793503, 0.04908667504787445, 0.048405393958091736, 0.0566830113530159, 0.0709770917892456, 0.027776388451457024, 0.03786168619990349, 0.03727549687027931, 0.04021059721708298, 0.04151909425854683, 0.030779022723436356, 0.034639421850442886, 0.038420092314481735, 0.02608594484627247, 0.03390679508447647, 0.02410868927836418, 0.03674287348985672, 0.03231172636151314, 0.02123035304248333, 0.03139307349920273, 0.03719018027186394, 0.01805039681494236, 0.012898925691843033, 0.042014021426439285, 0.023983260616660118, 0.021465424448251724, 0.021006356924772263, 0.02696014568209648, 0.0197975505143404, 0.023290257900953293, 0.019791724160313606, 0.016964055597782135, 0.02417847514152527, 0.02392183430492878, 0.013560018502175808, 0.01902715675532818, 0.023921621963381767, 0.013414239510893822, 0.024171123281121254, 0.019961172714829445, 0.010119336657226086, 0.01879132352769375, 0.0257041584700346, 0.011734817177057266, 0.015721019357442856, 0.014194580726325512, 0.012219349853694439, 0.02193807251751423, 0.015257773920893669, 0.013336099684238434, 0.011879365891218185, 0.016386112198233604, 0.014888244681060314, 0.01355784386396408, 0.01238236390054226, 0.0139086302369833, 0.01717541553080082, 0.01142845768481493, 0.010769035667181015, 0.01585831120610237, 0.016322826966643333, 0.007938330061733723, 0.008240502327680588, 0.022382469847798347, 0.010728822089731693, 0.005953817628324032, 0.004922028165310621, 0.004819560330361128, 0.004792067222297192, 0.004772390704602003, 0.004756178706884384, 0.0047418163157999516, 0.004728275816887617, 0.004714662674814463, 0.0047000558115541935, 0.0046833534725010395, 0.004663185216486454, 0.004637804813683033, 0.004604878835380077, 0.004561371635645628, 0.004503350704908371, 0.004425792023539543, 0.004322523716837168, 0.0041863261722028255, 0.004009431693702936, 0.003784766187891364, 0.0035082644317299128, 0.0031827737111598253, 0.07091333717107773, 0.006335385609418154, 0.0034994210582226515, 0.003162027569487691, 0.0031126216053962708, 0.0030831757467240095, 0.0030612486880272627, 0.003043828997761011, 0.003029489191249013, 0.0030173456761986017, 0.0030067453626543283, 0.0029971408657729626, 0.002987961983308196, 0.002978595905005932, 0.0029683755710721016, 0.0029564606957137585, 0.002941802376881242, 0.0029230397194623947, 0.0028984053060412407, 0.002865613205358386, 0.002821738366037607, 0.002763157244771719, 0.0026855869218707085, 0.0025843665935099125, 0.002455200534313917, 0.00229586916975677, 0.05925263091921806, 0.0077965520322322845, 0.003340283641591668, 0.0024698234628885984, 0.002311370335519314, 0.0022779577411711216, 0.002256615087389946, 0.0022403637412935495, 0.0022272574715316296, 0.0022163509856909513, 0.002207081764936447, 0.002199000446125865, 0.002191750332713127, 0.0021849835757166147, 0.0021783297415822744, 0.002171357162296772, 0.0021635484881699085, 0.0021542494650930166, 0.002142620272934437, 0.0021275696344673634, 0.0021076842676848173, 0.002081152983009815], "moving_avg_accuracy_train": [0.04881134427487079, 0.1051695285823874, 0.1611435764970353, 0.21466273934613206, 0.2660543544792099, 0.31499210263224864, 0.3596240141794243, 0.40136893312300825, 0.4387951648972246, 0.47419662587843237, 0.5068178318364086, 0.5384964423923857, 0.5676163808808603, 0.5911279099266337, 0.6172304349234959, 0.6400835077909655, 0.6646709149310734, 0.6849607130882059, 0.7044493902451475, 0.723283838938656, 0.7431130525496354, 0.7576559211711023, 0.7747014015207694, 0.7883779238248572, 0.8027998855317494, 0.8163118578036022, 0.829356297542345, 0.839127288802553, 0.8473885416152657, 0.8551354553800956, 0.8634675653826454, 0.8725824067587403, 0.8810275434245975, 0.8867588188786494, 0.8946325603527261, 0.901195805246071, 0.9076282092810338, 0.9130270363030504, 0.9187458891453828, 0.9218913722131258, 0.925217275279973, 0.9282362367746778, 0.9332713312877323, 0.9367890793708916, 0.9387741654410469, 0.9425228801088746, 0.9460480021778137, 0.9489066809017543, 0.951186523003301, 0.9542055346529985, 0.955646246587754, 0.9571775110658833, 0.9590905775176652, 0.9622817592742505, 0.9641541170135383, 0.9643302534503351, 0.9660350362506043, 0.9676366258910477, 0.9686340973401028, 0.9697478802394442, 0.9716151681083569, 0.9730911140951403, 0.9741893117999212, 0.9751940018247094, 0.9762121551386854, 0.9774656036498262, 0.9788471124812721, 0.9785793399962955, 0.9791473523502559, 0.9795516787212195, 0.9765956204432744, 0.9783664329894324, 0.9800159678524031, 0.979459032525496, 0.9801785299050985, 0.9815398621824458, 0.982169859185639, 0.9829670462206558, 0.9836961402962185, 0.9837105838927964, 0.9845722624451927, 0.9849617984399683, 0.985607674734076, 0.9859751218059342, 0.9864452249527217, 0.9872287158503067, 0.9878338762593236, 0.9881274045560103, 0.9883846766742372, 0.989123067972299, 0.9897992458846021, 0.9900381073449607, 0.990027615322397, 0.9907388604865859, 0.9908814353379366, 0.9902891007684748, 0.9909044429237701, 0.9917163423813931, 0.9924726285301586, 0.9931649118080951, 0.9937902919070474, 0.9943601094425331, 0.9948752703732798, 0.9953505409549994, 0.9957829347761662, 0.9961720892152163, 0.9965246533591708, 0.9968419610887299, 0.9971345134917616, 0.9974001358032997, 0.9976415210324936, 0.9978610928875776, 0.9980610327059627, 0.9982433036913188, 0.9984096727269488, 0.9985594048590158, 0.9986941637778762, 0.9988154468048506, 0.9989292518267464, 0.9990316763464526, 0.9984751418963311, 0.9983881373793171, 0.9984377164985282, 0.9984986137474849, 0.998567372164403, 0.9986385553348676, 0.9987095956347141, 0.9987851576486236, 0.9988601389075707, 0.9989276220406232, 0.998999982604418, 0.9990720825582619, 0.999148598260769, 0.9992174623930254, 0.9992817652608658, 0.9993419629907316, 0.9993961409476109, 0.9994449011088022, 0.9994911104026839, 0.9995303736183678, 0.9995657105124833, 0.9995975137171873, 0.999626136601421, 0.9996542223460408, 0.9996794995161987, 0.9997045741181503, 0.998927362167068, 0.9987207308610755, 0.9986765967630631, 0.9987066305391378, 0.9987452866816525, 0.9987893778051539, 0.9988476610067814, 0.9989070913346747, 0.9989698792250168, 0.9990333637727532, 0.9990974753121445, 0.9991621511440254, 0.9992226845415276, 0.9992748394504701, 0.9993264291661373, 0.9993775102078569, 0.999425808294214, 0.9994692765719354, 0.9995083980218847, 0.9995436073268391, 0.9995776208501075, 0.9996082330210492], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04753197359751505, 0.10213377435523341, 0.15532415845020703, 0.20545689344291224, 0.25338617821383186, 0.29811665513077695, 0.3379865478820065, 0.37410138495186307, 0.4057430395666165, 0.43471189849587355, 0.460117632356753, 0.48289734361279457, 0.5028100577172531, 0.5181536107275307, 0.5355834433200638, 0.5497239706465664, 0.5660456365525424, 0.5782824050226646, 0.5911074318867385, 0.6024240524499472, 0.6141685695035218, 0.6219480780934559, 0.6317329860220621, 0.6402362863938769, 0.6487916946050163, 0.6566105437815628, 0.6633891013668854, 0.6692781656277872, 0.6735305777924181, 0.6780686980063991, 0.6832548746101267, 0.6880393563226833, 0.6922506750672975, 0.6946146982985196, 0.6989569394061677, 0.7020237007554605, 0.7056566622405318, 0.7086354178444154, 0.7119560639835432, 0.712885628189481, 0.715051919945081, 0.7172436641328018, 0.7201480863113892, 0.7217712377235485, 0.7231588318069918, 0.725746468957618, 0.7286979009869314, 0.7297884542146691, 0.7302857889042714, 0.7323142742081215, 0.7328499366310594, 0.7331642229001823, 0.7341815614347122, 0.7366261335480181, 0.7379168981582012, 0.7377011037207697, 0.7386574381905602, 0.7392903236542602, 0.7403898233859727, 0.7406316557122851, 0.7420070608300626, 0.7433496411740143, 0.7436027265200917, 0.7447064681282483, 0.7464810855755891, 0.7473203758320363, 0.7485040126652484, 0.7487259711502294, 0.7491363418439414, 0.7488179636836436, 0.7460735449508215, 0.7474551070596549, 0.7484645203465358, 0.7480972840027708, 0.74850537022034, 0.7499081864550831, 0.7501931290576922, 0.7506815109937904, 0.7512157695329656, 0.7504066278676962, 0.7512470774209116, 0.7511581083365765, 0.7517992805130845, 0.752183081989261, 0.7523708414202295, 0.7530525202206011, 0.7537545688856645, 0.7540100537327908, 0.7540587965711081, 0.7551027592520997, 0.7553759394168746, 0.7556512160983047, 0.7558105744395285, 0.7565114023494913, 0.7560873423103254, 0.7555499383221392, 0.7561141674756181, 0.757540589583478, 0.7589687948382327, 0.7602796231386714, 0.761497019211476, 0.7626435628193193, 0.7636133874014687, 0.7645971223153127, 0.7655313118627725, 0.7663232543304861, 0.7669973224403592, 0.7675917767079949, 0.7681766431825268, 0.7686653724071958, 0.7690797851382383, 0.7693784849000169, 0.769682906270708, 0.7700046841206704, 0.7703939994529558, 0.7708308619794224, 0.7711884466681518, 0.771557041995689, 0.7715449218981533, 0.7714098844805518, 0.7701102987527526, 0.7696447084482605, 0.7694067236256483, 0.7693146075977974, 0.769293767837641, 0.7692750120535004, 0.7692723978963432, 0.7692578381236516, 0.7692091427431388, 0.7691907604718369, 0.7691620093964153, 0.769111719366036, 0.7690654288300348, 0.7689850872365644, 0.7688008575038718, 0.7686228437131986, 0.7684382172390926, 0.7682598463811472, 0.7680982831003367, 0.7679284620851072, 0.7677745936627411, 0.7675363968152923, 0.7672853985588384, 0.7671093577616895, 0.7669896011553248, 0.7669163822860272, 0.7651047327622438, 0.7645444959788658, 0.7643200150839159, 0.7645737604693497, 0.76483875240999, 0.7651504873440663, 0.765418841753485, 0.7655372609008022, 0.7656814887357973, 0.7658601219122929, 0.7659598566148889, 0.7661859542082946, 0.7664016490736096, 0.7665469463273933, 0.7666288857307986, 0.7666415960376134, 0.7667883421661563, 0.7669448277443449, 0.7670002155459646, 0.7669269647462628, 0.7667867673303714, 0.7665883769772289], "moving_var_accuracy_train": [0.02144292596927966, 0.04788483781831181, 0.07129420039604234, 0.08994348748505135, 0.10471902169042376, 0.11580124826999363, 0.12214919119818848, 0.1256180163968272, 0.12566272018050073, 0.12437581911888644, 0.12151552491037215, 0.1183957817201503, 0.11418794090628819, 0.10774427479829154, 0.10310192361936878, 0.09749209771280475, 0.09318375325038515, 0.08757046110866126, 0.08223169183374264, 0.07720115076866402, 0.07301981510366626, 0.06762128884297085, 0.06347409556183177, 0.05881011136665647, 0.054801037045266426, 0.05096409389281764, 0.047399101176415104, 0.04351844149063717, 0.03978083202389342, 0.03634288087742149, 0.03333340930353064, 0.030747791372979942, 0.028314895235427007, 0.02577903337685626, 0.023759092282376004, 0.02177086870590857, 0.01996616423033877, 0.018231873806227802, 0.01670303392609531, 0.0151217771070509, 0.013709154077236387, 0.012420265826071341, 0.011406408834262737, 0.010377138915025596, 0.009374890123876354, 0.008563876866435801, 0.007819327550200511, 0.00711094319160086, 0.0064466279925126345, 0.005883995075330459, 0.0053142764257079365, 0.0048039517212549706, 0.004356494958369875, 0.004012498231564951, 0.0036427999199432934, 0.003278799144348271, 0.002977075789478287, 0.0027024540149178404, 0.002441163157051177, 0.0022082114524678495, 0.0020187711830895617, 0.0018364998137837226, 0.001663704176194425, 0.0015064183769881636, 0.0013651062648261918, 0.0012427358368743, 0.0011356393530491385, 0.0010227207366776197, 0.0009233524053181218, 0.0008324884831146199, 0.0008278841596866299, 0.0007733177373806414, 0.000720474651019981, 0.0006512187785431957, 0.0005907559890021698, 0.0005483594202260808, 0.0004970955442197647, 0.00045310555431697744, 0.0004125792024244653, 0.0003713231597393577, 0.0003408732531143592, 0.00030815157242395616, 0.00028109082086717253, 0.0002541968949360096, 0.00023076617815998457, 0.00021321428222337264, 0.00019518882608680942, 0.00017644537322673056, 0.00015939653638941036, 0.00014836387813194836, 0.00013764243944053327, 0.00012439168867168148, 0.00011195351054735063, 0.00010531098664485401, 9.496283627450752e-05, 8.862429482667213e-05, 8.316967905675706e-05, 8.078533771467793e-05, 7.785452259254051e-05, 7.438237556548134e-05, 7.046404042242468e-05, 6.633986459390561e-05, 6.209439519562521e-05, 5.791789480869578e-05, 5.38087850770746e-05, 4.979087716625832e-05, 4.593050273005418e-05, 4.2243610214190343e-05, 3.878953136944833e-05, 3.5545575143985246e-05, 3.2515419089443395e-05, 2.9697783376404215e-05, 2.7087788417546594e-05, 2.4678013984716146e-05, 2.245932049039273e-05, 2.041516584371349e-05, 1.8537088955253762e-05, 1.6815766213416784e-05, 1.5250753839153641e-05, 1.3820095495371906e-05, 1.5225661293382539e-05, 1.3771223237871947e-05, 1.2416223715640537e-05, 1.1207977618450934e-05, 1.0129729335679679e-05, 9.162359795928061e-06, 8.29154433415589e-06, 7.5137764622549e-06, 6.812998518769123e-06, 6.1726844261113775e-06, 5.602540444234575e-06, 5.089072029909764e-06, 4.632856701490258e-06, 4.2122514497441225e-06, 3.8282400340821124e-06, 3.4780299308028677e-06, 3.15664419682704e-06, 2.8623777570189435e-06, 2.595357670886444e-06, 2.3496963047504325e-06, 2.1259649390470273e-06, 1.922471439607357e-06, 1.737597721163299e-06, 1.57093723050461e-06, 1.4195939254348352e-06, 1.2832931538586135e-06, 6.591489590618872e-06, 6.316609101102518e-06, 5.702478558458509e-06, 5.1403489519603735e-06, 4.639762732951453e-06, 4.193282704200861e-06, 3.8045268181083133e-06, 3.4558618111590197e-06, 3.1457565026055667e-06, 2.867453442556684e-06, 2.617700703649165e-06, 2.3935773023494797e-06, 2.1871982020329954e-06, 1.9929595925708703e-06, 1.8176171221774615e-06, 1.6593388653681548e-06, 1.5143993251432232e-06, 1.3799648131415327e-06, 1.2557427224426131e-06, 1.1413257065966914e-06, 1.0376054138232399e-06, 9.422788175287532e-07], "duration": 41482.609849, "accuracy_train": [0.48811344274870805, 0.612393187350037, 0.6649100077288667, 0.6963352049880029, 0.7285788906769103, 0.7554318360095976, 0.7613112181040051, 0.777073203615264, 0.7756312508651717, 0.7928097747093023, 0.8004086854581949, 0.8236039373961794, 0.8296958272771319, 0.8027316713385935, 0.8521531598952565, 0.8457611635981912, 0.8859575791920451, 0.8675688965023993, 0.8798474846576227, 0.8927938771802326, 0.9215759750484496, 0.8885417387643041, 0.928110724667774, 0.9114666245616464, 0.9325975408937799, 0.9379196082502769, 0.94675625519103, 0.927066210144426, 0.9217398169296788, 0.9248576792635659, 0.9384565554055924, 0.9546159791435955, 0.9570337734173128, 0.9383402979651162, 0.9654962336194168, 0.9602650092861758, 0.9655198455956996, 0.9616164795011997, 0.970215564726375, 0.9502007198228128, 0.9551504028815985, 0.955406890227021, 0.9785871819052234, 0.9684488121193245, 0.9566399400724437, 0.9762613121193245, 0.9777741007982651, 0.9746347894172205, 0.9717051019172205, 0.9813766395002769, 0.9686126540005537, 0.9709588913690477, 0.9763081755837025, 0.991002395083518, 0.9810053366671282, 0.9659154813815062, 0.9813780814530271, 0.9820509326550388, 0.9776113403815985, 0.979771926333518, 0.9884207589285714, 0.9863746279761905, 0.9840730911429494, 0.9842362120478036, 0.9853755349644703, 0.9887466402500923, 0.9912806919642857, 0.9761693876315062, 0.9842594635358989, 0.983190616059893, 0.9499910959417681, 0.9943037459048542, 0.99486178161914, 0.9744466145833334, 0.9866540063215209, 0.9937918526785714, 0.987839832214378, 0.9901417295358066, 0.9902579869762828, 0.9838405762619971, 0.9923273694167589, 0.9884676223929494, 0.9914205613810447, 0.9892821454526578, 0.9906761532738095, 0.9942801339285714, 0.9932803199404762, 0.9907691592261905, 0.9907001257382798, 0.9957685896548542, 0.9958848470953304, 0.9921878604881875, 0.9899331871193245, 0.9971400669642857, 0.9921646090000923, 0.9849580896433187, 0.9964425223214286, 0.9990234375, 0.9992792038690477, 0.9993954613095238, 0.9994187127976191, 0.9994884672619048, 0.99951171875, 0.9996279761904762, 0.9996744791666666, 0.9996744791666666, 0.9996977306547619, 0.9996977306547619, 0.9997674851190477, 0.9997907366071429, 0.9998139880952381, 0.9998372395833334, 0.9998604910714286, 0.9998837425595238, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999534970238095, 0.9999534970238095, 0.9934663318452381, 0.9976050967261905, 0.9988839285714286, 0.9990466889880952, 0.9991861979166666, 0.9992792038690477, 0.9993489583333334, 0.9994652157738095, 0.9995349702380952, 0.9995349702380952, 0.9996512276785714, 0.9997209821428571, 0.9998372395833334, 0.9998372395833334, 0.9998604910714286, 0.9998837425595238, 0.9998837425595238, 0.9998837425595238, 0.9999069940476191, 0.9998837425595238, 0.9998837425595238, 0.9998837425595238, 0.9998837425595238, 0.9999069940476191, 0.9999069940476191, 0.9999302455357143, 0.9919324546073275, 0.9968610491071429, 0.9982793898809523, 0.9989769345238095, 0.9990931919642857, 0.9991861979166666, 0.9993722098214286, 0.9994419642857143, 0.9995349702380952, 0.9996047247023809, 0.9996744791666666, 0.9997442336309523, 0.9997674851190477, 0.9997442336309523, 0.9997907366071429, 0.9998372395833334, 0.9998604910714286, 0.9998604910714286, 0.9998604910714286, 0.9998604910714286, 0.9998837425595238, 0.9998837425595238], "end": "2016-02-01 04:56:26.375000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0], "moving_var_accuracy_valid": [0.020333596626673816, 0.0451324467778766, 0.06608215474162636, 0.082093559328103, 0.09455915044315985, 0.10311057548580013, 0.10710599306917103, 0.1081339268714945, 0.10633128294517918, 0.10325090773963001, 0.09873487878275557, 0.09353162810865766, 0.087747110944845, 0.08109122142117332, 0.07571629085688955, 0.06994425238884472, 0.06534739815147692, 0.06016030485965163, 0.05562460620026442, 0.05121473868898272, 0.04733466794747978, 0.04314588793783951, 0.039692998952597265, 0.03637445411225731, 0.03339576378796467, 0.030606397031178446, 0.027959296914498416, 0.025475496923869856, 0.02309069431444398, 0.020966975698688474, 0.019112345978705085, 0.017407132768154674, 0.015826036341457857, 0.01429373015985189, 0.013034052664399238, 0.011815292624520964, 0.01075254904443698, 0.009757151004522291, 0.008880676121101798, 0.008000385315508266, 0.007242582163690868, 0.006561557630581453, 0.005981322881246535, 0.005406902177683034, 0.004883540715978393, 0.004455449438590258, 0.004088303053944151, 0.003690176505632496, 0.003323384931210583, 0.0030280792117409424, 0.0027278536986489773, 0.002455957311514713, 0.0022196763796077977, 0.0020514921370013935, 0.001861337582811365, 0.0016756229296832662, 0.0015162918172779247, 0.0013682675316415971, 0.001242320875417761, 0.0011186151337424317, 0.001023779273510266, 0.0009376240439789254, 0.0008444381093126253, 0.0007709585082195457, 0.0007222060611572499, 0.0006563251282526284, 0.0006033015808037916, 0.0005434148128449088, 0.0004905889685167369, 0.0004424423535416545, 0.0004659846258170776, 0.0004365645879804507, 0.0004020783658359908, 0.0003630842920420288, 0.00032827467208655615, 0.0003131582453740302, 0.0002825731514176623, 0.00025646248851545975, 0.00023338512934404813, 0.00021593900851991853, 0.00020070230673142504, 0.00018070331553998945, 0.00016633289982534278, 0.00015102534200084575, 0.00013624009023601965, 0.00012679825509430266, 0.00011855428053792785, 0.00010728630504813549, 9.657905732190698e-05, 9.672987430344492e-05, 8.772853349493873e-05, 7.963767540749691e-05, 7.19024635950055e-05, 6.913265506995062e-05, 6.383783181431279e-05, 6.005327605154702e-05, 5.69131392851114e-05, 6.953394562472274e-05, 8.093848330962861e-05, 8.830907247774688e-05, 9.281664401269148e-05, 9.536603981360086e-05, 9.429447331351202e-05, 9.357463540860363e-05, 9.207156286298983e-05, 8.850896242620746e-05, 8.374737653431737e-05, 7.855302176767895e-05, 7.37763387281927e-05, 6.854841115078351e-05, 6.323921124055586e-05, 5.771828404567951e-05, 5.278050697951247e-05, 4.843432514409866e-05, 4.4954990481261025e-05, 4.217713123641083e-05, 3.9110219399293346e-05, 3.642196009870457e-05, 3.27810861597126e-05, 2.9667093481113603e-05, 4.1900691708095575e-05, 3.966159152201965e-05, 3.62051633519615e-05, 3.266101528004873e-05, 2.9398822412474183e-05, 2.646210618617533e-05, 2.3815957071916583e-05, 2.143626924755239e-05, 1.9313983483546676e-05, 1.7385626306275936e-05, 1.5654503294689453e-05, 1.4111814749620639e-05, 1.2719918598168066e-05, 1.1506019683123446e-05, 1.0660883064482934e-05, 9.87999494506363e-06, 9.19877786502458e-06, 8.565245545199725e-06, 7.943645234036007e-06, 7.408833305554436e-06, 6.881029397612014e-06, 6.703566101061779e-06, 6.6002106136418055e-06, 6.219102812625024e-06, 5.726267334274488e-06, 5.201889626237932e-06, 3.422036663683713e-05, 3.3623117254200943e-05, 3.071433057855813e-05, 2.8222378006362433e-05, 2.603212676316517e-05, 2.4303522108960654e-05, 2.2521296699554584e-05, 2.039537487966105e-05, 1.8543052407181254e-05, 1.69759354721672e-05, 1.536786502306772e-05, 1.4291159616455553e-05, 1.3280762129119784e-05, 1.2142687543821347e-05, 1.0988845381912885e-05, 9.891414810815514e-06, 9.09608316591488e-06, 8.406864474952555e-06, 7.593788304571702e-06, 6.882700591027223e-06, 6.37132837072799e-06, 6.088424123635481e-06], "accuracy_test": 0.10028101084183674, "start": "2016-01-31 17:25:03.765000", "learning_rate_per_epoch": [0.000259733060374856, 0.00025753292720764875, 0.0002553514204919338, 0.0002531883947085589, 0.00025104370433837175, 0.0002489171747583896, 0.00024680866044946015, 0.0002447179867886007, 0.00024264503736048937, 0.00024058963754214346, 0.00023855165636632591, 0.0002365309337619692, 0.00023452732420992106, 0.00023254069674294442, 0.00023057089128997177, 0.00022861777688376606, 0.000226681208005175, 0.0002247610391350463, 0.00022285713930614293, 0.00022096936299931258, 0.0002190975792473182, 0.00021724165708292276, 0.00021540145098697394, 0.0002135768299922347, 0.000211767663131468, 0.00020997381943743676, 0.00020819518249481916, 0.00020643160678446293, 0.00020468297589104623, 0.00020294914429541677, 0.00020123001013416797, 0.00019952542788814753, 0.00019783529569394886, 0.00019615946803241968, 0.00019449784304015338, 0.00019285028974991292, 0.00019121669174637645, 0.00018959693261422217, 0.00018799089593812823, 0.00018639846530277282, 0.0001848195242928341, 0.00018325395649299026, 0.00018170164548791945, 0.0001801624894142151, 0.00017863637185655534, 0.0001771231763996184, 0.00017562280117999762, 0.00017413514433428645, 0.00017266008944716305, 0.00017119752010330558, 0.00016974734899122268, 0.00016830945969559252, 0.0001668837503530085, 0.00016547011910006404, 0.00016406846407335252, 0.0001626786688575521, 0.00016130064614117146, 0.00015993430861271918, 0.00015857953985687345, 0.0001572362525621429, 0.00015590434486512095, 0.00015458371490240097, 0.0001532742753624916, 0.00015197592438198626, 0.00015068857464939356, 0.0001494121243013069, 0.00014814648602623492, 0.00014689157251268625, 0.0001456472818972543, 0.0001444135414203629, 0.00014319024921860546, 0.00014197731798049062, 0.00014077466039452702, 0.00013958218914922327, 0.000138399816933088, 0.00013722745643462986, 0.00013606503489427269, 0.0001349124504486099, 0.00013376963033806533, 0.00013263650180306286, 0.00013151296298019588, 0.00013039894110988826, 0.00012929436343256384, 0.00012819914263673127, 0.00012711319141089916, 0.00012603643699549139, 0.0001249688066309318, 0.00012391022755764425, 0.00012286061246413738, 0.00012181988859083503, 0.00012078797590220347, 0.00011976480891462415, 0.00011875030759256333, 0.00011774439917644486, 0.0001167470109066926, 0.0001157580700237304, 0.00011477751104393974, 0.00011380525393178686, 0.00011284123320365325, 0.00011188537609996274, 0.00011093761713709682, 0.00010999789083143696, 0.00010906612442340702, 0.00010814224515343085, 0.00010722619481384754, 0.00010631790792103857, 0.00010541731171542779, 0.00010452434071339667, 0.0001036389367072843, 0.00010276103421347216, 0.00010189056774834171, 0.00010102747182827443, 0.0001001716882456094, 9.932315879268572e-05, 9.848181070992723e-05, 9.764759306563064e-05, 9.682044037617743e-05, 9.600029443390667e-05, 9.518709703115746e-05, 9.438078996026888e-05, 9.358130773762241e-05, 9.278859943151474e-05, 9.200260683428496e-05, 9.122327173827216e-05, 9.045053593581542e-05, 8.968434849521145e-05, 8.892465120879933e-05, 8.817138586891815e-05, 8.742450154386461e-05, 8.66839473019354e-05, 8.594966493546963e-05, 8.522160351276398e-05, 8.449971210211515e-05, 8.378393249586225e-05, 8.307421376230195e-05, 8.237051224568859e-05, 8.167276973836124e-05, 8.098093530861661e-05, 8.029496530070901e-05, 7.961480150697753e-05, 7.894040027167648e-05, 7.827171066310257e-05, 7.76086890255101e-05, 7.695128442719579e-05, 7.629944593645632e-05, 7.565312989754602e-05, 7.501228537876159e-05, 7.437686872435734e-05, 7.374683627858758e-05, 7.312214438570663e-05, 7.25027421140112e-05, 7.188858580775559e-05, 7.127963181119412e-05, 7.067583646858111e-05, 7.007715612417087e-05, 6.948354712221771e-05, 6.889496580697596e-05, 6.831136852269992e-05, 6.773271888960153e-05, 6.715896597597748e-05, 6.65900734020397e-05, 6.602600478800014e-05, 6.546670920215547e-05, 6.491215754067525e-05, 6.436229887185618e-05, 6.381709681591019e-05, 6.32765149930492e-05, 6.274050974752754e-05], "accuracy_train_first": 0.48811344274870805, "accuracy_train_last": 0.9998837425595238, "batch_size_eval": 1024, "accuracy_train_std": [0.017388795875303266, 0.014505881814878689, 0.01541692788190914, 0.018140182169435356, 0.017921305832506635, 0.01900924904916834, 0.022022422567620832, 0.023324617991086566, 0.023075930486589655, 0.02476974221329157, 0.02809823721786051, 0.030020069609876434, 0.028546605685927477, 0.026977290459591356, 0.027679835089707918, 0.02615768128353246, 0.023938247548877398, 0.02421021538251081, 0.024745156189848214, 0.023114761078341654, 0.019604577694419423, 0.02251415127895767, 0.01769939044154903, 0.01780995895553243, 0.016691725491314473, 0.018718950089240773, 0.01572379426387117, 0.01624380171414178, 0.018122604419621473, 0.01474333559641221, 0.01587696191541448, 0.013496405330748203, 0.01178109493793299, 0.015038337662837326, 0.01178321884620687, 0.011611437703736042, 0.010384179469177251, 0.009616113826210033, 0.009849141057596229, 0.011044247579200838, 0.01147174210288924, 0.010979555483127934, 0.008140774698740813, 0.008318441390635176, 0.010365448554401774, 0.00821303067713581, 0.0066259952460999035, 0.006930915806403598, 0.008763374692921863, 0.00655098694159601, 0.007306213627850311, 0.009296438105531274, 0.007416090134726218, 0.0036396282108190734, 0.0052153246798485485, 0.008768226229110032, 0.0054161353507833215, 0.006122892586692415, 0.006107439580325028, 0.00590109640901359, 0.004913276565369305, 0.005470378943298835, 0.005661135526485673, 0.005544574019565122, 0.006687607725788406, 0.00506265649894847, 0.0041562969897181, 0.005933380911630619, 0.0057283949612249975, 0.0053152493755537255, 0.008461567213462936, 0.003036078325560919, 0.002704904474458494, 0.008142437417609477, 0.0043456778489557495, 0.003108837865930112, 0.004985729701132773, 0.004218883202553004, 0.003886505358748117, 0.005455730454476853, 0.003201252667662229, 0.003760476981988771, 0.0034863159878446986, 0.003595835722152693, 0.003860657366289948, 0.0028636168746913413, 0.0033505547633670865, 0.004305545298190438, 0.0033923615957867992, 0.00260738756098394, 0.0019009273362229988, 0.003021962176940174, 0.0044481455517231755, 0.001862587879857518, 0.003242966225981288, 0.0048383458459843, 0.002129130525149068, 0.001022008043891179, 0.0007990532123065282, 0.0006722857279948363, 0.0006758948034667334, 0.0006116511550393372, 0.0006120929399687585, 0.0005618975992184976, 0.0005502306345888779, 0.0005502306345888779, 0.0005428114550748117, 0.0005428114550748117, 0.0004673491267262319, 0.0004007088899649852, 0.000383473365477833, 0.0003639433557128564, 0.0003417256895623853, 0.00031625442961159415, 0.0002866635976083043, 0.0002866635976083043, 0.0002866635976083043, 0.0002866635976083043, 0.00020796763183591793, 0.00020796763183591796, 0.003439413060103054, 0.0019785636532277536, 0.0010563445583705866, 0.0009878462512206102, 0.0009268569302452915, 0.0009303501220118376, 0.0009450521499675211, 0.0009338302468388767, 0.0007454994206604074, 0.0007143922756574227, 0.0005959824041097608, 0.000489939255620012, 0.0003639433557128564, 0.0003639433557128564, 0.00034172568956238535, 0.00031625442961159415, 0.00031625442961159415, 0.00031625442961159415, 0.0002866635976083043, 0.00031625442961159415, 0.00031625442961159415, 0.00031625442961159415, 0.00031625442961159415, 0.0002866635976083043, 0.0002866635976083043, 0.0003296467373223081, 0.0030302086667589683, 0.0022905961309952275, 0.0014423421148875393, 0.0011662887094479588, 0.0010084285919922545, 0.0009510398686857124, 0.0008476435143953769, 0.0008292668573347753, 0.000775359561036694, 0.0007086937618177163, 0.0005900566192545351, 0.0005662107357647843, 0.0005560947146159504, 0.0005662107357647843, 0.0005447997820805423, 0.00047252607498376054, 0.0004556342527498471, 0.0004556342527498471, 0.0004556342527498471, 0.0004556342527498471, 0.00043685579957347323, 0.00043685579957347323], "accuracy_test_std": 0.007566216449072469, "error_valid": [0.5246802640248494, 0.4064500188253012, 0.3659623846950302, 0.34334849162274095, 0.3152502588478916, 0.2993090526167168, 0.3031844173569277, 0.3008650814194277, 0.30948206890060237, 0.30456837114081325, 0.31123076289533136, 0.31208525508283136, 0.3179755153426205, 0.3437544121799698, 0.3075480633471386, 0.3230112834149097, 0.2870593702936747, 0.3115866787462349, 0.29346732633659633, 0.2957263624811747, 0.2801307770143072, 0.3080363445971386, 0.2802028426204819, 0.2832340102597892, 0.2742096314947289, 0.2730198136295181, 0.2756038803652108, 0.27772025602409633, 0.28819771272590367, 0.2810882200677711, 0.2700695359563253, 0.2689003082643072, 0.2698474562311747, 0.2841090926204819, 0.261962890625, 0.27037544710090367, 0.2616466843938253, 0.26455578172063254, 0.2581581207643072, 0.27874829395707834, 0.2654514542545181, 0.2630306381777108, 0.2537121140813253, 0.2636203995670181, 0.2643528214420181, 0.250964796686747, 0.24473921074924698, 0.2603965667356928, 0.2652381988893072, 0.24942935805722888, 0.2623291015625, 0.2640072006777108, 0.2566623917545181, 0.24137271743222888, 0.25046622035015065, 0.26424104621611444, 0.2527355515813253, 0.25501370717243976, 0.24971467902861444, 0.25719185335090367, 0.24561429310993976, 0.24456713573042166, 0.2541195053652108, 0.24535985739834332, 0.23754735739834332, 0.24512601185993976, 0.24084325583584332, 0.24927640248493976, 0.24717032191265065, 0.2540474397590362, 0.27862622364457834, 0.24011083396084332, 0.2424507600715362, 0.25520784309111444, 0.2478218538215362, 0.23746646743222888, 0.24724238751882532, 0.24492305158132532, 0.24397590361445776, 0.2568756471197289, 0.24118887660015065, 0.24964261342243976, 0.24243016989834332, 0.24436270472515065, 0.2459393237010542, 0.2408123705760542, 0.2399269931287651, 0.2436905826430723, 0.2455025178840362, 0.23550157661897586, 0.24216543910015065, 0.24187129376882532, 0.24275520048945776, 0.23718114646084332, 0.24772919804216864, 0.2492866975715362, 0.2388077701430723, 0.2296216114457832, 0.22817735786897586, 0.22792292215737953, 0.2275464161332832, 0.2270375447100903, 0.22765819135918675, 0.2265492634600903, 0.2260609822100903, 0.2265492634600903, 0.2269360645707832, 0.2270581348832832, 0.22655955854668675, 0.2269360645707832, 0.22719050028237953, 0.22793321724397586, 0.2275773013930723, 0.22709931522966864, 0.22610216255647586, 0.22523737528237953, 0.2255932911332832, 0.22512560005647586, 0.22856415897966864, 0.22980545227786142, 0.24158597279743976, 0.23454560429216864, 0.23273513977786142, 0.23151443665286142, 0.2308937900037651, 0.2308937900037651, 0.2307511295180723, 0.2308731998305723, 0.23122911568147586, 0.23097467996987953, 0.23109675028237953, 0.23134089090737953, 0.23135118599397586, 0.23173798710466864, 0.23285721009036142, 0.23297928040286142, 0.23322342102786142, 0.23334549134036142, 0.23335578642695776, 0.23359992705195776, 0.2336102221385542, 0.23460737481174698, 0.23497358574924698, 0.23447500941265065, 0.23408820830195776, 0.23374258753765065, 0.2512001129518072, 0.2404976350715362, 0.23770031297063254, 0.23314253106174698, 0.23277632012424698, 0.23204389824924698, 0.23216596856174698, 0.23339696677334332, 0.23302046074924698, 0.23253217949924698, 0.23314253106174698, 0.2317791674510542, 0.2316570971385542, 0.2321453783885542, 0.2326336596385542, 0.2332440112010542, 0.23189094267695776, 0.23164680205195776, 0.23250129423945776, 0.2337322924510542, 0.23447500941265065, 0.2351971362010542], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.008470786354127647, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.00026195199428722353, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 9.764878448937284e-07, "rotation_range": [0, 0], "momentum": 0.6672585631205303}, "accuracy_valid_max": 0.7748743999435241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7648028637989458, "accuracy_valid_std": [0.013662909661713145, 0.0067708089574831055, 0.0109052102583345, 0.019563568118127678, 0.017388973159680642, 0.01550834326552678, 0.01416599365442057, 0.009915681329744562, 0.013642215660665214, 0.010629227874343629, 0.012239313982657813, 0.015072361251359427, 0.012545897950746888, 0.01561387803200014, 0.011601565350498326, 0.009134894245198887, 0.013807464777966566, 0.01679412710168978, 0.017459063414255745, 0.019437646020019596, 0.01737121762401042, 0.009553619274438757, 0.014573547323406148, 0.019474421141447533, 0.021112801103339424, 0.01732747007548944, 0.016199584524863357, 0.012370011139042117, 0.01930405778950595, 0.010683435776183895, 0.01882679646080461, 0.013665160075507077, 0.010476395408531104, 0.010473994430627548, 0.012017572728748992, 0.013491540219027326, 0.013668686920027321, 0.01761965835407638, 0.012053474075202363, 0.013683148797021477, 0.014669051855965258, 0.014620959344709705, 0.012287578217803644, 0.014187966963245527, 0.014504279071277985, 0.01814512432384479, 0.02005688513173736, 0.007407885196266385, 0.012663322994202449, 0.01425291697248365, 0.011929836149857171, 0.013583346042238176, 0.012879334967303056, 0.009985779124219756, 0.019664315604320817, 0.012477178886636351, 0.01232061279474316, 0.018584291459805106, 0.006918510169258563, 0.008138575024432049, 0.015493755406535827, 0.00946103769117013, 0.008273888194649753, 0.014345322680421687, 0.011167049109181879, 0.012843800906257058, 0.012800704316345125, 0.014363676435959384, 0.01576704912290821, 0.015049416892152886, 0.014568215025073225, 0.013608612693413522, 0.012139649639690093, 0.013191265990416989, 0.013158774024084108, 0.00963708766945639, 0.009514302389360919, 0.012019675182169794, 0.018036499549177583, 0.01474283272223748, 0.015192993829704602, 0.016028043544231933, 0.01505856899666614, 0.015968336430659712, 0.017871144679248205, 0.01734378896301816, 0.0192177672062441, 0.02192191074115836, 0.012205246047132585, 0.02076766425282109, 0.01468371070751397, 0.012718105935674578, 0.018234115115732558, 0.015189590860478448, 0.022690598882836522, 0.01594986066669611, 0.021457856356839073, 0.02061460469631109, 0.019044238839362286, 0.01977621287383172, 0.020209830705610686, 0.02212838881283523, 0.021565618326788376, 0.02200925842465555, 0.02182403029702151, 0.022171152739005662, 0.020808374425669116, 0.02100824129592868, 0.0211443545444519, 0.020739513574084174, 0.019564759083095396, 0.018906386980784996, 0.016997701260102062, 0.016493174306713942, 0.017738471153562745, 0.018222666680345126, 0.019817425565868883, 0.01713846847451263, 0.016568198866750893, 0.01566027085118636, 0.015145422215097681, 0.01857626581685501, 0.01601629074334383, 0.015555320056322264, 0.016812119708545643, 0.017128228313344002, 0.019171230159197233, 0.018655323908925117, 0.020027271003361866, 0.021328430714751948, 0.021394947295389568, 0.021391959773334066, 0.020588794025185198, 0.01872618209661677, 0.017987357153638767, 0.01894907414112901, 0.01888358727420319, 0.018843247465550834, 0.01709147684937303, 0.016999422356033675, 0.016861856424364306, 0.015090113909503197, 0.015202062982759576, 0.015186676454529077, 0.01732707953162069, 0.016884355815013824, 0.01050639360848409, 0.011590200898253388, 0.011317787278801058, 0.013601475728265205, 0.013897570277592355, 0.01368081722943012, 0.013696706401638857, 0.012641119942446937, 0.013638022117359028, 0.01400417604978549, 0.014623569675625597, 0.01580873616098175, 0.015309027678843467, 0.015042994862232578, 0.015411974736740993, 0.015580088744098174, 0.016469705832080458, 0.01665441871960326, 0.016307174963875053, 0.01654224800051796, 0.01686765367831285, 0.01750780730034877], "accuracy_valid": [0.4753197359751506, 0.5935499811746988, 0.6340376153049698, 0.656651508377259, 0.6847497411521084, 0.7006909473832832, 0.6968155826430723, 0.6991349185805723, 0.6905179310993976, 0.6954316288591867, 0.6887692371046686, 0.6879147449171686, 0.6820244846573795, 0.6562455878200302, 0.6924519366528614, 0.6769887165850903, 0.7129406297063253, 0.6884133212537651, 0.7065326736634037, 0.7042736375188253, 0.7198692229856928, 0.6919636554028614, 0.7197971573795181, 0.7167659897402108, 0.7257903685052711, 0.7269801863704819, 0.7243961196347892, 0.7222797439759037, 0.7118022872740963, 0.7189117799322289, 0.7299304640436747, 0.7310996917356928, 0.7301525437688253, 0.7158909073795181, 0.738037109375, 0.7296245528990963, 0.7383533156061747, 0.7354442182793675, 0.7418418792356928, 0.7212517060429217, 0.7345485457454819, 0.7369693618222892, 0.7462878859186747, 0.7363796004329819, 0.7356471785579819, 0.749035203313253, 0.755260789250753, 0.7396034332643072, 0.7347618011106928, 0.7505706419427711, 0.7376708984375, 0.7359927993222892, 0.7433376082454819, 0.7586272825677711, 0.7495337796498494, 0.7357589537838856, 0.7472644484186747, 0.7449862928275602, 0.7502853209713856, 0.7428081466490963, 0.7543857068900602, 0.7554328642695783, 0.7458804946347892, 0.7546401426016567, 0.7624526426016567, 0.7548739881400602, 0.7591567441641567, 0.7507235975150602, 0.7528296780873494, 0.7459525602409638, 0.7213737763554217, 0.7598891660391567, 0.7575492399284638, 0.7447921569088856, 0.7521781461784638, 0.7625335325677711, 0.7527576124811747, 0.7550769484186747, 0.7560240963855422, 0.7431243528802711, 0.7588111233998494, 0.7503573865775602, 0.7575698301016567, 0.7556372952748494, 0.7540606762989458, 0.7591876294239458, 0.7600730068712349, 0.7563094173569277, 0.7544974821159638, 0.7644984233810241, 0.7578345608998494, 0.7581287062311747, 0.7572447995105422, 0.7628188535391567, 0.7522708019578314, 0.7507133024284638, 0.7611922298569277, 0.7703783885542168, 0.7718226421310241, 0.7720770778426205, 0.7724535838667168, 0.7729624552899097, 0.7723418086408133, 0.7734507365399097, 0.7739390177899097, 0.7734507365399097, 0.7730639354292168, 0.7729418651167168, 0.7734404414533133, 0.7730639354292168, 0.7728094997176205, 0.7720667827560241, 0.7724226986069277, 0.7729006847703314, 0.7738978374435241, 0.7747626247176205, 0.7744067088667168, 0.7748743999435241, 0.7714358410203314, 0.7701945477221386, 0.7584140272025602, 0.7654543957078314, 0.7672648602221386, 0.7684855633471386, 0.7691062099962349, 0.7691062099962349, 0.7692488704819277, 0.7691268001694277, 0.7687708843185241, 0.7690253200301205, 0.7689032497176205, 0.7686591090926205, 0.7686488140060241, 0.7682620128953314, 0.7671427899096386, 0.7670207195971386, 0.7667765789721386, 0.7666545086596386, 0.7666442135730422, 0.7664000729480422, 0.7663897778614458, 0.765392625188253, 0.765026414250753, 0.7655249905873494, 0.7659117916980422, 0.7662574124623494, 0.7487998870481928, 0.7595023649284638, 0.7622996870293675, 0.766857468938253, 0.767223679875753, 0.767956101750753, 0.767834031438253, 0.7666030332266567, 0.766979539250753, 0.767467820500753, 0.766857468938253, 0.7682208325489458, 0.7683429028614458, 0.7678546216114458, 0.7673663403614458, 0.7667559887989458, 0.7681090573230422, 0.7683531979480422, 0.7674987057605422, 0.7662677075489458, 0.7655249905873494, 0.7648028637989458], "seed": 250248888, "model": "residualv3", "loss_std": [0.32800227403640747, 0.13832461833953857, 0.12786197662353516, 0.12397944182157516, 0.12102518230676651, 0.1170179545879364, 0.11318697035312653, 0.10919007658958435, 0.10356045514345169, 0.09548857808113098, 0.08787612617015839, 0.07950656116008759, 0.07336831092834473, 0.0655105710029602, 0.062085334211587906, 0.059272412210702896, 0.05579531937837601, 0.048131659626960754, 0.04510761424899101, 0.0462295264005661, 0.040203746408224106, 0.042000096291303635, 0.04049412161111832, 0.037160713225603104, 0.03759591281414032, 0.03616062551736832, 0.039407044649124146, 0.037344563752412796, 0.032962046563625336, 0.03179125487804413, 0.03463849052786827, 0.03497269004583359, 0.03285086899995804, 0.031754087656736374, 0.034175172448158264, 0.09786640107631683, 0.08300136029720306, 0.032318104058504105, 0.04150477051734924, 0.02652059681713581, 0.02986888960003853, 0.028094282373785973, 0.02361730858683586, 0.025159990414977074, 0.02840592712163925, 0.02055002562701702, 0.026829630136489868, 0.018061095848679543, 0.02841637097299099, 0.027010830119252205, 0.017062924802303314, 0.023878052830696106, 0.030438698828220367, 0.016254166141152382, 0.010080252774059772, 0.03505134955048561, 0.02337103709578514, 0.019816946238279343, 0.01894841156899929, 0.023735765367746353, 0.017699936404824257, 0.021389612928032875, 0.01894664578139782, 0.014095902442932129, 0.02273220755159855, 0.022869620472192764, 0.012750847265124321, 0.01876613311469555, 0.02308008074760437, 0.013522484339773655, 0.02767929434776306, 0.021195216104388237, 0.009375474415719509, 0.02461222931742668, 0.025185994803905487, 0.009653636254370213, 0.017339451238512993, 0.012971391901373863, 0.011097544804215431, 0.024959439411759377, 0.01510713342577219, 0.01323340367525816, 0.011965055018663406, 0.017349813133478165, 0.014893915504217148, 0.014844985678792, 0.012860898859798908, 0.014331361278891563, 0.018862294033169746, 0.011504869908094406, 0.012146302498877048, 0.018469415605068207, 0.019673118367791176, 0.006864269729703665, 0.008206047117710114, 0.022814009338617325, 0.011963550932705402, 0.002529438119381666, 0.00022623632685281336, 5.6212666095234454e-05, 4.066885230713524e-05, 3.135529550490901e-05, 2.470780054864008e-05, 1.9717661416507326e-05, 1.5899759091553278e-05, 1.2987045010959264e-05, 1.0868810932151973e-05, 9.516188583802432e-06, 9.063662218977697e-06, 9.705213415145408e-06, 1.157349834102206e-05, 1.4770367670280393e-05, 1.944266477948986e-05, 2.5824494514381513e-05, 3.4199059882666916e-05, 4.48037899332121e-05, 5.7646971981739625e-05, 7.22591212252155e-05, 8.731216075830162e-05, 0.00010001139162341133, 0.13166694343090057, 0.007731609977781773, 0.0008738844189792871, 0.00010132788884220645, 6.410335481632501e-05, 4.7984940465539694e-05, 3.693764301715419e-05, 2.8797780032618903e-05, 2.2562273443327285e-05, 1.7701830074656755e-05, 1.3910675079387147e-05, 1.0983086212945636e-05, 8.751896530156955e-06, 7.100874427123927e-06, 6.015007784299087e-06, 5.519152637134539e-06, 5.701803729607491e-06, 6.633653356402647e-06, 8.370502655452583e-06, 1.0987505447701551e-05, 1.4612827726523392e-05, 1.9418588635744527e-05, 2.555420905991923e-05, 3.30385155393742e-05, 4.1584378777770326e-05, 5.0183261919301e-05, 0.10828384011983871, 0.011219809763133526, 0.002859189175069332, 0.0005436962237581611, 6.76200506859459e-05, 4.6169832785381004e-05, 3.525890861055814e-05, 2.7646214221022092e-05, 2.187500285799615e-05, 1.7358952391077764e-05, 1.3799063708574977e-05, 1.0966511581500527e-05, 8.738044925848953e-06, 6.994628165557515e-06, 5.658331701852148e-06, 4.696243649959797e-06, 4.1130356294161174e-06, 3.962256869272096e-06, 4.317138063925086e-06, 5.222701929596951e-06, 6.714123173878761e-06, 8.863637958711479e-06]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:27 2016", "state": "available"}], "summary": "d75638d23c916d6c96c5a1fa256d6be6"}