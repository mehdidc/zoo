{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 2, "nbg3": 2, "nbg2": 2, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.11900110086808649, 0.1190325695987576, 0.12383970432082904, 0.12239632511756504, 0.11807489109554486, 0.11810592708014246, 0.1190361654954102, 0.11830870620223195, 0.11832747284259691, 0.1147530986675327, 0.11266390055726584, 0.1128208258208799, 0.11409284464249941, 0.11038288386142729, 0.10767632856116932, 0.10476513853246144, 0.1039413620560379, 0.10681047665679712, 0.107190922197696, 0.10220273252262899, 0.10409773017522285, 0.10339919719057394, 0.10332500205009533, 0.09771945891584434, 0.1001759247004133, 0.09972760902596786, 0.10039493518391909, 0.10149713224397618, 0.09796226093403364, 0.10047457802506815, 0.0952938152470595, 0.09830003322424116, 0.09907424048765212, 0.09714468634401237, 0.09716010668923318, 0.09654284960189324, 0.0985699062162948, 0.09850474787021699, 0.09409095216512187, 0.09728310646430732, 0.09509400395657228, 0.09605994643473291, 0.09453958653340992, 0.09362654943909375, 0.09429591522912918, 0.09595210837803261, 0.09280008562768104, 0.09664006341746008, 0.0944285957377408, 0.09320959359539469, 0.09345266223228701, 0.09303416027579098, 0.09068304071022505, 0.09243344070631554, 0.09399243011280863, 0.09344130637296542, 0.09271548557512978, 0.09189538409838519, 0.0947573197846888, 0.09228426837447992, 0.09198461631056712, 0.09232339511102933, 0.09123714255602429, 0.09630582125657906, 0.09495295613536382, 0.09621939168507695, 0.0958874031297093, 0.09031254072011793, 0.09187180068628906, 0.09150260568577347, 0.09261299692652902, 0.09398474503571509, 0.09155638513404538, 0.09083425364380059, 0.09097629598132968, 0.09074280926318835, 0.09091285559602269, 0.09481151037500186, 0.08923288929632386, 0.09047748229676454, 0.09392020354031347, 0.09006604713329971, 0.08700574795334645, 0.08849361296074139, 0.09215353240702194, 0.09241530185933214, 0.08900955707549707, 0.09117134066711029, 0.091271442400205, 0.09291753256073619, 0.08999364202467428, 0.09038390107893979, 0.09035311348015691, 0.08919690579225785, 0.09149091031827764, 0.09234927726930543, 0.09381760519903878, 0.09032389503184925, 0.08936949447852353, 0.09100814656731207, 0.09076403335313842, 0.09156339751595645, 0.09267200188974975, 0.08734178556906191, 0.08909377262476216, 0.09210213490705776, 0.09109237439336156, 0.08843464352165818, 0.08950828224140775, 0.08972172670706655, 0.09093629545268396, 0.0879587275645038, 0.09153680605806488, 0.09099011560479991, 0.09002217520295139, 0.09149705057261194, 0.0906688792295874, 0.09084652434442818, 0.0889012916835575, 0.09302342436306286, 0.08964605935477721, 0.09185510424108517, 0.09138939019619345, 0.08914410371229958, 0.09146897747368476, 0.08971844679207452, 0.09311693856886903, 0.09131295630576187, 0.09450222663898097, 0.09002326483253806, 0.0915664165705599, 0.09294056278080909, 0.09356023587315679, 0.08732340603620235, 0.0900114763210434, 0.08689662793230768, 0.09084652434442818, 0.09320959359539469, 0.09196134668959673, 0.08895153118161815, 0.08898470778459741, 0.08901085946794113, 0.08963730526478891, 0.09121827703215167, 0.0883516164624562, 0.08866505628031894, 0.08977806289332275, 0.08888443854814146, 0.09147570410509225, 0.08639366447455057, 0.0882219260946247, 0.09110323998523844, 0.08951037437459883, 0.0911408190677965, 0.08670893702512042, 0.09025120275295237, 0.08925657051779191, 0.09145415764168784, 0.09123235323292496, 0.0891045816963973, 0.09210988024483159, 0.08858868770526972, 0.09014888006370599, 0.08908296224158523, 0.09132506504202977, 0.09026394788621296, 0.09173619991947886, 0.09024142038337397, 0.08889978706921962, 0.09231991785038333, 0.08851446965987148, 0.09039938959083624, 0.09127222401279522, 0.0899436871820659, 0.09053295420523544, 0.08906093703171718, 0.09089362844082566, 0.08938475970925412, 0.09069828149967105, 0.09105360009597413, 0.08651898374104856, 0.08955290381540879, 0.09051876924386693, 0.08924817789234828, 0.088984006292624, 0.08724647634566161, 0.08915220606217247, 0.0880349335604479, 0.08909937749226066, 0.08859110352978798, 0.09032942357128196, 0.08812028294516598, 0.0898892404951132, 0.09083425364380059, 0.0891766086919887, 0.09069120222569638, 0.087435257112852, 0.0904936445864239, 0.09005654171176321, 0.08627095406214597, 0.08732493781169177, 0.0882793204110045, 0.08727263800543678, 0.0901085122333943, 0.08980904762643283, 0.08796805418268529, 0.08987098504492869, 0.08871733935938278, 0.0907635421108727, 0.09122531540403565, 0.08820494315433117, 0.088984006292624, 0.08746911078289198, 0.08915130583743928, 0.0880255127236856, 0.08731115086484909, 0.08969936127148215, 0.08931200197361795, 0.08903119435529555, 0.08720568529712294, 0.0884128602480913, 0.09141982880711141, 0.08892024764284527, 0.08670430896944606, 0.08822920349689686, 0.09003128806249594, 0.08777147909386128, 0.08791360115029259, 0.08854428519674151, 0.08937348564024189, 0.08785921586573084, 0.08783322892190164, 0.08833294228589338, 0.0903878474485771, 0.08857570151961179, 0.08996509979686326, 0.08938954826403762, 0.09068736738821995, 0.08719167494699513, 0.08793064036045319, 0.09062638151024802, 0.08983208062811963, 0.08754767829384197, 0.08893498837340807, 0.08802399313945804, 0.08835040528422641, 0.0902393451989513, 0.08958715172485984, 0.09008743066472708, 0.08963700681483333, 0.0898177849775542, 0.08964924244828829, 0.08972291937369982, 0.09127222401279522, 0.09105360009597412, 0.08921369990029308, 0.08973911819217198, 0.08894952615660497, 0.09121329119013459, 0.08946682799537993, 0.08873352075946316, 0.08732493781169177, 0.08959322338874777, 0.08972172670706655, 0.08861405057789512, 0.08615634946145248, 0.08873231479415027, 0.08881137133878896, 0.09040964803580946, 0.09044465607872337, 0.08764296520948173, 0.09041467819406884, 0.08959322338874777, 0.08963700681483333], "moving_avg_accuracy_train": [0.04467479292168674, 0.0916192112198795, 0.13890966208584335, 0.18552792027484938, 0.23066818171121983, 0.27361463537744724, 0.3148219783156061, 0.3534381426828407, 0.389724599498894, 0.42398726756105276, 0.45706858598567035, 0.4872418102184286, 0.5152330847688749, 0.5422748177076501, 0.5671771363886923, 0.5904222427799435, 0.6121829175983347, 0.6325346559589832, 0.6510465329835669, 0.6682743345044873, 0.685019472590183, 0.7005160193070683, 0.7149335438823856, 0.727986970367641, 0.7403962929091902, 0.752200037112247, 0.7628516448468055, 0.7726945865368238, 0.7818097287867558, 0.7902298477755502, 0.7988504059196819, 0.8067901017734969, 0.8140581924997616, 0.8208606752076169, 0.8277665128073372, 0.8343770979723866, 0.8402889740185214, 0.8457484990564283, 0.850866796741147, 0.8559438971875142, 0.8605909419567145, 0.864766222761043, 0.8687451727740952, 0.8728274514304207, 0.8765768034259329, 0.8803065477821348, 0.8836797898412707, 0.88670394188124, 0.890025735193116, 0.8931683047460935, 0.8963354727654601, 0.8987011724768659, 0.9016703812833962, 0.903872036679153, 0.9067077245775027, 0.9089892299811982, 0.9115979312300663, 0.9138186915709151, 0.9160503389800887, 0.9183576733049713, 0.9203236755527874, 0.922453111461364, 0.9243648974537817, 0.9262431667445481, 0.9278983116664788, 0.9297573886323611, 0.9316470488655105, 0.9333500962379956, 0.9348969578491357, 0.9365479811907282, 0.9375820949692457, 0.9389693109241284, 0.9403684076931613, 0.9415334682792669, 0.9428879339513402, 0.9441963732369291, 0.9455575152807061, 0.9465519331803462, 0.9477387014586971, 0.9488750346260804, 0.9500506900490145, 0.9509864154718239, 0.9520709441053644, 0.953087023640611, 0.9542885810657066, 0.9554782282302202, 0.9562900627867162, 0.9570583644899723, 0.9583004760831437, 0.9593101310350702, 0.9599435004616836, 0.9608382693914189, 0.9616435614281806, 0.9623824432371698, 0.9629533103592359, 0.9638435967931919, 0.9646236761198969, 0.9651563198030879, 0.9660122051420562, 0.9665730704712241, 0.9673319908337402, 0.9675843903949446, 0.9681433459337634, 0.9689805550150858, 0.9695246117123725, 0.9699389615351112, 0.9702436346587086, 0.9708119858012714, 0.9711964310464455, 0.9716953873393913, 0.9721491543283438, 0.9725787230822565, 0.9728829742680067, 0.9731426813592783, 0.9737905743679287, 0.9742089566901719, 0.9747102184006728, 0.9750484021328947, 0.9755598458051474, 0.9761236842668013, 0.9766264325569887, 0.9768812403555067, 0.9771999875548959, 0.9776421687692859, 0.9779036484285019, 0.978087210543483, 0.9784030188566046, 0.9785672350432334, 0.9783291109365004, 0.9785689596320071, 0.9789401321929028, 0.9790459307206004, 0.9787458180702271, 0.9792781451487466, 0.9795642801820647, 0.9800712369530148, 0.9800874566312072, 0.9802550099138696, 0.9805917077176634, 0.9809300331808368, 0.9811921691699821, 0.981604578759008, 0.9816839552204566, 0.9816942118068447, 0.9820658297827867, 0.982586185810532, 0.98257446105478, 0.9829945375396635, 0.9833843721893116, 0.9834457843679709, 0.9838822676781618, 0.9842021546151649, 0.9845041718343713, 0.9846347975726208, 0.9851900489900575, 0.9853885704464733, 0.9854542879500188, 0.9856099133718844, 0.9858182179684309, 0.9859209782499011, 0.9861240611478025, 0.9864386128643475, 0.9865311032345393, 0.9868426013448203, 0.9869135181681695, 0.9871020609296658, 0.9874482366138077, 0.9871315003018245, 0.9873664865668228, 0.9875709147173694, 0.9876866583359938, 0.9879178983758884, 0.9880413005563718, 0.9883876787838672, 0.9886500027729503, 0.9887378451161372, 0.9889345613575355, 0.989076308535035, 0.9893356581032182, 0.9896514334073543, 0.9898438578377032, 0.9900193929876678, 0.9902197315503468, 0.9903012034254326, 0.9904639482937327, 0.9906104186752028, 0.9907681268076826, 0.9909853653317335, 0.9912350027443433, 0.9913796688855716, 0.9913780913042434, 0.9915366865412889, 0.9915264666823407, 0.9915831573635041, 0.991523580331973, 0.9915593811843177, 0.9918010334273318, 0.9919479255665263, 0.9921083664436086, 0.9922833543474405, 0.992436137135588, 0.9925124594160051, 0.9925740899804286, 0.9926342638137111, 0.9928413758359544, 0.9929077653607927, 0.9929133931921834, 0.9930337632103144, 0.9932621075218131, 0.993378197221439, 0.9936473993366446, 0.9935837700957512, 0.9936606340500315, 0.9937862875124982, 0.9938617250263087, 0.9939790352044007, 0.9941034396658883, 0.9942412884703838, 0.9942712258884058, 0.9943099353778785, 0.994438900424428, 0.9945808537554791, 0.9945886004582445, 0.9947179369485647, 0.9947566854223829, 0.9948739197415903, 0.9949300142132145, 0.9949781460750255, 0.9951297102325832, 0.995249645835831, 0.9953175841136936, 0.9953363716360593, 0.9954285816110076, 0.9954386225462923, 0.9955323732434703, 0.9956920500757498, 0.9957934022970905, 0.9959199167360561, 0.9960431923817276, 0.9960176570290971, 0.9961170396695609, 0.9961123575399542, 0.9961928574787298, 0.9962182441706159, 0.9963163933981326, 0.9963035417089218, 0.9963625700681501, 0.996460405681817, 0.9965955209871293, 0.9966535893703441, 0.9966046649212614, 0.9966947631881714, 0.9968182085561011, 0.9968963651101296, 0.9969525870328516, 0.9970267183898074, 0.9970040164303446, 0.9970330010824909, 0.9971296821489406, 0.9971390407412755, 0.9971898204020877, 0.9972190499582644, 0.997259475534727, 0.9972864459029411, 0.9973224850475868, 0.9973078570247558, 0.9973864651475814, 0.9974289745063172, 0.9975119430195409, 0.9975371982657796, 0.9976022849151052, 0.9976608628994983, 0.9976359287179822, 0.9976464322317261], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.017962534103360326, 0.03600028637722555, 0.05252773842745827, 0.0668343225539039, 0.07848967912140839, 0.0872402921518163, 0.09379866894484197, 0.09783967540429327, 0.09990607039823363, 0.10048083716304934, 0.10028211610514291, 0.09844771564003142, 0.09565454713465445, 0.09267039030417734, 0.08898448055498927, 0.08494904723975565, 0.08071588523274596, 0.07637203599817398, 0.07181903871711634, 0.06730830915260276, 0.06310107508292367, 0.05895225421596879, 0.054927813928290804, 0.05096856002251544, 0.04725762559372569, 0.043785818429253914, 0.04042834731230667, 0.03725746409109389, 0.03427949004611298, 0.031489626675570766, 0.02900949021246089, 0.02667589012347458, 0.024483727396374066, 0.022451818595652675, 0.020635852072670796, 0.01896556539142306, 0.01738356135774452, 0.01591346294472586, 0.014557889390957836, 0.013334092992344575, 0.012195038918892693, 0.011132431755158373, 0.010161676968499858, 0.009295494262900881, 0.00849246360008705, 0.007768416176741924, 0.0070939834169734435, 0.006466894535323755, 0.005919513879052796, 0.005416444181705231, 0.0049650783429007915, 0.004518939324731622, 0.004146391200689453, 0.003775377658955492, 0.003470210025771569, 0.003170036425358239, 0.0029142806826750307, 0.002667238602830909, 0.0024453369939776573, 0.0022487174197609286, 0.0020586321613305985, 0.0018935794207961612, 0.00173711580984379, 0.0015951552886171365, 0.0014602953021687606, 0.0013453712764375494, 0.0012429714909645117, 0.001144777675044416, 0.001051834935136148, 0.000971184344292881, 0.0008836904316258715, 0.0008126407014126133, 0.0007489938771934179, 0.0006863107849977458, 0.0006341909018093963, 0.0005861799319051075, 0.000544236307684633, 0.0004987124795482939, 0.0004615170021119645, 0.00042698657950642654, 0.0003967274126170537, 0.0003649349099573745, 0.00033902724017435994, 0.00031441627475444823, 0.00029596830949122304, 0.00027910882192641985, 0.0002571296178578681, 0.00023672924363711724, 0.0002269418901624237, 0.0002134223292437303, 0.0001956905077944753, 0.00018332695995360374, 0.0001708307213384899, 0.00015866116615353686, 0.00014572805297768804, 0.00013828873709029277, 0.00012993657718483488, 0.0001194963031055412, 0.00011413953021613536, 0.00010555670645168506, 0.00010018467685629133, 9.073955901712723e-05, 8.447748476480039e-05, 8.233800770095944e-05, 7.67681861396251e-05, 7.063653950609459e-05, 6.440831696566805e-05, 6.08746924603741e-05, 5.6117406533169234e-05, 5.2746282320284405e-05, 4.9324794410622534e-05, 4.605307879860249e-05, 4.228088997501619e-05, 3.8659830936825434e-05, 3.857173599906646e-05, 3.628995630725089e-05, 3.4922330398254175e-05, 3.245941148908442e-05, 3.156764200916188e-05, 3.127210210580818e-05, 3.0419694484803973e-05, 2.796206816399386e-05, 2.6080259341659948e-05, 2.5231951444728063e-05, 2.3324100809908658e-05, 2.129494617942493e-05, 2.0063065577212705e-05, 1.829946162304926e-05, 1.6979843272610724e-05, 1.5799605515975528e-05, 1.5459566594034706e-05, 1.40143498907982e-05, 1.3423523327945132e-05, 1.4631520061876152e-05, 1.3905227371316163e-05, 1.4827751142694494e-05, 1.334734373007106e-05, 1.2265276279842517e-05, 1.205903735157415e-05, 1.188331068770035e-05, 1.1313417110176636e-05, 1.1712810421243474e-05, 1.0598234982808034e-05, 9.539358262606255e-06, 9.82832171673498e-06, 1.1282423105560519e-05, 1.0155418024081462e-05, 1.0728054500041585e-05, 1.1022988536633817e-05, 9.95463278415946e-06, 1.0673828626420053e-05, 1.0527394635965065e-05, 1.029558477864303e-05, 9.419594052218047e-06, 1.1252371876085557e-05, 1.0481831606394592e-05, 9.472517558205333e-06, 8.74323924976238e-06, 8.259432569267713e-06, 7.5285263913713805e-06, 7.146857723014721e-06, 7.3226569921462056e-06, 6.667381510135457e-06, 6.873923013499659e-06, 6.231793474655297e-06, 5.928549483403637e-06, 6.414232973683027e-06, 6.675706698273086e-06, 6.505102931086313e-06, 6.230710456600945e-06, 5.72820867821152e-06, 5.6366354148444625e-06, 5.210024756692634e-06, 5.768823169368723e-06, 5.81126572966837e-06, 5.299585652010618e-06, 5.1179026034785245e-06, 4.786942704092247e-06, 4.913608220334545e-06, 5.319673782620793e-06, 5.120950856914645e-06, 4.886169071081071e-06, 4.758772021239569e-06, 4.342633816985585e-06, 4.146743464709212e-06, 3.925151272070258e-06, 3.75648284031539e-06, 3.8055677432706597e-06, 3.985880508914161e-06, 3.7756470897837815e-06, 3.3981047796710286e-06, 3.2846663446257197e-06, 2.9571397198154312e-06, 2.690350247810946e-06, 2.453260027204405e-06, 2.2194693337415398e-06, 2.523084659350696e-06, 2.464971898429944e-06, 2.4501461839374063e-06, 2.4807184639310395e-06, 2.4427298407250858e-06, 2.250882671045186e-06, 2.0599793421811994e-06, 1.8865694198702018e-06, 2.0839709857027544e-06, 1.915242008206771e-06, 1.7240028597615438e-06, 1.682003045169227e-06, 1.98307286199654e-06, 1.906056941030011e-06, 2.3676792564069933e-06, 2.1673494534362894e-06, 2.0037871153011026e-06, 1.945507537439905e-06, 1.8021741501049833e-06, 1.7458118360503237e-06, 1.7105188827875772e-06, 1.7104876306163916e-06, 1.5475051085350865e-06, 1.4062404188586943e-06, 1.4153042260564631e-06, 1.455130537219556e-06, 1.3101575861312114e-06, 1.3296931770730444e-06, 1.210236857374917e-06, 1.2129081420378352e-06, 1.1199366355551343e-06, 1.0287930570922337e-06, 1.1326589960885392e-06, 1.1488540368171884e-06, 1.0755091195260027e-06, 9.71134946543133e-07, 9.505455672084929e-07, 8.563983939201825e-07, 8.498612935204091e-07, 9.943453810696415e-07, 9.873612978988868e-07, 1.032678297510148e-06, 1.066182431100674e-06, 9.654326760963261e-07, 9.577815915166755e-07, 8.622007334038927e-07, 8.343028213494894e-07, 7.566728963388008e-07, 7.677050444640797e-07, 6.924210332578216e-07, 6.545380546707137e-07, 6.752305149178838e-07, 7.720127749927492e-07, 7.251589316560847e-07, 6.741854539527954e-07, 6.798261878591871e-07, 7.489923988432873e-07, 7.290691813973653e-07, 6.846104046086296e-07, 6.656084869047394e-07, 6.036860488852651e-07, 5.508784345370937e-07, 5.79915648572049e-07, 5.227123329692535e-07, 4.936482652421612e-07, 4.5197274130656556e-07, 4.214835122670013e-07, 3.858817678947086e-07, 3.589829706263476e-07, 3.250104850312009e-07, 3.4812256929560086e-07, 3.2957372258722963e-07, 3.585703180074671e-07, 3.284537333699065e-07, 3.337348073168836e-07, 3.3124374888521066e-07, 3.0371479466758625e-07, 2.74336229409551e-07], "duration": 41403.706197, "accuracy_train": [0.44674792921686746, 0.5141189759036144, 0.5645237198795181, 0.6050922439759037, 0.6369305346385542, 0.660132718373494, 0.6856880647590361, 0.7009836219879518, 0.7163027108433735, 0.7323512801204819, 0.7548004518072289, 0.758800828313253, 0.7671545557228916, 0.7856504141566265, 0.7912980045180723, 0.7996282003012049, 0.8080289909638554, 0.8157003012048193, 0.8176534262048193, 0.8233245481927711, 0.8357257153614458, 0.8399849397590361, 0.844691265060241, 0.8454678087349398, 0.8520801957831325, 0.858433734939759, 0.8587161144578314, 0.8612810617469879, 0.8638460090361446, 0.8660109186746988, 0.8764354292168675, 0.8782473644578314, 0.8794710090361446, 0.8820830195783133, 0.8899190512048193, 0.8938723644578314, 0.8934958584337349, 0.8948842243975904, 0.8969314759036144, 0.9016378012048193, 0.9024143448795181, 0.90234375, 0.9045557228915663, 0.9095679593373494, 0.9103209713855421, 0.9138742469879518, 0.914038968373494, 0.9139213102409639, 0.919921875, 0.9214514307228916, 0.924839984939759, 0.9199924698795181, 0.9283932605421686, 0.9236869352409639, 0.9322289156626506, 0.9295227786144579, 0.9350762424698795, 0.9338055346385542, 0.9361351656626506, 0.9391236822289156, 0.9380176957831325, 0.9416180346385542, 0.9415709713855421, 0.9431475903614458, 0.9427946159638554, 0.9464890813253012, 0.9486539909638554, 0.9486775225903614, 0.9488187123493976, 0.9514071912650602, 0.9468891189759037, 0.9514542545180723, 0.9529602786144579, 0.9520190135542169, 0.955078125, 0.9559723268072289, 0.9578077936746988, 0.9555016942771084, 0.9584196159638554, 0.9591020331325302, 0.9606315888554217, 0.9594079442771084, 0.9618317018072289, 0.9622317394578314, 0.9651025978915663, 0.9661850527108434, 0.9635965737951807, 0.9639730798192772, 0.9694794804216867, 0.9683970256024096, 0.9656438253012049, 0.9688911897590361, 0.9688911897590361, 0.9690323795180723, 0.9680911144578314, 0.9718561746987951, 0.971644390060241, 0.9699501129518072, 0.9737151731927711, 0.9716208584337349, 0.9741622740963856, 0.9698559864457831, 0.9731739457831325, 0.9765154367469879, 0.9744211219879518, 0.973668109939759, 0.9729856927710844, 0.9759271460843374, 0.9746564382530121, 0.9761859939759037, 0.9762330572289156, 0.9764448418674698, 0.975621234939759, 0.9754800451807228, 0.9796216114457831, 0.9779743975903614, 0.9792215737951807, 0.9780920557228916, 0.9801628388554217, 0.9811982304216867, 0.9811511671686747, 0.9791745105421686, 0.9800687123493976, 0.9816217996987951, 0.9802569653614458, 0.9797392695783133, 0.9812452936746988, 0.9800451807228916, 0.9761859939759037, 0.9807275978915663, 0.9822806852409639, 0.9799981174698795, 0.9760448042168675, 0.9840690888554217, 0.9821394954819277, 0.9846338478915663, 0.9802334337349398, 0.9817629894578314, 0.9836219879518072, 0.9839749623493976, 0.9835513930722891, 0.985316265060241, 0.982398343373494, 0.9817865210843374, 0.9854103915662651, 0.987269390060241, 0.9824689382530121, 0.9867752259036144, 0.9868928840361446, 0.9839984939759037, 0.9878106174698795, 0.9870811370481928, 0.9872223268072289, 0.9858104292168675, 0.9901873117469879, 0.9871752635542169, 0.9860457454819277, 0.9870105421686747, 0.9876929593373494, 0.9868458207831325, 0.9879518072289156, 0.989269578313253, 0.9873635165662651, 0.9896460843373494, 0.9875517695783133, 0.9887989457831325, 0.9905638177710844, 0.9842808734939759, 0.9894813629518072, 0.9894107680722891, 0.9887283509036144, 0.9899990587349398, 0.9891519201807228, 0.9915050828313253, 0.9910109186746988, 0.9895284262048193, 0.9907050075301205, 0.9903520331325302, 0.9916698042168675, 0.9924934111445783, 0.9915756777108434, 0.9915992093373494, 0.9920227786144579, 0.9910344503012049, 0.9919286521084337, 0.9919286521084337, 0.9921875, 0.9929405120481928, 0.9934817394578314, 0.9926816641566265, 0.9913638930722891, 0.9929640436746988, 0.9914344879518072, 0.9920933734939759, 0.9909873870481928, 0.9918815888554217, 0.9939759036144579, 0.9932699548192772, 0.9935523343373494, 0.9938582454819277, 0.9938111822289156, 0.993199359939759, 0.993128765060241, 0.993175828313253, 0.9947053840361446, 0.9935052710843374, 0.9929640436746988, 0.994117093373494, 0.9953172063253012, 0.9944230045180723, 0.996070218373494, 0.9930111069277109, 0.9943524096385542, 0.9949171686746988, 0.9945406626506024, 0.9950348268072289, 0.9952230798192772, 0.9954819277108434, 0.9945406626506024, 0.9946583207831325, 0.9955995858433735, 0.9958584337349398, 0.9946583207831325, 0.9958819653614458, 0.995105421686747, 0.9959290286144579, 0.9954348644578314, 0.9954113328313253, 0.9964937876506024, 0.9963290662650602, 0.9959290286144579, 0.9955054593373494, 0.9962584713855421, 0.9955289909638554, 0.9963761295180723, 0.9971291415662651, 0.9967055722891566, 0.997058546686747, 0.9971526731927711, 0.9957878388554217, 0.9970114834337349, 0.996070218373494, 0.9969173569277109, 0.9964467243975904, 0.9971997364457831, 0.9961878765060241, 0.9968938253012049, 0.9973409262048193, 0.9978115587349398, 0.9971762048192772, 0.9961643448795181, 0.9975056475903614, 0.9979292168674698, 0.9975997740963856, 0.9974585843373494, 0.9976939006024096, 0.9967996987951807, 0.9972938629518072, 0.9979998117469879, 0.9972232680722891, 0.9976468373493976, 0.9974821159638554, 0.9976233057228916, 0.9975291792168675, 0.9976468373493976, 0.9971762048192772, 0.9980939382530121, 0.9978115587349398, 0.9982586596385542, 0.9977644954819277, 0.9981880647590361, 0.9981880647590361, 0.9974115210843374, 0.9977409638554217], "end": "2016-01-18 02:39:24.235000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0], "accuracy_valid": [0.45085470085470086, 0.5045405982905983, 0.5535523504273504, 0.5925480769230769, 0.6287393162393162, 0.6523771367521367, 0.6765491452991453, 0.6868322649572649, 0.7005876068376068, 0.7154113247863247, 0.734107905982906, 0.7399839743589743, 0.7421207264957265, 0.7582799145299145, 0.7644230769230769, 0.7704326923076923, 0.7765758547008547, 0.7824519230769231, 0.7793803418803419, 0.7848557692307693, 0.7923344017094017, 0.7935363247863247, 0.7980769230769231, 0.7992788461538461, 0.8026175213675214, 0.8046207264957265, 0.8046207264957265, 0.8055555555555556, 0.8072916666666666, 0.8063568376068376, 0.811965811965812, 0.8108974358974359, 0.8125, 0.8142361111111112, 0.8126335470085471, 0.8185096153846154, 0.8153044871794872, 0.8104967948717948, 0.8169070512820513, 0.8183760683760684, 0.8179754273504274, 0.8170405982905983, 0.8202457264957265, 0.8219818376068376, 0.8199786324786325, 0.8206463675213675, 0.8197115384615384, 0.8221153846153846, 0.8223824786324786, 0.8254540598290598, 0.8227831196581197, 0.8225160256410257, 0.8285256410256411, 0.8234508547008547, 0.8319978632478633, 0.8293269230769231, 0.8298611111111112, 0.828125, 0.828125, 0.8299946581196581, 0.828659188034188, 0.8322649572649573, 0.8309294871794872, 0.8274572649572649, 0.8287927350427351, 0.8302617521367521, 0.8323985042735043, 0.8322649572649573, 0.8285256410256411, 0.8346688034188035, 0.8340010683760684, 0.8326655982905983, 0.8362713675213675, 0.8313301282051282, 0.8340010683760684, 0.8344017094017094, 0.8389423076923077, 0.8337339743589743, 0.8350694444444444, 0.8365384615384616, 0.8345352564102564, 0.8372061965811965, 0.8396100427350427, 0.8389423076923077, 0.8401442307692307, 0.8381410256410257, 0.8398771367521367, 0.8406784188034188, 0.8409455128205128, 0.8390758547008547, 0.8413461538461539, 0.8422809829059829, 0.8388087606837606, 0.8398771367521367, 0.8378739316239316, 0.8405448717948718, 0.8417467948717948, 0.8401442307692307, 0.8428151709401709, 0.8413461538461539, 0.843482905982906, 0.8416132478632479, 0.844551282051282, 0.8466880341880342, 0.84375, 0.8413461538461539, 0.8410790598290598, 0.8433493589743589, 0.8406784188034188, 0.8416132478632479, 0.8422809829059829, 0.844551282051282, 0.8406784188034188, 0.8386752136752137, 0.844551282051282, 0.8436164529914529, 0.844551282051282, 0.8450854700854701, 0.8446848290598291, 0.8452190170940171, 0.8449519230769231, 0.8426816239316239, 0.8454861111111112, 0.8486912393162394, 0.8460202991452992, 0.8460202991452992, 0.8425480769230769, 0.844284188034188, 0.8408119658119658, 0.8444177350427351, 0.8457532051282052, 0.8428151709401709, 0.8422809829059829, 0.8490918803418803, 0.8453525641025641, 0.8481570512820513, 0.8450854700854701, 0.8428151709401709, 0.8476228632478633, 0.8466880341880342, 0.8481570512820513, 0.8493589743589743, 0.8454861111111112, 0.8446848290598291, 0.8506944444444444, 0.8468215811965812, 0.8470886752136753, 0.8510950854700855, 0.8482905982905983, 0.8485576923076923, 0.8498931623931624, 0.8484241452991453, 0.8488247863247863, 0.8476228632478633, 0.8509615384615384, 0.8502938034188035, 0.8498931623931624, 0.8465544871794872, 0.8476228632478633, 0.8493589743589743, 0.8498931623931624, 0.8522970085470085, 0.8504273504273504, 0.8509615384615384, 0.8493589743589743, 0.8464209401709402, 0.8522970085470085, 0.8504273504273504, 0.8496260683760684, 0.8528311965811965, 0.8481570512820513, 0.8477564102564102, 0.8486912393162394, 0.8493589743589743, 0.8524305555555556, 0.8512286324786325, 0.8514957264957265, 0.8506944444444444, 0.8516292735042735, 0.8536324786324786, 0.8529647435897436, 0.8529647435897436, 0.8543002136752137, 0.8512286324786325, 0.8538995726495726, 0.8524305555555556, 0.8522970085470085, 0.8530982905982906, 0.8528311965811965, 0.8512286324786325, 0.8516292735042735, 0.8540331196581197, 0.8513621794871795, 0.8521634615384616, 0.8509615384615384, 0.8526976495726496, 0.8549679487179487, 0.8528311965811965, 0.8543002136752137, 0.8525641025641025, 0.8534989316239316, 0.8557692307692307, 0.8521634615384616, 0.8520299145299145, 0.8540331196581197, 0.8528311965811965, 0.8543002136752137, 0.8545673076923077, 0.8537660256410257, 0.8518963675213675, 0.8563034188034188, 0.8538995726495726, 0.8547008547008547, 0.8532318376068376, 0.8540331196581197, 0.8544337606837606, 0.8524305555555556, 0.8543002136752137, 0.8543002136752137, 0.8528311965811965, 0.8521634615384616, 0.8559027777777778, 0.8536324786324786, 0.858573717948718, 0.8547008547008547, 0.8528311965811965, 0.8537660256410257, 0.8524305555555556, 0.8559027777777778, 0.8545673076923077, 0.8529647435897436, 0.8548344017094017, 0.8529647435897436, 0.8529647435897436, 0.8524305555555556, 0.8557692307692307, 0.8544337606837606, 0.8544337606837606, 0.8553685897435898, 0.8540331196581197, 0.8541666666666666, 0.8529647435897436, 0.8548344017094017, 0.8534989316239316, 0.8512286324786325, 0.8552350427350427, 0.8534989316239316, 0.8551014957264957, 0.8540331196581197, 0.8547008547008547, 0.8521634615384616, 0.8567040598290598, 0.8568376068376068, 0.8556356837606838, 0.8536324786324786, 0.8551014957264957, 0.8529647435897436, 0.8549679487179487, 0.8520299145299145, 0.8537660256410257, 0.8544337606837606, 0.8534989316239316, 0.8557692307692307, 0.8555021367521367, 0.8520299145299145, 0.8544337606837606, 0.8536324786324786, 0.8545673076923077, 0.8536324786324786, 0.8513621794871795, 0.8548344017094017, 0.8526976495726496, 0.8525641025641025, 0.8547008547008547], "accuracy_test": 0.8444, "start": "2016-01-17 15:09:20.528000", "learning_rate_per_epoch": [0.0001357430883217603, 0.00013454112922772765, 0.00013334982213564217, 0.00013216906518209726, 0.0001309987565036863, 0.00012983880878891796, 0.00012868913472630084, 0.00012754964700434357, 0.00012642024375963956, 0.00012530083768069744, 0.00012419134145602584, 0.00012309166777413338, 0.00012200173659948632, 0.00012092146062059328, 0.00011985074525000528, 0.00011878951045218855, 0.00011773767619160935, 0.00011669515515677631, 0.00011566186731215566, 0.00011463772534625605, 0.0001136226492235437, 0.00011261656618444249, 0.00011161938891746104, 0.0001106310446630232, 0.00010965144610963762, 0.00010868052777368575, 0.00010771820234367624, 0.00010676439706003293, 0.0001058190391631797, 0.00010488204861758277, 0.00010395335993962362, 0.00010303289309376851, 0.00010212057532044128, 0.00010121633386006579, 0.00010032010322902352, 9.943181066773832e-05, 9.855138341663405e-05, 9.767874871613458e-05, 9.681384108262137e-05, 9.595659503247589e-05, 9.5106937806122e-05, 9.426480391994119e-05, 9.343012789031491e-05, 9.260283695766702e-05, 9.178287291433662e-05, 9.097017027670518e-05, 9.016466356115416e-05, 8.936628728406504e-05, 8.85749832377769e-05, 8.779068593867123e-05, 8.701332990312949e-05, 8.624285692349076e-05, 8.547920879209414e-05, 8.47223200253211e-05, 8.397213969146833e-05, 8.32285950309597e-05, 8.24916351120919e-05, 8.176120172720402e-05, 8.103723666863516e-05, 8.031968172872439e-05, 7.96084786998108e-05, 7.89035766501911e-05, 7.820491737220436e-05, 7.751244265818968e-05, 7.682610157644376e-05, 7.614583591930568e-05, 7.547159475507215e-05, 7.480331987608224e-05, 7.414096762659028e-05, 7.348447979893535e-05, 7.283380546141416e-05, 7.218888640636578e-05, 7.154967897804454e-05, 7.091613224474713e-05, 7.028819527477026e-05, 6.966581713641062e-05, 6.904895417392254e-05, 6.84375554556027e-05, 6.783157004974782e-05, 6.72309470246546e-05, 6.663564272457734e-05, 6.604560621781275e-05, 6.546080112457275e-05, 6.488116923719645e-05, 6.430667417589575e-05, 6.373726500896737e-05, 6.317289808066562e-05, 6.261352973524481e-05, 6.205910904100165e-05, 6.150959961814806e-05, 6.096495417295955e-05, 6.042513268766925e-05, 5.989009150653146e-05, 5.935978697380051e-05, 5.8834179071709514e-05, 5.831322414451279e-05, 5.7796882174443454e-05, 5.7285113143734634e-05, 5.677787703461945e-05, 5.627513019135222e-05, 5.5776836234144866e-05, 5.528295514523052e-05, 5.479344690684229e-05, 5.430827150121331e-05, 5.382739254855551e-05, 5.3350770031102e-05, 5.287836756906472e-05, 5.24101487826556e-05, 5.1946077292086557e-05, 5.148611307959072e-05, 5.103022340335883e-05, 5.057837188360281e-05, 5.013051850255579e-05, 4.968663051840849e-05, 4.924667518935166e-05, 4.881061613559723e-05, 4.837841697735712e-05, 4.795004497282207e-05, 4.752546738018282e-05, 4.710464781965129e-05, 4.6687553549418226e-05, 4.627415182767436e-05, 4.5864413550589234e-05, 4.545830233837478e-05, 4.505578544922173e-05, 4.465683377929963e-05, 4.426141458679922e-05, 4.386949512991123e-05, 4.3481046304805204e-05, 4.309603900765069e-05, 4.271444049663842e-05, 4.2336221667937934e-05, 4.1961349779739976e-05, 4.158979936619289e-05, 4.122153768548742e-05, 4.08565356337931e-05, 4.0494767745258287e-05, 4.013620127807371e-05, 3.978081076638773e-05, 3.942856710636988e-05, 3.907944119418971e-05, 3.873340756399557e-05, 3.8390437111957e-05, 3.805050437222235e-05, 3.7713580240961164e-05, 3.7379639252321795e-05, 3.704865594045259e-05, 3.67206048395019e-05, 3.6395456845639274e-05, 3.607319013099186e-05, 3.575377559172921e-05, 3.543718776199967e-05, 3.512340481393039e-05, 3.4812401281669736e-05, 3.450415169936605e-05, 3.419863060116768e-05, 3.3895816159201786e-05, 3.359568290761672e-05, 3.329820538056083e-05, 3.3003361750161275e-05, 3.271113018854521e-05, 3.242148522986099e-05, 3.213440504623577e-05, 3.1849867809796706e-05, 3.156784805469215e-05, 3.1288327591028064e-05, 3.10112809529528e-05, 3.073668631259352e-05, 3.046452548005618e-05, 3.0194772989489138e-05, 2.9927410650998354e-05, 2.9662414817721583e-05, 2.9399765480775386e-05, 2.9139442631276324e-05, 2.8881424441351555e-05, 2.862569090211764e-05, 2.837222200469114e-05, 2.812099592119921e-05, 2.7871994461747818e-05, 2.7625199436442927e-05, 2.7380589017411694e-05, 2.7138145014760084e-05, 2.689784741960466e-05, 2.6659678042051382e-05, 2.6423616873216815e-05, 2.6189645723206922e-05, 2.5957746402127668e-05, 2.5727900720085017e-05, 2.5500090487184934e-05, 2.5274297513533384e-05, 2.505050360923633e-05, 2.4828690584399737e-05, 2.4608842068118975e-05, 2.4390939870500006e-05, 2.41749676206382e-05, 2.396090712863952e-05, 2.3748742023599334e-05, 2.3538455934613012e-05, 2.333003249077592e-05, 2.3123453502194025e-05, 2.2918704416952096e-05, 2.2715768864145502e-05, 2.251462865388021e-05, 2.231527105323039e-05, 2.211767787230201e-05, 2.1921834559179842e-05, 2.1727724742959253e-05, 2.1535333871725015e-05, 2.13446473935619e-05, 2.1155648937565275e-05, 2.096832395181991e-05, 2.0782657884410582e-05, 2.059863618342206e-05, 2.041624247794971e-05, 2.0235464035067707e-05, 2.0056286302860826e-05, 1.9878694729413837e-05, 1.9702676581800915e-05, 1.9528217308106832e-05, 1.935530235641636e-05, 1.9183918993803672e-05, 1.9014052668353543e-05, 1.8845690647140145e-05, 1.8678818378248252e-05, 1.851342494774144e-05, 1.8349495803704485e-05, 1.818701821321156e-05, 1.8025979443336837e-05, 1.7866366761154495e-05, 1.770816743373871e-05, 1.7551368728163652e-05, 1.73959579115035e-05, 1.7241924069821835e-05, 1.7089252651203424e-05, 1.693793456070125e-05, 1.6787955246400088e-05, 1.6639303794363514e-05, 1.6491969290655106e-05, 1.634593900234904e-05, 1.6201202015508898e-05, 1.6057747416198254e-05, 1.5915562471491285e-05, 1.577463626745157e-05, 1.5634957890142687e-05, 1.5496516425628215e-05, 1.5359300959971733e-05, 1.522330057923682e-05, 1.5088504369487055e-05, 1.4954901416786015e-05, 1.4822481716691982e-05, 1.4691234355268534e-05, 1.4561149328073952e-05, 1.4432215721171815e-05, 1.4304423530120403e-05, 1.4177763659972697e-05, 1.4052225196792278e-05, 1.3927798136137426e-05, 1.380447247356642e-05, 1.3682239114132244e-05, 1.3561088053393178e-05, 1.3441010196402203e-05, 1.3321995538717601e-05, 1.3204034075897653e-05, 1.3087117622490041e-05, 1.2971236174053047e-05, 1.2856380635639653e-05, 1.274254191230284e-05, 1.2629711818590295e-05, 1.2517880350060295e-05, 1.2407039321260527e-05, 1.2297179637243971e-05, 1.2188293112558313e-05, 1.2080370652256534e-05, 1.1973403161391616e-05], "accuracy_train_last": 0.9977409638554217, "error_valid": [0.5491452991452992, 0.4954594017094017, 0.4464476495726496, 0.40745192307692313, 0.3712606837606838, 0.3476228632478633, 0.32345085470085466, 0.3131677350427351, 0.2994123931623932, 0.28458867521367526, 0.265892094017094, 0.26001602564102566, 0.25787927350427353, 0.2417200854700855, 0.23557692307692313, 0.2295673076923077, 0.22342414529914534, 0.21754807692307687, 0.2206196581196581, 0.21514423076923073, 0.20766559829059827, 0.20646367521367526, 0.20192307692307687, 0.20072115384615385, 0.1973824786324786, 0.19537927350427353, 0.19537927350427353, 0.19444444444444442, 0.19270833333333337, 0.19364316239316237, 0.18803418803418803, 0.1891025641025641, 0.1875, 0.18576388888888884, 0.18736645299145294, 0.18149038461538458, 0.18469551282051277, 0.18950320512820518, 0.18309294871794868, 0.18162393162393164, 0.1820245726495726, 0.18295940170940173, 0.17975427350427353, 0.17801816239316237, 0.18002136752136755, 0.17935363247863245, 0.18028846153846156, 0.17788461538461542, 0.1776175213675214, 0.17454594017094016, 0.17721688034188032, 0.17748397435897434, 0.17147435897435892, 0.17654914529914534, 0.1680021367521367, 0.17067307692307687, 0.17013888888888884, 0.171875, 0.171875, 0.1700053418803419, 0.17134081196581197, 0.1677350427350427, 0.16907051282051277, 0.1725427350427351, 0.1712072649572649, 0.16973824786324787, 0.16760149572649574, 0.1677350427350427, 0.17147435897435892, 0.16533119658119655, 0.16599893162393164, 0.16733440170940173, 0.16372863247863245, 0.1686698717948718, 0.16599893162393164, 0.16559829059829057, 0.1610576923076923, 0.16626602564102566, 0.16493055555555558, 0.16346153846153844, 0.1654647435897436, 0.16279380341880345, 0.1603899572649573, 0.1610576923076923, 0.15985576923076927, 0.16185897435897434, 0.1601228632478633, 0.15932158119658124, 0.15905448717948723, 0.16092414529914534, 0.15865384615384615, 0.15771901709401714, 0.16119123931623935, 0.1601228632478633, 0.16212606837606836, 0.1594551282051282, 0.15825320512820518, 0.15985576923076927, 0.1571848290598291, 0.15865384615384615, 0.15651709401709402, 0.15838675213675213, 0.15544871794871795, 0.15331196581196582, 0.15625, 0.15865384615384615, 0.15892094017094016, 0.15665064102564108, 0.15932158119658124, 0.15838675213675213, 0.15771901709401714, 0.15544871794871795, 0.15932158119658124, 0.1613247863247863, 0.15544871794871795, 0.15638354700854706, 0.15544871794871795, 0.15491452991452992, 0.1553151709401709, 0.15478098290598286, 0.15504807692307687, 0.15731837606837606, 0.15451388888888884, 0.15130876068376065, 0.1539797008547008, 0.1539797008547008, 0.15745192307692313, 0.15571581196581197, 0.15918803418803418, 0.1555822649572649, 0.15424679487179482, 0.1571848290598291, 0.15771901709401714, 0.15090811965811968, 0.1546474358974359, 0.15184294871794868, 0.15491452991452992, 0.1571848290598291, 0.1523771367521367, 0.15331196581196582, 0.15184294871794868, 0.15064102564102566, 0.15451388888888884, 0.1553151709401709, 0.14930555555555558, 0.15317841880341876, 0.15291132478632474, 0.1489049145299145, 0.15170940170940173, 0.1514423076923077, 0.15010683760683763, 0.15157585470085466, 0.1511752136752137, 0.1523771367521367, 0.14903846153846156, 0.14970619658119655, 0.15010683760683763, 0.15344551282051277, 0.1523771367521367, 0.15064102564102566, 0.15010683760683763, 0.14770299145299148, 0.1495726495726496, 0.14903846153846156, 0.15064102564102566, 0.15357905982905984, 0.14770299145299148, 0.1495726495726496, 0.15037393162393164, 0.14716880341880345, 0.15184294871794868, 0.15224358974358976, 0.15130876068376065, 0.15064102564102566, 0.14756944444444442, 0.14877136752136755, 0.14850427350427353, 0.14930555555555558, 0.14837072649572647, 0.1463675213675214, 0.1470352564102564, 0.1470352564102564, 0.1456997863247863, 0.14877136752136755, 0.1461004273504274, 0.14756944444444442, 0.14770299145299148, 0.14690170940170943, 0.14716880341880345, 0.14877136752136755, 0.14837072649572647, 0.14596688034188032, 0.14863782051282048, 0.14783653846153844, 0.14903846153846156, 0.1473023504273504, 0.14503205128205132, 0.14716880341880345, 0.1456997863247863, 0.14743589743589747, 0.14650106837606836, 0.14423076923076927, 0.14783653846153844, 0.1479700854700855, 0.14596688034188032, 0.14716880341880345, 0.1456997863247863, 0.1454326923076923, 0.14623397435897434, 0.14810363247863245, 0.14369658119658124, 0.1461004273504274, 0.14529914529914534, 0.14676816239316237, 0.14596688034188032, 0.14556623931623935, 0.14756944444444442, 0.1456997863247863, 0.1456997863247863, 0.14716880341880345, 0.14783653846153844, 0.1440972222222222, 0.1463675213675214, 0.14142628205128205, 0.14529914529914534, 0.14716880341880345, 0.14623397435897434, 0.14756944444444442, 0.1440972222222222, 0.1454326923076923, 0.1470352564102564, 0.14516559829059827, 0.1470352564102564, 0.1470352564102564, 0.14756944444444442, 0.14423076923076927, 0.14556623931623935, 0.14556623931623935, 0.14463141025641024, 0.14596688034188032, 0.14583333333333337, 0.1470352564102564, 0.14516559829059827, 0.14650106837606836, 0.14877136752136755, 0.1447649572649573, 0.14650106837606836, 0.14489850427350426, 0.14596688034188032, 0.14529914529914534, 0.14783653846153844, 0.14329594017094016, 0.1431623931623932, 0.14436431623931623, 0.1463675213675214, 0.14489850427350426, 0.1470352564102564, 0.14503205128205132, 0.1479700854700855, 0.14623397435897434, 0.14556623931623935, 0.14650106837606836, 0.14423076923076927, 0.1444978632478633, 0.1479700854700855, 0.14556623931623935, 0.1463675213675214, 0.1454326923076923, 0.1463675213675214, 0.14863782051282048, 0.14516559829059827, 0.1473023504273504, 0.14743589743589747, 0.14529914529914534], "accuracy_train_std": [0.1218714341285735, 0.12416452858805285, 0.11982913287871068, 0.11917262287857791, 0.11810459110625977, 0.11530394937079133, 0.11292621123372659, 0.11121107183675553, 0.1111353055728006, 0.10803704681639106, 0.10625340044072734, 0.10560783195862247, 0.10501831148574842, 0.1014852431545677, 0.10084935584863353, 0.10018356945892959, 0.09926967739843358, 0.09787183391253712, 0.09705626983283218, 0.09750520189911013, 0.09398673911052466, 0.09226644827076849, 0.09187537770873389, 0.09042804209594936, 0.08917371262572646, 0.08773196305149852, 0.08721332546070361, 0.08797998715096256, 0.08666949455709921, 0.08600215543354875, 0.08179985670690745, 0.08227699867597388, 0.08178915017121056, 0.08083485680923855, 0.07863782313500953, 0.07641030386984224, 0.07722939287870709, 0.07652892680173654, 0.07572516897038126, 0.07370333822185274, 0.07424472052206224, 0.07416175681095276, 0.07346861716551065, 0.07078172046198501, 0.07103286805477116, 0.06958686713558977, 0.06931447000300292, 0.06953940834116937, 0.06785799349578156, 0.06652245559851686, 0.06634695251124874, 0.06734328877248924, 0.06497602804414071, 0.06617210110085087, 0.06342394565349863, 0.06487545665709066, 0.06260586910163718, 0.06331499294453542, 0.060815174876866725, 0.06004211975542106, 0.06080410188330359, 0.05843155894399281, 0.05997501635939271, 0.05946501149487157, 0.057931934877862294, 0.057179644461314225, 0.055301364996878606, 0.0553630662713406, 0.05602116256486529, 0.05444483596167905, 0.05746189509910391, 0.05408040328575295, 0.053587000885740914, 0.05509166884917506, 0.051920170271025946, 0.05220381424180801, 0.05085671213249348, 0.052255509460407856, 0.04975820710899775, 0.04939137615044804, 0.04927924319757905, 0.050188182178801395, 0.04828843423157959, 0.04822221683698377, 0.04682719768253436, 0.04575607840567742, 0.047867602918830764, 0.04703919165609983, 0.043314144019821026, 0.04409281176263186, 0.04639310146973932, 0.04389341619915983, 0.043993821675008246, 0.04389273495680687, 0.04435536198035798, 0.042210149804420845, 0.0415935261105825, 0.043099399333155534, 0.04031751931729837, 0.04205230044906309, 0.040442179273708766, 0.043509455612736454, 0.040959092585833634, 0.038445780977369344, 0.040370279877475726, 0.04158026418048878, 0.04112229664973716, 0.038483577670077665, 0.03960058134530663, 0.03866331452002871, 0.038539919442746, 0.038574523346448716, 0.038386423294629074, 0.03886817843141446, 0.035763086952430405, 0.03746045735974079, 0.03530376919907736, 0.036395378624652815, 0.03526195976614649, 0.03482552727571032, 0.03467305914199414, 0.036181626234100726, 0.035417083561192754, 0.0338556487195998, 0.03502200992081092, 0.035187886905269694, 0.03446899766659394, 0.03488069747860334, 0.0378560612068444, 0.03473707269663176, 0.03337815854798675, 0.03539804312810885, 0.0386902019576263, 0.032095956775558036, 0.03276859048212511, 0.030353636489645484, 0.03536401853415648, 0.03349567300247068, 0.032214375555543365, 0.03163335991816927, 0.03206392003387714, 0.030230878262267807, 0.03239032439981835, 0.03295526790630997, 0.029934448798110115, 0.028410217128325078, 0.03290134593805159, 0.028623706433288612, 0.02787153036046178, 0.03152886713939049, 0.02762733213038905, 0.028168909932930156, 0.028024092515241874, 0.029856422874550217, 0.02466149261040977, 0.02836785155441048, 0.029171311826969745, 0.028935290190021456, 0.02717216180922859, 0.02857912890625203, 0.027314856852388113, 0.025774855546377717, 0.027825001588261837, 0.025354822526104114, 0.027856983559121595, 0.026478005314881477, 0.02420789128227121, 0.0312498582428923, 0.025431918976181033, 0.025661818627163557, 0.026641948019400404, 0.024942092178011646, 0.0258111695243846, 0.023007902660990134, 0.023673471211807486, 0.025393481783746827, 0.02420176020588578, 0.02445727425406726, 0.022649847554426884, 0.021784936235798982, 0.023065747834945357, 0.02316973943377589, 0.02241860169072223, 0.02383714274343137, 0.022515905769944493, 0.02231908718342353, 0.022704398101416175, 0.021287370585033598, 0.020296965694457814, 0.02150969588254326, 0.022762260427155005, 0.02069979424999361, 0.02370624219514588, 0.022410807514206522, 0.023445992055651812, 0.023015987843699466, 0.019302131314439513, 0.02040869084596441, 0.020571271982953613, 0.019073207090019622, 0.01996257377229657, 0.020276767123530545, 0.020648489383883983, 0.02037741031069757, 0.018228962468247647, 0.02019556518743079, 0.021052048559661207, 0.019269456838549633, 0.017409825803685077, 0.0185454150353751, 0.015459383168948276, 0.02085723959814024, 0.01911023077826276, 0.01824889393731588, 0.018619926417734793, 0.01758414075864966, 0.017384234947257823, 0.01672170029458016, 0.018540771464224594, 0.018455862319527068, 0.016796884230671914, 0.016012575901604497, 0.018455862319527068, 0.01633683064258742, 0.017811560500775408, 0.015892456391028653, 0.016708913053620083, 0.01717994076793706, 0.014785484775660662, 0.015570185733211188, 0.016438335986962472, 0.017119108682791463, 0.01512186701338716, 0.01673434540549826, 0.014806835397113083, 0.013306755073585474, 0.014784454825652594, 0.013565140781577802, 0.013585209680785493, 0.016040061822862817, 0.014086916884737294, 0.015742200859604105, 0.014170787684051231, 0.015167205768917818, 0.013155147387695241, 0.015441266120575607, 0.014217465220452677, 0.012845401721125126, 0.011866451189610381, 0.013205918604891254, 0.015765399498042076, 0.012353812568280005, 0.011317122262943626, 0.012252997233902723, 0.012462790163464596, 0.01178189789116469, 0.01398784487067765, 0.013174832106765488, 0.011133394185019168, 0.013215894416319995, 0.01226212261976773, 0.012643273791994047, 0.012553962848387843, 0.012535776942143735, 0.01226212261976773, 0.013316821674568822, 0.01101719993600562, 0.011741857200722235, 0.010285985919490719, 0.011981064721841522, 0.010898954224261759, 0.010763166349606432, 0.012570646858667956, 0.011665612488576556], "accuracy_test_std": 0.09042201059476614, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.5309942147082798, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00013695577702405203, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.4935533458491156e-07, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.008854618024617067}, "accuracy_valid_max": 0.858573717948718, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256, 512],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8547008547008547, "loss_train": [1.7221720218658447, 1.4639129638671875, 1.3214919567108154, 1.2152574062347412, 1.127669334411621, 1.0552005767822266, 0.9933755993843079, 0.9388889670372009, 0.8909831643104553, 0.8463237285614014, 0.805240273475647, 0.7692262530326843, 0.7400689125061035, 0.711061418056488, 0.6888681054115295, 0.6651291847229004, 0.6458498239517212, 0.630338191986084, 0.6102645397186279, 0.5952615141868591, 0.5813670754432678, 0.5663089156150818, 0.5523540377616882, 0.5403136014938354, 0.5286977887153625, 0.5177153944969177, 0.5050693154335022, 0.494816392660141, 0.483553022146225, 0.4745487868785858, 0.4644629657268524, 0.45516237616539, 0.4492717683315277, 0.4395606219768524, 0.4307660162448883, 0.4228515028953552, 0.41471484303474426, 0.4082038998603821, 0.3999551832675934, 0.3935113251209259, 0.38506391644477844, 0.3814123570919037, 0.3729434013366699, 0.36949461698532104, 0.36263513565063477, 0.35691308975219727, 0.3512635827064514, 0.34483402967453003, 0.3403985798358917, 0.33492618799209595, 0.3298097848892212, 0.3212648928165436, 0.31757935881614685, 0.31395575404167175, 0.31287330389022827, 0.30642399191856384, 0.30085113644599915, 0.29818564653396606, 0.29196739196777344, 0.28765982389450073, 0.2823885977268219, 0.2814195156097412, 0.27606913447380066, 0.27401623129844666, 0.2670109272003174, 0.265688955783844, 0.2601346969604492, 0.2575778365135193, 0.25486043095588684, 0.2512441575527191, 0.24727179110050201, 0.2462119162082672, 0.24178726971149445, 0.238925963640213, 0.2369312196969986, 0.23256146907806396, 0.22977221012115479, 0.22668948769569397, 0.22259759902954102, 0.22148004174232483, 0.21931450068950653, 0.2152431309223175, 0.2134598046541214, 0.21343167126178741, 0.20827129483222961, 0.20432688295841217, 0.20326903462409973, 0.20254912972450256, 0.197910875082016, 0.19762636721134186, 0.19633691012859344, 0.1925065815448761, 0.19055108726024628, 0.18834279477596283, 0.18451440334320068, 0.18429668247699738, 0.18420623242855072, 0.17979973554611206, 0.17786356806755066, 0.1755329668521881, 0.17603731155395508, 0.17189621925354004, 0.1706445962190628, 0.16840760409832, 0.1677405685186386, 0.16493192315101624, 0.16454710066318512, 0.16183380782604218, 0.160442516207695, 0.16098445653915405, 0.15764360129833221, 0.15518176555633545, 0.15506000816822052, 0.1511959582567215, 0.15290126204490662, 0.1488731950521469, 0.15062326192855835, 0.1476035714149475, 0.14736947417259216, 0.14418451488018036, 0.1445908397436142, 0.14073659479618073, 0.13893502950668335, 0.14007402956485748, 0.13828080892562866, 0.1362561285495758, 0.1343640238046646, 0.13368511199951172, 0.13117150962352753, 0.13127201795578003, 0.129858136177063, 0.1283959299325943, 0.1273787021636963, 0.1289539635181427, 0.12604495882987976, 0.12337760627269745, 0.12561583518981934, 0.12419211864471436, 0.12000014632940292, 0.1217639222741127, 0.11871091276407242, 0.11868394911289215, 0.11851850152015686, 0.11459443718194962, 0.11562103033065796, 0.11539024859666824, 0.11246054619550705, 0.11168712377548218, 0.11291177570819855, 0.10989924520254135, 0.11084386706352234, 0.11025030165910721, 0.10779409110546112, 0.10751605778932571, 0.10624519735574722, 0.1052214652299881, 0.10425426065921783, 0.10422387719154358, 0.10309522598981857, 0.10225626081228256, 0.10194624960422516, 0.10034934431314468, 0.10019075125455856, 0.10047581046819687, 0.09863382577896118, 0.09909568727016449, 0.09831047803163528, 0.09580053389072418, 0.0950867235660553, 0.09451787173748016, 0.09393757581710815, 0.09423092007637024, 0.09404855221509933, 0.0922171026468277, 0.0917721837759018, 0.09286320954561234, 0.09170263260602951, 0.0895484983921051, 0.088254414498806, 0.09041301906108856, 0.08845549076795578, 0.08790755271911621, 0.08686322718858719, 0.08654431253671646, 0.08528227359056473, 0.0842585563659668, 0.08539766818284988, 0.08363538235425949, 0.08475390821695328, 0.08026478439569473, 0.08128916472196579, 0.08058981597423553, 0.08244974166154861, 0.07983201742172241, 0.0783078521490097, 0.07880764454603195, 0.07856772840023041, 0.0785379558801651, 0.07943875342607498, 0.07910535484552383, 0.07894378155469894, 0.07517416030168533, 0.07611583918333054, 0.07420776039361954, 0.07539624720811844, 0.07581458985805511, 0.0746767669916153, 0.0736839771270752, 0.07500257343053818, 0.07418113201856613, 0.07276329398155212, 0.0729672759771347, 0.07132287323474884, 0.07029770314693451, 0.07069304585456848, 0.06940076500177383, 0.07040040194988251, 0.07125071436166763, 0.07018979638814926, 0.06909690052270889, 0.06889884918928146, 0.06963880360126495, 0.06775492429733276, 0.06883367896080017, 0.06890695542097092, 0.06753035634756088, 0.06691265851259232, 0.06541159003973007, 0.06691204011440277, 0.06570935249328613, 0.06538303196430206, 0.06566251814365387, 0.06407736986875534, 0.0638645738363266, 0.0659078061580658, 0.06314179301261902, 0.06344292312860489, 0.06298772245645523, 0.06206749379634857, 0.062344975769519806, 0.061471521854400635, 0.06241139769554138, 0.062377460300922394, 0.06047222390770912, 0.06051111966371536, 0.05985378473997116, 0.060489147901535034, 0.06103985384106636, 0.05928204208612442, 0.059603530913591385, 0.05989258363842964, 0.05857299640774727, 0.058117665350437164, 0.058855775743722916, 0.05854196101427078, 0.05872289463877678, 0.056625962257385254, 0.056516245007514954, 0.057374294847249985, 0.05641550570726395, 0.05852792039513588, 0.05684947967529297, 0.0558125376701355, 0.05656465142965317, 0.05550321564078331, 0.05604350566864014, 0.05455177277326584, 0.055261313915252686, 0.05478137359023094, 0.05561652407050133, 0.0549776591360569, 0.05428305268287659, 0.054476793855428696, 0.0538356713950634], "accuracy_train_first": 0.44674792921686746, "model": "residual", "loss_std": [0.26584258675575256, 0.24588383734226227, 0.25223758816719055, 0.2546074688434601, 0.2555917203426361, 0.2557395100593567, 0.2546788454055786, 0.25168904662132263, 0.24998964369297028, 0.24861879646778107, 0.2450072318315506, 0.24420617520809174, 0.2428097128868103, 0.2394285649061203, 0.2359083890914917, 0.23531168699264526, 0.23358558118343353, 0.23243457078933716, 0.2302822768688202, 0.22737060487270355, 0.2265220582485199, 0.224039688706398, 0.2219083160161972, 0.2179032862186432, 0.21809150278568268, 0.21739770472049713, 0.21257878839969635, 0.21173393726348877, 0.21009434759616852, 0.2103278785943985, 0.20708544552326202, 0.20446768403053284, 0.20439782738685608, 0.20358432829380035, 0.19797851145267487, 0.19898079335689545, 0.19504989683628082, 0.19368211925029755, 0.19156740605831146, 0.1888224184513092, 0.1884625256061554, 0.18787452578544617, 0.18625931441783905, 0.18580378592014313, 0.18130932748317719, 0.18207032978534698, 0.1803096979856491, 0.177664652466774, 0.1762847602367401, 0.17641879618167877, 0.17243780195713043, 0.1731431633234024, 0.16896258294582367, 0.16626021265983582, 0.16946619749069214, 0.1649067997932434, 0.16524925827980042, 0.16268514096736908, 0.16053077578544617, 0.1590040624141693, 0.15633545815944672, 0.1549798995256424, 0.1557825207710266, 0.1555500030517578, 0.15273283421993256, 0.15119192004203796, 0.1475772112607956, 0.14896105229854584, 0.14732162654399872, 0.14668840169906616, 0.14427818357944489, 0.14425095915794373, 0.14070889353752136, 0.14136482775211334, 0.13614392280578613, 0.13753758370876312, 0.13733665645122528, 0.1362241953611374, 0.1357296109199524, 0.136115163564682, 0.1340693235397339, 0.13079938292503357, 0.1299055814743042, 0.12903757393360138, 0.12904109060764313, 0.12680542469024658, 0.12775127589702606, 0.1246071308851242, 0.12335492670536041, 0.1241483986377716, 0.12278739362955093, 0.11999248713254929, 0.120796799659729, 0.11814416944980621, 0.1185193806886673, 0.11770087480545044, 0.1158967986702919, 0.11580485105514526, 0.11419150978326797, 0.11247880756855011, 0.11559692025184631, 0.11261574923992157, 0.11157645285129547, 0.1096225157380104, 0.11001446843147278, 0.10684667527675629, 0.10845796763896942, 0.10703402757644653, 0.10487992316484451, 0.10798991471529007, 0.10448157787322998, 0.10420658439397812, 0.10622892528772354, 0.10423415899276733, 0.10236360132694244, 0.09957048296928406, 0.10332237929105759, 0.10141526162624359, 0.1010468602180481, 0.09650034457445145, 0.09756937623023987, 0.09800578653812408, 0.09642031788825989, 0.09769446402788162, 0.09614157676696777, 0.09320876002311707, 0.09292103350162506, 0.09626072645187378, 0.09217394888401031, 0.0929681807756424, 0.0923650860786438, 0.09039042145013809, 0.0903826579451561, 0.0920344814658165, 0.09163954108953476, 0.08778256922960281, 0.0892992913722992, 0.09259290993213654, 0.08785448968410492, 0.08711546659469604, 0.08684676885604858, 0.0843735858798027, 0.08721348643302917, 0.08357967436313629, 0.08416558057069778, 0.08416126668453217, 0.0829777866601944, 0.08003673702478409, 0.08294863253831863, 0.08057190477848053, 0.08432045578956604, 0.0807395800948143, 0.08162049949169159, 0.0806819424033165, 0.07786062359809875, 0.07971149682998657, 0.07677016407251358, 0.08047057688236237, 0.07667254656553268, 0.07586972415447235, 0.07595737278461456, 0.07517668604850769, 0.07562226057052612, 0.07672832906246185, 0.07548784464597702, 0.07696346938610077, 0.0773126408457756, 0.07246407121419907, 0.07335199415683746, 0.07443499565124512, 0.07035910338163376, 0.07180948555469513, 0.07124927639961243, 0.07400619983673096, 0.07094038277864456, 0.07074141502380371, 0.0707687959074974, 0.07007303833961487, 0.06840426474809647, 0.07200098037719727, 0.0701499804854393, 0.07060664892196655, 0.06985147297382355, 0.06976572424173355, 0.06717219948768616, 0.06680285930633545, 0.0692615732550621, 0.06710195541381836, 0.06782761216163635, 0.0641365647315979, 0.06524607539176941, 0.06552966684103012, 0.06562335044145584, 0.06461034715175629, 0.062277860939502716, 0.06556913256645203, 0.0626252219080925, 0.0638624057173729, 0.06335075199604034, 0.06382301449775696, 0.06678410619497299, 0.06077706441283226, 0.06314901262521744, 0.06144169345498085, 0.06347622722387314, 0.06224829703569412, 0.06286090612411499, 0.06082834675908089, 0.06259498745203018, 0.0635836198925972, 0.06032177805900574, 0.061788398772478104, 0.058656103909015656, 0.05862788110971451, 0.059458184987306595, 0.05649065971374512, 0.05812403932213783, 0.05958734080195427, 0.06269066035747528, 0.05959770828485489, 0.057248808443546295, 0.05860239639878273, 0.05745219066739082, 0.059060536324977875, 0.05849248543381691, 0.05644216015934944, 0.058742865920066833, 0.05746796354651451, 0.05859833583235741, 0.05514458939433098, 0.0559963658452034, 0.05474322289228439, 0.056727513670921326, 0.055862944573163986, 0.057388804852962494, 0.05673341453075409, 0.05587537959218025, 0.05584629625082016, 0.053696077316999435, 0.05441759526729584, 0.0547100231051445, 0.054603271186351776, 0.05551457777619362, 0.05386725813150406, 0.05219825357198715, 0.051131296902894974, 0.05267681926488876, 0.052693866193294525, 0.05356421321630478, 0.052265726029872894, 0.05114062502980232, 0.054087989032268524, 0.05055621266365051, 0.05193381756544113, 0.051316823810338974, 0.053135957568883896, 0.051316481083631516, 0.05031779780983925, 0.05263371765613556, 0.04981318861246109, 0.054125621914863586, 0.051835086196660995, 0.05018192529678345, 0.05186711996793747, 0.05037982016801834, 0.05040307343006134, 0.04893331974744797, 0.04836009442806244, 0.04903487488627434, 0.049788810312747955, 0.04851756989955902, 0.04884934052824974, 0.04953338950872421, 0.04783759266138077]}, "state": "available", "life": [{"dt": "Sun May 15 22:04:59 2016", "state": "available"}], "summary": "3efed2e37d6c97a1b5cfb54361a3647d"}