{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 32, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 6, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.011935767696812052, 0.02058907132639276, 0.015764931839698147, 0.012347130352941993, 0.01026850524422497, 0.010321359644543828, 0.011606777886629135, 0.011991172659562422, 0.011952862915582237, 0.011507529276560815, 0.011657486782867623, 0.010440228081514456, 0.008874427408890915, 0.012253401748581236, 0.012742068838674682, 0.012750902571469285, 0.010861495891904837, 0.008553602473741253, 0.009964865889929253, 0.012125479394231364, 0.009651408112846977, 0.01065393649011902, 0.011430172590966424, 0.013151540063322366, 0.009960259545945465, 0.009299211822862346, 0.009178723408974255, 0.010338007790825878, 0.011684977987805045, 0.013544575119741597, 0.010686462625174854, 0.010893465643732312, 0.013003633483044888, 0.013098275090019585, 0.00960672302655161, 0.013678328394343601, 0.01184493985917211, 0.012912156881040315, 0.014413531531822196, 0.013999944304561598, 0.013493750204148615, 0.013070511798899514, 0.012806610423310315, 0.013608102705063548, 0.012884736667625204, 0.011465043590913975, 0.013733868142761011, 0.014613868300463788, 0.012253928930409564, 0.013356741120506254, 0.011725777774166345, 0.013282407166390392, 0.016149811749203612, 0.01409306857099231, 0.015312457218750197, 0.011783297497070142, 0.012902775066052441, 0.012084179012556815, 0.014549450884396414, 0.01357163919109443, 0.014407191185711613, 0.013411208492913912, 0.014275150752324668, 0.014769046092979573, 0.014307442311550228, 0.014596148662126336, 0.014215495106686245, 0.014159633206680632, 0.012745037771985802, 0.014116998786836095, 0.01455330035447451, 0.013787133267514289, 0.014823006793864708, 0.015540119328449451, 0.015070310279947277, 0.012764261686197024, 0.014013884295563708, 0.013958533896573365, 0.011983862011409928, 0.014720457701515121, 0.01303608569950078, 0.014892906587537579, 0.013876033992216454, 0.011934058549936778, 0.013577142793426334, 0.013951380895388187, 0.014137878021192629, 0.0131911000467455, 0.012913018823393688, 0.013621392878734049, 0.013991030028070197, 0.013824584927463095, 0.013003517293364086, 0.013761306636189935, 0.013718598947383302, 0.013653876178054403, 0.013849865878935445, 0.014858111676430075, 0.014401246002932694, 0.014631186098598727, 0.014140722234248003, 0.014467284999143688, 0.011275374040303243, 0.014045108383875871, 0.012939381912078904, 0.014533925831072632, 0.013804415268109053, 0.014524880898771884, 0.01257314748191178, 0.013900018611987293, 0.013076845298203927, 0.014118257680496038, 0.013247012569735454, 0.014582187605221305, 0.013704176295760729, 0.013599390611202824, 0.012800244265582765, 0.012126472973250662, 0.012413233745370398], "moving_avg_accuracy_train": [0.0478470203488372, 0.1045227785275932, 0.16138671298218898, 0.2162858439172665, 0.268526552276555, 0.3172194778963063, 0.36304034168382593, 0.40559235953533074, 0.4447491922706589, 0.4813179296050548, 0.5153922594643168, 0.5465006101720933, 0.5756513635697972, 0.6018497671491408, 0.6268282141491585, 0.6497830747086796, 0.6711000337395189, 0.6908874383113034, 0.7090844383259187, 0.7258128358093106, 0.7414704989395736, 0.7561227566199056, 0.7695095710857297, 0.7818460946549899, 0.7934045147898969, 0.8039745396744177, 0.8140152266549733, 0.8228518460910356, 0.8312118848692521, 0.8389473280672198, 0.8462114241929913, 0.8529446034502796, 0.8594088604306023, 0.8652731946890833, 0.8708811945550309, 0.8758307742332025, 0.8803272125733097, 0.8847880638115951, 0.8888166366236343, 0.8923911628318413, 0.8958500518954179, 0.8990862849395416, 0.9019477053566247, 0.9047648713058275, 0.907230313854093, 0.9096073943642171, 0.9118491094197666, 0.9139665622709331, 0.9157909617262872, 0.9176538103730105, 0.9194070680169572, 0.9209756632524522, 0.9224733573727126, 0.9239189383309471, 0.9252269366397867, 0.9264599747379896, 0.9276045141608775, 0.9287298946938485, 0.929712582336636, 0.9306412150913445, 0.9315188012003347, 0.9322201648972078, 0.933002635043469, 0.9336789563893898, 0.93427373075668, 0.9348833964003272, 0.9354274451819907, 0.9358636106628687, 0.9363004095206775, 0.9366934924438866, 0.9371611633176227, 0.9374797966051849, 0.9377850956568295, 0.9381459674068997, 0.9384218517593252, 0.9387189758015083, 0.9390073498275775, 0.9392854515926972, 0.939619412489629, 0.9399130378992578, 0.9401657471215136, 0.9402862285763057, 0.9403458698094374, 0.9405994015704187, 0.9407857635255491, 0.940981355022062, 0.9411016919439514, 0.9412517397057671, 0.9413588448568682, 0.9414576367393062, 0.9414767589203958, 0.9415567839500525, 0.9416636116112488, 0.9417179398765727, 0.9419109945415547, 0.9419987132340861, 0.9420753709573737, 0.9420514290535891, 0.9420926243092214, 0.94209475070951, 0.9421385171483412, 0.9422175065706887, 0.9422373356305357, 0.9422785053701307, 0.9423108717893284, 0.942356277608273, 0.9423762165060374, 0.9423244791473773, 0.9423522481888503, 0.9423679036821192, 0.9424819750248707, 0.9425056202226421, 0.9424757836756454, 0.9424953977107203, 0.9425455663768023, 0.9425791284810471, 0.9425697707962868, 0.942505545308574, 0.9424524287160703], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 925271589, "moving_var_accuracy_train": [0.020604036206358374, 0.04745290667195398, 0.07180917937966769, 0.09175349263854198, 0.10713996786360988, 0.11776498012594458, 0.12488444613745997, 0.12869206953282702, 0.1296221805283065, 0.1286954154275642, 0.1262754134830279, 0.1223574374885473, 0.1177695915525763, 0.11216983954827417, 0.10656816092424097, 0.10065367544158044, 0.09467802257832474, 0.08873409273767958, 0.08284086074969882, 0.07707532821599011, 0.0715742571266983, 0.06634902931020611, 0.06132698759306709, 0.05656399715773459, 0.052109971126096354, 0.047904502848021224, 0.0440213911185926, 0.04032202459425349, 0.03691883437018769, 0.03376548466638979, 0.030863840032470856, 0.028185477355420752, 0.025743009184647538, 0.02347822201283952, 0.021413446774023796, 0.019492587147536548, 0.01772529005250037, 0.016131853791181355, 0.014664733002180323, 0.013313254840480713, 0.012089604578419816, 0.010974902959420742, 0.00995110220470837, 0.009027419800105662, 0.008179383482724279, 0.007412299740216358, 0.006716297343707218, 0.0060850200685287174, 0.005506473962030112, 0.004987058411552496, 0.004516017781691763, 0.004086560422637949, 0.0036980921694749207, 0.0033470902912887193, 0.0030277789983431925, 0.002738684545073453, 0.002476605824981011, 0.002240343574578819, 0.0020250002921505233, 0.0018302614920735283, 0.0016541667592744106, 0.0014931772826645936, 0.0013493698901662435, 0.0012185495962161513, 0.001099878445526406, 0.00099323583074716, 0.0008965761493639094, 0.0008086306973679049, 0.0007294847668107616, 0.0006579269177903529, 0.0005941026704265875, 0.0005356061479314131, 0.000482884400736688, 0.000435768016443007, 0.0003928762243819258, 0.0003543831462117218, 0.00031969326780075175, 0.00028842000634654076, 0.0002605817746380023, 0.00023529954010481936, 0.00021234434365345576, 0.00019124055131664971, 0.00017214850987518998, 0.00015551216407210764, 0.00014027352466977752, 0.00012659047650437355, 0.00011406175762686453, 0.00010285821084161099, 9.267563337798124e-05, 8.349590856450382e-05, 7.514960862834008e-05, 6.769228381384993e-05, 6.1025764775234975e-05, 5.4949752341429503e-05, 4.979020804032863e-05, 4.488043835747069e-05, 4.044528218058033e-05, 3.640591289533379e-05, 3.2780595047579855e-05, 2.9502576237025557e-05, 2.656955812383469e-05, 2.3968756271036343e-05, 2.157541936846244e-05, 1.9433131958741082e-05, 1.749924702869211e-05, 1.5767877521369168e-05, 1.4194667806028793e-05, 1.2799291813956143e-05, 1.1526302709539514e-05, 1.0375878288810994e-05, 9.455400901064131e-06, 8.51489266935652e-06, 7.671415378250982e-06, 6.907736233773121e-06, 6.2396146659037355e-06, 5.625790932885433e-06, 5.063999935973549e-06, 4.594724161823771e-06, 4.160644097234296e-06], "duration": 69883.574736, "accuracy_train": [0.4784702034883721, 0.6146046021363972, 0.6731621230735512, 0.7103780223329641, 0.7386929275101514, 0.7554558084740679, 0.7754281157715025, 0.788560520198874, 0.7971606868886121, 0.810436565614618, 0.8220612281976744, 0.826475766542082, 0.8380081441491326, 0.8376353993632337, 0.8516342371493172, 0.8563768197443706, 0.8629526650170728, 0.8689740794573644, 0.8728574384574567, 0.8763684131598376, 0.8823894671119417, 0.8879930757428941, 0.889990901278147, 0.8928748067783315, 0.8974302960040605, 0.8991047636351052, 0.904381409479974, 0.9023814210155963, 0.9064522338732004, 0.9085663168489295, 0.9115882893249354, 0.9135432167658729, 0.9175871732535069, 0.9180522030154117, 0.9213531933485604, 0.9203769913367479, 0.9207951576342747, 0.9249357249561646, 0.925073791931986, 0.9245618987057033, 0.926980053467608, 0.9282123823366556, 0.9277004891103728, 0.9301193648486527, 0.9294192967884828, 0.9310011189553341, 0.9320245449197121, 0.9330236379314323, 0.932210556824474, 0.9344194481935216, 0.9351863868124769, 0.9350930203719084, 0.9359526044550572, 0.9369291669550572, 0.9369989214193429, 0.9375573176218162, 0.9379053689668696, 0.9388583194905868, 0.9385567711217239, 0.9389989098837209, 0.9394170761812477, 0.9385324381690661, 0.9400448663598191, 0.9397658485026762, 0.9396267000622923, 0.9403703871931525, 0.9403238842169619, 0.9397890999907714, 0.940231599240956, 0.9402312387527685, 0.9413702011812477, 0.9403474961932448, 0.9405327871216316, 0.9413938131575305, 0.9409048109311554, 0.9413930921811554, 0.9416027160622, 0.9417883674787744, 0.9426250605620154, 0.9425556665859173, 0.9424401301218162, 0.9413705616694352, 0.9408826409076227, 0.9428811874192506, 0.9424630211217239, 0.9427416784906791, 0.942184724240956, 0.9426021695621077, 0.9423227912167773, 0.9423467636812477, 0.941648858550203, 0.9422770092169619, 0.9426250605620154, 0.9422068942644887, 0.9436484865263934, 0.9427881814668696, 0.9427652904669619, 0.9418359519195275, 0.9424633816099114, 0.9421138883121077, 0.942532415097822, 0.9429284113718162, 0.9424157971691584, 0.9426490330264857, 0.9426021695621077, 0.9427649299787744, 0.9425556665859173, 0.9418588429194352, 0.9426021695621077, 0.9425088031215393, 0.9435086171096345, 0.9427184270025839, 0.9422072547526762, 0.9426719240263934, 0.9429970843715393, 0.9428811874192506, 0.942485551633444, 0.9419275159191584, 0.9419743793835363], "end": "2016-01-27 08:34:25.388000", "learning_rate_per_epoch": [0.00026934093330055475, 0.00025290518533438444, 0.0002374723699176684, 0.00022298131079878658, 0.0002093745133606717, 0.0001965980336535722, 0.00018460120190866292, 0.0001733364479150623, 0.0001627590972930193, 0.0001528271968709305, 0.00014350135461427271, 0.00013474459410645068, 0.0001265221944777295, 0.00011880154488608241, 0.00011155202082591131, 0.00010474488226464018, 9.835312812356278e-05, 9.23514089663513e-05, 8.671593241160735e-05, 8.142433944158256e-05, 7.645565347047523e-05, 7.179017120506614e-05, 6.740938260918483e-05, 6.329591997200623e-05, 5.9433470596559346e-05, 5.580671495408751e-05, 5.240127211436629e-05, 4.920363426208496e-05, 4.62011230411008e-05, 4.33818313467782e-05, 4.0734579670242965e-05, 3.824886880465783e-05, 3.591484346543439e-05, 3.3723244996508583e-05, 3.166538226651028e-05, 2.973309346998576e-05, 2.7918717023567297e-05, 2.6215057005174458e-05, 2.461535950715188e-05, 2.311327807547059e-05, 2.1702857338823378e-05, 2.0378503904794343e-05, 1.9134964531986043e-05, 1.7967307940125465e-05, 1.6870904801180586e-05, 1.5841405911487527e-05, 1.4874729458824731e-05, 1.3967041923024226e-05, 1.3114743524056394e-05, 1.2314454579609446e-05, 1.1563000953174196e-05, 1.0857402230612934e-05, 1.0194860806223005e-05, 9.572749149810988e-06, 8.988599802250974e-06, 8.440096280537546e-06, 7.925063982838765e-06, 7.441459729307098e-06, 6.987366305111209e-06, 6.560982455994235e-06, 6.160617431305582e-06, 5.784683708043303e-06, 5.4316901696438435e-06, 5.100237103761174e-06, 4.789009835803881e-06, 4.49677418146166e-06, 4.222371444484452e-06, 3.964713414461585e-06, 3.7227782740956172e-06, 3.4956065064761788e-06, 3.2822972571011633e-06, 3.0820044685242465e-06, 2.8939341518707806e-06, 2.717340066737961e-06, 2.551522129579098e-06, 2.3958227757248096e-06, 2.2496246856462676e-06, 2.1123478290974163e-06, 1.9834478734992445e-06, 1.8624136828293558e-06, 1.7487652712588897e-06, 1.6420518704762799e-06, 1.5418503380715265e-06, 1.4477633385467925e-06, 1.3594177517006756e-06, 1.2764631946993177e-06, 1.1985706578343525e-06, 1.125431367654528e-06, 1.0567551953499787e-06, 9.922697472575237e-07, 9.31719341679127e-07, 8.748638720135204e-07, 8.214778404180834e-07, 7.713495051575592e-07, 7.242801416396105e-07, 6.800830192332796e-07, 6.385828896782186e-07, 5.996151912768255e-07, 5.630254236166365e-07, 5.286684086058813e-07, 4.964079494129692e-07, 4.661160915020446e-07, 4.376726963073452e-07, 4.109649864858511e-07, 3.858870343265153e-07, 3.623393922680407e-07, 3.40228666573239e-07, 3.1946720469022694e-07, 2.999726405050751e-07, 2.8166766696813283e-07, 2.644797234552243e-07, 2.4834059786371654e-07, 2.3318632713653642e-07, 2.1895679935823864e-07, 2.0559559743560385e-07, 1.9304971488054434e-07, 1.8126941370155691e-07, 1.7020796860833798e-07, 1.5982152490323642e-07], "accuracy_valid": [0.4727062547063253, 0.6042024543486446, 0.6535718067582832, 0.6758194888930723, 0.6994305346385542, 0.7123302781438253, 0.7272846267884037, 0.7376914886106928, 0.7403255600527108, 0.7519943053463856, 0.7523296310240963, 0.7578742705195783, 0.7686473432793675, 0.7643439970820783, 0.7673957548945783, 0.7703960372740963, 0.7759406767695783, 0.7769481245293675, 0.7788909544427711, 0.7787997693900602, 0.7824618787650602, 0.7835193312311747, 0.7854930464043675, 0.7837325865963856, 0.7874564664909638, 0.7884227339043675, 0.7878123823418675, 0.7880668180534638, 0.7877917921686747, 0.7909553252070783, 0.7871711455195783, 0.7925731245293675, 0.7931422957454819, 0.7913009459713856, 0.7907420698418675, 0.7914230162838856, 0.7927966749811747, 0.7934070265436747, 0.7916774519954819, 0.7911891707454819, 0.7927760848079819, 0.7908229598079819, 0.7948718702936747, 0.7933967314570783, 0.7916980421686747, 0.7917186323418675, 0.7917995223079819, 0.7951160109186747, 0.7936717573418675, 0.7947600950677711, 0.7931834760918675, 0.7935496870293675, 0.7949836455195783, 0.7924098738704819, 0.7948615752070783, 0.7948924604668675, 0.7947600950677711, 0.7953807417168675, 0.7948821653802711, 0.7946380247552711, 0.7957366575677711, 0.7934173216302711, 0.7943938841302711, 0.7937732374811747, 0.7942615187311747, 0.7942615187311747, 0.7942615187311747, 0.7931628859186747, 0.7961234586784638, 0.7937732374811747, 0.7941394484186747, 0.7947600950677711, 0.7932746611445783, 0.7948718702936747, 0.7942615187311747, 0.7948924604668675, 0.7943938841302711, 0.7936614622552711, 0.7952689664909638, 0.7956145872552711, 0.7947806852409638, 0.7947497999811747, 0.7940379682793675, 0.7949027555534638, 0.7951366010918675, 0.7941497435052711, 0.7950042356927711, 0.7950145307793675, 0.7941497435052711, 0.7936614622552711, 0.7940276731927711, 0.7942718138177711, 0.7936614622552711, 0.7934070265436747, 0.7935393919427711, 0.7952483763177711, 0.7946380247552711, 0.7937835325677711, 0.7937732374811747, 0.7937732374811747, 0.7945159544427711, 0.7948821653802711, 0.7945365446159638, 0.7934173216302711, 0.7944041792168675, 0.7940173781061747, 0.7947600950677711, 0.7937732374811747, 0.7946483198418675, 0.7941497435052711, 0.7944041792168675, 0.7940276731927711, 0.7940276731927711, 0.7948821653802711, 0.7951263060052711, 0.7951263060052711, 0.7936614622552711, 0.7947806852409638, 0.7956248823418675], "accuracy_test": 0.8018136160714286, "start": "2016-01-26 13:09:41.814000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0], "accuracy_train_last": 0.9419743793835363, "batch_size_eval": 1024, "accuracy_train_std": [0.02117426590491218, 0.018917029399516817, 0.019304636833634738, 0.01933275783560302, 0.017839164661526137, 0.01594821500407368, 0.016223513413333064, 0.016799950862151074, 0.016590038417165658, 0.01587399641939387, 0.015454410087623993, 0.016374787891850942, 0.01662736463377365, 0.01661780301365221, 0.014289848977584627, 0.014938608717244901, 0.014910858599901796, 0.014582420560803314, 0.01347468810729245, 0.013050697996675466, 0.012088399665252122, 0.012017673494039843, 0.013321141450340036, 0.011944187754967677, 0.011599578717865095, 0.011284839779866425, 0.01298482841084918, 0.011901523250330835, 0.010875643939298827, 0.011210677098189792, 0.011370504720533532, 0.010546181146028209, 0.009922888726063903, 0.009782429200644613, 0.009716966752798541, 0.009498515533701221, 0.009312019443641734, 0.009296648426047618, 0.0091703594828736, 0.010284637313208087, 0.010191697149821903, 0.008575236259696905, 0.009961968911590947, 0.008881352267979344, 0.009156271563105715, 0.009337952815610255, 0.008718851276833644, 0.008869665117396933, 0.008791709606993372, 0.008108133356181565, 0.0089026579607838, 0.008652371542874387, 0.008504329620955993, 0.008617190129103662, 0.008948490865621278, 0.008362500026653917, 0.008681050982505094, 0.00864749863930954, 0.008233372215979256, 0.008790342279615148, 0.007518869639878738, 0.008725398257886607, 0.008164083126170925, 0.008306239583733414, 0.008354292274023171, 0.007506784908120385, 0.007855118283350289, 0.00836661979102178, 0.00822664954379655, 0.007999772776830234, 0.007644954270922481, 0.007737809492325048, 0.007633240059650426, 0.007493864791395926, 0.008567429967806668, 0.007934566654977633, 0.007795479822814344, 0.007805566299854563, 0.007791803198454945, 0.007519980028009686, 0.007359231501687132, 0.007769015306220713, 0.007770584536805331, 0.0070884589437069595, 0.007338648432963652, 0.007416061984062991, 0.007580341932150782, 0.007706677856586782, 0.007515034546077295, 0.007559982921478138, 0.007688086334554659, 0.00713754606983607, 0.007455234469816048, 0.0077357273721243135, 0.007090683706638838, 0.00742284819590752, 0.0073677383323515555, 0.007513484593575778, 0.007600356617110868, 0.0076947862327466305, 0.007443088345634119, 0.007269257291211568, 0.00765292491001525, 0.00777605562555722, 0.007387766843944642, 0.0076366619992354915, 0.006958531554923669, 0.007636412973099597, 0.006911377542689012, 0.007619247360498897, 0.007435054159730745, 0.007232706673615907, 0.007727377649683744, 0.006794477236765281, 0.0072419793775449605, 0.007580694372133405, 0.007638941913321735, 0.007857755777594084, 0.00698616293441197], "accuracy_test_std": 0.010746027838584691, "error_valid": [0.5272937452936747, 0.3957975456513554, 0.3464281932417168, 0.3241805111069277, 0.3005694653614458, 0.2876697218561747, 0.27271537321159633, 0.2623085113893072, 0.2596744399472892, 0.24800569465361444, 0.24767036897590367, 0.24212572948042166, 0.23135265672063254, 0.23565600291792166, 0.23260424510542166, 0.22960396272590367, 0.22405932323042166, 0.22305187547063254, 0.22110904555722888, 0.22120023060993976, 0.21753812123493976, 0.21648066876882532, 0.21450695359563254, 0.21626741340361444, 0.2125435335090362, 0.21157726609563254, 0.21218761765813254, 0.2119331819465362, 0.21220820783132532, 0.20904467479292166, 0.21282885448042166, 0.20742687547063254, 0.2068577042545181, 0.20869905402861444, 0.20925793015813254, 0.20857698371611444, 0.20720332501882532, 0.20659297345632532, 0.2083225480045181, 0.2088108292545181, 0.2072239151920181, 0.2091770401920181, 0.20512812970632532, 0.20660326854292166, 0.20830195783132532, 0.20828136765813254, 0.2082004776920181, 0.20488398908132532, 0.20632824265813254, 0.20523990493222888, 0.20681652390813254, 0.20645031297063254, 0.20501635448042166, 0.2075901261295181, 0.20513842479292166, 0.20510753953313254, 0.20523990493222888, 0.20461925828313254, 0.20511783461972888, 0.20536197524472888, 0.20426334243222888, 0.20658267836972888, 0.20560611586972888, 0.20622676251882532, 0.20573848126882532, 0.20573848126882532, 0.20573848126882532, 0.20683711408132532, 0.2038765413215362, 0.20622676251882532, 0.20586055158132532, 0.20523990493222888, 0.20672533885542166, 0.20512812970632532, 0.20573848126882532, 0.20510753953313254, 0.20560611586972888, 0.20633853774472888, 0.2047310335090362, 0.20438541274472888, 0.2052193147590362, 0.20525020001882532, 0.20596203172063254, 0.2050972444465362, 0.20486339890813254, 0.20585025649472888, 0.20499576430722888, 0.20498546922063254, 0.20585025649472888, 0.20633853774472888, 0.20597232680722888, 0.20572818618222888, 0.20633853774472888, 0.20659297345632532, 0.20646060805722888, 0.20475162368222888, 0.20536197524472888, 0.20621646743222888, 0.20622676251882532, 0.20622676251882532, 0.20548404555722888, 0.20511783461972888, 0.2054634553840362, 0.20658267836972888, 0.20559582078313254, 0.20598262189382532, 0.20523990493222888, 0.20622676251882532, 0.20535168015813254, 0.20585025649472888, 0.20559582078313254, 0.20597232680722888, 0.20597232680722888, 0.20511783461972888, 0.20487369399472888, 0.20487369399472888, 0.20633853774472888, 0.2052193147590362, 0.20437511765813254], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.5675846831964794, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0002868448220269416, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "l2_decay": 6.872857199325608e-06, "optimization": "adam", "nb_data_augmentation": 1, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.0610221143293766}, "accuracy_valid_max": 0.7961234586784638, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        #nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        nb_data_augmentation=make_constant_param(1),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7956248823418675, "loss_train": [1.7930893898010254, 1.3660516738891602, 1.1672016382217407, 1.048575758934021, 0.9619596004486084, 0.8948638439178467, 0.8395721316337585, 0.7966737747192383, 0.7571311593055725, 0.7230443358421326, 0.696241557598114, 0.6715332865715027, 0.6470111012458801, 0.6273027062416077, 0.6092732548713684, 0.5902683734893799, 0.5786592364311218, 0.5623223781585693, 0.5486385226249695, 0.5349979996681213, 0.5255368947982788, 0.5155049562454224, 0.5054654479026794, 0.4993211328983307, 0.48971816897392273, 0.48428359627723694, 0.47801268100738525, 0.47052207589149475, 0.46400904655456543, 0.4599076211452484, 0.4515743553638458, 0.45008453726768494, 0.43992164731025696, 0.4407435357570648, 0.43483492732048035, 0.431234747171402, 0.42811334133148193, 0.4255416989326477, 0.4208184778690338, 0.4194965660572052, 0.41742733120918274, 0.41075414419174194, 0.4132104814052582, 0.410398930311203, 0.4076521694660187, 0.4072561264038086, 0.4052973985671997, 0.3990737199783325, 0.3987765610218048, 0.40149930119514465, 0.3971627950668335, 0.3958592712879181, 0.3955981433391571, 0.39280959963798523, 0.3925309181213379, 0.39097344875335693, 0.3934001922607422, 0.3893926441669464, 0.38900336623191833, 0.3864178955554962, 0.3857782781124115, 0.3885749578475952, 0.38633719086647034, 0.38662275671958923, 0.38610923290252686, 0.383225679397583, 0.38556891679763794, 0.380536824464798, 0.3825880289077759, 0.3807743191719055, 0.3823191523551941, 0.3847205936908722, 0.3801313638687134, 0.37848934531211853, 0.3802972435951233, 0.37790337204933167, 0.37956464290618896, 0.3780297040939331, 0.3802627921104431, 0.3792355954647064, 0.3769707679748535, 0.37923088669776917, 0.3798576593399048, 0.37716442346572876, 0.37771961092948914, 0.3775732219219208, 0.3782556354999542, 0.37632375955581665, 0.3772925138473511, 0.3745585083961487, 0.3755106031894684, 0.37587326765060425, 0.3768785893917084, 0.3770143985748291, 0.37657544016838074, 0.37603074312210083, 0.37702739238739014, 0.37654343247413635, 0.3759145736694336, 0.37561509013175964, 0.3746720254421234, 0.37581995129585266, 0.3775901794433594, 0.37476831674575806, 0.37823963165283203, 0.3762848973274231, 0.37776991724967957, 0.3742625415325165, 0.377409428358078, 0.3735515773296356, 0.3757396638393402, 0.37400567531585693, 0.37687093019485474, 0.3761358857154846, 0.37731853127479553, 0.3765769600868225, 0.37662193179130554, 0.37441569566726685, 0.3731456696987152], "accuracy_train_first": 0.4784702034883721, "model": "residualv5", "loss_std": [0.2661631405353546, 0.17604538798332214, 0.1789054274559021, 0.17873753607273102, 0.17769122123718262, 0.17935329675674438, 0.1735619604587555, 0.17487595975399017, 0.17021696269512177, 0.1663549542427063, 0.16405706107616425, 0.16019852459430695, 0.1582230031490326, 0.15831875801086426, 0.15688957273960114, 0.15347188711166382, 0.15122658014297485, 0.1477821320295334, 0.1471971869468689, 0.14580203592777252, 0.14261898398399353, 0.14441965520381927, 0.14038819074630737, 0.13920418918132782, 0.13900911808013916, 0.13525250554084778, 0.13618651032447815, 0.13530191779136658, 0.13106946647167206, 0.1306583285331726, 0.13187400996685028, 0.13020801544189453, 0.12722884118556976, 0.1303148716688156, 0.12953394651412964, 0.12499064952135086, 0.1270652413368225, 0.12327662110328674, 0.12494039535522461, 0.12601102888584137, 0.12346678227186203, 0.12265464663505554, 0.12229649722576141, 0.12182874232530594, 0.12186595052480698, 0.12449253350496292, 0.1204947829246521, 0.12183929979801178, 0.12009049952030182, 0.11933440715074539, 0.12163302302360535, 0.12067320197820663, 0.12056777626276016, 0.12179330736398697, 0.11811088770627975, 0.11746134608983994, 0.11786151677370071, 0.12021421641111374, 0.11652913689613342, 0.11508256942033768, 0.11852332949638367, 0.1174885705113411, 0.11693676561117172, 0.11827035248279572, 0.11897614598274231, 0.11736419051885605, 0.11955466121435165, 0.11663107573986053, 0.1195109486579895, 0.11577010154724121, 0.11759976297616959, 0.11668070405721664, 0.1152096688747406, 0.11368053406476974, 0.11685863882303238, 0.11368854343891144, 0.11515982449054718, 0.11607030779123306, 0.11835785210132599, 0.11740287393331528, 0.11497140675783157, 0.11620859801769257, 0.11556420475244522, 0.11774349957704544, 0.11531632393598557, 0.11627309769392014, 0.11486340314149857, 0.11308301240205765, 0.11540071666240692, 0.11572147160768509, 0.11516569554805756, 0.11353820562362671, 0.11703917384147644, 0.11466994136571884, 0.11676034331321716, 0.11402691900730133, 0.11541827023029327, 0.11513487249612808, 0.11350389569997787, 0.115276999771595, 0.11483648419380188, 0.11371946334838867, 0.11433279514312744, 0.1134648397564888, 0.11514650285243988, 0.113154336810112, 0.1175101175904274, 0.11498992890119553, 0.11559498310089111, 0.1140173003077507, 0.11556008458137512, 0.11701664328575134, 0.11458185315132141, 0.11628978699445724, 0.11512240767478943, 0.11226674914360046, 0.11453504115343094, 0.11523550748825073, 0.11562349647283554]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:17 2016", "state": "available"}], "summary": "08e4e133fb1201dcd37a34c56f592c32"}