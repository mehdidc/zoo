{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.012066893756814693, 0.022208348423768277, 0.01744832760416067, 0.021449454919726534, 0.021573686574392514, 0.018417812091455286, 0.018501556563327408, 0.015471178114700087, 0.01486078078293364, 0.021172440986154208, 0.014004053719653395, 0.014184291694242023, 0.014386956294765007, 0.016846899283818606, 0.01470693682565221, 0.01762168977557497, 0.012463373310083743, 0.017771175183992353, 0.018103207752377917, 0.014610480194922903, 0.013054566062600973, 0.01488615723538183, 0.012374623471400632, 0.014426259866014068, 0.015153332259339188, 0.01706424348774692, 0.012343159575453778, 0.012378736790635225, 0.017130085106126892, 0.015343823788592016, 0.012859697484377257, 0.015968912183971975, 0.014404831681590829, 0.014025930731738214, 0.0122367766921559, 0.013618238883727018, 0.014301308197214854, 0.01294262187043708, 0.012976244878362594, 0.010586829468306256, 0.010247857864181724, 0.01437548482458997, 0.014818864299679128, 0.01113479915601169, 0.01215469301347578, 0.014172441905835076, 0.011425649730446985, 0.012636802155627336, 0.011131634612882009, 0.011382766751669372, 0.01228256091618203, 0.014353016377156061, 0.01116327213106144, 0.01045760041821685, 0.011009107663082291, 0.009056449462343748, 0.011894390518895943, 0.011830284977961113, 0.012229955541159925, 0.011087618544992968, 0.011864072174947116, 0.010072108268487917, 0.013037325446123536, 0.011505046997272603, 0.012032539974555423, 0.011134032582919614, 0.011358848344263045, 0.012996508395188027, 0.013618344269558567, 0.010540078919545701, 0.009135655843306263, 0.007960391686744327, 0.007722669577815258, 0.00950024168673787, 0.008608164880176601, 0.008834508001433466, 0.007556012318980902, 0.006634163479738271, 0.006563971536250232, 0.010419242046496727, 0.007600078864174427, 0.00815801934796636, 0.0073283213122991705, 0.010201716629884144, 0.00966261447652261, 0.010150615611086013, 0.00829260327505703, 0.007805710305029932, 0.009172669722787602, 0.011427786508501288, 0.005874596298760356, 0.008271448307275314, 0.009522673217672957, 0.010033252732929595, 0.011927161570841976, 0.009427395841639161, 0.010318365726892096, 0.007019380056752412, 0.010646182909485186, 0.009510607415934796, 0.008816110209377618, 0.010152377320715418, 0.011252008991725014, 0.00895112987903601, 0.011246809354756644, 0.008445989184872714, 0.011796822279823458, 0.010318566131030578, 0.008460169443724087, 0.0068440367286389334, 0.009104249903173194, 0.009847767365635212, 0.010536541048145224, 0.010945911672125412, 0.008816656710640101, 0.010353515801119631, 0.008540385972768072, 0.010076101492770885, 0.008948358212379907, 0.010318249172067442, 0.011012711542766422, 0.015821188731744918, 0.01267934800856507, 0.011106486795689438, 0.014729954659306363, 0.009301442347142367, 0.009258462373550366, 0.007788539029445722, 0.011480124123034837, 0.012900151130400928, 0.010122104164996504, 0.013097049370530234, 0.010842833603685592, 0.010807948225444104, 0.012064598013908665, 0.009813486627600482, 0.013257674048005196, 0.00819639436043819, 0.009968228548327263, 0.013022889493449735, 0.01305612455118228, 0.011883386563627822, 0.01108472533777779, 0.013705220510795561, 0.011329811887085796, 0.0077444304246128606, 0.013328586401856196, 0.011160373146591759, 0.011162695475399883, 0.00974614224813572, 0.010645544108508345, 0.014053813286447949, 0.012613135646721223, 0.012653494891057729, 0.015165822290856041, 0.012631135426670747, 0.010769818599300103, 0.01473384505414604, 0.013586327916336379, 0.011137039904392968, 0.0097740771346404, 0.013019597323460402, 0.012140662815228598, 0.01199038515963005, 0.009590151917372667, 0.013382012377521296, 0.011585717266068116, 0.012494458486622537, 0.010820746715960382, 0.012232843386713236, 0.011405793871428925, 0.013608444527324138, 0.012855272317012265, 0.013398223622741802, 0.01150026844839538, 0.013812738962305473, 0.010360469603120304, 0.012239563255818152, 0.015126115215203031, 0.012532659627793024, 0.0106736686848742, 0.009640395034665803, 0.011329013354793725, 0.009719397563643657, 0.011175059142023148, 0.011344449851385734, 0.007642626507419733, 0.009478534587989034, 0.01077266938160886, 0.011647475818084356, 0.01177962960377543, 0.010814383316604373, 0.01347868272711432, 0.013256344524446231, 0.013539189682923516, 0.015227691871144177, 0.017140080345972687, 0.010443271879989509, 0.01644708642274053, 0.013723720119286761, 0.012799689394484228, 0.0153318174395476, 0.011812188639297864, 0.012149031086200428, 0.011657246308673952, 0.011839922789965644, 0.011716899632529015, 0.012363341877750761, 0.01067664562822472, 0.01167031962871842, 0.014624928872067518, 0.01330249025023181, 0.011245059354214151, 0.013599911105318746, 0.013172448990463726, 0.01147549984451462, 0.011746023333384129, 0.015118443885324797, 0.014023048428369624, 0.011592872799678956, 0.010988217659223441, 0.013054495146240927, 0.010413475808119474, 0.011099122638897927, 0.010227920757106592, 0.013231280771940574, 0.009763240426171885, 0.012761312734575897, 0.011759971455294149, 0.013508478228394573, 0.01276165850899463, 0.009822784935940201, 0.009550419675658901, 0.010138652274115117, 0.011727966104515366, 0.01144438319195877, 0.009318371358684924, 0.012577672252814073, 0.013363286162336872, 0.009121498301653869, 0.013113390052205036, 0.009595483736596662, 0.008013532585317845, 0.008799735031414676, 0.011354020457635143, 0.008363403614732933, 0.00850499188502073, 0.011015875395813422, 0.008366644152810142, 0.010447809363135411, 0.01320905126565123, 0.012183157236215918, 0.01054428919674374, 0.01164836718545074, 0.011700430967449422, 0.011292428903228287, 0.008205954537516059, 0.009467789229953135, 0.010226017228103948, 0.01198539829328482, 0.013216056775321623, 0.013877358310432356, 0.012075667103744886, 0.01288965977935892, 0.009746676659590144, 0.012783052198073738, 0.010558001157252936, 0.01042785317046628, 0.014270357299326198, 0.009756498686381728, 0.011149424939500224], "moving_avg_accuracy_train": [0.05345333264119599, 0.1093027076988741, 0.16579502930047985, 0.22163828817137315, 0.27343385612772236, 0.3219374194871262, 0.36779501177729323, 0.4097502583443498, 0.4487767537700662, 0.48478887859608655, 0.5177950650835617, 0.5482490424484059, 0.5760527531791098, 0.6017621198820091, 0.6255188232050393, 0.6472416891195851, 0.6670667080998377, 0.6854135301320006, 0.702093333016964, 0.7178885505181468, 0.7321648803823528, 0.74540155267196, 0.7573377010742454, 0.7685757797232807, 0.7790876509538411, 0.7885970550398893, 0.7975763706518565, 0.8057276173133688, 0.8132681000622368, 0.8201709722207879, 0.8266997053039418, 0.8330498233382855, 0.8385951937060996, 0.8438045549764087, 0.8486232605506578, 0.8530136821365574, 0.8574230077328868, 0.8612494585457461, 0.8649654508833088, 0.8687514059680123, 0.8721053952680825, 0.8748892537548402, 0.8775877137441125, 0.8804044112927356, 0.8829858339162305, 0.8854114208249951, 0.8876944664905114, 0.8901561446799615, 0.8924297116730673, 0.8944107457025583, 0.8962471547517192, 0.8981278956257537, 0.8999111350694998, 0.9018485468486332, 0.9035433532760346, 0.9050920747440662, 0.906495152562895, 0.9076998659772404, 0.9090303575310482, 0.9104113785389715, 0.9116055774675587, 0.9127060052378294, 0.9137241838703312, 0.9146825054646103, 0.9157586922970252, 0.9166158695962541, 0.9176592273809994, 0.9186446081681855, 0.9198709947004811, 0.9210700736807375, 0.9219491377700741, 0.9226613485374097, 0.9236884210768489, 0.9244730971896788, 0.9251513318078741, 0.9256432685214204, 0.9264394341826597, 0.9273372727872804, 0.9279756277171626, 0.9289430252052285, 0.9294533209278304, 0.9301333680686207, 0.9309687329275024, 0.9317112607052579, 0.9324631329159244, 0.9329539141472187, 0.9336349994363082, 0.9341109366120018, 0.9343461124748419, 0.9347553363025699, 0.9351981506558862, 0.9357456012441366, 0.9362034295414191, 0.9367363827470686, 0.9371440331166954, 0.937626995645742, 0.9379661866254185, 0.938464554004774, 0.9390501963283183, 0.9393611437266788, 0.9398385619363752, 0.9403076937572264, 0.9408996482590878, 0.94136748338819, 0.9418605785686585, 0.9423181348798435, 0.9428928401718517, 0.9434496385132398, 0.9438529565752141, 0.9445134897809725, 0.9449476064959353, 0.9451568778346217, 0.9455988074549524, 0.9461220300513268, 0.9464464460130638, 0.946587285706008, 0.9467651947034674, 0.946997392414276, 0.9474341267908809, 0.9476854978477194, 0.9480209777441029, 0.9481694498294194, 0.9482868347133564, 0.9483598208791101, 0.9486393860699458, 0.9488142648309836, 0.9491786300087841, 0.9493184018593269, 0.9494485944807032, 0.9498727595804365, 0.9501149631928062, 0.9503307294415857, 0.9506201420202215, 0.9507155638243363, 0.9509153757397063, 0.9511719363742536, 0.951390998908386, 0.9516906780296367, 0.951830180905429, 0.9520883030246038, 0.9524787230509086, 0.9527091933364878, 0.9526469353804231, 0.9529675773271076, 0.9531049843576859, 0.9532819488637316, 0.9535273555715814, 0.9536922738419426, 0.9539174301959819, 0.9539552016420536, 0.9542192414803861, 0.9542966223111219, 0.9544474650230237, 0.954678662711382, 0.9548751509356757, 0.9551379847946736, 0.9552745538689622, 0.9553462046155562, 0.9556874550934616, 0.9559642454425965, 0.956004201510417, 0.9561239394262357, 0.9561477819004173, 0.9564645340259902, 0.956703144011634, 0.9569760938165891, 0.957070686066067, 0.9571302064048738, 0.9572882982597721, 0.9574842395958935, 0.9575837126924134, 0.9574385065959756, 0.9576006817127254, 0.9578792809463994, 0.9580066071257074, 0.9581097912359495, 0.9582397872184822, 0.9583870105372856, 0.9586611293086771, 0.9588103241482043, 0.9590840723835315, 0.9591933341132016, 0.959128909253238, 0.9593428250947101, 0.9593285553032623, 0.9592506083242927, 0.9593688291456102, 0.9593054199240632, 0.9593670063115941, 0.9595245243150784, 0.9595153721385078, 0.9596256096224237, 0.9596598633865564, 0.9599184842599716, 0.9600814525329409, 0.9600653275131278, 0.9602927025691239, 0.960376468430244, 0.9604169804731093, 0.9606695359556987, 0.9605040299364946, 0.9607060638429928, 0.96085065592907, 0.9610251468780143, 0.9610843882867891, 0.9613864604284866, 0.96141200377748, 0.9612582814820503, 0.9613546993482879, 0.9614252354350538, 0.961725955189352, 0.961789628675354, 0.9620118040853195, 0.9619887639614867, 0.9622189997261907, 0.962223887919177, 0.9622725732667019, 0.9622839100937786, 0.962328738128559, 0.962336711520622, 0.9624810353044218, 0.9625202098574513, 0.962715902223035, 0.9630058855460896, 0.9629671065845038, 0.9632809778405053, 0.9630587965327837, 0.9629658622987098, 0.962970613191624, 0.9630398850154572, 0.9628697868735921, 0.9630049809494757, 0.9630524310999601, 0.9631461453139305, 0.9633280722588664, 0.9634964568069276, 0.9635503106013641, 0.9636825564711372, 0.9637969635051328, 0.9637859254464246, 0.9640548648554551, 0.963999363373601, 0.9642842334685038, 0.9642780189337151, 0.964277112198843, 0.9643481955064597, 0.9644983091357233, 0.9643613689913463, 0.9643682590971027, 0.9644070843732543, 0.9644769404027523, 0.964383953761425, 0.9646234614687543, 0.9646971482791509, 0.964707698885898, 0.9646777029510273, 0.964634430567977, 0.9646257844553932, 0.9647991843171166, 0.9648901400260012, 0.9651138342413781, 0.9650524172197412, 0.965180900753858, 0.9653197513738394, 0.9655586131746707, 0.9655318093680472, 0.9655844158528003, 0.9655946674545819, 0.9654781556163774, 0.9655081896417644, 0.9655051375253639], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 842471575, "moving_var_accuracy_train": [0.025715328934053146, 0.05121617028964661, 0.07481699486013522, 0.09540152142601616, 0.11000639702270164, 0.1201791182474688, 0.1270874753585826, 0.13022091225324697, 0.13090642713484343, 0.1294876426317229, 0.1263435534865645, 0.12205620077395408, 0.1168079976701286, 0.11107594172949306, 0.10504777613155002, 0.09878994465026707, 0.09244823258334676, 0.08623286223313077, 0.08011351842834882, 0.07434756664870101, 0.06874713233335548, 0.06344930453974201, 0.05838661883390023, 0.053684606656007355, 0.04931064092131758, 0.04519343572383157, 0.04139974513118226, 0.03785775601729539, 0.034583710336339626, 0.03155418609904137, 0.028782386690176832, 0.026267064012610027, 0.023917117803995105, 0.021769643027196972, 0.01980165803517897, 0.017994974446978465, 0.01637045637221064, 0.014865186267398663, 0.013502945032134221, 0.012281651632051326, 0.01115472966687107, 0.010109005512852596, 0.009163640138390671, 0.008318680190275377, 0.007546785856097665, 0.006845058517155628, 0.006207463343037562, 0.005641255744309537, 0.0051236521317278415, 0.004646607380989069, 0.004212298226652723, 0.003822903080104825, 0.0034692322583179318, 0.003156091112103464, 0.002866333320330366, 0.002601286831967203, 0.0023588757950616895, 0.002136050225251855, 0.001938377072699457, 0.001761704336648439, 0.0015983689027129436, 0.001449430483939896, 0.0013138176250950529, 0.001190701285088104, 0.0010820547594636632, 0.000980462059818116, 0.0008922132130392004, 0.0008117306693970806, 0.000744093817796735, 0.0006826245496250969, 0.0006213168777210401, 0.0005637503875429139, 0.0005168692508000529, 0.00047072377513846257, 0.00042779141740048273, 0.000387190291231647, 0.0003541761799497115, 0.00032601358939426543, 0.00029707970360338243, 0.00027579445434229094, 0.00025055862442861424, 0.00022966493900902549, 0.0002129789551352137, 0.00019664318712833882, 0.00018206667480605808, 0.00016602780327836832, 0.0001535999174896585, 0.0001402785714975579, 0.00012674848352596516, 0.00011558081244399245, 0.00010578749216311944, 9.790606226598917e-05, 9.000191678752383e-05, 8.355807718348038e-05, 7.66978788798445e-05, 7.112736623202775e-05, 6.50500842950698e-05, 6.0780406268813964e-05, 5.778915802207086e-05, 5.288043678078816e-05, 4.964374642525741e-05, 4.6660133770748375e-05, 4.514781158413866e-05, 4.260285779792424e-05, 4.053085773114366e-05, 3.8361991959177194e-05, 3.74983683172202e-05, 3.653875102225101e-05, 3.4348865052058194e-05, 3.4840715590037657e-05, 3.3052759930925765e-05, 3.0141634376593107e-05, 2.888518704286493e-05, 2.8460525306789975e-05, 2.656168422217879e-05, 2.4084038171938655e-05, 2.1960498857137785e-05, 2.024969096356709e-05, 1.994135410858652e-05, 1.8515905371672606e-05, 1.767723568240253e-05, 1.6107907755226493e-05, 1.4621129878495948e-05, 1.3206959714169189e-05, 1.2589674006095608e-05, 1.1605949835045453e-05, 1.1640212696683202e-05, 1.0652016958852228e-05, 9.739366330914453e-06, 1.038467398430892e-05, 9.874169894482853e-06, 9.3057485720462e-06, 9.129010480895284e-06, 8.298057319110471e-06, 7.827574800913862e-06, 7.637227553616187e-06, 7.305400342999183e-06, 7.383128490121809e-06, 6.819965112298598e-06, 6.737611856733909e-06, 7.435700843519433e-06, 7.170179731981811e-06, 6.488046236623938e-06, 6.764542934724371e-06, 6.2580148697230075e-06, 5.914061310350819e-06, 5.8646752496348565e-06, 5.522990047761864e-06, 5.426949496864597e-06, 4.897094686423341e-06, 5.034838543820768e-06, 4.585244826127028e-06, 4.331502057119457e-06, 4.379423191327928e-06, 4.288949472769973e-06, 4.481789262414802e-06, 4.201470344641829e-06, 3.8275277755649446e-06, 4.492841996044677e-06, 4.733073872807807e-06, 4.274134871728083e-06, 3.97575590091689e-06, 3.5832964830010708e-06, 4.127954016195477e-06, 4.227571141816683e-06, 4.475328391860223e-06, 4.108324795626057e-06, 3.729376352648473e-06, 3.5813760286504887e-06, 3.568775490594632e-06, 3.3009520139165203e-06, 3.1606201065089628e-06, 3.081265012293363e-06, 3.471696308097351e-06, 3.2704342807221904e-06, 3.039213498108085e-06, 2.887382747569229e-06, 2.7937168232074597e-06, 3.190615048348901e-06, 3.071885444788116e-06, 3.439139767412209e-06, 3.202668920805524e-06, 2.919757091956905e-06, 3.0396212678554828e-06, 2.737491783601595e-06, 2.5184241890158817e-06, 2.3923672334511617e-06, 2.189317074500794e-06, 2.0045213152127043e-06, 2.027376476486762e-06, 1.8253926898618994e-06, 1.7522241466167245e-06, 1.5875616151703638e-06, 2.0307682591478804e-06, 2.066719355184294e-06, 1.8623875660416198e-06, 2.1414435542409196e-06, 1.9904496742195514e-06, 1.8061757373516202e-06, 2.199616609690143e-06, 2.2261851302560797e-06, 2.3709259116047406e-06, 2.3219951626497653e-06, 2.363819467755931e-06, 2.159023421602935e-06, 2.7643492885506765e-06, 2.4937865237957727e-06, 2.4570827684260723e-06, 2.2950421359517246e-06, 2.1103159781827635e-06, 2.7131757159912943e-06, 2.478346959769044e-06, 2.6747694789322638e-06, 2.4120701567951123e-06, 2.64793970725531e-06, 2.3833607864058226e-06, 2.1663570753378246e-06, 1.9508780806375197e-06, 1.773876246894303e-06, 1.5970607970337692e-06, 1.6248189084628748e-06, 1.4761488280621977e-06, 1.6731934627859243e-06, 2.2626870653552007e-06, 2.049952629574661e-06, 2.731593854712554e-06, 2.902715270749336e-06, 2.6901746904404584e-06, 2.42136036024775e-06, 2.2224115944175246e-06, 2.260570835769177e-06, 2.199010695578658e-06, 1.999373277049661e-06, 1.8784771344454974e-06, 1.988506140644166e-06, 2.044835730812057e-06, 1.866454238307663e-06, 1.8372095451254161e-06, 1.771289315461792e-06, 1.59525693257602e-06, 2.0866868908853743e-06, 1.9057419321888626e-06, 2.445526477698946e-06, 2.201321413912815e-06, 1.9811966720346872e-06, 1.8285525344266826e-06, 1.8485041962001928e-06, 1.8324272048582727e-06, 1.6496117463884647e-06, 1.4982171903639063e-06, 1.3923142550427107e-06, 1.330901468726404e-06, 1.7140867986848081e-06, 1.5915458330541833e-06, 1.4333930874733622e-06, 1.2981515837049412e-06, 1.185188917548123e-06, 1.0673428231586429e-06, 1.2312161492543771e-06, 1.1825510031370552e-06, 1.514647820761509e-06, 1.3971314936060744e-06, 1.4059905110974788e-06, 1.4389069120109373e-06, 1.8085108598770427e-06, 1.634125770334971e-06, 1.4956201734441237e-06, 1.3470040141515119e-06, 1.3344786887126885e-06, 1.2091492039699375e-06, 1.0883181223036445e-06], "duration": 147956.870033, "accuracy_train": [0.53453332641196, 0.6119470832179771, 0.6742259237149317, 0.724227618009413, 0.7395939677348652, 0.7584694897217608, 0.7805133423887967, 0.7873474774478589, 0.8000152126015135, 0.8088980020302695, 0.814850743470838, 0.8223348387320044, 0.8262861497554448, 0.8331464202081026, 0.8393291531123109, 0.8427474823504982, 0.8454918789221114, 0.8505349284214655, 0.8522115589816353, 0.860045508028793, 0.8606518491602067, 0.8645316032784238, 0.8647630366948136, 0.8697184875645996, 0.8736944920288853, 0.8741816918143227, 0.8783902111595607, 0.8790888372669805, 0.8811324448020488, 0.8822968216477483, 0.8854583030523256, 0.8902008856473791, 0.8885035270164268, 0.8906888064091916, 0.8919916107189, 0.892527476409653, 0.8971069380998523, 0.8956875158614802, 0.8984093819213732, 0.9028250017303433, 0.9022912989687154, 0.8999439801356589, 0.9018738536475637, 0.9057546892303433, 0.9062186375276854, 0.9072417030038759, 0.9082418774801587, 0.9123112483850129, 0.9128918146110188, 0.9122400519679772, 0.9127748361941677, 0.9150545634920635, 0.9159602900632153, 0.9192852528608343, 0.9187966111226468, 0.9190305679563492, 0.9191228529323551, 0.9185422867063492, 0.9210047815153194, 0.9228405676102805, 0.9223533678248431, 0.9226098551702658, 0.9228877915628461, 0.923307399813123, 0.9254443737887597, 0.9243304652893135, 0.9270494474437062, 0.9275130352528608, 0.9309084734911407, 0.9318617845030455, 0.9298607145741048, 0.9290712454434293, 0.9329320739318014, 0.9315351822051495, 0.9312554433716316, 0.930070698943337, 0.9336049251338132, 0.9354178202288667, 0.9337208220861019, 0.937649602597822, 0.9340459824312477, 0.9362537923357327, 0.9384870166574382, 0.9383940107050572, 0.9392299828119232, 0.9373709452288667, 0.9397647670381136, 0.9383943711932448, 0.9364626952404023, 0.9384383507521227, 0.9391834798357327, 0.9406726565383905, 0.9403238842169619, 0.9415329615979143, 0.940812886443337, 0.9419736584071613, 0.9410189054425065, 0.9429498604189737, 0.9443209772402179, 0.9421596703119232, 0.9441353258236435, 0.9445298801448875, 0.9462272387758398, 0.9455779995501107, 0.9462984351928755, 0.9464361416805095, 0.9480651877999261, 0.9484608235857327, 0.9474828191329827, 0.9504582886327981, 0.9488546569306018, 0.9470403198827981, 0.9495761740379292, 0.950831033418697, 0.949366189668697, 0.9478548429425065, 0.9483663756806018, 0.9490871718115541, 0.9513647361803249, 0.9499478373592655, 0.9510402968115541, 0.9495056985972684, 0.9493432986687893, 0.9490166963708934, 0.9511554727874677, 0.9503881736803249, 0.9524579166089886, 0.9505763485142118, 0.9506203280730897, 0.9536902454780363, 0.9522947957041344, 0.9522726256806018, 0.9532248552279439, 0.9515743600613695, 0.9527136829780363, 0.9534809820851791, 0.9533625617155776, 0.9543877901208934, 0.95308570678756, 0.9544114020971761, 0.9559925032876523, 0.9547834259067, 0.9520866137758398, 0.9558533548472684, 0.9543416476328904, 0.9548746294181433, 0.9557360159422297, 0.9551765382751938, 0.9559438373823367, 0.9542951446567, 0.9565956000253784, 0.9549930497877446, 0.9558050494301403, 0.9567594419066077, 0.956643544954319, 0.9575034895256552, 0.95650367553756, 0.9559910613349022, 0.9587587093946106, 0.9584553585848099, 0.9563638061208011, 0.9572015806686047, 0.956362364168051, 0.9593153031561462, 0.958850633882429, 0.959432642061185, 0.9579220163113695, 0.9576658894541344, 0.9587111249538575, 0.9592477116209857, 0.9584789705610927, 0.9561316517280363, 0.9590602577634736, 0.9603866740494648, 0.9591525427394795, 0.9590384482281286, 0.9594097510612772, 0.9597120204065154, 0.9611281982511997, 0.9601530777039498, 0.9615478065014765, 0.9601766896802326, 0.9585490855135659, 0.9612680676679586, 0.9592001271802326, 0.9585490855135659, 0.9604328165374677, 0.9587347369301403, 0.9599212837993725, 0.9609421863464378, 0.9594330025493725, 0.960617746977667, 0.9599681472637505, 0.9622460721207088, 0.961548166989664, 0.9599202023348099, 0.9623390780730897, 0.9611303611803249, 0.9607815888588963, 0.9629425352990033, 0.9590144757636582, 0.9625243690014765, 0.9621519847037652, 0.9625955654185124, 0.9616175609657622, 0.9641051097037652, 0.9616418939184201, 0.959874780823182, 0.962222460144426, 0.9620600602159468, 0.9644324329780363, 0.9623626900493725, 0.9640113827750092, 0.9617814028469915, 0.9642911216085271, 0.9622678816560539, 0.962710741394426, 0.9623859415374677, 0.9627321904415835, 0.9624084720491879, 0.9637799493586194, 0.9628727808347176, 0.964477133513289, 0.9656157354535806, 0.9626180959302326, 0.9661058191445183, 0.961059164763289, 0.9621294541920451, 0.9630133712278516, 0.9636633314299556, 0.961338903596807, 0.964221727632429, 0.963479482454319, 0.963989573239664, 0.964965414763289, 0.9650119177394795, 0.964034994751292, 0.9648727692990956, 0.9648266268110927, 0.963686582918051, 0.9664753195367294, 0.963499850036914, 0.9668480643226283, 0.9642220881206165, 0.9642689515849945, 0.9649879452750092, 0.9658493317990956, 0.9631289076919527, 0.964430270048911, 0.9647565118586194, 0.9651056446682356, 0.9635470739894795, 0.9667790308347176, 0.9653603295727206, 0.9648026543466224, 0.9644077395371908, 0.9642449791205242, 0.9645479694421374, 0.9663597830726283, 0.9657087414059615, 0.9671270821797711, 0.9644996640250092, 0.9663372525609081, 0.9665694069536729, 0.9677083693821521, 0.9652905751084349, 0.9660578742155776, 0.9656869318706165, 0.964429549072536, 0.9657784958702473, 0.9654776684777593], "end": "2016-01-31 03:53:06.606000", "learning_rate_per_epoch": [0.0003594878362491727, 0.00025419628946110606, 0.00020755040168296546, 0.00017974391812458634, 0.00016076784231700003, 0.00014676029968541116, 0.00013587363355327398, 0.00012709814473055303, 0.00011982928117504343, 0.00011368003470124677, 0.00010838965681614354, 0.00010377520084148273, 9.970398241421208e-05, 9.607716492610052e-05, 9.281936218030751e-05, 8.987195906229317e-05, 8.718860772205517e-05, 8.473209163639694e-05, 8.247216464951634e-05, 8.038392115850002e-05, 7.844667561585084e-05, 7.664306031074375e-05, 7.495839236071333e-05, 7.338014984270558e-05, 7.189756433945149e-05, 7.05013662809506e-05, 6.918346480233595e-05, 6.793681677663699e-05, 6.675521581200883e-05, 6.563319766428322e-05, 6.456592382164672e-05, 6.354907236527652e-05, 6.257880158955231e-05, 6.165165541460738e-05, 6.076453428249806e-05, 5.991464058752172e-05, 5.909943502047099e-05, 5.831662565469742e-05, 5.7564124290365726e-05, 5.6840017350623384e-05, 5.6142565881600603e-05, 5.547017644857988e-05, 5.482137930812314e-05, 5.419482840807177e-05, 5.358928319765255e-05, 5.3003590437583625e-05, 5.243669147603214e-05, 5.1887600420741364e-05, 5.1355404139030725e-05, 5.0839258619816974e-05, 5.033836714574136e-05, 4.985199120710604e-05, 4.937945050187409e-05, 4.892009746981785e-05, 4.8473328206455335e-05, 4.803858246305026e-05, 4.761532545671798e-05, 4.720306606031954e-05, 4.680133133661002e-05, 4.6409681090153754e-05, 4.602770059136674e-05, 4.565500057651661e-05, 4.5291209971765056e-05, 4.4935979531146586e-05, 4.458897819858976e-05, 4.424989310791716e-05, 4.391842958284542e-05, 4.3594303861027583e-05, 4.3277250370010734e-05, 4.2967014451278374e-05, 4.2663355998229235e-05, 4.236604581819847e-05, 4.2074869270436466e-05, 4.17896117141936e-05, 4.151008033659309e-05, 4.123608232475817e-05, 4.096743941772729e-05, 4.070398063049652e-05, 4.044554225401953e-05, 4.019196057925001e-05, 3.994309372501448e-05, 3.969878889620304e-05, 3.945891512557864e-05, 3.922333780792542e-05, 3.899192961398512e-05, 3.876457049045712e-05, 3.854114038404077e-05, 3.8321530155371875e-05, 3.810563430306502e-05, 3.789334368775599e-05, 3.76845637219958e-05, 3.7479196180356666e-05, 3.727715011336841e-05, 3.707833820953965e-05, 3.688267315737903e-05, 3.669007492135279e-05, 3.650045982794836e-05, 3.631375511758961e-05, 3.6129888030700386e-05, 3.5948782169725746e-05, 3.577037568902597e-05, 3.559459946700372e-05, 3.542138802004047e-05, 3.52506831404753e-05, 3.50824193446897e-05, 3.491654570098035e-05, 3.475300036370754e-05, 3.4591732401167974e-05, 3.4432690881658345e-05, 3.427582123549655e-05, 3.41210761689581e-05, 3.3968408388318494e-05, 3.381777059985325e-05, 3.366911914781667e-05, 3.352241401444189e-05, 3.3377607906004414e-05, 3.323466080473736e-05, 3.309353633085266e-05, 3.295419446658343e-05, 3.281659883214161e-05, 3.268071304773912e-05, 3.254650073358789e-05, 3.2413925509899855e-05, 3.228296191082336e-05, 3.215356991859153e-05, 3.2025720429373905e-05, 3.189938797731884e-05, 3.177453618263826e-05, 3.1651139579480514e-05, 3.152916906401515e-05, 3.1408599170390517e-05, 3.1289400794776157e-05, 3.117154847132042e-05, 3.1055020372150466e-05, 3.0939787393435836e-05, 3.082582770730369e-05, 3.071311948588118e-05, 3.060163726331666e-05, 3.049135921173729e-05, 3.038226714124903e-05, 3.0274337404989637e-05, 3.0167548175086267e-05, 3.006188308063429e-05, 2.995732029376086e-05, 2.9853839805582538e-05, 2.9751425245194696e-05, 2.9650056603713892e-05, 2.9549717510235496e-05, 2.9450391593854874e-05, 2.935205884568859e-05, 2.925470471382141e-05, 2.915831282734871e-05, 2.9062868634355254e-05, 2.8968355763936415e-05, 2.887475784518756e-05, 2.8782062145182863e-05, 2.8690252293017693e-05, 2.859931737475563e-05, 2.8509239200502634e-05, 2.8420008675311692e-05, 2.833160942827817e-05, 2.8244032364455052e-05, 2.8157261112937704e-05, 2.8071282940800302e-05, 2.798609057208523e-05, 2.790166763588786e-05, 2.781800321827177e-05, 2.773508822428994e-05, 2.7652909921016544e-05, 2.7571457394515164e-05, 2.749072154983878e-05, 2.741068965406157e-05, 2.7331354431225918e-05, 2.7252703148406e-05, 2.7174726710654795e-05, 2.7097414204035886e-05, 2.702076017158106e-05, 2.6944751880364493e-05, 2.686938205442857e-05, 2.6794641598826274e-05, 2.6720519599621184e-05, 2.664701059984509e-05, 2.657410550455097e-05, 2.6501795218791813e-05, 2.6430070647620596e-05, 2.635892633406911e-05, 2.628835318319034e-05, 2.621834573801607e-05, 2.614889308460988e-05, 2.607998794701416e-05, 2.60116266872501e-05, 2.5943800210370682e-05, 2.5876501240418293e-05, 2.5809722501435317e-05, 2.5743458536453545e-05, 2.5677702069515362e-05, 2.561244764365256e-05, 2.554768798290752e-05, 2.5483417630312033e-05, 2.5419629309908487e-05, 2.535631756472867e-05, 2.5293475118814968e-05, 2.5231100153177977e-05, 2.516918357287068e-05, 2.5107719920924865e-05, 2.5046703740372322e-05, 2.4986131393234245e-05, 2.492599560355302e-05, 2.4866292733349837e-05, 2.480701732565649e-05, 2.4748163923504762e-05, 2.4689725250937045e-05, 2.4631701307953335e-05, 2.4574082999606617e-05, 2.4516866687918082e-05, 2.4460048734908924e-05, 2.440362368361093e-05, 2.4347587896045297e-05, 2.4291935915243812e-05, 2.4236664103227668e-05, 2.4181768822018057e-05, 2.4127242795657367e-05, 2.4073086024145596e-05, 2.401929123152513e-05, 2.3965854779817164e-05, 2.3912774850032292e-05, 2.3860045985202305e-05, 2.380766272835899e-05, 2.375562507950235e-05, 2.370392576267477e-05, 2.3652562958886847e-05, 2.360153303015977e-05, 2.3550830519525334e-05, 2.3500455426983535e-05, 2.345040047657676e-05, 2.340066566830501e-05, 2.335124372621067e-05, 2.3302134650293738e-05, 2.325333480257541e-05, 2.3204840545076877e-05, 2.315664642082993e-05, 2.3108752429834567e-05, 2.3061154934111983e-05, 2.301385029568337e-05, 2.296683487656992e-05, 2.292010685778223e-05, 2.2873662601341493e-05, 2.2827500288258307e-05, 2.2781616280553862e-05, 2.2736006940249354e-05, 2.2690670448355377e-05, 2.2645604985882528e-05, 2.2600806914852e-05, 2.2556272597284988e-05, 2.251200203318149e-05, 2.2467989765573293e-05, 2.24242357944604e-05, 2.2380734662874602e-05, 2.2337486370815895e-05, 2.229448909929488e-05, 2.225173739134334e-05, 2.2209233065950684e-05, 2.2166968847159296e-05, 2.212494655395858e-05, 2.2083162548369728e-05, 2.2041613192413934e-05, 2.2000298486091197e-05, 2.195921479142271e-05, 2.191836028941907e-05, 2.1877733161090873e-05, 2.1837331587448716e-05], "accuracy_valid": [0.5296233763177711, 0.5973047463290663, 0.6601930181664157, 0.7005688770707832, 0.7142422227974398, 0.7324321700865963, 0.7455039886106928, 0.7467041015625, 0.7594508894954819, 0.7644866575677711, 0.7722682723079819, 0.7722888624811747, 0.7714034850338856, 0.7771819700677711, 0.7818412321159638, 0.7824206984186747, 0.7869681852409638, 0.7873755765248494, 0.7853812711784638, 0.7953101468373494, 0.7930114010730422, 0.7937232327748494, 0.7984133800828314, 0.7966529202748494, 0.7968970608998494, 0.7936114575489458, 0.8000914791980422, 0.7960425687123494, 0.7990531461784638, 0.8004473950489458, 0.8036521084337349, 0.801037156438253, 0.8028888012989458, 0.8032653073230422, 0.8019225338855422, 0.8041403896837349, 0.8036726986069277, 0.8030108716114458, 0.8034079678087349, 0.8046286709337349, 0.8066935711596386, 0.8054728680346386, 0.8049639966114458, 0.8033873776355422, 0.8058287838855422, 0.8062258800828314, 0.8075583584337349, 0.8097968044051205, 0.8081995952560241, 0.8044860104480422, 0.8069583019578314, 0.8060729245105422, 0.8060832195971386, 0.8063376553087349, 0.8096438488328314, 0.8053507977221386, 0.8091349774096386, 0.8090026120105422, 0.8081084102033133, 0.8072936276355422, 0.8101733104292168, 0.8072230327560241, 0.8057170086596386, 0.8069480068712349, 0.8080672298569277, 0.8086672863328314, 0.8077216090926205, 0.8078333843185241, 0.8088805416980422, 0.8091761577560241, 0.8098173945783133, 0.8087084666792168, 0.8115969738328314, 0.8059611492846386, 0.8092982280685241, 0.8099291698042168, 0.8085452160203314, 0.8138354198042168, 0.8102644954819277, 0.8105189311935241, 0.8091452724962349, 0.8122382106551205, 0.8139780802899097, 0.815453219126506, 0.8149752329631024, 0.8130221079631024, 0.8124823512801205, 0.8175078242658133, 0.8087790615587349, 0.8099997646837349, 0.8106204113328314, 0.8137236445783133, 0.8127367869917168, 0.8107836619917168, 0.808373141001506, 0.8087187617658133, 0.8097453289721386, 0.8148119823042168, 0.815819430064006, 0.8097556240587349, 0.8122588008283133, 0.8112307628953314, 0.8116175640060241, 0.8146693218185241, 0.8153208537274097, 0.8109969173569277, 0.8144457713667168, 0.8165312617658133, 0.8139677852033133, 0.8165106715926205, 0.819847750376506, 0.8133677287274097, 0.8176195994917168, 0.815087008189006, 0.8138045345444277, 0.813744234751506, 0.8151884883283133, 0.817650484751506, 0.8168871776167168, 0.8190138483621988, 0.8173048639871988, 0.8155149896460843, 0.8158297251506024, 0.8175592996987951, 0.8172136789344879, 0.8167856974774097, 0.815087008189006, 0.8162974162274097, 0.8167651073042168, 0.8208757883094879, 0.8160326854292168, 0.8208654932228916, 0.8237642954631024, 0.818382906626506, 0.8186476374246988, 0.8224215220256024, 0.8190241434487951, 0.8206007624246988, 0.8177622599774097, 0.8216685099774097, 0.822045016001506, 0.8198683405496988, 0.8193697642131024, 0.8209669733621988, 0.8190035532756024, 0.820336031626506, 0.8199801157756024, 0.8209360881024097, 0.822167086314006, 0.818260836314006, 0.8222788615399097, 0.8215773249246988, 0.8212008189006024, 0.8202242564006024, 0.8212317041603916, 0.821922945689006, 0.8208140177899097, 0.8199595256024097, 0.8213434793862951, 0.8220656061746988, 0.8235304499246988, 0.8244055322853916, 0.8245276025978916, 0.8217802852033133, 0.8224009318524097, 0.8241613916603916, 0.8218317606362951, 0.821434664439006, 0.8237848856362951, 0.8233774943524097, 0.8233774943524097, 0.818138766001506, 0.8226244823042168, 0.8251276590737951, 0.8231539439006024, 0.8212111139871988, 0.8227980280496988, 0.8216685099774097, 0.8244967173381024, 0.8259718561746988, 0.823631930064006, 0.8246187876506024, 0.8200815959149097, 0.8232554240399097, 0.8251173639871988, 0.8205595820783133, 0.8227568477033133, 0.821190523814006, 0.8265822077371988, 0.8238863657756024, 0.8222685664533133, 0.8222994517131024, 0.8221773814006024, 0.8244555369917168, 0.8255644648908133, 0.8253923898719879, 0.8263998376317772, 0.8213022990399097, 0.8243040521460843, 0.8250158838478916, 0.8236834054969879, 0.8256365304969879, 0.8232554240399097, 0.8254938700112951, 0.8254835749246988, 0.8242525767131024, 0.8253717996987951, 0.8178740352033133, 0.8237642954631024, 0.824120211314006, 0.8242319865399097, 0.8225435923381024, 0.820946383189006, 0.8215361445783133, 0.8267042780496988, 0.8216685099774097, 0.8279146860881024, 0.8258703760353916, 0.8240084360881024, 0.8255041650978916, 0.8301428369728916, 0.8240084360881024, 0.8265410273908133, 0.8285250376506024, 0.8267145731362951, 0.8266027979103916, 0.8213228892131024, 0.8204889871987951, 0.8247202677899097, 0.8263483621987951, 0.8236422251506024, 0.8252291392131024, 0.8241099162274097, 0.8271822642131024, 0.8277926157756024, 0.8260527461408133, 0.825951266001506, 0.8255953501506024, 0.825340914439006, 0.8242525767131024, 0.8292677546121988, 0.8268160532756024, 0.8260527461408133, 0.824242281626506, 0.8275896554969879, 0.8254732798381024, 0.8223097467996988, 0.8199389354292168, 0.824852633189006, 0.8244761271649097, 0.8253717996987951, 0.8257174204631024, 0.8245070124246988, 0.8284338525978916, 0.8244158273719879, 0.8260424510542168, 0.8223906367658133, 0.8242525767131024, 0.824852633189006, 0.8271013742469879, 0.825218844126506, 0.8240290262612951, 0.8278235010353916, 0.8283117822853916, 0.8296236704631024, 0.8243746470256024, 0.8273043345256024, 0.8285662179969879, 0.8276102456701807, 0.8265719126506024, 0.8240996211408133], "accuracy_test": 0.798860012755102, "start": "2016-01-29 10:47:09.736000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0], "accuracy_train_last": 0.9654776684777593, "batch_size_eval": 1024, "accuracy_train_std": [0.018464622730965496, 0.021591073033328516, 0.021110113434218737, 0.02001969011859659, 0.020742533269931588, 0.020565068395040763, 0.017034390801062324, 0.01646140557531638, 0.018450773168346833, 0.016893504008196364, 0.01646003011969244, 0.016735157609278822, 0.017685033859551016, 0.015835343093036018, 0.01652643112804451, 0.016501292700707805, 0.014385703178528294, 0.016034203451294228, 0.01451567842189253, 0.01449822250747156, 0.014966325325564297, 0.015091847921424296, 0.014194887498598464, 0.013570982580840413, 0.013054531861379497, 0.014365016935618327, 0.014398419979565742, 0.014182295904097569, 0.013906501728675769, 0.014469840381319661, 0.014601702572167951, 0.01365768988510093, 0.012937710515955794, 0.012072066832151937, 0.012645990625219627, 0.012509856078414115, 0.014746412447013992, 0.01305947911193589, 0.013608411555916468, 0.012295753089761899, 0.012357596498616853, 0.011851538283741504, 0.011680650787321386, 0.013347534559196047, 0.01392856055420294, 0.012214692070489115, 0.013645313415449912, 0.011839615032931955, 0.012955807488610745, 0.013373860949470245, 0.011636387655530631, 0.01316055222655343, 0.011740713316140473, 0.01195376806698987, 0.012652707144887003, 0.012401377346289, 0.012155571599650833, 0.011628585548911854, 0.012967707512122676, 0.013118301588133013, 0.012213200465079274, 0.01247883955687463, 0.01139960593147106, 0.01291644343500029, 0.011666799915403418, 0.011525577469772171, 0.011229938148922675, 0.011822542563300814, 0.011114877300002591, 0.011273553717952316, 0.011454650103299015, 0.010582959640157732, 0.011404360306216527, 0.010963988128764906, 0.010104798127318284, 0.011129810281224223, 0.011607773112400086, 0.011214446603406395, 0.01108337189417628, 0.010304324969025365, 0.011206876621248363, 0.010226122956437904, 0.010615345243823824, 0.011498107065561603, 0.010502811415878362, 0.01090463280744742, 0.010842071567499901, 0.008956315060873991, 0.01067711414860013, 0.011422607957065357, 0.010368989089354136, 0.010295673816676584, 0.010250480872162309, 0.011501952701675559, 0.010095798243160984, 0.009936691408381914, 0.010026536271896343, 0.010447465120130867, 0.010427881935821766, 0.010393694696476913, 0.010231253908309389, 0.010301216899196643, 0.010405527483261082, 0.00983714654789816, 0.009955119767373533, 0.009622295499246154, 0.010274475456601661, 0.010328222725773595, 0.009997548897140081, 0.009162049129997943, 0.010834517190602144, 0.010873018244924704, 0.00913924095634911, 0.009393598584482955, 0.009639975163225232, 0.010546625547693936, 0.010227383693060184, 0.010091308491483571, 0.010071834373231305, 0.010011320350758413, 0.011052084857618787, 0.01057167698065976, 0.010740837833099839, 0.009859044469386317, 0.010106298207209756, 0.009083940664330131, 0.009004040779662994, 0.009314022421569318, 0.010379355280058487, 0.009668633906531127, 0.010080967072269041, 0.009247126312125504, 0.009983546843818084, 0.009166126617236465, 0.008558173708822881, 0.009895523340639312, 0.010160188407148725, 0.009211429260674156, 0.009159715740505775, 0.009786684339844151, 0.009675562655433345, 0.00940542687215061, 0.00937940568206646, 0.010139796694266658, 0.008772024995783816, 0.00950902600282372, 0.009520427213474507, 0.009077641666942724, 0.008653008298023254, 0.009078444628273055, 0.008451884227578534, 0.009112708813011646, 0.009618170822118839, 0.009155170317758431, 0.009071034412014971, 0.008963975649293604, 0.00845904960561431, 0.00815477668969087, 0.008050403454548077, 0.008868402433565525, 0.009226420998996383, 0.008818890835913883, 0.009081133355265648, 0.00851189072486042, 0.008551044843305164, 0.008472806516461914, 0.009351856103639797, 0.009559871763462164, 0.008811941235750232, 0.008462717071952876, 0.009055060948501586, 0.009018500053915112, 0.008575966576997723, 0.007891639521839649, 0.008962246203856739, 0.008896878739969626, 0.00837156678361841, 0.009284225470772848, 0.009501738859504656, 0.008861276271398691, 0.009005512400497066, 0.009522907439261817, 0.008638027933103453, 0.008815431369018002, 0.009121693053726305, 0.009023717968552503, 0.008338374194002653, 0.009490332430323265, 0.008021560144361069, 0.008343322397616378, 0.009208656110945058, 0.008427058047358472, 0.007862785199527846, 0.008474575887053514, 0.008436861967329132, 0.008978779724015609, 0.008297083379380883, 0.008456778559619564, 0.008410425801372483, 0.008697721488597572, 0.008681712889879184, 0.008944164289366674, 0.007875817559565571, 0.008058608576581588, 0.007486973137265415, 0.008157737808082882, 0.008071829414688389, 0.0074882841281404995, 0.008796185552108133, 0.007980450311507627, 0.008278408791783874, 0.008062538845005894, 0.008624185984696373, 0.0074157243846261515, 0.0076589776911013836, 0.008635697152917428, 0.008743413582837567, 0.008238134434436307, 0.008060181739407719, 0.008474632388029571, 0.007698619796404117, 0.00881583970534478, 0.008479970036332305, 0.007432430659468409, 0.00873454071432438, 0.008192613362143868, 0.008163631598087504, 0.008153345797025447, 0.00814480365787544, 0.007544101006905857, 0.008051722897763678, 0.007329651940332213, 0.008329086509833465, 0.008300085339998459, 0.008017890618038561, 0.0074808088745345665, 0.007867115686577017, 0.006631949509267527, 0.007982295611938672, 0.007809408965796896, 0.007907211150477383, 0.008322680005185863, 0.007637832522378062, 0.007092060628393531, 0.008897580648533528, 0.008246793443648589, 0.00803955425130953, 0.007974365046530658, 0.007283010656752531, 0.007295035584319358, 0.0072472441151551275, 0.007249897255564798, 0.007177664027642651, 0.007623873332340765, 0.007804896556305056, 0.008344670392403497, 0.007543765020382331, 0.007854855442915355, 0.00751299319731811, 0.007692590757196159, 0.006968291530422232, 0.007635910977955641, 0.007435157665205169, 0.007324021960372224, 0.0069113806169102555, 0.0072042305059588675, 0.007413733184852159, 0.00658522825430807, 0.007793503819148484, 0.007623611025169079, 0.006961710443935681], "accuracy_test_std": 0.0050061553981160705, "error_valid": [0.4703766236822289, 0.40269525367093373, 0.33980698183358427, 0.2994311229292168, 0.28575777720256024, 0.26756782991340367, 0.2544960113893072, 0.2532958984375, 0.2405491105045181, 0.23551334243222888, 0.2277317276920181, 0.22771113751882532, 0.22859651496611444, 0.22281802993222888, 0.2181587678840362, 0.21757930158132532, 0.2130318147590362, 0.21262442347515065, 0.2146187288215362, 0.20468985316265065, 0.20698859892695776, 0.20627676722515065, 0.20158661991716864, 0.20334707972515065, 0.20310293910015065, 0.2063885424510542, 0.19990852080195776, 0.20395743128765065, 0.2009468538215362, 0.1995526049510542, 0.1963478915662651, 0.19896284356174698, 0.1971111987010542, 0.19673469267695776, 0.19807746611445776, 0.1958596103162651, 0.1963273013930723, 0.1969891283885542, 0.1965920321912651, 0.1953713290662651, 0.19330642884036142, 0.19452713196536142, 0.1950360033885542, 0.19661262236445776, 0.19417121611445776, 0.19377411991716864, 0.1924416415662651, 0.19020319559487953, 0.19180040474397586, 0.19551398955195776, 0.19304169804216864, 0.19392707548945776, 0.19391678040286142, 0.1936623446912651, 0.19035615116716864, 0.19464920227786142, 0.19086502259036142, 0.19099738798945776, 0.19189158979668675, 0.19270637236445776, 0.1898266895707832, 0.19277696724397586, 0.19428299134036142, 0.1930519931287651, 0.1919327701430723, 0.19133271366716864, 0.19227839090737953, 0.19216661568147586, 0.19111945830195776, 0.19082384224397586, 0.19018260542168675, 0.1912915333207832, 0.18840302616716864, 0.19403885071536142, 0.19070177193147586, 0.1900708301957832, 0.19145478397966864, 0.1861645801957832, 0.1897355045180723, 0.18948106880647586, 0.1908547275037651, 0.18776178934487953, 0.1860219197100903, 0.18454678087349397, 0.18502476703689763, 0.18697789203689763, 0.18751764871987953, 0.18249217573418675, 0.1912209384412651, 0.1900002353162651, 0.18937958866716864, 0.18627635542168675, 0.1872632130082832, 0.1892163380082832, 0.19162685899849397, 0.19128123823418675, 0.19025467102786142, 0.1851880176957832, 0.18418056993599397, 0.1902443759412651, 0.18774119917168675, 0.18876923710466864, 0.18838243599397586, 0.18533067818147586, 0.1846791462725903, 0.1890030826430723, 0.1855542286332832, 0.18346873823418675, 0.18603221479668675, 0.18348932840737953, 0.18015224962349397, 0.1866322712725903, 0.1823804005082832, 0.18491299181099397, 0.1861954654555723, 0.18625576524849397, 0.18481151167168675, 0.18234951524849397, 0.1831128223832832, 0.18098615163780118, 0.18269513601280118, 0.18448501035391573, 0.18417027484939763, 0.18244070030120485, 0.18278632106551207, 0.1832143025225903, 0.18491299181099397, 0.1837025837725903, 0.1832348926957832, 0.17912421169051207, 0.1839673145707832, 0.1791345067771084, 0.17623570453689763, 0.18161709337349397, 0.18135236257530118, 0.17757847797439763, 0.18097585655120485, 0.17939923757530118, 0.1822377400225903, 0.1783314900225903, 0.17795498399849397, 0.18013165945030118, 0.18063023578689763, 0.17903302663780118, 0.18099644672439763, 0.17966396837349397, 0.18001988422439763, 0.1790639118975903, 0.17783291368599397, 0.18173916368599397, 0.1777211384600903, 0.17842267507530118, 0.17879918109939763, 0.17977574359939763, 0.1787682958396084, 0.17807705431099397, 0.1791859822100903, 0.1800404743975903, 0.17865652061370485, 0.17793439382530118, 0.17646955007530118, 0.1755944677146084, 0.1754723974021084, 0.17821971479668675, 0.1775990681475903, 0.1758386083396084, 0.17816823936370485, 0.17856533556099397, 0.17621511436370485, 0.1766225056475903, 0.1766225056475903, 0.18186123399849397, 0.1773755176957832, 0.17487234092620485, 0.17684605609939763, 0.17878888601280118, 0.17720197195030118, 0.1783314900225903, 0.17550328266189763, 0.17402814382530118, 0.17636806993599397, 0.17538121234939763, 0.1799184040850903, 0.1767445759600903, 0.17488263601280118, 0.17944041792168675, 0.17724315229668675, 0.17880947618599397, 0.17341779226280118, 0.17611363422439763, 0.17773143354668675, 0.17770054828689763, 0.17782261859939763, 0.1755444630082832, 0.17443553510918675, 0.17460761012801207, 0.17360016236822284, 0.1786977009600903, 0.17569594785391573, 0.1749841161521084, 0.17631659450301207, 0.17436346950301207, 0.1767445759600903, 0.17450612998870485, 0.17451642507530118, 0.17574742328689763, 0.17462820030120485, 0.18212596479668675, 0.17623570453689763, 0.17587978868599397, 0.1757680134600903, 0.17745640766189763, 0.17905361681099397, 0.17846385542168675, 0.17329572195030118, 0.1783314900225903, 0.17208531391189763, 0.1741296239646084, 0.17599156391189763, 0.1744958349021084, 0.1698571630271084, 0.17599156391189763, 0.17345897260918675, 0.17147496234939763, 0.17328542686370485, 0.1733972020896084, 0.17867711078689763, 0.17951101280120485, 0.1752797322100903, 0.17365163780120485, 0.17635777484939763, 0.17477086078689763, 0.1758900837725903, 0.17281773578689763, 0.17220738422439763, 0.17394725385918675, 0.17404873399849397, 0.17440464984939763, 0.17465908556099397, 0.17574742328689763, 0.17073224538780118, 0.17318394672439763, 0.17394725385918675, 0.17575771837349397, 0.17241034450301207, 0.17452672016189763, 0.17769025320030118, 0.1800610645707832, 0.17514736681099397, 0.1755238728350903, 0.17462820030120485, 0.17428257953689763, 0.17549298757530118, 0.1715661474021084, 0.17558417262801207, 0.1739575489457832, 0.17760936323418675, 0.17574742328689763, 0.17514736681099397, 0.17289862575301207, 0.17478115587349397, 0.17597097373870485, 0.1721764989646084, 0.1716882177146084, 0.17037632953689763, 0.17562535297439763, 0.17269566547439763, 0.17143378200301207, 0.1723897543298193, 0.17342808734939763, 0.17590037885918675], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.7259248354924194, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0003594878336890056, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "l2_decay": 2.084980160199338e-08, "optimization": "rmsprop", "nb_data_augmentation": 1, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.09172740863268841}, "accuracy_valid_max": 0.8301428369728916, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop', 'santa_sss'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8240996211408133, "loss_train": [1.5601959228515625, 1.2275676727294922, 1.0687265396118164, 0.9735192656517029, 0.9088031649589539, 0.8578304052352905, 0.8182899951934814, 0.7865796685218811, 0.758175790309906, 0.7339495420455933, 0.7098991274833679, 0.6933799386024475, 0.675298810005188, 0.6562260985374451, 0.6407911777496338, 0.6303320527076721, 0.6191872358322144, 0.6080718636512756, 0.5940125584602356, 0.584985613822937, 0.5730680823326111, 0.5650589466094971, 0.5577684044837952, 0.5518469214439392, 0.5409511923789978, 0.5331479907035828, 0.5258012413978577, 0.519855797290802, 0.5144542455673218, 0.5060920715332031, 0.5020620822906494, 0.49542272090911865, 0.48858290910720825, 0.4832177460193634, 0.47824791073799133, 0.4720347821712494, 0.46773406863212585, 0.4641578197479248, 0.45706331729888916, 0.4540902078151703, 0.4493986964225769, 0.44511866569519043, 0.44299596548080444, 0.43895575404167175, 0.4322318136692047, 0.43202194571495056, 0.4290640652179718, 0.42401620745658875, 0.4190264046192169, 0.4150814116001129, 0.411898136138916, 0.4088520109653473, 0.40436244010925293, 0.4015585780143738, 0.40035635232925415, 0.401620477437973, 0.3920985162258148, 0.3902055323123932, 0.39201629161834717, 0.3863813579082489, 0.3845193386077881, 0.3805038630962372, 0.37967565655708313, 0.3739876449108124, 0.37605127692222595, 0.3699267506599426, 0.3703429400920868, 0.3677147626876831, 0.3637465834617615, 0.3639976680278778, 0.3628081977367401, 0.357543021440506, 0.35714179277420044, 0.3558381199836731, 0.35046836733818054, 0.35158780217170715, 0.34920942783355713, 0.3480747938156128, 0.34509915113449097, 0.340487539768219, 0.3397819697856903, 0.34216073155403137, 0.3384951949119568, 0.33437275886535645, 0.33647608757019043, 0.3293144702911377, 0.33065515756607056, 0.32853585481643677, 0.32692068815231323, 0.3238030672073364, 0.32324424386024475, 0.3231930136680603, 0.3213624656200409, 0.3200662434101105, 0.3171893060207367, 0.319748193025589, 0.31712186336517334, 0.3118864893913269, 0.31173694133758545, 0.3137631416320801, 0.3119836151599884, 0.3079098165035248, 0.30761754512786865, 0.3090514838695526, 0.3044772148132324, 0.30438053607940674, 0.30589601397514343, 0.30099645256996155, 0.29950809478759766, 0.2979555130004883, 0.3004246652126312, 0.29700759053230286, 0.2933371067047119, 0.2945576310157776, 0.2911789119243622, 0.29333367943763733, 0.2922777831554413, 0.2889881134033203, 0.28988516330718994, 0.2864036560058594, 0.2888083755970001, 0.2868516445159912, 0.28762316703796387, 0.2871478199958801, 0.28742533922195435, 0.28125402331352234, 0.2796885371208191, 0.27871978282928467, 0.2808924615383148, 0.2769985795021057, 0.27962735295295715, 0.2784040570259094, 0.276449978351593, 0.27754443883895874, 0.27491021156311035, 0.2749147117137909, 0.2752573788166046, 0.2736738622188568, 0.27296948432922363, 0.27053192257881165, 0.27007734775543213, 0.268949031829834, 0.2706910967826843, 0.26702672243118286, 0.26487109065055847, 0.26659151911735535, 0.26566198468208313, 0.2655329406261444, 0.265634685754776, 0.26510700583457947, 0.26275891065597534, 0.26126188039779663, 0.26193347573280334, 0.2617974579334259, 0.2588404715061188, 0.2588020861148834, 0.2576046884059906, 0.2602648437023163, 0.2565983533859253, 0.25587913393974304, 0.2547212839126587, 0.2545795738697052, 0.254514217376709, 0.2548255920410156, 0.253286749124527, 0.2540189027786255, 0.2491733282804489, 0.2525641620159149, 0.25159624218940735, 0.25360313057899475, 0.2489878088235855, 0.24660950899124146, 0.24855493009090424, 0.24792301654815674, 0.24856530129909515, 0.24613340198993683, 0.2463173270225525, 0.24779865145683289, 0.24470670521259308, 0.2432030737400055, 0.2426033765077591, 0.24133233726024628, 0.23931506276130676, 0.2412746548652649, 0.24152395129203796, 0.24343208968639374, 0.24191147089004517, 0.23762008547782898, 0.2388361543416977, 0.23626475036144257, 0.23679816722869873, 0.23802581429481506, 0.2392546832561493, 0.23726071417331696, 0.23618051409721375, 0.2379775196313858, 0.23534682393074036, 0.23370742797851562, 0.23452693223953247, 0.23437491059303284, 0.23172147572040558, 0.23281896114349365, 0.22944417595863342, 0.2298862338066101, 0.22818800806999207, 0.22983184456825256, 0.2325010746717453, 0.22902457416057587, 0.22743846476078033, 0.2304169088602066, 0.2322649359703064, 0.2291639745235443, 0.22769448161125183, 0.22420215606689453, 0.22512131929397583, 0.22565044462680817, 0.22678890824317932, 0.2246222347021103, 0.22605925798416138, 0.22667528688907623, 0.2249642312526703, 0.22734591364860535, 0.22442202270030975, 0.22224076092243195, 0.22128598392009735, 0.224344402551651, 0.22265921533107758, 0.21826773881912231, 0.22636784613132477, 0.22064095735549927, 0.2217317372560501, 0.22085148096084595, 0.22109973430633545, 0.21649493277072906, 0.21842849254608154, 0.2201777845621109, 0.22010362148284912, 0.21672672033309937, 0.2178977131843567, 0.22015854716300964, 0.21566155552864075, 0.21771188080310822, 0.21482032537460327, 0.21633225679397583, 0.2155616730451584, 0.21504925191402435, 0.2119753509759903, 0.21240225434303284, 0.2152383029460907, 0.21201340854167938, 0.21259264647960663, 0.2149040251970291, 0.21167805790901184, 0.21231171488761902, 0.21029186248779297, 0.212461456656456, 0.21106131374835968, 0.21058566868305206, 0.21069803833961487, 0.20546716451644897, 0.20779506862163544, 0.20806822180747986, 0.2085941880941391, 0.20690710842609406, 0.2091907113790512, 0.20920467376708984, 0.2083875834941864, 0.20739178359508514, 0.205109640955925, 0.2062155157327652, 0.2056661695241928], "accuracy_train_first": 0.53453332641196, "model": "residualv3", "loss_std": [0.31587642431259155, 0.25887012481689453, 0.2554691433906555, 0.2518230676651001, 0.24845898151397705, 0.24594366550445557, 0.2436109036207199, 0.24275292456150055, 0.24251709878444672, 0.23788999021053314, 0.23523667454719543, 0.23735684156417847, 0.23188896477222443, 0.23164166510105133, 0.2314225733280182, 0.23171482980251312, 0.23234933614730835, 0.2259751856327057, 0.22439296543598175, 0.22517120838165283, 0.22497524321079254, 0.22202333807945251, 0.22070066630840302, 0.2207968831062317, 0.22015966475009918, 0.2161046862602234, 0.2141849547624588, 0.21714797616004944, 0.21475817263126373, 0.21271084249019623, 0.20883986353874207, 0.2078341692686081, 0.2064846158027649, 0.20795485377311707, 0.20773164927959442, 0.20155447721481323, 0.20101970434188843, 0.2016991525888443, 0.2032114565372467, 0.19998599588871002, 0.19565562903881073, 0.1938796490430832, 0.1978306621313095, 0.1944536715745926, 0.19251497089862823, 0.19437816739082336, 0.1933666169643402, 0.1932612806558609, 0.19215594232082367, 0.19227515161037445, 0.1898217797279358, 0.18841542303562164, 0.18767738342285156, 0.18499350547790527, 0.18447807431221008, 0.18093693256378174, 0.18574777245521545, 0.18202649056911469, 0.18129727244377136, 0.1841869354248047, 0.17784513533115387, 0.17885272204875946, 0.1782957911491394, 0.17943906784057617, 0.17778971791267395, 0.17511585354804993, 0.17336228489875793, 0.17590197920799255, 0.1773063689470291, 0.1711595207452774, 0.1748887151479721, 0.1703684777021408, 0.17269684374332428, 0.1723557710647583, 0.16709323227405548, 0.1691267043352127, 0.17101888358592987, 0.1665850579738617, 0.16994212567806244, 0.16646549105644226, 0.16461284458637238, 0.1660940796136856, 0.16508324444293976, 0.16694828867912292, 0.16365490853786469, 0.1628824770450592, 0.16422484815120697, 0.1605820208787918, 0.16113798320293427, 0.16115058958530426, 0.1572682410478592, 0.15953102707862854, 0.15751875936985016, 0.15758392214775085, 0.15771923959255219, 0.1610228568315506, 0.1573685109615326, 0.15632517635822296, 0.1565474420785904, 0.1572694480419159, 0.16253487765789032, 0.1555664837360382, 0.15239952504634857, 0.15469206869602203, 0.15365149080753326, 0.1545097976922989, 0.15509867668151855, 0.1529580056667328, 0.1515345275402069, 0.15152832865715027, 0.1540348380804062, 0.1519928276538849, 0.1492978185415268, 0.15231624245643616, 0.14794744551181793, 0.1472368687391281, 0.14985300600528717, 0.1475168764591217, 0.1490754783153534, 0.14612917602062225, 0.14997532963752747, 0.15036606788635254, 0.1479259878396988, 0.1506834328174591, 0.1483898013830185, 0.14610792696475983, 0.14642897248268127, 0.14443662762641907, 0.14435608685016632, 0.14512673020362854, 0.14648103713989258, 0.1449040174484253, 0.14447632431983948, 0.14696171879768372, 0.14375118911266327, 0.14643163979053497, 0.14713852107524872, 0.14495466649532318, 0.14310407638549805, 0.1446492075920105, 0.1399480104446411, 0.1418134868144989, 0.1424563229084015, 0.14229917526245117, 0.14380857348442078, 0.13891252875328064, 0.1395845115184784, 0.14473126828670502, 0.14166688919067383, 0.14115680754184723, 0.14157864451408386, 0.13829705119132996, 0.13660362362861633, 0.1399112045764923, 0.14113275706768036, 0.13793151080608368, 0.1376795768737793, 0.14011861383914948, 0.13796815276145935, 0.13681302964687347, 0.13741746544837952, 0.1368493288755417, 0.13884210586547852, 0.1370309442281723, 0.1385544091463089, 0.1346481740474701, 0.1355566829442978, 0.13483287394046783, 0.13556121289730072, 0.1387125551700592, 0.13415899872779846, 0.13566084206104279, 0.1358291059732437, 0.1355888396501541, 0.13480006158351898, 0.13701580464839935, 0.13741435110569, 0.13425526022911072, 0.13369490206241608, 0.13288170099258423, 0.13371986150741577, 0.13510794937610626, 0.13368931412696838, 0.13243231177330017, 0.1323794275522232, 0.13573648035526276, 0.13281869888305664, 0.13240595161914825, 0.13175630569458008, 0.13051141798496246, 0.13183893263339996, 0.13029363751411438, 0.13346152007579803, 0.1312062293291092, 0.1300303041934967, 0.13235634565353394, 0.12938106060028076, 0.13167691230773926, 0.1308313012123108, 0.13279545307159424, 0.12958571314811707, 0.13105905055999756, 0.12737469375133514, 0.13029322028160095, 0.12618061900138855, 0.1295476257801056, 0.13215284049510956, 0.1299949437379837, 0.12745709717273712, 0.12733182311058044, 0.12910056114196777, 0.12959915399551392, 0.12437579780817032, 0.1262291669845581, 0.12598712742328644, 0.12496466189622879, 0.12523634731769562, 0.12688207626342773, 0.12603504955768585, 0.12823377549648285, 0.12951745092868805, 0.12793433666229248, 0.12837550044059753, 0.12501662969589233, 0.12718693912029266, 0.12493105232715607, 0.1272708773612976, 0.12553732097148895, 0.12695284187793732, 0.12437962740659714, 0.12839727103710175, 0.12703436613082886, 0.12779413163661957, 0.12263515591621399, 0.1267070174217224, 0.12712742388248444, 0.13028885424137115, 0.12456098198890686, 0.12309113144874573, 0.12874722480773926, 0.12389672547578812, 0.12440700083971024, 0.12359941750764847, 0.1234351396560669, 0.12456617504358292, 0.12622904777526855, 0.12338608503341675, 0.12418919801712036, 0.12692014873027802, 0.12265894562005997, 0.12426429986953735, 0.12612786889076233, 0.12383200228214264, 0.12279758602380753, 0.12130183726549149, 0.12303599715232849, 0.12489837408065796, 0.12375367432832718, 0.12292640656232834, 0.12024963647127151, 0.12268472462892532, 0.12160742282867432, 0.1230071485042572, 0.12223535776138306, 0.12402094900608063, 0.12120428681373596, 0.12482715398073196, 0.12340345233678818, 0.1231452226638794, 0.12319334596395493, 0.12136156111955643]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:25 2016", "state": "available"}], "summary": "e9849ea47259919bd471eb02b56b2c47"}