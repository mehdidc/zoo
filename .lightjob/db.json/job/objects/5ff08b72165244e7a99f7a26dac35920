{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 16, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.01347523007442501, 0.01819062550173022, 0.017448121815817667, 0.01941033855920803, 0.00956871174396595, 0.014648626507828874, 0.00944836734106366, 0.011445254940794328, 0.014135416103345785, 0.013138189405501686, 0.013348600251883707, 0.011227403226317337, 0.013677645862099165, 0.01714455403473172, 0.015820027887330623, 0.014208896504397411, 0.01025957822240256, 0.015849196815895184, 0.016141992295232045, 0.011907847341981382, 0.011639960736337345, 0.011856452015418881, 0.012487534290248138, 0.014594510156048153, 0.011225087540344214, 0.01592537567771434, 0.020909802475985804, 0.013090047589764276, 0.016441030032947942, 0.018226908062427095, 0.015044320478590171, 0.01537886958854405, 0.014361001017302664, 0.014635994164398215, 0.015805880630307686, 0.01963341310252321, 0.014879123453082404, 0.02145262011146501, 0.015874193450003165, 0.017910472691693748, 0.010835075454849406, 0.022283471429193003, 0.01836259074063172, 0.014991439291002131, 0.014767608176920624, 0.019593211949360964, 0.019105007089402874, 0.014752208533547691, 0.021396714052353296, 0.0194531087918091, 0.02049800108966807, 0.020374604764980805, 0.01696256122660935, 0.015503148669492697, 0.017787865872541983, 0.02342734737836256, 0.01855751938863276, 0.02007508657294835, 0.025359839491497855, 0.015971520253765567, 0.018481111607552104, 0.021264385085206016, 0.020318493193793304, 0.020696082861431545, 0.02371906808766355, 0.018589720055812265, 0.021687693681745536, 0.01950278487212717, 0.01744213534999604, 0.021728962144333668, 0.021744258613014815, 0.017933066471039188, 0.02007892863656035, 0.016571807299843276, 0.015007735266261802, 0.020836387225314317, 0.020668063830885045, 0.0158981569957406, 0.018589173229857734, 0.013495943960352816, 0.015705492152859515, 0.017681965656445902, 0.02152308865295327, 0.025190735146311566, 0.01333975637938193, 0.014017033290222332, 0.013241969045868112, 0.013083850093766862, 0.01573019262228454, 0.01814255921200009, 0.016971263903084854, 0.015309928456889934, 0.014775964367659877, 0.01644555887201709, 0.013137385374321964, 0.020512547252384588, 0.021057986042270736, 0.01553141386520285, 0.014232887368363943, 0.013728132810690016, 0.013514521892578929, 0.015952556528567495, 0.017582066614955975, 0.018983227180054414, 0.019657623777674528, 0.018042018157842454, 0.016060186400824353, 0.010752718954374737, 0.011658445290430825, 0.014507657985000658, 0.012567751525899163, 0.011555681566023613, 0.01155333479105571, 0.012651479986636039, 0.014697753182550302, 0.012912489486544448, 0.015287743411847497, 0.01598850583231279, 0.012896707961335852, 0.01499404311704121, 0.014461940816644446, 0.014004638794002556, 0.013134516243988944, 0.015553451051865943, 0.01828907561644915, 0.015827602979019112, 0.010842860834036678, 0.010758258329694225, 0.006432369775873453, 0.009940804014501406, 0.010939825920640085, 0.014402203707993838, 0.014258009086057687, 0.008315899498295098, 0.011119630002929141, 0.01586790238568581, 0.010621170433001918, 0.012148860253770972, 0.015350323791040057, 0.010825002889539975, 0.013816250678961755, 0.01155309102561453, 0.008907361623832563, 0.008552275255363666, 0.017781049939779192, 0.014489167216349942, 0.00963093265274535, 0.012667878818616118, 0.020767473441675736, 0.008714756148432751, 0.007791737018672808, 0.007239707053926688, 0.011316455487738776, 0.007713840598509407, 0.011211937154262823, 0.014790709423292919, 0.00914425868832287, 0.013921201837844246, 0.005407045495499292, 0.00950691077889107, 0.00863406978612641, 0.008437423214519676, 0.00947163633174031, 0.012993732676161749, 0.014866021745480504, 0.007839612116236702, 0.009103724230289118, 0.008372625456313594, 0.012207291282335057, 0.007774642829862883, 0.011859701930813225, 0.008695053288113484, 0.006971417951844, 0.0106087548835635, 0.009147185357210694, 0.007381309546716991, 0.006229280767088089, 0.009113772572916066, 0.0063123271134662, 0.009736124155713588, 0.009699580005874658, 0.011563509189446552, 0.008380935046254426, 0.0109020065515344, 0.00863347251757765, 0.010206877645892877, 0.005638372221216655, 0.008602990152267374, 0.008102855029422226, 0.00910680014410534, 0.008317971785342828, 0.005495456696972367, 0.00733969744436355, 0.009759564678155046, 0.011526280634220157, 0.010846034247613148, 0.015597135380962964, 0.014393662016030236, 0.015164576617641496, 0.012715740307063197, 0.007349475098594321, 0.00807630739043665, 0.009669291704923203, 0.010795975888295917, 0.01083384494795972, 0.01576799623470577, 0.011378355077117697, 0.010897932390669754, 0.013785445911378744, 0.00880754417471945, 0.008700735370087075, 0.01020965934666946, 0.011317627502727632, 0.009455420403456536, 0.008639361224007512, 0.01282576515420905, 0.013440126817793857, 0.011341403979088435, 0.013659518143895183, 0.013513779227239772, 0.009712936169577023, 0.01003087409734119, 0.011189829570768962, 0.008978484981614196, 0.00676629261123083, 0.010776599316393989, 0.010203385568005596, 0.010552488973722038, 0.010003148409193826, 0.006608027732991411, 0.010025601766071346, 0.011802860991632379, 0.009945127057671104, 0.005897557411029964, 0.009214235255550051, 0.009980185942591802, 0.011074589693420525, 0.01271289180084732, 0.014401216939609827, 0.007197251057648211, 0.006304810140560257, 0.008316375353346922, 0.016588461961652094, 0.00809257890945925, 0.009211267896491657, 0.011370631217509121, 0.004430543243171663, 0.005064741667160432, 0.011986748062658172, 0.008697031253362663, 0.0057762474416173685, 0.0069403537943872285, 0.007581813596447847, 0.00791156773617534, 0.0079083503730444, 0.009691034663479073, 0.007570402426143682, 0.008118598580132502, 0.003432760453133601, 0.015910200789533535, 0.006920625826440275, 0.005898195369921593, 0.007720552232795181, 0.006036320708367627, 0.008014216136207062, 0.004396373455984559, 0.00720167119386329, 0.007718059613002283, 0.005787117841122437, 0.013279587693420376, 0.006303086284809624, 0.012467106190533124, 0.010771256535345209, 0.008072949238271107, 0.005678903567139569, 0.01205026430323376, 0.003439978717937859, 0.007695696230145356, 0.007320198250967946, 0.008177405269147618, 0.005960101584668322, 0.010758106831214741, 0.010377091690706322, 0.010743978640971617, 0.008074226122138203, 0.006849524422020114, 0.006279800294235698, 0.007696944224649749, 0.009351438354745254, 0.011184618432556317, 0.004185954709447475, 0.008264716353629182, 0.01189654992446879, 0.008019356487448715, 0.008892666241490859, 0.00846314904351215, 0.013521490714821486, 0.006026215209387425], "moving_avg_accuracy_train": [0.04950573464608711, 0.1042317275747508, 0.15800434532461236, 0.21234856749204034, 0.26344364683549043, 0.3112959162016368, 0.3568479659274495, 0.399220721994819, 0.43870235546970954, 0.4752819983661217, 0.508801420461034, 0.5401146219284504, 0.5692801493420099, 0.5958987505772902, 0.6204715840259288, 0.6430683317868188, 0.664295828619211, 0.6837025567230521, 0.7018429051712711, 0.718480860812782, 0.7336688264341616, 0.7479006454564893, 0.7610555495051095, 0.7733063702928783, 0.7847206251459733, 0.7951210853565513, 0.8046234417699087, 0.8134150528693114, 0.8214808905825648, 0.8285866847030643, 0.8355746681626675, 0.8421429071822719, 0.8476940684297147, 0.8528735479666344, 0.8576373500486624, 0.8628850223320021, 0.8678963539858452, 0.8721900612932869, 0.8763149226831074, 0.8801086060446417, 0.8840182498640885, 0.8875718425825523, 0.8907328375993986, 0.8940077414490472, 0.8962973540935482, 0.8989740978104853, 0.9010738502664246, 0.9036052964505611, 0.9061392562388751, 0.9083362949353088, 0.910374011533509, 0.9123381648052227, 0.9146057376461751, 0.9161583080018512, 0.9180857912993496, 0.9185579704635269, 0.9195711222624584, 0.9210712575791251, 0.9223352767605353, 0.9229824318202698, 0.924445886479928, 0.92519122535939, 0.9265153250687445, 0.9277465062881066, 0.9285616366843513, 0.9293091328361912, 0.9305235669478286, 0.9316515790757202, 0.9325203777134601, 0.9341090149778746, 0.9348040775408568, 0.9353854199713412, 0.9366317133897202, 0.9376230609864717, 0.9386734560402332, 0.9393886579052944, 0.940450830320745, 0.9408208119458318, 0.9419165163155713, 0.9426029223448208, 0.9436087713294232, 0.9442792314346223, 0.9451477124935872, 0.9462826238704282, 0.9466344733500797, 0.9472835981127091, 0.9479329866633799, 0.9487498070446609, 0.9494153351188032, 0.9488679399247985, 0.9498053589145077, 0.9502560137587989, 0.950721984890071, 0.9512019209237199, 0.9515757346337658, 0.9520166905227794, 0.9522625603455476, 0.9524070411776872, 0.953053256962327, 0.9538579573077609, 0.9543522141794211, 0.954308655967459, 0.9550948814040741, 0.9559025738422935, 0.9563456486378352, 0.9569954959764326, 0.957113147865731, 0.9577653724387001, 0.9583012573293815, 0.9586881865809856, 0.9587248169181344, 0.9582441065787572, 0.9585832724828047, 0.9591512636119236, 0.9597321740435976, 0.9597714345773608, 0.9597533266839473, 0.9600625504132085, 0.9606919131909629, 0.9612839163278467, 0.9616283460486519, 0.9622707569795009, 0.962467638461322, 0.9625797997259318, 0.963034203531947, 0.9633477998073514, 0.9633371037540341, 0.963562245238173, 0.963823001294136, 0.9641855288802078, 0.9641073359612715, 0.9644623924687342, 0.964163489790936, 0.9642129146213663, 0.9645713641556767, 0.9651218693687081, 0.9646128237259034, 0.965045178592608, 0.9651901573476421, 0.9652044528843342, 0.9653939580792433, 0.9656296529701469, 0.9657139312362552, 0.966196574570963, 0.9666543132067514, 0.9672243520491899, 0.967597914127632, 0.9675272189565631, 0.9678402313609252, 0.9682869920415086, 0.9684123839457003, 0.9684067622166433, 0.968080796075959, 0.968201375135076, 0.9683772174573011, 0.968509898910399, 0.968819974420568, 0.9683202617238046, 0.9684632890478712, 0.9686548647550257, 0.9690062472521607, 0.9684925215210383, 0.9686764515856195, 0.9692302884949332, 0.9693381527621342, 0.969321226213311, 0.9689665566419983, 0.9690705311111503, 0.9694292111464915, 0.9694869922628317, 0.9696830102984534, 0.9700175366495605, 0.9696212459667934, 0.9700178604689513, 0.9699121449566169, 0.9701378715312302, 0.9702386828519444, 0.9704921013596164, 0.9703855007832247, 0.9706102866049116, 0.9710196041861148, 0.971060107978236, 0.9712174330804217, 0.9714311773831216, 0.9715002422710091, 0.9716182402903553, 0.9718268171530233, 0.9718680519544246, 0.9719190420709054, 0.9720579030793002, 0.9720526696535223, 0.9722874859465218, 0.9721595291281248, 0.97216505943675, 0.9722560311716464, 0.972379830509262, 0.9725262352917152, 0.9724766019399615, 0.9727876075936029, 0.9729023910675852, 0.973026622533455, 0.9730012831217946, 0.9731365156727103, 0.9730769354590292, 0.9736278519571924, 0.9740284178019862, 0.9737680402325203, 0.9739382763128581, 0.9739426071637152, 0.97406977386521, 0.9743539237108318, 0.9742818846873862, 0.9738241354662943, 0.9735632958399306, 0.9735563687107178, 0.9735176182599119, 0.9732386022291866, 0.9731153349372388, 0.9731183987637899, 0.9730932544219717, 0.9732984890976686, 0.9732971523522151, 0.973384304936069, 0.973404649590118, 0.9734507894668388, 0.9734527878261258, 0.9736080101220939, 0.9735407719444176, 0.9739662497345181, 0.974063186442037, 0.9744386758335476, 0.9746324931085354, 0.9743327785429754, 0.9747255586494106, 0.9744187545321162, 0.974981937449152, 0.9746610851471124, 0.9748490096300478, 0.975018105615871, 0.9753562318102362, 0.9751001845220697, 0.9752790402508336, 0.9753632444471879, 0.9755924880453355, 0.9755779902444011, 0.975922979091408, 0.9759243324085038, 0.9762973939593201, 0.9761448681050547, 0.9761796918969394, 0.9764039846120074, 0.9762663763293781, 0.9757194238893159, 0.9760503054206501, 0.9762643573928892, 0.976196551452419, 0.9756704963440912, 0.9755946111442059, 0.9754171406167177, 0.9756108397610259, 0.9756805372944749, 0.975992055997198, 0.9760049586189159, 0.9758515214618046, 0.9761482308477855, 0.9758316929927965, 0.975972203008993, 0.9760638208402459, 0.9761486380860016, 0.9763087150131434, 0.9764131846201717, 0.9763746377355355, 0.9765120426000864, 0.976856596115087, 0.976718012655987, 0.9764746689046925, 0.9763975296547271, 0.9765837986011685, 0.9767328394624895, 0.9765600926436399, 0.9765023128054939, 0.9764642618440198, 0.976088219103693, 0.976519332795714, 0.9768399058030567, 0.976075237245407, 0.9761124819720937, 0.9761784461629888, 0.9762005755050233, 0.9765715893830924, 0.9766148582721642, 0.9767003753461567, 0.9771051506460741, 0.977325325238628, 0.977498013881478, 0.9775231171802533, 0.9773155204170083, 0.9774843950491262], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 381549864, "moving_var_accuracy_train": [0.02205735986563911, 0.04680603259732855, 0.06814887911465024, 0.0879136415500302, 0.10261864159304832, 0.11296533458515559, 0.12034370423464624, 0.12446838792188479, 0.1260507435663067, 0.1254883016795374, 0.12305143642977576, 0.11957094206204921, 0.11526949975964414, 0.11011949916918555, 0.1045419665455178, 0.09868328697528958, 0.09287041787368365, 0.08697296594758305, 0.08123731952922995, 0.07560498168766687, 0.07012055221634607, 0.06493139904887005, 0.05999572264873868, 0.055346893873631085, 0.05098477141093059, 0.04685982042316388, 0.04298649137750577, 0.03938347407126345, 0.03603064630628598, 0.032882012466403716, 0.030033298435248525, 0.02741824446609156, 0.0249537585402384, 0.02269982576067488, 0.020634087477097995, 0.018818521308928186, 0.017162690182538645, 0.015612344466262584, 0.014204240353003408, 0.0129133446187313, 0.011759577990012622, 0.01069727238188983, 0.009717472149169591, 0.008842249891272618, 0.008005205836702084, 0.007269169865367339, 0.006581933522216613, 0.005981414148043562, 0.0054410613031183434, 0.00494039798410915, 0.0044837287861094685, 0.004070076990171575, 0.0037093462704556436, 0.003360105915793993, 0.0030575320509738167, 0.0027537854243441834, 0.0024876451710188693, 0.0022591343076317784, 0.002047600577287355, 0.0018466098066006805, 0.0016812241218084885, 0.0015181014800347784, 0.0013820704923941138, 0.0012575057079088935, 0.0011377350751839428, 0.0010289903221386873, 0.000939364941828396, 0.0008568801498915905, 0.0007779854345588802, 0.0007229008063239675, 0.0006549587333897053, 0.000592504491244067, 0.0005472332676819136, 0.000501354871431987, 0.00046114935220948727, 0.0004196380403586219, 0.00038782812848405787, 0.00035027729326176906, 0.0003260546765283874, 0.0002976895880084585, 0.00027702621882604473, 0.00025336924771741215, 0.00023482065709369755, 0.00022293080588387575, 0.00020175190780246768, 0.00018536898363935065, 0.00017062743468309615, 0.00015956945103227176, 0.00014759885448628805, 0.00013553574252343444, 0.000129890957531497, 0.00011872966987649554, 0.0001088108647454579, 0.0001000028256384635, 9.126017328298154e-05, 8.388413481918541e-05, 7.60397890649995e-05, 6.862368255620131e-05, 6.551966786344137e-05, 6.479558489057112e-05, 6.051463509816433e-05, 5.448024744881186e-05, 5.459557663855654e-05, 5.500732264751203e-05, 5.127342785276042e-05, 4.994679913882387e-05, 4.507669692844088e-05, 4.439759927786023e-05, 4.254239289462066e-05, 3.9635581816880904e-05, 3.56840996695895e-05, 3.419543157608705e-05, 3.181119001269358e-05, 3.153359631624452e-05, 3.1417349051269246e-05, 2.8289486651744645e-05, 2.5463489048805037e-05, 2.3777713976568547e-05, 2.4964820133116906e-05, 2.562254754652731e-05, 2.4127979285040233e-05, 2.5429407593205935e-05, 2.3235327694841782e-05, 2.1025016268867387e-05, 2.0780860012270255e-05, 1.9587857626570934e-05, 1.7630101513922935e-05, 1.6323289553452863e-05, 1.5302904084600305e-05, 1.4955449932107793e-05, 1.3514932132042947e-05, 1.3298025030263392e-05, 1.2772307824391002e-05, 1.1517062366719397e-05, 1.1521730747873543e-05, 1.3097061579259392e-05, 1.4119502619459868e-05, 1.4389928934382255e-05, 1.3140105595645275e-05, 1.182793429740457e-05, 1.0968350837742095e-05, 1.0371484488350646e-05, 9.398261474759483e-06, 1.0554936624124514e-05, 1.1385164889953988e-05, 1.3171146937956875e-05, 1.3109969882210573e-05, 1.1843953158901599e-05, 1.1541348730572592e-05, 1.2183569808953173e-05, 1.1106720994789259e-05, 9.996333329848638e-06, 9.952985320717082e-06, 9.088540574123062e-06, 8.457971217280565e-06, 7.770613407517973e-06, 7.858873464825484e-06, 9.320401132101238e-06, 8.572472357757904e-06, 8.045536386128071e-06, 8.352209681150288e-06, 9.892215854389533e-06, 9.207466686862495e-06, 1.1047337917239036e-05, 1.0047316426764472e-05, 9.045163356583613e-06, 9.272761564261046e-06, 8.44278161995384e-06, 8.756365767729932e-06, 7.910777107606558e-06, 7.465507029446424e-06, 7.726127242766713e-06, 8.366931265721762e-06, 8.945965709046963e-06, 8.151951064075395e-06, 7.795328336047812e-06, 7.107261803900286e-06, 6.974524083786256e-06, 6.379344821390978e-06, 6.196168329934377e-06, 7.084419437479235e-06, 6.390742508317139e-06, 5.974428947484868e-06, 5.788165695166002e-06, 5.252278754299683e-06, 4.852362671996174e-06, 4.758665173560629e-06, 4.298101435823976e-06, 3.891691220050074e-06, 3.6760635149170545e-06, 3.3087036621337072e-06, 3.4740815190428615e-06, 3.2740298935073603e-06, 2.9469021629780466e-06, 2.7266946556308416e-06, 2.591961674014602e-06, 2.525674749539883e-06, 2.2952785010426105e-06, 2.936271300310284e-06, 2.7612213833742015e-06, 2.6240003590461103e-06, 2.3673790951911445e-06, 2.295231771116726e-06, 2.09765681076567e-06, 4.619472021224281e-06, 5.601601783240745e-06, 5.651609913045259e-06, 5.3472718291799215e-06, 4.812713452684243e-06, 4.4769844371375495e-06, 4.7559562063261446e-06, 4.327067173784597e-06, 5.780169601098193e-06, 5.8144884371221255e-06, 5.233471459482077e-06, 4.723638690472888e-06, 4.951924330041485e-06, 4.593485324414672e-06, 4.134221275271424e-06, 3.7264892890735447e-06, 3.7329318091418437e-06, 3.3596547102233253e-06, 3.0920493950525143e-06, 2.7865696000826496e-06, 2.5270726340888105e-06, 2.2744013116384875e-06, 2.2638068309650647e-06, 2.0781149007036814e-06, 3.499585559452681e-06, 3.234197530889097e-06, 4.179708326033112e-06, 4.099823718183094e-06, 4.4983007336445715e-06, 5.436956568381413e-06, 5.74041980904201e-06, 8.02095281050534e-06, 8.145373326971792e-06, 7.648676495853783e-06, 7.141149918062083e-06, 7.455998836099443e-06, 7.300440876486178e-06, 6.858301134242463e-06, 6.236284140971502e-06, 6.085629372499183e-06, 5.478958111336674e-06, 6.002218041235482e-06, 5.402012720316391e-06, 6.114385734561766e-06, 5.712324387079958e-06, 5.1520062167030285e-06, 5.089570593325756e-06, 4.751037889026869e-06, 6.968346845334231e-06, 7.256855450803348e-06, 6.943534127098335e-06, 6.290559524455895e-06, 8.152109364991309e-06, 7.388725500546872e-06, 6.9333150436344215e-06, 6.577657765822908e-06, 5.963611704760369e-06, 6.240645653600639e-06, 5.6180793870653566e-06, 5.268158099000189e-06, 5.5336704266623985e-06, 5.882069306765212e-06, 5.4715499579526545e-06, 4.999939405188559e-06, 4.5646911512680684e-06, 4.33884363956976e-06, 4.003184364746464e-06, 3.6162386891082362e-06, 3.4245356914177393e-06, 4.150536244569307e-06, 3.908330996337629e-06, 4.0504435283506764e-06, 3.6989533504825806e-06, 3.6413230991094127e-06, 3.4771093942880824e-06, 3.397971625662966e-06, 3.08822105036208e-06, 2.7924298263477944e-06, 3.785860126684547e-06, 5.0800052530469095e-06, 5.496908205072273e-06, 1.0209679412087804e-05, 9.201195997872724e-06, 8.320237868409467e-06, 7.492621451578423e-06, 7.982220985899448e-06, 7.200848658163001e-06, 6.546582321844871e-06, 7.366511480469171e-06, 7.066151993278774e-06, 6.627929100275338e-06, 5.970807770732483e-06, 5.761594738647307e-06, 5.4421030371392495e-06], "duration": 137579.319949, "accuracy_train": [0.4950573464608712, 0.5967656639327242, 0.6419579050733665, 0.7014465669988926, 0.7232993609265412, 0.7419663404969545, 0.7668164134597637, 0.7805755266011444, 0.7940370567437246, 0.8044987844338316, 0.8104762193152455, 0.8219334351351975, 0.8317698960640458, 0.8354661616948136, 0.8416270850636766, 0.8464390616348283, 0.855343300110742, 0.8583631096576227, 0.8651060412052418, 0.8682224615863787, 0.870360517026578, 0.8759870166574382, 0.8794496859426911, 0.8835637573827981, 0.8874489188238279, 0.8887252272517534, 0.8901446494901256, 0.892539552763935, 0.8940734300018457, 0.89253883178756, 0.8984665192990956, 0.9012570583587117, 0.8976545196567, 0.899488863798911, 0.900511568786914, 0.9101140728820598, 0.9129983388704319, 0.9108334270602622, 0.9134386751914912, 0.9142517562984496, 0.9192050442391103, 0.9195541770487264, 0.9191817927510151, 0.9234818760958842, 0.9169038678940569, 0.9230647912629198, 0.9199716223698781, 0.9263883121077889, 0.9289448943337025, 0.9281096432032114, 0.9287134609173128, 0.930015544250646, 0.9350138932147471, 0.9301314412029347, 0.9354331409768365, 0.9228075829411223, 0.9286894884528424, 0.9345724754291252, 0.9337114493932264, 0.9288068273578812, 0.9376169784168512, 0.9318992752745479, 0.9384322224529347, 0.9388271372623662, 0.9358978102505537, 0.9360365982027501, 0.9414534739525655, 0.9418036882267442, 0.9403395654531194, 0.9484067503576044, 0.9410596406076966, 0.9406175018456996, 0.9478483541551311, 0.9465451893572352, 0.9481270115240864, 0.9458254746908453, 0.9500103820598007, 0.9441506465716132, 0.9517778556432264, 0.9487805766080657, 0.9526614121908453, 0.9503133723814139, 0.952964042024271, 0.9564968262619971, 0.9498011186669435, 0.953125720976375, 0.9537774836194168, 0.9561011904761905, 0.9554050877860835, 0.943941383178756, 0.95824212982189, 0.9543119073574198, 0.9549157250715209, 0.9555213452265596, 0.9549400580241787, 0.9559852935239018, 0.9544753887504615, 0.9537073686669435, 0.9588691990240864, 0.9611002604166666, 0.9588005260243633, 0.9539166320598007, 0.9621709103336102, 0.963171805786268, 0.9603333217977114, 0.9628441220238095, 0.9581720148694168, 0.9636353935954227, 0.963124221345515, 0.9621705498454227, 0.9590544899524732, 0.9539177135243633, 0.9616357656192323, 0.9642631837739941, 0.9649603679286637, 0.9601247793812293, 0.9595903556432264, 0.9628455639765596, 0.966356178190753, 0.9666119445598007, 0.9647282135358989, 0.9680524553571429, 0.9642395717977114, 0.9635892511074198, 0.9671238377860835, 0.9661701662859912, 0.9632408392741787, 0.9655885185954227, 0.9661698057978036, 0.9674482771548542, 0.9634035996908453, 0.9676579010358989, 0.961473365690753, 0.9646577380952381, 0.9677974099644703, 0.9700764162859912, 0.9600314129406607, 0.9689363723929494, 0.9664949661429494, 0.9653331127145626, 0.9670995048334257, 0.9677509069882798, 0.9664724356312293, 0.9705403645833334, 0.9707739609288483, 0.972354701631137, 0.9709599728336102, 0.9668909624169435, 0.9706573430001846, 0.9723078381667589, 0.9695409110834257, 0.9683561666551311, 0.9651471008098007, 0.9692865866671282, 0.9699597983573275, 0.9697040319882798, 0.9716106540120893, 0.9638228474529347, 0.9697505349644703, 0.9703790461194168, 0.972168689726375, 0.9638689899409376, 0.9703318221668512, 0.974214820678756, 0.9703089311669435, 0.9691688872739018, 0.9657745305001846, 0.970006301333518, 0.9726573314645626, 0.970007022309893, 0.9714471726190477, 0.9730282738095238, 0.96605462982189, 0.9735873909883721, 0.9689607053456073, 0.9721694107027501, 0.9711459847383721, 0.9727728679286637, 0.9694260955956996, 0.9726333590000923, 0.9747034624169435, 0.9714246421073275, 0.9726333590000923, 0.9733548761074198, 0.9721218262619971, 0.9726802224644703, 0.9737040089170359, 0.9722391651670359, 0.9723779531192323, 0.9733076521548542, 0.9720055688215209, 0.974400832583518, 0.9710079177625508, 0.972214832214378, 0.9730747767857143, 0.9734940245478036, 0.9738438783337948, 0.9720299017741787, 0.975586658476375, 0.9739354423334257, 0.9741447057262828, 0.9727732284168512, 0.9743536086309523, 0.9725407135358989, 0.9785861004406607, 0.9776335104051311, 0.9714246421073275, 0.9754704010358989, 0.9739815848214286, 0.9752142741786637, 0.9769112723214286, 0.973633533476375, 0.9697043924764673, 0.9712157392026578, 0.9734940245478036, 0.9731688642026578, 0.9707274579526578, 0.9720059293097084, 0.9731459732027501, 0.9728669553456073, 0.9751456011789406, 0.9732851216431341, 0.974168678190753, 0.9735877514765596, 0.9738660483573275, 0.9734707730597084, 0.9750050107858066, 0.9729356283453304, 0.9777955498454227, 0.9749356168097084, 0.9778180803571429, 0.9763768485834257, 0.9716353474529347, 0.9782605796073275, 0.9716575174764673, 0.9800505837024732, 0.971773414428756, 0.9765403299764673, 0.9765399694882798, 0.9783993675595238, 0.9727957589285714, 0.9768887418097084, 0.976121082214378, 0.9776556804286637, 0.9754475100359912, 0.9790278787144703, 0.9759365122623662, 0.9796549479166666, 0.9747721354166666, 0.9764931060239018, 0.9784226190476191, 0.9750279017857143, 0.970796851928756, 0.9790282392026578, 0.9781908251430418, 0.9755862979881875, 0.97093600036914, 0.9749116443452381, 0.9738199058693245, 0.9773541320598007, 0.976307815095515, 0.9787957243217055, 0.976121082214378, 0.9744705870478036, 0.9788186153216132, 0.9729828522978959, 0.9772367931547619, 0.9768883813215209, 0.9769119932978036, 0.9777494073574198, 0.9773534110834257, 0.9760277157738095, 0.9777486863810447, 0.9799575777500923, 0.9754707615240864, 0.9742845751430418, 0.9757032764050388, 0.97826021911914, 0.978074207214378, 0.9750053712739941, 0.9759822942621816, 0.976121803190753, 0.972703834440753, 0.9803993560239018, 0.97972506286914, 0.9691932202265596, 0.9764476845122739, 0.9767721238810447, 0.9763997395833334, 0.9799107142857143, 0.9770042782738095, 0.9774700290120893, 0.9807481283453304, 0.9793068965716132, 0.9790522116671282, 0.9777490468692323, 0.9754471495478036, 0.9790042667381875], "end": "2016-01-31 01:00:03.933000", "learning_rate_per_epoch": [0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575, 0.006260070484131575], "accuracy_valid": [0.48744587725903615, 0.5927454936935241, 0.6261839349585843, 0.680994975997741, 0.6981068806475903, 0.7194088855421686, 0.7404976350715362, 0.7543121705572289, 0.7650749482304217, 0.7686355774661144, 0.7725624176393072, 0.7807823089231928, 0.7902023131588856, 0.7915244964231928, 0.7958175475338856, 0.7980354033320783, 0.8073745176016567, 0.8062347044427711, 0.8043727644954819, 0.812023484563253, 0.8152179028614458, 0.8197550945971386, 0.8172622129141567, 0.8156752988516567, 0.8218199948230422, 0.8203036756400602, 0.8144943053463856, 0.8231421780873494, 0.8176078336784638, 0.8202933805534638, 0.8269263577748494, 0.8221450254141567, 0.8230201077748494, 0.8268351727221386, 0.8239966702748494, 0.8272410932793675, 0.8288897778614458, 0.8268645872552711, 0.827892625188253, 0.8291030332266567, 0.8329592785203314, 0.8255115187311747, 0.8271396131400602, 0.8362448818712349, 0.8280455807605422, 0.8293368787650602, 0.8249320524284638, 0.8324298169239458, 0.8315238493034638, 0.8288588926016567, 0.8312900037650602, 0.837536179875753, 0.8361022213855422, 0.8315753247364458, 0.8342608716114458, 0.8256232939570783, 0.832775437688253, 0.8343520566641567, 0.8295398390436747, 0.827892625188253, 0.8373023343373494, 0.8280955854668675, 0.8323886365775602, 0.831798875188253, 0.8337108198418675, 0.8300795957266567, 0.8355624647025602, 0.8345961972891567, 0.8386759930346386, 0.8403335019766567, 0.8371596738516567, 0.8396422604480422, 0.839245164250753, 0.8387877682605422, 0.8402732021837349, 0.8369052381400602, 0.8402423169239458, 0.8400187664721386, 0.8416262707078314, 0.8438647166792168, 0.8396731457078314, 0.8417277508471386, 0.8404761624623494, 0.8452060193900602, 0.8416262707078314, 0.8443427028426205, 0.8437529414533133, 0.8400599468185241, 0.8419924816453314, 0.8376891354480422, 0.8469973644578314, 0.8437220561935241, 0.8415144954819277, 0.8451663097703314, 0.8409144390060241, 0.8434161450489458, 0.8448809887989458, 0.8426028332078314, 0.8417689311935241, 0.8416365657944277, 0.8437323512801205, 0.8384318524096386, 0.8462546474962349, 0.8470988445971386, 0.8460002117846386, 0.8475974209337349, 0.8449324642319277, 0.8544142389871988, 0.8483004282756024, 0.8487578242658133, 0.8474047557417168, 0.8447706842996988, 0.8485239787274097, 0.8526949595256024, 0.8538744823042168, 0.8470488398908133, 0.8467738140060241, 0.8484930934676205, 0.8528170298381024, 0.8525522990399097, 0.8535185664533133, 0.855126070689006, 0.850609469126506, 0.8512904155685241, 0.8491946300828314, 0.8473841655685241, 0.8494093561746988, 0.8498873423381024, 0.8575380624058735, 0.8533053110881024, 0.8537229974585843, 0.8500800075301205, 0.8482489528426205, 0.8543127588478916, 0.854271578501506, 0.8541186229292168, 0.8480562876506024, 0.8503447383283133, 0.8497240916792168, 0.8506197642131024, 0.8543730586408133, 0.8571100809487951, 0.8595823724585843, 0.8551672510353916, 0.8564173686935241, 0.8564585490399097, 0.8577101374246988, 0.8493681758283133, 0.8523478680346386, 0.8577410226844879, 0.8579851633094879, 0.8532141260353916, 0.8510874552899097, 0.8550657708960843, 0.8557673075112951, 0.8575468867658133, 0.8571203760353916, 0.8508124294051205, 0.8592470467808735, 0.8616472726844879, 0.8602236092808735, 0.8528376200112951, 0.8539362528237951, 0.8650240610881024, 0.8547289744917168, 0.8589720208960843, 0.8563879541603916, 0.8593176416603916, 0.8589617258094879, 0.8567953454442772, 0.8558687876506024, 0.8598265130835843, 0.8506403543862951, 0.8633356668862951, 0.8568659403237951, 0.8633768472326807, 0.8573954019201807, 0.8574659967996988, 0.8542112787085843, 0.8572321512612951, 0.8606604150978916, 0.8589308405496988, 0.8616575677710843, 0.8556246470256024, 0.8539259577371988, 0.8612707666603916, 0.8636415780308735, 0.8598162179969879, 0.8609251458960843, 0.8568762354103916, 0.8577307275978916, 0.8581278237951807, 0.8576086572853916, 0.8583204889871988, 0.8625929499246988, 0.8591955713478916, 0.8574145213667168, 0.8552172557417168, 0.8558481974774097, 0.8555437570594879, 0.8583410791603916, 0.8574865869728916, 0.8551363657756024, 0.8546583796121988, 0.8654520425451807, 0.8596220820783133, 0.8573336314006024, 0.8566115046121988, 0.8570586055158133, 0.8577204325112951, 0.8594397119728916, 0.8542818735881024, 0.857079195689006, 0.8529493952371988, 0.8589411356362951, 0.8612707666603916, 0.857567476939006, 0.8579645731362951, 0.8537730021649097, 0.8537627070783133, 0.8591852762612951, 0.8593176416603916, 0.8551466608621988, 0.8571306711219879, 0.8589617258094879, 0.8555025767131024, 0.8628576807228916, 0.8589411356362951, 0.8585955148719879, 0.8635195077183735, 0.8574865869728916, 0.8603956842996988, 0.8550348856362951, 0.8684229103915663, 0.8555128717996988, 0.8605280496987951, 0.855248141001506, 0.8635695124246988, 0.8573130412274097, 0.8618002282567772, 0.8615869728915663, 0.8616472726844879, 0.8586352244917168, 0.8625120599585843, 0.8623796945594879, 0.8629591608621988, 0.8622885095067772, 0.8698980492281627, 0.857567476939006, 0.8621561441076807, 0.8679346291415663, 0.8611795816076807, 0.8604265695594879, 0.8620237787085843, 0.8626547204442772, 0.8628885659826807, 0.8558996729103916, 0.8576498376317772, 0.8640283791415663, 0.8566718044051205, 0.8631430016942772, 0.8651064217808735, 0.8627562005835843, 0.8580057534826807, 0.8622576242469879, 0.8603353845067772, 0.8620237787085843, 0.8583513742469879, 0.865757953689759, 0.860375094126506, 0.8634283226656627, 0.8612398814006024, 0.8592058664344879, 0.8628988610692772, 0.8608339608433735, 0.858055758189006, 0.8615766778049698, 0.8648622811558735, 0.8629606315888554, 0.8636930534638554, 0.8595926675451807, 0.8612604715737951, 0.8594191217996988, 0.8642107492469879, 0.8624723503388554, 0.8589720208960843, 0.8603250894201807, 0.8652284920933735, 0.8588293604103916, 0.8635798075112951, 0.8617193382906627, 0.8602942041603916, 0.8599176981362951, 0.8670801369540663, 0.8619017083960843, 0.8670492516942772, 0.859398531626506, 0.8669374764683735], "accuracy_test": 0.7087631536989796, "start": "2016-01-29 10:47:04.613000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0], "accuracy_train_last": 0.9790042667381875, "batch_size_eval": 1024, "accuracy_train_std": [0.020177154516577055, 0.018314901874786498, 0.02008178474637277, 0.01960387854496149, 0.01835709015411707, 0.01635309149984433, 0.018608134484503294, 0.019920018024602252, 0.018436748754793883, 0.018349312594049667, 0.01689930033591296, 0.02016673391791578, 0.018601134198729483, 0.01774755583295315, 0.018732312199102034, 0.017737542743712052, 0.017830989916855437, 0.018553438594124422, 0.018634403438665105, 0.01797076936499659, 0.01751699370079268, 0.01792365873431824, 0.017815935973205663, 0.01813687341860425, 0.017154016628305534, 0.019081227669661426, 0.017558312771592303, 0.0189824031087339, 0.017805957216465263, 0.018515141694244376, 0.017901159047914703, 0.01783196373533687, 0.01667081615108321, 0.0187114979282526, 0.018051652553446713, 0.018044246305442005, 0.016418063869266128, 0.018473541427639694, 0.01783358655293646, 0.018435586163090236, 0.01707413467367291, 0.016476395450161958, 0.016469993322178255, 0.016008040487711993, 0.01669667587649103, 0.016380201904723796, 0.017131824861393814, 0.015481371742278397, 0.016605429514970745, 0.014109510017470284, 0.01669486546270619, 0.01476874395837054, 0.01420392783533626, 0.014514119303581258, 0.01466836513538611, 0.016755427509876106, 0.01603718417681982, 0.01418558258088689, 0.015811235795642125, 0.015266111505659798, 0.015316872707662663, 0.01506828300899756, 0.014886314488814193, 0.01391535102987418, 0.013558160179919976, 0.014233038922118933, 0.014900009592874635, 0.013690946538579904, 0.013257721631759107, 0.012713614349729131, 0.012600745238990357, 0.013029282074174087, 0.012716538031582793, 0.012626943029607087, 0.013073151646677567, 0.013620599385667825, 0.012729858406571808, 0.013869558100353532, 0.011216854371458152, 0.01074270639768657, 0.011217319156450882, 0.012017925823087396, 0.012409277448919384, 0.010126027622550339, 0.011533546338460382, 0.012231402031016395, 0.011515686670560092, 0.011025815447560297, 0.011578409374515111, 0.013237677649002523, 0.010757717018694619, 0.011445128748609694, 0.012315093747704675, 0.011119287404192931, 0.011398420547941336, 0.011412599290315824, 0.00989909259382303, 0.011324569334746754, 0.011487604827156302, 0.009732824068127931, 0.010655278539731467, 0.011880691784315691, 0.010362575394361888, 0.009802020081493694, 0.010225747109390455, 0.010083535333759986, 0.010016038726841557, 0.009890020203406286, 0.009854247887432672, 0.009961614832355052, 0.010887085908093624, 0.01088605102628014, 0.009766509247205218, 0.009879062826617284, 0.010228359315286989, 0.011037312208768638, 0.010947428020631702, 0.009385790416164911, 0.009557698092025675, 0.009545868016867206, 0.008693466739970618, 0.009171584773378125, 0.009226391320642601, 0.010087564287897952, 0.009257768045180354, 0.009096682147182282, 0.009894200139023958, 0.009963076900022998, 0.009268827505628905, 0.009458893289278712, 0.01041608816786293, 0.009410646918051237, 0.009577236474952894, 0.010608693697619437, 0.009267884263047137, 0.008414127504295894, 0.0111090837443535, 0.009550980896224989, 0.008622104744362476, 0.00911032187296338, 0.009128638495223405, 0.008633682881414409, 0.008845679786296632, 0.009116036435508105, 0.008347853417095263, 0.007630894583088132, 0.008053404994812031, 0.009111531419050111, 0.008288491340598687, 0.007170637371286013, 0.009440963898796803, 0.008813764462985728, 0.008901679357884966, 0.00743076731167758, 0.007433124537780343, 0.008401590761824819, 0.008184865366304167, 0.008800129997631495, 0.008240587938709897, 0.0080248461085186, 0.00750114964716143, 0.008278446065818523, 0.007759337302022384, 0.007247880680414444, 0.008428221443029574, 0.007854823527159716, 0.009874108123320482, 0.008454901654419748, 0.007185802414756616, 0.008122277077677814, 0.0086505535776255, 0.00727663854847108, 0.008389164186855667, 0.006435343274444853, 0.008672059005608218, 0.006916915128579798, 0.0076873895633795715, 0.007581223027098445, 0.007543809276965973, 0.008478440847318717, 0.006911046973664841, 0.0073353502587400424, 0.007009423285534306, 0.0076458604596191205, 0.0073993667439253095, 0.007516939960547411, 0.0071590332127725136, 0.00691983100285629, 0.007942324947972283, 0.007422179554127164, 0.007948157853435922, 0.007568096849567814, 0.006809968365370409, 0.007605172543648318, 0.0075918156016155204, 0.007208723261411255, 0.006735011316016044, 0.007850492057313285, 0.007095580741899722, 0.006522743436238861, 0.0067477359115958304, 0.00690186423191198, 0.007870585789013004, 0.0072703897667256686, 0.006643733308110783, 0.006560455928813926, 0.0078091374250161254, 0.006901582476524528, 0.007677111819620957, 0.0071359896368984686, 0.007325990077756483, 0.006947019612411259, 0.007121140001776558, 0.007816367703638001, 0.007822054895286286, 0.007492753550915202, 0.0074756612585772115, 0.007459934312967427, 0.006200031822983378, 0.0076828570092557546, 0.0062395519895773995, 0.007060820034388796, 0.005925480852153549, 0.006889325383610734, 0.007293978334582003, 0.007608225880952873, 0.007246849098137959, 0.008739018465449305, 0.006611843687971565, 0.006926152459259417, 0.007023643017535584, 0.006700339374447396, 0.006982324086775113, 0.006341845202809861, 0.007463367024970433, 0.006148425507716111, 0.007955302466964694, 0.006478930563053718, 0.007019839302331855, 0.0065378041211414505, 0.006546026919776919, 0.006709465142643596, 0.007284741692240429, 0.006240424073591358, 0.007075748335897058, 0.0058817330668569905, 0.00687884951027492, 0.006421158501159142, 0.007128354138492056, 0.0063708124419742055, 0.006656913629781397, 0.007061871593963231, 0.007121013069349876, 0.006491645327235469, 0.00583310241532679, 0.007287253900700035, 0.00824035378466542, 0.007085449891692659, 0.007236757797165169, 0.006332573900780428, 0.005824042351966919, 0.005618085162115285, 0.007117623845097978, 0.006853382085304153, 0.005310668229575972, 0.006784843982545898, 0.00708544989169266, 0.006769187759592896, 0.006243715227942818, 0.006813704481573406, 0.006703674866591076, 0.007122891390380189, 0.006424486706944982, 0.005865283337671486, 0.007071350053298537, 0.00739858587842587, 0.007277041826021614, 0.006340941171069919, 0.005439439305389415, 0.006995927563141654, 0.006072233729904209, 0.006432270323063269, 0.00799627620973632, 0.005681007338959187, 0.005726499483431499, 0.00787809774260177, 0.0067899571316572, 0.006674164669799277, 0.006765543789349789, 0.006035541720058379, 0.007827605783527106, 0.005878660167488665, 0.005904004727006832, 0.005885558138518259, 0.005395739146211798, 0.006980945936810487, 0.006732946427344344, 0.006469197698176261], "accuracy_test_std": 0.011718110905593509, "error_valid": [0.5125541227409638, 0.40725450630647586, 0.37381606504141573, 0.31900502400225905, 0.3018931193524097, 0.28059111445783136, 0.2595023649284638, 0.24568782944277112, 0.23492505176957834, 0.23136442253388556, 0.22743758236069278, 0.21921769107680722, 0.20979768684111444, 0.20847550357680722, 0.20418245246611444, 0.20196459666792166, 0.19262548239834332, 0.19376529555722888, 0.1956272355045181, 0.18797651543674698, 0.1847820971385542, 0.18024490540286142, 0.18273778708584332, 0.18432470114834332, 0.17818000517695776, 0.17969632435993976, 0.18550569465361444, 0.17685782191265065, 0.1823921663215362, 0.1797066194465362, 0.17307364222515065, 0.17785497458584332, 0.17697989222515065, 0.17316482727786142, 0.17600332972515065, 0.17275890672063254, 0.1711102221385542, 0.17313541274472888, 0.17210737481174698, 0.17089696677334332, 0.16704072147966864, 0.17448848126882532, 0.17286038685993976, 0.1637551181287651, 0.17195441923945776, 0.17066312123493976, 0.1750679475715362, 0.1675701830760542, 0.1684761506965362, 0.17114110739834332, 0.16870999623493976, 0.16246382012424698, 0.16389777861445776, 0.1684246752635542, 0.1657391283885542, 0.17437670604292166, 0.16722456231174698, 0.16564794333584332, 0.17046016095632532, 0.17210737481174698, 0.16269766566265065, 0.17190441453313254, 0.16761136342243976, 0.16820112481174698, 0.16628918015813254, 0.16992040427334332, 0.16443753529743976, 0.16540380271084332, 0.16132400696536142, 0.15966649802334332, 0.16284032614834332, 0.16035773955195776, 0.16075483574924698, 0.16121223173945776, 0.1597267978162651, 0.16309476185993976, 0.1597576830760542, 0.15998123352786142, 0.15837372929216864, 0.1561352833207832, 0.16032685429216864, 0.15827224915286142, 0.15952383753765065, 0.15479398060993976, 0.15837372929216864, 0.15565729715737953, 0.15624705854668675, 0.15994005318147586, 0.15800751835466864, 0.16231086455195776, 0.15300263554216864, 0.15627794380647586, 0.1584855045180723, 0.15483369022966864, 0.15908556099397586, 0.1565838549510542, 0.1551190112010542, 0.15739716679216864, 0.15823106880647586, 0.1583634342055723, 0.15626764871987953, 0.16156814759036142, 0.1537453525037651, 0.15290115540286142, 0.15399978821536142, 0.1524025790662651, 0.1550675357680723, 0.14558576101280118, 0.15169957172439763, 0.15124217573418675, 0.1525952442582832, 0.15522931570030118, 0.1514760212725903, 0.14730504047439763, 0.1461255176957832, 0.15295116010918675, 0.15322618599397586, 0.15150690653237953, 0.14718297016189763, 0.1474477009600903, 0.14648143354668675, 0.14487392931099397, 0.14939053087349397, 0.14870958443147586, 0.15080536991716864, 0.15261583443147586, 0.15059064382530118, 0.15011265766189763, 0.1424619375941265, 0.14669468891189763, 0.14627700254141573, 0.14991999246987953, 0.15175104715737953, 0.1456872411521084, 0.14572842149849397, 0.1458813770707832, 0.15194371234939763, 0.14965526167168675, 0.1502759083207832, 0.14938023578689763, 0.14562694135918675, 0.14288991905120485, 0.14041762754141573, 0.1448327489646084, 0.14358263130647586, 0.1435414509600903, 0.14228986257530118, 0.15063182417168675, 0.14765213196536142, 0.14225897731551207, 0.14201483669051207, 0.1467858739646084, 0.1489125447100903, 0.14493422910391573, 0.14423269248870485, 0.14245311323418675, 0.1428796239646084, 0.14918757059487953, 0.1407529532191265, 0.13835272731551207, 0.1397763907191265, 0.14716237998870485, 0.14606374717620485, 0.13497593891189763, 0.1452710255082832, 0.14102797910391573, 0.1436120458396084, 0.1406823583396084, 0.14103827419051207, 0.14320465455572284, 0.14413121234939763, 0.14017348691641573, 0.14935964561370485, 0.13666433311370485, 0.14313405967620485, 0.1366231527673193, 0.1426045980798193, 0.14253400320030118, 0.14578872129141573, 0.14276784873870485, 0.1393395849021084, 0.14106915945030118, 0.13834243222891573, 0.14437535297439763, 0.14607404226280118, 0.1387292333396084, 0.1363584219691265, 0.14018378200301207, 0.13907485410391573, 0.1431237645896084, 0.1422692724021084, 0.1418721762048193, 0.1423913427146084, 0.14167951101280118, 0.13740705007530118, 0.1408044286521084, 0.1425854786332832, 0.1447827442582832, 0.1441518025225903, 0.14445624294051207, 0.1416589208396084, 0.1425134130271084, 0.14486363422439763, 0.14534162038780118, 0.1345479574548193, 0.14037791792168675, 0.14266636859939763, 0.14338849538780118, 0.14294139448418675, 0.14227956748870485, 0.1405602880271084, 0.14571812641189763, 0.14292080431099397, 0.14705060476280118, 0.14105886436370485, 0.1387292333396084, 0.14243252306099397, 0.14203542686370485, 0.1462269978350903, 0.14623729292168675, 0.14081472373870485, 0.1406823583396084, 0.14485333913780118, 0.14286932887801207, 0.14103827419051207, 0.14449742328689763, 0.1371423192771084, 0.14105886436370485, 0.14140448512801207, 0.1364804922816265, 0.1425134130271084, 0.13960431570030118, 0.14496511436370485, 0.13157708960843373, 0.14448712820030118, 0.13947195030120485, 0.14475185899849397, 0.13643048757530118, 0.1426869587725903, 0.13819977174322284, 0.13841302710843373, 0.13835272731551207, 0.1413647755082832, 0.13748794004141573, 0.13762030544051207, 0.13704083913780118, 0.13771149049322284, 0.13010195077183728, 0.14243252306099397, 0.1378438558923193, 0.13206537085843373, 0.1388204183923193, 0.13957343044051207, 0.13797622129141573, 0.13734527955572284, 0.1371114340173193, 0.1441003270896084, 0.14235016236822284, 0.13597162085843373, 0.14332819559487953, 0.13685699830572284, 0.1348935782191265, 0.13724379941641573, 0.1419942465173193, 0.13774237575301207, 0.13966461549322284, 0.13797622129141573, 0.14164862575301207, 0.13424204631024095, 0.13962490587349397, 0.13657167733433728, 0.13876011859939763, 0.14079413356551207, 0.13710113893072284, 0.1391660391566265, 0.14194424181099397, 0.13842332219503017, 0.1351377188441265, 0.1370393684111446, 0.1363069465361446, 0.1404073324548193, 0.13873952842620485, 0.14058087820030118, 0.13578925075301207, 0.1375276496611446, 0.14102797910391573, 0.1396749105798193, 0.1347715079066265, 0.1411706395896084, 0.13642019248870485, 0.13828066170933728, 0.1397057958396084, 0.14008230186370485, 0.13291986304593373, 0.13809829160391573, 0.13295074830572284, 0.14060146837349397, 0.1330625235316265], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.7044934174277575, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00626007025834305, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "l2_decay": 1.2292809867136643e-06, "optimization": "nesterov_momentum", "nb_data_augmentation": 1, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.02032150524981351}, "accuracy_valid_max": 0.8698980492281627, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop', 'santa_sss'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8669374764683735, "loss_train": [1.6197842359542847, 1.3112128973007202, 1.1541059017181396, 1.0519077777862549, 0.9684120416641235, 0.9017136096954346, 0.8442947268486023, 0.7988040447235107, 0.7597362399101257, 0.7243604063987732, 0.6939175128936768, 0.6692459583282471, 0.6456788778305054, 0.621256411075592, 0.6035361886024475, 0.5867574214935303, 0.5707188844680786, 0.5524271130561829, 0.5368242263793945, 0.5263699293136597, 0.5131123661994934, 0.49627700448036194, 0.48811301589012146, 0.4748976230621338, 0.4648563861846924, 0.45731738209724426, 0.44588136672973633, 0.43763718008995056, 0.4259433448314667, 0.4200580418109894, 0.40983161330223083, 0.4013878107070923, 0.3955375850200653, 0.38726845383644104, 0.38112613558769226, 0.37543046474456787, 0.36862215399742126, 0.3634839355945587, 0.3581736385822296, 0.35195329785346985, 0.3446847200393677, 0.3410063683986664, 0.3345053195953369, 0.3315736949443817, 0.32479479908943176, 0.32255488634109497, 0.31818151473999023, 0.31187018752098083, 0.3058956563472748, 0.30129003524780273, 0.3002083897590637, 0.2949165999889374, 0.2910468578338623, 0.2872653305530548, 0.28694406151771545, 0.281602144241333, 0.2801242172718048, 0.27661123871803284, 0.2697502672672272, 0.2678645849227905, 0.2690000534057617, 0.2633737027645111, 0.26168468594551086, 0.2569475769996643, 0.2565264105796814, 0.2531542479991913, 0.2518768012523651, 0.24847547709941864, 0.24693413078784943, 0.24391692876815796, 0.24342156946659088, 0.23731020092964172, 0.2383754849433899, 0.2354259490966797, 0.23156136274337769, 0.23319222033023834, 0.2296782284975052, 0.22787664830684662, 0.2257111817598343, 0.2245468646287918, 0.22144445776939392, 0.22146794199943542, 0.2214937061071396, 0.2207067608833313, 0.21787960827350616, 0.21192136406898499, 0.21334615349769592, 0.211749866604805, 0.2077970653772354, 0.2094431221485138, 0.20766310393810272, 0.2075577825307846, 0.2054663598537445, 0.2016383856534958, 0.20177192986011505, 0.203299418091774, 0.1996718794107437, 0.19822728633880615, 0.19668440520763397, 0.19488941133022308, 0.19558051228523254, 0.19619162380695343, 0.19190934300422668, 0.19145064055919647, 0.19109143316745758, 0.1934196501970291, 0.18836574256420135, 0.18484553694725037, 0.18808797001838684, 0.18537284433841705, 0.1829826533794403, 0.18415124714374542, 0.18265612423419952, 0.18368488550186157, 0.17943882942199707, 0.18274693191051483, 0.1791105419397354, 0.1782858967781067, 0.17935679852962494, 0.1761450320482254, 0.1768287867307663, 0.1747022420167923, 0.17322281002998352, 0.17323902249336243, 0.17132988572120667, 0.17209145426750183, 0.16974535584449768, 0.17263126373291016, 0.166966050863266, 0.16826950013637543, 0.165325328707695, 0.16832147538661957, 0.16541363298892975, 0.16631154716014862, 0.16402514278888702, 0.16443590819835663, 0.15958848595619202, 0.164255753159523, 0.16177323460578918, 0.16191431879997253, 0.15757162868976593, 0.15978451073169708, 0.15943744778633118, 0.15679699182510376, 0.15537090599536896, 0.15919995307922363, 0.1537412405014038, 0.15615630149841309, 0.15539169311523438, 0.15230995416641235, 0.15267615020275116, 0.1535567343235016, 0.15123653411865234, 0.15166965126991272, 0.15146322548389435, 0.15088501572608948, 0.15052475035190582, 0.14688576757907867, 0.14873364567756653, 0.1504509299993515, 0.14472655951976776, 0.14691807329654694, 0.14532533288002014, 0.14545919001102448, 0.14567039906978607, 0.1471555531024933, 0.14562459290027618, 0.14436057209968567, 0.14338251948356628, 0.14277048408985138, 0.14464245736598969, 0.14098802208900452, 0.14104796946048737, 0.13887648284435272, 0.139529287815094, 0.1409551352262497, 0.13967156410217285, 0.13959680497646332, 0.1398179829120636, 0.13885876536369324, 0.14002865552902222, 0.1348249763250351, 0.13548702001571655, 0.13995809853076935, 0.13601087033748627, 0.13744433224201202, 0.1353144347667694, 0.13301566243171692, 0.13648074865341187, 0.13473288714885712, 0.13213542103767395, 0.13086232542991638, 0.1333240568637848, 0.1332762986421585, 0.1308407485485077, 0.1331094354391098, 0.1318736970424652, 0.12951026856899261, 0.12977886199951172, 0.13214685022830963, 0.13019567728042603, 0.12849320471286774, 0.12843959033489227, 0.12954193353652954, 0.1286483108997345, 0.1252557933330536, 0.12733246386051178, 0.12503404915332794, 0.12507067620754242, 0.12768322229385376, 0.1271316409111023, 0.12708105146884918, 0.12336451560258865, 0.12429875880479813, 0.12478175014257431, 0.12325567752122879, 0.12547346949577332, 0.11963693797588348, 0.12467201054096222, 0.1225631907582283, 0.12336353957653046, 0.12239652872085571, 0.1234244555234909, 0.12203729897737503, 0.12212998420000076, 0.11941506713628769, 0.118899405002594, 0.12228283286094666, 0.1206323653459549, 0.11825722455978394, 0.11766854673624039, 0.11648156493902206, 0.11972444504499435, 0.1146523505449295, 0.11922585219144821, 0.11693290621042252, 0.1157127320766449, 0.11689678579568863, 0.11591964960098267, 0.11889276653528214, 0.11301840096712112, 0.11320246756076813, 0.11731898039579391, 0.11540939658880234, 0.11510660499334335, 0.1180134192109108, 0.11269494891166687, 0.1147475615143776, 0.11339233815670013, 0.11538628488779068, 0.11365042626857758, 0.1133868470788002, 0.11330805718898773, 0.1129530817270279, 0.11130651086568832, 0.11252884566783905, 0.1129898652434349, 0.11101828515529633, 0.1113957092165947, 0.10961216688156128, 0.1128535196185112, 0.10983394831418991, 0.11091025173664093, 0.10742741078138351, 0.10985232144594193, 0.1094798892736435, 0.11136625707149506, 0.10774719715118408, 0.10714379698038101, 0.10784449428319931, 0.10732794553041458, 0.10799538344144821, 0.10922256112098694, 0.10757957398891449, 0.10485763847827911, 0.10732247680425644, 0.10756181925535202, 0.10700269043445587, 0.10534293204545975, 0.10554438084363937, 0.10854574292898178, 0.1063857153058052, 0.10412684828042984, 0.10672455281019211, 0.10787013918161392, 0.10258399695158005, 0.10684019327163696, 0.10386838763952255, 0.1041775792837143, 0.10326539725065231, 0.10365113615989685, 0.1038077175617218, 0.10111650079488754, 0.10347310453653336, 0.1035124659538269, 0.1049492284655571, 0.10286133736371994, 0.10317808389663696], "accuracy_train_first": 0.4950573464608712, "model": "residualv3", "loss_std": [0.28796207904815674, 0.2616048753261566, 0.2608347237110138, 0.25764596462249756, 0.25685110688209534, 0.2556944787502289, 0.24962776899337769, 0.24728727340698242, 0.24468031525611877, 0.24155187606811523, 0.23706991970539093, 0.23370027542114258, 0.23405174911022186, 0.228814035654068, 0.2250770479440689, 0.22436468303203583, 0.21974219381809235, 0.2171000838279724, 0.21347090601921082, 0.21208852529525757, 0.20788531005382538, 0.20262372493743896, 0.20367448031902313, 0.20181059837341309, 0.19793684780597687, 0.19692251086235046, 0.1913958638906479, 0.19231781363487244, 0.18802575767040253, 0.18474356830120087, 0.18147481977939606, 0.18041610717773438, 0.1812375783920288, 0.17677636444568634, 0.17487138509750366, 0.17427051067352295, 0.17028823494911194, 0.1693364679813385, 0.1681709885597229, 0.16694550216197968, 0.16573797166347504, 0.16351741552352905, 0.15822292864322662, 0.16179542243480682, 0.1564990133047104, 0.16008229553699493, 0.15611489117145538, 0.15259531140327454, 0.15348125994205475, 0.14818046987056732, 0.1505061835050583, 0.14732809364795685, 0.14391370117664337, 0.1467769593000412, 0.14809350669384003, 0.14176228642463684, 0.1398024559020996, 0.14075209200382233, 0.14065326750278473, 0.13797913491725922, 0.14062459766864777, 0.13678736984729767, 0.13987253606319427, 0.13470914959907532, 0.1346653401851654, 0.1356297880411148, 0.13331955671310425, 0.13249091804027557, 0.13150754570960999, 0.13128100335597992, 0.13043485581874847, 0.12796226143836975, 0.13083787262439728, 0.1305103451013565, 0.1265362650156021, 0.1263907253742218, 0.1286771446466446, 0.12434247881174088, 0.12372297048568726, 0.12263314425945282, 0.11989547312259674, 0.1244407594203949, 0.12390920519828796, 0.12266790121793747, 0.12188046425580978, 0.11899282038211823, 0.1213064193725586, 0.12072505801916122, 0.11844958364963531, 0.1194925457239151, 0.11778701096773148, 0.11986220628023148, 0.11582878977060318, 0.11644823104143143, 0.11377227306365967, 0.11550484597682953, 0.11434223502874374, 0.11644411087036133, 0.11361531913280487, 0.11495896428823471, 0.11225111782550812, 0.11590645462274551, 0.11248935014009476, 0.11296914517879486, 0.11250980943441391, 0.11499069631099701, 0.11067721247673035, 0.11284451186656952, 0.11236937344074249, 0.11247998476028442, 0.10773550719022751, 0.11004476249217987, 0.11110520362854004, 0.11083856225013733, 0.10938552767038345, 0.10814624279737473, 0.10752756148576736, 0.10769453644752502, 0.10838928818702698, 0.10690365731716156, 0.10685320198535919, 0.10772325843572617, 0.10564089566469193, 0.10515280067920685, 0.10279279947280884, 0.10632913559675217, 0.10515870898962021, 0.10661716759204865, 0.10303135216236115, 0.10522866994142532, 0.10262060910463333, 0.10607726871967316, 0.10372385382652283, 0.10201259702444077, 0.10571417957544327, 0.10530684888362885, 0.10022757202386856, 0.10005394369363785, 0.10451941192150116, 0.10044798254966736, 0.10020171850919724, 0.10165462642908096, 0.10014650225639343, 0.10015412420034409, 0.10047473013401031, 0.1002955287694931, 0.09680218994617462, 0.10202833265066147, 0.1013425886631012, 0.09691538661718369, 0.09748759120702744, 0.09611983597278595, 0.09832310676574707, 0.09858746826648712, 0.09512469917535782, 0.0971887856721878, 0.09815230220556259, 0.09628953784704208, 0.09575493633747101, 0.09725749492645264, 0.09576447308063507, 0.09732627868652344, 0.0958433449268341, 0.0963897705078125, 0.09522634744644165, 0.09840743243694305, 0.09641531854867935, 0.09571830183267593, 0.0950125902891159, 0.0921875387430191, 0.0944816991686821, 0.09439343214035034, 0.09345945715904236, 0.0926511287689209, 0.0932963490486145, 0.09160290658473969, 0.09217020869255066, 0.09270375967025757, 0.0931452065706253, 0.09211019426584244, 0.09244176000356674, 0.0895582064986229, 0.08983325213193893, 0.09476114064455032, 0.09197775274515152, 0.09291225671768188, 0.09316384792327881, 0.08683083206415176, 0.09137604385614395, 0.0916663184762001, 0.08893513679504395, 0.08707177639007568, 0.09156928956508636, 0.08855846524238586, 0.08906121551990509, 0.09296826273202896, 0.08935071527957916, 0.08977053314447403, 0.08902961760759354, 0.0894404947757721, 0.08871900290250778, 0.08855921775102615, 0.08752647042274475, 0.0905202180147171, 0.08607525378465652, 0.08646222949028015, 0.0899953842163086, 0.08735299110412598, 0.08685504645109177, 0.08798586577177048, 0.08995718508958817, 0.08723263442516327, 0.08611758053302765, 0.08671768754720688, 0.0879342257976532, 0.08546663820743561, 0.08906333148479462, 0.08220411837100983, 0.08768050372600555, 0.08614571392536163, 0.0859285444021225, 0.08695654571056366, 0.08774487674236298, 0.08460824191570282, 0.08758042752742767, 0.08602988719940186, 0.08418113738298416, 0.08537494391202927, 0.08320382237434387, 0.08453413844108582, 0.0826321691274643, 0.08270043134689331, 0.08501829206943512, 0.08230141550302505, 0.0848376601934433, 0.08452926576137543, 0.08282561600208282, 0.0819673091173172, 0.08287447690963745, 0.08704733848571777, 0.08023601770401001, 0.08076193183660507, 0.08408259600400925, 0.07978084683418274, 0.08238103240728378, 0.08438928425312042, 0.08307907730340958, 0.0811539813876152, 0.08220916241407394, 0.08426827192306519, 0.08257602155208588, 0.0832957923412323, 0.08285100013017654, 0.08087123930454254, 0.07926368713378906, 0.08021310716867447, 0.08173049241304398, 0.08293808996677399, 0.07999998331069946, 0.08161327987909317, 0.08458790183067322, 0.07971007376909256, 0.08090728521347046, 0.07907754182815552, 0.08057901263237, 0.07994523644447327, 0.07901977747678757, 0.08013563603162766, 0.07863365858793259, 0.07996317744255066, 0.07946609705686569, 0.07873529940843582, 0.07870901376008987, 0.07960305362939835, 0.07810526341199875, 0.07794908434152603, 0.07903474569320679, 0.08028896152973175, 0.07807784527540207, 0.07783687859773636, 0.08074136078357697, 0.07737293839454651, 0.07778679579496384, 0.07795637100934982, 0.07837650179862976, 0.07554855942726135, 0.08220668882131577, 0.07728516310453415, 0.0778152197599411, 0.07655666768550873, 0.07791464775800705, 0.07692816108465195, 0.07761097699403763, 0.07579964399337769, 0.07837402820587158, 0.07948654145002365, 0.07770989835262299, 0.0767727866768837]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:24 2016", "state": "available"}], "summary": "2309cf7dfa8d6a132316b1a90cd1e5dd"}