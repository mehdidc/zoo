{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 32, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.5630226135253906, 1.0801477432250977, 0.8114773631095886, 0.6772185564041138, 0.5889469385147095, 0.5213493704795837, 0.4658465087413788, 0.41869911551475525, 0.3752048909664154, 0.33526524901390076, 0.2972928285598755, 0.26179492473602295, 0.22765402495861053, 0.1959850788116455, 0.1662605255842209, 0.13816645741462708, 0.11327236145734787, 0.09127049893140793, 0.07263705879449844, 0.05718802660703659, 0.04543740302324295, 0.03567923232913017, 0.028190553188323975, 0.022947825491428375, 0.017861943691968918, 0.013938430696725845, 0.011239324696362019, 0.00819827988743782, 0.006362625397741795, 0.005078574642539024, 0.0038828046526759863, 0.003250427544116974, 0.0028996688779443502, 0.0026685127522796392, 0.0024979193694889545, 0.002365655032917857, 0.0022598467767238617, 0.0021722952369600534, 0.002099611097946763, 0.0020380921196192503, 0.0019858861342072487, 0.001940997433848679, 0.0019021256593987346, 0.0018680604407563806, 0.0018378065433353186, 0.00181113020516932, 0.0017873127944767475, 0.0017660543089732528, 0.0017468504374846816, 0.0017295079305768013, 0.0017137315589934587, 0.0016993500757962465, 0.0016861187759786844, 0.001674048020504415, 0.001662895898334682, 0.001652529346756637, 0.0016428438248112798, 0.0016337463166564703, 0.0016253568464890122, 0.0016175922937691212, 0.0016101642977446318, 0.0016032245475798845], "moving_avg_accuracy_train": [0.03596284231958286, 0.08249622568867662, 0.14814561812188537, 0.21115638247940888, 0.2703278622581845, 0.325655758162534, 0.37722931492518424, 0.42523352055083674, 0.4696042419257549, 0.5106654801893441, 0.5487294022181671, 0.5838727416428989, 0.6159945344775015, 0.6454342098595779, 0.6723762741772377, 0.6972123586631223, 0.7201600367468377, 0.7411803205340863, 0.7606751407497345, 0.7783159181914646, 0.7946715624949648, 0.809503141364516, 0.8236305232471212, 0.835696558570065, 0.8475906455321338, 0.8586442042658806, 0.8688295002071866, 0.8786542476186385, 0.8877709599461066, 0.8963363270086665, 0.9042730579971224, 0.9117206743319617, 0.9185723385571265, 0.9249318237109654, 0.9307460411529918, 0.9360532776615391, 0.9409065564787646, 0.9453093846464106, 0.9493277335687205, 0.9530000511702279, 0.956342339392537, 0.9593783005783295, 0.9621315919848283, 0.9646421063340107, 0.966915520141132, 0.9689801937580174, 0.9708570012036903, 0.972560114846472, 0.9740975674225945, 0.9754835998899143, 0.9767449800033592, 0.9779011484447453, 0.9789509645884121, 0.979912075159379, 0.9807840501196776, 0.9815758030303751, 0.98230233154286, 0.9829631826505248, 0.9835556234986137, 0.9840888202618937, 0.9845779979440838, 0.9850205830068645], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03648534567959336, 0.08244530367564004, 0.1457623614575489, 0.20541605283438436, 0.26015932730433444, 0.3105086701292474, 0.3565565300553286, 0.39850215128737104, 0.4363732216913899, 0.4708610465949166, 0.5021961462840695, 0.5305564274105571, 0.5554906248897574, 0.577616078825857, 0.5975310463856659, 0.6149652064308343, 0.6308390559402358, 0.6451397865472664, 0.6578761667498441, 0.6690204966110043, 0.6788489039340906, 0.687536808627278, 0.6954047509761465, 0.7022539654963782, 0.7089371309290446, 0.7149784528982637, 0.7200656097262836, 0.7251079180590017, 0.7295901079454961, 0.7336474633971815, 0.7375819040397675, 0.7411330486320258, 0.7442558365775581, 0.747177238518447, 0.7498187072964968, 0.7522814784154916, 0.7545701851014274, 0.7566544351812695, 0.7585048166819678, 0.7601823670638463, 0.761692162407537, 0.7630753922793586, 0.764295885101498, 0.7653566780390139, 0.7663235987140281, 0.767230448415291, 0.7680588201776776, 0.7687911182239159, 0.7694247428943707, 0.77000721212903, 0.7705680555339733, 0.7711094356921724, 0.7716088848658016, 0.7720705961533179, 0.7724739292808325, 0.7728003080018456, 0.7731439064844171, 0.7734653521499815, 0.7737546532489894, 0.7740516453318464, 0.7743067311751679, 0.7745241014029072], "moving_var_accuracy_train": [0.011639934249328625, 0.02996414273437123, 0.06575631300257911, 0.09491388952659544, 0.11693387674682634, 0.13279107365896653, 0.14345045210742266, 0.14984504071642973, 0.15257938488276232, 0.15249567398413924, 0.1502858660276722, 0.14637276817820216, 0.14102177753456416, 0.13471985016052604, 0.1277807386117457, 0.1205541445838811, 0.11323809349039751, 0.105890955115826, 0.09872229174140741, 0.09165083582600457, 0.0848933161486477, 0.07838376611965638, 0.0723416357774034, 0.06641777507539381, 0.06104922130980573, 0.05604392962494866, 0.051373198943161655, 0.04710461000413496, 0.04314217899667773, 0.03948825071325743, 0.03610635093097975, 0.03299491873952045, 0.03011793458945804, 0.027470128593309308, 0.025027361854146855, 0.022778126502951083, 0.02071230269015555, 0.01881553648400434, 0.017079306988156764, 0.01549274953843816, 0.014044012599643219, 0.012722564882573641, 0.011518533916438183, 0.01042340466547142, 0.009427579891969965, 0.00852318779707133, 0.0077025706730573995, 0.006958418970473718, 0.006283850917240777, 0.005672755599520879, 0.005119799757684139, 0.00461985031109944, 0.004167784305409028, 0.0037593194766347426, 0.0033902305919537605, 0.003056849386802765, 0.0027559150412375696, 0.0024842540547923304, 0.002238987524739456, 0.002017647461360861, 0.001818036368467551, 0.0016379956654609647], "duration": 27792.156912, "accuracy_train": [0.3596284231958287, 0.5012966760105205, 0.7389901500207641, 0.7782532616971208, 0.802871180267165, 0.8236068213016795, 0.8413913257890366, 0.8572713711817092, 0.8689407343000184, 0.8802166245616464, 0.8913047004775747, 0.9001627964654854, 0.9050906699889257, 0.9103912882982651, 0.9148548530361758, 0.9207371190360835, 0.9266891395002769, 0.9303628746193245, 0.9361285226905685, 0.9370829151670359, 0.9418723612264673, 0.9429873511904762, 0.9507769601905685, 0.9442908764765596, 0.954637428190753, 0.9581262328696014, 0.9604971636789406, 0.9670769743217055, 0.9698213708933187, 0.9734246305717055, 0.9757036368932264, 0.978749221345515, 0.9802373165836102, 0.982167190095515, 0.9830739981312293, 0.9838184062384644, 0.9845860658337948, 0.9849348381552234, 0.9854928738695091, 0.9860509095837948, 0.9864229333933187, 0.9867019512504615, 0.9869112146433187, 0.9872367354766519, 0.9873762444052234, 0.9875622563099853, 0.9877482682147471, 0.9878881376315062, 0.9879346406076966, 0.9879578920957919, 0.9880974010243633, 0.9883066644172205, 0.9883993098814139, 0.9885620702980805, 0.9886318247623662, 0.9887015792266519, 0.9888410881552234, 0.9889108426195091, 0.9888875911314139, 0.9888875911314139, 0.9889805970837948, 0.98900384857189], "end": "2016-02-03 21:07:58.399000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0], "moving_var_accuracy_valid": [0.011980624044234802, 0.0297934212907967, 0.06289552741713532, 0.0886330407293664, 0.10674117155366039, 0.11888256130439985, 0.1260779538079079, 0.12930507469199481, 0.12928252898471077, 0.12705896668542652, 0.12319006626964624, 0.11810980955284231, 0.11189425643294391, 0.10511065219655569, 0.09816904037307428, 0.09108768576409175, 0.08424672907190671, 0.07766265422776981, 0.07135632723097433, 0.06533845930036603, 0.0596739916849059, 0.054385909708036466, 0.049504459388478896, 0.04497621910552839, 0.04088057949677904, 0.037120999687323054, 0.03364181219992658, 0.030506454839833705, 0.027636619591457672, 0.02502111683166379, 0.02265832355702771, 0.02050598685256106, 0.018543154408279815, 0.01676565027115389, 0.015151881459787212, 0.01369128048806949, 0.012369296043910764, 0.011171463325077588, 0.010085132197852969, 0.009101946555621339, 0.008212267237877675, 0.007408260437994604, 0.006680840818755188, 0.006022884271786221, 0.00542901026493353, 0.004893510625866302, 0.004410335361270146, 0.003974128168999851, 0.0035803286741069467, 0.0032253492403801734, 0.0029056452242659726, 0.0026177185341206, 0.0023581917260018896, 0.00212429114921888, 0.0019133261328027483, 0.001722952227148245, 0.001551719543688449, 0.0013974775351627948, 0.0012584830377794997, 0.001133428572677068, 0.001020671334496528, 0.0009190294493900419], "accuracy_test": 0.3527961575255102, "start": "2016-02-03 13:24:46.242000", "learning_rate_per_epoch": [0.005590739659965038, 0.002795369829982519, 0.0018635798478499055, 0.0013976849149912596, 0.0011181478621438146, 0.0009317899239249527, 0.0007986770360730588, 0.0006988424574956298, 0.0006211932632140815, 0.0005590739310719073, 0.0005082490388303995, 0.00046589496196247637, 0.00043005688348785043, 0.0003993385180365294, 0.000372715963749215, 0.0003494212287478149, 0.00032886702683754265, 0.00031059663160704076, 0.0002942494465969503, 0.00027953696553595364, 0.00026622568839229643, 0.00025412451941519976, 0.00024307562853209674, 0.00023294748098123819, 0.0002236295840702951, 0.00021502844174392521, 0.00020706442592199892, 0.0001996692590182647, 0.00019278412219136953, 0.0001863579818746075, 0.00018034644017461687, 0.00017471061437390745, 0.00016941635112743825, 0.00016443351341877133, 0.00015973541303537786, 0.00015529831580352038, 0.00015110106323845685, 0.00014712472329847515, 0.00014335229934658855, 0.00013976848276797682, 0.0001363594928989187, 0.00013311284419614822, 0.0001300172007177025, 0.00012706225970759988, 0.00012423864973243326, 0.00012153781426604837, 0.00011895190255017951, 0.00011647374049061909, 0.00011409672151785344, 0.00011181479203514755, 0.00010962234227918088, 0.00010751422087196261, 0.0001054856475093402, 0.00010353221296099946, 0.00010164980631088838, 9.983462950913236e-05, 9.808314644033089e-05, 9.639206109568477e-05, 9.475829574512318e-05, 9.317899093730375e-05, 9.165146911982447e-05, 9.017322008730844e-05], "accuracy_train_first": 0.3596284231958287, "accuracy_train_last": 0.98900384857189, "batch_size_eval": 1024, "accuracy_train_std": [0.015567008375478301, 0.017846092217114133, 0.02197101095704059, 0.02334836955844378, 0.02376102602875092, 0.02320112582908487, 0.02391013278695597, 0.02277442060896844, 0.0230947034046975, 0.023426905808843577, 0.02319640505595527, 0.02276338965258506, 0.024112062039971606, 0.02414119701477187, 0.023264631725440032, 0.023829931697482955, 0.023831980754505155, 0.02322683136813708, 0.023331702033288385, 0.022152142030439453, 0.020511940475566228, 0.021879143750303778, 0.01886032598326686, 0.019319673373126456, 0.01821515010928385, 0.016193165934886716, 0.015546644833225971, 0.013128926918872769, 0.011620357066901413, 0.010344899640451951, 0.008871992032307062, 0.00828241603369823, 0.007868892965080053, 0.007181398003837441, 0.006722711231780831, 0.006320505894602992, 0.006042476226577874, 0.005869312821686448, 0.0055076034155252, 0.005252991986282154, 0.005034453134799858, 0.004832496804166479, 0.004902890231082595, 0.005036792199341699, 0.004954930637031475, 0.004732981664135677, 0.004617035732807351, 0.004630288377623643, 0.004614359920145207, 0.0043605659659748195, 0.004150103596521736, 0.004074067378696076, 0.004150601930801682, 0.004221500194564399, 0.004175694349251159, 0.0040728271147439064, 0.003976857519162955, 0.004014777534815303, 0.00395283768096599, 0.004043703096796398, 0.004051141840249088, 0.004016082172037628], "accuracy_test_std": 0.012984350955583333, "error_valid": [0.6351465432040663, 0.5039150743599398, 0.2843841185052711, 0.25770072477409633, 0.24715120246611444, 0.2363472444465362, 0.22901273060993976, 0.22398725762424698, 0.22278714467243976, 0.21874852927334332, 0.2157879565135542, 0.2142010424510542, 0.22010159779743976, 0.22325483574924698, 0.2232342455760542, 0.22812735316265065, 0.22629629847515065, 0.22615363798945776, 0.22749641142695776, 0.2306805346385542, 0.23269543015813254, 0.2342720491340362, 0.2337837678840362, 0.2361031038215362, 0.23091438017695776, 0.2306496493787651, 0.2341499788215362, 0.2295113069465362, 0.2300701830760542, 0.22983633753765065, 0.22700813017695776, 0.22690665003765065, 0.22763907191265065, 0.2265301440135542, 0.2264080737010542, 0.2255535815135542, 0.22483145472515065, 0.22458731410015065, 0.22484174981174698, 0.22471967949924698, 0.22471967949924698, 0.22447553887424698, 0.22471967949924698, 0.22509618552334332, 0.22497411521084332, 0.22460790427334332, 0.22448583396084332, 0.22461819935993976, 0.2248726350715362, 0.2247505647590362, 0.2243843538215362, 0.2240181428840362, 0.2238960725715362, 0.2237740022590362, 0.2238960725715362, 0.2242622835090362, 0.22376370717243976, 0.22364163685993976, 0.22364163685993976, 0.22327542592243976, 0.22339749623493976, 0.22351956654743976], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.010068997383166734, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.00559073945224859, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.446580638556899e-07, "rotation_range": [0, 0], "momentum": 0.5819711107289505}, "accuracy_valid_max": 0.7857989575489458, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            print(X_train.min(), X_train.max())\n            print(X_valid.min(), X_valid.max())\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7764804334525602, "accuracy_valid_std": [0.014468351879501113, 0.02562083558600159, 0.01702086129362143, 0.012401089027353773, 0.013161562925317737, 0.015366111497292745, 0.01622459973365855, 0.019447027398716864, 0.01617233655460071, 0.01689382777498441, 0.020967381349164347, 0.01890129829800742, 0.01692650606640094, 0.019501677024818944, 0.02006654745134551, 0.018629572356528838, 0.018021169368799494, 0.01892740138428308, 0.01922450620943623, 0.01857869135509267, 0.018330428810715147, 0.02014489150103467, 0.01726815961411671, 0.016106897104087553, 0.01981219230880129, 0.022546380626258175, 0.019716229090085725, 0.019064518978759375, 0.02146639209932278, 0.020554236562069613, 0.020904842631406646, 0.01879377528930819, 0.019012199935180534, 0.019222796643423582, 0.019865705885210437, 0.019759391449873338, 0.018399081266854612, 0.017720550514526354, 0.017868208911801582, 0.018275050295446845, 0.0178460151198947, 0.017522283493786785, 0.017839333986458372, 0.017707441389408215, 0.018033877306613367, 0.018179102382104496, 0.018299596905590496, 0.01847371293851556, 0.018386486041673634, 0.018070665156309052, 0.0179141118283842, 0.017416404184871274, 0.017449446752729865, 0.01715808187653116, 0.017264005628492268, 0.016774602522450537, 0.01707536165134033, 0.017135098161153675, 0.017431683449791624, 0.017169602321572237, 0.017042794711806458, 0.017214547797592506], "accuracy_valid": [0.36485345679593373, 0.49608492564006024, 0.7156158814947289, 0.7422992752259037, 0.7528487975338856, 0.7636527555534638, 0.7709872693900602, 0.776012742375753, 0.7772128553275602, 0.7812514707266567, 0.7842120434864458, 0.7857989575489458, 0.7798984022025602, 0.776745164250753, 0.7767657544239458, 0.7718726468373494, 0.7737037015248494, 0.7738463620105422, 0.7725035885730422, 0.7693194653614458, 0.7673045698418675, 0.7657279508659638, 0.7662162321159638, 0.7638968961784638, 0.7690856198230422, 0.7693503506212349, 0.7658500211784638, 0.7704886930534638, 0.7699298169239458, 0.7701636624623494, 0.7729918698230422, 0.7730933499623494, 0.7723609280873494, 0.7734698559864458, 0.7735919262989458, 0.7744464184864458, 0.7751685452748494, 0.7754126858998494, 0.775158250188253, 0.775280320500753, 0.775280320500753, 0.775524461125753, 0.775280320500753, 0.7749038144766567, 0.7750258847891567, 0.7753920957266567, 0.7755141660391567, 0.7753818006400602, 0.7751273649284638, 0.7752494352409638, 0.7756156461784638, 0.7759818571159638, 0.7761039274284638, 0.7762259977409638, 0.7761039274284638, 0.7757377164909638, 0.7762362928275602, 0.7763583631400602, 0.7763583631400602, 0.7767245740775602, 0.7766025037650602, 0.7764804334525602], "seed": 539193109, "model": "residualv4", "loss_std": [0.28987056016921997, 0.16298802196979523, 0.13751013576984406, 0.12815485894680023, 0.12292192876338959, 0.11787533015012741, 0.11279715597629547, 0.10826792567968369, 0.10415326803922653, 0.10003507137298584, 0.09573200345039368, 0.09048456698656082, 0.08420590311288834, 0.07801054418087006, 0.07113363593816757, 0.0638347864151001, 0.05647027865052223, 0.04919320344924927, 0.0419190414249897, 0.03542693704366684, 0.030091525986790657, 0.0252717025578022, 0.02014896646142006, 0.016979031264781952, 0.013464873656630516, 0.010939499363303185, 0.008703215979039669, 0.0062519400380551815, 0.0049512856639921665, 0.004318350460380316, 0.002293461700901389, 0.0007866511004976928, 0.0005792611045762897, 0.00047977420035749674, 0.0004126796848140657, 0.00036264219670556486, 0.0003223850217182189, 0.0002897474041674286, 0.00026273218099959195, 0.0002399995137238875, 0.0002209813828812912, 0.00020487449364736676, 0.00019120125216431916, 0.0001793427945813164, 0.00016895050066523254, 0.00015975907444953918, 0.00015164792421273887, 0.00014449399895966053, 0.00013805163325741887, 0.00013226976443547755, 0.00012706297275144607, 0.0001223391736857593, 0.00011798155901487917, 0.000114107780973427, 0.00011049260501749814, 0.00010709386697271839, 0.00010394853597972542, 0.00010092520824400708, 9.817616228247061e-05, 9.570430120220408e-05, 9.329255408374593e-05, 9.099954331759363e-05]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:34 2016", "state": "available"}], "summary": "27e7f81e15195a36ca7eb11f43cddc6f"}