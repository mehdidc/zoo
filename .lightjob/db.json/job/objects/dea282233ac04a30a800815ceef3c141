{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 64, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4916443824768066, 1.0815457105636597, 0.8516147136688232, 0.7475481033325195, 0.6835946440696716, 0.636530876159668, 0.602640688419342, 0.5743547677993774, 0.5505585074424744, 0.529016375541687, 0.510827898979187, 0.49630650877952576, 0.48042532801628113, 0.4690701365470886, 0.45626354217529297, 0.4435214102268219, 0.4345971345901489, 0.4259485602378845, 0.41671350598335266, 0.4084150195121765, 0.39960503578186035, 0.3927522599697113, 0.38623112440109253, 0.3798579275608063, 0.37322476506233215, 0.3676365315914154, 0.36147889494895935, 0.3569757342338562, 0.35204392671585083, 0.34813109040260315, 0.3408673107624054, 0.33823809027671814, 0.3326290249824524, 0.32809504866600037, 0.32481127977371216, 0.32047605514526367, 0.3171539306640625, 0.3133811056613922, 0.30975979566574097, 0.3078573942184448, 0.30107223987579346, 0.299201101064682, 0.29624855518341064, 0.29235178232192993, 0.28997036814689636, 0.2874165177345276, 0.2844848036766052, 0.2820889949798584, 0.27908745408058167, 0.2776503264904022, 0.27458128333091736, 0.273031622171402, 0.26907241344451904, 0.26767465472221375, 0.26521944999694824, 0.26174476742744446, 0.2604517936706543, 0.25738710165023804, 0.25804316997528076, 0.2542612850666046, 0.25317391753196716, 0.25245335698127747, 0.25129348039627075, 0.24762500822544098, 0.2444571703672409, 0.2449379414319992, 0.241893470287323, 0.23968751728534698, 0.2394879013299942, 0.23659498989582062, 0.23555949330329895, 0.2331380844116211, 0.2340642660856247, 0.23351363837718964, 0.22958236932754517, 0.22741004824638367, 0.22769202291965485, 0.2256733477115631, 0.22526875138282776, 0.22361893951892853, 0.22188030183315277, 0.22055964171886444, 0.2188078910112381, 0.21674683690071106, 0.21739928424358368, 0.21596656739711761, 0.21455799043178558, 0.21207264065742493, 0.20964990556240082, 0.20936493575572968, 0.2088100165128708, 0.20922844111919403, 0.20731019973754883, 0.20597957074642181, 0.20455428957939148, 0.20560958981513977, 0.2042844146490097, 0.2036263346672058, 0.20132587850093842, 0.2015669345855713, 0.200065478682518, 0.19833512604236603, 0.19967404007911682, 0.1960826814174652, 0.1948866844177246, 0.19413505494594574, 0.19323807954788208, 0.1932484209537506, 0.1908208280801773, 0.192687526345253, 0.19054271280765533, 0.19167852401733398, 0.18945255875587463, 0.18852637708187103, 0.18850275874137878, 0.18590612709522247, 0.18619538843631744, 0.18467776477336884, 0.18546843528747559, 0.18403974175453186, 0.18285052478313446, 0.18167586624622345, 0.182399183511734, 0.1813119351863861, 0.17952898144721985, 0.1796356588602066, 0.17968913912773132, 0.17722275853157043, 0.17689423263072968, 0.17621050775051117, 0.17641502618789673, 0.17485082149505615, 0.17480266094207764, 0.17486780881881714, 0.17427890002727509, 0.17360030114650726, 0.17322766780853271, 0.1725897341966629, 0.17089584469795227, 0.16958260536193848, 0.17123103141784668, 0.17110271751880646, 0.17018195986747742, 0.1688341647386551, 0.16848406195640564, 0.16720668971538544, 0.16653917729854584, 0.16661863029003143, 0.1644616723060608, 0.1648237407207489, 0.16427135467529297, 0.16499269008636475, 0.1636413335800171, 0.1625909060239792, 0.16362811625003815, 0.1622443050146103, 0.16217470169067383, 0.1624913066625595, 0.1625540405511856, 0.16086746752262115, 0.1596120148897171, 0.15844057500362396, 0.15920309722423553, 0.15817762911319733, 0.15726320445537567, 0.15779158473014832, 0.15580599009990692, 0.1568906009197235, 0.15668167173862457, 0.15524500608444214, 0.15519565343856812, 0.15381114184856415, 0.15511247515678406, 0.15458473563194275, 0.15344449877738953, 0.15350273251533508, 0.1535436064004898, 0.15123547613620758, 0.15275679528713226, 0.152737095952034, 0.15101732313632965, 0.15107446908950806, 0.15129925310611725, 0.14982230961322784, 0.15030719339847565, 0.14913907647132874, 0.1482083797454834], "moving_avg_accuracy_train": [0.05786442832341269, 0.11903190716996584, 0.18430375798120843, 0.24603580734573985, 0.3039313181809333, 0.3572158039396672, 0.4065226804832235, 0.4521913997687882, 0.4938140804591297, 0.5318765984756475, 0.5669930255547624, 0.5991210765545649, 0.628368530343599, 0.6549935801966051, 0.6794070597380835, 0.7017256745468518, 0.7223331530616203, 0.7410124893046922, 0.758067888353182, 0.7738013610015754, 0.7881335113482156, 0.8012417461018676, 0.8133553776182497, 0.8243783374281762, 0.8345944393511947, 0.8440888752783399, 0.8527268375163328, 0.860584600741213, 0.8677496296448048, 0.8744259481437333, 0.8805577955820362, 0.8863322606943751, 0.8915965644156815, 0.8965088599743902, 0.9009414796236381, 0.905002989018694, 0.9089676643635485, 0.9126704784631386, 0.9161169073956177, 0.9193698641562866, 0.9223557260587643, 0.9250941189959848, 0.9276354025501976, 0.930006118910857, 0.9323816872580973, 0.9344591007062909, 0.9363777090811214, 0.9382601334422507, 0.9400519355684483, 0.9417808149225024, 0.9433136269506933, 0.9447303241081987, 0.9460983575023345, 0.947329551508238, 0.9485073805778369, 0.9497279341059706, 0.9507356433312631, 0.9519077927935872, 0.9529300310310704, 0.9539104272162154, 0.9548161794662162, 0.9556569331281217, 0.9565111955761991, 0.9572986329699451, 0.9580863456350215, 0.9588255139681141, 0.9595163060559835, 0.9601427413303224, 0.9608506923034179, 0.9615064133208613, 0.9621686418496556, 0.9626740388196364, 0.9632427202378296, 0.963793988946328, 0.9643646436923374, 0.9647480246304126, 0.9651952298270243, 0.9655908832528214, 0.9660539281812768, 0.9665217497930587, 0.9670544324353383, 0.9674175172752763, 0.9678350825812481, 0.968187711966165, 0.968528257803048, 0.9688229430681012, 0.9691975859959718, 0.9696206869905515, 0.9699643115535396, 0.9702271067328571, 0.9705379190096913, 0.9708875126695842, 0.9711439821944309, 0.9714841588584779, 0.9717298639870727, 0.9720159946230185, 0.9722502246584557, 0.9724983422177578, 0.9726634111544352, 0.9728352967831777, 0.9731155158359415, 0.9733746523810387, 0.9736240792156554, 0.9738694897060962, 0.9740648906570444, 0.9742709063497841, 0.9744935949518396, 0.974756757662728, 0.9749772559632233, 0.9752129068146215, 0.9753832840975835, 0.9755574418450788, 0.9757677343380811, 0.975922156398459, 0.976086712889704, 0.9762439340829687, 0.9765110993390775, 0.9766678427124327, 0.9768391026341573, 0.9770071514077479, 0.9771699849992083, 0.9773421839660649, 0.97751351117554, 0.9776629832688111, 0.977748680027755, 0.9779071873191378, 0.9779568379290015, 0.9780177274219078, 0.9780586491703039, 0.9782117722331555, 0.9783332348504177, 0.9785424965559444, 0.9786541742778416, 0.9788174271965876, 0.9789179599937247, 0.9790106925623201, 0.9791221257574078, 0.9792269577841494, 0.9793353295987115, 0.9795072689937222, 0.9795735866968324, 0.9796030817439265, 0.9796296272863113, 0.9796976961018385, 0.9797310922989174, 0.9798262530429551, 0.9799188731590177, 0.9799998700658457, 0.9801006330188864, 0.9801564784932989, 0.9801765485345652, 0.9802433675990673, 0.9802361114904617, 0.9803249120939073, 0.9804141692810651, 0.9805455819256791, 0.9806126639832035, 0.9806615562862028, 0.9807217993517501, 0.9807875717571527, 0.980858356617244, 0.9808686206175259, 0.9809917905094463, 0.9810236244014696, 0.9811080424269004, 0.9811537917152643, 0.9812483723997732, 0.981296436830154, 0.9812953727948407, 0.9813619526249912, 0.9814427287137748, 0.9815572438234327, 0.9816255383364383, 0.981626513480277, 0.9816878089299605, 0.9817405775882287, 0.9818602571402217, 0.9818260625619969, 0.9818813900451844, 0.9819218481359964, 0.9819884513034322, 0.9820414547565146, 0.9820797851714131, 0.9821724833626975, 0.9822489362884247, 0.9823410314584933, 0.9823564877960788], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05737731198230421, 0.11794582137142318, 0.1813912618246423, 0.24065177325512987, 0.2955691766430958, 0.34678633183270186, 0.39316959271004914, 0.43596947973045985, 0.4748363224671277, 0.5108236345445866, 0.5432478069993899, 0.5726116381688033, 0.5991907181395736, 0.622812744311309, 0.6446748304317594, 0.6642998207978456, 0.6825757522158019, 0.6988999611621434, 0.71386236291867, 0.7273427905481132, 0.7395229740309525, 0.7503986604380981, 0.760285463963189, 0.76944199380934, 0.7776309540198969, 0.7853591401502867, 0.7922290584488876, 0.7981881403204898, 0.80353204748573, 0.8085582019709673, 0.8132546984625001, 0.81743168767122, 0.8210190500129082, 0.8246169755839066, 0.8276343525266454, 0.8304567665303815, 0.8332594638419518, 0.8356190819814765, 0.8379167252705276, 0.8399113620431736, 0.8417930138659647, 0.8435618017112959, 0.8451760658172748, 0.846716411748725, 0.8481016935783706, 0.8494705175375517, 0.8507146661320646, 0.8518343998671263, 0.8525816945377931, 0.8533417679774625, 0.854208939541915, 0.8548937967172415, 0.8558174029736048, 0.8565601108596027, 0.8570210284257509, 0.8577329410199228, 0.8582607105474486, 0.8588099748183814, 0.8594152054521307, 0.8597015063489356, 0.8602053767983794, 0.8606323871230595, 0.8611052341600005, 0.861690517408157, 0.8622071243175673, 0.8624014568312173, 0.862525468951183, 0.8628812204841521, 0.8630172618864146, 0.8631864682561315, 0.8633397834975364, 0.8635551274369393, 0.8638079131213328, 0.8639754145896964, 0.8642594137463141, 0.86430749345602, 0.864238842896186, 0.8644853216995644, 0.864609496372605, 0.8647792002086125, 0.8648576619648598, 0.8647085509829823, 0.8648459943127714, 0.8650561720369913, 0.8650011913637892, 0.8650584835131783, 0.8653450685673574, 0.865492102326209, 0.8655745750755158, 0.8656864511523016, 0.865972304107478, 0.8662326602931159, 0.8663285854818012, 0.8664138886429584, 0.8665771402154095, 0.8665765527469559, 0.8667632475287361, 0.8669525983688595, 0.8668534299288109, 0.866901544202496, 0.8668817528752433, 0.8670613121980353, 0.8671730579548884, 0.8670375775076676, 0.8669909463099882, 0.8673091591902846, 0.8674825989753224, 0.8675797186429257, 0.8678115517014494, 0.8679326932180514, 0.8680448091089722, 0.8682667542146413, 0.8684929778895626, 0.8684971486623533, 0.8684419262189342, 0.8683789894799475, 0.8685542800086093, 0.8684679008594051, 0.8686607733299404, 0.8686827266351241, 0.8685580592521087, 0.8687408863747141, 0.8686449650941704, 0.8687204158739099, 0.8686397781833564, 0.8687035406229273, 0.8688474055459509, 0.8688781982180124, 0.8689557692565274, 0.8690866183474409, 0.8690436321056938, 0.8691545173891003, 0.8694272715989855, 0.8696228927542226, 0.8697857152540261, 0.8698234217312591, 0.870152385328088, 0.8699570827892551, 0.8698779372456459, 0.8699796637112168, 0.8700345964364806, 0.870160366602697, 0.8700751587263128, 0.870181577106317, 0.8702773536483208, 0.8701672105274646, 0.870348843437444, 0.8704899580112447, 0.8705538669540962, 0.8707609579036414, 0.8708964526159128, 0.8710560484593667, 0.8710145202324059, 0.8711256882204604, 0.8712358874236403, 0.8713360962151618, 0.8715005558236908, 0.8716109188689573, 0.871685831547197, 0.8717044248326129, 0.8715482013346679, 0.8713709790927674, 0.8713478154361262, 0.871363589238899, 0.871511033496485, 0.871498278461972, 0.8715844551809103, 0.8715521509467048, 0.8716441179397602, 0.8715793743498503, 0.8715200756102719, 0.871467736253311, 0.8714959320368654, 0.8713615873271547, 0.8712518546110056, 0.8714125313487002, 0.8713241773102157, 0.8712690727380797, 0.8713781700294072, 0.8715495997791021, 0.8715574021788274, 0.8713935259010801, 0.8713904626087884, 0.8713887351543854, 0.8714349790617631, 0.8713799718370627, 0.8714037075223323], "moving_var_accuracy_train": [0.030134628586758288, 0.060794309944074205, 0.0930586095245928, 0.11805036184083803, 0.13641233723056626, 0.14832423131066408, 0.15537232084993127, 0.1586057760555915, 0.15833722638068354, 0.15554230124243487, 0.1510865421754165, 0.14526779290728803, 0.1384397355948344, 0.1309758015524266, 0.12324238324708355, 0.11540123002521471, 0.10768312055932305, 0.10005506692572644, 0.09266753996348284, 0.08562866542133428, 0.07891449368122914, 0.0725694766783179, 0.06663318962711827, 0.06106342145114776, 0.0558963979525465, 0.051118056979463845, 0.04667778080614238, 0.04256570271161266, 0.03877117119315516, 0.03529521313213186, 0.03210408779597827, 0.029193779042383034, 0.026523817181176166, 0.024088611291963533, 0.02185658321536127, 0.019819387620920288, 0.017978916714139134, 0.016304422533030334, 0.01478088113120696, 0.013398028567267298, 0.012138464052246577, 0.0109921068099295, 0.009951019227862767, 0.009006499969640777, 0.008156639897428387, 0.0073798167273981695, 0.006674964577522081, 0.00603935981304823, 0.005464318825478423, 0.0049447881573184485, 0.004471454956010504, 0.004042372737934209, 0.003654979102448026, 0.003303123740324778, 0.002985296898147029, 0.0027001749665676814, 0.002439296770855571, 0.002207732503028253, 0.0019963639918529844, 0.0018053781827863094, 0.0016322238487531126, 0.001475363264357869, 0.00133439481689384, 0.00120653585404608, 0.0010914666898259675, 0.0009872373492651918, 0.0008928083577166378, 0.0008070593123213985, 0.0007308641323120202, 0.000661647449555271, 0.0005994296242188851, 0.0005417854966723897, 0.0004905175340037352, 0.0004442008553040864, 0.0004027115913259664, 0.0003637632606864848, 0.0003291868670087253, 0.000297677055007957, 0.00026983904495907576, 0.00024482485400721996, 0.00022289612578297156, 0.00020179298861360917, 0.00018318293681501033, 0.0001659837704814712, 0.00015042913663648885, 0.00013616777762179557, 0.00012381421577024692, 0.00011304392425775065, 0.00010280223239457408, 9.314356091156939e-05, 8.469864326329052e-05, 7.732872048029671e-05, 7.018783798684278e-05, 6.421053565301864e-05, 5.833282117967691e-05, 5.323637572914962e-05, 4.840651154174272e-05, 4.411992129667466e-05, 3.995315895170985e-05, 3.622374508085277e-05, 3.330807503055412e-05, 3.058163326854316e-05, 2.8083393654130925e-05, 2.581709106808307e-05, 2.357901574595771e-05, 2.1603096362256854e-05, 1.9889098647400282e-05, 1.8523480294279393e-05, 1.710870776954361e-05, 1.5897618906471642e-05, 1.4569112782770093e-05, 1.3385179793606654e-05, 1.244466820776398e-05, 1.1414816941569876e-05, 1.0517044796710398e-05, 9.687806849543665e-06, 9.361421631234494e-06, 8.646395833927584e-06, 8.045725897636898e-06, 7.495316820620784e-06, 6.984418145129595e-06, 6.552848688294872e-06, 6.161740933824081e-06, 5.746644000443075e-06, 5.238075010840203e-06, 4.940388562549952e-06, 4.468536353833418e-06, 4.055050491567691e-06, 3.664616747837096e-06, 3.50917512444654e-06, 3.291036118531416e-06, 3.356046659277753e-06, 3.132689215463419e-06, 3.059283933228612e-06, 2.8443171296076346e-06, 2.637279380151592e-06, 2.4853076548434383e-06, 2.3356846738360284e-06, 2.207816258175904e-06, 2.253103032368198e-06, 2.0673750688437465e-06, 1.8684671821871546e-06, 1.6879624563529423e-06, 1.5608664835431586e-06, 1.4148175890028839e-06, 1.3548359349549594e-06, 1.296558714554417e-06, 1.2259473333403322e-06, 1.1947311543557438e-06, 1.103326492031463e-06, 9.966191018361823e-07, 9.371402780810264e-07, 8.439001102817788e-07, 8.304800238041906e-07, 8.191336305576909e-07, 8.926438159820485e-07, 8.438794563591699e-07, 7.810056263564546e-07, 7.355681062396413e-07, 7.009453794277796e-07, 6.759453092483079e-07, 6.092989256395544e-07, 6.849064335566272e-07, 6.255363603330921e-07, 6.271203514583915e-07, 5.832452927847396e-07, 6.054303164459968e-07, 5.656789900118167e-07, 5.091212805509667e-07, 4.981050165416743e-07, 5.070175035601493e-07, 5.743391462639009e-07, 5.588824961975102e-07, 5.030028047273133e-07, 4.865167136218496e-07, 4.6292582391855357e-07, 5.455419980137329e-07, 5.015112208321346e-07, 4.789102723117196e-07, 4.457509590898661e-07, 4.4109970039320743e-07, 4.2227402470180816e-07, 3.932696085882963e-07, 4.312792397358934e-07, 4.4075676443266956e-07, 4.730147711390174e-07, 4.278633793691335e-07], "duration": 246216.096787, "accuracy_train": [0.578644283234127, 0.6695392167889442, 0.771750415282392, 0.8016242516265227, 0.8249909156976744, 0.8367761757682725, 0.8502845693752308, 0.8632098733388703, 0.8684182066722037, 0.8744392606243078, 0.8830408692667959, 0.8882735355527871, 0.8915956144449059, 0.8946190288736618, 0.8991283756113879, 0.9025932078257659, 0.9078004596945367, 0.9091265154923404, 0.9115664797895902, 0.9154026148371169, 0.9171228644679772, 0.919215858884736, 0.9223780612656883, 0.9235849757175157, 0.9265393566583611, 0.9295387986226468, 0.9304684976582688, 0.9313044697651348, 0.9322348897771319, 0.9345128146340901, 0.9357444225267626, 0.9383024467054264, 0.9389752979074382, 0.9407195200027685, 0.9408350564668696, 0.9415565735741971, 0.9446497424672389, 0.9459958053594499, 0.9471347677879292, 0.948646475002307, 0.9492284831810631, 0.9497396554309707, 0.9505069545381136, 0.9513425661567922, 0.9537618023832595, 0.9531558217400333, 0.9536451844545959, 0.9552019526924143, 0.9561781547042267, 0.9573407291089886, 0.9571089352044113, 0.9574805985257475, 0.958410658049557, 0.9584102975613695, 0.9591078422042267, 0.9607129158591732, 0.9598050263588963, 0.9624571379545036, 0.9621301751684201, 0.9627339928825213, 0.9629679497162238, 0.9632237160852714, 0.9641995576088963, 0.9643855695136582, 0.9651757596207088, 0.9654780289659468, 0.965733434846807, 0.9657806587993725, 0.9672222510612772, 0.9674079024778516, 0.968128698608804, 0.9672226115494648, 0.9683608530015688, 0.9687554073228128, 0.9695005364064231, 0.9681984530730897, 0.9692200765965301, 0.9691517640849945, 0.9702213325373754, 0.9707321442990956, 0.9718485762158545, 0.9706852808347176, 0.9715931703349945, 0.9713613764304172, 0.9715931703349945, 0.9714751104535806, 0.972569372346807, 0.9734285959417681, 0.9730569326204319, 0.9725922633467147, 0.9733352295011997, 0.9740338556086194, 0.973452207918051, 0.9745457488349022, 0.973941210144426, 0.9745911703465301, 0.9743582949773901, 0.9747314002514765, 0.974149031584533, 0.9743822674418604, 0.9756374873108158, 0.975706881286914, 0.9758689207272055, 0.9760781841200628, 0.9758234992155776, 0.9761250475844407, 0.9764977923703396, 0.9771252220607235, 0.9769617406676817, 0.9773337644772055, 0.9769166796442414, 0.977124861572536, 0.9776603667751015, 0.9773119549418604, 0.9775677213109081, 0.9776589248223514, 0.9789155866440569, 0.9780785330726283, 0.9783804419296788, 0.9785195903700628, 0.9786354873223514, 0.978891974667774, 0.9790554560608158, 0.9790082321082503, 0.9785199508582503, 0.9793337529415835, 0.978403693417774, 0.9785657328580657, 0.9784269449058692, 0.9795898797988187, 0.9794263984057769, 0.9804258519056847, 0.9796592737749169, 0.9802867034653008, 0.9798227551679586, 0.9798452856796788, 0.9801250245131967, 0.9801704460248246, 0.9803106759297711, 0.9810547235488187, 0.9801704460248246, 0.979868537167774, 0.979868537167774, 0.9803103154415835, 0.9800316580726283, 0.9806826997392949, 0.9807524542035806, 0.9807288422272978, 0.9810074995962532, 0.9806590877630121, 0.9803571789059615, 0.9808447391795865, 0.9801708065130121, 0.9811241175249169, 0.9812174839654854, 0.9817282957272055, 0.9812164025009228, 0.9811015870131967, 0.9812639869416758, 0.9813795234057769, 0.9814954203580657, 0.9809609966200628, 0.9821003195367294, 0.9813101294296788, 0.9818678046557769, 0.9815655353105389, 0.9820995985603543, 0.9817290167035806, 0.981285796477021, 0.9819611710963455, 0.9821697135128276, 0.9825878798103543, 0.9822401889534883, 0.9816352897748246, 0.9822394679771133, 0.9822154955126431, 0.982937373108158, 0.9815183113579733, 0.9823793373938722, 0.9822859709533037, 0.9825878798103543, 0.9825184858342562, 0.9824247589055003, 0.9830067670842562, 0.9829370126199704, 0.9831698879891103, 0.9824955948343485], "end": "2016-02-04 06:10:41.164000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0], "moving_var_accuracy_valid": [0.02962940337283204, 0.05968336200212697, 0.08994294103064103, 0.11255492086260346, 0.12844271953023229, 0.1392072204486548, 0.14464916041033382, 0.14667071732993978, 0.14559932877579765, 0.14269517557326167, 0.13788760065034497, 0.13185895181382282, 0.12503108406127394, 0.11754997673926992, 0.11009653635118485, 0.10255314493788713, 0.09530391746684304, 0.08817184389967309, 0.08136952070661918, 0.07486806599761119, 0.06871647122493074, 0.06290934909587684, 0.05749815414178289, 0.05250291707701568, 0.04785615699328488, 0.043608065041749945, 0.03967202053444001, 0.03602441439176813, 0.032678989046707664, 0.02963845020222213, 0.026873118895654736, 0.024342832155737123, 0.022024371457298478, 0.019938439927298626, 0.018026537007099913, 0.01629557749366629, 0.014736715754282212, 0.013313154358733356, 0.012029351405013516, 0.010862223447205293, 0.00980786662472468, 0.008855237456228337, 0.007993166348040167, 0.007215203703532969, 0.006510954384907588, 0.005876722057697881, 0.0053029810034551485, 0.0047839671358465485, 0.004310596466185158, 0.003884736224269861, 0.0035030304805426307, 0.003156948696643734, 0.0028489312636304997, 0.0025690026723027616, 0.002314014410097541, 0.002087174344963452, 0.0018809637765347701, 0.0016955826200352037, 0.0015293210951119395, 0.0013771266994323478, 0.0012416989983575172, 0.0011191701388782165, 0.0010092653838734901, 0.0009114218538112956, 0.0008226816127198192, 0.0007407533375805907, 0.000666816414875617, 0.0006012738057669438, 0.0005413129905584153, 0.00048743936866254894, 0.00043890698186551747, 0.0003954336407891041, 0.00035646538213030194, 0.00032107135459440774, 0.0002896901188236031, 0.00026074191186761147, 0.00023471013677513991, 0.00021178588930225947, 0.00019074607451685606, 0.00017193066159277163, 0.00015479300165823498, 0.0001395138082566599, 0.0001257324434511256, 0.00011355677118783712, 0.00010222829993888526, 9.20350114584314e-05, 8.357068925209809e-05, 7.540819066306659e-05, 6.792858738616395e-05, 6.124837495656034e-05, 5.585894466875239e-05, 5.08831182924756e-05, 4.587762123964701e-05, 4.1355348779413045e-05, 3.745967358464167e-05, 3.3713709332250164e-05, 3.065603287292116e-05, 2.7913113251527875e-05, 2.5210311341890143e-05, 2.271011505769141e-05, 2.044262882163205e-05, 1.8688539893082346e-05, 1.6932069931346155e-05, 1.54040575024238e-05, 1.3883221969554568e-05, 1.3406234707277666e-05, 1.2336343467855555e-05, 1.1187599189588373e-05, 1.0552558373849617e-05, 9.629379939866441e-06, 8.779571702852402e-06, 8.344951201941176e-06, 7.971050441601614e-06, 7.174101955552499e-06, 6.484137424311788e-06, 5.871372979909244e-06, 5.5607766068653655e-06, 5.071851162934171e-06, 4.899464155654619e-06, 4.4138552685655446e-06, 4.112347349200237e-06, 4.001944425121739e-06, 3.6845580111598513e-06, 3.3673375915136743e-06, 3.0891257666027388e-06, 2.816804028242866e-06, 2.7213976701077016e-06, 2.4577916009711385e-06, 2.266167835020734e-06, 2.1936444128547386e-06, 1.9909103243851336e-06, 1.9024792066319295e-06, 2.381785017059393e-06, 2.488015242739732e-06, 2.4778142164465534e-06, 2.242828800629748e-06, 2.9924993529142542e-06, 3.0365371526940018e-06, 2.78925959108342e-06, 2.6034680961530987e-06, 2.370279725282021e-06, 2.2756149651447247e-06, 2.1133969084113376e-06, 2.0039810619947818e-06, 1.8861412697792192e-06, 1.806710706448737e-06, 1.9229542616922818e-06, 1.90987874197385e-06, 1.7556500445639508e-06, 1.966064992559339e-06, 1.934687846784995e-06, 1.9704565613363706e-06, 1.788932247913274e-06, 1.72126391723491e-06, 1.658432304944703e-06, 1.5829652915340379e-06, 1.6680914279182473e-06, 1.6109023009708018e-06, 1.5003192551232807e-06, 1.3533987219739445e-06, 1.4377108815681512e-06, 1.5766093006295548e-06, 1.4237773654675217e-06, 1.2836389446060422e-06, 1.350933332001239e-06, 1.2173042169499562e-06, 1.1624116372377563e-06, 1.05556254544241e-06, 1.0261276412030855e-06, 9.612404689923815e-07, 8.967634867334301e-07, 8.317418126438283e-07, 7.557226512716867e-07, 8.425868953896239e-07, 8.66699626792004e-07, 1.0123827904384802e-06, 9.814024364432892e-07, 9.10590817631621e-07, 9.266517066435732e-07, 1.09847996770306e-06, 9.89179867906019e-07, 1.1319607907898987e-06, 1.0188491655478906e-06, 9.169911058815294e-07, 8.44538486019417e-07, 7.873167903406469e-07, 7.136555561035546e-07], "accuracy_test": 0.8583844866071428, "start": "2016-02-01 09:47:05.067000", "learning_rate_per_epoch": [0.007148173172026873, 0.0035740865860134363, 0.0023827243130654097, 0.0017870432930067182, 0.0014296346344053745, 0.0011913621565327048, 0.0010211676126345992, 0.0008935216465033591, 0.0007942414376884699, 0.0007148173172026873, 0.0006498339353129268, 0.0005956810782663524, 0.0005498594837263227, 0.0005105838063172996, 0.000476544868433848, 0.00044676082325167954, 0.00042048076284117997, 0.00039712071884423494, 0.0003762196283787489, 0.00035740865860134363, 0.00034038920421153307, 0.0003249169676564634, 0.0003107901429757476, 0.0002978405391331762, 0.0002859269152395427, 0.0002749297418631613, 0.00026474715559743345, 0.0002552919031586498, 0.0002464887220412493, 0.000238272434216924, 0.00023058622900862247, 0.00022338041162583977, 0.0002166113117709756, 0.00021024038142058998, 0.0002042335254373029, 0.00019856035942211747, 0.0001931938750203699, 0.00018810981418937445, 0.00018328649457544088, 0.00017870432930067182, 0.00017434568144381046, 0.00017019460210576653, 0.00016623658302705735, 0.0001624584838282317, 0.00015884829917922616, 0.0001553950714878738, 0.00015208878903649747, 0.0001489202695665881, 0.00014588108751922846, 0.00014296345761977136, 0.00014016026398167014, 0.00013746487093158066, 0.00013487119576893747, 0.00013237357779871672, 0.00012996677833143622, 0.0001276459515793249, 0.0001254065427929163, 0.00012324436102062464, 0.00012115547724533826, 0.000119136217108462, 0.00011718316818587482, 0.00011529311450431123, 0.00011346306564519182, 0.00011169020581291988, 0.00010997189383488148, 0.0001083056558854878, 0.00010668914910638705, 0.00010512019071029499, 0.0001035967143252492, 0.00010211676271865144, 0.00010067849507322535, 9.928017971105874e-05, 9.792017954168841e-05, 9.659693751018494e-05, 9.530897659715265e-05, 9.405490709468722e-05, 9.283341933041811e-05, 9.164324728772044e-05, 9.048320498550311e-05, 8.935216465033591e-05, 8.824904944049194e-05, 8.717284072190523e-05, 8.612257079221308e-05, 8.509730105288327e-05, 8.409615111304447e-05, 8.311829151352867e-05, 8.216290734708309e-05, 8.122924191411585e-05, 8.031655306695029e-05, 7.942414958961308e-05, 7.855135481804609e-05, 7.76975357439369e-05, 7.686207391088828e-05, 7.604439451824874e-05, 7.524393004132435e-05, 7.446013478329405e-05, 7.369250670308247e-05, 7.294054375961423e-05, 7.220376573968679e-05, 7.148172880988568e-05, 7.077398913679644e-05, 7.008013199083507e-05, 6.939974264241755e-05, 6.873243546579033e-05, 6.807783938711509e-05, 6.743559788446873e-05, 6.680535443592817e-05, 6.618678889935836e-05, 6.557956658070907e-05, 6.498338916571811e-05, 6.43979583401233e-05, 6.382297578966245e-05, 6.325817230390385e-05, 6.270327139645815e-05, 6.215802568476647e-05, 6.162218051031232e-05, 6.109549576649442e-05, 6.057773862266913e-05, 6.00686835241504e-05, 5.9568108554231e-05, 5.907580998609774e-05, 5.859158409293741e-05, 5.811522714793682e-05, 5.764655725215562e-05, 5.718538523069583e-05, 5.673153282259591e-05, 5.6284829042851925e-05, 5.584510290645994e-05, 5.541219434235245e-05, 5.498594691744074e-05, 5.456620783661492e-05, 5.41528279427439e-05, 5.3745661716675386e-05, 5.3344574553193524e-05, 5.294943184708245e-05, 5.2560095355147496e-05, 5.2176445024088025e-05, 5.17983571626246e-05, 5.1425704441498965e-05, 5.105838135932572e-05, 5.069626422482543e-05, 5.0339247536612675e-05, 4.998722579330206e-05, 4.964008985552937e-05, 4.9297745135845616e-05, 4.8960089770844206e-05, 4.862702917307615e-05, 4.829846875509247e-05, 4.7974317567422986e-05, 4.7654488298576325e-05, 4.733889363706112e-05, 4.702745354734361e-05, 4.672008435591124e-05, 4.6416709665209055e-05, 4.6117245801724494e-05, 4.582162364386022e-05, 4.552976679406129e-05, 4.5241602492751554e-05, 4.495706525631249e-05, 4.4676082325167954e-05, 4.4398591853678226e-05, 4.412452472024597e-05, 4.385382271721028e-05, 4.3586420360952616e-05, 4.332226308179088e-05, 4.306128539610654e-05, 4.2803432734217495e-05, 4.2548650526441634e-05, 4.229688420309685e-05, 4.2048075556522235e-05, 4.18021809309721e-05, 4.155914575676434e-05, 4.131891910219565e-05, 4.1081453673541546e-05, 4.084670217707753e-05, 4.061462095705792e-05, 4.038515908177942e-05, 4.0158276533475146e-05, 3.9933929656399414e-05, 3.971207479480654e-05, 3.949266829295084e-05, 3.9275677409023046e-05, 3.906105484929867e-05, 3.884876787196845e-05, 3.863877282128669e-05, 3.843103695544414e-05, 3.8225523894652724e-05], "accuracy_train_first": 0.578644283234127, "accuracy_train_last": 0.9824955948343485, "batch_size_eval": 1024, "accuracy_train_std": [0.012949928534886888, 0.014475251196106324, 0.018035512237095763, 0.01982249382779892, 0.017977423242727768, 0.018738172881376514, 0.016412111676290513, 0.016666982466035516, 0.016487599992342606, 0.015118840286084251, 0.01611179177866734, 0.01609123970292043, 0.01507010127953802, 0.015057881932119157, 0.014183472021344776, 0.014201815017459398, 0.013779002359980171, 0.013789956357930715, 0.01445279332569858, 0.012886978092344393, 0.013120001787653929, 0.013309542095564396, 0.013113840897248397, 0.013901933516346752, 0.012871724566080326, 0.012093628725121926, 0.012511340199600837, 0.01156104933889659, 0.010882394395260153, 0.011404594811186913, 0.011173725174985497, 0.011282267701401553, 0.010877404035255233, 0.011091051867595302, 0.010411898302696287, 0.01065007725738263, 0.010653000390582897, 0.010367035938028327, 0.009999807267860173, 0.009618352773913213, 0.00910440093325683, 0.00932581581103911, 0.009153627483207288, 0.009013450732095918, 0.00865333776631094, 0.008597040436822252, 0.008635582159419106, 0.008694299629069768, 0.008850240698821009, 0.008329261579821437, 0.007934848333900686, 0.00772998061959013, 0.007749188516730784, 0.007522010531596973, 0.007829433585708735, 0.007386986678561987, 0.006941062418447042, 0.007203314609551475, 0.007089683353917956, 0.007902225998618504, 0.0066545579097255616, 0.0070204800381967625, 0.006510357104004856, 0.006835378029398602, 0.006444789870741877, 0.006391965740426536, 0.0071544755649175125, 0.006796378686665864, 0.007057812029894455, 0.00674989528934016, 0.006670928334266797, 0.006562050286539616, 0.006594760274009138, 0.006465472823437487, 0.00671366598041476, 0.0062719923076170235, 0.00612102565901155, 0.006477321132674179, 0.006841758287591515, 0.006977358693685203, 0.006215130185592632, 0.006458545324354967, 0.00585131136276933, 0.006279887003091635, 0.006212688522848269, 0.006562074340353275, 0.006319107678128562, 0.006096352444890469, 0.006137698825750345, 0.006144804033645239, 0.006138605818916338, 0.00646637648940033, 0.005946353116982027, 0.0059223467849121815, 0.005907983905829175, 0.0057224600377340645, 0.00603173806005981, 0.0061789498182817015, 0.005611356706900373, 0.006667654759090209, 0.0058411868847796635, 0.005839953645874408, 0.005427919144934671, 0.0062191539987787965, 0.005658807137227628, 0.005960435817518129, 0.00547291350141158, 0.005736577562028288, 0.005169002187033926, 0.005592724266576583, 0.005413705013559274, 0.005154519232667307, 0.005902288388017246, 0.005964091651755486, 0.006090736431939599, 0.005965604394375189, 0.005541473644886568, 0.0054602199525002025, 0.005918149879429623, 0.0053869835480453, 0.005806845911090592, 0.005397561896295135, 0.005629336134941959, 0.005673522679107745, 0.005032331301696875, 0.005178046368262214, 0.005589119165352687, 0.005994484894826298, 0.00569218329492389, 0.00553167522756725, 0.005400599977979206, 0.005065282417435467, 0.005647619932214084, 0.005403521270143842, 0.005429320861893499, 0.005375166451898039, 0.005075197640134412, 0.0055864561350019585, 0.005262233812356011, 0.004969241029492498, 0.004948470356662881, 0.005471988725389543, 0.004935266345437783, 0.0050529347407986674, 0.005404195229078101, 0.0052817973200480995, 0.005289253444730867, 0.005598918478051404, 0.005236372249014434, 0.005243709637926543, 0.005458263907334751, 0.005410311215195551, 0.004687395316784079, 0.005010492778161837, 0.004527965975248636, 0.005411062545883887, 0.0050145144346613055, 0.005011186596999173, 0.0049971975045295155, 0.004933275357267636, 0.00508242332782978, 0.005113761815420615, 0.00541238835133531, 0.004820494573592067, 0.005252782173919224, 0.005121955589829086, 0.00462352231991258, 0.0049696386658205005, 0.0051590788621591254, 0.005315754657307449, 0.004701825170501212, 0.005006356123245491, 0.0048227996742375625, 0.005082005528388806, 0.0045003145363523055, 0.004423206825633607, 0.00514758677890195, 0.005509998400594294, 0.005026225962814161, 0.004962588775634244, 0.004673250922222214, 0.004753192168616074, 0.004561884364974834, 0.005041455995200309, 0.004896087512930753, 0.004590445341188962, 0.004932378176717861], "accuracy_test_std": 0.008307859189761497, "error_valid": [0.42622688017695776, 0.33693759412650603, 0.24759977409638556, 0.2260036238704819, 0.21017419286521077, 0.19225927146084332, 0.18938105939382532, 0.17883153708584332, 0.17536209290286142, 0.1652905567582832, 0.16493464090737953, 0.16311388130647586, 0.16159756212349397, 0.1645890201430723, 0.15856639448418675, 0.15907526590737953, 0.1529408650225903, 0.1541821583207832, 0.1514760212725903, 0.15133336078689763, 0.15085537462349397, 0.1517201618975903, 0.15073330431099397, 0.14814923757530118, 0.1486684040850903, 0.14508718467620485, 0.14594167686370485, 0.1481801228350903, 0.1483727880271084, 0.14620640766189763, 0.14447683311370485, 0.14497540945030118, 0.14669468891189763, 0.1430016942771084, 0.14520925498870485, 0.14414150743599397, 0.14151626035391573, 0.14314435476280118, 0.14140448512801207, 0.14213690700301207, 0.14127211972891573, 0.14051910768072284, 0.14029555722891573, 0.13942047486822284, 0.1394307699548193, 0.1382100668298193, 0.1380879965173193, 0.1380879965173193, 0.14069265342620485, 0.13981757106551207, 0.13798651637801207, 0.1389424887048193, 0.1358701407191265, 0.13675551816641573, 0.13883071347891573, 0.13585984563253017, 0.1369893637048193, 0.13624664674322284, 0.1351377188441265, 0.1377217855798193, 0.1352597891566265, 0.1355245199548193, 0.13463914250753017, 0.13304193335843373, 0.13314341349774095, 0.13584955054593373, 0.1363584219691265, 0.1339170157191265, 0.13575836549322284, 0.13529067441641573, 0.1352803793298193, 0.13450677710843373, 0.1339170157191265, 0.13451707219503017, 0.1331845938441265, 0.1352597891566265, 0.1363790121423193, 0.13329636907003017, 0.13427293157003017, 0.1336934652673193, 0.13443618222891573, 0.13663344785391573, 0.1339170157191265, 0.13305222844503017, 0.13549363469503017, 0.1344258871423193, 0.13207566594503017, 0.1331845938441265, 0.13368317018072284, 0.1333066641566265, 0.13145501929593373, 0.1314241340361446, 0.13280808782003017, 0.1328183829066265, 0.13195359563253017, 0.1334287344691265, 0.13155649943524095, 0.13134324407003017, 0.1340390860316265, 0.13266542733433728, 0.13329636907003017, 0.13132265389683728, 0.13182123023343373, 0.1341817465173193, 0.1334287344691265, 0.12982692488704817, 0.13095644295933728, 0.1315462043486446, 0.13010195077183728, 0.13097703313253017, 0.13094614787274095, 0.12973573983433728, 0.1294710090361446, 0.13146531438253017, 0.13205507577183728, 0.13218744117093373, 0.12986810523343373, 0.13230951148343373, 0.12960337443524095, 0.13111969361822284, 0.13256394719503017, 0.12961366952183728, 0.13221832643072284, 0.13060052710843373, 0.1320859610316265, 0.13072259742093373, 0.12985781014683728, 0.13084466773343373, 0.13034609139683728, 0.12973573983433728, 0.13134324407003017, 0.12984751506024095, 0.12811794051204817, 0.1286165168486446, 0.12874888224774095, 0.1298372199736446, 0.12688694230045183, 0.13180064006024095, 0.13083437264683728, 0.1291047980986446, 0.1294710090361446, 0.1287077019013554, 0.1306917121611446, 0.1288606574736446, 0.1288606574736446, 0.13082407756024095, 0.12801646037274095, 0.12824001082454817, 0.12887095256024095, 0.12737522355045183, 0.1278840949736446, 0.12750758894954817, 0.12935923381024095, 0.12787379988704817, 0.12777231974774095, 0.1277620246611446, 0.12701930769954817, 0.1273958137236446, 0.1276399543486446, 0.1281282355986446, 0.12985781014683728, 0.13022402108433728, 0.1288606574736446, 0.1284944465361446, 0.12716196818524095, 0.1286165168486446, 0.1276399543486446, 0.1287385871611446, 0.12752817912274095, 0.12900331795933728, 0.12901361304593373, 0.12900331795933728, 0.1282503059111446, 0.12984751506024095, 0.12973573983433728, 0.12714137801204817, 0.1294710090361446, 0.1292268684111446, 0.1276399543486446, 0.1269075324736446, 0.1283723762236446, 0.1300813605986446, 0.12863710702183728, 0.12862681193524095, 0.12814882577183728, 0.12911509318524095, 0.12838267131024095], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.03219354335867194, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.007148173148252126, "optimization": "nesterov_momentum", "nb_data_augmentation": 3, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 3.09099437331003e-06, "rotation_range": [0, 0], "momentum": 0.8457647320365311}, "accuracy_valid_max": 0.8731130576995482, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.871617328689759, "accuracy_valid_std": [0.015032358023842307, 0.012556343107540585, 0.012936609318472327, 0.01779866958876513, 0.014792140779975402, 0.011638836791069399, 0.015548117591821732, 0.014443598186724922, 0.010879444441490018, 0.008648236788173494, 0.009241446087295317, 0.011320513062791445, 0.009056164880734961, 0.011708887477510454, 0.011814639250610104, 0.012353411166475963, 0.012886522407814224, 0.013057056258399875, 0.010992877698848264, 0.009802732762682356, 0.010205798600476613, 0.013508553806897397, 0.010948666818704333, 0.011211460335734566, 0.014581998922918614, 0.010773582231550062, 0.012032796946752121, 0.01328986684790928, 0.0108719250052779, 0.010723759319106312, 0.010132477878995062, 0.010268846909092287, 0.011925257475258622, 0.008921605858641274, 0.008933030390947005, 0.012084185366963656, 0.008099131858094875, 0.010455900375844642, 0.008467063669494344, 0.007684116528504383, 0.0072703848645812, 0.006466537418955577, 0.00740524527189846, 0.006602657752664677, 0.008144354660603223, 0.008593353534979274, 0.0077465482237128735, 0.007512172168939263, 0.01074581739076729, 0.007674075109215509, 0.008721582682296522, 0.00657493446977602, 0.005368123889425481, 0.008114290865409901, 0.008456681856501343, 0.007096487620539096, 0.009602550831196533, 0.005514158680497375, 0.006164777930034008, 0.008867916845357936, 0.007396435112162953, 0.009017720647595732, 0.006662499542001559, 0.00588097377415605, 0.006802417009144257, 0.007768084578459222, 0.006962796984121899, 0.007452691799316899, 0.006776352441897694, 0.009773092616700929, 0.0076018666984037945, 0.00584398007090429, 0.00782717451920186, 0.006431398544052798, 0.007956119431947323, 0.006667477294079809, 0.007706116908310107, 0.005934040520322104, 0.007685265925521676, 0.008557773980214909, 0.009652828008635941, 0.009894599061082249, 0.00892316600455596, 0.007331284132893786, 0.008192723070775483, 0.00921945964991735, 0.007909525707965954, 0.00749314880690107, 0.008779796171881012, 0.006932136197277362, 0.006497174171197268, 0.0054723555091162, 0.007898623053729107, 0.00703496757335916, 0.008612056914733332, 0.0074450756068731114, 0.00884887867779736, 0.007203117544225323, 0.009370282428176054, 0.007885640801122027, 0.007807819378020561, 0.006785118490104298, 0.006553945455458569, 0.008891057196274275, 0.008686559240377532, 0.006826604925203506, 0.005577047453566351, 0.006913356330688431, 0.0052723216296983524, 0.007341207498768149, 0.008456319538578554, 0.00692604768351084, 0.00663880213277759, 0.008493330183781924, 0.005859380721950816, 0.005262250728840918, 0.007887246394041971, 0.006909192078684989, 0.006850688970316294, 0.008386186955029724, 0.007633699710536696, 0.007016454312942921, 0.008067966226978626, 0.005995377484520054, 0.008013846364682818, 0.006318761893116314, 0.007122707029301099, 0.008272621341931526, 0.006438870025152297, 0.006751736867151314, 0.007399048945989302, 0.004935485191564009, 0.0060478712207099735, 0.005659518036401546, 0.005421490064051056, 0.00530546351256897, 0.005854390534942427, 0.0058133655729850076, 0.0063849986549732686, 0.005829409660393228, 0.006419709557990419, 0.007284118054357165, 0.0058558204040300675, 0.00421982183021932, 0.0064165346590467865, 0.006337474308340833, 0.004810609755939643, 0.005273860710700604, 0.005233499335285958, 0.005481513080739924, 0.007394100901157609, 0.00732934958215304, 0.005798522958917545, 0.006206159094509922, 0.005144180328619537, 0.005274903396129677, 0.005294788975678418, 0.006387482023230295, 0.0042838344380388225, 0.004812913153805876, 0.007105950805216267, 0.0060160479726518905, 0.0035442471046134975, 0.004353239603958214, 0.005461855863324202, 0.005784518638483567, 0.005143682453454969, 0.005653916305205173, 0.005446467386592887, 0.007177032162393011, 0.006681680512147276, 0.005941155382677468, 0.005083558976510069, 0.006003459373738127, 0.007245694550365448, 0.00599922942135424, 0.005753819524411625, 0.006987116956545385, 0.005258285089027442, 0.0051891352899766045, 0.004870609490075716, 0.004577995526552848, 0.006840878058668997, 0.008090713703123219, 0.005760498003148637, 0.005364481074650175, 0.005475184883320477], "accuracy_valid": [0.5737731198230422, 0.663062405873494, 0.7524002259036144, 0.7739963761295181, 0.7898258071347892, 0.8077407285391567, 0.8106189406061747, 0.8211684629141567, 0.8246379070971386, 0.8347094432417168, 0.8350653590926205, 0.8368861186935241, 0.838402437876506, 0.8354109798569277, 0.8414336055158133, 0.8409247340926205, 0.8470591349774097, 0.8458178416792168, 0.8485239787274097, 0.8486666392131024, 0.849144625376506, 0.8482798381024097, 0.849266695689006, 0.8518507624246988, 0.8513315959149097, 0.8549128153237951, 0.8540583231362951, 0.8518198771649097, 0.8516272119728916, 0.8537935923381024, 0.8555231668862951, 0.8550245905496988, 0.8533053110881024, 0.8569983057228916, 0.8547907450112951, 0.855858492564006, 0.8584837396460843, 0.8568556452371988, 0.8585955148719879, 0.8578630929969879, 0.8587278802710843, 0.8594808923192772, 0.8597044427710843, 0.8605795251317772, 0.8605692300451807, 0.8617899331701807, 0.8619120034826807, 0.8619120034826807, 0.8593073465737951, 0.8601824289344879, 0.8620134836219879, 0.8610575112951807, 0.8641298592808735, 0.8632444818335843, 0.8611692865210843, 0.8641401543674698, 0.8630106362951807, 0.8637533532567772, 0.8648622811558735, 0.8622782144201807, 0.8647402108433735, 0.8644754800451807, 0.8653608574924698, 0.8669580666415663, 0.866856586502259, 0.8641504494540663, 0.8636415780308735, 0.8660829842808735, 0.8642416345067772, 0.8647093255835843, 0.8647196206701807, 0.8654932228915663, 0.8660829842808735, 0.8654829278049698, 0.8668154061558735, 0.8647402108433735, 0.8636209878576807, 0.8667036309299698, 0.8657270684299698, 0.8663065347326807, 0.8655638177710843, 0.8633665521460843, 0.8660829842808735, 0.8669477715549698, 0.8645063653049698, 0.8655741128576807, 0.8679243340549698, 0.8668154061558735, 0.8663168298192772, 0.8666933358433735, 0.8685449807040663, 0.8685758659638554, 0.8671919121799698, 0.8671816170933735, 0.8680464043674698, 0.8665712655308735, 0.868443500564759, 0.8686567559299698, 0.8659609139683735, 0.8673345726656627, 0.8667036309299698, 0.8686773461031627, 0.8681787697665663, 0.8658182534826807, 0.8665712655308735, 0.8701730751129518, 0.8690435570406627, 0.8684537956513554, 0.8698980492281627, 0.8690229668674698, 0.869053852127259, 0.8702642601656627, 0.8705289909638554, 0.8685346856174698, 0.8679449242281627, 0.8678125588290663, 0.8701318947665663, 0.8676904885165663, 0.870396625564759, 0.8688803063817772, 0.8674360528049698, 0.8703863304781627, 0.8677816735692772, 0.8693994728915663, 0.8679140389683735, 0.8692774025790663, 0.8701421898531627, 0.8691553322665663, 0.8696539086031627, 0.8702642601656627, 0.8686567559299698, 0.870152484939759, 0.8718820594879518, 0.8713834831513554, 0.871251117752259, 0.8701627800263554, 0.8731130576995482, 0.868199359939759, 0.8691656273531627, 0.8708952019013554, 0.8705289909638554, 0.8712922980986446, 0.8693082878388554, 0.8711393425263554, 0.8711393425263554, 0.869175922439759, 0.871983539627259, 0.8717599891754518, 0.871129047439759, 0.8726247764495482, 0.8721159050263554, 0.8724924110504518, 0.870640766189759, 0.8721262001129518, 0.872227680252259, 0.8722379753388554, 0.8729806923004518, 0.8726041862763554, 0.8723600456513554, 0.8718717644013554, 0.8701421898531627, 0.8697759789156627, 0.8711393425263554, 0.8715055534638554, 0.872838031814759, 0.8713834831513554, 0.8723600456513554, 0.8712614128388554, 0.872471820877259, 0.8709966820406627, 0.8709863869540663, 0.8709966820406627, 0.8717496940888554, 0.870152484939759, 0.8702642601656627, 0.8728586219879518, 0.8705289909638554, 0.8707731315888554, 0.8723600456513554, 0.8730924675263554, 0.8716276237763554, 0.8699186394013554, 0.8713628929781627, 0.871373188064759, 0.8718511742281627, 0.870884906814759, 0.871617328689759], "seed": 126078785, "model": "residualv3", "loss_std": [0.3420109748840332, 0.2709120810031891, 0.2492351531982422, 0.23898595571517944, 0.23041541874408722, 0.2245933711528778, 0.21905982494354248, 0.21239367127418518, 0.21049246191978455, 0.2051541954278946, 0.20199984312057495, 0.19942359626293182, 0.19494479894638062, 0.19302628934383392, 0.19021707773208618, 0.1854293942451477, 0.18529444932937622, 0.1831691414117813, 0.1783749908208847, 0.1777649223804474, 0.17654231190681458, 0.17249643802642822, 0.17395782470703125, 0.16967621445655823, 0.16843578219413757, 0.1658971756696701, 0.16514712572097778, 0.1628451645374298, 0.1618419587612152, 0.16013427078723907, 0.1575123369693756, 0.1560399979352951, 0.1552446335554123, 0.15321804583072662, 0.15159405767917633, 0.15053218603134155, 0.14900045096874237, 0.14653658866882324, 0.14730903506278992, 0.14586234092712402, 0.14301592111587524, 0.14364071190357208, 0.14152368903160095, 0.1386980414390564, 0.13787347078323364, 0.13855499029159546, 0.13457563519477844, 0.13658156991004944, 0.13408510386943817, 0.13646568357944489, 0.13349474966526031, 0.13394200801849365, 0.13122344017028809, 0.12942813336849213, 0.12777043879032135, 0.1276949644088745, 0.12704096734523773, 0.126226007938385, 0.12608997523784637, 0.12422611564397812, 0.12382632493972778, 0.1253475546836853, 0.12352268397808075, 0.12096554785966873, 0.12016560137271881, 0.12017746269702911, 0.12087190896272659, 0.11965453624725342, 0.11707261949777603, 0.11640768498182297, 0.11639436334371567, 0.11572455614805222, 0.11816832423210144, 0.11501061916351318, 0.11445639282464981, 0.11377377808094025, 0.1140192523598671, 0.11357197910547256, 0.11169066280126572, 0.11053626984357834, 0.11325151473283768, 0.11101117730140686, 0.10933201760053635, 0.10917073488235474, 0.10913538187742233, 0.10819579660892487, 0.10844114422798157, 0.10634822398424149, 0.10618625581264496, 0.1064642146229744, 0.10333795845508575, 0.10472895950078964, 0.10483706742525101, 0.10400914400815964, 0.10341404378414154, 0.10446200519800186, 0.10387051850557327, 0.10418405383825302, 0.10236580669879913, 0.10207885503768921, 0.10125359147787094, 0.09976740926504135, 0.10113198310136795, 0.0989309549331665, 0.09834299981594086, 0.09768989682197571, 0.09818879514932632, 0.09972729533910751, 0.09616947919130325, 0.10017826408147812, 0.097769595682621, 0.09805143624544144, 0.09524450451135635, 0.09613800048828125, 0.09734134376049042, 0.09381378442049026, 0.09410957247018814, 0.09502755105495453, 0.0948835164308548, 0.0943814143538475, 0.09418438374996185, 0.0936485156416893, 0.09354673326015472, 0.09320039302110672, 0.09158498793840408, 0.09332126379013062, 0.09285666793584824, 0.09217922389507294, 0.08987154066562653, 0.09094594419002533, 0.09065649658441544, 0.08996390551328659, 0.09158273041248322, 0.09020944684743881, 0.08957330882549286, 0.09049802273511887, 0.08871693909168243, 0.08821853250265121, 0.0884399488568306, 0.0871632993221283, 0.08785448968410492, 0.08915407210588455, 0.08674024045467377, 0.08402089029550552, 0.08637547492980957, 0.08567379415035248, 0.0865045040845871, 0.08435467630624771, 0.085292749106884, 0.0853109136223793, 0.08426526188850403, 0.08640620112419128, 0.08410408347845078, 0.08620837330818176, 0.08452609926462173, 0.08390222489833832, 0.08298356831073761, 0.08417749404907227, 0.08441270142793655, 0.08377311378717422, 0.08203072100877762, 0.08279357105493546, 0.08295733481645584, 0.08310732990503311, 0.08190371096134186, 0.08074852079153061, 0.08088578283786774, 0.08185555785894394, 0.08174904435873032, 0.08141954988241196, 0.07986731827259064, 0.08075705915689468, 0.07923201471567154, 0.08149343729019165, 0.08078347891569138, 0.0792386382818222, 0.0821978747844696, 0.0792810320854187, 0.07804498821496964, 0.08067115396261215, 0.0802958756685257, 0.07922103255987167, 0.07985082268714905, 0.07740693539381027, 0.07919006049633026, 0.07724212110042572, 0.07573077082633972]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:35 2016", "state": "available"}], "summary": "e56eb0204dad5c20be571600f2bf80b5"}