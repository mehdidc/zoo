{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 64, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.690713882446289, 1.4052684307098389, 1.2708187103271484, 1.1702924966812134, 1.089199423789978, 1.022172212600708, 0.9633827805519104, 0.9101701974868774, 0.8653894662857056, 0.8248668909072876, 0.7903279066085815, 0.7604438662528992, 0.7327041029930115, 0.7083948850631714, 0.6872804760932922, 0.6670258045196533, 0.6511361598968506, 0.6324647068977356, 0.6175916790962219, 0.6015622615814209, 0.5882312655448914, 0.5761381983757019, 0.5646346807479858, 0.5533708930015564, 0.5432415008544922, 0.5334658026695251, 0.5243250131607056, 0.5158947706222534, 0.5081794261932373, 0.5008737444877625, 0.4935622215270996, 0.4876272976398468, 0.4807433485984802, 0.47112134099006653, 0.4673340320587158, 0.4623946249485016, 0.45555418729782104, 0.4517482817173004, 0.4469083249568939, 0.4438270628452301, 0.43752583861351013, 0.4347006380558014, 0.4300786852836609, 0.4269646108150482, 0.4218789339065552, 0.42078545689582825, 0.4172474443912506, 0.41507917642593384, 0.4116794764995575, 0.4093957543373108, 0.40524837374687195, 0.40261968970298767, 0.40085485577583313, 0.39946088194847107, 0.39529353380203247, 0.3936924636363983, 0.3921491205692291, 0.39154374599456787, 0.3890237808227539, 0.3860630691051483, 0.3872053921222687, 0.38281774520874023, 0.38197460770606995, 0.38034579157829285, 0.3801708221435547, 0.37812092900276184, 0.37646979093551636, 0.37838950753211975, 0.37585321068763733, 0.37561893463134766, 0.3720364570617676, 0.3711589574813843, 0.37351423501968384, 0.3714357316493988, 0.3694395422935486, 0.36951085925102234, 0.36876845359802246, 0.36782267689704895, 0.3690655827522278, 0.36790865659713745, 0.3660929501056671, 0.3663271367549896, 0.36439037322998047, 0.36559757590293884, 0.36456620693206787, 0.36478662490844727, 0.36218297481536865, 0.36412176489830017, 0.3635666072368622, 0.3638996183872223, 0.3644891381263733, 0.3607572317123413, 0.36294808983802795, 0.3612954020500183, 0.3602515757083893, 0.35953930020332336, 0.3614790439605713, 0.3592672348022461, 0.3603046238422394, 0.35909318923950195, 0.36042293906211853, 0.3582456707954407, 0.35813459753990173, 0.3593911826610565, 0.3580688536167145, 0.3575994372367859, 0.358357310295105, 0.3575207591056824, 0.35911524295806885, 0.35773223638534546, 0.3580559194087982, 0.35772815346717834, 0.35711246728897095, 0.3569352328777313, 0.35659950971603394, 0.3560391366481781, 0.3582618534564972, 0.3565872609615326, 0.3595764636993408, 0.3588571846485138, 0.35800084471702576, 0.3601531684398651, 0.35578653216362, 0.3565887212753296, 0.3577977120876312, 0.3560970425605774, 0.3583579659461975, 0.3565047085285187, 0.35724589228630066, 0.3552438020706177, 0.3552621304988861, 0.3563329577445984, 0.35660672187805176, 0.3558630347251892, 0.3529983460903168, 0.3569706082344055, 0.3554406762123108, 0.35423335433006287, 0.35553082823753357, 0.3565206527709961, 0.35553139448165894, 0.3570721745491028, 0.3564106822013855, 0.3561961352825165, 0.35720929503440857, 0.3574869632720947, 0.35773053765296936, 0.3561514914035797, 0.3573850095272064, 0.35669785737991333, 0.3581181764602661, 0.35562044382095337, 0.35709771513938904, 0.35632070899009705, 0.3556967079639435, 0.35761332511901855, 0.35799404978752136, 0.35692766308784485, 0.3560168147087097, 0.35630324482917786, 0.3547450304031372, 0.3573037087917328, 0.3555649518966675, 0.355468213558197, 0.35614097118377686, 0.35414448380470276, 0.35767003893852234, 0.3549998700618744, 0.3571319878101349, 0.3566080331802368, 0.356375128030777, 0.35605868697166443, 0.35432180762290955, 0.356055349111557, 0.3571891784667969, 0.3570396900177002, 0.3543049395084381, 0.35735416412353516, 0.3564855456352234, 0.35707128047943115, 0.35387638211250305, 0.35454100370407104, 0.3546614944934845, 0.35563191771507263, 0.35568293929100037, 0.35630324482917786, 0.35734960436820984, 0.3560682237148285, 0.35615986585617065, 0.355182409286499, 0.3573804497718811, 0.35554423928260803, 0.3561464846134186], "moving_avg_accuracy_train": [0.04323518681939829, 0.09130388577427093, 0.13463274761212624, 0.17577433093392394, 0.21544276448297342, 0.25272534772113786, 0.2897898182150355, 0.32528175148558625, 0.36136213879665297, 0.3963359509586543, 0.4287842941068365, 0.4599292661473341, 0.48995181673244376, 0.5165767288149672, 0.5428219411367281, 0.5678120006798475, 0.5895499223472818, 0.6103204075431092, 0.6301019057157548, 0.6471331604710988, 0.6632240827557073, 0.6782149041082282, 0.6934641674349469, 0.706623709561192, 0.7188879691652427, 0.7316321736445286, 0.7426251940234774, 0.7538235010907679, 0.7641830681155505, 0.7739532151557396, 0.7833597902406177, 0.792523288508684, 0.8006796840487348, 0.8087272492240569, 0.8163838983211233, 0.8232631846667979, 0.8297776659647914, 0.8359638948175093, 0.8416455412230783, 0.8471309386511581, 0.8522421464483253, 0.857423484619338, 0.8622400045994032, 0.8661821387255648, 0.8702437010331026, 0.8741594877277343, 0.8776628775600736, 0.8812576345853508, 0.884346467581919, 0.8874217472264587, 0.8901731507672402, 0.8927795862384582, 0.8951788926339922, 0.8974916561137639, 0.899631344063434, 0.9016454909705365, 0.9035790588273865, 0.9053308956425992, 0.9070145056215286, 0.908655240540642, 0.9100830738428438, 0.9114961151458056, 0.9128002602065296, 0.9138810208576189, 0.9150886175709988, 0.9161985979546797, 0.9172069890416868, 0.918119227366431, 0.9190471266063014, 0.9199334252448129, 0.9207473700611399, 0.9214403568172537, 0.9221571229477745, 0.9228486433437962, 0.923529104371635, 0.9240462602931371, 0.9246418368581848, 0.9251987460571947, 0.9257627794029795, 0.9263540426736911, 0.926793281811407, 0.9272606045508089, 0.9277090247043475, 0.9281475882211312, 0.9285329587421798, 0.9288798282599422, 0.9291920108259284, 0.929565981087697, 0.9298908564816035, 0.930218157617081, 0.9304825377533057, 0.9307762473985177, 0.9310382969792179, 0.9313066936851814, 0.9315738273574532, 0.9318189340089357, 0.9320789854273943, 0.932229362395683, 0.9323646295695053, 0.9325538353902402, 0.9326892433967588, 0.9328459878347685, 0.9329870938777959, 0.9331001384236634, 0.9332064927637443, 0.9332766710817313, 0.9333839733464818, 0.9333758776395098, 0.9334964746877589, 0.9336003256847453, 0.9336915024820422, 0.9337038431841426, 0.9337869933803093, 0.9338594673592312, 0.9339084899962317, 0.9339735367088178, 0.9340367290477644, 0.9341098781944829, 0.9341082831110534, 0.9341440499169192, 0.934173914893389, 0.9342030464233837, 0.9341921345170642, 0.9342683082585101, 0.9343043846401158, 0.9343252276395132, 0.9343462754389616, 0.9343745190537033, 0.9344022274069615, 0.9344341764201413, 0.934430342399851, 0.9344455290208847, 0.9344335482452728, 0.9344786051674694, 0.934507638799855, 0.934487193995174, 0.9345222720935802, 0.9345445057380889, 0.9345715275133941, 0.9346027865087786, 0.9346100293141577, 0.9346374741782846, 0.9346528379119419, 0.9346574007258142, 0.9346800723999567, 0.9347051632531227, 0.9346765917471627, 0.9347554730394084, 0.9347567838357813, 0.9347463378084694, 0.9347787890624599, 0.9347707207124617, 0.9347634231486445, 0.9347708422828849, 0.9347472925691774, 0.9347447711149545, 0.9347122388228111, 0.9347386551848544, 0.9347299499249976, 0.934703550049469, 0.9347216428400648, 0.9347076994170771, 0.9346672125018551, 0.9346819636007837, 0.9346161845302956, 0.9346615429656473, 0.934681475266997, 0.9346948000894114, 0.9347114787760221, 0.9346566269832297, 0.9346607748411545, 0.9346691942597246, 0.934706926573324, 0.9347293320091532, 0.9346634303466284, 0.9346413572801272, 0.9346354063643145, 0.9346417123329495, 0.9346868070880265, 0.9346623963473856, 0.9346636421200851, 0.9346972793500293, 0.9346694962343784, 0.9346700680671975, 0.9346775581631633, 0.9347098037887998, 0.9347202957590339, 0.9346971143512738, 0.9347250431604709, 0.9347711414768528, 0.9347081064116242, 0.9347234184171949, 0.9347441386198183], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.0427375517695783, 0.0908728468561747, 0.1346483316076807, 0.17593732821912647, 0.21559692512236442, 0.25198842213384787, 0.2873623397096197, 0.32155085159709146, 0.3558342253511624, 0.3889791831341938, 0.41986665638703946, 0.44952393959057946, 0.47755532645795223, 0.5025882621385878, 0.5268483612353465, 0.54953488359261, 0.5691276760597798, 0.587900561221121, 0.605641531548557, 0.6205259500239725, 0.6342943146413041, 0.6475119499599298, 0.6603792367033947, 0.6715468147273324, 0.6817420603065569, 0.6918974323538379, 0.7008328361911198, 0.7096580086619928, 0.7177502367867573, 0.7251441348889551, 0.732079404899683, 0.7388328137131787, 0.744568055261665, 0.7506525065596702, 0.7562902926601037, 0.761571819681744, 0.7661592960343528, 0.7704152426074989, 0.7743798718670805, 0.778340722218023, 0.7819654931814617, 0.7853376503298065, 0.7886676195306361, 0.7912922038219249, 0.7939900965797926, 0.7965137972945543, 0.7987129152589995, 0.8009016999755694, 0.8028186600608438, 0.8046690829760696, 0.8063456411223633, 0.8077558576953678, 0.8090107865625027, 0.810314209506403, 0.8115717098660036, 0.8127034601896441, 0.8136610003246706, 0.8144851358437849, 0.815439524885536, 0.8161489021221329, 0.8167130699389106, 0.8173306842552605, 0.817985222898635, 0.8183800246863316, 0.8189418363178491, 0.8195807146213051, 0.8200346642905751, 0.8204177754217585, 0.8209090598148236, 0.8212067904109015, 0.8215968182598716, 0.8219346067840351, 0.8222864150721225, 0.8226284861025609, 0.8228986994275457, 0.8230686492325321, 0.8233813249719294, 0.8235640473787275, 0.8238170352895746, 0.8240782569771081, 0.824192315692048, 0.8245014585580841, 0.8248417518024264, 0.8250127088699246, 0.8250678844720135, 0.825252849366303, 0.8253826966774137, 0.8255239733199133, 0.825675536360663, 0.8258729782535877, 0.8260384689259699, 0.8261263753748639, 0.8262299052413684, 0.8263108750899726, 0.8264081620162163, 0.8265944060084953, 0.8267121679678867, 0.826903602950089, 0.8269772086754115, 0.8270577198767709, 0.8271657715430848, 0.8272884616139269, 0.8273256404901849, 0.8274313141576572, 0.8274775923333825, 0.8277155847001948, 0.8277944709779163, 0.8277800194091156, 0.8279267339121046, 0.8279967122998851, 0.8279498295676375, 0.8280297054211148, 0.8280893866579943, 0.8280830941235954, 0.8280886083652268, 0.8280203289951952, 0.8280443267809167, 0.8281279894529756, 0.8280923930679189, 0.8281102139550277, 0.8281506668159255, 0.8282236954844836, 0.8282395636525262, 0.8283281166999241, 0.8284810566300823, 0.8284844252234747, 0.8284874569575278, 0.828501363040766, 0.8285027009930901, 0.8285283192126817, 0.8285015179766545, 0.8285140179579801, 0.8285262974498326, 0.8285994136574096, 0.8285665324855693, 0.8286701872660033, 0.8286668498270535, 0.8286150180069988, 0.8286161679852899, 0.8286426465369116, 0.828690891295871, 0.8287221045476845, 0.8288722667868166, 0.8289341706145356, 0.8289166418719826, 0.8289619011599348, 0.8290270485815919, 0.8289514039173334, 0.828882294210841, 0.8288943671711575, 0.8288930258041924, 0.8288796115426738, 0.828904159801057, 0.8288408040148519, 0.8287837838072674, 0.8288301218704411, 0.828834175524888, 0.8288632673850499, 0.8288650359966956, 0.8288177996221766, 0.8287752868851095, 0.8287370254217491, 0.8287636252609748, 0.828836393241278, 0.8288398197586412, 0.8287951050079276, 0.8288036898572855, 0.8287992091904576, 0.8287829695590624, 0.8287307032883972, 0.828745728309708, 0.8288202859851379, 0.8288629738305247, 0.8289502210163728, 0.8289300577249765, 0.8288030769901296, 0.8288474857350172, 0.8288253889405065, 0.8288299158879469, 0.8287851620156431, 0.8287835636416391, 0.8287933026276258, 0.8287400030501042, 0.8287907191889944, 0.8288119496514955, 0.8288676781614965, 0.8288445916329974, 0.828812636234758, 0.8287950538989327, 0.82885247198419, 0.828915325783512, 0.8289851307428114, 0.8289980975725213], "moving_var_accuracy_train": [0.016823532413774447, 0.03593657754532457, 0.04923943220426769, 0.059549157887860735, 0.06775650368119285, 0.0734907724292695, 0.07850566994327965, 0.08199219889448271, 0.08550912814168368, 0.0879667231618019, 0.08864610560318135, 0.08851157859349361, 0.0877726026268635, 0.08537531585479606, 0.08303708479764525, 0.08035390400159859, 0.07657134874721429, 0.07279693136992361, 0.06903900726252064, 0.06474567928314144, 0.060601371374551086, 0.05656375676050472, 0.053000241372522724, 0.04925877917602221, 0.045686609831139924, 0.04257968157831461, 0.039409331893951, 0.03659701743511586, 0.033903201352072934, 0.031371983175547895, 0.029031137751440176, 0.026883751280875848, 0.0247941172466401, 0.022897575269235613, 0.021135436220872526, 0.019447813824417348, 0.01788497864121278, 0.016440905623855306, 0.015087345014371024, 0.013849416777429778, 0.012699595105999217, 0.011671251982580845, 0.010712916566788057, 0.009781488703327079, 0.008951806428396466, 0.008194626254497517, 0.007485627291903801, 0.006853365065350442, 0.0062538965623416, 0.005713623010136525, 0.005210392702120902, 0.004750494984699424, 0.004327255526846336, 0.003942669848381993, 0.003589607244241466, 0.003267157609687835, 0.0029740900106324433, 0.0027043013996134076, 0.0024593821427024245, 0.002237672028105361, 0.0020322531967447177, 0.0018469980485851306, 0.0016776053927813146, 0.0015203572457676718, 0.0013814461295903974, 0.0012543900247007642, 0.0011381026954898862, 0.0010317820347910866, 0.0009363528043061462, 0.0008497872513651796, 0.0007707710817048939, 0.0006980160493317463, 0.0006328382275713283, 0.000573858208937222, 0.0005206396329371681, 0.00047098272186775307, 0.0004270768526844837, 0.0003871604981195117, 0.0003513076508439751, 0.00031932321605721134, 0.0002891272736324019, 0.00026218006115402096, 0.00023777178074551445, 0.00021572564429524687, 0.00019548967381216137, 0.0001770235725921201, 0.00016019833692345974, 0.00014543718704129892, 0.00013184336453126252, 0.00011962316237770013, 0.00010828991784780193, 9.823731426423715e-05, 8.903161268251927e-05, 8.077678254021538e-05, 7.334134787594672e-05, 6.654790852376045e-05, 6.0501758333565345e-05, 5.46551015935339e-05, 4.935426630900524e-05, 4.474102926150464e-05, 4.04319442894183e-05, 3.660986923009899e-05, 3.312808054549876e-05, 2.9930284115102423e-05, 2.7039056914478887e-05, 2.4379476189870306e-05, 2.2045152555068475e-05, 1.9841227163804005e-05, 1.7987997279841156e-05, 1.628626281803264e-05, 1.4732455411517381e-05, 1.3260580506720603e-05, 1.1996748052151694e-05, 1.084434554552336e-05, 9.781539961417347e-06, 8.841465638639985e-06, 7.993258520089831e-06, 7.2420898470717545e-06, 6.517903760984902e-06, 5.877626764503034e-06, 5.2978913394285865e-06, 4.775740019844276e-06, 4.299237645155588e-06, 3.921535830613027e-06, 3.5410957953395056e-06, 3.1908960914204868e-06, 2.8757935710330416e-06, 2.5953935298928416e-06, 2.3427639524661476e-06, 2.11767421220801e-06, 1.9060390883914825e-06, 1.717510880678132e-06, 1.547051643468687e-06, 1.410617615262299e-06, 1.2771424200215824e-06, 1.1531900883654037e-06, 1.0489453364190149e-06, 9.48499817310374e-07, 8.602214226451284e-07, 7.829934035126355e-07, 7.05166187229202e-07, 6.414285536087624e-07, 5.794100970549258e-07, 5.216564607833286e-07, 4.741168579807969e-07, 4.323711303961061e-07, 3.9648099593195337e-07, 4.128332207359379e-07, 3.715653623465259e-07, 3.353909014912982e-07, 3.1132956631225667e-07, 2.8078249412628763e-07, 2.531835346526581e-07, 2.283605731632851e-07, 2.105158169882872e-07, 1.8952145487204795e-07, 1.8009445967370308e-07, 1.6836543135878983e-07, 1.5221092216548016e-07, 1.4326241080023798e-07, 1.3188231136408484e-07, 1.2044385162918894e-07, 1.2315217920395604e-07, 1.1279531555996067e-07, 1.4045775903248834e-07, 1.4492847204728154e-07, 1.3401129457638647e-07, 1.222081231501181e-07, 1.1249091811863629e-07, 1.2832029885955312e-07, 1.1564311150187037e-07, 1.0471677983320029e-07, 1.0705864925590687e-07, 1.0087081632262055e-07, 1.2987099680211135e-07, 1.2126887950477765e-07, 1.094607121453826e-07, 9.887252809467397e-08, 1.0728710770441991e-07, 1.0192135526174325e-07, 9.174318728214082e-08, 9.275203769882228e-08, 9.042394756631361e-08, 8.138449574463898e-08, 7.375096000835784e-08, 7.573388736167814e-08, 6.915123158004762e-08, 6.707250741373047e-08, 6.738542212086801e-08, 7.977237286794712e-08, 1.0755591061658133e-07, 9.891043718629757e-08, 9.288333463847835e-08], "duration": 86453.848813, "accuracy_train": [0.43235186819398297, 0.5239221763681248, 0.524592504152824, 0.5460485808301033, 0.5724586664244187, 0.588268596864618, 0.6233700526601145, 0.6447091509205427, 0.6860856245962532, 0.7111002604166666, 0.7208193824404762, 0.7402340145118125, 0.7601547719984312, 0.756200937557678, 0.7790288520325765, 0.7927225365679217, 0.7851912173541897, 0.7972547743055556, 0.8081353892695644, 0.8004144532691952, 0.8080423833171835, 0.8131322962809154, 0.8307075373754154, 0.8250595886973975, 0.8292663056016981, 0.8463300139581026, 0.8415623774340162, 0.8546082646963824, 0.8574191713385935, 0.8618845385174418, 0.868018966004522, 0.8749947729212809, 0.8740872439091916, 0.8811553358019564, 0.8852937401947213, 0.88517676177787, 0.8884079976467331, 0.8916399544919711, 0.8927803588732004, 0.8964995155038759, 0.8982430166228312, 0.9040555281584534, 0.905588684419989, 0.9016613458610188, 0.9067977618009413, 0.9094015679794205, 0.909193386051126, 0.9136104478128461, 0.9121459645510337, 0.9150992640273165, 0.9149357826342747, 0.9162375054794205, 0.9167726501937985, 0.9183065274317092, 0.9188885356104651, 0.9197728131344592, 0.9209811695390366, 0.9210974269795128, 0.9221669954318937, 0.9234218548126615, 0.9229335735626615, 0.9242134868724622, 0.9245375657530455, 0.9236078667174235, 0.9259569879914176, 0.9261884214078073, 0.9262825088247508, 0.9263293722891289, 0.9273982197651348, 0.9279101129914176, 0.9280728734080842, 0.9276772376222776, 0.9286080181224622, 0.9290723269079919, 0.9296532536221853, 0.9287006635866556, 0.9300020259436139, 0.9302109288482835, 0.9308390795150425, 0.931675412110096, 0.930746434050849, 0.9314665092054264, 0.9317448060861941, 0.9320946598721853, 0.9320012934316169, 0.9320016539198044, 0.9320016539198044, 0.9329317134436139, 0.9328147350267626, 0.9331638678363787, 0.9328619589793282, 0.9334196342054264, 0.9333967432055187, 0.933722264038852, 0.9339780304078996, 0.9340248938722776, 0.9344194481935216, 0.9335827551102805, 0.9335820341339055, 0.9342566877768549, 0.9339079154554264, 0.9342566877768549, 0.9342570482650425, 0.934117539336471, 0.934163681824474, 0.9339082759436139, 0.9343496937292359, 0.9333030162767626, 0.9345818481220007, 0.9345349846576227, 0.934512093657715, 0.9338149095030455, 0.9345353451458103, 0.9345117331695275, 0.9343496937292359, 0.934558957122093, 0.9346054600982835, 0.9347682205149501, 0.9340939273601883, 0.9344659511697121, 0.9344426996816169, 0.934465230193337, 0.9340939273601883, 0.9349538719315246, 0.9346290720745662, 0.9345128146340901, 0.9345357056339978, 0.9346287115863787, 0.9346516025862864, 0.9347217175387597, 0.9343958362172389, 0.9345822086101883, 0.9343257212647655, 0.9348841174672389, 0.9347689414913253, 0.9343031907530455, 0.9348379749792359, 0.9347446085386674, 0.9348147234911407, 0.9348841174672389, 0.9346752145625692, 0.9348844779554264, 0.9347911115148578, 0.9346984660506644, 0.9348841174672389, 0.9349309809316169, 0.9344194481935216, 0.9354654046696198, 0.9347685810031378, 0.9346523235626615, 0.9350708503483758, 0.9346981055624769, 0.9346977450742894, 0.9348376144910484, 0.9345353451458103, 0.9347220780269472, 0.9344194481935216, 0.9349764024432448, 0.9346516025862864, 0.9344659511697121, 0.9348844779554264, 0.9345822086101883, 0.9343028302648578, 0.9348147234911407, 0.9340241728959026, 0.9350697688838132, 0.9348608659791436, 0.9348147234911407, 0.9348615869555187, 0.9341629608480989, 0.9346981055624769, 0.9347449690268549, 0.935046517395718, 0.9349309809316169, 0.9340703153839055, 0.9344426996816169, 0.9345818481220007, 0.9346984660506644, 0.9350926598837209, 0.9344426996816169, 0.9346748540743817, 0.9350000144195275, 0.9344194481935216, 0.9346752145625692, 0.9347449690268549, 0.9350000144195275, 0.9348147234911407, 0.9344884816814323, 0.9349764024432448, 0.9351860263242894, 0.9341407908245662, 0.9348612264673312, 0.9349306204434293], "end": "2016-01-30 17:00:29.134000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0], "moving_var_accuracy_valid": [0.016438484981316472, 0.03564769618084822, 0.04932956414982742, 0.05973963890546452, 0.06792162765366397, 0.07304853438092884, 0.07700550734475346, 0.07982464571599629, 0.08242032858804857, 0.08406558976719408, 0.084245354825982, 0.0837368093665186, 0.08243495627724161, 0.07983129146863496, 0.07714513399543242, 0.07406272526588875, 0.07011135038925412, 0.06627200630585689, 0.062477483928701914, 0.0582236487559933, 0.05410739465851609, 0.0502690081434101, 0.046732210942316006, 0.04318142303837102, 0.03979876802632021, 0.03674707545645647, 0.03379094088642862, 0.031112799820051645, 0.02859087724225556, 0.026223817080341157, 0.02403431710340237, 0.022041362168481928, 0.020133262912209095, 0.01845312154936836, 0.016893871083459702, 0.015455534724236575, 0.014099385705384616, 0.012852464865947415, 0.011708682945846037, 0.01067900967078449, 0.009729359384542535, 0.008858766440586478, 0.008072688050434092, 0.007327415229709403, 0.00666018133473506, 0.006051484788940753, 0.005489861388440587, 0.00498399225641594, 0.0045186656544911625, 0.0040976156737287835, 0.0037131517313170373, 0.0033597349552303263, 0.00303793507786141, 0.0027494317724114413, 0.0024887203595598596, 0.0022513760527594195, 0.0020344903954751577, 0.0018371541501124337, 0.0016616364610883203, 0.0015000017595537063, 0.001352866151527725, 0.0012210125633687957, 0.0011027670945529516, 0.0009938932011617733, 0.0008973445718293704, 0.0008112836040260755, 0.0007320098763435417, 0.0006601298559587176, 0.0005962891135566701, 0.0005374579937715711, 0.00048508128990116405, 0.0004376000706945563, 0.0003949539852692039, 0.0003565117000510699, 0.0003215176672149574, 0.0002896258469193959, 0.00026154315728952574, 0.00023568932886208773, 0.00021269642192319214, 0.00019204091066121363, 0.00017295390410917573, 0.0001565186375028477, 0.00014190896918186733, 0.00012798110913402928, 0.00011521039734421916, 0.00010399726571887339, 9.374928206481008e-05, 8.45539856657727e-05, 7.630532929708691e-05, 6.902564607711329e-05, 6.236956593321157e-05, 5.620215723370477e-05, 5.06784074096604e-05, 4.566957171614114e-05, 4.118779725868857e-05, 3.7381198954759805e-05, 3.376788997100123e-05, 3.0720927145598255e-05, 2.769759465624059e-05, 2.498617367251562e-05, 2.2592632768602913e-05, 2.0468845173091836e-05, 1.8434401075340864e-05, 1.6691463283780554e-05, 1.504159198133861e-05, 1.4047196083153283e-05, 1.2698483878152727e-05, 1.1430515120904656e-05, 1.0481189917300096e-05, 9.47714369837732e-06, 8.54921124378654e-06, 7.751711487126311e-06, 7.008596988732877e-06, 6.308093653762033e-06, 5.677557950132759e-06, 5.151760806466833e-06, 4.641767769295944e-06, 4.24058597663072e-06, 3.827931302629519e-06, 3.4479964285226384e-06, 3.1179246912637497e-06, 2.8541309000196276e-06, 2.570983998830922e-06, 2.3844603787790643e-06, 2.35652994103229e-06, 2.1209790737220493e-06, 1.9089638890521654e-06, 1.7198079125061955e-06, 1.5478432323033675e-06, 1.3989655476484197e-06, 1.2655337491568482e-06, 1.1403866200394079e-06, 1.0277050313168893e-06, 9.730483464791499e-07, 8.854740549855942e-07, 8.936254710484999e-07, 8.04363170432338e-07, 7.481056915207947e-07, 6.73307024419345e-07, 6.122863452412149e-07, 5.72005721620589e-07, 5.235735532574889e-07, 6.741544804823936e-07, 6.41227787410464e-07, 5.798703200088058e-07, 5.4031891632151e-07, 5.244847036264954e-07, 5.235352703409994e-07, 5.141671070900502e-07, 4.6406220371827974e-07, 4.1767217673446853e-07, 3.7752444076983544e-07, 3.451955495996983e-07, 3.4680159545072547e-07, 3.4138317256256167e-07, 3.265698001946576e-07, 2.940607092045624e-07, 2.722716652331681e-07, 2.4507265059422817e-07, 2.4064686123405937e-07, 2.3284817042704548e-07, 2.227388095906145e-07, 2.0683289165304762e-07, 2.3380621310429893e-07, 2.1053126098502992e-07, 2.074728152688714e-07, 1.8738883048845553e-07, 1.688306348166175e-07, 1.543211019856095e-07, 1.6347485923034652e-07, 1.4915913469584554e-07, 1.8427284391571317e-07, 1.822458288180607e-07, 2.32529888882027e-07, 2.1293592487321813e-07, 3.3675929558657586e-07, 3.2083259563038356e-07, 2.9314375101619934e-07, 2.64013815192726e-07, 2.556386154490479e-07, 2.3009774709925525e-07, 2.079416030217705e-07, 2.1271504739543547e-07, 2.145926833512472e-07, 1.9719000785824357e-07, 2.0542200851485707e-07, 1.8967669784660636e-07, 1.7989935535175545e-07, 1.6469166661420787e-07, 1.7789402858435502e-07, 1.956600265287758e-07, 2.1994861496101733e-07, 1.9946700151942787e-07], "accuracy_test": 0.8255779655612244, "start": "2016-01-29 16:59:35.285000", "learning_rate_per_epoch": [0.0032692658714950085, 0.003092363942414522, 0.0029250343795865774, 0.0027667591348290443, 0.0026170480996370316, 0.0024754381738603115, 0.0023414907045662403, 0.002214791253209114, 0.002094947500154376, 0.001981588779017329, 0.0018743638647720218, 0.001772940973751247, 0.0016770061338320374, 0.0015862623695284128, 0.0015004287706688046, 0.0014192396774888039, 0.0013424437493085861, 0.0012698033824563026, 0.001201093546114862, 0.001136101665906608, 0.0010746265761554241, 0.001016477937810123, 0.0009614757145754993, 0.0009094497072510421, 0.0008602388552390039, 0.0008136908290907741, 0.0007696615648455918, 0.0007280147401615977, 0.0006886214250698686, 0.0006513597327284515, 0.000616114295553416, 0.0005827759741805494, 0.0005512416246347129, 0.0005214136326685548, 0.0004931996227242053, 0.0004665123124141246, 0.0004412690468598157, 0.0004173917113803327, 0.00039480641135014594, 0.00037344321026466787, 0.0003532359842211008, 0.00033412218908779323, 0.0003160426567774266, 0.00029894139152020216, 0.00028276551165618, 0.0002674649003893137, 0.0002529922057874501, 0.00023930265160743147, 0.00022635384812019765, 0.00021410570479929447, 0.00020252031390555203, 0.00019156181951984763, 0.00018119630112778395, 0.00017139165720436722, 0.00016211756155826151, 0.00015334528870880604, 0.00014504768478218466, 0.00013719906564801931, 0.00012977514415979385, 0.00012275292829144746, 0.00011611069203354418, 0.00010982787352986634, 0.00010388502414571121, 9.826374298427254e-05, 9.29466332308948e-05, 8.791723666945472e-05, 8.315998275065795e-05, 7.866014493629336e-05, 7.440379704348743e-05, 7.037776231300086e-05, 6.656957702944055e-05, 6.296746141742915e-05, 5.956025415798649e-05, 5.633741238852963e-05, 5.3288960771169513e-05, 5.040546238888055e-05, 4.7677993279648945e-05, 4.5098109694663435e-05, 4.2657826270442456e-05, 4.034958692500368e-05, 3.816624666796997e-05, 3.610104977269657e-05, 3.41476006724406e-05, 3.229985304642469e-05, 3.055208799196407e-05, 2.8898895834572613e-05, 2.7335159757058136e-05, 2.5856037609628402e-05, 2.445695281494409e-05, 2.313357254024595e-05, 2.1881802240386605e-05, 2.0697765648947097e-05, 1.957779750227928e-05, 1.851843080658e-05, 1.7516387742944062e-05, 1.656856511544902e-05, 1.5672030713176355e-05, 1.4824007848801557e-05, 1.4021871720615309e-05, 1.3263140317576472e-05, 1.2545464414870366e-05, 1.1866622116940562e-05, 1.1224512491025962e-05, 1.0617147381708492e-05, 1.0042647772934288e-05, 9.499233783571981e-06, 8.985224667412695e-06, 8.499028808728326e-06, 8.039140993787441e-06, 7.604138318129117e-06, 7.192673820100026e-06, 6.803474207117688e-06, 6.435334398702253e-06, 6.087114797992399e-06, 5.757737653766526e-06, 5.446182967716595e-06, 5.151486675458727e-06, 4.872736553807044e-06, 4.6090699470369145e-06, 4.359670583653497e-06, 4.123766302654985e-06, 3.900626779795857e-06, 3.689561481223791e-06, 3.4899171623692382e-06, 3.301075594208669e-06, 3.122452426396194e-06, 2.9534946861531353e-06, 2.7936794140259735e-06, 2.6425118448969442e-06, 2.4995240437419852e-06, 2.3642733140150085e-06, 2.236341060779523e-06, 2.1153314264665823e-06, 2.0008696992590558e-06, 1.8926015172837651e-06, 1.790191731743107e-06, 1.6933233837335138e-06, 1.6016966810639133e-06, 1.5150279750741902e-06, 1.4330489648273215e-06, 1.3555059013015125e-06, 1.2821586778954952e-06, 1.2127803756811772e-06, 1.1471561265352648e-06, 1.085082885765587e-06, 1.0263684089295566e-06, 9.708310244604945e-07, 9.182987810163468e-07, 8.686091064191714e-07, 8.216081823775312e-07, 7.771504897391424e-07, 7.350984105869429e-07, 6.953218303351605e-07, 6.576975692951237e-07, 6.221091553015867e-07, 5.884464826522162e-07, 5.566053005168214e-07, 5.264870424070978e-07, 4.979985419595323e-07, 4.7105154976634367e-07, 4.4556267653206305e-07, 4.2145302359131165e-07, 3.986479555351252e-07, 3.7707687283727864e-07, 3.566730129023199e-07, 3.373732226918946e-07, 3.191177597727801e-07, 3.0185012178662873e-07, 2.855168474980019e-07, 2.7006737468582287e-07, 2.5545386961312033e-07, 2.416311133401905e-07, 2.2855631698348589e-07, 2.161890080287776e-07, 2.044908882226082e-07, 1.9342576251801802e-07, 1.8295938275514345e-07, 1.7305934818523383e-07, 1.6369500599466846e-07, 1.5483738025068305e-07, 1.4645904400367726e-07, 1.3853406244379585e-07, 1.3103790763580037e-07, 1.239473732539409e-07, 1.1724051063310981e-07, 1.1089655771456819e-07, 1.0489588220252699e-07, 9.921990340444609e-08, 9.385105670389748e-08, 8.877272250629176e-08, 8.396917650088653e-08, 7.942555413364971e-08, 7.51277937638406e-08], "accuracy_train_first": 0.43235186819398297, "accuracy_train_last": 0.9349306204434293, "batch_size_eval": 1024, "accuracy_train_std": [0.014593304334890377, 0.01571189247984976, 0.013282373147613206, 0.014162433441302897, 0.015499167807323307, 0.017945237900625983, 0.015804449885088244, 0.013971919848797016, 0.018375924407119472, 0.0169506537688818, 0.01483971467728907, 0.015616007908873828, 0.013812117085471438, 0.0161093159807731, 0.015005304040231388, 0.013108866894999358, 0.013899513065716441, 0.012437305287277604, 0.012820443988281137, 0.01418159325758928, 0.014586672833295466, 0.012246074680040053, 0.01270489627458496, 0.011710010653879862, 0.012580279136784892, 0.012106619178140432, 0.012453256239024386, 0.012174963068693688, 0.012260706750266996, 0.010667055919528412, 0.011569441750410985, 0.011655617407221291, 0.011739552075208132, 0.010773298993090579, 0.011833775255421865, 0.010549104456781727, 0.012049699655355198, 0.011171702940564264, 0.012533843724635257, 0.011663460336541824, 0.01071648212120276, 0.010116403862456665, 0.010548986534931082, 0.010989559903988467, 0.010062101479228161, 0.0102932338592189, 0.010835181806700471, 0.010221382660427379, 0.009529829427269368, 0.009562561304849422, 0.009254168486706446, 0.010167166356849583, 0.010546681837420241, 0.009473065396896192, 0.010130202454197513, 0.009317565234825319, 0.009555325614045292, 0.010211872395760673, 0.009453108218146966, 0.009143044510339001, 0.009637574918308519, 0.009492528706327717, 0.010095317261665241, 0.009196447839418809, 0.009523620298174405, 0.009632407204466165, 0.009037080991943698, 0.008545941280699108, 0.0092456663994515, 0.009084036091497709, 0.008239000412071727, 0.008962375107099869, 0.008868424875130317, 0.00861264552355083, 0.008433677804961326, 0.007954244439003038, 0.007972372216049347, 0.00857504292648989, 0.008546870347377172, 0.00784317002949605, 0.008064325323702612, 0.008076899822192457, 0.00799839708646794, 0.007839059804745563, 0.007987293658107873, 0.008192220157990275, 0.008108642256037805, 0.007201469204093595, 0.008302133432402338, 0.007805477372944327, 0.007920302244247751, 0.00787181771299379, 0.007647367456217325, 0.007535172754969401, 0.007506829421670684, 0.007540274217825706, 0.007512133430057782, 0.007840457185296945, 0.007898075032776999, 0.007514657736697535, 0.007408158495749853, 0.007460070091584924, 0.007541725925668208, 0.007385493944860623, 0.007870418445552347, 0.008045777142801875, 0.007767526375255348, 0.007638341700485993, 0.007817173637494134, 0.007559889943325221, 0.007369918211496817, 0.007334526170012375, 0.007702986731696656, 0.007759841119828682, 0.007923810407583722, 0.0074651303245407115, 0.007645380835150093, 0.007260480460594149, 0.007510633672285683, 0.007430872407071671, 0.0075502507880281945, 0.00789281472830356, 0.00754381613302032, 0.007702359940635102, 0.007508790975668332, 0.0077337426148076, 0.00774130546938088, 0.007773361000345802, 0.0077716038370175934, 0.007558828460537538, 0.007944902931876047, 0.007569340053942253, 0.008001178113184343, 0.0076922450658478735, 0.007554359683030242, 0.007236331849393917, 0.007628878555502814, 0.007781754777640062, 0.007595356756856251, 0.007624049692340856, 0.007306060671519491, 0.007783291309361148, 0.007713159785825691, 0.007602688817648225, 0.007531157199794486, 0.007696184964272931, 0.007206681307306195, 0.007809503357927681, 0.007679846472445501, 0.007612188873914646, 0.007390095998445711, 0.007904245953562828, 0.0074575872338622645, 0.00765257306260464, 0.007539117066405328, 0.007323768023876173, 0.00784047183714979, 0.007704897084234168, 0.007950687774405388, 0.008030076557426184, 0.007686416104904703, 0.007347091620235564, 0.007701369593852975, 0.007450477652808129, 0.007416104580189244, 0.0075779929765864935, 0.007473073415861804, 0.007595356756856251, 0.007506395064085672, 0.007662437277093938, 0.007938643514269077, 0.007658305548827526, 0.007526880797037708, 0.007453375404924521, 0.007888011886006876, 0.00752916964368039, 0.007605160298464485, 0.007647357268905614, 0.007931787495740703, 0.007822038655570136, 0.007678736475637867, 0.007520626483732398, 0.007439236195102788, 0.0074750412028064765, 0.00792925335129365, 0.007441712375386515, 0.007719895912299233, 0.007880133981192495, 0.007897005838665499, 0.007552917242650804, 0.007549545306256475, 0.007554745544702731, 0.007630925542993212], "accuracy_test_std": 0.011065537768932184, "error_valid": [0.5726244823042168, 0.47590949736445776, 0.4713723056287651, 0.4524617022778614, 0.42746670274849397, 0.4204881047628012, 0.39427240210843373, 0.3707525414156627, 0.3356154108621988, 0.31271619681852414, 0.30214608433734935, 0.28356051157756024, 0.2701621917356928, 0.2721153167356928, 0.2548107468938253, 0.2462864151920181, 0.2545371917356928, 0.24314347232680722, 0.2346897355045181, 0.24551428369728923, 0.24179040380271077, 0.23352933217243976, 0.22381518260542166, 0.22794498305722888, 0.22650072948042166, 0.21670421922063254, 0.21874852927334332, 0.21091543910015065, 0.20941971009036142, 0.2083107821912651, 0.2055031650037651, 0.20038650696536142, 0.20381477080195776, 0.1945874317582832, 0.19296963243599397, 0.19089443712349397, 0.19255341679216864, 0.19128123823418675, 0.18993846479668675, 0.18601162462349397, 0.1854115681475903, 0.1843129353350903, 0.18136265766189763, 0.18508653755647586, 0.18172886859939763, 0.1807728962725903, 0.18149502306099397, 0.17939923757530118, 0.17992869917168675, 0.17867711078689763, 0.17856533556099397, 0.1795521931475903, 0.1796948536332832, 0.17795498399849397, 0.1771107868975903, 0.1771107868975903, 0.1777211384600903, 0.17809764448418675, 0.17597097373870485, 0.17746670274849397, 0.1782094197100903, 0.1771107868975903, 0.17612392931099397, 0.17806675922439763, 0.17600185899849397, 0.1746693806475903, 0.17587978868599397, 0.1761342243975903, 0.1746693806475903, 0.17611363422439763, 0.17489293109939763, 0.17502529649849397, 0.1745473103350903, 0.17429287462349397, 0.1746693806475903, 0.1754018025225903, 0.17380459337349397, 0.1747914509600903, 0.17390607351280118, 0.1735707478350903, 0.17478115587349397, 0.1727162556475903, 0.17209560899849397, 0.1734486775225903, 0.17443553510918675, 0.1730824665850903, 0.1734486775225903, 0.1732045368975903, 0.1729603962725903, 0.1723500447100903, 0.1724721150225903, 0.1730824665850903, 0.1728383259600903, 0.1729603962725903, 0.1727162556475903, 0.17172939806099397, 0.1722279743975903, 0.1713734822100903, 0.17236033979668675, 0.17221767931099397, 0.1718617634600903, 0.17160732774849397, 0.17233974962349397, 0.1716176228350903, 0.1721059040850903, 0.17014248399849397, 0.1714955525225903, 0.1723500447100903, 0.17075283556099397, 0.1713734822100903, 0.1724721150225903, 0.1712514118975903, 0.1713734822100903, 0.17197353868599397, 0.1718617634600903, 0.1725941853350903, 0.1717396931475903, 0.17111904649849397, 0.1722279743975903, 0.17172939806099397, 0.17148525743599397, 0.17111904649849397, 0.1716176228350903, 0.17087490587349397, 0.17014248399849397, 0.17148525743599397, 0.17148525743599397, 0.1713734822100903, 0.17148525743599397, 0.17124111681099397, 0.1717396931475903, 0.1713734822100903, 0.17136318712349397, 0.17074254047439763, 0.17172939806099397, 0.1703969197100903, 0.17136318712349397, 0.17185146837349397, 0.1713734822100903, 0.17111904649849397, 0.17087490587349397, 0.17099697618599397, 0.16977627306099397, 0.17050869493599397, 0.17124111681099397, 0.17063076524849397, 0.17038662462349397, 0.17172939806099397, 0.1717396931475903, 0.17099697618599397, 0.17111904649849397, 0.17124111681099397, 0.17087490587349397, 0.17172939806099397, 0.17172939806099397, 0.17075283556099397, 0.1711293415850903, 0.17087490587349397, 0.17111904649849397, 0.17160732774849397, 0.17160732774849397, 0.17160732774849397, 0.17099697618599397, 0.17050869493599397, 0.1711293415850903, 0.17160732774849397, 0.17111904649849397, 0.17124111681099397, 0.17136318712349397, 0.1717396931475903, 0.17111904649849397, 0.17050869493599397, 0.17075283556099397, 0.17026455431099397, 0.1712514118975903, 0.17233974962349397, 0.17075283556099397, 0.1713734822100903, 0.1711293415850903, 0.1716176228350903, 0.17123082172439763, 0.17111904649849397, 0.1717396931475903, 0.17075283556099397, 0.17099697618599397, 0.17063076524849397, 0.17136318712349397, 0.17147496234939763, 0.17136318712349397, 0.17063076524849397, 0.1705189900225903, 0.17038662462349397, 0.1708852009600903], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.054110584228039105, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.0034562875604861668, "optimization": "nesterov_momentum", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.2357278276136652e-07, "rotation_range": [0, 0], "momentum": 0.8803063851476038}, "accuracy_valid_max": 0.830223726939006, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8291147990399097, "accuracy_valid_std": [0.006443507103342941, 0.016249626417163723, 0.014395668976235334, 0.012662250937978861, 0.00748321389666398, 0.01464572194135167, 0.008307228679829127, 0.008756435287004281, 0.007298249973877786, 0.006377656706468834, 0.007859307853215433, 0.0068527780615867855, 0.008407560564146873, 0.0093559800871942, 0.01296018274275826, 0.009711419042527822, 0.007472169023146498, 0.0071570068472402324, 0.0069868891056127005, 0.011256050980775272, 0.007211430378988176, 0.010733326361754577, 0.007571261974517891, 0.004149276225356639, 0.009405922840811466, 0.007887500203589685, 0.0066244544123234715, 0.0074141043330620575, 0.007867793251992848, 0.010305696833875217, 0.007565036935563798, 0.005401513506547362, 0.006540323757080987, 0.009028492674150016, 0.010485235102217098, 0.009235814919131766, 0.007133870281350583, 0.013512005548469458, 0.008927691684303712, 0.007990696004749524, 0.009195022577629967, 0.01042468888284991, 0.009178086521929042, 0.007833320333286452, 0.010541766515207896, 0.008084067908188147, 0.009671881264484265, 0.011428045438868302, 0.008538704083983786, 0.009326103867676055, 0.009325776371674416, 0.009691752559012286, 0.008142180671460057, 0.010241937270021479, 0.008939683956670516, 0.008668885606761746, 0.007647962877318204, 0.010494603248027631, 0.01196780797815968, 0.008908620037647696, 0.007726341655457041, 0.00880532585735114, 0.010583400422815284, 0.00738207918253952, 0.009246267015384604, 0.009035566227187224, 0.00898024672855854, 0.007276729841739669, 0.00799990513646073, 0.009531054509432108, 0.008695909126711922, 0.008861904689051018, 0.008004358588994724, 0.008163183218053299, 0.008449228257333281, 0.008358177244059694, 0.00778807522241267, 0.007903600076327929, 0.008699514017619406, 0.009797550377712379, 0.008756376001393637, 0.0070962608428354465, 0.008704761324909977, 0.008426120964275498, 0.00787112447541565, 0.007102191104645666, 0.006655571624227935, 0.008690397249451833, 0.007473085602557242, 0.009337975950416973, 0.008195057328778552, 0.00870134977297624, 0.008454294467214171, 0.00821763462312148, 0.00854439482726589, 0.008278198564097448, 0.00826707894986023, 0.008811083875976454, 0.008384625439277572, 0.008499825853904835, 0.008224022437696295, 0.00823905798676567, 0.007890127084631764, 0.007894508757134265, 0.008292978744740475, 0.007199936902324431, 0.008394699048350565, 0.007575979967164014, 0.009483685115910698, 0.008536206855943744, 0.008121999244426168, 0.007956880769816667, 0.007574273552352029, 0.00879554142423238, 0.008438650587757238, 0.007835524667632307, 0.008084023491798317, 0.007821980324088883, 0.007559029113943712, 0.00857527618375979, 0.008168778493223968, 0.007219658591967785, 0.008292199355551685, 0.007794527158526103, 0.0064856711028458, 0.007515114315164558, 0.00720742604312119, 0.008633409381071416, 0.007703114053368937, 0.008168075172239391, 0.008054476932597419, 0.00792800398367681, 0.007435993975903615, 0.007126074217035713, 0.008321287592910712, 0.008534692429751054, 0.00782652355054362, 0.008372510878940769, 0.00835268734953851, 0.00836689091701281, 0.008468878807945765, 0.007537346412009589, 0.007437985560620562, 0.007943972757809246, 0.007870773814392223, 0.008016223401000258, 0.007899405267151582, 0.008263785626909952, 0.007276927215704841, 0.007755607715843788, 0.007942967003786819, 0.007885905085430833, 0.008050327289603048, 0.007742448102439487, 0.008378394925063868, 0.007967171461533426, 0.007362344091287161, 0.007530042349168724, 0.00800277446512473, 0.0072047228752730305, 0.008439190519043224, 0.0076695612979770745, 0.007097484716354917, 0.007512055841244239, 0.007585642400346384, 0.007448779121171866, 0.007729997717711452, 0.007106686192625035, 0.007355400295984376, 0.0078899933008607, 0.00800277446512473, 0.007958964867111614, 0.007982119998883394, 0.007699384122070125, 0.007666941931575364, 0.007144818555699388, 0.007724061356038524, 0.008121126072997246, 0.007394656697691522, 0.007065798072630462, 0.008077022451489148, 0.008135733915976263, 0.007260526917763218, 0.007982119998883394, 0.008086696469034193, 0.008236268348060764, 0.007483933601187248, 0.007400296693454125, 0.008227500988936804, 0.008293961093330126, 0.007331835988226789, 0.00773162332273016, 0.008046593657536235], "accuracy_valid": [0.42737551769578314, 0.5240905026355422, 0.5286276943712349, 0.5475382977221386, 0.572533297251506, 0.5795118952371988, 0.6057275978915663, 0.6292474585843373, 0.6643845891378012, 0.6872838031814759, 0.6978539156626506, 0.7164394884224398, 0.7298378082643072, 0.7278846832643072, 0.7451892531061747, 0.7537135848079819, 0.7454628082643072, 0.7568565276731928, 0.7653102644954819, 0.7544857163027108, 0.7582095961972892, 0.7664706678275602, 0.7761848173945783, 0.7720550169427711, 0.7734992705195783, 0.7832957807793675, 0.7812514707266567, 0.7890845608998494, 0.7905802899096386, 0.7916892178087349, 0.7944968349962349, 0.7996134930346386, 0.7961852291980422, 0.8054125682417168, 0.807030367564006, 0.809105562876506, 0.8074465832078314, 0.8087187617658133, 0.8100615352033133, 0.813988375376506, 0.8145884318524097, 0.8156870646649097, 0.8186373423381024, 0.8149134624435241, 0.8182711314006024, 0.8192271037274097, 0.818504976939006, 0.8206007624246988, 0.8200713008283133, 0.8213228892131024, 0.821434664439006, 0.8204478068524097, 0.8203051463667168, 0.822045016001506, 0.8228892131024097, 0.8228892131024097, 0.8222788615399097, 0.8219023555158133, 0.8240290262612951, 0.822533297251506, 0.8217905802899097, 0.8228892131024097, 0.823876070689006, 0.8219332407756024, 0.823998141001506, 0.8253306193524097, 0.824120211314006, 0.8238657756024097, 0.8253306193524097, 0.8238863657756024, 0.8251070689006024, 0.824974703501506, 0.8254526896649097, 0.825707125376506, 0.8253306193524097, 0.8245981974774097, 0.826195406626506, 0.8252085490399097, 0.8260939264871988, 0.8264292521649097, 0.825218844126506, 0.8272837443524097, 0.827904391001506, 0.8265513224774097, 0.8255644648908133, 0.8269175334149097, 0.8265513224774097, 0.8267954631024097, 0.8270396037274097, 0.8276499552899097, 0.8275278849774097, 0.8269175334149097, 0.8271616740399097, 0.8270396037274097, 0.8272837443524097, 0.828270601939006, 0.8277720256024097, 0.8286265177899097, 0.8276396602033133, 0.827782320689006, 0.8281382365399097, 0.828392672251506, 0.827660250376506, 0.8283823771649097, 0.8278940959149097, 0.829857516001506, 0.8285044474774097, 0.8276499552899097, 0.829247164439006, 0.8286265177899097, 0.8275278849774097, 0.8287485881024097, 0.8286265177899097, 0.828026461314006, 0.8281382365399097, 0.8274058146649097, 0.8282603068524097, 0.828880953501506, 0.8277720256024097, 0.828270601939006, 0.828514742564006, 0.828880953501506, 0.8283823771649097, 0.829125094126506, 0.829857516001506, 0.828514742564006, 0.828514742564006, 0.8286265177899097, 0.828514742564006, 0.828758883189006, 0.8282603068524097, 0.8286265177899097, 0.828636812876506, 0.8292574595256024, 0.828270601939006, 0.8296030802899097, 0.828636812876506, 0.828148531626506, 0.8286265177899097, 0.828880953501506, 0.829125094126506, 0.829003023814006, 0.830223726939006, 0.829491305064006, 0.828758883189006, 0.829369234751506, 0.829613375376506, 0.828270601939006, 0.8282603068524097, 0.829003023814006, 0.828880953501506, 0.828758883189006, 0.829125094126506, 0.828270601939006, 0.828270601939006, 0.829247164439006, 0.8288706584149097, 0.829125094126506, 0.828880953501506, 0.828392672251506, 0.828392672251506, 0.828392672251506, 0.829003023814006, 0.829491305064006, 0.8288706584149097, 0.828392672251506, 0.828880953501506, 0.828758883189006, 0.828636812876506, 0.8282603068524097, 0.828880953501506, 0.829491305064006, 0.829247164439006, 0.829735445689006, 0.8287485881024097, 0.827660250376506, 0.829247164439006, 0.8286265177899097, 0.8288706584149097, 0.8283823771649097, 0.8287691782756024, 0.828880953501506, 0.8282603068524097, 0.829247164439006, 0.829003023814006, 0.829369234751506, 0.828636812876506, 0.8285250376506024, 0.828636812876506, 0.829369234751506, 0.8294810099774097, 0.829613375376506, 0.8291147990399097], "seed": 538118591, "model": "residualv3", "loss_std": [0.25127968192100525, 0.1273145228624344, 0.1270504742860794, 0.1258818358182907, 0.1245604157447815, 0.12532101571559906, 0.12675194442272186, 0.1227356418967247, 0.11825057119131088, 0.11805281043052673, 0.11820614337921143, 0.11712806671857834, 0.11575919389724731, 0.11348768323659897, 0.11335226893424988, 0.11137575656175613, 0.11262255162000656, 0.11023516207933426, 0.10852286964654922, 0.11057028919458389, 0.10641743987798691, 0.10769132524728775, 0.10532122850418091, 0.10265182703733444, 0.10398753732442856, 0.104059599339962, 0.10168281942605972, 0.10158257931470871, 0.1005672961473465, 0.10196565091609955, 0.10030300915241241, 0.0982629731297493, 0.0965673178434372, 0.09664247184991837, 0.09749267250299454, 0.09392771869897842, 0.09623495489358902, 0.09397663921117783, 0.09279096126556396, 0.09264642000198364, 0.0934915617108345, 0.0918700098991394, 0.09106893092393875, 0.09067977219820023, 0.0914694294333458, 0.09259431809186935, 0.08987651765346527, 0.09058204293251038, 0.08963228762149811, 0.08970879018306732, 0.08677387237548828, 0.08880835026502609, 0.08619166165590286, 0.0881100594997406, 0.08744269609451294, 0.08759431540966034, 0.0868837758898735, 0.08519678562879562, 0.08687639236450195, 0.08549930155277252, 0.08603222668170929, 0.0854545533657074, 0.08722151815891266, 0.08409896492958069, 0.08753835409879684, 0.08438083529472351, 0.08478270471096039, 0.08516088128089905, 0.0853862464427948, 0.08598948270082474, 0.0860292911529541, 0.08303683251142502, 0.08546148985624313, 0.08317676186561584, 0.08240653574466705, 0.08474428951740265, 0.0827489122748375, 0.08385881781578064, 0.08294964581727982, 0.08127282559871674, 0.0826793909072876, 0.08422203361988068, 0.08121483772993088, 0.08076972514390945, 0.08336310088634491, 0.08269719779491425, 0.08201451599597931, 0.08280627429485321, 0.08213112503290176, 0.0809035673737526, 0.08082147687673569, 0.0818825289607048, 0.0811007022857666, 0.08398284018039703, 0.08302029967308044, 0.08198017627000809, 0.0826108306646347, 0.08257956057786942, 0.08299169689416885, 0.08020467311143875, 0.0825091302394867, 0.08226609975099564, 0.08057243376970291, 0.08066358417272568, 0.08172469586133957, 0.08101906627416611, 0.08180259168148041, 0.07919587939977646, 0.08233701437711716, 0.08187465369701385, 0.08332808315753937, 0.08347490429878235, 0.08229845762252808, 0.08116580545902252, 0.08159428834915161, 0.08037922531366348, 0.07963164895772934, 0.08166898041963577, 0.08156400918960571, 0.07906097918748856, 0.0823523998260498, 0.08281760662794113, 0.08023097366094589, 0.0812605544924736, 0.08134457468986511, 0.0827496275305748, 0.08173695206642151, 0.07982929795980453, 0.0830303505063057, 0.08218615502119064, 0.0812210962176323, 0.08178985863924026, 0.08047416806221008, 0.07912123948335648, 0.0791935846209526, 0.08115534484386444, 0.08153273165225983, 0.07985664159059525, 0.08151785284280777, 0.08168156445026398, 0.08135698735713959, 0.08195016533136368, 0.08116783946752548, 0.07918773591518402, 0.08013512939214706, 0.08213705569505692, 0.0806557759642601, 0.07968322932720184, 0.08122339844703674, 0.08298641443252563, 0.08183610439300537, 0.08080064505338669, 0.08065996319055557, 0.08126670867204666, 0.08276569843292236, 0.08059366792440414, 0.08154043555259705, 0.08254247158765793, 0.08097760379314423, 0.08208490908145905, 0.08100933581590652, 0.08209633827209473, 0.08117842674255371, 0.08043243736028671, 0.08477783203125, 0.07978207617998123, 0.0810658410191536, 0.08107718825340271, 0.08146439492702484, 0.08228249102830887, 0.08041118830442429, 0.07959835976362228, 0.08042153716087341, 0.08084265887737274, 0.08167587965726852, 0.08036042749881744, 0.07965104281902313, 0.08096753060817719, 0.08237729966640472, 0.08115188032388687, 0.08265925943851471, 0.08123724162578583, 0.08260183781385422, 0.08269138634204865, 0.08394968509674072, 0.08169492334127426, 0.08047772943973541, 0.08024777472019196, 0.08158174902200699, 0.07995814830064774, 0.08237724006175995, 0.08071150630712509, 0.08145394921302795]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:23 2016", "state": "available"}], "summary": "142967e9e0b815c2e09a9120467fb98e"}