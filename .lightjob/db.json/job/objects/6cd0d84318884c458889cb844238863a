{"content": {"hp_model": {"f0": 16, "f1": 32, "f2": 64, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.013010323991444937, 0.012067302000502272, 0.015831451536953617, 0.015127360409345083, 0.015473492089061968, 0.015890476149445977, 0.016224861235498628, 0.01672461408730332, 0.01328221931785701, 0.015533141743152035, 0.014188915892220107, 0.012184972036560049, 0.013461238032118149, 0.01220849409238276, 0.012280668595797632, 0.011485931042813381, 0.011904722586042249, 0.011424368285921466, 0.010743021798913668, 0.010379912276944276, 0.009721744832570444, 0.01126406944630627, 0.011264069446306271, 0.012156353969207152, 0.01207735934489409, 0.011322672834011864, 0.01259909568251567, 0.010824060204258445, 0.012048329843034385, 0.0114980412031078, 0.010699072556790628, 0.012431452326882333, 0.012492146518812745, 0.01196849413005968, 0.012112708937174853, 0.011486204481003178, 0.010228442790905167, 0.010298551885601826, 0.011614433259268857, 0.011778521465354403, 0.012157461384185891, 0.010033269117513384, 0.00957435857946185, 0.010708192523619152, 0.008517122066963896, 0.008788347657413355, 0.009157312027512464, 0.009251939048146904, 0.010648445224539506, 0.009403242326997184, 0.009216027041461596, 0.009585462987278666, 0.009741862348549657, 0.008750071650167945, 0.00880265559482328, 0.008835501014810239, 0.007401138442407591, 0.009355800795321834, 0.009924557632872665, 0.00886158481300684, 0.0093195313365083, 0.009554414507186703, 0.009972488080946366, 0.008147018065395068, 0.009859838819063708, 0.009963410570961142, 0.009519899815737127, 0.009374924280712954, 0.008570682147650891, 0.0079345930753359, 0.008665287694025291, 0.008046930340007497, 0.009625973155662595, 0.01005886022428321, 0.009515287768799842, 0.009546641480614477, 0.010130345994013433, 0.009425744635195243, 0.009752434038980679, 0.009943166780063736, 0.009349582292781333, 0.010069590057192473, 0.009872279714360036, 0.009622376250619666, 0.009701856600869295, 0.01027724761474239, 0.012009568810169605, 0.010703359734247242, 0.010712053227537521, 0.010242390482569167, 0.011145168932857075, 0.010818975181966875, 0.009991049629632274, 0.010689773018703152, 0.01040630643980053, 0.011452533648886664, 0.010357193255716891, 0.01127668411678456, 0.009968787832374525, 0.010607557258157294, 0.009638483081513476, 0.009684344395646976, 0.011208882096876293, 0.011335984699727547, 0.010737321462039928, 0.010489743401668984, 0.010402539366031348, 0.01053106004623747, 0.009683009540245636, 0.009208918406559624, 0.011304479145918601, 0.011283368805560927, 0.01072694981910461, 0.01085181411639253, 0.009203239014762738, 0.010674604084045046, 0.010411471267654017, 0.011164747737865424, 0.01053855843616794, 0.008971449482596953, 0.010244578123181091, 0.010806247353672471, 0.009896618244949616, 0.00912621419467266, 0.010501517282225554, 0.01099218348252429, 0.00905367372321672, 0.010217580858616971, 0.010096990845850449, 0.01042182095242187, 0.008876906367554952, 0.009008577630156464, 0.00837166758257326, 0.009874307186254599, 0.010504174419392087, 0.009506900767892151, 0.010401534166703344, 0.010099159864288535, 0.010113345743903112, 0.009825171679807607, 0.009136579076005819, 0.01024424831769953, 0.009905291404901295, 0.0096538147087186, 0.00915298177036711, 0.008997101172851726, 0.009338855209644238, 0.010793746599148892, 0.008444744820386462, 0.009003509432953943, 0.009983961478066175, 0.009605528710771603, 0.010971912239819009, 0.011309442268259674, 0.009378369883427001, 0.009286829144734929, 0.009002846215646138, 0.010423071151675633, 0.010984610666358252, 0.010144106587452342, 0.009331851382817872, 0.00988378911958228, 0.009322461798906391, 0.009587305872257671, 0.01034195408529358, 0.01017628486712266, 0.008769010450214575, 0.009897313251632697, 0.00857259292786335, 0.010056547547597562, 0.010430490916124418, 0.009886985518670491, 0.010260013368310684, 0.00920860647398238, 0.010595372779994007, 0.009387242137418358, 0.01118512820724051, 0.009632367131608687, 0.009752544492050262, 0.01073488091616498, 0.011574861258787768, 0.010303248835155095, 0.0095052387959238, 0.009459557909549866, 0.009750849742590318, 0.01025795806925241, 0.00869684521644296, 0.009326620601434478, 0.010172243043932714, 0.010040932552891034, 0.010273033908177761, 0.009897313251632697, 0.009862841653813412, 0.009464652374056377, 0.010081189175789328, 0.010935591986579932, 0.009743113658887977, 0.009721424323642371, 0.009610871692303418, 0.008423436930916562, 0.00939428249283391, 0.009160046443749422, 0.009828387142543804, 0.01004625938551272, 0.009040725554113598, 0.009168822802285741, 0.009497648828375484, 0.008313131872504797, 0.009857435344069276, 0.01051893964091466, 0.010478584253291307, 0.01026380240556536, 0.009848168323875571, 0.010135466203609944, 0.008988501871122663, 0.00951029480256001, 0.010046698603598518, 0.008781632386627195, 0.008657167215933985, 0.009418227485440252, 0.009317834087413036, 0.010033895268827121, 0.008829707842333761, 0.01024625147958393, 0.008967356078697806, 0.008924137518474354, 0.010751191725689757, 0.00963437055294996, 0.008812418260991297, 0.008252825737622286, 0.00995906592613029, 0.010321005886029166, 0.008507338859030947, 0.008766746729706001, 0.009150387549315957, 0.010034826069865228, 0.008867253731825083, 0.00840524646248425, 0.01050131254232192, 0.009594896267859074, 0.00870352612300557, 0.009826670914571635, 0.00991487384039178, 0.009921498916025302, 0.009380742302960751, 0.009455733916002568], "moving_avg_accuracy_train": [0.01150721553156146, 0.024441939051541156, 0.036734195837370795, 0.04825284796482788, 0.05896586575924579, 0.06879366577662131, 0.0779292212469935, 0.08633963032153742, 0.09414619971601712, 0.10120237515439141, 0.1077318253119866, 0.11359437956096513, 0.11898461067671247, 0.12394742582374221, 0.12851619390605054, 0.13258870184564112, 0.13632829165553992, 0.1397427866582676, 0.14286702148335076, 0.14580893301280268, 0.14842181220598533, 0.15086179518343035, 0.15302984202859782, 0.1550205756701917, 0.15683781258453097, 0.1585477666181598, 0.16013079492935048, 0.16154407490946823, 0.16279967875227003, 0.1639948263774583, 0.16509603587703253, 0.1661104840612008, 0.16701876503169572, 0.16789441872301675, 0.16874049157016874, 0.1695275337695103, 0.1702150175072695, 0.17094067366767213, 0.17157981331917732, 0.17218057959361802, 0.172730677982309, 0.17321868293924605, 0.17375557969930816, 0.17421317409764053, 0.17463445384665277, 0.1750437604576501, 0.17541442550753847, 0.17579914127742877, 0.17612678427985384, 0.17650075409037896, 0.1767908239436611, 0.1770333937675951, 0.1772864756948223, 0.17755613815671697, 0.1777872446771933, 0.17809053559799373, 0.17834951048503822, 0.17861281481790206, 0.17881487543651792, 0.17900370543970073, 0.1792131799723272, 0.1793552401243193, 0.17953664478136874, 0.17975800164413258, 0.1799734988622867, 0.18019534814433968, 0.1803554489196067, 0.1805740164768893, 0.18075445123677697, 0.1809376607135053, 0.18109092349851322, 0.181242882995515, 0.18130981998089338, 0.1814701528129997, 0.18150041192377242, 0.1816253734711054, 0.18183309786725807, 0.1819597041012041, 0.18205966277007962, 0.18211936258872502, 0.18222664294576246, 0.18228363168851547, 0.18233263245700243, 0.1824580412593365, 0.1825151056100086, 0.18256657167206977, 0.18258724239338253, 0.1825872809009066, 0.18266168427076424, 0.1828378211512275, 0.18288484534724353, 0.18300386098555352, 0.18306450813266076, 0.18318884502934302, 0.1832356440696904, 0.1832823774548033, 0.18337086837995792, 0.18342965597094885, 0.18342218303143054, 0.18346410526677032, 0.18347178858814608, 0.1835111114654426, 0.18362097891455173, 0.18372218476755944, 0.1838039694400283, 0.18383808416430714, 0.18395478187329173, 0.18398300780302604, 0.18390624878744288, 0.18397660250435197, 0.18401201906385586, 0.1840833854483525, 0.1841337003503611, 0.184190537408579, 0.18424176285861257, 0.18426933667080408, 0.1843358615850729, 0.1844352615376767, 0.18452933574382044, 0.18455827105555872, 0.1846168649194565, 0.1846812611898309, 0.1846950400057869, 0.1846841894520521, 0.18474646751796722, 0.18483506986062417, 0.18492407651543477, 0.18493682528692562, 0.18497849006697245, 0.18505319074996698, 0.18503446295634718, 0.18508256791348102, 0.18506086635469104, 0.1850436601005896, 0.1851164580290227, 0.1850936205098506, 0.18520560022473856, 0.185285455628852, 0.1853550724413821, 0.185473495095269, 0.18550327347541543, 0.1855393746127853, 0.18555330049476074, 0.18564721399687195, 0.18569914801662, 0.18571584194396315, 0.18573308348092527, 0.18574398661539088, 0.18577236457806737, 0.18579794079329495, 0.18583480213340067, 0.18586808548595207, 0.18590272684968612, 0.1858920153496566, 0.18593105892935502, 0.18594301876062586, 0.18597478104569282, 0.18600096985580608, 0.1860385267265839, 0.18604206492694142, 0.18608241563939676, 0.1860769867484914, 0.18605113835857215, 0.18606747443504418, 0.18609373055027917, 0.1861126386587341, 0.18607857478017148, 0.1861292974977985, 0.18612161371631875, 0.18612152956414052, 0.18616098135694203, 0.18618479012877828, 0.18622024101392554, 0.18627067590339677, 0.18631610335273965, 0.1863338086666905, 0.18643795490873316, 0.1864574980575793, 0.18648656844031344, 0.18648490209669738, 0.1865763001933676, 0.186602790957761, 0.18658485206478115, 0.18656638191228975, 0.18663331993691532, 0.18662849604123044, 0.18661023969107565, 0.18664270919857384, 0.1867182905362377, 0.1867165953246682, 0.1867708732056842, 0.1867942548081501, 0.18685239248486554, 0.18689534370103383, 0.18692241010035646, 0.18696311799905097, 0.18699514085907576, 0.1870286117307171, 0.1870424234247089, 0.18713158386001577, 0.18715362743391636, 0.18721986148016112, 0.18727965236587518, 0.18726374574755086, 0.18726803098153516, 0.1872973922313883, 0.1872656165383805, 0.18722782596589166, 0.18725190712207104, 0.18728509776022384, 0.18733371472031257, 0.18732864185939244, 0.1873310156821741, 0.18734713906435352, 0.18739184099402004, 0.18744140937477677, 0.18743247039720126, 0.18748727643287794, 0.187490026791159, 0.18749493540887774, 0.18751087076241596, 0.18749269654608577, 0.18752287877639784, 0.18757086097650816, 0.18758628736616817, 0.18763722930253954, 0.18765059705957796, 0.187660302892103, 0.1877062765711467, 0.18774293048702945, 0.18775495662321945, 0.18776578014579043, 0.18778947220896147, 0.1877899408241672, 0.18778810952668035, 0.18774460868037074, 0.18778436878294089, 0.1877876728895582, 0.18785807590099, 0.18792369166245063, 0.1879199307810893, 0.18790967868789177, 0.18787720031591876, 0.18782468224422905, 0.18774958629163155, 0.1877748977402185], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 299412782, "moving_var_accuracy_train": [0.0011917440836082837, 0.0025783333280922993, 0.003680396187282043, 0.004506470690054183, 0.005088742373420399, 0.005449139014712098, 0.0056553504770111155, 0.00572643025652054, 0.005702269962265931, 0.005580149472393389, 0.005405837999398728, 0.005174580080358801, 0.004918613395653458, 0.004648417863740404, 0.004371438853475637, 0.004083562856390329, 0.003801067358267986, 0.003525889607554057, 0.0032611482359790134, 0.0030129270034052118, 0.0027730785421681914, 0.0025493523403233662, 0.002336720950396596, 0.0021387160392428994, 0.0019545655853441452, 0.001785424511983843, 0.001629435868491739, 0.0014844685243623795, 0.0013502105410166693, 0.0012280448875289411, 0.0011161543600336195, 0.0010138008700955187, 0.0009198455519782353, 0.0008347619212645289, 0.0007577282825022671, 0.0006875303730639401, 0.0006230310407646962, 0.000565467128456399, 0.000512596911057895, 0.0004645855010006538, 0.0004208504250357522, 0.00038090872207413324, 0.00034541217304540664, 0.0003127554894413326, 0.00028307723013954974, 0.00025627729424184987, 0.0002318860980305436, 0.00021002954423990984, 0.00018999273924926195, 0.00017225214609699365, 0.00015578419616534242, 0.00014073533762415852, 0.00012723825801874396, 0.00011516889280706536, 0.00010413269554061891, 9.45472944303167e-05, 8.569617691636234e-05, 7.775052177006996e-05, 7.034292603542174e-05, 6.362954436279782e-05, 5.766150614488969e-05, 5.2076985311456856e-05, 4.716545562670415e-05, 4.288989981026753e-05, 3.901886128853021e-05, 3.555992909520401e-05, 3.223462650985355e-05, 2.9441109852736514e-05, 2.679000919064434e-05, 2.4413099682847617e-05, 2.2183195045978267e-05, 2.017270073994169e-05, 1.819575570605141e-05, 1.6607539688907336e-05, 1.4955026244079421e-05, 1.3600062114478158e-05, 1.2628400725843213e-05, 1.150982289952486e-05, 1.0448766228922686e-05, 9.435966221147081e-06, 8.595951274087075e-06, 7.765585597883503e-06, 7.010636715905963e-06, 6.451119353641199e-06, 5.835314479335745e-06, 5.275621831298913e-06, 4.751905156645334e-06, 4.276714654326265e-06, 3.898865941909224e-06, 3.7881971536522604e-06, 3.4292789133856367e-06, 3.2138335215080537e-06, 2.925552857427489e-06, 2.77213454657388e-06, 2.5146324435133876e-06, 2.2828252827190526e-06, 2.125018548959584e-06, 1.9436205217542656e-06, 1.749761073004235e-06, 1.5906022300467676e-06, 1.4320733078883591e-06, 1.3027825752094042e-06, 1.2811420250521668e-06, 1.2452114446941517e-06, 1.180888894082289e-06, 1.0732743343876402e-06, 1.0885120984891e-06, 9.868312166244917e-07, 9.411756132216904e-07, 8.916048612458429e-07, 8.13733369305095e-07, 7.781984798997088e-07, 7.231629361869553e-07, 6.79920703249999e-07, 6.355450535052779e-07, 5.78833384223715e-07, 5.607801237675807e-07, 5.93625266589601e-07, 6.139123462848058e-07, 5.600563820448568e-07, 5.349499118186392e-07, 5.187768373799656e-07, 4.6860785556431353e-07, 4.228066806550557e-07, 4.1543303003671415e-07, 4.445431031517414e-07, 4.713884542417272e-07, 4.2571238938828843e-07, 3.987647355166113e-07, 4.0910999032358173e-07, 3.7135556357601857e-07, 3.550467893260469e-07, 3.23780729278669e-07, 2.9406715297263176e-07, 3.123562831327304e-07, 2.858146253568862e-07, 3.700882717386921e-07, 3.904714146599187e-07, 3.9504277847556357e-07, 4.817538252105348e-07, 4.4155921000677863e-07, 4.091329180806792e-07, 3.699649979717557e-07, 4.123462110837431e-07, 3.953858716400579e-07, 3.583554693673036e-07, 3.2519535780191883e-07, 2.9374572709230447e-07, 2.7161893327408847e-07, 2.5034432501499346e-07, 2.3753871806300051e-07, 2.237548802702509e-07, 2.1217960897542815e-07, 1.9199427417382705e-07, 1.8651445679744805e-07, 1.6915034919394751e-07, 1.613148990486401e-07, 1.5135609312011095e-07, 1.4891515069170142e-07, 1.3413630537845848e-07, 1.3537629480150875e-07, 1.2210392102951716e-07, 1.1590678227933722e-07, 1.0671791060191189e-07, 1.0225057182680753e-07, 9.524316373221317e-08, 9.616197776353491e-08, 1.0970092673839574e-07, 9.926219854501154e-08, 8.933604242481226e-08, 9.441043377962225e-08, 9.007110894881586e-08, 9.237488537346118e-08, 1.0603049951989607e-07, 1.140003279520915e-07, 1.0542159843576307e-07, 1.9249739617664548e-07, 1.7668506856038157e-07, 1.6662234607512436e-07, 1.49985101777033e-07, 2.1016910027381325e-07, 1.954680356297515e-07, 1.788174669988643e-07, 1.6400603909647933e-07, 1.8793172745381088e-07, 1.6934798443463803e-07, 1.5541283487994237e-07, 1.4935997164652647e-07, 1.8583682190937215e-07, 1.672790033988235e-07, 1.770658983672405e-07, 1.642796025353816e-07, 1.782715473666692e-07, 1.7704765536302644e-07, 1.659361995773403e-07, 1.6425677676471195e-07, 1.5706027116573182e-07, 1.5143693728503365e-07, 1.3801010957483423e-07, 1.9575534763437848e-07, 1.8055308522374228e-07, 2.0198031663894426e-07, 2.139568351052819e-07, 1.9483833615339445e-07, 1.755197716107568e-07, 1.657265413861204e-07, 1.5824113924263285e-07, 1.5527017163968063e-07, 1.4496227322213556e-07, 1.4038061204883805e-07, 1.4761503011837343e-07, 1.330851323677725e-07, 1.19827334442385e-07, 1.1018427207427775e-07, 1.1715020751005273e-07, 1.2754840609664105e-07, 1.1551271336783424e-07, 1.30994755950413e-07, 1.1796336059143895e-07, 1.0638387528347215e-07, 9.803090718661615e-08, 9.120053572090394e-08, 9.0279185388305e-08, 1.019718905963048e-07, 9.391646301815365e-08, 1.0788054464772165e-07, 9.870076253708959e-08, 8.967851494841755e-08, 9.973287593686641e-08, 1.0185117428903543e-07, 9.296770842507682e-08, 8.472527535017482e-08, 8.13045725308663e-08, 7.31760916796791e-08, 6.588866536607952e-08, 7.63307114963336e-08, 8.292543215420795e-08, 7.473114302363451e-08, 1.1186728488923621e-07, 1.394294097688197e-07, 1.2561376684946457e-07, 1.1399833889889463e-07, 1.1209210682315849e-07, 1.2570622682687952e-07, 1.638902230129346e-07, 1.5326722557776338e-07], "duration": 238945.210675, "accuracy_train": [0.11507215531561461, 0.14085445073135844, 0.14736450690983757, 0.15192071711194166, 0.15538302590900702, 0.1572438659330011, 0.1601492204803433, 0.16203331199243265, 0.16440532426633445, 0.16470795409976008, 0.1664968767303433, 0.16635736780177188, 0.16749669071843853, 0.16861276214701, 0.1696351066468254, 0.16924127330195646, 0.16998459994462903, 0.17047324168281652, 0.1709851349090993, 0.17228613677787005, 0.17193772494462903, 0.1728216419804356, 0.17254226363510522, 0.17293717844453674, 0.17319294481358435, 0.1739373529208195, 0.17437804973006643, 0.17426359473052788, 0.17410011333748615, 0.17475115500415284, 0.17500692137320045, 0.17524051771871538, 0.17519329376614987, 0.17577530194490587, 0.17635514719453674, 0.17661091356358435, 0.17640237114710225, 0.17747157911129569, 0.17733207018272426, 0.17758747606358435, 0.17768156348052788, 0.1776107275516796, 0.1785876505398671, 0.17833152368263197, 0.17842597158776302, 0.17872751995662606, 0.1787504109565338, 0.17926158320644148, 0.1790755713016796, 0.17986648238510522, 0.17940145262320045, 0.1792165221830011, 0.1795642130398671, 0.1799831003137689, 0.17986720336148027, 0.18082015388519748, 0.18068028446843853, 0.18098255381367664, 0.18063342100406055, 0.18070317546834624, 0.18109845076596529, 0.18063378149224807, 0.18116928669481358, 0.18175021340900702, 0.18191297382567367, 0.18219199168281652, 0.18179635589701, 0.18254112449243265, 0.18237836407576596, 0.18258654600406055, 0.18247028856358435, 0.18261051846853082, 0.18191225284929863, 0.18291314830195646, 0.1817727439207272, 0.18275002739710225, 0.18370261743263197, 0.18309916020671835, 0.1829592907899594, 0.1826566609565338, 0.1831921661590993, 0.18279653037329271, 0.18277363937338503, 0.1835867204803433, 0.1830286847660576, 0.18302976623062014, 0.18277327888519748, 0.18258762746862311, 0.1833313145994832, 0.18442305307539683, 0.18330806311138798, 0.1840750017303433, 0.18361033245662606, 0.1843078770994832, 0.18365683543281652, 0.1837029779208195, 0.18416728670634921, 0.1839587442898671, 0.18335492657576596, 0.18384140538482835, 0.18354093848052788, 0.1838650173611111, 0.1846097859565338, 0.18463303744462903, 0.18454003149224807, 0.18414511668281652, 0.18500506125415284, 0.18423704117063494, 0.18321541764719454, 0.1846097859565338, 0.18433076809939092, 0.18472568290882244, 0.18458653446843853, 0.18470207093253968, 0.18470279190891473, 0.18451750098052788, 0.18493458581349206, 0.1853298611111111, 0.18537600359911405, 0.1848186888612034, 0.18514420969453674, 0.18526082762320045, 0.18481904934939092, 0.18458653446843853, 0.1853069701112034, 0.18563249094453674, 0.18572513640873017, 0.1850515642303433, 0.18535347308739386, 0.18572549689691767, 0.1848659128137689, 0.1855155125276855, 0.1848655523255814, 0.18488880381367664, 0.18577163938492064, 0.1848880828373016, 0.18621341765873017, 0.18600415426587302, 0.18598162375415284, 0.186539298980251, 0.18577127889673312, 0.18586428484911405, 0.18567863343253968, 0.18649243551587302, 0.18616655419435216, 0.1858660872900517, 0.18588825731358435, 0.1858421148255814, 0.18602776624215578, 0.1860281267303433, 0.18616655419435216, 0.18616763565891473, 0.18621449912329271, 0.18579561184939092, 0.18628245114664083, 0.1860506572420635, 0.18626064161129569, 0.1862366691468254, 0.18637653856358435, 0.18607390873015875, 0.186445572051495, 0.1860281267303433, 0.18581850284929863, 0.18621449912329271, 0.18633003558739386, 0.18628281163482835, 0.18577199987310816, 0.18658580195644148, 0.1860524596830011, 0.18612077219453674, 0.18651604749215578, 0.18639906907530454, 0.186539298980251, 0.18672458990863788, 0.1867249503968254, 0.18649315649224807, 0.18737527108711702, 0.18663338639719454, 0.18674820188492064, 0.18646990500415284, 0.18739888306339977, 0.1868412078373016, 0.18642340202796234, 0.1864001505398671, 0.1872357621585456, 0.18658508098006643, 0.18644593253968256, 0.1869349347660576, 0.18739852257521225, 0.18670133842054262, 0.18725937413482835, 0.1870046892303433, 0.18737563157530454, 0.18728190464654854, 0.1871660076942599, 0.1873294890873016, 0.18728334659929863, 0.1873298495754891, 0.18716672867063494, 0.1879340277777778, 0.18735201959902179, 0.18781596789636396, 0.1878177703373016, 0.18712058618263197, 0.18730659808739386, 0.18756164348006643, 0.18697963530131045, 0.18688771081349206, 0.1874686375276855, 0.18758381350359912, 0.1877712673611111, 0.1872829861111111, 0.1873523800872093, 0.18749224950396826, 0.18779415836101881, 0.1878875248015873, 0.18735201959902179, 0.18798053075396826, 0.18751478001568844, 0.18753911296834624, 0.1876542889442599, 0.18732912859911405, 0.18779451884920637, 0.18800270077750092, 0.18772512487310816, 0.18809570672988188, 0.18777090687292358, 0.18774765538482835, 0.18812003968253968, 0.18807281572997417, 0.1878631918489295, 0.1878631918489295, 0.18800270077750092, 0.18779415836101881, 0.18777162784929863, 0.18735310106358435, 0.18814220970607234, 0.18781740984911405, 0.18849170300387597, 0.18851423351559615, 0.1878860828488372, 0.18781740984911405, 0.1875848949681617, 0.18735201959902179, 0.18707372271825398, 0.18800270077750092], "end": "2016-01-28 08:50:35.793000", "learning_rate_per_epoch": [0.00018585840007290244, 9.292920003645122e-05, 6.195280002430081e-05, 4.646460001822561e-05, 3.717168146977201e-05, 3.097640001215041e-05, 2.655120078998152e-05, 2.3232300009112805e-05, 2.0650933947763406e-05, 1.8585840734886006e-05, 1.689621785772033e-05, 1.5488200006075203e-05, 1.4296800145530142e-05, 1.327560039499076e-05, 1.2390560186759103e-05, 1.1616150004556403e-05, 1.0932847544609103e-05, 1.0325466973881703e-05, 9.782021152204834e-06, 9.292920367443003e-06, 8.850400263327174e-06, 8.448108928860165e-06, 8.08080039860215e-06, 7.744100003037602e-06, 7.434336112055462e-06, 7.148400072765071e-06, 6.883644346089568e-06, 6.63780019749538e-06, 6.408910394384293e-06, 6.1952800933795515e-06, 5.995432275085477e-06, 5.808075002278201e-06, 5.63207277082256e-06, 5.466423772304552e-06, 5.310239885147894e-06, 5.1627334869408514e-06, 5.0232001740369014e-06, 4.891010576102417e-06, 4.765599896927597e-06, 4.646460183721501e-06, 4.533131686912384e-06, 4.425200131663587e-06, 4.322288532421226e-06, 4.224054464430083e-06, 4.130186880502151e-06, 4.040400199301075e-06, 3.954434305342147e-06, 3.872050001518801e-06, 3.79302855435526e-06, 3.717168056027731e-06, 3.644282514869701e-06, 3.5742000363825355e-06, 3.5067623684881255e-06, 3.441822173044784e-06, 3.3792437079682713e-06, 3.31890009874769e-06, 3.2606737931928365e-06, 3.2044551971921464e-06, 3.1501424473390216e-06, 3.0976400466897758e-06, 3.0468590921373107e-06, 2.9977161375427386e-06, 2.950133421109058e-06, 2.9040375011391006e-06, 2.8593601655302336e-06, 2.81603638541128e-06, 2.7740061341319233e-06, 2.733211886152276e-06, 2.693599981284933e-06, 2.655119942573947e-06, 2.617724021547474e-06, 2.5813667434704257e-06, 2.5460055894654943e-06, 2.5116000870184507e-06, 2.4781120373518206e-06, 2.4455052880512085e-06, 2.4137455056916224e-06, 2.3827999484637985e-06, 2.352637920921552e-06, 2.3232300918607507e-06, 2.2945482669456396e-06, 2.266565843456192e-06, 2.239257810288109e-06, 2.2126000658317935e-06, 2.1865694179723505e-06, 2.161144266210613e-06, 2.1363034647947643e-06, 2.1120272322150413e-06, 2.088296696456382e-06, 2.0650934402510757e-06, 2.042399955826113e-06, 2.0202000996505376e-06, 1.9984775008197175e-06, 1.9772171526710736e-06, 1.956404275915702e-06, 1.9360250007594004e-06, 1.916065912155318e-06, 1.89651427717763e-06, 1.8773575902741868e-06, 1.8585840280138655e-06, 1.8401822217128938e-06, 1.8221412574348506e-06, 1.8044505623038276e-06, 1.7871000181912677e-06, 1.7700800754028023e-06, 1.7533811842440628e-06, 1.7369944771417067e-06, 1.720911086522392e-06, 1.7051229406206403e-06, 1.6896218539841357e-06, 1.6743999822210753e-06, 1.659450049373845e-06, 1.644764665797993e-06, 1.6303368965964182e-06, 1.616160034245695e-06, 1.6022275985960732e-06, 1.5885333368714782e-06, 1.5750712236695108e-06, 1.5618353472746094e-06, 1.5488200233448879e-06, 1.5360199085989734e-06, 1.5234295460686553e-06, 1.5110439335330739e-06, 1.4988580687713693e-06, 1.4868671769363573e-06, 1.475066710554529e-06, 1.4634520084655378e-06, 1.4520187505695503e-06, 1.4407628441404086e-06, 1.4296800827651168e-06, 1.4187664874043548e-06, 1.40801819270564e-06, 1.3974315606901655e-06, 1.3870030670659617e-06, 1.3767289601673838e-06, 1.366605943076138e-06, 1.3566307188739302e-06, 1.3467999906424666e-06, 1.3371108025239664e-06, 1.3275599712869735e-06, 1.3181446547605447e-06, 1.308862010773737e-06, 1.2997090834687697e-06, 1.2906833717352129e-06, 1.2817821470889612e-06, 1.2730027947327471e-06, 1.2643429272429785e-06, 1.2558000435092254e-06, 1.2473718697947334e-06, 1.2390560186759103e-06, 1.2308503301028395e-06, 1.2227526440256042e-06, 1.2147608003942878e-06, 1.2068727528458112e-06, 1.1990864550170954e-06, 1.1913999742318993e-06, 1.183811491500819e-06, 1.176318960460776e-06, 1.1689207894960418e-06, 1.1616150459303753e-06, 1.1544000244612107e-06, 1.1472741334728198e-06, 1.1402355539757991e-06, 1.133282921728096e-06, 1.1264145314271445e-06, 1.1196289051440544e-06, 1.1129245649499353e-06, 1.1063000329158967e-06, 1.0997538311130484e-06, 1.0932847089861752e-06, 1.0868913022932247e-06, 1.0805721331053064e-06, 1.0743260645540431e-06, 1.0681517323973821e-06, 1.0620479997669463e-06, 1.0560136161075206e-06, 1.050047444550728e-06, 1.044148348228191e-06, 1.038315076584695e-06, 1.0325467201255378e-06, 1.0268420282955049e-06, 1.0211999779130565e-06, 1.015619659483491e-06, 1.0101000498252688e-06, 1.0046400120700127e-06, 9.992387504098588e-07, 9.938952416632674e-07, 9.886085763355368e-07, 9.833778449319652e-07, 9.78202137957851e-07, 9.730806596053299e-07, 9.680125003797002e-07, 9.62996864473098e-07, 9.58032956077659e-07, 9.531200362289383e-07, 9.48257138588815e-07, 9.434436947231006e-07, 9.386787951370934e-07, 9.339618145531858e-07, 9.292920140069327e-07, 9.246686545338889e-07, 9.200911108564469e-07, 9.155586440101615e-07, 9.110706287174253e-07, 9.066263828572119e-07, 9.022252811519138e-07, 8.978666983239236e-07, 8.935500090956339e-07, 8.892746450328559e-07, 8.850400377014012e-07, 8.808455049802433e-07, 8.766905921220314e-07, 8.72574673849158e-07, 8.684972385708534e-07, 8.644577178529289e-07, 8.60455543261196e-07, 8.564903168917226e-07, 8.525614703103201e-07, 8.486684919262188e-07, 8.448109269920678e-07, 8.409882639170974e-07, 8.371999911105377e-07, 8.334457675118756e-07, 8.297250246869226e-07, 8.260373647317465e-07, 8.223823328989965e-07, 8.187594744413218e-07, 8.151684482982091e-07, 8.116087428788887e-07, 8.080800171228475e-07, 8.045818162827345e-07, 8.011137992980366e-07, 7.976755682648218e-07, 7.942666684357391e-07, 7.908868155936943e-07, 7.875356118347554e-07, 7.842126592549903e-07, 7.809176736373047e-07, 7.776502002343477e-07, 7.744100116724439e-07, 7.711967100476613e-07, 7.680099542994867e-07, 7.648494033674069e-07, 7.617147730343277e-07, 7.586057222397358e-07, 7.555219667665369e-07], "accuracy_valid": [0.12122023249246988, 0.14421210231551204, 0.15149661144578314, 0.15652208443147592, 0.15947236210466867, 0.16217849915286145, 0.16339920227786145, 0.1653729174510542, 0.16680687594126506, 0.1683026049510542, 0.16840408509036145, 0.16924828219126506, 0.17146613798945784, 0.17095726656626506, 0.17303246187876506, 0.17449730562876506, 0.17242211031626506, 0.17436494022966867, 0.17460908085466867, 0.1756974185805723, 0.1750870670180723, 0.1764298404555723, 0.1764298404555723, 0.17814911991716867, 0.17864769625376506, 0.17839326054216867, 0.17864769625376506, 0.17803734469126506, 0.17988898955195784, 0.18000076477786145, 0.17863740116716867, 0.18013313017695784, 0.1811199877635542, 0.17974632906626506, 0.18135383330195784, 0.18062141142695784, 0.17974632906626506, 0.18169945406626506, 0.17951248352786145, 0.18208625517695784, 0.1825848315135542, 0.18182152437876506, 0.18230980562876506, 0.18097732727786145, 0.1808243717055723, 0.1818009342055723, 0.18145531344126506, 0.1815567935805723, 0.18403938017695784, 0.18255394625376506, 0.18217744022966867, 0.1814347232680723, 0.1830216373305723, 0.18229951054216867, 0.18328636812876506, 0.18278779179216867, 0.1833878482680723, 0.18229951054216867, 0.18316429781626506, 0.1820450748305723, 0.1822892154555723, 0.18365257906626506, 0.18316429781626506, 0.1821671451430723, 0.18340843844126506, 0.18267601656626506, 0.18304222750376506, 0.1827774967055723, 0.18437470585466867, 0.1824112857680723, 0.18264513130647592, 0.1838761295180723, 0.18401879000376506, 0.18353050875376506, 0.18340843844126506, 0.18377464937876506, 0.18400849491716867, 0.18401879000376506, 0.18513801298945784, 0.18488357727786145, 0.18414086031626506, 0.18599250517695784, 0.18512771790286145, 0.18415115540286145, 0.18500564759036145, 0.18549392884036145, 0.1872235033885542, 0.18538215361445784, 0.18599250517695784, 0.18549392884036145, 0.1864910815135542, 0.18660285673945784, 0.18609398531626506, 0.18599250517695784, 0.18733527861445784, 0.1869793627635542, 0.1883221362010542, 0.1880779955760542, 0.18670433687876506, 0.18660285673945784, 0.18708084290286145, 0.18756912415286145, 0.18806770048945784, 0.18794563017695784, 0.1888104174510542, 0.18720291321536145, 0.18744705384036145, 0.18843391142695784, 0.18732498352786145, 0.18830154602786145, 0.1885662768260542, 0.1885662768260542, 0.1890545580760542, 0.1883221362010542, 0.18706025272966867, 0.1883221362010542, 0.1889324877635542, 0.1897869799510542, 0.18818977080195784, 0.18780296969126506, 0.18707054781626506, 0.1894207690135542, 0.18854568665286145, 0.18768089937876506, 0.18831184111445784, 0.1894207690135542, 0.18854568665286145, 0.18782355986445784, 0.1896649096385542, 0.1888104174510542, 0.18828095585466867, 0.18915603821536145, 0.18755882906626506, 0.18817947571536145, 0.1894207690135542, 0.18805740540286145, 0.1894207690135542, 0.1894207690135542, 0.18953254423945784, 0.1900311205760542, 0.18927810852786145, 0.18866775696536145, 0.19014289580195784, 0.1900311205760542, 0.18915603821536145, 0.18903396790286145, 0.18854568665286145, 0.1889324877635542, 0.18914574312876506, 0.1911297533885542, 0.18805740540286145, 0.18953254423945784, 0.1899090502635542, 0.1901634859751506, 0.18928840361445784, 0.1901531908885542, 0.19001053040286145, 0.1899193453501506, 0.1907635424510542, 0.1896649096385542, 0.19026496611445784, 0.1901531908885542, 0.18903396790286145, 0.1905194018260542, 0.1896649096385542, 0.18965461455195784, 0.19014289580195784, 0.19038703642695784, 0.18952224915286145, 0.1908856127635542, 0.1913738940135542, 0.1911297533885542, 0.1905194018260542, 0.19049881165286145, 0.19038703642695784, 0.18964431946536145, 0.1916283297251506, 0.1910076830760542, 0.19075324736445784, 0.19050910673945784, 0.1913841891001506, 0.19026496611445784, 0.19001053040286145, 0.1913738940135542, 0.1914959643260542, 0.18965461455195784, 0.18952224915286145, 0.18976638977786145, 0.1911297533885542, 0.1906414721385542, 0.1911400484751506, 0.19038703642695784, 0.1911297533885542, 0.1912518237010542, 0.1921063158885542, 0.1923504565135542, 0.1910076830760542, 0.19098709290286145, 0.1919842455760542, 0.19124152861445784, 0.1910076830760542, 0.19075324736445784, 0.1910076830760542, 0.1913738940135542, 0.19013260071536145, 0.19124152861445784, 0.18965461455195784, 0.19038703642695784, 0.1906517672251506, 0.1907635424510542, 0.1922386812876506, 0.1908959078501506, 0.1914959643260542, 0.1906414721385542, 0.1906414721385542, 0.1917401049510542, 0.1912621187876506, 0.1918621752635542, 0.18965461455195784, 0.19160773955195784, 0.1910076830760542, 0.19172980986445784, 0.1911297533885542, 0.19050910673945784, 0.19172980986445784, 0.19087531767695784, 0.1910179781626506, 0.1913738940135542, 0.1912518237010542, 0.19049881165286145, 0.1911297533885542, 0.1914959643260542, 0.19025467102786145, 0.1917401049510542, 0.1908856127635542, 0.1912621187876506, 0.1914959643260542, 0.1913738940135542, 0.1922386812876506, 0.1916180346385542, 0.1912518237010542, 0.19099738798945784, 0.1913738940135542, 0.1906414721385542, 0.1907635424510542, 0.19099738798945784], "accuracy_test": 0.1909099968112245, "start": "2016-01-25 14:28:10.582000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0], "accuracy_train_last": 0.18800270077750092, "batch_size_eval": 1024, "accuracy_train_std": [0.0077514694312453844, 0.008911488188499106, 0.008836458762606678, 0.009020240930744843, 0.009322039864446442, 0.009661663256158266, 0.009437227684983956, 0.00929195219954378, 0.01050652846768547, 0.009931665662184687, 0.009895786107786797, 0.009676586727556289, 0.009062910827587351, 0.009338755605549883, 0.009181381014322119, 0.00955007936019456, 0.009152475932146013, 0.010290772870663736, 0.009535340783418658, 0.009912294196686407, 0.00953546672121375, 0.00981193280417793, 0.01027207588564209, 0.01011159782015272, 0.01065842375826116, 0.009875701616695279, 0.010207065485995434, 0.010719823382354391, 0.010588349645775525, 0.01059449870178278, 0.010829077819473332, 0.010907803031383572, 0.011067498950673833, 0.011195318970922939, 0.010601319790018174, 0.01046029380786902, 0.010687828111012258, 0.011080475281200939, 0.010960885614766946, 0.010760576607787122, 0.010945573653225908, 0.010997758051210327, 0.011126463872626911, 0.010696284459504062, 0.011420180586915688, 0.011752991789199316, 0.011330306819746061, 0.01059709789017337, 0.010715886143398717, 0.011299465017400877, 0.011277144613997378, 0.012161899346815707, 0.011476663310684749, 0.011826887138587346, 0.01166636235542712, 0.011505099669162994, 0.011646801715092117, 0.011713427910483108, 0.011721879047321164, 0.011370823443689306, 0.011604807737540303, 0.011832454961729598, 0.011758182387278184, 0.011618142851751717, 0.012031251270411318, 0.011972486632519722, 0.011538631301566838, 0.012534975503586737, 0.011993183566330685, 0.011627814736508053, 0.012521155955322409, 0.011785119888183562, 0.012176447790626061, 0.011613880878912582, 0.012167568725962747, 0.012739881834717325, 0.011993251346042589, 0.011967863923780584, 0.012466593282379224, 0.011853718632833379, 0.012678790654155591, 0.012324385598459869, 0.012055908760117463, 0.012644043989200049, 0.012464934710187977, 0.012315709666117714, 0.01266184831900336, 0.012818181874414743, 0.012610287654586496, 0.011906318461872324, 0.012522143447999012, 0.011969498130193545, 0.01243715743296876, 0.01251501050183923, 0.012215957297574463, 0.012080598634298854, 0.012800365973209951, 0.012979136528253766, 0.012516199786946385, 0.01263335319537689, 0.012799974824968781, 0.01270264685520042, 0.012556226707103001, 0.01257149409927435, 0.012917260372401896, 0.01258022144602597, 0.012775606961098971, 0.012430725305259576, 0.012925152836466154, 0.01235018838061377, 0.012843672446353037, 0.012822337579752638, 0.013067585572958451, 0.012272745886429948, 0.0128540584232652, 0.013269053875690186, 0.012457226909997475, 0.012988564201534962, 0.012178348285943245, 0.012749834024363976, 0.0125054748940836, 0.013029312894492719, 0.012476716799284058, 0.013257346250364479, 0.01309061745483304, 0.012746298139669598, 0.012730479340230007, 0.012551586222573385, 0.012981655998193354, 0.012301111340654234, 0.013577715638362868, 0.012619014044264737, 0.013114567020002485, 0.01341106872459767, 0.013097239878482537, 0.013160463220209223, 0.013105609817692425, 0.012671653333996074, 0.013005135943320298, 0.012989762295636717, 0.012376304421726816, 0.012794677129245969, 0.013016775224012057, 0.012883861020131416, 0.013231362746482829, 0.013253796183027432, 0.013063184466716858, 0.0136379184980703, 0.013289748842948246, 0.013083576156352555, 0.012994128310164941, 0.013548440123228894, 0.013249989257513814, 0.013688700061545392, 0.012843997223626964, 0.01281423287107424, 0.01283632899348655, 0.012326722315552922, 0.0134230918612069, 0.013421746816377748, 0.012852991441834475, 0.013727233110126807, 0.01347464200341835, 0.01405012094169311, 0.013381840553812282, 0.013219395371311164, 0.013963736286992897, 0.013261226851237318, 0.013760974416616478, 0.01319688764238965, 0.013617026915174782, 0.012864986434725922, 0.013276765152062577, 0.012842816062959488, 0.013567388859806934, 0.013381097690004154, 0.012963305763365214, 0.01365836171540654, 0.013329800958179639, 0.013627356320440666, 0.012674661982206185, 0.013254447288764942, 0.01410042815069661, 0.013852486758501795, 0.01298396710540613, 0.013273718894240654, 0.013471253960420232, 0.013749006576448198, 0.013398483282695965, 0.013328153998274537, 0.013300476295807563, 0.013709526421463105, 0.01339647446070573, 0.012985715320365994, 0.013019909885194313, 0.012791380705991893, 0.013309714521969825, 0.013982609395622748, 0.013488974070594543, 0.013644289852099088, 0.013578179239233603, 0.0131838613768525, 0.013382880494111168, 0.013663885257434567, 0.013652823638690043, 0.013339158572842706, 0.01321723487447944, 0.01363495537352555, 0.013776384761847251, 0.013728330969087196, 0.013400858664749283, 0.013389133875485536, 0.013143849401775837, 0.013357783729761425, 0.01368230657170197, 0.013645689803309014, 0.013418372125469738, 0.012994889459082868, 0.013191351196113709, 0.01358076923544819, 0.013091967582325082, 0.013679422723188922, 0.013428297476432798, 0.013391993931788911, 0.013305308169567626, 0.013157225375060385, 0.013164328620037418, 0.01309127763804372, 0.01304828175595135, 0.013151320768827454, 0.013042668833805594, 0.013464131005344635, 0.013219636233186744, 0.013635759874932917, 0.013879128883727842, 0.013889185947187582, 0.012829972062011192, 0.013644394429238928, 0.013101150642898421, 0.013311917519126693, 0.013742171813614727, 0.01352572260139692, 0.01343317420320053, 0.013501035166578815, 0.014177470801452105, 0.013214482318642898], "accuracy_test_std": 0.01304515115406891, "error_valid": [0.8787797675075302, 0.8557878976844879, 0.8485033885542168, 0.8434779155685241, 0.8405276378953314, 0.8378215008471386, 0.8366007977221386, 0.8346270825489458, 0.8331931240587349, 0.8316973950489458, 0.8315959149096386, 0.8307517178087349, 0.8285338620105421, 0.8290427334337349, 0.8269675381212349, 0.8255026943712349, 0.8275778896837349, 0.8256350597703314, 0.8253909191453314, 0.8243025814194277, 0.8249129329819277, 0.8235701595444277, 0.8235701595444277, 0.8218508800828314, 0.8213523037462349, 0.8216067394578314, 0.8213523037462349, 0.8219626553087349, 0.8201110104480421, 0.8199992352221386, 0.8213625988328314, 0.8198668698230421, 0.8188800122364458, 0.8202536709337349, 0.8186461666980421, 0.8193785885730421, 0.8202536709337349, 0.8183005459337349, 0.8204875164721386, 0.8179137448230421, 0.8174151684864458, 0.8181784756212349, 0.8176901943712349, 0.8190226727221386, 0.8191756282944277, 0.8181990657944277, 0.8185446865587349, 0.8184432064194277, 0.8159606198230421, 0.8174460537462349, 0.8178225597703314, 0.8185652767319277, 0.8169783626694277, 0.8177004894578314, 0.8167136318712349, 0.8172122082078314, 0.8166121517319277, 0.8177004894578314, 0.8168357021837349, 0.8179549251694277, 0.8177107845444277, 0.8163474209337349, 0.8168357021837349, 0.8178328548569277, 0.8165915615587349, 0.8173239834337349, 0.8169577724962349, 0.8172225032944277, 0.8156252941453314, 0.8175887142319277, 0.8173548686935241, 0.8161238704819277, 0.8159812099962349, 0.8164694912462349, 0.8165915615587349, 0.8162253506212349, 0.8159915050828314, 0.8159812099962349, 0.8148619870105421, 0.8151164227221386, 0.8158591396837349, 0.8140074948230421, 0.8148722820971386, 0.8158488445971386, 0.8149943524096386, 0.8145060711596386, 0.8127764966114458, 0.8146178463855421, 0.8140074948230421, 0.8145060711596386, 0.8135089184864458, 0.8133971432605421, 0.8139060146837349, 0.8140074948230421, 0.8126647213855421, 0.8130206372364458, 0.8116778637989458, 0.8119220044239458, 0.8132956631212349, 0.8133971432605421, 0.8129191570971386, 0.8124308758471386, 0.8119322995105421, 0.8120543698230421, 0.8111895825489458, 0.8127970867846386, 0.8125529461596386, 0.8115660885730421, 0.8126750164721386, 0.8116984539721386, 0.8114337231739458, 0.8114337231739458, 0.8109454419239458, 0.8116778637989458, 0.8129397472703314, 0.8116778637989458, 0.8110675122364458, 0.8102130200489458, 0.8118102291980421, 0.8121970303087349, 0.8129294521837349, 0.8105792309864458, 0.8114543133471386, 0.8123191006212349, 0.8116881588855421, 0.8105792309864458, 0.8114543133471386, 0.8121764401355421, 0.8103350903614458, 0.8111895825489458, 0.8117190441453314, 0.8108439617846386, 0.8124411709337349, 0.8118205242846386, 0.8105792309864458, 0.8119425945971386, 0.8105792309864458, 0.8105792309864458, 0.8104674557605421, 0.8099688794239458, 0.8107218914721386, 0.8113322430346386, 0.8098571041980421, 0.8099688794239458, 0.8108439617846386, 0.8109660320971386, 0.8114543133471386, 0.8110675122364458, 0.8108542568712349, 0.8088702466114458, 0.8119425945971386, 0.8104674557605421, 0.8100909497364458, 0.8098365140248494, 0.8107115963855421, 0.8098468091114458, 0.8099894695971386, 0.8100806546498494, 0.8092364575489458, 0.8103350903614458, 0.8097350338855421, 0.8098468091114458, 0.8109660320971386, 0.8094805981739458, 0.8103350903614458, 0.8103453854480421, 0.8098571041980421, 0.8096129635730421, 0.8104777508471386, 0.8091143872364458, 0.8086261059864458, 0.8088702466114458, 0.8094805981739458, 0.8095011883471386, 0.8096129635730421, 0.8103556805346386, 0.8083716702748494, 0.8089923169239458, 0.8092467526355421, 0.8094908932605421, 0.8086158108998494, 0.8097350338855421, 0.8099894695971386, 0.8086261059864458, 0.8085040356739458, 0.8103453854480421, 0.8104777508471386, 0.8102336102221386, 0.8088702466114458, 0.8093585278614458, 0.8088599515248494, 0.8096129635730421, 0.8088702466114458, 0.8087481762989458, 0.8078936841114458, 0.8076495434864458, 0.8089923169239458, 0.8090129070971386, 0.8080157544239458, 0.8087584713855421, 0.8089923169239458, 0.8092467526355421, 0.8089923169239458, 0.8086261059864458, 0.8098673992846386, 0.8087584713855421, 0.8103453854480421, 0.8096129635730421, 0.8093482327748494, 0.8092364575489458, 0.8077613187123494, 0.8091040921498494, 0.8085040356739458, 0.8093585278614458, 0.8093585278614458, 0.8082598950489458, 0.8087378812123494, 0.8081378247364458, 0.8103453854480421, 0.8083922604480421, 0.8089923169239458, 0.8082701901355421, 0.8088702466114458, 0.8094908932605421, 0.8082701901355421, 0.8091246823230421, 0.8089820218373494, 0.8086261059864458, 0.8087481762989458, 0.8095011883471386, 0.8088702466114458, 0.8085040356739458, 0.8097453289721386, 0.8082598950489458, 0.8091143872364458, 0.8087378812123494, 0.8085040356739458, 0.8086261059864458, 0.8077613187123494, 0.8083819653614458, 0.8087481762989458, 0.8090026120105421, 0.8086261059864458, 0.8093585278614458, 0.8092364575489458, 0.8090026120105421], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.9795390282301776, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00018585840337291217, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "optimization": "adadelta", "nb_data_augmentation": 2, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.9726158843152106e-06, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.07539860383245496}, "accuracy_valid_max": 0.1923504565135542, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.19099738798945784, "loss_train": [2.4833028316497803, 2.4298722743988037, 2.4017629623413086, 2.389664888381958, 2.3821115493774414, 2.3777050971984863, 2.373398780822754, 2.370621681213379, 2.3677756786346436, 2.3652234077453613, 2.3633320331573486, 2.3618743419647217, 2.3602592945098877, 2.3593029975891113, 2.357560873031616, 2.356694459915161, 2.3556628227233887, 2.3547427654266357, 2.353841781616211, 2.3527209758758545, 2.351694107055664, 2.3512842655181885, 2.3505399227142334, 2.349855422973633, 2.3492112159729004, 2.3490021228790283, 2.3486168384552, 2.347329616546631, 2.3467135429382324, 2.3467278480529785, 2.345822811126709, 2.345540761947632, 2.3448691368103027, 2.344407081604004, 2.3441028594970703, 2.34395432472229, 2.3432955741882324, 2.3429574966430664, 2.3424437046051025, 2.3422398567199707, 2.3413918018341064, 2.3414292335510254, 2.340865135192871, 2.3406453132629395, 2.34081768989563, 2.3399856090545654, 2.340322494506836, 2.3393445014953613, 2.338693857192993, 2.3384337425231934, 2.3385794162750244, 2.338263988494873, 2.338136672973633, 2.337275266647339, 2.3375368118286133, 2.3372905254364014, 2.3366613388061523, 2.3362512588500977, 2.336838722229004, 2.336155414581299, 2.3364574909210205, 2.3353655338287354, 2.3352630138397217, 2.3355095386505127, 2.3353466987609863, 2.3348255157470703, 2.3347349166870117, 2.334747314453125, 2.334479331970215, 2.334242105484009, 2.334044933319092, 2.33374285697937, 2.333709239959717, 2.333192825317383, 2.333104133605957, 2.332470417022705, 2.332995653152466, 2.3322153091430664, 2.3326687812805176, 2.33231782913208, 2.3322207927703857, 2.3319292068481445, 2.331817150115967, 2.3312623500823975, 2.331345796585083, 2.330883026123047, 2.330812454223633, 2.3312196731567383, 2.330998182296753, 2.33063006401062, 2.330671787261963, 2.3306260108947754, 2.3304505348205566, 2.3298370838165283, 2.32956600189209, 2.329374074935913, 2.3296730518341064, 2.329343318939209, 2.329385995864868, 2.3294506072998047, 2.329310894012451, 2.328977584838867, 2.3287415504455566, 2.328343152999878, 2.328474283218384, 2.328540086746216, 2.3279740810394287, 2.328352451324463, 2.3281023502349854, 2.327802896499634, 2.3277127742767334, 2.3278727531433105, 2.327660322189331, 2.32778263092041, 2.3271567821502686, 2.3277859687805176, 2.326897144317627, 2.3274922370910645, 2.327199935913086, 2.3269577026367188, 2.3269925117492676, 2.327011823654175, 2.3269622325897217, 2.3264617919921875, 2.327214241027832, 2.3263957500457764, 2.3260252475738525, 2.3258755207061768, 2.326005697250366, 2.3258461952209473, 2.325754404067993, 2.325716972351074, 2.3256871700286865, 2.3259150981903076, 2.3259217739105225, 2.325387477874756, 2.325291156768799, 2.3256285190582275, 2.325342893600464, 2.3251941204071045, 2.324514865875244, 2.324852228164673, 2.3247177600860596, 2.324963092803955, 2.3245975971221924, 2.3244948387145996, 2.3248846530914307, 2.3245537281036377, 2.3245489597320557, 2.3242623805999756, 2.3240387439727783, 2.3243541717529297, 2.323983907699585, 2.323324203491211, 2.3233718872070312, 2.324009418487549, 2.3237345218658447, 2.3240249156951904, 2.3233983516693115, 2.323702812194824, 2.3234002590179443, 2.323596715927124, 2.322890281677246, 2.323847770690918, 2.323141574859619, 2.322727918624878, 2.323513984680176, 2.3229761123657227, 2.3233771324157715, 2.3231120109558105, 2.3227639198303223, 2.323059320449829, 2.322460889816284, 2.322580575942993, 2.3227458000183105, 2.322690010070801, 2.3226773738861084, 2.322639226913452, 2.322193145751953, 2.322335720062256, 2.3223042488098145, 2.3221259117126465, 2.3222479820251465, 2.322103261947632, 2.322159767150879, 2.321929931640625, 2.3219611644744873, 2.3222811222076416, 2.322075605392456, 2.3219244480133057, 2.321842670440674, 2.321871042251587, 2.3214914798736572, 2.321678876876831, 2.3217108249664307, 2.3213870525360107, 2.3212130069732666, 2.321781873703003, 2.321462869644165, 2.3210175037384033, 2.3210692405700684, 2.32125186920166, 2.32114315032959, 2.320639133453369, 2.3206238746643066, 2.3212685585021973, 2.3209731578826904, 2.3209056854248047, 2.3214855194091797, 2.3202006816864014, 2.320761203765869, 2.3206093311309814, 2.320641040802002, 2.320566177368164, 2.3211402893066406, 2.3204524517059326, 2.320632219314575, 2.3203125, 2.3198373317718506, 2.320469379425049, 2.3206887245178223, 2.3202621936798096, 2.320354461669922, 2.320230484008789, 2.320085048675537, 2.3197264671325684, 2.3200976848602295, 2.3204169273376465, 2.3201136589050293, 2.3201112747192383, 2.3201494216918945, 2.320382595062256, 2.3198609352111816, 2.3196380138397217, 2.319913387298584, 2.3197548389434814, 2.3196940422058105, 2.319983720779419, 2.31988525390625, 2.3195719718933105, 2.3193018436431885, 2.3192219734191895, 2.3192896842956543, 2.3196637630462646, 2.3196561336517334, 2.319505453109741], "accuracy_train_first": 0.11507215531561461, "model": "residualv5", "loss_std": [0.07907663285732269, 0.06536849588155746, 0.05863058939576149, 0.056636545807123184, 0.05569696053862572, 0.05617513135075569, 0.05559162423014641, 0.05509883165359497, 0.0550762303173542, 0.055341657251119614, 0.055105071514844894, 0.05547680705785751, 0.05571693554520607, 0.05565277487039566, 0.05567539855837822, 0.055713050067424774, 0.05590425804257393, 0.05672655254602432, 0.055880479514598846, 0.056125860661268234, 0.05587363243103027, 0.05630524456501007, 0.05614544823765755, 0.05642803758382797, 0.056043561547994614, 0.05667581409215927, 0.0569012276828289, 0.0568065382540226, 0.056642480194568634, 0.056672632694244385, 0.056945666670799255, 0.05704854801297188, 0.05697627365589142, 0.05698947608470917, 0.05690358579158783, 0.05666327849030495, 0.05720101669430733, 0.05688561126589775, 0.057744793593883514, 0.05772450566291809, 0.05723077803850174, 0.057716742157936096, 0.0574413426220417, 0.05729464441537857, 0.05744869261980057, 0.05755601078271866, 0.05764884874224663, 0.057420726865530014, 0.05711451545357704, 0.057738397270441055, 0.05792088434100151, 0.057372480630874634, 0.05774962529540062, 0.05820009857416153, 0.057484742254018784, 0.05819276347756386, 0.05833100527524948, 0.05793709307909012, 0.05798986181616783, 0.05789797753095627, 0.05803106352686882, 0.05789467692375183, 0.057875651866197586, 0.05815545842051506, 0.05834314227104187, 0.058041639626026154, 0.0583219937980175, 0.05831614509224892, 0.05828939005732536, 0.058249834924936295, 0.05898395553231239, 0.05860421806573868, 0.05881130322813988, 0.058165162801742554, 0.05823638662695885, 0.058065395802259445, 0.05824919417500496, 0.05864754691720009, 0.05914952978491783, 0.05918998643755913, 0.059198930859565735, 0.0587247870862484, 0.05861847475171089, 0.05846993625164032, 0.05881193280220032, 0.0587552972137928, 0.059181660413742065, 0.059040021151304245, 0.05891010910272598, 0.058940719813108444, 0.059011559933423996, 0.05874304473400116, 0.059259265661239624, 0.058873407542705536, 0.058726321905851364, 0.05849897488951683, 0.05875337868928909, 0.0590728260576725, 0.059280019253492355, 0.05913772061467171, 0.059660229831933975, 0.05873378738760948, 0.05895702540874481, 0.05892099067568779, 0.0592585988342762, 0.05931348353624344, 0.05933768302202225, 0.059147242456674576, 0.05926640331745148, 0.058896277099847794, 0.058711569756269455, 0.05912673473358154, 0.0596647672355175, 0.059502966701984406, 0.05962945893406868, 0.05927291139960289, 0.05913083627820015, 0.05955830216407776, 0.059585582464933395, 0.05898110195994377, 0.059673260897397995, 0.05919816717505455, 0.05978840962052345, 0.059569939970970154, 0.05924822762608528, 0.05955079197883606, 0.05895092338323593, 0.059430304914712906, 0.05953258275985718, 0.059424303472042084, 0.05930526554584503, 0.05921056494116783, 0.059441544115543365, 0.0594845749437809, 0.05998208746314049, 0.05955306440591812, 0.06031923368573189, 0.059454530477523804, 0.06019708514213562, 0.05986567586660385, 0.05989944189786911, 0.06008504331111908, 0.060133256018161774, 0.059831324964761734, 0.059301022440195084, 0.060006141662597656, 0.05972866714000702, 0.05993227660655975, 0.05932313948869705, 0.0595986433327198, 0.059740737080574036, 0.05951487272977829, 0.05978356674313545, 0.05970986559987068, 0.05977718532085419, 0.06033839285373688, 0.059333622455596924, 0.05995892360806465, 0.0600409060716629, 0.05986923351883888, 0.06037643179297447, 0.05993693694472313, 0.059838514775037766, 0.0595671609044075, 0.05948840081691742, 0.06013328954577446, 0.06011497974395752, 0.0595564991235733, 0.060216549783945084, 0.060091279447078705, 0.0600028894841671, 0.06005309149622917, 0.059858813881874084, 0.06016739830374718, 0.06035005301237106, 0.0603761225938797, 0.06047739088535309, 0.059785395860672, 0.059724777936935425, 0.06033219024538994, 0.059747498482465744, 0.06010233238339424, 0.06006742641329765, 0.05998773127794266, 0.06028950586915016, 0.06002546846866608, 0.05994865670800209, 0.060231029987335205, 0.06011944264173508, 0.06031849607825279, 0.05937284231185913, 0.060320544987916946, 0.060253776609897614, 0.06002518907189369, 0.06003876030445099, 0.06050877645611763, 0.06049906834959984, 0.060134612023830414, 0.06010565161705017, 0.060906361788511276, 0.0601763054728508, 0.06022671237587929, 0.060033563524484634, 0.06051437184214592, 0.06016213446855545, 0.060376644134521484, 0.06030048057436943, 0.0605643130838871, 0.06053394824266434, 0.060441579669713974, 0.06014394387602806, 0.060540877282619476, 0.060500290244817734, 0.06026932969689369, 0.06115112081170082, 0.060490772128105164, 0.06095612049102783, 0.060314539819955826, 0.0605139322578907, 0.06049110367894173, 0.0604734942317009, 0.060790520161390305, 0.06019539013504982, 0.06098760664463043, 0.06011626869440079, 0.06073058769106865, 0.060961052775382996, 0.06104092299938202, 0.060511521995067596, 0.060001175850629807, 0.060330964624881744, 0.06054204702377319, 0.06052186340093613, 0.060233794152736664, 0.060943689197301865, 0.06040836498141289, 0.060846198350191116, 0.06050848588347435, 0.06074836105108261, 0.06037505716085434, 0.060806285589933395, 0.060593754053115845, 0.06010179594159126, 0.06044628098607063, 0.06056048348546028, 0.060409825295209885]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:19 2016", "state": "available"}], "summary": "06cdba7c2daf6c27c09be5fbb3e11dd4"}