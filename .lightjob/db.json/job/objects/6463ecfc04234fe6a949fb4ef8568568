{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 64, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.527580976486206, 1.1411304473876953, 0.9496930837631226, 0.833625078201294, 0.7509627342224121, 0.687565803527832, 0.6350212693214417, 0.5909274816513062, 0.5537929534912109, 0.5213028788566589, 0.489461213350296, 0.4626082181930542, 0.43801629543304443, 0.4149029850959778, 0.392154335975647, 0.3754003047943115, 0.35447779297828674, 0.33818772435188293, 0.3238390386104584, 0.30832424759864807, 0.29473474621772766, 0.2823171019554138, 0.27068954706192017, 0.25782397389411926, 0.24821504950523376, 0.23770585656166077, 0.22640803456306458, 0.2189691960811615, 0.2115785926580429, 0.2028878927230835, 0.1951432228088379, 0.18717756867408752, 0.18139518797397614, 0.175893172621727, 0.17250719666481018, 0.16318656504154205, 0.16138029098510742, 0.1528042107820511, 0.14873118698596954, 0.14354880154132843, 0.13976836204528809, 0.13517528772354126, 0.1330997794866562, 0.1271255910396576, 0.1262863427400589, 0.11871988326311111, 0.11956224590539932, 0.11376865953207016, 0.11132259666919708, 0.11100447922945023, 0.10432736575603485, 0.10271826386451721, 0.09905573725700378, 0.09857678413391113, 0.09602677077054977, 0.09333863854408264, 0.0919366404414177, 0.09161671251058578, 0.08804568648338318, 0.08569598942995071, 0.08521381765604019, 0.08284041285514832, 0.08010757714509964, 0.07926899939775467, 0.07625576853752136, 0.07729006558656693, 0.07520260661840439, 0.07250580936670303, 0.07082313299179077, 0.07071463018655777, 0.07012689858675003, 0.06794733554124832, 0.06786153465509415, 0.06558670848608017, 0.06549914181232452, 0.06430390477180481, 0.06407401710748672, 0.062293268740177155, 0.05974629521369934, 0.06097510829567909, 0.05795289948582649, 0.0619945228099823, 0.05662977695465088, 0.05572390928864479, 0.05695819482207298, 0.052964452654123306, 0.05422283336520195, 0.05542471632361412, 0.05175519362092018, 0.052042268216609955, 0.04995407536625862, 0.05010597035288811, 0.05016301944851875, 0.050787847489118576, 0.04582546278834343, 0.050477948039770126, 0.04815104976296425, 0.045488886535167694, 0.04588976129889488, 0.04836674779653549, 0.043930694460868835, 0.04535523056983948, 0.04351222142577171, 0.04424017667770386, 0.04166698083281517, 0.044584713876247406, 0.042075805366039276, 0.04326244443655014, 0.04219498485326767, 0.04024941101670265, 0.04021359235048294, 0.039095379412174225, 0.04106279835104942, 0.03945229575037956, 0.038217321038246155, 0.038999807089567184, 0.03838266432285309, 0.0378228984773159, 0.03650152310729027, 0.03658401966094971, 0.03824251517653465, 0.03435198962688446, 0.036051876842975616, 0.035665497183799744, 0.03687542304396629, 0.034760285168886185, 0.035466186702251434, 0.03451814129948616, 0.03361649066209793, 0.03349851444363594, 0.033949702978134155, 0.034254416823387146, 0.03315284103155136, 0.03253195434808731, 0.032456714659929276, 0.031277284026145935, 0.033560123294591904, 0.030794944614171982, 0.028993899002671242, 0.03339352086186409, 0.03078058920800686, 0.03061121515929699, 0.02951192297041416, 0.030089637264609337, 0.028780752792954445, 0.031125295907258987, 0.030659625306725502, 0.027873417362570763, 0.0277506485581398, 0.0307965986430645, 0.02780170924961567, 0.028134949505329132, 0.027696356177330017, 0.027482859790325165, 0.0284819807857275, 0.0271677877753973, 0.028536422178149223, 0.026907820254564285, 0.02579830028116703, 0.027021948248147964, 0.027881469577550888, 0.025652309879660606, 0.026196042075753212, 0.025357196107506752, 0.02598094567656517, 0.024405241012573242, 0.025704743340611458, 0.026396682485938072, 0.02577883191406727, 0.02465089038014412, 0.026011118665337563, 0.024547124281525612, 0.024526217952370644, 0.024914517998695374, 0.023795774206519127, 0.023914054036140442, 0.024172604084014893, 0.02292533777654171, 0.02501245215535164, 0.02445785142481327, 0.023095235228538513, 0.024284807965159416, 0.022488411515951157, 0.02268477901816368, 0.023542918264865875, 0.022522293031215668, 0.022982794791460037, 0.02208530530333519, 0.020986879244446754, 0.023023605346679688, 0.02202771231532097, 0.02213347889482975, 0.022397104650735855, 0.02182183414697647, 0.02363497205078602, 0.02221415564417839, 0.02100135199725628, 0.020115241408348083, 0.022702718153595924, 0.020470885559916496, 0.022554095834493637, 0.019541069865226746, 0.02206277847290039, 0.020110782235860825, 0.0209503136575222, 0.020763088017702103, 0.019498029723763466, 0.021641692146658897, 0.018669260665774345, 0.019074885174632072, 0.021189074963331223, 0.019498061388731003, 0.019463496282696724, 0.019740000367164612, 0.018841395154595375, 0.020348550751805305, 0.018500804901123047, 0.018705181777477264, 0.020364910364151, 0.018712101504206657, 0.018428297713398933, 0.019135816022753716, 0.018607791513204575, 0.019099144265055656, 0.0194151122123003, 0.020376944914460182, 0.017630405724048615, 0.018738720566034317, 0.019413193687796593, 0.017527252435684204, 0.018819117918610573, 0.01755043864250183, 0.01838768646121025, 0.01807306706905365, 0.019293231889605522, 0.01708553358912468, 0.01658092625439167, 0.018479952588677406, 0.017240475863218307, 0.018247278407216072], "moving_avg_accuracy_train": [0.059167394852805456, 0.12114507270325764, 0.18279236060642762, 0.24174332076671506, 0.29689360325607345, 0.3490027076833731, 0.3974234776011746, 0.4427503940414078, 0.4847650696208864, 0.5235500456495231, 0.5585170500419813, 0.5915146523236819, 0.6216822104855552, 0.6491863273038325, 0.6733612145819856, 0.6970713415953171, 0.7193962469049161, 0.7385167855299929, 0.7562228521378002, 0.7732044488050187, 0.7882436370340591, 0.8018581777926318, 0.8143530439027189, 0.8253588970255976, 0.8365988002528552, 0.8460543348466635, 0.8559105050441677, 0.8644766079231488, 0.8723256094428032, 0.879319884248569, 0.8859843220880164, 0.8919312349673469, 0.8978994767979932, 0.9025386528146686, 0.9076183941165812, 0.9125132488263701, 0.9162419637127899, 0.9203883937546247, 0.9244108243934664, 0.9266360668779846, 0.9298920042735656, 0.9328640564128848, 0.9357970309049481, 0.9381183428049942, 0.9403213837090647, 0.9422738575393856, 0.9445007279973796, 0.9445588339536402, 0.9462550455714267, 0.9478605108428646, 0.9497937108371588, 0.9505758097665935, 0.9520724303518574, 0.9529869112000235, 0.9545377876383915, 0.9552521996852759, 0.9564485559441385, 0.9574625696568951, 0.9591749971400336, 0.9586631115248675, 0.959134943339112, 0.9605638399647338, 0.9618103554468503, 0.9625858082569548, 0.9635184476693546, 0.9649181840036095, 0.9651597117699614, 0.9660489105703554, 0.9666633578300419, 0.9670721650887505, 0.96764459657037, 0.9682737171954944, 0.9688167824164672, 0.96908690502961, 0.9697578067135723, 0.9703476673362811, 0.9711343443145855, 0.9715516018474126, 0.9721504200103088, 0.9723406200843057, 0.9730837507092269, 0.9736455753775991, 0.9742860401612679, 0.9746625677665881, 0.9746363942482811, 0.9752476758044423, 0.9754768505228167, 0.9760877197110297, 0.9766747043613737, 0.9768706024133778, 0.977188636591106, 0.9774981909367942, 0.977616426677694, 0.9778017497087526, 0.977815044566458, 0.9782083703919735, 0.9780786966337378, 0.9782596092989447, 0.9790222830416693, 0.9789763756815776, 0.9794139676146195, 0.9796683274746045, 0.9796507495259629, 0.9804277690674141, 0.980399387174977, 0.9805110272515454, 0.9804464177549808, 0.9802604220723674, 0.9801813455639586, 0.9804914650623339, 0.9800219467918424, 0.980415507580543, 0.9806254809665454, 0.9812748004294147, 0.9811802805424349, 0.9817486155084479, 0.9820368666433267, 0.9817429432968696, 0.9819597541374484, 0.9825919758213411, 0.9828005412225496, 0.9827022928288844, 0.983011397623377, 0.9832943143336768, 0.9834396573788989, 0.9839447790291136, 0.9840645310369165, 0.9844908532308438, 0.9844491130708731, 0.9845185758697751, 0.9846530638554258, 0.9847577909520262, 0.9847381490961186, 0.9852598699007924, 0.9857224431785703, 0.985803937699999, 0.9860911964597611, 0.9860591217911752, 0.986262805519219, 0.9862112808446964, 0.9859369719566553, 0.9861132710407517, 0.9864951545021527, 0.9865179790816994, 0.9870058761140056, 0.9871310883537955, 0.9872275754255773, 0.987274886260419, 0.987401099271282, 0.9870706236072582, 0.9869917594977321, 0.9870859394622723, 0.9872240717065213, 0.987480960257307, 0.9876471999816225, 0.9876106596334695, 0.9873103812070366, 0.9876167675280089, 0.9877134427097317, 0.9877377795018815, 0.9881990996909975, 0.988058541246907, 0.98834362603533, 0.9884071428960828, 0.9881085603029031, 0.9884049192273932, 0.9885367836284819, 0.9886253067525753, 0.9887490111963654, 0.9889999262219854, 0.9893000824093107, 0.9890261742052936, 0.9890539883323833, 0.9891580761062878, 0.9895842874313825, 0.9899074237549201, 0.9898634610663514, 0.9896983005621064, 0.9891127083761893, 0.9889622413695505, 0.9890569026492622, 0.9884934173319642, 0.9884420097130627, 0.9888212450881942, 0.9890139276460969, 0.9890499418755349, 0.9895614074344283, 0.989726432538623, 0.9897610228407316, 0.990033933540001, 0.9899331059967245, 0.9899750028363746, 0.9901056438468032, 0.9901906686728557, 0.9903857375567697, 0.9906496191582357, 0.9906127450400312, 0.9905981595241232, 0.9903571679764728, 0.9904425809776443, 0.9906728764513084, 0.9907407776443097, 0.9907808542322688, 0.9904193227150035, 0.9904404275709026, 0.990436242550754, 0.9903137852968783, 0.9906639532326759, 0.9906466080951318, 0.9911123032749136, 0.991203619003393, 0.9914159393947204, 0.9913746210124189, 0.9915419394171294, 0.991646095102816, 0.9916631053092195, 0.9919387951128306, 0.9915242485253662, 0.9912720643347436, 0.9915589204012691, 0.9917962005706753, 0.9920073915255125, 0.9916976284884559, 0.9910607688384383, 0.9912595445581844, 0.9914849096333276, 0.9915668665116799, 0.9919149952617209, 0.9923887464046148, 0.9926267132820105, 0.992780429602619, 0.9930397541268994, 0.993098832135675, 0.9931077163697357, 0.9932134044792091, 0.9933411479587061, 0.9934327214068831, 0.9934291430531088, 0.9935073027430452, 0.9934288369401785], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05909364999058734, 0.12027089314288401, 0.18084725474162272, 0.23789077663191827, 0.29011282354515716, 0.3393874386868764, 0.3846815932086255, 0.42689499803497677, 0.4654069642518104, 0.500725884025801, 0.5322749482493504, 0.5615397762312677, 0.5880235762813337, 0.6120635744043299, 0.6328633175380686, 0.6529360078098642, 0.6713442554381397, 0.6872322025882263, 0.7021824457141927, 0.7156873750885566, 0.7280788926625323, 0.73903697548777, 0.7486499618621858, 0.7574899026112082, 0.7660582598651476, 0.7729335262167353, 0.780714357047622, 0.7872735336357816, 0.7929611840372636, 0.7981268385062782, 0.8034799643789184, 0.808272334093135, 0.8126657685113817, 0.8159352362291442, 0.8194372215953112, 0.8231597974402982, 0.8254592815046268, 0.828415812409134, 0.8312242041068502, 0.8330803699160447, 0.8356268839410065, 0.8375920981730354, 0.8396628782371324, 0.8411512508520487, 0.8429689194415426, 0.8446008502101142, 0.8462618118758497, 0.8459865107710961, 0.8468414906239563, 0.8479324733386691, 0.8496041285838685, 0.8501064651607225, 0.8510753814270298, 0.8519281395475045, 0.8530007976371817, 0.8536264520602106, 0.8547063543880751, 0.8556507638946742, 0.8573216920703423, 0.8566179667168472, 0.8568463126468191, 0.8584384250756614, 0.8598692672443, 0.8608884705085749, 0.8616094114377625, 0.8629469995673296, 0.8628190858963647, 0.8634588875853426, 0.8639980880116729, 0.8637590355169815, 0.8640311400130997, 0.8644764941029042, 0.8650329156639993, 0.8654186842444367, 0.8664912383538785, 0.8674585960696956, 0.8680474267865211, 0.8685926699888931, 0.8695584335811183, 0.869603572668413, 0.8705669317513458, 0.8705376941014371, 0.8710017204838386, 0.8714366988025481, 0.87128180433645, 0.8721791145372176, 0.8722725088534508, 0.8726087933596719, 0.8733856116893673, 0.8731771627662891, 0.8735328451624764, 0.8744013932893011, 0.8742460866505065, 0.8744257525054107, 0.8744674404796438, 0.8751641393439534, 0.8749549131448743, 0.875102376461411, 0.8758230899636132, 0.8754432529646163, 0.8761644408929288, 0.8764686246274311, 0.8760985058582121, 0.8767918190995747, 0.876802360928322, 0.8769889240636525, 0.8771425648368807, 0.8772737820448342, 0.877097732200667, 0.8769688489467148, 0.8768884456032482, 0.8770327206306493, 0.8770435863687891, 0.8777878464254343, 0.8776031882889149, 0.8782447190458669, 0.8782808693174851, 0.8780682344282817, 0.8784710365972758, 0.8795293593306205, 0.880102402313221, 0.8797982108864922, 0.8803931968385057, 0.8805115861154984, 0.8805295987200631, 0.881275290485858, 0.8816605038130252, 0.8821882422589064, 0.8818819568601994, 0.882007073015294, 0.8822336588707677, 0.8820947597570342, 0.8819676915373549, 0.8822135110978514, 0.8828965568724789, 0.8829191835176858, 0.8832295747950588, 0.8835333410071945, 0.8841017583654359, 0.8838604690123261, 0.8837419943531868, 0.8841246779186211, 0.8844558565876024, 0.8845352203358451, 0.8850827219280136, 0.8852011734268539, 0.8849506873435812, 0.8847353978825665, 0.8850309481263128, 0.8848076325870249, 0.8847440144713947, 0.8851404773408968, 0.8851991776301505, 0.8855815977342288, 0.8858525336403993, 0.8860119562458624, 0.8855653810561406, 0.8856252715555717, 0.8855134221108579, 0.8854371716731155, 0.8863329017478974, 0.8855347901781528, 0.8863781073293887, 0.8862520094635432, 0.8862107340631227, 0.8861034325412231, 0.8863110074441038, 0.8862729507508983, 0.8863028234092422, 0.8867112152964806, 0.8873412927032029, 0.8868635581523856, 0.8870236525912886, 0.8872287727425512, 0.8877531187363683, 0.8884935848183038, 0.8881234361444552, 0.8879378162216514, 0.8866821264198929, 0.8868094768897258, 0.8867581943457079, 0.8860671264171611, 0.886412609276198, 0.8870653407243312, 0.8874208654339011, 0.8872515269138543, 0.8879577324679508, 0.8883369698103877, 0.8884259067243038, 0.8892364598771746, 0.8892416248363698, 0.8892086226972358, 0.8893630557494249, 0.8895539621473739, 0.8890635096920492, 0.8895396888433262, 0.8897373459943851, 0.8893597439721304, 0.888983281058351, 0.8894176254393382, 0.8895766017884766, 0.8899383775565416, 0.88998321402905, 0.8897194205817173, 0.8890618198733197, 0.8888870773155811, 0.888950565084776, 0.8894400977140996, 0.8891410486448734, 0.8897162486561391, 0.8899999360552089, 0.8902359881951699, 0.8901869399215867, 0.8901458850013406, 0.8906379559515079, 0.8908244721504083, 0.8912344183370994, 0.8905138555978924, 0.8900738981725158, 0.8902628444810172, 0.8906689477870571, 0.891168718106243, 0.8907547536280734, 0.8900546547712902, 0.8900156508434836, 0.8906214899854153, 0.8905440395467383, 0.8910765967178176, 0.8914145613400871, 0.8913717850818315, 0.8913882916263591, 0.8918415711327744, 0.8920012640289096, 0.8921093960503408, 0.8921945078383791, 0.8923189070639538, 0.8919680286881306, 0.8923378909172092, 0.8924988389772202, 0.8922092395768626], "moving_var_accuracy_train": [0.031507025523010115, 0.06292741593631901, 0.09083816729503405, 0.11303129189990885, 0.12910214563782224, 0.14063015995197697, 0.1476682825916733, 0.15139221851832493, 0.15214009334293196, 0.15046455329851607, 0.14642232053430418, 0.1415796642879455, 0.135612431948201, 0.12885947673096187, 0.12123335563206837, 0.11416955117575635, 0.10723820863192375, 0.09980474274454888, 0.09264581162257496, 0.08597660208863024, 0.0794145365230638, 0.07314128435135896, 0.06723225102820411, 0.06159918515204511, 0.056576285457863626, 0.051723321122169603, 0.047425285828612176, 0.04334316031255057, 0.039563305704995354, 0.03604725405502295, 0.032842261234963366, 0.029876327066616155, 0.027209273554896222, 0.024682043786429866, 0.022446073353036094, 0.020417102441401967, 0.01850052202959965, 0.01680520576546615, 0.015270304723118168, 0.013787839587840496, 0.012504465783971934, 0.011333517050844235, 0.010277586400099658, 0.009298324160525348, 0.008412172247497886, 0.00760526440927089, 0.006889368536673974, 0.006200462069725954, 0.005606310067424187, 0.005068876729321909, 0.00459562441635117, 0.00414156708333486, 0.003747569233587495, 0.003380338787223708, 0.0030639518680451, 0.0027621501423951917, 0.00249881654283875, 0.002258188902841803, 0.0020587616835226943, 0.001855243757117551, 0.0016717230087541955, 0.0015229264179791974, 0.001384617983805683, 0.0012515681289714062, 0.0011342396625363177, 0.0010384490525315892, 0.0009351291682357007, 0.0008487323219717305, 0.0007672569986889838, 0.0006920354091930413, 0.0006257809684840801, 0.0005667650064842834, 0.0005127427843439283, 0.0004621252019447157, 0.0004199636633761343, 0.0003810987170265231, 0.0003485585913376172, 0.0003152696668421646, 0.0002869699488878781, 0.0002585985386124258, 0.00023770887288244552, 0.00021677880821612525, 0.00019879268364659036, 0.0001801893726200451, 0.0001621766008355857, 0.00014932192702015276, 0.0001348624237820159, 0.0001247346318897861, 0.00011536212751846334, 0.00010417129918762772, 9.466448091269481e-05, 8.60604478578355e-05, 7.7580220285887e-05, 7.013129988986496e-05, 6.311976068005114e-05, 5.820013145720322e-05, 5.253145586365773e-05, 4.757287480918226e-05, 4.8050628468837636e-05, 4.3264532993349107e-05, 4.0661459992784696e-05, 3.717760443885089e-05, 3.346262485347186e-05, 3.555019667829983e-05, 3.200242679683472e-05, 2.8914355677416984e-05, 2.6060489593092326e-05, 2.3765790179339994e-05, 2.1445489009045082e-05, 2.0166507037593362e-05, 2.0133882990761195e-05, 1.9514505541308732e-05, 1.7959854392642253e-05, 1.995841083712554e-05, 1.8042975834725157e-05, 1.9145719953590265e-05, 1.7978946409061095e-05, 1.6958570170487693e-05, 1.5685775618771374e-05, 1.7714536375150926e-05, 1.6334578476867038e-05, 1.4787995350900225e-05, 1.4169107781614504e-05, 1.3472573788154848e-05, 1.2315437816489565e-05, 1.3380224968480069e-05, 1.2171267361987566e-05, 1.2589896143104455e-05, 1.134658669738341e-05, 1.0255353751526752e-05, 9.392601540933687e-06, 8.552051269701221e-06, 7.700318365262583e-06, 9.380019911002131e-06, 1.036778425572964e-05, 9.390778043362684e-06, 9.194358594566466e-06, 8.284181794393892e-06, 7.829147164582896e-06, 7.070125576886437e-06, 7.040321313722754e-06, 6.616021485829457e-06, 7.266934140071075e-06, 6.544929378947292e-06, 8.032828068251791e-06, 7.370648206365486e-06, 6.7173711809181205e-06, 6.0657788986670595e-06, 5.602568525799971e-06, 6.025239153827234e-06, 5.478691168386632e-06, 5.010650843035105e-06, 4.681310410842873e-06, 4.807104917481429e-06, 4.575115239197543e-06, 4.129620488666086e-06, 4.528162640228959e-06, 4.920199575316142e-06, 4.512294434634985e-06, 4.066395506240752e-06, 5.575102807591138e-06, 5.195402612678355e-06, 5.4073223807222245e-06, 4.90289966704891e-06, 5.2149737848932875e-06, 5.483933915528088e-06, 5.0920345064455285e-06, 4.653358147294434e-06, 4.325747437285722e-06, 4.459797844294174e-06, 4.8246616909715615e-06, 5.017426859925119e-06, 4.5226468049244565e-06, 4.167890506519615e-06, 5.3860062986187935e-06, 5.787159421061731e-06, 5.2258379408313256e-06, 4.948756076210218e-06, 7.54014434245448e-06, 6.989892788990757e-06, 6.371550330981442e-06, 8.59203662317651e-06, 7.756617650388939e-06, 8.275331113110391e-06, 7.781937114878436e-06, 7.015416625888661e-06, 8.66824812470838e-06, 8.0465228773677e-06, 7.252638990630567e-06, 7.197697339548941e-06, 6.56942334694277e-06, 5.928279118802558e-06, 5.489054869374583e-06, 5.005212371844332e-06, 4.847157959903486e-06, 4.989143660242931e-06, 4.502466599558888e-06, 4.05413457507169e-06, 4.171413451914995e-06, 3.8199305336455596e-06, 3.915261526992732e-06, 3.5652305223924835e-06, 3.2231626662753126e-06, 4.077191741432925e-06, 3.6734813017723127e-06, 3.306290801137877e-06, 3.1106237322650773e-06, 3.903119608385252e-06, 3.5155153317145306e-06, 5.115811802790715e-06, 4.679277682921291e-06, 4.617069451789788e-06, 4.17072738505492e-06, 4.005613683543201e-06, 3.702687976936239e-06, 3.3350233033396286e-06, 3.6855647833417733e-06, 4.8636481636122894e-06, 4.9496551412509615e-06, 5.195267253248962e-06, 5.18245743706467e-06, 5.065626268003778e-06, 5.422641893342197e-06, 8.530689628392933e-06, 8.033226746398697e-06, 7.687008825607408e-06, 6.978760312230046e-06, 7.371626920452657e-06, 8.65442553694763e-06, 8.298637095889828e-06, 7.681431751293505e-06, 7.5185314562033166e-06, 6.7980902106709365e-06, 6.118991556137464e-06, 5.6076221888803805e-06, 5.193725538978245e-06, 4.7498242527796635e-06, 4.274957069043304e-06, 3.902441796317622e-06, 3.5676095566615326e-06], "duration": 275219.40213, "accuracy_train": [0.5916739485280547, 0.6789441733573275, 0.7376179517349575, 0.7723019622093023, 0.7932461456602989, 0.8179846475290697, 0.8332104068613879, 0.8506926420035069, 0.8628971498361941, 0.8726148299072536, 0.8732200895741048, 0.8884930728589886, 0.8931902339424143, 0.8967233786683279, 0.8909352000853636, 0.9104624847153008, 0.9203203946913067, 0.9106016331556847, 0.9155774516080657, 0.9260388188099853, 0.9235963310954227, 0.924389044619786, 0.9268068388935032, 0.9244115751315062, 0.9377579292981728, 0.9311541461909376, 0.9446160368217055, 0.9415715338339794, 0.9429666231196937, 0.9422683575004615, 0.9459642626430418, 0.9454534508813216, 0.9516136532738095, 0.9442912369647471, 0.9533360658337948, 0.9565669412144703, 0.9498003976905685, 0.957706264131137, 0.9606127001430418, 0.946663249238649, 0.9591954408337948, 0.9596125256667589, 0.962193801333518, 0.959010149905408, 0.9601487518456996, 0.9598461220122739, 0.9645425621193245, 0.9450817875599853, 0.9615209501315062, 0.9623096982858066, 0.9671925107858066, 0.9576147001315062, 0.9655420156192323, 0.961217238833518, 0.9684956755837025, 0.9616819081072352, 0.9672157622739018, 0.9665886930717055, 0.9745868444882798, 0.9540561409883721, 0.9633814296673128, 0.9734239095953304, 0.9730289947858989, 0.9695648835478959, 0.9719122023809523, 0.9775158110119048, 0.9673334616671282, 0.9740516997739018, 0.9721933831672205, 0.9707514304171282, 0.9727964799049464, 0.9739358028216132, 0.9737043694052234, 0.9715180085478959, 0.9757959218692323, 0.9756564129406607, 0.9782144371193245, 0.9753069196428571, 0.977539783476375, 0.9740524207502769, 0.979771926333518, 0.9787019973929494, 0.9800502232142857, 0.9780513162144703, 0.974400832583518, 0.980749209809893, 0.9775394229881875, 0.9815855424049464, 0.9819575662144703, 0.9786336848814139, 0.9800509441906607, 0.9802841800479882, 0.9786805483457919, 0.9794696569882798, 0.9779346982858066, 0.9817483028216132, 0.9769116328096161, 0.9798878232858066, 0.9858863467261905, 0.978563209440753, 0.9833522950119971, 0.9819575662144703, 0.9794925479881875, 0.9874209449404762, 0.9801439501430418, 0.9815157879406607, 0.9798649322858989, 0.9785864609288483, 0.9794696569882798, 0.9832825405477114, 0.9757962823574198, 0.9839575546788483, 0.9825152414405685, 0.9871186755952381, 0.9803296015596161, 0.9868636302025655, 0.9846311268572352, 0.979097633178756, 0.9839110517026578, 0.988281970976375, 0.9846776298334257, 0.9818180572858989, 0.9857933407738095, 0.985840564726375, 0.9847477447858989, 0.9884908738810447, 0.9851422991071429, 0.9883277529761905, 0.984073451631137, 0.985143741059893, 0.9858634557262828, 0.9857003348214286, 0.9845613723929494, 0.9899553571428571, 0.9898856026785714, 0.9865373883928571, 0.9886765252976191, 0.9857704497739018, 0.9880959590716132, 0.9857475587739941, 0.9834681919642857, 0.9876999627976191, 0.9899321056547619, 0.9867234002976191, 0.9913969494047619, 0.9882579985119048, 0.9880959590716132, 0.9877006837739941, 0.9885370163690477, 0.9840963426310447, 0.9862819825119971, 0.9879335591431341, 0.9884672619047619, 0.989792957214378, 0.9891433575004615, 0.9872817965000923, 0.98460787536914, 0.9903742444167589, 0.9885835193452381, 0.9879568106312293, 0.9923509813930418, 0.9867935152500923, 0.990909389131137, 0.9889787946428571, 0.9854213169642857, 0.9910721495478036, 0.9897235632382798, 0.9894220148694168, 0.9898623511904762, 0.9912581614525655, 0.9920014880952381, 0.98656100036914, 0.9893043154761905, 0.9900948660714286, 0.9934201893572352, 0.9928156506667589, 0.9894677968692323, 0.9882118560239018, 0.9838423787029347, 0.9876080383098007, 0.9899088541666666, 0.9834220494762828, 0.9879793411429494, 0.992234363464378, 0.9907480706672205, 0.9893740699404762, 0.9941645974644703, 0.991211658476375, 0.9900723355597084, 0.9924901298334257, 0.9890256581072352, 0.9903520743932264, 0.9912814129406607, 0.9909558921073275, 0.9921413575119971, 0.9930245535714286, 0.9902808779761905, 0.9904668898809523, 0.9881882440476191, 0.9912112979881875, 0.9927455357142857, 0.9913518883813216, 0.9911415435239018, 0.9871655390596161, 0.9906303712739941, 0.9903985773694168, 0.9892116700119971, 0.9938154646548542, 0.9904905018572352, 0.9953035598929494, 0.9920254605597084, 0.9933268229166666, 0.9910027555717055, 0.9930478050595238, 0.9925834962739941, 0.9918161971668512, 0.9944200033453304, 0.9877933292381875, 0.98900240661914, 0.994140625, 0.9939317220953304, 0.9939081101190477, 0.9889097611549464, 0.9853290319882798, 0.9930485260358989, 0.9935131953096161, 0.9923044784168512, 0.9950481540120893, 0.9966525066906607, 0.9947684151785714, 0.9941638764880952, 0.9953736748454227, 0.9936305342146549, 0.9931876744762828, 0.9941645974644703, 0.9944908392741787, 0.9942568824404762, 0.99339693786914, 0.9942107399524732, 0.992722644714378], "end": "2016-02-04 14:14:00.803000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0], "moving_var_accuracy_valid": [0.031428535222890394, 0.061969577418038435, 0.0887980799371049, 0.10920394245023206, 0.12282782785948557, 0.13239693434981792, 0.1376212848193969, 0.139896900260758, 0.139255754111661, 0.13655701354650918, 0.13185940327229306, 0.12638133435636467, 0.12005572590655508, 0.1132514469036825, 0.10581996604317984, 0.09886418549158878, 0.09202753916912514, 0.08509662703400814, 0.07859855225633691, 0.07238014508736222, 0.06652407794870133, 0.060952386366674126, 0.05568883329331904, 0.05082325093600318, 0.04640167655668309, 0.04218693248766225, 0.03851311119466592, 0.03504900525283126, 0.031835249031353444, 0.028891880003057355, 0.026260595612226593, 0.023841237318303597, 0.021630833980360153, 0.019563955354741557, 0.017717934932811027, 0.016070859577825048, 0.014511362262701456, 0.013138895711335067, 0.011895989715551766, 0.010737398907597593, 0.009722021619951778, 0.008784578060756519, 0.007944713425345624, 0.007170179360178557, 0.006482896696071797, 0.005858575808765315, 0.005297547370784171, 0.004768474749990262, 0.004298206189930409, 0.003879097760491587, 0.0035163378657716514, 0.003166975157522496, 0.00285872683035028, 0.0025793989150235726, 0.0023318143819173664, 0.0021021559348391294, 0.0019024360426947605, 0.0017202196222706777, 0.0015733256687577844, 0.001420450166240372, 0.0012788744263899474, 0.0011738003816256165, 0.0010748461272670467, 0.0009767104921855178, 0.0008837172453773683, 0.0008114477988788614, 0.0007304502761559526, 0.0006610893643513292, 0.0005975970618139882, 0.000538351670489553, 0.000485182871151867, 0.00043844964642443063, 0.00039739112636485134, 0.00035899137030724057, 0.00033344558413564234, 0.00030852305427523356, 0.00028079124336540673, 0.00025538773037646177, 0.00023824325118342423, 0.00021443726389989808, 0.00020134608401393026, 0.00018121916917408686, 0.00016503513660875955, 0.00015023447818760977, 0.0001354269610294994, 0.00012913075529416465, 0.00011629618224948993, 0.00010568434944666086, 0.0001005469349581524, 9.088330004412972e-05, 8.293355974233502e-05, 8.142958640559682e-05, 7.350370913352015e-05, 6.644385659493415e-05, 5.981511192020161e-05, 5.820210449595556e-05, 5.277587446778966e-05, 4.769399588852663e-05, 4.7599447869983995e-05, 4.413798839524807e-05, 4.440519780721586e-05, 4.079742772551618e-05, 3.795057608291839e-05, 3.848166773046388e-05, 3.463450112879753e-05, 3.148430324709673e-05, 2.854832230717027e-05, 2.5848451677421265e-05, 2.3542548438360626e-05, 2.133779163286842e-05, 1.9262194748347145e-05, 1.7523312825296684e-05, 1.577204412115494e-05, 1.9180146996296892e-05, 1.7569019943112334e-05, 1.951617335783833e-05, 1.7576317601297074e-05, 1.6225608206125953e-05, 1.606329367163063e-05, 2.453738737569547e-05, 2.503905297729612e-05, 2.3367939496423825e-05, 2.421722009462134e-05, 2.1921642273321125e-05, 1.9732398131297827e-05, 2.2763664204336885e-05, 2.1822801550748364e-05, 2.214709220102358e-05, 2.077667969007066e-05, 1.8839898191454305e-05, 1.7417978721415262e-05, 1.5849817523437025e-05, 1.4410152763165586e-05, 1.3512982793752979e-05, 1.6360648286506142e-05, 1.4729191143515408e-05, 1.4123356734786998e-05, 1.3541486266025699e-05, 1.5095222277774207e-05, 1.4109685017314377e-05, 1.2825042719306352e-05, 1.2860558848657548e-05, 1.2561616760885575e-05, 1.1362142525613313e-05, 1.2923750213895433e-05, 1.1757652010703315e-05, 1.1146576310852844e-05, 1.0449064647983748e-05, 1.0190307702392235e-05, 9.620105402940044e-06, 8.694520244373086e-06, 9.239713481980329e-06, 8.346753649408496e-06, 8.8282845084971e-06, 8.606112444919216e-06, 7.97424130462105e-06, 8.971681774834299e-06, 8.106795444649857e-06, 7.408708584729936e-06, 6.720164889560141e-06, 1.3269139702421916e-05, 1.7675064432020777e-05, 2.2308212346936795e-05, 2.0220497158180217e-05, 1.821378037048112e-05, 1.649602488285078e-05, 1.5234208457319101e-05, 1.3723822418666877e-05, 1.2359471558248973e-05, 1.2624579804483626e-05, 1.4935099670193843e-05, 1.5495662412575695e-05, 1.417676823562717e-05, 1.313775990015083e-05, 1.4298432401224772e-05, 1.7803199327573868e-05, 1.725596976158232e-05, 1.5840465587099796e-05, 2.8447230932552724e-05, 2.574847111879763e-05, 2.3197293100806265e-05, 2.5175737727517965e-05, 2.3732389607760997e-05, 2.5193675737423686e-05, 2.3811888535714165e-05, 2.1688779491487318e-05, 2.4008438104069215e-05, 2.2901982950749343e-05, 2.06829726275866e-05, 2.4527643087487536e-05, 2.2075118869970173e-05, 1.987740925365991e-05, 1.8104314436769816e-05, 1.6621890268093897e-05, 1.7124593739691107e-05, 1.745285362272003e-05, 1.6059183404730703e-05, 1.5736514649155767e-05, 1.543838211330103e-05, 1.559243927362717e-05, 1.4260656662533007e-05, 1.401252635351082e-05, 1.2629366501562784e-05, 1.1992712697107608e-05, 1.4685389652562477e-05, 1.3491665340671473e-05, 1.2178775078140437e-05, 1.3117677326878758e-05, 1.2610782706436578e-05, 1.4327399912433228e-05, 1.3618966784708907e-05, 1.2758555621259699e-05, 1.150435165740722e-05, 1.0369086049954158e-05, 1.151138182494427e-05, 1.0673338274520199e-05, 1.1118507330911357e-05, 1.4679552548020618e-05, 1.4953660118514539e-05, 1.3779600474129968e-05, 1.3885919483305443e-05, 1.4745260882427159e-05, 1.4813034096859598e-05, 1.7742976370596556e-05, 1.598237049099608e-05, 1.768750303496599e-05, 1.5972739865530833e-05, 1.6928020143188486e-05, 1.626319890202119e-05, 1.4653347286252294e-05, 1.3190464751737267e-05, 1.3720579074988382e-05, 1.2578037557174012e-05, 1.142546660798605e-05, 1.0348116095354982e-05, 9.452580991731854e-06, 9.615363604140918e-06, 9.885009860217138e-06, 9.129647376387205e-06, 8.97149295293558e-06], "accuracy_test": 0.7063755580357143, "start": "2016-02-01 09:47:01.401000", "learning_rate_per_epoch": [0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225, 0.0001977052161237225], "accuracy_train_first": 0.5916739485280547, "accuracy_train_last": 0.992722644714378, "batch_size_eval": 1024, "accuracy_train_std": [0.019884779469925985, 0.02030970755606543, 0.021806717083890367, 0.0233147509065192, 0.023902584619183126, 0.022171385852606567, 0.02029488785098639, 0.019526933082743832, 0.018393497229075385, 0.019195035902852903, 0.018126712327801536, 0.016892111609495997, 0.016171926255869263, 0.016537587880205245, 0.01793190550445479, 0.01587783070909422, 0.015080650498210463, 0.01733135678051318, 0.015721366256550778, 0.014606771150361743, 0.01624920399367874, 0.013772432290588584, 0.014709651852753625, 0.01533774370046567, 0.013706503422319893, 0.01384178877055481, 0.013196325239969919, 0.011971588408563135, 0.012258326737792324, 0.013212433650860353, 0.01269756388008926, 0.012228016171232346, 0.011983542671182281, 0.012903939141819247, 0.011821896500447496, 0.01143135158506079, 0.012182034686863191, 0.01109306607507052, 0.010349881568171184, 0.011882156027022582, 0.009427273428951858, 0.010995871008722688, 0.010704841135243212, 0.010404008756400388, 0.011831806308531966, 0.01009997338070465, 0.009030906331145441, 0.01225557091487788, 0.010334115822709962, 0.00962186552393203, 0.00888042965385121, 0.010657269540608902, 0.009528502028993214, 0.009449865394367747, 0.008386007722587055, 0.009545479428027444, 0.010338552034612302, 0.008584785740355235, 0.0072020486472691, 0.011445979529347125, 0.009960860305786513, 0.007984773856483258, 0.007889677686189154, 0.00803625432233275, 0.008443332180475929, 0.006384174428146292, 0.00774249973487593, 0.008188618543277914, 0.007384502000219939, 0.007926478632860253, 0.006572820991600753, 0.007465289935244535, 0.006338556903072113, 0.007594364590536229, 0.006955078575052031, 0.007455703088047645, 0.006415254097650808, 0.006866712039167493, 0.005907961445169487, 0.007522582686673027, 0.00519292585964724, 0.006055832478630981, 0.006198865913435278, 0.006056830269233075, 0.006843324156187221, 0.006117270805362447, 0.006958815689442144, 0.005601955558233375, 0.005984706516725254, 0.0051061565265494695, 0.0067512180215208405, 0.005511910373445981, 0.00641025402663629, 0.006046342845682181, 0.006548827400861521, 0.005511696615617429, 0.006117801711073908, 0.005907032515278214, 0.005537418898000671, 0.005877542705221524, 0.004615968360580705, 0.005772260704750182, 0.00599080147737382, 0.004368372359014504, 0.006176961727107696, 0.005572791557629056, 0.005884387375078074, 0.005433655433967489, 0.00607257385680357, 0.004931108354128026, 0.006458160319612374, 0.005077181272522601, 0.005437504687832666, 0.004279284624377731, 0.005685720465762858, 0.003995310687542438, 0.004699269054787567, 0.005443946177072509, 0.004345044278486833, 0.00410050237919316, 0.0043761523954607895, 0.004814468472130459, 0.004703759375963521, 0.0038333509457984657, 0.004967244031334584, 0.004179693737205959, 0.005435330640572538, 0.003946456381933989, 0.0049377041783945285, 0.0040263856850283304, 0.004670960529553503, 0.005064609653479436, 0.0049219613328760565, 0.004056168617439829, 0.004345540772090547, 0.004411475859171398, 0.004434699460114109, 0.004828275607169748, 0.0037063610662576357, 0.003855867700973227, 0.004999502507586307, 0.004336324608525306, 0.0038387495633229606, 0.0038480334710255704, 0.002970007877945641, 0.004457316938858125, 0.003588072485671968, 0.004139511148401962, 0.004615347176349012, 0.004124017967652147, 0.00382483090548649, 0.003930115465556791, 0.0043372595709712585, 0.00405643635459288, 0.003618318045690753, 0.003670449483360637, 0.004836193954472926, 0.0035383724978438383, 0.004040477125776439, 0.003124435346339242, 0.0024487055968096627, 0.004880100047733367, 0.003447096345593481, 0.004011134422032705, 0.004837930149284026, 0.002693304763833978, 0.0038971763407778504, 0.00399870959787742, 0.0037030504188278377, 0.003044519223630273, 0.003529021367169675, 0.004979474746553529, 0.003940698530948732, 0.004118861821355179, 0.00295387076785279, 0.0030948059597251383, 0.004114312142834133, 0.004275627258085816, 0.004201054885901288, 0.003834679251327513, 0.0037379253095440076, 0.004297722547091831, 0.003904203624485894, 0.003175489515164783, 0.0035339687210520277, 0.0033505547633670865, 0.003171948431446369, 0.0034766272120369756, 0.003295245439550156, 0.002934151771332287, 0.003584655674558083, 0.003705309470320613, 0.0026320311336844493, 0.003655348750556747, 0.0034099625873813162, 0.003221820698602822, 0.0035972990338195157, 0.00335466681489424, 0.0038169284791611615, 0.002875780117866111, 0.0032885857902226834, 0.003479701744079469, 0.0037002914592401326, 0.00403066551260553, 0.003030518455107065, 0.0028830633951156814, 0.0038304872121933584, 0.0028410286526827965, 0.0038310019525597426, 0.00215520961422598, 0.0034628243905894763, 0.003217202802205701, 0.0033875149451791466, 0.0031261796519665166, 0.002852494583868866, 0.0026878811024766106, 0.002432959881841839, 0.003931817993129235, 0.0034441310886048323, 0.0026871317360851314, 0.0023595962769255444, 0.002873417355985009, 0.0035149146361306534, 0.004324636311880382, 0.0028693846911512066, 0.002834303597679294, 0.002993501359662223, 0.0020598023515771397, 0.001399452009478579, 0.0024835593509755253, 0.0025258651341047546, 0.0024767977889105872, 0.0025938145161106966, 0.0028793840079437607, 0.001993967515239275, 0.002751239500129949, 0.0024409633243341637, 0.001974900343450289, 0.0022090291768385, 0.0031485048255645563], "accuracy_test_std": 0.012311779532658227, "error_valid": [0.4090635000941265, 0.3291339184864458, 0.2739654908697289, 0.24871752635542166, 0.23988875423569278, 0.21714102503765065, 0.20767101609563254, 0.19318435852786142, 0.18798533979668675, 0.1814038380082832, 0.18378347373870485, 0.17507677193147586, 0.1736222232680723, 0.17157644248870485, 0.1799389942582832, 0.16640977974397586, 0.16298151590737953, 0.16977627306099397, 0.1632653661521084, 0.16276826054216864, 0.16039744917168675, 0.1623402790850903, 0.1648331607680723, 0.1629506306475903, 0.15682652484939763, 0.16518907661897586, 0.14925816547439763, 0.1536938770707832, 0.15584996234939763, 0.1553822712725903, 0.1483419027673193, 0.14859633847891573, 0.14779332172439763, 0.15463955431099397, 0.14904491010918675, 0.1433370199548193, 0.15384536191641573, 0.14497540945030118, 0.14350027061370485, 0.15021413780120485, 0.14145448983433728, 0.14472097373870485, 0.14170010118599397, 0.14545339561370485, 0.14067206325301207, 0.14071177287274095, 0.13878953313253017, 0.15649119917168675, 0.14546369070030118, 0.14224868222891573, 0.13535097420933728, 0.1453725056475903, 0.14020437217620485, 0.14039703736822284, 0.13734527955572284, 0.14074265813253017, 0.1355745246611446, 0.13584955054593373, 0.1276399543486446, 0.1497155614646084, 0.14109857398343373, 0.12723256306475905, 0.12725315323795183, 0.12993870011295183, 0.13190212019954817, 0.12501470726656627, 0.1383321371423193, 0.1307828972138554, 0.1311491081513554, 0.13839243693524095, 0.13351991952183728, 0.1315153190888554, 0.1299592902861446, 0.1311093985316265, 0.12385577466114461, 0.12383518448795183, 0.12665309676204817, 0.12650014118975905, 0.12174969408885539, 0.12999017554593373, 0.12076283650225905, 0.12972544474774095, 0.12482204207454817, 0.12464849632906627, 0.13011224585843373, 0.11974509365587349, 0.12688694230045183, 0.12436464608433728, 0.11962302334337349, 0.12869887754141573, 0.12326601327183728, 0.11778167356927716, 0.1271516730986446, 0.12395725480045183, 0.12515736775225905, 0.11856557087725905, 0.12692812264683728, 0.12357045368975905, 0.11769048851656627, 0.1279752800263554, 0.11734486775225905, 0.12079372176204817, 0.12723256306475905, 0.11696836172816272, 0.12310276261295183, 0.12133200771837349, 0.12147466820406627, 0.12154526308358427, 0.12448671639683728, 0.12419110033885539, 0.12383518448795183, 0.12166880412274095, 0.12285862198795183, 0.11551381306475905, 0.12405873493975905, 0.11598150414156627, 0.12139377823795183, 0.12384547957454817, 0.11790374388177716, 0.11094573606927716, 0.11474021084337349, 0.12293951195406627, 0.11425192959337349, 0.11842291039156627, 0.11930828783885539, 0.11201348362198793, 0.11487257624246983, 0.11306211172816272, 0.12087461172816272, 0.11686688158885539, 0.11572706842996983, 0.11915533226656627, 0.11917592243975905, 0.11557411285768071, 0.11095603115587349, 0.11687717667545183, 0.11397690370858427, 0.11373276308358427, 0.1107824854103916, 0.11831113516566272, 0.11732427757906627, 0.11243116999246983, 0.11256353539156627, 0.11475050592996983, 0.10998976374246983, 0.11373276308358427, 0.11730368740587349, 0.11720220726656627, 0.11230909967996983, 0.11720220726656627, 0.11582854856927716, 0.11129135683358427, 0.11427251976656627, 0.11097662132906627, 0.11170904320406627, 0.11255324030496983, 0.11845379565135539, 0.11383571394954817, 0.11549322289156627, 0.11524908226656627, 0.10560552757906627, 0.12164821394954817, 0.10603203830948793, 0.11488287132906627, 0.11416074454066272, 0.11486228115587349, 0.11182081842996983, 0.11406955948795183, 0.11342832266566272, 0.10961325771837349, 0.10698801063629515, 0.11743605280496983, 0.11153549745858427, 0.11092514589608427, 0.10752776731927716, 0.10484222044427716, 0.11520790192018071, 0.11373276308358427, 0.12461908179593373, 0.11204436888177716, 0.11370334855045183, 0.12015248493975905, 0.11047804499246983, 0.10706007624246983, 0.10937941217996983, 0.11427251976656627, 0.10568641754518071, 0.10824989410768071, 0.11077366105045183, 0.10346856174698793, 0.11071189053087349, 0.11108839655496983, 0.10924704678087349, 0.10872788027108427, 0.11535056240587349, 0.10617469879518071, 0.10848373964608427, 0.11403867422816272, 0.11440488516566272, 0.10667327513177716, 0.10899261106927716, 0.10680564053087349, 0.10961325771837349, 0.11265472044427716, 0.11685658650225905, 0.11268560570406627, 0.11047804499246983, 0.10615410862198793, 0.11355039297816272, 0.10510695124246983, 0.10744687735316272, 0.10763954254518071, 0.11025449454066272, 0.11022360928087349, 0.10493340549698793, 0.10749688205948793, 0.10507606598268071, 0.11597120905496983, 0.11388571865587349, 0.10803663874246983, 0.10567612245858427, 0.10433334902108427, 0.11297092667545183, 0.11624623493975905, 0.11033538450677716, 0.10392595773719882, 0.11015301440135539, 0.10413038874246983, 0.10554375705948793, 0.10901320124246983, 0.1084631494728916, 0.10407891330948793, 0.10656149990587349, 0.10691741575677716, 0.10703948606927716, 0.10656149990587349, 0.11118987669427716, 0.10433334902108427, 0.10605262848268071, 0.11039715502635539], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.0668272362177758, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.00019770521027279877, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.060343924679621e-08, "rotation_range": [0, 0], "momentum": 0.9339659167183437}, "accuracy_valid_max": 0.8965314382530121, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8896028449736446, "accuracy_valid_std": [0.014013941096087288, 0.023578239693302548, 0.022582381679420453, 0.009547589539522143, 0.012330546940847899, 0.011363911539499155, 0.011786382413183569, 0.006728068762269784, 0.007677875511894213, 0.008396541036461964, 0.01251858124320993, 0.008206360461582698, 0.009897586104908603, 0.0070882822810602415, 0.010959676531614605, 0.01169514439304587, 0.011372874951000858, 0.008141921384947896, 0.0069671393820537175, 0.013048017681547707, 0.009294322241163229, 0.008657498017692482, 0.01487217295503819, 0.009791565705593228, 0.009845158047644976, 0.01083575149037638, 0.010482640948724649, 0.012813110749202591, 0.007831775079632184, 0.008390591862338934, 0.00597858309338194, 0.005025872179370918, 0.009069140735213348, 0.00830876465013549, 0.011731254748990854, 0.005198369449062378, 0.006174182498935846, 0.010338265246983346, 0.010185917625957261, 0.008267302914638635, 0.004330566565568542, 0.01045513243740384, 0.012182611811251971, 0.008112860851057864, 0.009756266339744364, 0.0062877180218204026, 0.009034313644532182, 0.011115518168687208, 0.008795391532126823, 0.007818652922508806, 0.006674985893922266, 0.012296314869525609, 0.010190983702212868, 0.008689740005053022, 0.007296826778666914, 0.006702208361737725, 0.006247191892624455, 0.006837636946292698, 0.002673118829149569, 0.008059272763532518, 0.009842320359858948, 0.005254930012358328, 0.0046807793067014, 0.006548921704695411, 0.0060961985380115725, 0.0073294187874423005, 0.007837512012648717, 0.006448951078440097, 0.006723567620018938, 0.007363974632704911, 0.00612413529035899, 0.00859231642533589, 0.004158861329831216, 0.008712963559244438, 0.0037888510627580338, 0.004593435125447943, 0.006132300217433098, 0.008833567767556401, 0.00412566169733999, 0.0093078058380209, 0.0037798736616016407, 0.005850629573701017, 0.003606554939421307, 0.008711439512544307, 0.007253929221738607, 0.0071202613631131334, 0.003959449376580235, 0.005685381095107056, 0.007684805596258738, 0.010362555814839811, 0.007629648945000096, 0.007485464116125891, 0.0036794485944197097, 0.0061206517599828964, 0.0060421659376944685, 0.0033679547312004602, 0.006698090128070493, 0.005760002516484189, 0.005678003833968576, 0.008273062036777305, 0.005827508059758471, 0.004758682406544621, 0.0051170086926030246, 0.007861253828904735, 0.006906922599630219, 0.00823639650728889, 0.005452460977169383, 0.010526061987948069, 0.0069339880060918235, 0.004025222756016058, 0.005448184569134493, 0.009362847697198034, 0.007388328824569477, 0.006519836604250826, 0.004257086838495437, 0.006425752708995831, 0.006265295557228915, 0.004397201914031231, 0.008718863452316176, 0.008625986245214868, 0.00891643340102978, 0.008156096706374192, 0.006430401769154634, 0.007946885825874208, 0.006036257103219588, 0.009392835142719916, 0.004386348005055911, 0.005694799279865692, 0.005423787670961616, 0.004889133419311668, 0.006380053428864388, 0.005961082112415945, 0.008889646168573573, 0.00984476333852329, 0.00616104915729576, 0.0063278665158235225, 0.007814576101135676, 0.008738880943316405, 0.008210229965906146, 0.008309550945583338, 0.005452724385163455, 0.00706387854393873, 0.005450534419323813, 0.007747619260224038, 0.007403209088132603, 0.0108450197937131, 0.006871122714088055, 0.008203756531705316, 0.004417690528051736, 0.006464582992554931, 0.008282823337495752, 0.010444628858647767, 0.00499492637998362, 0.005545573152749071, 0.00881477724210827, 0.0054503421427905705, 0.005201161348509953, 0.006193780008433088, 0.004291442280681797, 0.006413503550349861, 0.006553740004927534, 0.0060705822582534635, 0.005836339833817467, 0.0057048952405153565, 0.008000685423221498, 0.010757738782557594, 0.00800653312383906, 0.0055902689736740995, 0.004518516549325523, 0.006365581574659435, 0.011272302211359369, 0.006702382474983096, 0.008334934698335713, 0.007379064060574323, 0.004288110324230551, 0.003758812511978792, 0.006861879761241908, 0.009818105763638415, 0.007861357285241325, 0.008937679222638314, 0.005619178104578446, 0.005419022442957811, 0.0060665140988000145, 0.003417542187338347, 0.00629038972267858, 0.009501367281359268, 0.006838134377178673, 0.006630254840085152, 0.006583822662404288, 0.00640226757469121, 0.007815513826900003, 0.003956318947581481, 0.005707363760776165, 0.007528160023854195, 0.0076416634619577714, 0.008232057418306876, 0.006331283352602389, 0.004779661384750545, 0.007314939615651316, 0.006858934138282173, 0.0049271230759217995, 0.0047089348877310715, 0.006440054588281837, 0.007247649639749834, 0.007829000424683442, 0.00534390731609894, 0.005011993908113096, 0.00593479082358727, 0.008427937606075494, 0.008358885271435778, 0.007249818873188037, 0.006109562100865684, 0.006875942045219783, 0.007898595668694611, 0.00742923999403663, 0.01097219484082734, 0.0071957806827197945, 0.00451417140813296, 0.004915762330172082, 0.0032737291804343636, 0.005622147503969612, 0.007305463941006702, 0.005834484980058163, 0.0035320571612143287, 0.006460607247003372, 0.007913022100101228, 0.007495385077642266, 0.005261130298619593, 0.007875981557381817, 0.0037159287851281655, 0.008990882977409445, 0.007994983601641912, 0.004185932748075289, 0.005450497710705629, 0.0048964199105216285, 0.0034002306530395965, 0.007714556171261041, 0.006692289185748994, 0.005312958266048274, 0.007529606715450774], "accuracy_valid": [0.5909364999058735, 0.6708660815135542, 0.7260345091302711, 0.7512824736445783, 0.7601112457643072, 0.7828589749623494, 0.7923289839043675, 0.8068156414721386, 0.8120146602033133, 0.8185961619917168, 0.8162165262612951, 0.8249232280685241, 0.8263777767319277, 0.8284235575112951, 0.8200610057417168, 0.8335902202560241, 0.8370184840926205, 0.830223726939006, 0.8367346338478916, 0.8372317394578314, 0.8396025508283133, 0.8376597209149097, 0.8351668392319277, 0.8370493693524097, 0.8431734751506024, 0.8348109233810241, 0.8507418345256024, 0.8463061229292168, 0.8441500376506024, 0.8446177287274097, 0.8516580972326807, 0.8514036615210843, 0.8522066782756024, 0.845360445689006, 0.8509550898908133, 0.8566629800451807, 0.8461546380835843, 0.8550245905496988, 0.8564997293862951, 0.8497858621987951, 0.8585455101656627, 0.8552790262612951, 0.858299898814006, 0.8545466043862951, 0.8593279367469879, 0.859288227127259, 0.8612104668674698, 0.8435088008283133, 0.8545363092996988, 0.8577513177710843, 0.8646490257906627, 0.8546274943524097, 0.8597956278237951, 0.8596029626317772, 0.8626547204442772, 0.8592573418674698, 0.8644254753388554, 0.8641504494540663, 0.8723600456513554, 0.8502844385353916, 0.8589014260165663, 0.872767436935241, 0.8727468467620482, 0.8700612998870482, 0.8680978798004518, 0.8749852927334337, 0.8616678628576807, 0.8692171027861446, 0.8688508918486446, 0.861607563064759, 0.8664800804781627, 0.8684846809111446, 0.8700407097138554, 0.8688906014683735, 0.8761442253388554, 0.8761648155120482, 0.8733469032379518, 0.873499858810241, 0.8782503059111446, 0.8700098244540663, 0.879237163497741, 0.870274555252259, 0.8751779579254518, 0.8753515036709337, 0.8698877541415663, 0.8802549063441265, 0.8731130576995482, 0.8756353539156627, 0.8803769766566265, 0.8713011224585843, 0.8767339867281627, 0.8822183264307228, 0.8728483269013554, 0.8760427451995482, 0.874842632247741, 0.881434429122741, 0.8730718773531627, 0.876429546310241, 0.8823095114834337, 0.8720247199736446, 0.882655132247741, 0.8792062782379518, 0.872767436935241, 0.8830316382718373, 0.8768972373870482, 0.8786679922816265, 0.8785253317959337, 0.8784547369164157, 0.8755132836031627, 0.8758088996611446, 0.8761648155120482, 0.878331195877259, 0.8771413780120482, 0.884486186935241, 0.875941265060241, 0.8840184958584337, 0.8786062217620482, 0.8761545204254518, 0.8820962561182228, 0.8890542639307228, 0.8852597891566265, 0.8770604880459337, 0.8857480704066265, 0.8815770896084337, 0.8806917121611446, 0.8879865163780121, 0.8851274237575302, 0.8869378882718373, 0.8791253882718373, 0.8831331184111446, 0.8842729315700302, 0.8808446677334337, 0.880824077560241, 0.8844258871423193, 0.8890439688441265, 0.8831228233245482, 0.8860230962914157, 0.8862672369164157, 0.8892175145896084, 0.8816888648343373, 0.8826757224209337, 0.8875688300075302, 0.8874364646084337, 0.8852494940700302, 0.8900102362575302, 0.8862672369164157, 0.8826963125941265, 0.8827977927334337, 0.8876909003200302, 0.8827977927334337, 0.8841714514307228, 0.8887086431664157, 0.8857274802334337, 0.8890233786709337, 0.8882909567959337, 0.8874467596950302, 0.8815462043486446, 0.8861642860504518, 0.8845067771084337, 0.8847509177334337, 0.8943944724209337, 0.8783517860504518, 0.8939679616905121, 0.8851171286709337, 0.8858392554593373, 0.8851377188441265, 0.8881791815700302, 0.8859304405120482, 0.8865716773343373, 0.8903867422816265, 0.8930119893637049, 0.8825639471950302, 0.8884645025414157, 0.8890748541039157, 0.8924722326807228, 0.8951577795557228, 0.8847920980798193, 0.8862672369164157, 0.8753809182040663, 0.8879556311182228, 0.8862966514495482, 0.879847515060241, 0.8895219550075302, 0.8929399237575302, 0.8906205878200302, 0.8857274802334337, 0.8943135824548193, 0.8917501058923193, 0.8892263389495482, 0.8965314382530121, 0.8892881094691265, 0.8889116034450302, 0.8907529532191265, 0.8912721197289157, 0.8846494375941265, 0.8938253012048193, 0.8915162603539157, 0.8859613257718373, 0.8855951148343373, 0.8933267248682228, 0.8910073889307228, 0.8931943594691265, 0.8903867422816265, 0.8873452795557228, 0.883143413497741, 0.8873143942959337, 0.8895219550075302, 0.8938458913780121, 0.8864496070218373, 0.8948930487575302, 0.8925531226468373, 0.8923604574548193, 0.8897455054593373, 0.8897763907191265, 0.8950665945030121, 0.8925031179405121, 0.8949239340173193, 0.8840287909450302, 0.8861142813441265, 0.8919633612575302, 0.8943238775414157, 0.8956666509789157, 0.8870290733245482, 0.883753765060241, 0.8896646154932228, 0.8960740422628012, 0.8898469855986446, 0.8958696112575302, 0.8944562429405121, 0.8909867987575302, 0.8915368505271084, 0.8959210866905121, 0.8934385000941265, 0.8930825842432228, 0.8929605139307228, 0.8934385000941265, 0.8888101233057228, 0.8956666509789157, 0.8939473715173193, 0.8896028449736446], "seed": 813604890, "model": "residualv3", "loss_std": [0.34504199028015137, 0.2609754800796509, 0.25470709800720215, 0.24832852184772491, 0.24078726768493652, 0.23199672996997833, 0.2255619466304779, 0.22128498554229736, 0.21304641664028168, 0.2065073847770691, 0.20211321115493774, 0.1941125988960266, 0.18867997825145721, 0.18359467387199402, 0.1771537959575653, 0.17340852320194244, 0.16719993948936462, 0.1647566556930542, 0.15726754069328308, 0.15262672305107117, 0.1472460776567459, 0.1479189693927765, 0.13995206356048584, 0.13662835955619812, 0.13241970539093018, 0.12669186294078827, 0.12329234927892685, 0.12219841778278351, 0.12003498524427414, 0.11462661623954773, 0.11195718497037888, 0.10878192633390427, 0.10729328542947769, 0.10403924435377121, 0.10289391875267029, 0.09989168494939804, 0.09625857323408127, 0.09417421370744705, 0.0927291288971901, 0.09084303677082062, 0.0881844237446785, 0.08649253845214844, 0.08728964626789093, 0.08270671963691711, 0.08357033133506775, 0.07856632024049759, 0.07994638383388519, 0.07750259339809418, 0.07775191962718964, 0.0776885598897934, 0.07238288223743439, 0.07356778532266617, 0.06953085958957672, 0.07145202159881592, 0.06918561458587646, 0.06869207322597504, 0.06834132969379425, 0.07026165723800659, 0.0658058449625969, 0.06483232975006104, 0.06655983626842499, 0.06182825192809105, 0.06393350660800934, 0.061513785272836685, 0.06019541248679161, 0.06421905755996704, 0.06231573969125748, 0.058849480003118515, 0.05864323675632477, 0.05842283368110657, 0.05987393110990524, 0.056641340255737305, 0.05930589139461517, 0.05561070889234543, 0.05815713480114937, 0.054841261357069016, 0.05711828172206879, 0.05543681979179382, 0.052521489560604095, 0.056277208030223846, 0.05112205073237419, 0.05891459062695503, 0.05236046388745308, 0.05099320784211159, 0.052474960684776306, 0.04768241569399834, 0.05060974135994911, 0.05264800414443016, 0.047592487186193466, 0.050441958010196686, 0.04896464943885803, 0.04795188084244728, 0.048003073781728745, 0.05020688474178314, 0.04401185363531113, 0.049858734011650085, 0.048251569271087646, 0.04615330696105957, 0.04672500863671303, 0.048622507601976395, 0.0446518138051033, 0.04669537767767906, 0.0447610504925251, 0.04540672525763512, 0.04374753683805466, 0.0491376593708992, 0.04472135007381439, 0.04466311261057854, 0.046754758805036545, 0.04403682425618172, 0.04386945441365242, 0.04401461035013199, 0.043937403708696365, 0.0432928204536438, 0.04043155908584595, 0.04363197833299637, 0.043491169810295105, 0.04208594188094139, 0.03919319063425064, 0.04188189655542374, 0.04309195652604103, 0.03994631767272949, 0.04327055811882019, 0.041325487196445465, 0.043916139751672745, 0.040343452244997025, 0.043098658323287964, 0.04097432643175125, 0.03956591710448265, 0.039466727524995804, 0.04001061990857124, 0.04147154837846756, 0.04039229825139046, 0.038964081555604935, 0.03849715366959572, 0.03755071386694908, 0.04040861502289772, 0.03664188086986542, 0.03646771237254143, 0.04397411644458771, 0.040651559829711914, 0.04044787958264351, 0.03635775297880173, 0.038035955280065536, 0.035984355956315994, 0.04142124578356743, 0.03837961331009865, 0.03786921501159668, 0.03556924685835838, 0.04022114723920822, 0.03566374629735947, 0.03705790638923645, 0.03341778740286827, 0.0340062752366066, 0.036953363567590714, 0.03713514655828476, 0.036019232124090195, 0.03507688641548157, 0.03583299741148949, 0.03641447797417641, 0.039504360407590866, 0.03286513313651085, 0.033624451607465744, 0.03425503522157669, 0.034420195966959, 0.03349877893924713, 0.035884834825992584, 0.03735640272498131, 0.03566383197903633, 0.03290795162320137, 0.037355367094278336, 0.03502487763762474, 0.03628123179078102, 0.035001710057258606, 0.033141475170850754, 0.03273236006498337, 0.03484458476305008, 0.03205692395567894, 0.03579286113381386, 0.033610161393880844, 0.032249514013528824, 0.03634556010365486, 0.031802982091903687, 0.03234801068902016, 0.03639703989028931, 0.032494258135557175, 0.03348726034164429, 0.031786784529685974, 0.031053509563207626, 0.03269040212035179, 0.03436961770057678, 0.032187022268772125, 0.035198137164115906, 0.03595224767923355, 0.035147618502378464, 0.03417700156569481, 0.031238313764333725, 0.031321726739406586, 0.034188490360975266, 0.029521245509386063, 0.03819536790251732, 0.028811519965529442, 0.032875362783670425, 0.0304552111774683, 0.03100169636309147, 0.032090671360492706, 0.030101370066404343, 0.03380722925066948, 0.03023846447467804, 0.028003964573144913, 0.03382963687181473, 0.029668064787983894, 0.03070114552974701, 0.0286782905459404, 0.028948739171028137, 0.03385346382856369, 0.028715701773762703, 0.02742786332964897, 0.03033379651606083, 0.028430407866835594, 0.029405085369944572, 0.028695495799183846, 0.02967873215675354, 0.030500954017043114, 0.02967906929552555, 0.033584531396627426, 0.02909279055893421, 0.03609404340386391, 0.03875967115163803, 0.02991979569196701, 0.0333915650844574, 0.028349315747618675, 0.027912180870771408, 0.028927959501743317, 0.03385425731539726, 0.027426403015851974, 0.026571162045001984, 0.02952004410326481, 0.027759484946727753, 0.02821688912808895]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:37 2016", "state": "available"}], "summary": "8c480c1633681f2d7cb6a5cff43f5d4d"}