{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 16, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [2.038048267364502, 1.6539900302886963, 1.5151159763336182, 1.437984824180603, 1.3813917636871338, 1.3356997966766357, 1.2964603900909424, 1.263942003250122, 1.2342427968978882, 1.2112480401992798, 1.1889808177947998, 1.1669723987579346, 1.1509528160095215, 1.1317901611328125, 1.1178550720214844, 1.1049222946166992, 1.0911222696304321, 1.0774859189987183, 1.0678232908248901, 1.0561331510543823, 1.0471433401107788, 1.0404945611953735, 1.0299293994903564, 1.020551085472107, 1.0117279291152954, 1.0059967041015625, 0.9993279576301575, 0.9890367388725281, 0.9846631288528442, 0.9775301814079285, 0.9743650555610657, 0.9659172892570496, 0.9609893560409546, 0.9558320045471191, 0.9511796832084656, 0.9467925429344177, 0.9413419961929321, 0.9336677193641663, 0.9322929382324219, 0.9281178116798401, 0.924980640411377, 0.9218913912773132, 0.917481005191803, 0.9123778939247131, 0.9095525145530701, 0.9058317542076111, 0.9031880497932434, 0.900449812412262, 0.8966554999351501, 0.8926219344139099, 0.8912344574928284, 0.889053463935852, 0.8853188753128052, 0.885560929775238, 0.879793107509613, 0.8789487481117249, 0.875920832157135, 0.8739287853240967, 0.8723952174186707, 0.8716109991073608, 0.8667113184928894, 0.8669257760047913, 0.8643736243247986, 0.8610976338386536, 0.8604398965835571, 0.8597941994667053, 0.8555086255073547, 0.8549287915229797, 0.8534495234489441, 0.8493128418922424, 0.8493078947067261, 0.8506529927253723, 0.84721839427948, 0.8471986055374146, 0.845649242401123, 0.8453412055969238, 0.8428989052772522, 0.8433205485343933, 0.8420416712760925, 0.8385621905326843, 0.8369538187980652, 0.8369284272193909, 0.8344334363937378, 0.8342268466949463, 0.8347995281219482, 0.8330388069152832, 0.8319838047027588, 0.8290560841560364, 0.8302883505821228, 0.829896092414856, 0.8294916152954102, 0.8253388404846191, 0.8280918002128601, 0.8275629281997681, 0.8247717618942261, 0.8246690034866333, 0.8235592842102051, 0.8233861327171326, 0.8220722675323486, 0.8254324793815613, 0.8202655911445618, 0.8216999173164368, 0.8193612098693848, 0.8203313946723938, 0.820442259311676, 0.8188047409057617, 0.8151553273200989, 0.8167731165885925, 0.8158717751502991, 0.8177182078361511, 0.8173382878303528, 0.8158919215202332, 0.8156313300132751, 0.8132344484329224, 0.8138360977172852, 0.8136749863624573, 0.813400149345398, 0.8142346739768982, 0.811067521572113, 0.8110224008560181, 0.8110440373420715, 0.8119725584983826, 0.8111127018928528, 0.8086920976638794, 0.8099600076675415, 0.8103415966033936, 0.8082907795906067, 0.8088136315345764, 0.8104258179664612, 0.811221718788147, 0.8083618879318237, 0.807851254940033, 0.8070818781852722, 0.809022843837738, 0.8078947067260742, 0.8059039115905762, 0.807708740234375, 0.8079929351806641, 0.8034358024597168, 0.8057039976119995, 0.8070200085639954, 0.8054131269454956, 0.8054998517036438, 0.8059853911399841, 0.806755542755127, 0.8053455948829651, 0.8052806258201599, 0.803530216217041, 0.8053980469703674, 0.8049171566963196, 0.8041787147521973, 0.8029096126556396, 0.8052369356155396, 0.8051283359527588, 0.8039426207542419, 0.8041136264801025, 0.8013015985488892, 0.8035603761672974, 0.8026049733161926, 0.804103434085846, 0.8004449009895325, 0.8015099763870239, 0.8024898767471313, 0.8039475679397583, 0.8023238182067871, 0.8024163842201233, 0.802294135093689, 0.8018903136253357, 0.8033091425895691, 0.8019827008247375, 0.8035309314727783, 0.8025782108306885, 0.8025553822517395, 0.8018612861633301, 0.8011433482170105, 0.8014631867408752, 0.8027856945991516, 0.8021878004074097, 0.8013584017753601, 0.8020142316818237, 0.8015044331550598, 0.8001425862312317, 0.8007945418357849, 0.801073431968689, 0.8009985685348511, 0.8014427423477173, 0.8004249334335327, 0.8008426427841187, 0.8005940914154053, 0.7987725734710693, 0.7982355356216431, 0.7988684773445129, 0.7999328970909119, 0.7995502948760986, 0.8015475869178772, 0.8008030652999878, 0.8010646104812622, 0.7988743185997009, 0.8004574775695801, 0.8009697794914246, 0.7998230457305908, 0.7998813986778259, 0.8009137511253357, 0.7982988953590393, 0.799067497253418, 0.800661027431488, 0.7985103130340576, 0.7994243502616882, 0.7994423508644104, 0.7993302345275879, 0.7981217503547668, 0.7993274331092834, 0.7985130548477173, 0.7994664907455444, 0.7986851334571838, 0.7992985248565674, 0.7987908124923706, 0.7994662523269653, 0.799550473690033, 0.7991014719009399, 0.798854410648346, 0.7996894121170044, 0.7974826693534851, 0.7987419962882996, 0.7982384562492371, 0.7993932962417603, 0.7997116446495056, 0.7989698052406311, 0.7987741231918335, 0.7965651750564575, 0.7993686199188232, 0.7989588379859924, 0.7983903288841248, 0.8005490303039551, 0.7982239127159119, 0.7974697947502136, 0.7985718846321106, 0.7997612357139587, 0.7982863187789917, 0.7979569435119629, 0.798812747001648, 0.7975034117698669, 0.797773003578186, 0.7993950247764587, 0.8002640008926392, 0.7987309694290161, 0.7994959354400635, 0.7969781756401062, 0.7966190576553345, 0.7993351221084595, 0.7997618913650513, 0.7981563806533813, 0.8003438115119934, 0.7986463308334351, 0.7964226603507996, 0.7982150912284851, 0.7975557446479797, 0.7990160584449768, 0.7983059287071228, 0.7990368008613586, 0.8006965517997742, 0.7980252504348755, 0.7981582283973694, 0.7973513007164001, 0.8000558614730835, 0.7971532344818115, 0.7988686561584473, 0.8003928661346436, 0.7992547154426575, 0.7982423305511475, 0.7976292967796326, 0.798608660697937, 0.7983572483062744, 0.7974710464477539, 0.8002265095710754, 0.797451913356781, 0.7978194952011108, 0.7976170182228088, 0.7979501485824585, 0.7965377569198608, 0.7972193956375122, 0.7985581159591675, 0.797059953212738, 0.7965131998062134, 0.7975859045982361, 0.7972266674041748, 0.7982417941093445, 0.7969264984130859, 0.7970104217529297, 0.7980718612670898, 0.7991545796394348, 0.7994589805603027, 0.798244833946228, 0.7992795705795288, 0.7975438237190247, 0.7999395132064819, 0.7978988289833069, 0.7988644242286682, 0.7991989850997925, 0.7969445586204529, 0.7979332804679871, 0.7977725863456726, 0.8001716136932373, 0.7992086410522461, 0.7991239428520203, 0.7980219125747681, 0.7982044219970703, 0.79468834400177, 0.7962019443511963, 0.7992983460426331, 0.7979015707969666, 0.7977840900421143, 0.7984554767608643, 0.7962231040000916, 0.7977699041366577, 0.7953923940658569, 0.7968566417694092, 0.797515869140625, 0.7983298301696777, 0.7985585331916809, 0.7978405356407166, 0.7985293865203857, 0.7992282509803772, 0.7980504035949707, 0.7989389896392822, 0.7991855144500732, 0.7992302775382996, 0.7975647449493408, 0.7975856065750122, 0.7974966168403625, 0.7965567111968994, 0.7981628775596619, 0.7975704073905945, 0.7961124181747437, 0.7994539737701416, 0.7982118129730225, 0.7996951937675476, 0.7974379658699036, 0.798795223236084, 0.7994704842567444, 0.798067569732666, 0.7975758910179138], "moving_avg_accuracy_train": [0.03634823529411764, 0.07757929411764705, 0.1183366588235294, 0.15764887529411764, 0.19485575247058823, 0.2303701772235294, 0.2630084536188235, 0.2940581964922353, 0.32267825919595294, 0.3495610215116518, 0.3745484487722513, 0.3976441921303203, 0.41954330232905296, 0.4397042662137947, 0.4582773690041799, 0.4760402203390561, 0.4922009041875034, 0.5067266961216943, 0.5208704970977601, 0.5339858003291605, 0.545344867355068, 0.5559656747372083, 0.5663408719693699, 0.575737373007727, 0.584311871001072, 0.5921159780186118, 0.5997349684520448, 0.6067544127833109, 0.6131307362108622, 0.6192388390603643, 0.6249055433896219, 0.6301820478741891, 0.6352956077926525, 0.6398225176016226, 0.6438308540767544, 0.6481254157279025, 0.6520587565080534, 0.6559493514454834, 0.6596485339479939, 0.6630883864355475, 0.6662007242625809, 0.6696559459539698, 0.6725727042997494, 0.6754189632815392, 0.6782747140122087, 0.6807366543756938, 0.683335930114595, 0.6858423371031356, 0.6881663386869397, 0.6907049989358928, 0.6930697931599505, 0.6952145785498378, 0.6973001795183834, 0.6991560439194863, 0.7008992630569494, 0.7026563955747839, 0.7044825207231878, 0.7062413274743985, 0.707988959432841, 0.7095712399601453, 0.711119998317072, 0.7125703514265412, 0.7139486104015341, 0.7153725728907925, 0.7167506097193603, 0.7179579016886009, 0.7193032879903289, 0.7204553121324726, 0.721678016213343, 0.7227219792978911, 0.7238733107798666, 0.7250459797018799, 0.7260613817316919, 0.7270105376761697, 0.7278577192026705, 0.7287637119882858, 0.7295885172600454, 0.7305496655340409, 0.7313888166276956, 0.7321816996708085, 0.732890588527257, 0.7334791767333548, 0.7342300825894311, 0.734962368448135, 0.7355578963092039, 0.7362068125606365, 0.7367649548339846, 0.737373165232939, 0.7378287898861158, 0.7383070873680924, 0.7388410845136361, 0.7392722701799195, 0.7397521019854569, 0.7402168917869112, 0.7406304967258671, 0.7410662705826921, 0.7414443494067758, 0.7418810909366865, 0.742238864195959, 0.7425867424822454, 0.742918656469315, 0.7432456143517953, 0.7435681117401451, 0.7439289476249542, 0.7442513469801058, 0.7445979769879775, 0.7448722969362386, 0.7451333025367324, 0.7454011487536474, 0.7456822103488709, 0.7459634010786897, 0.7461247080296443, 0.7463898842855033, 0.7465885429157766, 0.7467391003889049, 0.7469993079970733, 0.7471370242561894, 0.747300968889394, 0.7474838131769252, 0.7476789612709975, 0.7478381239674272, 0.7480848998059786, 0.7482552333547925, 0.7483591217840191, 0.74852791548797, 0.7486986533509378, 0.7488217291923146, 0.7489583798024948, 0.7491025418222453, 0.7492252288164913, 0.7493803529936657, 0.7495152588707696, 0.7496202035719279, 0.7497311243912057, 0.7498450707756146, 0.750025269580406, 0.7501098014458949, 0.7502564683601289, 0.7502990568182337, 0.7504103276069987, 0.7505034124933576, 0.7506083653616689, 0.7507192935313842, 0.7508073641782458, 0.7509078042310094, 0.7510382002784968, 0.7511014390741765, 0.7511818834020529, 0.75123545976773, 0.7513048549674276, 0.7513461341765673, 0.7514609325236165, 0.7515689569183136, 0.7516638259323646, 0.7517445021626574, 0.7518359342993329, 0.7519323408693996, 0.7519673420765773, 0.7520529608100961, 0.7521017823761453, 0.7521951335502954, 0.75224620843056, 0.7522874699404452, 0.752355193534636, 0.7524820271223488, 0.7525608832336433, 0.7526459713808673, 0.75270843306631, 0.7527481779949731, 0.7528263013719463, 0.7528613182935752, 0.7528998923465706, 0.7529393148766195, 0.7529771480948398, 0.7530464921088853, 0.7530689017215262, 0.7531431880199617, 0.7531865162767891, 0.7532372764138161, 0.7532735487724345, 0.753310899777544, 0.7533656921527307, 0.7533797111727517, 0.7534417400554766, 0.7534763895793407, 0.7535263976802302, 0.7536208167357367, 0.753663440944516, 0.7536123909677115, 0.7536511518709403, 0.7536930955073757, 0.7537473153684029, 0.7537467014786214, 0.7537767372131122, 0.7538155340800363, 0.7538810394955622, 0.7539141120165942, 0.7539415243443466, 0.7539756072040296, 0.7539921641306855, 0.7540305947764404, 0.7540887117693846, 0.7541410170630345, 0.7541598565332016, 0.7542356355857638, 0.7542144249683639, 0.754240041295057, 0.7542466254008454, 0.7542854922725256, 0.7543392959864496, 0.7543665428583929, 0.7544075356313772, 0.7544561938329453, 0.7544741038614154, 0.7545161052399798, 0.754495082951276, 0.7545420452443837, 0.75455137013171, 0.7545315272361861, 0.754520727453744, 0.7545463017671932, 0.7545481421787091, 0.7545780338431911, 0.7545719951647544, 0.7546065603541613, 0.7546094337305099, 0.7546143727104001, 0.75463293543936, 0.7546425830718946, 0.7546159718235287, 0.7546390805235287, 0.7545939960005876, 0.7546122434593524, 0.7546074897016524, 0.7546314466138401, 0.7546459490112796, 0.7546378246983869, 0.7546705128167835, 0.75466699094687, 0.7546661742051242, 0.7546983803140235, 0.7547132481649741, 0.7547030998190649, 0.7547433780724525, 0.7547490402652073, 0.7547188421210396, 0.7546751932030533, 0.7546806150592187, 0.754718435906238, 0.7547501217273789, 0.7547504036722881, 0.7547741868344711, 0.754776768151024, 0.7548026207476863, 0.7548352998493882, 0.7547941228056259, 0.7547547105250633, 0.7548157100607923, 0.7548423743488307, 0.7548569604433594, 0.7549077349872587, 0.7549134320767681, 0.7549915006337972, 0.7549676446880645, 0.7549414684545521, 0.7548967333738028, 0.7549082365070108, 0.754949177562192, 0.754960142158914, 0.7549770691194932, 0.7549993622075439, 0.7549770730456131, 0.7549711304469342, 0.7549657821081232, 0.7549656744855461, 0.7549608717428739, 0.7549518433921159, 0.7549272472881984, 0.7549380519711433, 0.7549336585387347, 0.7548802926848612, 0.7549146163575516, 0.7549031547217965, 0.7548904863084404, 0.7549026141481845, 0.7549511762627779, 0.7549548821659118, 0.7549182174787323, 0.7549652192602709, 0.7549134032165967, 0.7548408864243489, 0.754836797781914, 0.7548542944743108, 0.754830041497468, 0.7548623314653683, 0.754858451260008, 0.7549184884869483, 0.7548972278735475, 0.7549251521450162, 0.7549008722246322, 0.7549166673551102, 0.754954412384305, 0.7549107358517569, 0.7548973093254048, 0.7548781666281584, 0.7549244676124014, 0.754935550262926, 0.7549478775895746, 0.7549566192423818, 0.7549833102593201, 0.7550026262922116, 0.7549988342512257, 0.7550354214143384, 0.755023643978787, 0.7549942207573788, 0.7549630339757585, 0.7549820246958296, 0.7549732339909525, 0.7549723811800926, 0.7549692607091422, 0.7550040993441103, 0.7549695717626405, 0.7549737910569646, 0.7549799413630329, 0.7549948884032002, 0.7550177525040567, 0.7550053890183568, 0.7549707324694623, 0.7549277768695749, 0.7549408815355586, 0.754903263970238, 0.7549611728673318, 0.7549356438158927, 0.7548938441401858, 0.7549197538438143, 0.7548889549300211, 0.7548894712017249, 0.7548428770227289, 0.7547821187322207, 0.7547721421531163, 0.7548125749966281, 0.7547877880852005], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03614666666666666, 0.07663866666666666, 0.1167348, 0.15520798666666666, 0.19176718799999998, 0.2259904692, 0.25753808894666663, 0.28725094671866663, 0.31465918538013327, 0.3403532668421199, 0.36441127349124125, 0.38647681280878377, 0.40749579819457205, 0.42686621837511485, 0.44468626320427, 0.4614443035505097, 0.4768198731954587, 0.49084455254257947, 0.5044267639549882, 0.5170774208928227, 0.5281030121368738, 0.5384260442565199, 0.5487834398308679, 0.5578650958477811, 0.5663585862630031, 0.5740427276367028, 0.581531788206366, 0.5881652760523961, 0.5943620817804899, 0.6001925402691076, 0.6057332862421968, 0.6108666242846438, 0.6158199618561794, 0.6200379656705615, 0.623860835770172, 0.6279280855264883, 0.6316152769738395, 0.6349204159431222, 0.6383083743488099, 0.6414242035805957, 0.6441617832225361, 0.6469189382336159, 0.6495337110769209, 0.6518070066358955, 0.6541196393056393, 0.6563076753750754, 0.6584235745042345, 0.6603945503871443, 0.6621684286817632, 0.6639782524802536, 0.6657804272322283, 0.6675090511756722, 0.6690114793914382, 0.6704036647856277, 0.6717366316403983, 0.6729763018096918, 0.674172004962056, 0.675501471132517, 0.6768446573525986, 0.6779468582840054, 0.6791921724556048, 0.6802329552100443, 0.6812096596890399, 0.682248693720136, 0.683330491014789, 0.6843174419133102, 0.6852056977219791, 0.6859251279497812, 0.6867592818214697, 0.6875633536393227, 0.6882336849420572, 0.6891169831145181, 0.6898452848030663, 0.6903274229894264, 0.6910680140238171, 0.691787879288102, 0.6924490913592919, 0.6929908488900294, 0.6937717640010264, 0.694567920934257, 0.6952711288408313, 0.6955573492900815, 0.6960416143610734, 0.6966107862582993, 0.6971097076324694, 0.6977587368692224, 0.6982361965156335, 0.6986792435307367, 0.6989846525109964, 0.6994195205932301, 0.6998509018672404, 0.7002391450138497, 0.7006018971791315, 0.7010217074612183, 0.7013995367150965, 0.7016862497102535, 0.7020242914058947, 0.7023151955986385, 0.7026570093721081, 0.7028846417682306, 0.703129510924741, 0.7034832264989336, 0.7038149038490402, 0.7043534134641362, 0.7045580721177225, 0.7047822649059502, 0.7050907050820219, 0.705314967907153, 0.705476804449771, 0.7057291240047939, 0.7059162116043145, 0.7062445904438831, 0.7064867980661614, 0.7067314515928786, 0.7070049731002575, 0.7071044757902317, 0.7071940282112086, 0.7074212920567544, 0.707639162851079, 0.7077685798993043, 0.7079917219093739, 0.7082192163851032, 0.7083439614132596, 0.708482898605267, 0.7087146087447402, 0.7087898145369329, 0.7089908330832395, 0.7092784164415822, 0.7094839081307573, 0.7096021839843483, 0.7098286322525801, 0.7100724356939887, 0.7101451921245898, 0.7102506729121308, 0.7104522722875845, 0.7105137117254927, 0.7105956738862769, 0.7106827731643159, 0.7107878291812176, 0.7109223795964292, 0.7111368083034529, 0.711316460806441, 0.7114381480591302, 0.7115876665865505, 0.7116422332612288, 0.7116913432684393, 0.7118688756082621, 0.7120819880474359, 0.7122071225760257, 0.7122530769850899, 0.7123744359532476, 0.7125903256912562, 0.7126512931221306, 0.7128128304765842, 0.7128915474289258, 0.7129090593526999, 0.7129514867507633, 0.7130696714090202, 0.7132027042681182, 0.713189100507973, 0.7132968571238424, 0.7133671714114582, 0.7134704542703124, 0.7136167421766145, 0.713695067958953, 0.7136588944963911, 0.713693005046752, 0.7137637045420768, 0.7138673340878692, 0.7139206006790823, 0.7139018739445073, 0.7139116865500567, 0.7140405178950511, 0.7140631327722127, 0.7140568194949914, 0.7140378042121589, 0.714114023790943, 0.7141692880785154, 0.7142590259373305, 0.7143931233435974, 0.7144204776759043, 0.7144184299083138, 0.7145232535841491, 0.7144575948924008, 0.7145451687364941, 0.7145973185295114, 0.7147375866765603, 0.7147304946755709, 0.7147507785413472, 0.7147957006872125, 0.714822797285158, 0.7148205175566422, 0.714858465800978, 0.7149459525542134, 0.7150246906321254, 0.7151755549022462, 0.7151113327453549, 0.715106866137486, 0.715102846190404, 0.7150992282380302, 0.7150826387475605, 0.7151743748728044, 0.7152302707188574, 0.7152139103136382, 0.7151725192822744, 0.715175267354047, 0.7151510739519756, 0.7150359665567781, 0.7150257032344336, 0.7150164662443236, 0.7150348196198912, 0.7150780043245688, 0.7151035372254453, 0.7152598501695674, 0.715267198485944, 0.715273811970683, 0.715239764106948, 0.7152224543629199, 0.7152335422599613, 0.7151768547006319, 0.7152458358972353, 0.7152812523075118, 0.715286460410094, 0.715291147702418, 0.7152420329321761, 0.7152511629722919, 0.715219380008396, 0.715204108674223, 0.7150703644734673, 0.7150433280261206, 0.7150456618901752, 0.7149410957011577, 0.7149536527977086, 0.7149116208512711, 0.7149404587661441, 0.7149130795561964, 0.7148884382672435, 0.714719594440519, 0.7147676349964671, 0.7148775381634871, 0.7148297843471384, 0.7148534725790912, 0.7148881253211821, 0.7148926461223972, 0.7149367148434909, 0.7149897100258085, 0.7149707390232276, 0.7150069984542382, 0.7150262986088143, 0.7149903354145996, 0.7149179685398063, 0.7150661716858255, 0.7149728878505763, 0.7148622657321855, 0.7150827058256335, 0.7151611019097368, 0.7151516583854297, 0.71516982588022, 0.715212843292198, 0.7152382256296449, 0.7152744030666803, 0.7152536294266789, 0.7153015998173444, 0.7152381065022767, 0.7152209625187157, 0.7152721996001774, 0.7152649796401596, 0.7151918150094769, 0.7152059668418626, 0.715232036824343, 0.7152288331419088, 0.7152659498277179, 0.7152860215116127, 0.7151574193604514, 0.7152283440910729, 0.7150921763486324, 0.7150896253804359, 0.7150606628423922, 0.715034596558153, 0.715104470235671, 0.7151673565454373, 0.7152906208908936, 0.7152415588018042, 0.7151440695882905, 0.7152429959627947, 0.7152786963665152, 0.7152974933965304, 0.7153010773902106, 0.7152643029845229, 0.7152845393527373, 0.7152627520841301, 0.7154564768757171, 0.7155108291881455, 0.7156130796026643, 0.7155851049757312, 0.7156532611448247, 0.7156612683636756, 0.715615141527308, 0.7156136273745771, 0.7156122646371194, 0.7156510381734075, 0.7155926010227334, 0.71547334092046, 0.7154326734950807, 0.7154627394789059, 0.7154764655310153, 0.715502152311247, 0.7153919370801223, 0.7153594100387767, 0.7153168023682324, 0.7152784554647424, 0.7151639432516016, 0.7151942155931081, 0.715221460700464, 0.7150593146304176, 0.7151000498340425, 0.7151500448506383, 0.7151017070322412, 0.7150582029956838, 0.7149923826961154, 0.7148931444265039, 0.7148704966505202, 0.7148234469854681, 0.7149011022869213, 0.7148376587248958, 0.7149138928524061, 0.7150091702338323, 0.7149749198771157, 0.7149574278894041, 0.715075018433797, 0.7152208499237506, 0.7152587649313755, 0.7152662217715713, 0.7152595995944142, 0.7152803063016394, 0.7152856090048089, 0.7153303814376613, 0.7153440099605618, 0.7153296089645056, 0.7152633147347217, 0.7153103165945829, 0.7153259516017912], "moving_var_accuracy_train": [0.011890747880968857, 0.026001674998256053, 0.03835197249834518, 0.04842582852298416, 0.05604241105371045, 0.0617896392381303, 0.06519798908881778, 0.06735496897248087, 0.06799144397771535, 0.06769644576744503, 0.0665461448806343, 0.06469225064392697, 0.06253916482700042, 0.05994342852715714, 0.05705372699980137, 0.05418802428772543, 0.051119731180998086, 0.04790674574473691, 0.04491649512471828, 0.041972946221910695, 0.03893690723301115, 0.036058430454746764, 0.03342138986772836, 0.03087389896683014, 0.02844820721268802, 0.02615152326849015, 0.024058812078663817, 0.02209638425927513, 0.020252663337422268, 0.018563177287460892, 0.016995863400311857, 0.015546850556461595, 0.014227501956172879, 0.012989187972322533, 0.011834870026771131, 0.010817372362073625, 0.009874875653101448, 0.009023618648495704, 0.008244412344328052, 0.007526464376120402, 0.006860997759254614, 0.006282344995758957, 0.00573067780941213, 0.005230520740193688, 0.0047808664762958005, 0.004357330181846431, 0.003982403272963351, 0.003640701629596858, 0.0033252403168908874, 0.00305071944793833, 0.0027959777686437305, 0.0025577809310974235, 0.0023411504205876673, 0.0021380334726064276, 0.0019515794419967443, 0.0017842091299641516, 0.0016358008144864373, 0.0015000613437307303, 0.0013775431665171837, 0.0012623213548692378, 0.0011576770914156652, 0.0010608410995534233, 0.0009718533698174181, 0.0008929170553730099, 0.0008207162193437118, 0.0007517625825002727, 0.0006928769029581451, 0.0006355336492790655, 0.0005854353317755527, 0.0005367005288950892, 0.0004949605536380736, 0.0004578408698801697, 0.00042133615443146986, 0.00038731061205076205, 0.00035503899969528186, 0.0003269225060740365, 0.0003003529890935356, 0.000278631944225622, 0.00025710632082489725, 0.00023705366042290965, 0.0002178710050777913, 0.0001992018292572293, 0.0001843563827737132, 0.00017074692770606198, 0.00015686411583523902, 0.00014496753496407455, 0.0001332744866433509, 0.00012327631698358314, 0.00011281702970646613, 0.00010359424306720642, 9.580119532352523e-05, 8.789436550044746e-05, 8.117707600485084e-05, 7.500363444018913e-05, 6.904289240592892e-05, 6.384769285396565e-05, 5.87494159435539e-05, 5.45911628247368e-05, 5.0284061887717487e-05, 4.634482941757212e-05, 4.270184852912672e-05, 3.939377678845783e-05, 3.6390440199044515e-05, 3.392321900103322e-05, 3.146636919874965e-05, 2.9401103540089373e-05, 2.7138256092206093e-05, 2.50375457943876e-05, 2.3179465578189946e-05, 2.1572479603157125e-05, 2.0126845681665636e-05, 1.8348340505335375e-05, 1.7146372474844904e-05, 1.5786922489798607e-05, 1.4412238215251529e-05, 1.358038638786456e-05, 1.2393039661302764e-05, 1.1395636279981755e-05, 1.0556960953328675e-05, 9.844009865575842e-06, 9.087603754431096e-06, 8.726928209422685e-06, 8.11535704914427e-06, 7.400956595774432e-06, 6.9172827666385775e-06, 6.487917250631731e-06, 5.975454490144037e-06, 5.545969544493482e-06, 5.178416781491063e-06, 4.796043990356153e-06, 4.533011184416838e-06, 4.243506427070004e-06, 3.918276297073902e-06, 3.6371795207098262e-06, 3.3903155753174563e-06, 3.3435285010202367e-06, 3.073486377465361e-06, 2.9597383932972404e-06, 2.6800885448411778e-06, 2.5235103862482406e-06, 2.349142512239567e-06, 2.213364202116522e-06, 2.1027733114326838e-06, 1.962303929836975e-06, 1.8568673746457817e-06, 1.8242087999839703e-06, 1.6777802274967806e-06, 1.5682438137345797e-06, 1.4372532749935761e-06, 1.336869191163827e-06, 1.2185180300121505e-06, 1.215274171377908e-06, 1.1987701828873529e-06, 1.1598943330416831e-06, 1.1024827869460584e-06, 1.0674730288047543e-06, 1.044373766692525e-06, 9.509621505583308e-07, 9.218410432666622e-07, 8.511088467434779e-07, 8.444279375060732e-07, 7.83462934301836e-07, 7.204392506536899e-07, 6.896736924793783e-07, 7.65487153980515e-07, 7.449030151789261e-07, 7.355726488429918e-07, 6.971285432937601e-07, 6.416326231543145e-07, 6.323987191062747e-07, 5.801945103989321e-07, 5.355666774394799e-07, 4.959972325745788e-07, 4.5927968092533836e-07, 4.5662904338819097e-07, 4.1548585569780186e-07, 4.2360335734542476e-07, 3.9813906216815735e-07, 3.8151447955031453e-07, 3.5520418759295694e-07, 3.3223964707786954e-07, 3.2603552177756685e-07, 2.9520076590096387e-07, 3.003089299396798e-07, 2.810833424817943e-07, 2.7548229962474017e-07, 3.281686920467289e-07, 3.1170323140858623e-07, 3.039878094534268e-07, 2.871106970801317e-07, 2.742330451089297e-07, 2.732678805662438e-07, 2.459444842555935e-07, 2.2946934394764905e-07, 2.200691815010017e-07, 2.3668089851974175e-07, 2.2285693349448713e-07, 2.07334161560253e-07, 1.9705551732176363e-07, 1.798171519721753e-07, 1.75127667573265e-07, 1.8801316463581235e-07, 1.9383444186632272e-07, 1.7764532840529867e-07, 2.1156297882978852e-07, 1.9445569356117516e-07, 1.8091588994424972e-07, 1.632144549911225e-07, 1.6048871291983097e-07, 1.7049339831589533e-07, 1.601255867605439e-07, 1.5923669501692262e-07, 1.64621610733867e-07, 1.510463717387044e-07, 1.5181877677657656e-07, 1.4061432870005755e-07, 1.4640200859545113e-07, 1.3254438944874575e-07, 1.2283361502884015e-07, 1.115999712331342e-07, 1.063263836853677e-07, 9.572422934776413e-08, 9.419341086254516e-08, 8.510226051165403e-08, 8.734480532911554e-08, 7.868463142096892e-08, 7.103570998007235e-08, 6.70333131400451e-08, 6.116767314774202e-08, 6.14243326893059e-08, 6.00880075616179e-08, 7.237273468490415e-08, 6.813218897875942e-08, 6.152235399131148e-08, 6.05355213663054e-08, 5.6374845013119283e-08, 5.1331400651608834e-08, 5.581487834524234e-08, 5.03450226199162e-08, 4.531652396163895e-08, 5.011997261940516e-08, 4.709745228446631e-08, 4.331460737825061e-08, 5.358418590404764e-08, 4.8514311154770426e-08, 5.187023123990465e-08, 6.383026048829348e-08, 5.771180315795398e-08, 6.481437106548087e-08, 6.736885531129328e-08, 6.063268521655023e-08, 5.966016592568125e-08, 5.37541180894293e-08, 5.43939170681385e-08, 5.856583855374992e-08, 6.79691950954339e-08, 7.515222631818902e-08, 1.0112549391871265e-07, 9.741180283620026e-08, 8.958540993497987e-08, 1.038293577151718e-07, 9.373853340356071e-08, 1.3921697643262376e-07, 1.3041723411055606e-07, 1.2354226750752716e-07, 1.2919908780361276e-07, 1.1747007768565146e-07, 1.2080859991129343e-07, 1.0980974135164344e-07, 1.0140746516652363e-07, 9.573955462338669e-08, 9.063685981727267e-08, 8.189100414707756e-08, 7.395934628471107e-08, 6.65635158998117e-08, 6.011476134441327e-08, 5.4836885266653486e-08, 5.479791169125538e-08, 5.036879108398098e-08, 4.5505632210530614e-08, 6.65862982262842e-08, 7.053069896624278e-08, 6.465995091727439e-08, 5.963835409820076e-08, 5.4998279160131036e-08, 7.07229620080886e-08, 6.377426926962574e-08, 6.949553591633836e-08, 8.242848953486772e-08, 9.834976201975804e-08, 1.3584295223912848e-07, 1.2240910998785892e-07, 1.1292340719253843e-07, 1.06924928444945e-07, 1.0561621384344608e-07, 9.51900964018488e-08, 1.1811130432988001e-07, 1.1036829703645968e-07, 1.0634935176637638e-07, 1.0102004739440691e-07, 9.316341797630699e-08, 9.66692612389627e-08, 1.0417109057393768e-07, 9.537642600551285e-08, 8.91367691257522e-08, 9.951712248999158e-08, 9.067083652483807e-08, 8.297141971306043e-08, 7.536202618597631e-08, 7.423751703418208e-08, 7.017174747076251e-08, 6.328398889723226e-08, 6.90031745492416e-08, 6.335122898784212e-08, 6.480763971133081e-08, 6.708041387064688e-08, 6.361819952299066e-08, 5.795186800081467e-08, 5.21632267779989e-08, 4.703454015077167e-08, 5.325466051368336e-08, 5.865857940173436e-08, 5.295294346290858e-08, 4.799808549921475e-08, 4.5209003037160377e-08, 4.539300670521135e-08, 4.222940804252797e-08, 4.8816154669773404e-08, 6.054119125797772e-08, 5.603266256707596e-08, 6.31651272961922e-08, 8.702957783021199e-08, 8.419221225359229e-08, 9.149790703106649e-08, 8.838993100700061e-08, 8.808809572386625e-08, 7.928168497972868e-08, 9.089267412857336e-08, 1.1502753550501181e-07, 1.0442057113015168e-07, 1.0869184752726336e-07, 1.0335218157757713e-07], "duration": 116143.053853, "accuracy_train": [0.3634823529411765, 0.4486588235294118, 0.48515294117647056, 0.5114588235294117, 0.5297176470588235, 0.55, 0.5567529411764706, 0.5735058823529412, 0.5802588235294117, 0.5915058823529412, 0.5994352941176471, 0.6055058823529412, 0.6166352941176471, 0.6211529411764706, 0.6254352941176471, 0.6359058823529412, 0.6376470588235295, 0.6374588235294117, 0.648164705882353, 0.6520235294117647, 0.6475764705882353, 0.6515529411764706, 0.6597176470588235, 0.6603058823529412, 0.6614823529411765, 0.6623529411764706, 0.6683058823529412, 0.6699294117647059, 0.6705176470588236, 0.6742117647058824, 0.6759058823529411, 0.6776705882352941, 0.6813176470588236, 0.680564705882353, 0.6799058823529411, 0.6867764705882353, 0.6874588235294118, 0.6909647058823529, 0.6929411764705883, 0.6940470588235295, 0.6942117647058823, 0.7007529411764706, 0.6988235294117647, 0.7010352941176471, 0.7039764705882353, 0.7028941176470588, 0.7067294117647058, 0.7084, 0.7090823529411765, 0.7135529411764706, 0.7143529411764706, 0.7145176470588235, 0.7160705882352941, 0.7158588235294118, 0.7165882352941176, 0.7184705882352941, 0.7209176470588236, 0.7220705882352941, 0.7237176470588236, 0.7238117647058824, 0.7250588235294118, 0.7256235294117647, 0.7263529411764705, 0.7281882352941177, 0.7291529411764706, 0.7288235294117648, 0.7314117647058823, 0.7308235294117648, 0.7326823529411765, 0.7321176470588235, 0.7342352941176471, 0.7356, 0.7352, 0.7355529411764706, 0.7354823529411765, 0.7369176470588236, 0.7370117647058824, 0.7392, 0.7389411764705882, 0.7393176470588235, 0.7392705882352941, 0.7387764705882353, 0.7409882352941176, 0.7415529411764706, 0.7409176470588236, 0.7420470588235294, 0.7417882352941176, 0.7428470588235294, 0.7419294117647058, 0.7426117647058823, 0.7436470588235294, 0.7431529411764706, 0.7440705882352942, 0.7444, 0.7443529411764706, 0.7449882352941176, 0.7448470588235294, 0.7458117647058824, 0.7454588235294117, 0.7457176470588235, 0.7459058823529412, 0.7461882352941176, 0.7464705882352941, 0.7471764705882353, 0.7471529411764706, 0.7477176470588235, 0.7473411764705883, 0.7474823529411765, 0.7478117647058824, 0.7482117647058824, 0.7484941176470589, 0.7475764705882353, 0.7487764705882353, 0.7483764705882353, 0.7480941176470588, 0.7493411764705883, 0.7483764705882353, 0.7487764705882353, 0.7491294117647059, 0.7494352941176471, 0.7492705882352941, 0.7503058823529412, 0.7497882352941176, 0.7492941176470588, 0.7500470588235294, 0.7502352941176471, 0.7499294117647058, 0.7501882352941176, 0.7504, 0.7503294117647059, 0.7507764705882353, 0.7507294117647059, 0.7505647058823529, 0.7507294117647059, 0.7508705882352941, 0.7516470588235294, 0.7508705882352941, 0.7515764705882353, 0.7506823529411765, 0.7514117647058823, 0.7513411764705883, 0.7515529411764705, 0.7517176470588235, 0.7516, 0.7518117647058824, 0.7522117647058824, 0.7516705882352941, 0.7519058823529412, 0.7517176470588235, 0.7519294117647058, 0.7517176470588235, 0.7524941176470589, 0.7525411764705883, 0.7525176470588235, 0.7524705882352941, 0.7526588235294117, 0.7528, 0.7522823529411765, 0.7528235294117647, 0.7525411764705883, 0.753035294117647, 0.7527058823529412, 0.7526588235294117, 0.752964705882353, 0.7536235294117647, 0.7532705882352941, 0.7534117647058823, 0.7532705882352941, 0.7531058823529412, 0.7535294117647059, 0.7531764705882353, 0.7532470588235294, 0.7532941176470588, 0.7533176470588235, 0.7536705882352941, 0.7532705882352941, 0.7538117647058824, 0.7535764705882353, 0.7536941176470588, 0.7536, 0.7536470588235294, 0.7538588235294118, 0.7535058823529411, 0.754, 0.7537882352941176, 0.7539764705882352, 0.7544705882352941, 0.7540470588235294, 0.7531529411764706, 0.754, 0.7540705882352942, 0.754235294117647, 0.7537411764705882, 0.7540470588235294, 0.754164705882353, 0.7544705882352941, 0.7542117647058824, 0.7541882352941176, 0.7542823529411765, 0.7541411764705882, 0.7543764705882353, 0.7546117647058823, 0.7546117647058823, 0.7543294117647059, 0.7549176470588236, 0.7540235294117648, 0.7544705882352941, 0.7543058823529412, 0.7546352941176471, 0.7548235294117647, 0.7546117647058823, 0.7547764705882353, 0.7548941176470588, 0.7546352941176471, 0.7548941176470588, 0.7543058823529412, 0.754964705882353, 0.7546352941176471, 0.7543529411764706, 0.7544235294117647, 0.7547764705882353, 0.7545647058823529, 0.7548470588235294, 0.7545176470588235, 0.7549176470588236, 0.7546352941176471, 0.7546588235294117, 0.7548, 0.7547294117647059, 0.7543764705882353, 0.7548470588235294, 0.7541882352941176, 0.7547764705882353, 0.7545647058823529, 0.7548470588235294, 0.7547764705882353, 0.7545647058823529, 0.754964705882353, 0.7546352941176471, 0.7546588235294117, 0.7549882352941176, 0.7548470588235294, 0.7546117647058823, 0.7551058823529412, 0.7548, 0.7544470588235294, 0.7542823529411765, 0.7547294117647059, 0.7550588235294118, 0.755035294117647, 0.7547529411764706, 0.7549882352941176, 0.7548, 0.755035294117647, 0.7551294117647059, 0.7544235294117647, 0.7544, 0.7553647058823529, 0.7550823529411764, 0.7549882352941176, 0.7553647058823529, 0.754964705882353, 0.7556941176470588, 0.7547529411764706, 0.7547058823529412, 0.7544941176470589, 0.7550117647058824, 0.7553176470588235, 0.7550588235294118, 0.7551294117647059, 0.7552, 0.7547764705882353, 0.7549176470588236, 0.7549176470588236, 0.754964705882353, 0.7549176470588236, 0.7548705882352941, 0.7547058823529412, 0.755035294117647, 0.7548941176470588, 0.7544, 0.7552235294117647, 0.7548, 0.7547764705882353, 0.7550117647058824, 0.7553882352941177, 0.7549882352941176, 0.7545882352941177, 0.7553882352941177, 0.7544470588235294, 0.7541882352941176, 0.7548, 0.7550117647058824, 0.7546117647058823, 0.7551529411764706, 0.7548235294117647, 0.7554588235294117, 0.7547058823529412, 0.7551764705882353, 0.7546823529411765, 0.7550588235294118, 0.7552941176470588, 0.7545176470588235, 0.7547764705882353, 0.7547058823529412, 0.7553411764705882, 0.755035294117647, 0.7550588235294118, 0.755035294117647, 0.7552235294117647, 0.7551764705882353, 0.754964705882353, 0.7553647058823529, 0.7549176470588236, 0.7547294117647059, 0.7546823529411765, 0.7551529411764706, 0.7548941176470588, 0.754964705882353, 0.7549411764705882, 0.7553176470588235, 0.7546588235294117, 0.7550117647058824, 0.755035294117647, 0.7551294117647059, 0.7552235294117647, 0.7548941176470588, 0.7546588235294117, 0.7545411764705883, 0.7550588235294118, 0.7545647058823529, 0.7554823529411765, 0.7547058823529412, 0.7545176470588235, 0.7551529411764706, 0.7546117647058823, 0.7548941176470588, 0.7544235294117647, 0.754235294117647, 0.7546823529411765, 0.7551764705882353, 0.7545647058823529], "end": "2016-02-05 09:05:17.571000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0], "moving_var_accuracy_valid": [0.011759233599999998, 0.025339728815999996, 0.037275055108959995, 0.04686922442865759, 0.054211478804972645, 0.05933142770932384, 0.06235555574351391, 0.06406568542197442, 0.06442002079849223, 0.06391969111821987, 0.06273681116176037, 0.060845122273950475, 0.058736789766387264, 0.05624002939148555, 0.0534740124317549, 0.050654098434795174, 0.04771636186847576, 0.0447149503587342, 0.04190374352452307, 0.03915372126069979, 0.036332422095157864, 0.033658264814931255, 0.031257919121189845, 0.028874415493156683, 0.02663622835874221, 0.02450401978072702, 0.022558392056599055, 0.020698581299970008, 0.018974326781058624, 0.017382842318640207, 0.015920856880220928, 0.014565931627321137, 0.0133301584424673, 0.012157266603823845, 0.011073068965627925, 0.010114644754287415, 0.00922553870578345, 0.008401300327661544, 0.0076644746543234245, 0.006985402715105933, 0.0063543115242590395, 0.005787297505629233, 0.005270101088265081, 0.0047896018337246545, 0.004358776079138686, 0.003965985987795196, 0.003609680651138664, 0.0032836752994039094, 0.0029836275673005993, 0.0027147439702047776, 0.002472500077714194, 0.0022521433365834003, 0.0020472446178168317, 0.0018599637775813, 0.0016899586055464221, 0.0015347937841495055, 0.0013941817599917169, 0.001270670906678149, 0.0011598411590066887, 0.0010547906651447662, 0.0009632688651041679, 0.0008766910372711994, 0.0007976074982976894, 0.0007275630739279011, 0.0006653393350155793, 0.0006075720501988459, 0.000553915830613669, 0.0005031824662263803, 0.0004591265337386193, 0.0004190326637591466, 0.00038117349388206226, 0.0003500780854471117, 0.0003198440870482799, 0.00028995179342017075, 0.00026589288980013255, 0.0002439674548086358, 0.00022350552195555612, 0.0002037964807589974, 0.0001889052883783497, 0.00017571955230149652, 0.00016259810931016434, 0.00014707559768926883, 0.00013447865185118663, 0.00012394639650339454, 0.00011379205969148884, 0.00010620400427378234, 9.763531327196316e-05, 8.963839786309449e-05, 8.151402988379424e-05, 7.506461913592533e-05, 6.923296545443373e-05, 6.366626357699212e-05, 5.848393942004192e-05, 5.422171153455033e-05, 5.00843348868705e-05, 4.5815740472510654e-05, 4.22626161171881e-05, 3.8797981749672905e-05, 3.5969713476306594e-05, 3.2839090698556265e-05, 3.0094829762991102e-05, 2.8211379153529392e-05, 2.638033001934032e-05, 2.635223046736373e-05, 2.4093973901017507e-05, 2.213693816755576e-05, 2.077946243073614e-05, 1.915416052028478e-05, 1.747446406699533e-05, 1.630000408091836e-05, 1.498501960187598e-05, 1.4457011602175884e-05, 1.3539291232565916e-05, 1.2724060242525734e-05, 1.212498035326212e-05, 1.1001589385744913e-05, 9.97360717209571e-06, 9.441086154316567e-06, 8.924186686061442e-06, 8.182506968797769e-06, 7.812387481838967e-06, 7.496932362041134e-06, 6.887291024284566e-06, 6.372293811762142e-06, 6.218270729198556e-06, 5.647346856892609e-06, 5.446288274836728e-06, 5.6459971393141295e-06, 5.461438934263102e-06, 5.041197638720766e-06, 4.998587238515481e-06, 5.033689577048311e-06, 4.5779621030878326e-06, 4.220301661641521e-06, 4.164052269126852e-06, 3.781620282988463e-06, 3.463918416893147e-06, 3.185803133318032e-06, 2.9665537201715597e-06, 2.8328326762568405e-06, 2.9633664421940175e-06, 2.957504994443419e-06, 2.7950245822025713e-06, 2.716724234359763e-06, 2.471849508792794e-06, 2.2463706931874057e-06, 2.3053932090150897e-06, 2.4836060936889844e-06, 2.37617333652848e-06, 2.1575622722875014e-06, 2.0743580374294247e-06, 2.286397644483176e-06, 2.091211128681649e-06, 2.1169388677683365e-06, 1.9610122082650245e-06, 1.7676709947069456e-06, 1.6071046521940834e-06, 1.572102708000601e-06, 1.5741721115985968e-06, 1.4184204610495189e-06, 1.3810818093171374e-06, 1.2874705197716223e-06, 1.2547296081922933e-06, 1.3218580111453007e-06, 1.2448865636412918e-06, 1.1321745818206595e-06, 1.0294288904518957e-06, 9.714717691593393e-07, 9.709763370934982e-07, 8.994146710393069e-07, 8.126294192259216e-07, 7.32233062352318e-07, 8.083873951945051e-07, 7.321515496963475e-07, 6.592951119501665e-07, 5.966198295859415e-07, 5.892426643375896e-07, 5.57805671231758e-07, 5.745010538510896e-07, 6.78889977773705e-07, 6.177353154599549e-07, 5.55999524082899e-07, 5.99291598815197e-07, 5.781620131524953e-07, 5.893684153606748e-07, 5.549079820302879e-07, 6.764935615159377e-07, 6.092968736666418e-07, 5.520701031974337e-07, 5.150250855799578e-07, 4.701306076038978e-07, 4.2316432130245984e-07, 3.938085124057209e-07, 4.2331304909041165e-07, 4.3677890840084493e-07, 5.979412695524934e-07, 5.752675115191582e-07, 5.179203156399267e-07, 4.6627372384680775e-07, 4.197641576765343e-07, 3.8026464265527564e-07, 4.1797782846270625e-07, 4.0429915607014825e-07, 3.662782061935231e-07, 3.450693428704216e-07, 3.106303756695832e-07, 2.8483522443670773e-07, 3.7559911385556523e-07, 3.3898722453992906e-07, 3.058563999625712e-07, 2.7830237751885426e-07, 2.6725640822974945e-07, 2.463981286512768e-07, 4.4166194428733264e-07, 3.9798172964073457e-07, 3.5857720030019047e-07, 3.331527934944045e-07, 3.0253415928984096e-07, 2.7338721650805264e-07, 2.749698093018295e-07, 2.9029847773527725e-07, 2.7255752901358846e-07, 2.455458951047856e-07, 2.2118904197827718e-07, 2.207804836835895e-07, 1.9945265400786313e-07, 1.8859879975312422e-07, 1.7183784260460507e-07, 3.156416594660075e-07, 2.906562188855996e-07, 2.616396192898681e-07, 3.3388244833171643e-07, 3.0191332956264035e-07, 2.876221572983219e-07, 2.663445695764274e-07, 2.464567028550497e-07, 2.2727577066092138e-07, 4.6112233400112103e-07, 4.3578115574322505e-07, 5.009113952580422e-07, 4.713440985150317e-07, 4.292598796609869e-07, 3.9714120450464e-07, 3.576110228468159e-07, 3.3932839017157493e-07, 3.306719552942814e-07, 3.0084385021515577e-07, 2.825921822285364e-07, 2.576854277056626e-07, 2.43557046978255e-07, 2.6633402338655075e-07, 4.3737817345827824e-07, 4.719572213816933e-07, 5.34896776939285e-07, 9.187516124401033e-07, 8.821899652207007e-07, 7.94773590060665e-07, 7.182667518572211e-07, 6.630945562710619e-07, 6.025834681323552e-07, 5.541043838732482e-07, 5.025778425560813e-07, 4.730304837258258e-07, 4.620100448779087e-07, 4.184542859411787e-07, 4.0023600399753826e-07, 3.606815540017044e-07, 3.727909672478515e-07, 3.373143397619091e-07, 3.096997016644794e-07, 2.788221037282906e-07, 2.6333872864454243e-07, 2.4063070822947455e-07, 3.6541425695628614e-07, 3.741456879842789e-07, 5.036060059182642e-07, 4.533039722750975e-07, 4.155230325369222e-07, 3.80085789849591e-07, 3.8601818815367613e-07, 3.830085609424355e-07, 4.814545945950666e-07, 4.5497293240786706e-07, 4.950129599308426e-07, 5.335895120908142e-07, 4.917012303140135e-07, 4.457110623191257e-07, 4.012555611835172e-07, 3.733012172883402e-07, 3.396566909460772e-07, 3.099631875116758e-07, 6.167305226392797e-07, 5.81645035172066e-07, 6.175768570782337e-07, 5.628623891388225e-07, 5.483835206945172e-07, 4.941222086085953e-07, 4.6385915304725514e-07, 4.174938716689592e-07, 3.7576119798247105e-07, 3.517155622307564e-07, 3.4727811121783025e-07, 4.40557048044256e-07, 4.11385898622686e-07, 3.7838297921084835e-07, 3.422403218483559e-07, 3.1395458577161497e-07, 3.918857017412858e-07, 3.622192073354208e-07, 3.4233600890481235e-07, 3.213367730797077e-07, 4.0722051839761965e-07, 3.747461985004375e-07, 3.439522415238826e-07, 5.461791496549198e-07, 5.064954460186928e-07, 4.783414165765071e-07, 4.51536177105431e-07, 4.2341597016601884e-07, 4.2006517966685386e-07, 4.6669276909961186e-07, 4.246397880027296e-07, 4.0209884803601207e-07, 4.1616207582648853e-07, 4.1077163830613907e-07, 4.219992542510082e-07, 4.614993435285479e-07, 4.2590719159259675e-07, 3.8607019914025203e-07, 4.7191100440184374e-07, 6.161213151205516e-07, 5.674471138372925e-07, 5.112028426449127e-07, 4.6047723745312603e-07, 4.1828842322482384e-07, 3.767126488504657e-07, 3.5708252065716337e-07, 3.230458983195029e-07, 2.926078066742447e-07, 3.0290135013057624e-07, 2.92493788591193e-07, 2.654444907857292e-07], "accuracy_test": 0.7166, "start": "2016-02-04 00:49:34.517000", "learning_rate_per_epoch": [0.00013095722533762455, 0.00012757199874613434, 0.0001242742728209123, 0.00012106179201509804, 0.00011793235171353444, 0.00011488381278468296, 0.00011191407247679308, 0.00010902110079769045, 0.0001062029114109464, 0.00010345757618779317, 0.00010078320337925106, 9.817796671995893e-05, 9.564007632434368e-05, 9.316778596257791e-05, 9.075940761249512e-05, 8.841328235575929e-05, 8.61278094816953e-05, 8.390141010750085e-05, 8.17325635580346e-05, 7.961978553794324e-05, 7.756162085570395e-05, 7.555665797553957e-05, 7.360352174146101e-05, 7.170087337726727e-05, 6.984741048654541e-05, 6.804185977671295e-05, 6.628298433497548e-05, 6.456957635236904e-05, 6.290045712376013e-05, 6.127448432380334e-05, 5.9690544730983675e-05, 5.814755058963783e-05, 5.6644439609954134e-05, 5.518018588190898e-05, 5.3753781685372815e-05, 5.236425204202533e-05, 5.101064016344026e-05, 4.9692018365021795e-05, 4.840748442802578e-05, 4.7156154323602095e-05, 4.593717312673107e-05, 4.474970046430826e-05, 4.3592925067059696e-05, 4.2466050217626616e-05, 4.136830466450192e-05, 4.029893898405135e-05, 3.9257214666577056e-05, 3.824241866823286e-05, 3.72538561350666e-05, 3.629084676504135e-05, 3.535273208399303e-05, 3.443886816967279e-05, 3.354862565174699e-05, 3.268139698775485e-05, 3.1836585549172014e-05, 3.101361289736815e-05, 3.021191332663875e-05, 2.943093750218395e-05, 2.8670150641119108e-05, 2.7929028874495998e-05, 2.7207066523260437e-05, 2.6503767003305256e-05, 2.5818646463449113e-05, 2.5151237423415296e-05, 2.4501079678884707e-05, 2.3867729396442883e-05, 2.325075001863297e-05, 2.264971953991335e-05, 2.2064226868678816e-05, 2.1493868189281784e-05, 2.0938254237989895e-05, 2.0397003027028404e-05, 1.9869741663569584e-05, 1.9356109987711534e-05, 1.8855756934499368e-05, 1.8368336895946413e-05, 1.789351699699182e-05, 1.7430971638532355e-05, 1.6980382497422397e-05, 1.6541440345463343e-05, 1.6113845049403608e-05, 1.569730375194922e-05, 1.5291529052774422e-05, 1.4896244465489872e-05, 1.451117805117974e-05, 1.4136065146885812e-05, 1.3770649275102187e-05, 1.3414679415291175e-05, 1.3067910913378e-05, 1.27301063912455e-05, 1.240103392774472e-05, 1.2080467968189623e-05, 1.1768189324357081e-05, 1.1463982446002774e-05, 1.1167639058839995e-05, 1.087895634555025e-05, 1.0597736036288552e-05, 1.0323785318178125e-05, 1.0056915925815701e-05, 9.796945960260928e-06, 9.543695341562852e-06, 9.296991265728138e-06, 9.056664566742256e-06, 8.822550626064185e-06, 8.594488463131711e-06, 8.372321644856129e-06, 8.155898285622243e-06, 7.945069228298962e-06, 7.739689863228705e-06, 7.539619673480047e-06, 7.344721325353021e-06, 7.154861123126466e-06, 6.9699085543106776e-06, 6.78973719914211e-06, 6.61422291159397e-06, 6.4432456383656245e-06, 6.2766885093878955e-06, 6.114436473581009e-06, 5.9563790273386985e-06, 5.802407031296752e-06, 5.6524154388171155e-06, 5.506301022251137e-06, 5.363963737181621e-06, 5.225305812928127e-06, 5.090232207294321e-06, 4.9586501518206205e-06, 4.830469606531551e-06, 4.7056023504410405e-06, 4.583962891047122e-06, 4.465468009584583e-06, 4.350035851530265e-06, 4.237587745592464e-06, 4.128046384721529e-06, 4.021336735604564e-06, 3.917385583918076e-06, 3.816121534327976e-06, 3.7174750104895793e-06, 3.6213787097949535e-06, 3.527766466504545e-06, 3.4365739338682033e-06, 3.347738811498857e-06, 3.2612001632514875e-06, 3.1768984172231285e-06, 3.0947758205002174e-06, 3.0147762117849197e-06, 2.9368445666477783e-06, 2.860927452275064e-06, 2.7869728000951e-06, 2.7149299057782628e-06, 2.6447492018633056e-06, 2.57638271250471e-06, 2.5097833713516593e-06, 2.4449057036690647e-06, 2.3817051442165393e-06, 2.3201382646220736e-06, 2.2601630007557105e-06, 2.2017379706085194e-06, 2.144823156413622e-06, 2.089379677272518e-06, 2.035369334407733e-06, 1.9827552932838444e-06, 1.931501174112782e-06, 1.8815720750353648e-06, 1.8329335489397636e-06, 1.7855523992693634e-06, 1.7393959979017382e-06, 1.6944327398960013e-06, 1.6506318161191302e-06, 1.6079630995591288e-06, 1.5663973726987024e-06, 1.525906100141583e-06, 1.4864615422993666e-06, 1.4480366417046753e-06, 1.4106050230111578e-06, 1.374140992993489e-06, 1.33861954054737e-06, 1.3040163366895285e-06, 1.2703076208708808e-06, 1.2374703146633692e-06, 1.2054817943862872e-06, 1.1743202321667923e-06, 1.143964141192555e-06, 1.1143927167722723e-06, 1.0855857226488297e-06, 1.0575233773124637e-06, 1.0301864676875994e-06, 1.0035562354460126e-06, 9.776143770068302e-07, 9.523431572233676e-07, 9.277251820094534e-07, 9.03743568869686e-07, 8.803818900560145e-07, 8.576241157243203e-07, 8.354546139344166e-07, 8.138582074934675e-07, 7.928200602691504e-07, 7.723257340330747e-07, 7.523611884607817e-07, 7.32912724288326e-07, 7.139669833122753e-07, 6.955110052331293e-07, 6.77532113968482e-07, 6.600179744964407e-07, 6.429565928556258e-07, 6.26336202458333e-07, 6.10145491464209e-07, 5.943732617197384e-07, 5.790087698187563e-07, 5.640414428853546e-07, 5.494609922607196e-07, 5.352574703465507e-07, 5.214211000748037e-07, 5.079423885945289e-07, 4.948121272718708e-07, 4.820212780032307e-07, 4.695610584803944e-07, 4.574229421905329e-07, 4.455986015727831e-07, 4.340799080182478e-07, 4.228589887134149e-07, 4.119281129533192e-07, 4.0127980582838063e-07, 3.909067629592755e-07, 3.808018504969368e-07, 3.70958161965973e-07, 3.6136893299953954e-07, 3.5202756976104865e-07, 3.429276773658785e-07, 3.3406303145966376e-07, 3.2542752137487696e-07, 3.1701523539595655e-07, 3.088204323375976e-07, 3.0083745627962344e-07, 2.93060821832114e-07, 2.8548521413540584e-07, 2.7810543201667315e-07, 2.7091641641163733e-07, 2.639132503645669e-07, 2.5709110218485876e-07, 2.5044531071216625e-07, 2.4397132847298053e-07, 2.3766469325892103e-07, 2.3152108497015433e-07, 2.2553628298283002e-07, 2.197061945707901e-07, 2.140268122730049e-07, 2.0849424231528246e-07, 2.031046903994138e-07, 1.9785444749231829e-07, 1.9273993245860765e-07, 1.8775762100631255e-07, 1.8290410253030132e-07, 1.781760516905706e-07, 1.7357021420139063e-07, 1.6908343525301461e-07, 1.6471264530082408e-07, 1.604548316436194e-07, 1.5630708105618396e-07, 1.5226655136757472e-07, 1.4833047146112222e-07, 1.4449614127443056e-07, 1.4076093179937743e-07, 1.371222708712594e-07, 1.3357767159050127e-07, 1.3012470390094677e-07, 1.2676099458985846e-07, 1.2348422728791775e-07, 1.2029217089093436e-07, 1.1718262982185479e-07, 1.141534653470444e-07, 1.1120260978714214e-07, 1.0832803098992372e-07, 1.0552776075201109e-07, 1.027998806080177e-07, 1.0014251472512115e-07, 9.755383700849052e-08, 9.503207820671378e-08, 9.257550459551567e-08, 9.018243218861244e-08, 8.785122673771184e-08, 8.558028241623106e-08, 8.336803603015142e-08, 8.12129812288731e-08, 7.911363297807839e-08, 7.706854887601366e-08, 7.507633625891685e-08, 7.313561667388058e-08, 7.124506851141632e-08, 6.940339147831764e-08, 6.76093208085149e-08, 6.58616272630752e-08, 6.415911002477515e-08, 6.250060380352807e-08, 6.088497173095675e-08, 5.9311101807679734e-08, 5.777791400873866e-08, 5.628436028359829e-08, 5.482941389800544e-08, 5.3412076539416375e-08, 5.203137831699678e-08, 5.068637065619441e-08, 4.937613340416647e-08, 4.8099764171638526e-08, 4.6856388991045606e-08, 4.564515521110479e-08, 4.446523149681525e-08, 4.331580782945821e-08, 4.2196099059310654e-08, 4.110533424750429e-08, 4.004276377145288e-08, 3.900766287756596e-08, 3.799931747039409e-08, 3.7017038323483575e-08, 3.606015042123545e-08, 3.512800006433281e-08, 3.4219944211599795e-08, 3.3335361138142616e-08, 3.24736433299222e-08, 3.163420103646786e-08, 3.081645871816363e-08, 3.001985504624827e-08, 2.924384467917207e-08, 2.8487892933526382e-08, 2.7751482889470935e-08, 2.703411006166334e-08, 2.6335280622902246e-08, 2.5654516733197852e-08, 2.4991349434344556e-08, 2.4345325755348313e-08, 2.371600160699927e-08, 2.3102945334585456e-08, 2.250573594153593e-08, 2.1923964865777634e-08, 2.13572324270217e-08, 2.08051496031203e-08, 2.026733803006664e-08, 1.9743428225638127e-08, 1.923306314211004e-08, 1.873588928447134e-08, 1.8251567368565702e-08, 1.7779765215664156e-08, 1.7320159528821932e-08], "accuracy_train_first": 0.3634823529411765, "accuracy_train_last": 0.7545647058823529, "batch_size_eval": 1024, "accuracy_train_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_test_std": 0, "error_valid": [0.6385333333333334, 0.5589333333333333, 0.5224, 0.4985333333333334, 0.47919999999999996, 0.46599999999999997, 0.45853333333333335, 0.44533333333333336, 0.43866666666666665, 0.4284, 0.4190666666666667, 0.4149333333333334, 0.4033333333333333, 0.39880000000000004, 0.39493333333333336, 0.3877333333333334, 0.38480000000000003, 0.38293333333333335, 0.3733333333333333, 0.36906666666666665, 0.3726666666666667, 0.3686666666666667, 0.358, 0.36040000000000005, 0.35719999999999996, 0.3568, 0.35106666666666664, 0.3521333333333333, 0.34986666666666666, 0.3473333333333334, 0.34440000000000004, 0.3429333333333333, 0.3396, 0.34199999999999997, 0.34173333333333333, 0.3354666666666667, 0.33520000000000005, 0.33533333333333337, 0.33120000000000005, 0.33053333333333335, 0.33120000000000005, 0.3282666666666667, 0.3269333333333333, 0.3277333333333333, 0.3250666666666666, 0.32399999999999995, 0.32253333333333334, 0.32186666666666663, 0.32186666666666663, 0.3197333333333333, 0.31799999999999995, 0.3169333333333333, 0.3174666666666667, 0.3170666666666667, 0.3162666666666667, 0.31586666666666663, 0.3150666666666667, 0.31253333333333333, 0.3110666666666667, 0.3121333333333334, 0.3096, 0.3104, 0.31000000000000005, 0.3084, 0.3069333333333333, 0.30679999999999996, 0.30679999999999996, 0.3076, 0.3057333333333333, 0.3052, 0.3057333333333333, 0.3029333333333334, 0.3036, 0.30533333333333335, 0.3022666666666667, 0.3017333333333333, 0.3016, 0.30213333333333336, 0.2992, 0.2982666666666667, 0.2984, 0.3018666666666666, 0.2996, 0.2982666666666667, 0.2984, 0.2964, 0.29746666666666666, 0.29733333333333334, 0.2982666666666667, 0.29666666666666663, 0.2962666666666667, 0.2962666666666667, 0.29613333333333336, 0.2952, 0.2952, 0.2957333333333333, 0.2949333333333334, 0.2950666666666667, 0.2942666666666667, 0.2950666666666667, 0.29466666666666663, 0.29333333333333333, 0.2932, 0.29079999999999995, 0.29359999999999997, 0.2932, 0.29213333333333336, 0.29266666666666663, 0.2930666666666667, 0.29200000000000004, 0.2924, 0.29079999999999995, 0.29133333333333333, 0.2910666666666667, 0.2905333333333333, 0.29200000000000004, 0.29200000000000004, 0.2905333333333333, 0.2904, 0.2910666666666667, 0.29000000000000004, 0.2897333333333333, 0.2905333333333333, 0.2902666666666667, 0.2892, 0.2905333333333333, 0.2892, 0.28813333333333335, 0.2886666666666666, 0.28933333333333333, 0.28813333333333335, 0.2877333333333333, 0.2892, 0.28879999999999995, 0.2877333333333333, 0.2889333333333334, 0.2886666666666666, 0.2885333333333333, 0.28826666666666667, 0.2878666666666667, 0.2869333333333334, 0.2870666666666667, 0.28746666666666665, 0.2870666666666667, 0.2878666666666667, 0.2878666666666667, 0.2865333333333333, 0.28600000000000003, 0.2866666666666666, 0.28733333333333333, 0.2865333333333333, 0.28546666666666665, 0.28680000000000005, 0.2857333333333333, 0.2864, 0.2869333333333334, 0.2866666666666666, 0.2858666666666667, 0.28559999999999997, 0.2869333333333334, 0.2857333333333333, 0.28600000000000003, 0.28559999999999997, 0.2850666666666667, 0.28559999999999997, 0.2866666666666666, 0.28600000000000003, 0.28559999999999997, 0.2852, 0.28559999999999997, 0.28626666666666667, 0.28600000000000003, 0.28480000000000005, 0.2857333333333333, 0.28600000000000003, 0.28613333333333335, 0.2852, 0.2853333333333333, 0.28493333333333337, 0.2844, 0.2853333333333333, 0.28559999999999997, 0.2845333333333333, 0.28613333333333335, 0.2846666666666666, 0.28493333333333337, 0.28400000000000003, 0.2853333333333333, 0.2850666666666667, 0.28480000000000005, 0.28493333333333337, 0.2852, 0.28480000000000005, 0.28426666666666667, 0.28426666666666667, 0.28346666666666664, 0.28546666666666665, 0.28493333333333337, 0.28493333333333337, 0.28493333333333337, 0.2850666666666667, 0.28400000000000003, 0.28426666666666667, 0.28493333333333337, 0.2852, 0.28480000000000005, 0.2850666666666667, 0.28600000000000003, 0.2850666666666667, 0.2850666666666667, 0.28480000000000005, 0.2845333333333333, 0.2846666666666666, 0.2833333333333333, 0.2846666666666666, 0.2846666666666666, 0.2850666666666667, 0.28493333333333337, 0.2846666666666666, 0.2853333333333333, 0.28413333333333335, 0.2844, 0.2846666666666666, 0.2846666666666666, 0.2852, 0.2846666666666666, 0.2850666666666667, 0.28493333333333337, 0.28613333333333335, 0.2852, 0.28493333333333337, 0.28600000000000003, 0.28493333333333337, 0.28546666666666665, 0.28480000000000005, 0.2853333333333333, 0.2853333333333333, 0.28680000000000005, 0.28480000000000005, 0.28413333333333335, 0.28559999999999997, 0.28493333333333337, 0.28480000000000005, 0.2850666666666667, 0.2846666666666666, 0.2845333333333333, 0.2852, 0.2846666666666666, 0.28480000000000005, 0.2853333333333333, 0.2857333333333333, 0.28359999999999996, 0.2858666666666667, 0.28613333333333335, 0.28293333333333337, 0.28413333333333335, 0.28493333333333337, 0.2846666666666666, 0.2844, 0.2845333333333333, 0.2844, 0.28493333333333337, 0.28426666666666667, 0.2853333333333333, 0.28493333333333337, 0.28426666666666667, 0.28480000000000005, 0.28546666666666665, 0.2846666666666666, 0.2845333333333333, 0.28480000000000005, 0.2844, 0.2845333333333333, 0.28600000000000003, 0.28413333333333335, 0.28613333333333335, 0.28493333333333337, 0.2852, 0.2852, 0.28426666666666667, 0.28426666666666667, 0.28359999999999996, 0.2852, 0.2857333333333333, 0.2838666666666667, 0.2844, 0.2845333333333333, 0.2846666666666666, 0.2850666666666667, 0.2845333333333333, 0.28493333333333337, 0.28280000000000005, 0.28400000000000003, 0.28346666666666664, 0.2846666666666666, 0.2837333333333333, 0.28426666666666667, 0.28480000000000005, 0.2844, 0.2844, 0.28400000000000003, 0.28493333333333337, 0.28559999999999997, 0.28493333333333337, 0.28426666666666667, 0.2844, 0.28426666666666667, 0.28559999999999997, 0.28493333333333337, 0.2850666666666667, 0.2850666666666667, 0.2858666666666667, 0.2845333333333333, 0.2845333333333333, 0.2864, 0.2845333333333333, 0.2844, 0.2853333333333333, 0.2853333333333333, 0.28559999999999997, 0.28600000000000003, 0.2853333333333333, 0.28559999999999997, 0.2844, 0.2857333333333333, 0.2844, 0.28413333333333335, 0.2853333333333333, 0.2852, 0.2838666666666667, 0.28346666666666664, 0.2844, 0.2846666666666666, 0.28480000000000005, 0.2845333333333333, 0.2846666666666666, 0.28426666666666667, 0.2845333333333333, 0.28480000000000005, 0.2853333333333333, 0.28426666666666667, 0.2845333333333333], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.025849914271898936, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.00013443230010848077, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 4.218784802352638e-06, "rotation_range": [0, 0], "momentum": 0.9279691110696562}, "accuracy_valid_max": 0.7172, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        y_pred = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            y_pred.extend((nnet.predict(X[mini_batch]) == y[mini_batch]).tolist())\n        return np.mean(y_pred)\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            acc = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = acc\n            status[\"accuracy_train_std\"] = 0\n            acc = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = acc\n            status[\"accuracy_valid_std\"] = 0\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    acc = evaluate(X_test, y_test, batch_size_eval)\n    light.set(\"accuracy_test\", acc)\n    light.set(\"accuracy_test_std\", 0)\n    print(\"Test accuracy : {}+-{}\".format(acc, 0))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7154666666666667, "accuracy_valid_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_valid": [0.36146666666666666, 0.44106666666666666, 0.4776, 0.5014666666666666, 0.5208, 0.534, 0.5414666666666667, 0.5546666666666666, 0.5613333333333334, 0.5716, 0.5809333333333333, 0.5850666666666666, 0.5966666666666667, 0.6012, 0.6050666666666666, 0.6122666666666666, 0.6152, 0.6170666666666667, 0.6266666666666667, 0.6309333333333333, 0.6273333333333333, 0.6313333333333333, 0.642, 0.6396, 0.6428, 0.6432, 0.6489333333333334, 0.6478666666666667, 0.6501333333333333, 0.6526666666666666, 0.6556, 0.6570666666666667, 0.6604, 0.658, 0.6582666666666667, 0.6645333333333333, 0.6648, 0.6646666666666666, 0.6688, 0.6694666666666667, 0.6688, 0.6717333333333333, 0.6730666666666667, 0.6722666666666667, 0.6749333333333334, 0.676, 0.6774666666666667, 0.6781333333333334, 0.6781333333333334, 0.6802666666666667, 0.682, 0.6830666666666667, 0.6825333333333333, 0.6829333333333333, 0.6837333333333333, 0.6841333333333334, 0.6849333333333333, 0.6874666666666667, 0.6889333333333333, 0.6878666666666666, 0.6904, 0.6896, 0.69, 0.6916, 0.6930666666666667, 0.6932, 0.6932, 0.6924, 0.6942666666666667, 0.6948, 0.6942666666666667, 0.6970666666666666, 0.6964, 0.6946666666666667, 0.6977333333333333, 0.6982666666666667, 0.6984, 0.6978666666666666, 0.7008, 0.7017333333333333, 0.7016, 0.6981333333333334, 0.7004, 0.7017333333333333, 0.7016, 0.7036, 0.7025333333333333, 0.7026666666666667, 0.7017333333333333, 0.7033333333333334, 0.7037333333333333, 0.7037333333333333, 0.7038666666666666, 0.7048, 0.7048, 0.7042666666666667, 0.7050666666666666, 0.7049333333333333, 0.7057333333333333, 0.7049333333333333, 0.7053333333333334, 0.7066666666666667, 0.7068, 0.7092, 0.7064, 0.7068, 0.7078666666666666, 0.7073333333333334, 0.7069333333333333, 0.708, 0.7076, 0.7092, 0.7086666666666667, 0.7089333333333333, 0.7094666666666667, 0.708, 0.708, 0.7094666666666667, 0.7096, 0.7089333333333333, 0.71, 0.7102666666666667, 0.7094666666666667, 0.7097333333333333, 0.7108, 0.7094666666666667, 0.7108, 0.7118666666666666, 0.7113333333333334, 0.7106666666666667, 0.7118666666666666, 0.7122666666666667, 0.7108, 0.7112, 0.7122666666666667, 0.7110666666666666, 0.7113333333333334, 0.7114666666666667, 0.7117333333333333, 0.7121333333333333, 0.7130666666666666, 0.7129333333333333, 0.7125333333333334, 0.7129333333333333, 0.7121333333333333, 0.7121333333333333, 0.7134666666666667, 0.714, 0.7133333333333334, 0.7126666666666667, 0.7134666666666667, 0.7145333333333334, 0.7132, 0.7142666666666667, 0.7136, 0.7130666666666666, 0.7133333333333334, 0.7141333333333333, 0.7144, 0.7130666666666666, 0.7142666666666667, 0.714, 0.7144, 0.7149333333333333, 0.7144, 0.7133333333333334, 0.714, 0.7144, 0.7148, 0.7144, 0.7137333333333333, 0.714, 0.7152, 0.7142666666666667, 0.714, 0.7138666666666666, 0.7148, 0.7146666666666667, 0.7150666666666666, 0.7156, 0.7146666666666667, 0.7144, 0.7154666666666667, 0.7138666666666666, 0.7153333333333334, 0.7150666666666666, 0.716, 0.7146666666666667, 0.7149333333333333, 0.7152, 0.7150666666666666, 0.7148, 0.7152, 0.7157333333333333, 0.7157333333333333, 0.7165333333333334, 0.7145333333333334, 0.7150666666666666, 0.7150666666666666, 0.7150666666666666, 0.7149333333333333, 0.716, 0.7157333333333333, 0.7150666666666666, 0.7148, 0.7152, 0.7149333333333333, 0.714, 0.7149333333333333, 0.7149333333333333, 0.7152, 0.7154666666666667, 0.7153333333333334, 0.7166666666666667, 0.7153333333333334, 0.7153333333333334, 0.7149333333333333, 0.7150666666666666, 0.7153333333333334, 0.7146666666666667, 0.7158666666666667, 0.7156, 0.7153333333333334, 0.7153333333333334, 0.7148, 0.7153333333333334, 0.7149333333333333, 0.7150666666666666, 0.7138666666666666, 0.7148, 0.7150666666666666, 0.714, 0.7150666666666666, 0.7145333333333334, 0.7152, 0.7146666666666667, 0.7146666666666667, 0.7132, 0.7152, 0.7158666666666667, 0.7144, 0.7150666666666666, 0.7152, 0.7149333333333333, 0.7153333333333334, 0.7154666666666667, 0.7148, 0.7153333333333334, 0.7152, 0.7146666666666667, 0.7142666666666667, 0.7164, 0.7141333333333333, 0.7138666666666666, 0.7170666666666666, 0.7158666666666667, 0.7150666666666666, 0.7153333333333334, 0.7156, 0.7154666666666667, 0.7156, 0.7150666666666666, 0.7157333333333333, 0.7146666666666667, 0.7150666666666666, 0.7157333333333333, 0.7152, 0.7145333333333334, 0.7153333333333334, 0.7154666666666667, 0.7152, 0.7156, 0.7154666666666667, 0.714, 0.7158666666666667, 0.7138666666666666, 0.7150666666666666, 0.7148, 0.7148, 0.7157333333333333, 0.7157333333333333, 0.7164, 0.7148, 0.7142666666666667, 0.7161333333333333, 0.7156, 0.7154666666666667, 0.7153333333333334, 0.7149333333333333, 0.7154666666666667, 0.7150666666666666, 0.7172, 0.716, 0.7165333333333334, 0.7153333333333334, 0.7162666666666667, 0.7157333333333333, 0.7152, 0.7156, 0.7156, 0.716, 0.7150666666666666, 0.7144, 0.7150666666666666, 0.7157333333333333, 0.7156, 0.7157333333333333, 0.7144, 0.7150666666666666, 0.7149333333333333, 0.7149333333333333, 0.7141333333333333, 0.7154666666666667, 0.7154666666666667, 0.7136, 0.7154666666666667, 0.7156, 0.7146666666666667, 0.7146666666666667, 0.7144, 0.714, 0.7146666666666667, 0.7144, 0.7156, 0.7142666666666667, 0.7156, 0.7158666666666667, 0.7146666666666667, 0.7148, 0.7161333333333333, 0.7165333333333334, 0.7156, 0.7153333333333334, 0.7152, 0.7154666666666667, 0.7153333333333334, 0.7157333333333333, 0.7154666666666667, 0.7152, 0.7146666666666667, 0.7157333333333333, 0.7154666666666667], "seed": 268121432, "model": "residualv3", "loss_std": [0.2890460193157196, 0.09948547184467316, 0.09019525349140167, 0.08825048804283142, 0.08684471994638443, 0.08617821335792542, 0.08733923733234406, 0.08519496023654938, 0.08770477771759033, 0.08778838813304901, 0.08765383809804916, 0.08703120052814484, 0.08650600165128708, 0.08313287794589996, 0.08534673601388931, 0.08528301119804382, 0.08539347350597382, 0.08514762669801712, 0.08487095683813095, 0.08256414532661438, 0.08334352821111679, 0.0843905508518219, 0.08523441851139069, 0.08198455721139908, 0.08361779898405075, 0.08198318630456924, 0.08370764553546906, 0.0830221027135849, 0.08202154189348221, 0.08220536261796951, 0.08194438368082047, 0.08357422053813934, 0.0838681161403656, 0.080738365650177, 0.08152452111244202, 0.08138469606637955, 0.08271940797567368, 0.08191975206136703, 0.08270693570375443, 0.07959221303462982, 0.08008256554603577, 0.08073015511035919, 0.07963605225086212, 0.07960966229438782, 0.08245372772216797, 0.08081164956092834, 0.08351711928844452, 0.08164618909358978, 0.07976222783327103, 0.08044008165597916, 0.07980497926473618, 0.08137905597686768, 0.0798175185918808, 0.07955385744571686, 0.07940059155225754, 0.07849781215190887, 0.08005080372095108, 0.08031337708234787, 0.07977059483528137, 0.07975788414478302, 0.0808226615190506, 0.07853369414806366, 0.07780646532773972, 0.07908613979816437, 0.07964326441287994, 0.08037745952606201, 0.08026248216629028, 0.07872628420591354, 0.08119311183691025, 0.08194822072982788, 0.0812840610742569, 0.07991793751716614, 0.0798516646027565, 0.0795508399605751, 0.08018539845943451, 0.08291247487068176, 0.08062916249036789, 0.07819093018770218, 0.07732775807380676, 0.07787059992551804, 0.07934065163135529, 0.07922789454460144, 0.07894373685121536, 0.08059564232826233, 0.0790519043803215, 0.07990948110818863, 0.08029036223888397, 0.08150334656238556, 0.07936760038137436, 0.0764840692281723, 0.07932505011558533, 0.08183642476797104, 0.080910325050354, 0.07953925430774689, 0.07885128259658813, 0.07774275541305542, 0.07870937138795853, 0.07903757691383362, 0.07914295047521591, 0.0791395753622055, 0.08174682408571243, 0.0803743302822113, 0.08202094584703445, 0.07927853614091873, 0.07895752042531967, 0.08077386766672134, 0.07997233420610428, 0.07939689606428146, 0.07910207659006119, 0.08056828379631042, 0.07854145765304565, 0.08028338849544525, 0.07743752002716064, 0.08068803697824478, 0.0790511965751648, 0.07924459874629974, 0.07866106927394867, 0.07819543778896332, 0.07652391493320465, 0.07788334041833878, 0.07780642807483673, 0.07763644307851791, 0.08233224600553513, 0.07797582447528839, 0.07931331545114517, 0.07961739599704742, 0.07937932759523392, 0.07798515260219574, 0.07799191772937775, 0.07910259813070297, 0.07943210005760193, 0.07899250835180283, 0.08054913580417633, 0.08000602573156357, 0.07939170300960541, 0.07901282608509064, 0.08104325830936432, 0.07690226286649704, 0.07761895656585693, 0.08211568742990494, 0.07977361232042313, 0.0780138224363327, 0.07939203083515167, 0.07976173609495163, 0.0794757828116417, 0.0770651251077652, 0.08037636429071426, 0.07958080619573593, 0.07954668253660202, 0.07870658487081528, 0.07979774475097656, 0.08001147955656052, 0.07974771410226822, 0.07814541459083557, 0.07788602262735367, 0.07966621220111847, 0.07894235104322433, 0.08063168078660965, 0.08164297789335251, 0.07727210223674774, 0.07973282039165497, 0.0783899798989296, 0.08061568439006805, 0.07913517206907272, 0.08017019182443619, 0.07770693302154541, 0.07724057883024216, 0.07899603247642517, 0.07890795916318893, 0.07766585797071457, 0.07921984791755676, 0.07661247253417969, 0.07795294374227524, 0.08061487972736359, 0.07634218782186508, 0.07849213480949402, 0.07800139486789703, 0.07893597334623337, 0.07963103801012039, 0.07925654947757721, 0.07702627778053284, 0.07744166254997253, 0.08036566525697708, 0.07879184186458588, 0.07739294320344925, 0.07890593260526657, 0.07942073792219162, 0.07753886282444, 0.07808158546686172, 0.07968626916408539, 0.07937297224998474, 0.08018544316291809, 0.07862775027751923, 0.07807572931051254, 0.07954283058643341, 0.07830590009689331, 0.0807335302233696, 0.07997015863656998, 0.07800095528364182, 0.07999031990766525, 0.07880889624357224, 0.07930615544319153, 0.07702405750751495, 0.08096810430288315, 0.08014800399541855, 0.07865141332149506, 0.0772266685962677, 0.07594164460897446, 0.0793365016579628, 0.08074666559696198, 0.08039407432079315, 0.07749013602733612, 0.08008845150470734, 0.0757140964269638, 0.07818116247653961, 0.08086700737476349, 0.07759314030408859, 0.07757939398288727, 0.07925855368375778, 0.08112998306751251, 0.07962007820606232, 0.07990537583827972, 0.08003715425729752, 0.08091609925031662, 0.08103391528129578, 0.07822487503290176, 0.0805458277463913, 0.07865462452173233, 0.07852927595376968, 0.08098766952753067, 0.07843521982431412, 0.07971768081188202, 0.08127212524414062, 0.07775936275720596, 0.08132640272378922, 0.08117806911468506, 0.07833146303892136, 0.07937394082546234, 0.07910721749067307, 0.07704717665910721, 0.0788646712899208, 0.0806533545255661, 0.07907555252313614, 0.08242335170507431, 0.07807768881320953, 0.07755497843027115, 0.08006705343723297, 0.0786055251955986, 0.07813100516796112, 0.0756998285651207, 0.08020547032356262, 0.07919656485319138, 0.07812602818012238, 0.07765310257673264, 0.07795922458171844, 0.07948442548513412, 0.07785230129957199, 0.07950197160243988, 0.08105491101741791, 0.079740010201931, 0.08000699430704117, 0.07858051359653473, 0.07974229753017426, 0.08014553040266037, 0.07978696376085281, 0.07991912961006165, 0.07831358164548874, 0.07794338464736938, 0.07942557334899902, 0.07928955554962158, 0.07924199849367142, 0.07676239311695099, 0.07952842116355896, 0.07858435809612274, 0.08085116744041443, 0.0779903307557106, 0.07942773401737213, 0.07837475091218948, 0.07921113073825836, 0.08055929839611053, 0.07995298504829407, 0.07988759130239487, 0.08035486936569214, 0.07994755357503891, 0.07892846316099167, 0.08002762496471405, 0.07901937514543533, 0.07876203209161758, 0.07981400936841965, 0.07714852690696716, 0.08007132261991501, 0.07905077189207077, 0.07997895032167435, 0.08048485219478607, 0.08206812292337418, 0.07806885242462158, 0.07811480015516281, 0.0793219730257988, 0.07859174907207489, 0.07786809653043747, 0.07964160293340683, 0.0799688994884491, 0.07937255501747131, 0.08045578002929688, 0.07815062254667282, 0.07988986372947693, 0.08099628984928131, 0.07791690528392792, 0.08211677521467209, 0.07990790158510208, 0.08144956082105637, 0.07785622775554657, 0.07956378161907196, 0.08065163344144821, 0.07890919595956802, 0.07866699248552322, 0.07972560822963715, 0.07674240320920944, 0.07740841060876846, 0.0811028704047203, 0.0807281956076622, 0.07645183801651001, 0.08043252676725388, 0.08116862922906876, 0.07618841528892517, 0.07919557392597198, 0.07674398273229599, 0.07946501672267914, 0.07958705723285675, 0.07814604043960571, 0.08136545866727829, 0.07764428853988647, 0.0793163925409317, 0.07952950894832611, 0.07757717370986938, 0.08174817264080048, 0.08069642633199692, 0.07881861925125122, 0.07803266495466232, 0.07795993238687515, 0.078711599111557, 0.080384761095047]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:39 2016", "state": "available"}], "summary": "54667c2eef9a81d235d74861352ad941"}