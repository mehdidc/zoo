{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 64, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.580391764640808, 1.1948332786560059, 0.9517921209335327, 0.8191131949424744, 0.737920343875885, 0.6818615794181824, 0.6406962275505066, 0.6022859215736389, 0.5765207409858704, 0.5539032816886902, 0.5333452224731445, 0.515731930732727, 0.49882596731185913, 0.48575273156166077, 0.471828818321228, 0.4598429203033447, 0.4495384097099304, 0.4387231767177582, 0.4288099408149719, 0.4195551574230194, 0.4122454524040222, 0.40585848689079285, 0.3972461223602295, 0.3917035460472107, 0.3853904604911804, 0.3795510232448578, 0.37284398078918457, 0.3670266270637512, 0.3644333481788635, 0.35870620608329773, 0.35291674733161926, 0.3498765230178833, 0.3465842604637146, 0.3403438925743103, 0.3382773995399475, 0.33398503065109253, 0.32955724000930786, 0.32460829615592957, 0.3237795829772949, 0.32144197821617126, 0.31755003333091736, 0.3135591149330139, 0.3103105127811432, 0.3065447509288788, 0.30323782563209534, 0.3015083968639374, 0.3001280725002289, 0.29569628834724426, 0.294095903635025, 0.29080700874328613, 0.2877295911312103, 0.2878844439983368, 0.2846524715423584, 0.28275778889656067, 0.2814316153526306, 0.27784469723701477, 0.27632641792297363, 0.2762417495250702, 0.2725988030433655, 0.2698085308074951, 0.2691138982772827, 0.2676759362220764, 0.2658112645149231, 0.26266661286354065, 0.2621740400791168, 0.25840938091278076, 0.25760915875434875, 0.2564775347709656, 0.2551870048046112, 0.2524046003818512, 0.253094881772995, 0.2522438168525696, 0.24807144701480865, 0.24766658246517181, 0.24643999338150024, 0.24492844939231873, 0.24481578171253204, 0.24130907654762268, 0.2416759729385376, 0.24122384190559387, 0.23861967027187347, 0.23625193536281586, 0.23696668446063995, 0.2350080907344818, 0.23154523968696594, 0.23266376554965973, 0.23063625395298004, 0.2297976166009903, 0.2299511730670929, 0.22977979481220245, 0.22550979256629944, 0.22512200474739075, 0.22494779527187347, 0.22572165727615356, 0.222024068236351, 0.22199517488479614, 0.22271500527858734, 0.21971456706523895, 0.22074587643146515, 0.21667112410068512, 0.2174079567193985, 0.21537066996097565, 0.21558281779289246, 0.21419884264469147, 0.21177244186401367, 0.2125602513551712, 0.213846355676651, 0.2120285928249359, 0.20930726826190948, 0.208391934633255, 0.20744064450263977, 0.20730704069137573, 0.20640431344509125, 0.2051413208246231, 0.20646317303180695, 0.20489725470542908, 0.20272545516490936, 0.2024405151605606, 0.20346388220787048, 0.20090435445308685, 0.20060282945632935, 0.20023302733898163, 0.20017215609550476, 0.19761835038661957, 0.19838401675224304, 0.19709843397140503, 0.19766436517238617, 0.1970086693763733, 0.19630445539951324, 0.19411978125572205, 0.19229523837566376, 0.19373482465744019, 0.19290463626384735, 0.19279049336910248, 0.19160586595535278, 0.19020837545394897, 0.1889512985944748, 0.19029180705547333, 0.1899460256099701, 0.18733321130275726, 0.18604572117328644, 0.18814274668693542, 0.18729162216186523, 0.18669557571411133, 0.1857539415359497, 0.1859070062637329, 0.18646223843097687, 0.1836961805820465, 0.18329821527004242, 0.18221011757850647, 0.18114732205867767, 0.18178075551986694, 0.1815997064113617, 0.18010862171649933, 0.18051542341709137, 0.18044258654117584, 0.1801152378320694, 0.17882338166236877, 0.17696677148342133, 0.17715297639369965, 0.17674589157104492, 0.17841944098472595, 0.17655043303966522, 0.17393317818641663, 0.17467838525772095, 0.17462819814682007, 0.17303048074245453, 0.1741265505552292, 0.17459705471992493, 0.1727263480424881, 0.17214512825012207, 0.17015017569065094, 0.16871297359466553, 0.1718197613954544, 0.1694931536912918, 0.17089669406414032, 0.17074713110923767, 0.17033618688583374, 0.16733115911483765, 0.1683049201965332, 0.16828201711177826, 0.16696520149707794, 0.1666189432144165, 0.16486500203609467, 0.16581447422504425, 0.16495585441589355], "moving_avg_accuracy_train": [0.05376007203995938, 0.11274926676702655, 0.17572692190672293, 0.23660283996199008, 0.2934230218318855, 0.34649098692905866, 0.39566773855568954, 0.4411080266637142, 0.4829548752870253, 0.5212006874480145, 0.5562193374416774, 0.5882058024954979, 0.6175564152022974, 0.6442647911931418, 0.6687835632908358, 0.6911340542358847, 0.7115820644638282, 0.730229306147521, 0.7473769080747585, 0.7630539264830911, 0.7774606818541158, 0.7906430726249611, 0.8026863328746927, 0.8137250857017952, 0.8237624139890816, 0.83296327596665, 0.8416184007047949, 0.8494311563107643, 0.8565952779847359, 0.8633288365996068, 0.8695147415839799, 0.8750959348651353, 0.8801586084455745, 0.8848590296988852, 0.8892778540268926, 0.8933547052232713, 0.8971772590238031, 0.9005757408145291, 0.9037204049321349, 0.9067506375332367, 0.9094964120158857, 0.9121024676812222, 0.9145594528252446, 0.9168661066048741, 0.9190560633470259, 0.9210967788792485, 0.9229705891903823, 0.9247197253906224, 0.9263033567125328, 0.9278681698796425, 0.9293252217085849, 0.9308504459962904, 0.9322022936135772, 0.9335305636119925, 0.9347422466034141, 0.9358187022563802, 0.9367783198952678, 0.9379093318345432, 0.9388900041501198, 0.9398306298079208, 0.9407122143273594, 0.9415822982079309, 0.9424329472111965, 0.9434053253629082, 0.9441664973589633, 0.9449190175197077, 0.9456752686262642, 0.9462720811185658, 0.946909446102178, 0.9475805866421539, 0.9482311521531416, 0.9488282868570781, 0.9493400954048975, 0.9498379254788873, 0.9503859539442877, 0.9508650844750158, 0.9513173003895944, 0.9518894523758287, 0.9523532719384489, 0.9528194295233507, 0.9532390073985813, 0.9536817316529553, 0.9540406559521301, 0.9544426707832736, 0.9548533843539404, 0.9552229184210842, 0.9555764614696182, 0.9559109262549653, 0.9563328522998731, 0.956661504564118, 0.9569571834554821, 0.957288470722014, 0.9575449207785962, 0.9578987784723313, 0.9581846622645407, 0.9584814852072912, 0.9588253918152996, 0.9591068617815179, 0.9594927542820759, 0.9597796757611681, 0.9600215569530468, 0.9603067874876701, 0.9605424965319078, 0.960840701226493, 0.96112525334683, 0.9613721217575327, 0.9615919060807182, 0.9618245531549092, 0.9620596203050422, 0.9622779759424966, 0.962455966923367, 0.9626836241704452, 0.9629280792713962, 0.9631782797479572, 0.963435940162558, 0.9636399687988031, 0.963830606066671, 0.9640742952696661, 0.9643052052475907, 0.9645246139229515, 0.9646383763736335, 0.964840707929238, 0.9650437326685679, 0.9651892886018311, 0.965343576478682, 0.9654707737749813, 0.9656014913344986, 0.9657842773535497, 0.9658953423968953, 0.9660463821120784, 0.9661591024164667, 0.9663395697011213, 0.9665555047287482, 0.9667636890000133, 0.9669558493370459, 0.967124179391575, 0.9672965667311181, 0.9674748947271645, 0.9676539190164452, 0.9678150769256164, 0.9679277472046309, 0.9680174165652402, 0.9681258765802279, 0.9682863056603925, 0.9683655876658742, 0.968537103113711, 0.9687098879631464, 0.9688281558978672, 0.9689253324926965, 0.9690592583554147, 0.9691984649199747, 0.969270236356641, 0.9693814057234686, 0.9695303223274322, 0.9696061464531238, 0.9697232162912462, 0.9698495054848422, 0.9699492148662213, 0.9700761556904149, 0.9701811378857699, 0.970338328781809, 0.9705123887203962, 0.9706039745472769, 0.9706328512712128, 0.9706774415132314, 0.9708035671881818, 0.970905526649227, 0.9709996153129772, 0.971126111740105, 0.9711516389185769, 0.9712326700018022, 0.9712940443302949, 0.9714259750878339, 0.9714493816684284, 0.9715728262362202, 0.9716862154472236, 0.9717417267121172, 0.971845093175503, 0.9719009927092355, 0.9719977331681477, 0.9720685956371395, 0.9721625627449373, 0.9723098761109936, 0.9724378438916439, 0.9725391000501908, 0.9725929561142932], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05277011365775601, 0.11045652826148342, 0.17226640889730796, 0.23159109048498677, 0.28687451132165376, 0.33801310264054263, 0.3853806082650426, 0.4284590525213697, 0.46784000391456404, 0.5032685941198697, 0.535928515816693, 0.5655696744948129, 0.5924949759647593, 0.6169607103901207, 0.6395515428243767, 0.6600094803623455, 0.678750184481608, 0.6956290252201941, 0.7106714384926024, 0.7245555253474084, 0.7371112091643243, 0.7488029791082081, 0.7590061302278842, 0.7681767592043428, 0.776471064411544, 0.7840813939643655, 0.7910893819681548, 0.7971768446090652, 0.8026168808748153, 0.8076970484914001, 0.8124156837213263, 0.81650376402201, 0.8202653969853964, 0.8236793987495826, 0.826933046788781, 0.8299223651803096, 0.8327226150139353, 0.8349244275430387, 0.8371624064754818, 0.8392640957507499, 0.8411434090672412, 0.8429070037309236, 0.8443599615844879, 0.8456310025589457, 0.8470923222484579, 0.8482620551026784, 0.8492415724839768, 0.8502075578372358, 0.851054589609988, 0.8519979646568959, 0.8529345104351823, 0.8536898933995707, 0.8543453240050203, 0.8551315535585845, 0.8559510824553616, 0.8565990912090723, 0.8573084874345506, 0.8579601805773907, 0.8584978762809468, 0.8590418080617376, 0.8593695667322204, 0.859826329467884, 0.86026491851846, 0.8608529021466592, 0.8614166494884692, 0.8617063545509175, 0.861866344331142, 0.8620612222756633, 0.8624064813545729, 0.8627660426505914, 0.8630784702944179, 0.8634084832988617, 0.8633748756504513, 0.863652893074111, 0.8638176595366547, 0.8640402210491037, 0.8641387521256693, 0.8643780325042167, 0.8646523609838404, 0.8648646945390708, 0.8650669722613685, 0.8652246081489365, 0.8653542734164976, 0.8654587651260527, 0.8655894287584023, 0.8657680611837668, 0.8658189670853449, 0.865850516348196, 0.8659653894121716, 0.86592126128609, 0.8658825754812762, 0.8658223146857842, 0.8657701389871606, 0.8657475949208993, 0.8658657006396526, 0.8659587592466211, 0.8660892811005735, 0.8661568931354708, 0.8663164297255382, 0.8663989775003489, 0.8663878212789284, 0.8665375015945598, 0.8665613210887182, 0.8665837881421204, 0.8665673873964325, 0.866736761702723, 0.8669380267033844, 0.86708151460157, 0.8670631398262775, 0.8671463177958334, 0.8670970486386146, 0.8669672571783676, 0.8668626518953954, 0.866888518435901, 0.8668162010896753, 0.8668833338045029, 0.8666741690516881, 0.8666079910866549, 0.8666481461854443, 0.8666110435868547, 0.866565444216874, 0.866525434292551, 0.8665748745794104, 0.8665705427125838, 0.8666266496800302, 0.8667880387406417, 0.866982117020192, 0.8667518964232179, 0.8667807495143298, 0.8668189243275806, 0.8667057677758466, 0.8668857181066957, 0.8669479581371405, 0.8668585192982006, 0.8669855438744046, 0.8672707644304882, 0.8672080211011443, 0.8672502378633943, 0.8673757411854885, 0.8672313170104637, 0.8673454758779414, 0.8671643686139425, 0.8671743295311628, 0.8670622535528206, 0.8670102132973126, 0.8669898501471748, 0.8671037416384814, 0.8670210794945881, 0.867120670528563, 0.8671227942230711, 0.8673322250793785, 0.8674617367111244, 0.8674684338984457, 0.8672760603410561, 0.8673002956567246, 0.8672600427759166, 0.8671383659644394, 0.8671774002264292, 0.8672837142324008, 0.8672715925738445, 0.8672464170325745, 0.8672868532190008, 0.8674331090680345, 0.8673317762297551, 0.8672527837065537, 0.8672905242082628, 0.867202420347301, 0.8673815335460047, 0.8672609441974283, 0.8672988981587095, 0.8672730510762723, 0.8671633099746692, 0.8672873580717053, 0.8671761862705588, 0.867161580868277, 0.8669266504264042, 0.8668159578046974, 0.8668750258514114, 0.8668406788573847, 0.8668585946877607, 0.8669245765687588, 0.8668455648832685, 0.8667653358610561, 0.8668294661021342, 0.8668617397479449, 0.8665703146906956], "moving_var_accuracy_train": [0.02601130811167461, 0.0547277031514378, 0.08495059825834475, 0.1098084350241547, 0.12788438913129122, 0.14044183049415523, 0.14816282354966578, 0.15192991924476176, 0.1524973559776064, 0.15041229971052883, 0.14640782236588398, 0.14097524564904906, 0.13463084728052496, 0.12758779868508732, 0.12023955048318648, 0.11271149544423027, 0.10520343600034597, 0.09781256900200185, 0.09067767436849668, 0.08382182708722379, 0.07730763578138633, 0.0711408510411651, 0.06533212699403348, 0.059895600870430915, 0.054812772415708644, 0.05009339792431016, 0.04575825878997477, 0.041731785262404744, 0.03802052849039949, 0.03462654294593865, 0.031508277435626, 0.028637797158037926, 0.02600469341627283, 0.02360306971427273, 0.021418496818821565, 0.019426233578036134, 0.017615117478254165, 0.015957552836765816, 0.01445079776480225, 0.013088358774873046, 0.01184737639497184, 0.010723762490652147, 0.009705717225568457, 0.008783031367943322, 0.007947891425941461, 0.007190582962298402, 0.006503125151807565, 0.005880347933649721, 0.005314884133758371, 0.0048054334826141696, 0.0043439971346427705, 0.003930534203328756, 0.003553928210819156, 0.003214414100435451, 0.0029061862714372102, 0.002625996455248713, 0.0023716846038396204, 0.0021460288355167087, 0.001940081415679885, 0.0017540362637649164, 0.0015856273587726492, 0.0014338780365284586, 0.0012970026664164234, 0.0011758120732041166, 0.0010634453111519112, 0.0009621973593676626, 0.0008711248650564059, 0.0007872180449094706, 0.0007121523475195385, 0.0006449909793871783, 0.0005843010008052401, 0.000529080029416524, 0.00047852955838145994, 0.00043290711558643187, 0.00039231942081778976, 0.000355153573325293, 0.0003214787090933465, 0.0002922770592421792, 0.0002649855105979838, 0.00024044268558383943, 0.00021798282736590154, 0.00019794858751801108, 0.00017931316863905282, 0.00016283639509528217, 0.00014807092631992228, 0.00013449283252894856, 0.00012216848346055338, 0.00011095843534823392, 0.00010146478609975346, 9.229041828691773e-05, 8.384821051941085e-05, 7.645115074416538e-05, 6.939793535343839e-05, 6.3585079224834e-05, 5.7962137186183256e-05, 5.295885820165221e-05, 4.872741817677374e-05, 4.456770443604265e-05, 4.1451151190320985e-05, 3.804695148776873e-05, 3.476881493785405e-05, 3.20241415650023e-05, 2.932175619032154e-05, 2.7189914930142963e-05, 2.5199652619823407e-05, 2.3228183467667177e-05, 2.1340111459363212e-05, 1.9693222263593607e-05, 1.8221209122878784e-05, 1.6828200870264065e-05, 1.54305078866782e-05, 1.4353907497335477e-05, 1.3456341415030805e-05, 1.26741097797699e-05, 1.2004198805062862e-05, 1.1178428084228978e-05, 1.0387668386907426e-05, 9.883361397124322e-06, 9.374900018557668e-06, 8.870671518114531e-06, 8.100081422969553e-06, 7.65851580621273e-06, 7.263635628610816e-06, 6.727950833122763e-06, 6.269398490298784e-06, 5.788071010941783e-06, 5.363047633143229e-06, 5.1274394286737195e-06, 4.725714480486705e-06, 4.458459992501399e-06, 4.126966796443802e-06, 4.007386084274655e-06, 4.026298901253186e-06, 4.013735228347399e-06, 3.944692061669113e-06, 3.805237920822052e-06, 3.692170682252662e-06, 3.6091614815932047e-06, 3.536692598805636e-06, 3.4167701841212124e-06, 3.189344491668112e-06, 2.9427753905899554e-06, 2.7543700251909456e-06, 2.7105704305343597e-06, 2.4960841150195705e-06, 2.511233643137289e-06, 2.528801716573516e-06, 2.401807284364263e-06, 2.2466161711715306e-06, 2.1833797843975863e-06, 2.139448014507295e-06, 1.971863465146782e-06, 1.8859047717197238e-06, 1.8968996889721627e-06, 1.7589534024070419e-06, 1.7064061851485194e-06, 1.679306210405661e-06, 1.6008532359803012e-06, 1.5857936680049827e-06, 1.5264056532783951e-06, 1.5961458881287387e-06, 1.7092030593049048e-06, 1.6137744265431034e-06, 1.459901770556291e-06, 1.33180620065017e-06, 1.3417947535203585e-06, 1.3011768634380333e-06, 1.2507332669109817e-06, 1.269672054905007e-06, 1.148569580981162e-06, 1.0928069509211227e-06, 1.0174275296103997e-06, 1.0723362997126306e-06, 9.700334818775522e-07, 1.0101771855453226e-06, 1.024873485538345e-06, 9.501196417554382e-07, 9.512693093561254e-07, 8.842651992640635e-07, 8.800671268525227e-07, 8.37253819771788e-07, 8.329967939253249e-07, 9.450081649023266e-07, 9.97889124373291e-07, 9.903754987291013e-07, 9.17442229621585e-07], "duration": 221266.776525, "accuracy_train": [0.537600720399594, 0.6436520193106312, 0.7425258181639904, 0.7844861024593945, 0.804804658660945, 0.8241026728036176, 0.8382585031953673, 0.8500706196359358, 0.8595765128968254, 0.8654129968969176, 0.8713871873846438, 0.876083987979882, 0.881711929563492, 0.884640175110742, 0.8894525121700813, 0.8922884727413253, 0.8956141565153194, 0.8980544813007567, 0.9017053254198967, 0.9041470921580842, 0.907121480193337, 0.9092845895625692, 0.9110756751222776, 0.913073861145718, 0.9140983685746585, 0.9157710337647655, 0.9195145233480989, 0.9197459567644887, 0.9210723730504798, 0.923930864133444, 0.925187886443337, 0.9253266743955334, 0.9257226706695275, 0.9271628209786821, 0.929047272978959, 0.9300463659906791, 0.9315802432285898, 0.9311620769310631, 0.9320223819905868, 0.9340227309431525, 0.9342083823597268, 0.9355569686692506, 0.936672319121447, 0.9376259906215393, 0.9387656740263934, 0.9394632186692506, 0.9398348819905868, 0.9404619511927832, 0.9405560386097268, 0.9419514883836286, 0.9424386881690661, 0.9445774645856404, 0.9443689221691584, 0.9454849935977298, 0.9456473935262089, 0.945506803133075, 0.9454148786452565, 0.9480884392880213, 0.9477160549903102, 0.9482962607281286, 0.948646475002307, 0.949413053133075, 0.9500887882405868, 0.9521567287283131, 0.9510170453234589, 0.9516916989664084, 0.9524815285852714, 0.9516433935492802, 0.952645730954688, 0.953620851501938, 0.9540862417520304, 0.9542024991925065, 0.9539463723352714, 0.9543183961447952, 0.9553182101328904, 0.9551772592515688, 0.9553872436208011, 0.957038820251938, 0.9565276480020304, 0.9570148477874677, 0.9570152082756552, 0.957666249942322, 0.9572709746447029, 0.9580608042635659, 0.9585498064899409, 0.9585487250253784, 0.9587583489064231, 0.9589211093230897, 0.9601301867040422, 0.959619374942322, 0.9596182934777593, 0.9602700561208011, 0.9598529712878369, 0.9610834977159468, 0.960757616394426, 0.9611528916920451, 0.9619205512873754, 0.9616400914774824, 0.9629657867870985, 0.9623619690729974, 0.9621984876799556, 0.9628738622992802, 0.962663877930048, 0.9635245434777593, 0.9636862224298633, 0.9635939374538575, 0.9635699649893872, 0.9639183768226283, 0.9641752246562385, 0.9642431766795865, 0.9640578857511997, 0.9647325393941492, 0.9651281751799556, 0.9654300840370063, 0.9657548838939645, 0.9654762265250092, 0.9655463414774824, 0.9662674980966224, 0.966383395048911, 0.9664992920011997, 0.9656622384297711, 0.9666616919296788, 0.966870955322536, 0.9664992920011997, 0.9667321673703396, 0.9666155494416758, 0.966777949370155, 0.9674293515250092, 0.9668949277870063, 0.9674057395487264, 0.9671735851559615, 0.9679637752630121, 0.9684989199773901, 0.968637347441399, 0.9686852923703396, 0.9686391498823367, 0.9688480527870063, 0.9690798466915835, 0.9692651376199704, 0.969265498108158, 0.9689417797157622, 0.9688244408107235, 0.9691020167151162, 0.9697301673818751, 0.9690791257152085, 0.9700807421442414, 0.9702649516080657, 0.9698925673103543, 0.9697999218461609, 0.9702645911198781, 0.9704513240010151, 0.9699161792866371, 0.9703819300249169, 0.9708705717631044, 0.9702885635843485, 0.9707768448343485, 0.9709861082272055, 0.9708465992986341, 0.971218623108158, 0.9711259776439645, 0.9717530468461609, 0.9720789281676817, 0.9714282469892026, 0.9708927417866371, 0.971078753691399, 0.9719386982627353, 0.9718231617986341, 0.9718464132867294, 0.9722645795842562, 0.9713813835248246, 0.9719619497508305, 0.9718464132867294, 0.9726133519056847, 0.9716600408937799, 0.9726838273463455, 0.9727067183462532, 0.9722413280961609, 0.9727753913459765, 0.9724040885128276, 0.9728683972983574, 0.9727063578580657, 0.9730082667151162, 0.9736356964055003, 0.9735895539174971, 0.9734504054771133, 0.9730776606912146], "end": "2016-02-03 05:08:43.785000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0], "moving_var_accuracy_valid": [0.025062164059072394, 0.05250544952166337, 0.08163905666743093, 0.10514991161000317, 0.1221412300236391, 0.13346350671999818, 0.14031028134978168, 0.1429810244507128, 0.14264065599933978, 0.13967325543482512, 0.13530596425852626, 0.12968275242270697, 0.12323922391366376, 0.11630245097104823, 0.10926531726459711, 0.10210553041290435, 0.09505590328958557, 0.08811437034273403, 0.08133940108198197, 0.07494037178390996, 0.06886514137051221, 0.06320890459324734, 0.05782495276886115, 0.05279936141438978, 0.04813858476278266, 0.04384598032962733, 0.0399033893594159, 0.03624656523611463, 0.03288825466365725, 0.029831702124404894, 0.027048921577862317, 0.024494441024979625, 0.022172345865442773, 0.020060009951311297, 0.018149284986246985, 0.016414780707635662, 0.014843875229048582, 0.013403119511863576, 0.01210788450799575, 0.010936849937484167, 0.009874951310609625, 0.008915448574788588, 0.008042903496027836, 0.007253153052853809, 0.006547056844683028, 0.005904665634766911, 0.005322834159992611, 0.004798948893317748, 0.004325511169402441, 0.0039009696607743513, 0.0035187667566503496, 0.0031720255117913083, 0.002858689264119217, 0.002578383749905376, 0.0023265900234287124, 0.002097710259189814, 0.0018924684203133386, 0.0017070439138538284, 0.00153894157249505, 0.0013877101712849338, 0.0012499059858711308, 0.001126793077054235, 0.0010158450125463785, 0.0009173720340150131, 0.0008284951302020922, 0.0007464009783907564, 0.0006719912511196673, 0.0006051339227270484, 0.000545693364938469, 0.0004922875873749734, 0.0004439373279311183, 0.0004005237723859244, 0.000360481560413617, 0.00032512904756298064, 0.00029286047469129515, 0.0002640202298635779, 0.00023770558223466256, 0.000214450319907217, 0.0001936825929490882, 0.0001747201035022705, 0.00015761633964448513, 0.00014207834733748068, 0.000128021830338238, 0.00011531791396070584, 0.00010393977942800426, 9.383298737572856e-05, 8.447301133549506e-05, 7.603466840582355e-05, 6.854996395268545e-05, 6.17124931810202e-05, 5.555471318636502e-05, 5.0031924138988576e-05, 4.5053232456831464e-05, 4.0552483325460635e-05, 3.6622775640134995e-05, 3.3038437215099694e-05, 2.988791708282215e-05, 2.694026785990673e-05, 2.447530838604899e-05, 2.208910476357978e-05, 1.988131443870924e-05, 1.809482076682554e-05, 1.629044500486068e-05, 1.466594342077184e-05, 1.3201769938826743e-05, 1.2139781845626505e-05, 1.1290372065485074e-05, 1.0346633851268207e-05, 9.315009157444849e-06, 8.44577541327547e-06, 7.623044920625454e-06, 7.012352836940348e-06, 6.409597940277755e-06, 5.7746598475095535e-06, 5.244262049844661e-06, 4.7603970574613805e-06, 4.678106396095744e-06, 4.249711463989679e-06, 3.8392522052197356e-06, 3.46771641009668e-06, 3.1396584919707015e-06, 2.8400997891725746e-06, 2.5780888879379378e-06, 2.320448884775973e-06, 2.1167359224626948e-06, 2.1394801901818037e-06, 2.264529578502429e-06, 2.515090330091829e-06, 2.2710738048830704e-06, 2.057082271695328e-06, 1.9666136913286845e-06, 2.061391416350012e-06, 1.890116667223044e-06, 1.7730987536990902e-06, 1.7410060649675172e-06, 2.2990623489846804e-06, 2.1045866424807486e-06, 1.9101682733665585e-06, 1.860911200740258e-06, 1.862545161650468e-06, 1.7935808686995881e-06, 1.9094213514883377e-06, 1.719372195186314e-06, 1.660484199959906e-06, 1.518809473703926e-06, 1.370660447285379e-06, 1.3503358486852516e-06, 1.2767995341140869e-06, 1.238384947136422e-06, 1.1145870431280557e-06, 1.3978798909779132e-06, 1.409051266697448e-06, 1.268549810889851e-06, 1.474763100045999e-06, 1.3325729447713585e-06, 1.2138983000143105e-06, 1.225755688074199e-06, 1.1168931817485662e-06, 1.1069278743651557e-06, 9.975574983840513e-07, 9.03506019449778e-07, 8.278711840591048e-07, 9.376010260421679e-07, 9.362560204616968e-07, 8.987887869110616e-07, 8.217290174432411e-07, 8.094167285463339e-07, 1.0172088972403028e-06, 1.0463641264269336e-06, 9.546922423767e-07, 8.652356631736797e-07, 8.871000812859377e-07, 9.36881446561838e-07, 9.54425826236933e-07, 8.609031035955545e-07, 1.2715436059033002e-06, 1.2546649538156657e-06, 1.1605997657175488e-06, 1.0551572331338116e-06, 9.525303026229816e-07, 8.964597499410172e-07, 8.629993929431355e-07, 8.346297176952214e-07, 7.881809363123404e-07, 7.187371366063223e-07, 1.411220498880535e-06], "accuracy_test": 0.8358896683673469, "start": "2016-01-31 15:40:57.008000", "learning_rate_per_epoch": [0.0008475072681903839, 0.00042375363409519196, 0.00028250241302885115, 0.00021187681704759598, 0.00016950145072769374, 0.00014125120651442558, 0.00012107246584491804, 0.00010593840852379799, 9.416747343493626e-05, 8.475072536384687e-05, 7.704611198278144e-05, 7.062560325721279e-05, 6.519286398543045e-05, 6.053623292245902e-05, 5.6500484788557515e-05, 5.2969204261898994e-05, 4.985336636309512e-05, 4.708373671746813e-05, 4.4605643779505044e-05, 4.2375362681923434e-05, 4.035748861497268e-05, 3.852305599139072e-05, 3.684814146254212e-05, 3.5312801628606394e-05, 3.390029087313451e-05, 3.2596431992715225e-05, 3.138915781164542e-05, 3.026811646122951e-05, 2.9224387617432512e-05, 2.8250242394278757e-05, 2.733894325501751e-05, 2.6484602130949497e-05, 2.5682038540253416e-05, 2.492668318154756e-05, 2.4214492441387847e-05, 2.3541868358734064e-05, 2.2905602236278355e-05, 2.2302821889752522e-05, 2.173095526813995e-05, 2.1187681340961717e-05, 2.0670908270403743e-05, 2.017874430748634e-05, 1.970947050722316e-05, 1.926152799569536e-05, 1.883349432318937e-05, 1.842407073127106e-05, 1.803206941985991e-05, 1.7656400814303197e-05, 1.7296066289418377e-05, 1.6950145436567254e-05, 1.6617788787698373e-05, 1.6298215996357612e-05, 1.599070310476236e-05, 1.569457890582271e-05, 1.540922312415205e-05, 1.5134058230614755e-05, 1.4868548532831483e-05, 1.4612193808716256e-05, 1.436452930647647e-05, 1.4125121197139379e-05, 1.3893561117583886e-05, 1.3669471627508756e-05, 1.3452496204990894e-05, 1.3242301065474749e-05, 1.3038573342782911e-05, 1.2841019270126708e-05, 1.26493623611168e-05, 1.246334159077378e-05, 1.2282714124012273e-05, 1.2107246220693924e-05, 1.193672142107971e-05, 1.1770934179367032e-05, 1.1609688044700306e-05, 1.1452801118139178e-05, 1.1300096957711503e-05, 1.1151410944876261e-05, 1.1006587556039449e-05, 1.0865477634069975e-05, 1.0727940207289066e-05, 1.0593840670480859e-05, 1.0463052603881806e-05, 1.0335454135201871e-05, 1.0210930668108631e-05, 1.008937215374317e-05, 9.970673090720084e-06, 9.85473525361158e-06, 9.74146223597927e-06, 9.63076399784768e-06, 9.522553227725439e-06, 9.416747161594685e-06, 9.313266673416365e-06, 9.21203536563553e-06, 9.112981388170738e-06, 9.016034709929954e-06, 8.92112893779995e-06, 8.828200407151598e-06, 8.737188181839883e-06, 8.648033144709188e-06, 8.560678907088004e-06, 8.475072718283627e-06, 8.391160918108653e-06, 8.308894393849187e-06, 8.228225851780735e-06, 8.149107998178806e-06, 8.071497177297715e-06, 7.99535155238118e-06, 7.920628377178218e-06, 7.847289452911355e-06, 7.775295671308413e-06, 7.704611562076025e-06, 7.635200745426118e-06, 7.567029115307378e-06, 7.50006438465789e-06, 7.434274266415741e-06, 7.369628292508423e-06, 7.306096904358128e-06, 7.243651907629101e-06, 7.182264653238235e-06, 7.121909675333882e-06, 7.062560598569689e-06, 7.004191957094008e-06, 6.946780558791943e-06, 6.890302756801248e-06, 6.834735813754378e-06, 6.780057901778491e-06, 6.726248102495447e-06, 6.673285497527104e-06, 6.621150532737374e-06, 6.56982365399017e-06, 6.5192866713914555e-06, 6.469520940299844e-06, 6.420509635063354e-06, 6.3722350205352996e-06, 6.3246811805584e-06, 6.277831289480673e-06, 6.23167079538689e-06, 6.1861842368671205e-06, 6.141357062006136e-06, 6.0971742641413584e-06, 6.053623110346962e-06, 6.010689503455069e-06, 5.968360710539855e-06, 5.926623998675495e-06, 5.885467089683516e-06, 5.844877705385443e-06, 5.804844022350153e-06, 5.765355581388576e-06, 5.726400559069589e-06, 5.68796804145677e-06, 5.6500484788557515e-06, 5.612630957330111e-06, 5.5757054724381305e-06, 5.539262929232791e-06, 5.503293778019724e-06, 5.467788923851913e-06, 5.432738817034988e-06, 5.398135272116633e-06, 5.363970103644533e-06, 5.33023421667167e-06, 5.296920335240429e-06, 5.264020273898495e-06, 5.231526301940903e-06, 5.199431143410038e-06, 5.167727067600936e-06, 5.136407708050683e-06, 5.1054653340543155e-06, 5.07489357914892e-06, 5.044686076871585e-06, 5.014836006012047e-06, 4.985336545360042e-06, 4.9561826926947106e-06, 4.92736762680579e-06, 4.898885890725069e-06, 4.870731117989635e-06, 4.84289876112598e-06, 4.81538199892384e-06, 4.788176738657057e-06, 4.761276613862719e-06, 4.734677531814668e-06, 4.708373580797343e-06, 4.682360668084584e-06, 4.6566333367081825e-06, 4.631187039194629e-06, 4.606017682817765e-06, 4.581120265356731e-06, 4.556490694085369e-06], "accuracy_train_first": 0.537600720399594, "accuracy_train_last": 0.9730776606912146, "batch_size_eval": 1024, "accuracy_train_std": [0.01937461927680501, 0.01929571362990856, 0.018416384048428387, 0.017183495316764552, 0.01812355900089687, 0.014612118110280426, 0.014766020900087048, 0.014167254011144563, 0.015097281918952786, 0.013603842338823374, 0.013443336455904372, 0.012825365270320951, 0.010736303116438693, 0.011716855437514948, 0.011614021087566893, 0.011987905283645177, 0.011465766918874784, 0.0113594016913397, 0.010486444383681817, 0.010534452614943906, 0.009900099086474995, 0.010226083009326628, 0.010106069799272728, 0.009953523969194356, 0.009240892958243214, 0.010148361623960494, 0.009862968128583546, 0.009147821150825935, 0.00948269723512054, 0.009453488410855323, 0.009181001703224691, 0.009600642954992376, 0.008861793504464163, 0.009443550326517225, 0.007779482087029538, 0.008736470741013845, 0.008929406053691035, 0.008690968655387021, 0.008793133450259148, 0.00824945550758638, 0.008066984226043043, 0.007655228132477803, 0.007647513439583236, 0.00745686592519755, 0.007592262933153147, 0.007454650353616066, 0.007302414464394554, 0.007691869328713933, 0.007110801966868746, 0.007329499765670314, 0.00706087908307536, 0.00651798206384516, 0.007372329189115947, 0.006525870924832772, 0.006883022411920762, 0.007022066540700713, 0.006830829721311121, 0.006326039859358408, 0.00643676081156206, 0.006774443099495257, 0.006429011466493788, 0.0065661160375233485, 0.005909853288035876, 0.0058482495739256984, 0.006347036694348546, 0.006014425055169454, 0.0065748150171860914, 0.006772700554153169, 0.005977320525896842, 0.005848096619063088, 0.005900218267156062, 0.006109259127634049, 0.006052476618206877, 0.005658871004040217, 0.00537885021349592, 0.006755684316033824, 0.0055398519638639255, 0.0056691230603095714, 0.005563074756981654, 0.006290359627962105, 0.00614973281979954, 0.005862897830009316, 0.005847826755787976, 0.00616134469302065, 0.00560186295568454, 0.005983858887194345, 0.0059041121386230865, 0.006072980620863262, 0.005509057042475097, 0.005902961249663074, 0.005613139033023929, 0.006099833310372455, 0.004981899880710737, 0.005121960940042881, 0.005466023914455824, 0.005940559144973954, 0.005776931238026493, 0.005819550620986284, 0.005790232191962489, 0.0055013497612901125, 0.006043797097583636, 0.0055369617122075325, 0.005655826259125896, 0.005584529889841697, 0.005782355607378046, 0.005283189518133703, 0.005563312381330863, 0.005990365487303684, 0.00539821539089323, 0.0059419549200845625, 0.00605167375697681, 0.006046234747596755, 0.00565684599567097, 0.005697038758513851, 0.006200062487167234, 0.00568521869293331, 0.005697837234787526, 0.005986978465934399, 0.005696526365413609, 0.006386644482253619, 0.006120128208716897, 0.005308265885124244, 0.00590668265794558, 0.005844563336173445, 0.005330711296441831, 0.005577078310336378, 0.005699748890437054, 0.005778695272305849, 0.00515037994257119, 0.005637036596001704, 0.005724148874800154, 0.006083324008099857, 0.005763024787104875, 0.005820856447895555, 0.005739170235919002, 0.005811598296259097, 0.00582704398778578, 0.005801385279079127, 0.005622171495866187, 0.0057808336022481515, 0.005370970643185701, 0.0057205766919083975, 0.005580439745389335, 0.005588500911581657, 0.005976352718314957, 0.0050067843233204635, 0.005761027617117987, 0.006204628856420185, 0.005929098056415767, 0.005254411991712111, 0.0052263919470783805, 0.005839677809610092, 0.005772946774538444, 0.005270634107293988, 0.006010855361596208, 0.0058117453275523725, 0.005803363880378388, 0.005866832441861776, 0.005534649996723097, 0.00489301527327804, 0.005411269454229069, 0.005194648519390955, 0.004988874944350291, 0.0055520316661333185, 0.006017881173530014, 0.0059690541100240295, 0.005292328050938483, 0.005280908153759476, 0.00556675019832817, 0.005432042569253382, 0.0058079582870311725, 0.0057066221519479045, 0.005937184131534397, 0.005175820153664066, 0.005272941213225154, 0.005654198936138043, 0.005550766395685301, 0.005157293992499621, 0.0053162880079064495, 0.0053742846692541365, 0.005115356519696103, 0.005638896777431375, 0.005603330541198425, 0.004846518492135417, 0.0053546429875896565, 0.005596087316462295], "accuracy_test_std": 0.006147039426864596, "error_valid": [0.47229886342243976, 0.3703657403049698, 0.2714446653802711, 0.23448677522590367, 0.21557470114834332, 0.20173957548945776, 0.18831184111445776, 0.18383494917168675, 0.17773143354668675, 0.17787409403237953, 0.17013218891189763, 0.1676598974021084, 0.16517731080572284, 0.1628476797816265, 0.1571309652673193, 0.15586908179593373, 0.15258347844503017, 0.15246140813253017, 0.15394684205572284, 0.15048769295933728, 0.14988763648343373, 0.14597109139683728, 0.14916550969503017, 0.14928758000753017, 0.1488801887236446, 0.14742564006024095, 0.14583872599774095, 0.14803599162274095, 0.14842279273343373, 0.14658144295933728, 0.14511659920933728, 0.14670351327183728, 0.1458799063441265, 0.14559458537274095, 0.14378412085843373, 0.14317376929593373, 0.14207513648343373, 0.14525925969503017, 0.14269578313253017, 0.14182070077183728, 0.14194277108433728, 0.14122064429593373, 0.14256341773343373, 0.14292962867093373, 0.13975580054593373, 0.14121034920933728, 0.14194277108433728, 0.14109857398343373, 0.14132212443524095, 0.13951165992093373, 0.13863657756024095, 0.13951165992093373, 0.13975580054593373, 0.13779238045933728, 0.1366731574736446, 0.13756883000753017, 0.1363069465361446, 0.13617458113704817, 0.13666286238704817, 0.1360628059111446, 0.13768060523343373, 0.1360628059111446, 0.1357877800263554, 0.13385524519954817, 0.13350962443524095, 0.13568629988704817, 0.13669374764683728, 0.1361848762236446, 0.13448618693524095, 0.13399790568524095, 0.1341096809111446, 0.1336213996611446, 0.13692759318524095, 0.13384495011295183, 0.13469944230045183, 0.1339567253388554, 0.13497446818524095, 0.1334684440888554, 0.13287868269954817, 0.1332243034638554, 0.13311252823795183, 0.13335666886295183, 0.13347873917545183, 0.13360080948795183, 0.13323459855045183, 0.13262424698795183, 0.13372287980045183, 0.1338655402861446, 0.13300075301204817, 0.1344758918486446, 0.13446559676204817, 0.1347200324736446, 0.13469944230045183, 0.13445530167545183, 0.13307134789156627, 0.13320371329066272, 0.1327360222138554, 0.13323459855045183, 0.1322477409638554, 0.1328580925263554, 0.1337125847138554, 0.13211537556475905, 0.1332243034638554, 0.13321400837725905, 0.13358021931475905, 0.13173886954066272, 0.13125058829066272, 0.13162709431475905, 0.1331022331513554, 0.13210508047816272, 0.1333463737763554, 0.1342008659638554, 0.1340787956513554, 0.13287868269954817, 0.1338346550263554, 0.13251247176204817, 0.1352083137236446, 0.1339876105986446, 0.13299045792545183, 0.13372287980045183, 0.13384495011295183, 0.1338346550263554, 0.1329801628388554, 0.1334684440888554, 0.13286838761295183, 0.1317594597138554, 0.1312711784638554, 0.13532008894954817, 0.13295957266566272, 0.13283750235316272, 0.13431264118975905, 0.13149472891566272, 0.1324918815888554, 0.13394643025225905, 0.13187123493975905, 0.13016225056475905, 0.13335666886295183, 0.1323698112763554, 0.13149472891566272, 0.13406850056475905, 0.13162709431475905, 0.13446559676204817, 0.1327360222138554, 0.13394643025225905, 0.13345814900225905, 0.13319341820406627, 0.13187123493975905, 0.13372287980045183, 0.13198301016566272, 0.1328580925263554, 0.1307828972138554, 0.13137265860316272, 0.13247129141566272, 0.13445530167545183, 0.13248158650225905, 0.1331022331513554, 0.1339567253388554, 0.13247129141566272, 0.1317594597138554, 0.13283750235316272, 0.1329801628388554, 0.13234922110316272, 0.13125058829066272, 0.13358021931475905, 0.13345814900225905, 0.1323698112763554, 0.1335905144013554, 0.13100644766566272, 0.13382435993975905, 0.13235951618975905, 0.13295957266566272, 0.13382435993975905, 0.13159620905496983, 0.13382435993975905, 0.13296986775225905, 0.13518772355045183, 0.13418027579066272, 0.13259336172816272, 0.1334684440888554, 0.1329801628388554, 0.13248158650225905, 0.1338655402861446, 0.1339567253388554, 0.13259336172816272, 0.13284779743975905, 0.13605251082454817], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.016115684758144434, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.0008475072506046837, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.483856436773003e-08, "rotation_range": [0, 0], "momentum": 0.547631180906978}, "accuracy_valid_max": 0.869837749435241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8639474891754518, "accuracy_valid_std": [0.015644314537480317, 0.016056271963368233, 0.015270564932726742, 0.0147243699966484, 0.014800409169633487, 0.01292663985760935, 0.014055001429386397, 0.011165539807948842, 0.014126443688099314, 0.01202298802264155, 0.010496683922771366, 0.012079227287307766, 0.012983535940721196, 0.01651406891748834, 0.012245711300129762, 0.013655013184919292, 0.012286433148462153, 0.010538735873117041, 0.01089717704351796, 0.01124694936611549, 0.009100806639529842, 0.010150719600503007, 0.009468511144631726, 0.011301603750736947, 0.012764088072835932, 0.011297924214126464, 0.012156551386126589, 0.012802769313918261, 0.010325863242617942, 0.010262441434617053, 0.008609926279862089, 0.011070883062807332, 0.010572977625818795, 0.013058846841498991, 0.009021831958491064, 0.011330872086807015, 0.00992818841732051, 0.010052975924415392, 0.0088361198779369, 0.010347052678069745, 0.009420938175449358, 0.009483977053547015, 0.010142722624554583, 0.007634554257402324, 0.009168504669203135, 0.008708779954355783, 0.00891379557319317, 0.011903527331727672, 0.010921757955697175, 0.010375824589773638, 0.011407106130311973, 0.009424577877482252, 0.01027225145663502, 0.010147455891845267, 0.011897195733428333, 0.011073213025562838, 0.013097164317571538, 0.0129871899300353, 0.012915662251430277, 0.012433251065972194, 0.010938871774767317, 0.012614106590338786, 0.014369787238410026, 0.011938364250881964, 0.012900270933856857, 0.011639258654943186, 0.012228722649620695, 0.012443881339745807, 0.011475051979407905, 0.011851743972971085, 0.013616242196238504, 0.013255247079609407, 0.013522970998930713, 0.013056895898167517, 0.013957436105352923, 0.015193496461084347, 0.014854003436481723, 0.01544011152505709, 0.015044557997376992, 0.014517670291964168, 0.014608906075049714, 0.01522533031075873, 0.015364689124664611, 0.013981565203151757, 0.01606348250064233, 0.015084475815342073, 0.016058072207206828, 0.01468127173739435, 0.015314473783601517, 0.014975078277599698, 0.014079019777923064, 0.01505719169804877, 0.01475459949401404, 0.013686750025730058, 0.017339661453519097, 0.015033889317051706, 0.014629624926004392, 0.013113594587022215, 0.014504308375479811, 0.014018057286404501, 0.014044485645100063, 0.014925576127504047, 0.014369106314672142, 0.013167661998108994, 0.015285178013636167, 0.01542377375172561, 0.014438577443290157, 0.013806548617059313, 0.01226414602399131, 0.01526244410698606, 0.015776992537734912, 0.013910699662771406, 0.014231440496941486, 0.01242321675121899, 0.013626740113552839, 0.013331725608315791, 0.01294742206642389, 0.01252894273919706, 0.012609513840955756, 0.013034002736051263, 0.01201068219521322, 0.013018278793427486, 0.01295185157242417, 0.013073812987053873, 0.011915597194326548, 0.012937732872288743, 0.012379157902283852, 0.014159971033160171, 0.013969782753642386, 0.014161223586437397, 0.014591166846330828, 0.012670366056520154, 0.013436903552811526, 0.013509801351531113, 0.011736022738621616, 0.011667319339463057, 0.012012954030605257, 0.012112843225445077, 0.012903435220272048, 0.012494645194823422, 0.012280263922459544, 0.010590075110757467, 0.011603126244023577, 0.01310671188735991, 0.012846222680223231, 0.012911767141251732, 0.013144647612217427, 0.012454046547973672, 0.012636427288551627, 0.012593545013528553, 0.01313319344024413, 0.013160371041498881, 0.012334694686802856, 0.012066643067732148, 0.012034483712992355, 0.012166556287905228, 0.012354798289234433, 0.01260239712243216, 0.011565807893155602, 0.012827277498391267, 0.011331875114134846, 0.013533665931711451, 0.01330418228018848, 0.013947616998465731, 0.010721825196231917, 0.011692193578706482, 0.011023434386568182, 0.01291823071139852, 0.01305749260054933, 0.013088803582403902, 0.013909920924658533, 0.011991464971137825, 0.013783827160780086, 0.011831336986511731, 0.01312751591004536, 0.011181145312568792, 0.01318162836879793, 0.012694636325976134, 0.011979417741433799, 0.01285020835566448, 0.012074041268551492, 0.01139945042226831, 0.013320532008678655, 0.01311949107577976, 0.012250022674374748, 0.012940110655838798], "accuracy_valid": [0.5277011365775602, 0.6296342596950302, 0.7285553346197289, 0.7655132247740963, 0.7844252988516567, 0.7982604245105422, 0.8116881588855422, 0.8161650508283133, 0.8222685664533133, 0.8221259059676205, 0.8298678110881024, 0.8323401025978916, 0.8348226891942772, 0.8371523202183735, 0.8428690347326807, 0.8441309182040663, 0.8474165215549698, 0.8475385918674698, 0.8460531579442772, 0.8495123070406627, 0.8501123635165663, 0.8540289086031627, 0.8508344903049698, 0.8507124199924698, 0.8511198112763554, 0.852574359939759, 0.854161274002259, 0.851964008377259, 0.8515772072665663, 0.8534185570406627, 0.8548834007906627, 0.8532964867281627, 0.8541200936558735, 0.854405414627259, 0.8562158791415663, 0.8568262307040663, 0.8579248635165663, 0.8547407403049698, 0.8573042168674698, 0.8581792992281627, 0.8580572289156627, 0.8587793557040663, 0.8574365822665663, 0.8570703713290663, 0.8602441994540663, 0.8587896507906627, 0.8580572289156627, 0.8589014260165663, 0.858677875564759, 0.8604883400790663, 0.861363422439759, 0.8604883400790663, 0.8602441994540663, 0.8622076195406627, 0.8633268425263554, 0.8624311699924698, 0.8636930534638554, 0.8638254188629518, 0.8633371376129518, 0.8639371940888554, 0.8623193947665663, 0.8639371940888554, 0.8642122199736446, 0.8661447548004518, 0.866490375564759, 0.8643137001129518, 0.8633062523531627, 0.8638151237763554, 0.865513813064759, 0.866002094314759, 0.8658903190888554, 0.8663786003388554, 0.863072406814759, 0.8661550498870482, 0.8653005576995482, 0.8660432746611446, 0.865025531814759, 0.8665315559111446, 0.8671213173004518, 0.8667756965361446, 0.8668874717620482, 0.8666433311370482, 0.8665212608245482, 0.8663991905120482, 0.8667654014495482, 0.8673757530120482, 0.8662771201995482, 0.8661344597138554, 0.8669992469879518, 0.8655241081513554, 0.8655344032379518, 0.8652799675263554, 0.8653005576995482, 0.8655446983245482, 0.8669286521084337, 0.8667962867093373, 0.8672639777861446, 0.8667654014495482, 0.8677522590361446, 0.8671419074736446, 0.8662874152861446, 0.867884624435241, 0.8667756965361446, 0.866785991622741, 0.866419780685241, 0.8682611304593373, 0.8687494117093373, 0.868372905685241, 0.8668977668486446, 0.8678949195218373, 0.8666536262236446, 0.8657991340361446, 0.8659212043486446, 0.8671213173004518, 0.8661653449736446, 0.8674875282379518, 0.8647916862763554, 0.8660123894013554, 0.8670095420745482, 0.8662771201995482, 0.8661550498870482, 0.8661653449736446, 0.8670198371611446, 0.8665315559111446, 0.8671316123870482, 0.8682405402861446, 0.8687288215361446, 0.8646799110504518, 0.8670404273343373, 0.8671624976468373, 0.865687358810241, 0.8685052710843373, 0.8675081184111446, 0.866053569747741, 0.868128765060241, 0.869837749435241, 0.8666433311370482, 0.8676301887236446, 0.8685052710843373, 0.865931499435241, 0.868372905685241, 0.8655344032379518, 0.8672639777861446, 0.866053569747741, 0.866541850997741, 0.8668065817959337, 0.868128765060241, 0.8662771201995482, 0.8680169898343373, 0.8671419074736446, 0.8692171027861446, 0.8686273413968373, 0.8675287085843373, 0.8655446983245482, 0.867518413497741, 0.8668977668486446, 0.8660432746611446, 0.8675287085843373, 0.8682405402861446, 0.8671624976468373, 0.8670198371611446, 0.8676507788968373, 0.8687494117093373, 0.866419780685241, 0.866541850997741, 0.8676301887236446, 0.8664094855986446, 0.8689935523343373, 0.866175640060241, 0.867640483810241, 0.8670404273343373, 0.866175640060241, 0.8684037909450302, 0.866175640060241, 0.867030132247741, 0.8648122764495482, 0.8658197242093373, 0.8674066382718373, 0.8665315559111446, 0.8670198371611446, 0.867518413497741, 0.8661344597138554, 0.8660432746611446, 0.8674066382718373, 0.867152202560241, 0.8639474891754518], "seed": 941504751, "model": "residualv3", "loss_std": [0.3044113218784332, 0.2558302581310272, 0.2447671741247177, 0.23696368932724, 0.23555521667003632, 0.23018281161785126, 0.2269943654537201, 0.22141112387180328, 0.21839424967765808, 0.2149292528629303, 0.21258220076560974, 0.20857088267803192, 0.20513515174388885, 0.20235224068164825, 0.19859550893306732, 0.19425109028816223, 0.1945830136537552, 0.19192886352539062, 0.18855145573616028, 0.1874293088912964, 0.18480926752090454, 0.18304580450057983, 0.1797465831041336, 0.17990398406982422, 0.17768393456935883, 0.1774653196334839, 0.17494846880435944, 0.17350368201732635, 0.17358839511871338, 0.1696065366268158, 0.16707754135131836, 0.16771340370178223, 0.16542290151119232, 0.16426968574523926, 0.16367946565151215, 0.16159793734550476, 0.1600702553987503, 0.15936103463172913, 0.15969450771808624, 0.15799376368522644, 0.1571824699640274, 0.15512098371982574, 0.15581604838371277, 0.1522844284772873, 0.15161831676959991, 0.15276537835597992, 0.1505187451839447, 0.14842486381530762, 0.14903409779071808, 0.1487552672624588, 0.14742736518383026, 0.14612828195095062, 0.1457805335521698, 0.14665356278419495, 0.144151508808136, 0.14284229278564453, 0.14291363954544067, 0.14294415712356567, 0.1432405561208725, 0.14089056849479675, 0.14019091427326202, 0.13945354521274567, 0.14076676964759827, 0.13766218721866608, 0.1378556340932846, 0.1341990828514099, 0.13393810391426086, 0.13459470868110657, 0.1356801688671112, 0.1350717693567276, 0.13456350564956665, 0.1331590712070465, 0.13170182704925537, 0.130848228931427, 0.13028542697429657, 0.13035139441490173, 0.13077780604362488, 0.13172301650047302, 0.1319701224565506, 0.12875570356845856, 0.12858057022094727, 0.12733398377895355, 0.12717723846435547, 0.12548549473285675, 0.1254194676876068, 0.12581972777843475, 0.1261066049337387, 0.1256968230009079, 0.12484163790941238, 0.12625667452812195, 0.12407093495130539, 0.12393186241388321, 0.12321501970291138, 0.12324966490268707, 0.1240701675415039, 0.12034115940332413, 0.12092893570661545, 0.12015165388584137, 0.12224609404802322, 0.12040269374847412, 0.11970840394496918, 0.11828920245170593, 0.118026964366436, 0.11834999173879623, 0.1154811903834343, 0.11811023205518723, 0.11980530619621277, 0.11771316081285477, 0.11776341497898102, 0.11518824100494385, 0.11668363213539124, 0.11568544059991837, 0.11599898338317871, 0.1143275648355484, 0.11705374717712402, 0.11514663696289062, 0.1133161261677742, 0.11414536088705063, 0.11445023119449615, 0.11422674357891083, 0.11151145398616791, 0.11315590143203735, 0.11306793242692947, 0.11001896858215332, 0.11301128566265106, 0.11087824404239655, 0.11139781028032303, 0.10956556349992752, 0.1105288416147232, 0.10941999405622482, 0.10876651853322983, 0.10902240127325058, 0.10733558982610703, 0.11018981039524078, 0.11061128973960876, 0.10841482132673264, 0.10771849751472473, 0.10793950408697128, 0.1094924807548523, 0.10665085166692734, 0.1063481792807579, 0.10802171379327774, 0.10768269747495651, 0.10731819272041321, 0.10748114436864853, 0.10565553605556488, 0.10522845387458801, 0.10729066282510757, 0.10508453100919724, 0.1019965410232544, 0.10408206284046173, 0.10302245616912842, 0.10428252816200256, 0.10230802744626999, 0.10249260812997818, 0.10371054708957672, 0.10403216630220413, 0.1044720709323883, 0.100342757999897, 0.10323938727378845, 0.1020834818482399, 0.10332667827606201, 0.10170109570026398, 0.10141630470752716, 0.10132287442684174, 0.10090335458517075, 0.10033072531223297, 0.10087966918945312, 0.10182733833789825, 0.10204724222421646, 0.10082834959030151, 0.09872979670763016, 0.09808878600597382, 0.1006164699792862, 0.0982280895113945, 0.09952220320701599, 0.10087017714977264, 0.09831178188323975, 0.09851484000682831, 0.09919306635856628, 0.10050796717405319, 0.09824267029762268, 0.09762241691350937, 0.09620492905378342, 0.09589371085166931, 0.09821245819330215]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:33 2016", "state": "available"}], "summary": "3a49f194707e586c61f289aad31027e6"}