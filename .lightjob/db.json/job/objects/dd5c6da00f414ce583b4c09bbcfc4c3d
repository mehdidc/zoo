{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 16, "f3": 32, "nonlin": "rectify", "nbg1": 2, "nbg3": 2, "nbg2": 2, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.022316866279338484, 0.02512041591202351, 0.024782286493768995, 0.026641670937664043, 0.03140752509006395, 0.024498798587046674, 0.031205262083018742, 0.03172480409486105, 0.02753319744391455, 0.026399487560982336, 0.026778206956588765, 0.028697372046278296, 0.02693830815597892, 0.029877522915973648, 0.032696463155852985, 0.03298815501739067, 0.03178251417387234, 0.033104002498503524, 0.02942224771869838, 0.03259141623887201, 0.028593496694036647, 0.030319980505570984, 0.027187037654780987, 0.03583480486647958, 0.03388940093052027, 0.02554441912060201, 0.024783018603678715, 0.03307164999829223, 0.041497563607693334, 0.03594046849007561, 0.03261645809636953, 0.0325027804893671, 0.03289893367242847, 0.029600539921126035, 0.03112200676002603, 0.03321453004531442, 0.03196126411828998, 0.034978525459631836, 0.024469898434977277, 0.031906720733087084, 0.03280449232734649, 0.02666141332770911, 0.03781160788690247, 0.02844080014595549, 0.02671647858467167, 0.03200551217556507, 0.02583820513584091, 0.03112725317194676, 0.034067747757623355, 0.027581918317306615, 0.03676350027203318, 0.03419267379529644, 0.029516446436345236, 0.030443598322530355, 0.03269923759290503, 0.029094203976394773, 0.028692946025203336, 0.0276850016520845, 0.03089263184585053, 0.032914923166597554, 0.029350627586131144, 0.03121456355111399, 0.032150872976291545, 0.026998185339927542, 0.03695989130688718, 0.03385083179708643, 0.025265892430373613, 0.03125986857406293, 0.024557235696243865, 0.03514153848948346, 0.026080730832413884, 0.028344947085611527, 0.028143237703921402, 0.024617745218158977, 0.031102762344955338, 0.030489453867750503, 0.028454831443272887, 0.030235487683540088, 0.02806253591675866, 0.02939818800589375, 0.029202511650560127, 0.028159350307410045, 0.02925155345504395, 0.026407046469529797, 0.031018062062061674, 0.027033779535133837, 0.03404270753741763, 0.029881773480699123, 0.03327838058714432, 0.030706480277532342, 0.023964182334597076, 0.026506485143163894, 0.027409030597414095, 0.030832667785274992, 0.028732124202184184, 0.030088109594266627, 0.0299690799074919, 0.024686192374948165, 0.035895005539663585, 0.03235731840356167, 0.02694773585704458, 0.02749297072293419, 0.03190842662514607, 0.028692946025203333, 0.033060127061729415, 0.03171336389972694, 0.026448238850750188, 0.02153235255478484, 0.03375367862791136, 0.03426794027833148, 0.028832983219504133, 0.026719194916190528, 0.029848967734171814, 0.027100811077498472, 0.024713371325285522, 0.030125473415717564, 0.030070617031853982, 0.0315952888279594, 0.02888642133727616, 0.026503747011330427, 0.028473316679748496, 0.031099262080964706, 0.030286451290964092, 0.03217118235587696, 0.03334482957116075], "moving_avg_accuracy_train": [0.015632059487951804, 0.03671333772590361, 0.059762165850903604, 0.08146855468749999, 0.1053623618693524, 0.1305306625800075, 0.16010749090032, 0.1818908871416133, 0.20277371107805436, 0.22724408093410436, 0.2510887616961156, 0.2675061468216848, 0.2814746586455404, 0.29491934263038394, 0.30797023592758654, 0.3289686754372375, 0.3424220526224294, 0.3557607961553672, 0.37689828958199917, 0.3897614538466908, 0.39893572261864824, 0.41058817821822924, 0.4282643001554425, 0.43091744468809096, 0.4392446572975951, 0.4465203045196428, 0.4694016889773171, 0.4834813807723565, 0.48849591212283167, 0.4832151273864521, 0.48435003407551774, 0.4879646353366407, 0.4883704496644224, 0.48616367578231745, 0.4906746613667363, 0.504413106374641, 0.5132738476950082, 0.5244888198532182, 0.5351211690425951, 0.5469093156925524, 0.5533253118341406, 0.559459742247112, 0.5681127891067382, 0.5784654785695583, 0.5799115700198314, 0.5798929280780892, 0.5820904763847381, 0.5763428368787944, 0.577106990690915, 0.579023080025438, 0.5883788669024123, 0.5915844666579542, 0.5948013023716768, 0.6036193649055934, 0.6045690812764799, 0.6159777604982295, 0.6027751275206956, 0.611153488262602, 0.6202800445568237, 0.6221309934143944, 0.6327318059705453, 0.6335305380240932, 0.6247802703662622, 0.6349420211910817, 0.6334489485900457, 0.6372256651768243, 0.632132146098901, 0.6379654299829869, 0.6482252687617966, 0.647707617638629, 0.6505526314771758, 0.6493292583896991, 0.6484353009242232, 0.6539960441751744, 0.6666696701793438, 0.6688680081312889, 0.6626928037037021, 0.6666560158032114, 0.6728702146746975, 0.6726130313096373, 0.6708990738112037, 0.6816682590505654, 0.6839974798322559, 0.6856537371201147, 0.6643516352454526, 0.6560066449136784, 0.6572710971391781, 0.6673181779373084, 0.6685151063785173, 0.6752846424274126, 0.6731788061967194, 0.6788136740710234, 0.6857958232301862, 0.6761770842806615, 0.687550339708017, 0.6822459834480586, 0.6822936930851805, 0.6832025956140118, 0.6631974715947793, 0.6624062447666267, 0.6628919004104459, 0.6524785575079555, 0.6601034427210154, 0.6591462799248174, 0.6652854922937815, 0.6673916380945238, 0.6718544697669993, 0.6833893729409017, 0.6802942232974141, 0.6800876548833353, 0.6762472817142788, 0.6852650610729715, 0.6813422823753128, 0.6831299291377816, 0.6796700988746058, 0.6888279948606393, 0.6825863851336115, 0.69073258472266, 0.6937178729371409, 0.6712681488964389, 0.6753809800911323, 0.672100694582019, 0.6697979105153834, 0.6693067301566162, 0.6713119569903523], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.002199251554513777, 0.005979109028375863, 0.010162434426960396, 0.013386696831194, 0.017186253342866477, 0.021168618254537495, 0.026924855390486904, 0.028503017017684935, 0.02957754633596001, 0.032008982710390925, 0.0339252036451319, 0.032958458089870045, 0.03141868618404179, 0.02990365331270839, 0.028446220324132254, 0.029570008448283266, 0.02824194782263832, 0.02701905175171189, 0.028338289231788882, 0.026993609262713956, 0.02505175320394358, 0.02376859537705107, 0.024203743419999035, 0.021846721661199237, 0.02028613172367428, 0.018733933933804067, 0.021572560332722743, 0.02119944378884016, 0.019305809131940233, 0.017626208405634024, 0.015875179683806594, 0.014405249795918139, 0.012966206983744021, 0.011713414944070282, 0.010725214368148767, 0.011351396772450879, 0.010922871725923959, 0.010962564957916397, 0.010883730105688365, 0.011046000708087637, 0.010311885695678737, 0.009619378254535169, 0.009331317408675625, 0.00936278927983035, 0.008445330976190291, 0.007600801006269189, 0.00688418387268277, 0.006493083724427055, 0.005849030731421555, 0.005297170243320254, 0.005555229951774505, 0.005092189784731628, 0.0046761030943402, 0.004908316826574763, 0.004425602794583454, 0.005154464169388138, 0.00620780341030449, 0.006218795427767697, 0.006346562153115312, 0.00574274004286386, 0.0061798610802332975, 0.005567616728250251, 0.005699959712178376, 0.0060593143593920306, 0.005473446315580504, 0.005054473977614088, 0.004782522009227206, 0.004610514616155501, 0.0050968417804444655, 0.004589569266567869, 0.004203459273584784, 0.0037965831216267643, 0.003424117249014809, 0.003360002313640319, 0.004469589247118294, 0.004066124530165125, 0.004002710424650992, 0.0037438028334971655, 0.0037169689586768594, 0.003345867352358546, 0.003037719469880623, 0.0037777256793697046, 0.003448780536481462, 0.0031285911766655828, 0.006899747957505356, 0.00683652293449146, 0.006167260195917453, 0.00645902866940315, 0.005826019541703208, 0.005655857152388519, 0.005130182353224163, 0.004902929741549511, 0.004851390429321731, 0.005198932637201478, 0.005843197824624181, 0.005512103800154796, 0.004960913906024585, 0.004472257449684372, 0.007626876587939793, 0.006869823288188109, 0.00618496371200866, 0.0065424067344514135, 0.006411415931617323, 0.00577851978402142, 0.0055398771622204475, 0.005025812097204264, 0.004702482686315478, 0.005429720338765681, 0.004972967866729355, 0.004476055114643674, 0.0041611857978777825, 0.004476950319148565, 0.004167749021630944, 0.0037797352479941333, 0.0035094955522446004, 0.003913349527039199, 0.0038726338021960295, 0.00408261553167795, 0.003754561490021827, 0.007915016326552723, 0.007275753117821844, 0.006645020263231344, 0.006028243567026168, 0.0054275905336271, 0.004921019892157003], "duration": 5251.523749, "accuracy_train": [0.15632059487951808, 0.22644484186746988, 0.2672016189759036, 0.27682605421686746, 0.3204066265060241, 0.3570453689759036, 0.42629894578313254, 0.377941453313253, 0.3907191265060241, 0.4474774096385542, 0.46569088855421686, 0.4152626129518072, 0.40719126506024095, 0.4159214984939759, 0.42542827560240964, 0.5179546310240963, 0.4635024472891566, 0.4758094879518072, 0.5671357304216867, 0.5055299322289156, 0.4815041415662651, 0.5154602786144579, 0.5873493975903614, 0.4547957454819277, 0.5141895707831325, 0.5120011295180723, 0.6753341490963856, 0.6101986069277109, 0.5336266942771084, 0.43568806475903615, 0.49456419427710846, 0.520496046686747, 0.4920227786144578, 0.4663027108433735, 0.531273531626506, 0.6280591114457831, 0.5930205195783133, 0.6254235692771084, 0.6308123117469879, 0.6530026355421686, 0.6110692771084337, 0.6146696159638554, 0.6459902108433735, 0.6716396837349398, 0.5929263930722891, 0.5797251506024096, 0.6018684111445783, 0.5246140813253012, 0.583984375, 0.5962678840361446, 0.6725809487951807, 0.6204348644578314, 0.6237528237951807, 0.6829819277108434, 0.6131165286144579, 0.7186558734939759, 0.48395143072289154, 0.686558734939759, 0.7024190512048193, 0.6387895331325302, 0.7281391189759037, 0.6407191265060241, 0.5460278614457831, 0.7263977786144579, 0.6200112951807228, 0.6712161144578314, 0.5862904743975904, 0.690464984939759, 0.7405638177710844, 0.6430487575301205, 0.6761577560240963, 0.6383189006024096, 0.6403896837349398, 0.7040427334337349, 0.7807323042168675, 0.6886530496987951, 0.6071159638554217, 0.7023249246987951, 0.7287980045180723, 0.6702983810240963, 0.6554734563253012, 0.7785909262048193, 0.7049604668674698, 0.7005600527108434, 0.47263271837349397, 0.5809017319277109, 0.6686511671686747, 0.7577419051204819, 0.6792874623493976, 0.7362104668674698, 0.6542262801204819, 0.729527484939759, 0.7486351656626506, 0.5896084337349398, 0.7899096385542169, 0.6345067771084337, 0.6827230798192772, 0.691382718373494, 0.48315135542168675, 0.655285203313253, 0.6672628012048193, 0.5587584713855421, 0.7287274096385542, 0.6505318147590361, 0.7205384036144579, 0.6863469503012049, 0.7120199548192772, 0.7872035015060241, 0.6524378765060241, 0.6782285391566265, 0.6416839231927711, 0.7664250753012049, 0.6460372740963856, 0.69921875, 0.6485316265060241, 0.7712490587349398, 0.6264118975903614, 0.7640483810240963, 0.7205854668674698, 0.4692206325301205, 0.7123964608433735, 0.642578125, 0.6490728539156626, 0.6648861069277109, 0.6893589984939759], "end": "2016-01-17 09:19:00.273000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0], "accuracy_valid": [0.1509967672413793, 0.22561961206896552, 0.26764547413793105, 0.27330280172413796, 0.31721443965517243, 0.3472521551724138, 0.4222790948275862, 0.36866918103448276, 0.38591056034482757, 0.43494073275862066, 0.45164331896551724, 0.4044989224137931, 0.3962823275862069, 0.40369073275862066, 0.4073275862068966, 0.5090247844827587, 0.4502963362068966, 0.46012931034482757, 0.544854525862069, 0.48518318965517243, 0.46066810344827586, 0.4982489224137931, 0.5695043103448276, 0.43103448275862066, 0.49690193965517243, 0.49151400862068967, 0.6376616379310345, 0.5824353448275862, 0.5053879310344828, 0.41783405172413796, 0.47238685344827586, 0.4971713362068966, 0.4703663793103448, 0.44342672413793105, 0.49757543103448276, 0.5894396551724138, 0.5658674568965517, 0.5889008620689655, 0.58984375, 0.6117995689655172, 0.576239224137931, 0.5665409482758621, 0.611260775862069, 0.6240571120689655, 0.5494342672413793, 0.5453933189655172, 0.5678879310344828, 0.4994612068965517, 0.5497036637931034, 0.5549568965517241, 0.6214978448275862, 0.5859375, 0.5792025862068966, 0.6333512931034483, 0.5657327586206896, 0.6593480603448276, 0.4535290948275862, 0.6371228448275862, 0.6495150862068966, 0.5914601293103449, 0.658135775862069, 0.5948275862068966, 0.5103717672413793, 0.6592133620689655, 0.5769127155172413, 0.6182650862068966, 0.548760775862069, 0.6345635775862069, 0.6803609913793104, 0.5953663793103449, 0.6140894396551724, 0.5897090517241379, 0.5889008620689655, 0.6417025862068966, 0.7174030172413793, 0.6375269396551724, 0.5571120689655172, 0.6450700431034483, 0.6636584051724138, 0.6185344827586207, 0.5984644396551724, 0.7047413793103449, 0.6433189655172413, 0.6376616379310345, 0.43615301724137934, 0.5470096982758621, 0.6197467672413793, 0.6819773706896551, 0.6241918103448276, 0.6640625, 0.5971174568965517, 0.6610991379310345, 0.6768588362068966, 0.5460668103448276, 0.7071659482758621, 0.5806842672413793, 0.6251346982758621, 0.6316002155172413, 0.45231681034482757, 0.6057381465517241, 0.6087015086206896, 0.5169719827586207, 0.6578663793103449, 0.5933459051724138, 0.658135775862069, 0.6255387931034483, 0.6439924568965517, 0.7048760775862069, 0.5946928879310345, 0.6200161637931034, 0.58984375, 0.6860183189655172, 0.5849946120689655, 0.6364493534482759, 0.5929418103448276, 0.6938308189655172, 0.5806842672413793, 0.689520474137931, 0.6448006465517241, 0.4397898706896552, 0.6421066810344828, 0.5930765086206896, 0.5868803879310345, 0.6038523706896551, 0.6232489224137931], "accuracy_test": 0.711738782051282, "start": "2016-01-17 07:51:28.749000", "learning_rate_per_epoch": [0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766, 0.0032907023560255766], "accuracy_train_last": 0.6893589984939759, "error_valid": [0.8490032327586207, 0.7743803879310345, 0.732354525862069, 0.7266971982758621, 0.6827855603448276, 0.6527478448275862, 0.5777209051724138, 0.6313308189655172, 0.6140894396551724, 0.5650592672413793, 0.5483566810344828, 0.5955010775862069, 0.6037176724137931, 0.5963092672413793, 0.5926724137931034, 0.4909752155172413, 0.5497036637931034, 0.5398706896551724, 0.45514547413793105, 0.5148168103448276, 0.5393318965517242, 0.5017510775862069, 0.4304956896551724, 0.5689655172413793, 0.5030980603448276, 0.5084859913793103, 0.3623383620689655, 0.4175646551724138, 0.49461206896551724, 0.5821659482758621, 0.5276131465517242, 0.5028286637931034, 0.5296336206896552, 0.556573275862069, 0.5024245689655172, 0.4105603448275862, 0.4341325431034483, 0.4110991379310345, 0.41015625, 0.38820043103448276, 0.42376077586206895, 0.4334590517241379, 0.38873922413793105, 0.3759428879310345, 0.45056573275862066, 0.45460668103448276, 0.43211206896551724, 0.5005387931034483, 0.4502963362068966, 0.4450431034482759, 0.3785021551724138, 0.4140625, 0.4207974137931034, 0.3666487068965517, 0.4342672413793104, 0.3406519396551724, 0.5464709051724138, 0.3628771551724138, 0.3504849137931034, 0.40853987068965514, 0.34186422413793105, 0.4051724137931034, 0.48962823275862066, 0.3407866379310345, 0.4230872844827587, 0.3817349137931034, 0.45123922413793105, 0.36543642241379315, 0.3196390086206896, 0.40463362068965514, 0.3859105603448276, 0.4102909482758621, 0.4110991379310345, 0.3582974137931034, 0.28259698275862066, 0.3624730603448276, 0.44288793103448276, 0.3549299568965517, 0.3363415948275862, 0.38146551724137934, 0.4015355603448276, 0.29525862068965514, 0.3566810344827587, 0.3623383620689655, 0.5638469827586207, 0.4529903017241379, 0.38025323275862066, 0.31802262931034486, 0.3758081896551724, 0.3359375, 0.4028825431034483, 0.3389008620689655, 0.3231411637931034, 0.4539331896551724, 0.2928340517241379, 0.41931573275862066, 0.3748653017241379, 0.3683997844827587, 0.5476831896551724, 0.3942618534482759, 0.3912984913793104, 0.48302801724137934, 0.34213362068965514, 0.4066540948275862, 0.34186422413793105, 0.3744612068965517, 0.3560075431034483, 0.29512392241379315, 0.4053071120689655, 0.3799838362068966, 0.41015625, 0.31398168103448276, 0.4150053879310345, 0.3635506465517241, 0.4070581896551724, 0.30616918103448276, 0.41931573275862066, 0.31047952586206895, 0.3551993534482759, 0.5602101293103448, 0.35789331896551724, 0.4069234913793104, 0.4131196120689655, 0.39614762931034486, 0.37675107758620685], "accuracy_train_std": [0.024430191929357203, 0.027519419766965675, 0.027961959564146145, 0.02904096364591758, 0.028479762838380197, 0.02808005435574802, 0.030219812800102937, 0.028455497120988143, 0.030260573768237476, 0.031471313768204924, 0.029918869146202367, 0.030655062693262094, 0.033954367645560174, 0.03189834142312587, 0.03088555337281578, 0.03263412422706555, 0.03151278422846316, 0.03262549483279825, 0.03219636489549992, 0.03138841135184003, 0.03285082485412925, 0.03276728927785351, 0.03246801696260862, 0.029685135178792555, 0.028593598807854233, 0.032857532905008355, 0.032035533188808474, 0.03180919763684612, 0.03262227837832459, 0.03237867153832202, 0.032007865078195835, 0.030413541689774753, 0.033783852249608136, 0.032110074891498204, 0.03224740474694876, 0.030978490328727574, 0.033269101435687974, 0.030963436004228788, 0.03265315682895627, 0.03012871687127065, 0.0327898164738241, 0.031910768363814235, 0.0321444085265628, 0.03053498528829845, 0.03162661983012101, 0.03388632654714655, 0.03352886856048899, 0.031785086995506404, 0.029384595080821137, 0.0330067196125776, 0.0325390920391738, 0.02931534481244579, 0.031688260024787494, 0.0298723409537783, 0.02962014918866708, 0.03118507883419795, 0.033553624030008423, 0.033029452338775946, 0.031957612254200844, 0.033478616302608837, 0.032154579198713076, 0.034875235988176254, 0.029915796665900465, 0.030925794989823136, 0.03276244733016697, 0.03255984689924248, 0.03201948859665685, 0.03466964932581195, 0.03224074150287834, 0.035115818191051404, 0.03163364874699339, 0.028431697598754944, 0.029215023696636058, 0.03247583567396289, 0.02925226324975135, 0.03154064084650863, 0.03281463168280824, 0.031392389249314465, 0.029620037020732144, 0.03142592995859592, 0.030689688912902947, 0.02962538321994613, 0.02903821780170148, 0.028336622054519842, 0.03480543936287257, 0.03137640404074833, 0.031117255204220207, 0.031024082463611956, 0.02966132351431653, 0.03050178105462324, 0.030622232782513463, 0.029937556356999784, 0.030114157139038353, 0.03167276506569569, 0.03008737238031741, 0.030979348312091485, 0.03024971137770603, 0.03066055350275022, 0.031199529266597272, 0.028888299166498824, 0.031816360260375647, 0.029660464743087103, 0.030600561852125865, 0.03115762409827643, 0.0313252177692536, 0.03401681172205295, 0.03166965292477912, 0.02848218341269574, 0.029964475034135768, 0.029919868559733845, 0.03196080897141731, 0.031518046553678444, 0.03290253244835772, 0.03021816362608724, 0.03342717034947546, 0.027917446051876356, 0.031141438366913875, 0.030248503187623066, 0.03222509979451144, 0.03324198531189754, 0.03377043388267642, 0.033028253622386566, 0.03301866232460736, 0.030487117960359134, 0.03430589143220455], "accuracy_test_std": 0.029126836775589922, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1.0, 1.2], "translation_range": [-3, 3], "momentum": 0.6925927286746609, "shear_range": [1, 1.1], "patience_check_each": 1, "learning_rate": 0.0032907023000052775, "patience_threshold": 1, "do_flip": true, "batch_size": 256, "optimization": "rmsprop", "nb_data_augmentation": 1, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 4.953954461895129e-07, "valid_ratio": 0.15, "rotation_range": [-90, 90], "learning_rate_decay": 0.9959376392464412}, "accuracy_valid_max": 0.7174030172413793, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.98, interval=[0.8, 1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256, 512],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1.0, 1.2)),\n        rotation_range=make_constant_param((-90, 90)),\n        shear_range=make_constant_param((1, 1.1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    instantiate = instantiate_random\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.6232489224137931, "loss_train": [2.111208200454712, 1.8722457885742188, 1.7279903888702393, 1.640682339668274, 1.5675641298294067, 1.5155630111694336, 1.4674155712127686, 1.4242513179779053, 1.3867651224136353, 1.3558474779129028, 1.3219012022018433, 1.2924848794937134, 1.2722628116607666, 1.2541160583496094, 1.2259135246276855, 1.1992510557174683, 1.171866536140442, 1.1654220819473267, 1.1483254432678223, 1.1188044548034668, 1.1010254621505737, 1.094594955444336, 1.078019380569458, 1.069371223449707, 1.0599925518035889, 1.0504429340362549, 1.0310304164886475, 1.0236130952835083, 1.0156495571136475, 1.0087376832962036, 1.0068321228027344, 0.9932271242141724, 0.9876641631126404, 0.9858475923538208, 0.980981171131134, 0.9720467925071716, 0.9607476592063904, 0.9522382616996765, 0.949013352394104, 0.945401668548584, 0.941023051738739, 0.938426673412323, 0.9278106689453125, 0.9255512952804565, 0.919747531414032, 0.9185290336608887, 0.9166672825813293, 0.9134692549705505, 0.909705638885498, 0.9043243527412415, 0.8970998525619507, 0.896872341632843, 0.890149712562561, 0.8867926597595215, 0.8773568272590637, 0.8804053664207458, 0.8826034665107727, 0.8710325360298157, 0.8686424493789673, 0.8678417801856995, 0.8663209676742554, 0.8626935482025146, 0.858652651309967, 0.8631277680397034, 0.8542216420173645, 0.8510481119155884, 0.8477843403816223, 0.8457117080688477, 0.8474951386451721, 0.8392406105995178, 0.838763415813446, 0.8451870679855347, 0.836451530456543, 0.8357312083244324, 0.833092987537384, 0.8300275802612305, 0.82610684633255, 0.8305314779281616, 0.8225753903388977, 0.8177737593650818, 0.8197763562202454, 0.8230944275856018, 0.8187607526779175, 0.8148717880249023, 0.811238169670105, 0.821888267993927, 0.811179518699646, 0.8098140954971313, 0.8028274178504944, 0.8037625551223755, 0.8055954575538635, 0.80595463514328, 0.7981674075126648, 0.7942495942115784, 0.7996185421943665, 0.800037145614624, 0.7956846952438354, 0.793408215045929, 0.7893205285072327, 0.8036824464797974, 0.7921048402786255, 0.7882304191589355, 0.790144145488739, 0.7828662395477295, 0.7899473905563354, 0.783396303653717, 0.7840093970298767, 0.7844972610473633, 0.7784658670425415, 0.7837952971458435, 0.7759949564933777, 0.7785161137580872, 0.775397777557373, 0.7707828283309937, 0.7722501754760742, 0.771258533000946, 0.7651099562644958, 0.7700278162956238, 0.7739919424057007, 0.765457808971405, 0.7794822454452515, 0.7691587209701538, 0.7672455310821533, 0.776212215423584, 0.7613344192504883], "accuracy_train_first": 0.15632059487951808, "model": "residual", "loss_std": [0.13432630896568298, 0.24208511412143707, 0.12824347615242004, 0.15503855049610138, 0.13122360408306122, 0.12924036383628845, 0.11291413009166718, 0.1102602407336235, 0.11366642266511917, 0.13966134190559387, 0.10142580419778824, 0.09590140730142593, 0.13985545933246613, 0.13890238106250763, 0.14017808437347412, 0.13986225426197052, 0.1072176843881607, 0.13329191505908966, 0.1251220554113388, 0.11033892631530762, 0.11785164475440979, 0.13037371635437012, 0.1276302933692932, 0.10166556388139725, 0.12375564873218536, 0.14507143199443817, 0.11789418011903763, 0.10899844765663147, 0.10626371204853058, 0.11762847751379013, 0.15123820304870605, 0.15436339378356934, 0.12083916366100311, 0.1632639616727829, 0.1591448336839676, 0.12508073449134827, 0.11767547577619553, 0.09600726515054703, 0.09859323501586914, 0.11818799376487732, 0.11503937840461731, 0.12849700450897217, 0.10455169528722763, 0.1073954701423645, 0.09667894244194031, 0.11982446163892746, 0.12157724797725677, 0.12342500686645508, 0.11736265569925308, 0.11491184681653976, 0.11740973591804504, 0.1028590053319931, 0.11434461921453476, 0.11273461580276489, 0.10480816662311554, 0.12026562541723251, 0.09852439165115356, 0.15072064101696014, 0.10333320498466492, 0.08715318143367767, 0.12353387475013733, 0.09201236814260483, 0.10527292639017105, 0.1419067531824112, 0.09671485424041748, 0.11400648951530457, 0.09893317520618439, 0.11761301010847092, 0.11251229792833328, 0.08542218804359436, 0.11311759799718857, 0.11989298462867737, 0.10679889470338821, 0.12047068774700165, 0.1000858023762703, 0.08587609231472015, 0.08837443590164185, 0.10148856043815613, 0.10359519720077515, 0.09455620497465134, 0.0980662852525711, 0.1067844107747078, 0.09576937556266785, 0.11603154987096786, 0.10542582720518112, 0.17443212866783142, 0.12114457786083221, 0.0989614874124527, 0.08695080131292343, 0.10583387315273285, 0.10239139199256897, 0.10487836599349976, 0.08700966089963913, 0.08687970042228699, 0.1360345333814621, 0.07976704835891724, 0.10438137501478195, 0.09305031597614288, 0.10463964194059372, 0.19522146880626678, 0.09644569456577301, 0.11400400847196579, 0.15980637073516846, 0.08606260269880295, 0.11150579899549484, 0.08997499942779541, 0.10612347722053528, 0.09592564404010773, 0.08831165730953217, 0.1196872666478157, 0.10725748538970947, 0.13877196609973907, 0.08185524493455887, 0.11328157782554626, 0.09714511781930923, 0.09730847179889679, 0.08734356611967087, 0.1114063709974289, 0.08635719120502472, 0.09078830480575562, 0.19902847707271576, 0.08469440788030624, 0.119693323969841, 0.14332300424575806, 0.0953008309006691]}, "state": "available", "life": [{"dt": "Sun May 15 22:04:57 2016", "state": "available"}], "summary": "c04ee9346c51246fccbc18707ec3c00f"}