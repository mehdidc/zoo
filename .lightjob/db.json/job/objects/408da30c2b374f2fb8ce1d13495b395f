{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 16, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 2, "nbg3": 2, "nbg2": 2, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.03349196178431046, 0.04353589139973086, 0.04171473164713741, 0.04238182306722056, 0.04377673242656522, 0.04517596233635488, 0.04194202374633193, 0.03972480299820423, 0.039828118655125956, 0.03782600042991697, 0.03934135197221694, 0.03775326197815831, 0.04011928846763396, 0.04222850026053774, 0.03946659482758621, 0.03886529628646074, 0.041650310001711925, 0.032226404155242805, 0.032229782008001445, 0.03231664011881557, 0.033596893172785414, 0.03922958654192107, 0.029821906245649874, 0.037983241969200825, 0.036414651874552395, 0.03646618435794355, 0.03369530611492398, 0.036769668789503517, 0.0353207543912912, 0.032876590503209284, 0.036065196102594864, 0.028729598190117046, 0.03046832124915567, 0.034447224164619095, 0.03796126258362595, 0.03537105937587788, 0.03273057238792254, 0.03152515236276018, 0.03416161789326856, 0.02932124989278837, 0.03191638624918079, 0.03250585054141338, 0.0356747054944454, 0.031963250920670316, 0.03096068512620397, 0.029903017241379313, 0.03677139578896116, 0.030293938707899076, 0.03352011994632201, 0.031108012002475108, 0.03212377383010429, 0.031234900855820702, 0.034771206102039404, 0.035865170777247025, 0.02822628002134958, 0.039271882355194965, 0.0362045312368817, 0.03186888334637756, 0.03257276146637795, 0.03356798866379832, 0.03120613421342746, 0.03464888969428952, 0.037296831299847566, 0.030706480277532342, 0.030250485892585506, 0.028482236293167183, 0.030292740845553494, 0.029319702883005835, 0.032550473107221325, 0.030305914727306194, 0.0301266779287592, 0.03219514221655664, 0.02667842090354967, 0.030950134942601137, 0.028362544397316142, 0.03168589057903476, 0.02794753897966141, 0.03218584227113126, 0.03275467698300956, 0.028842106138011022, 0.033908669045938734, 0.0320547937204525, 0.0307067757125362, 0.03136590426256009, 0.029845016462784323, 0.03360121320535731, 0.032356757671596674, 0.02850134035078039, 0.02998209342922879, 0.03182187969831741, 0.032540438364982285, 0.030776124295584285, 0.028502613499346047, 0.028454193807135545, 0.03272031562648486, 0.0332530187701725, 0.031715938303417505, 0.034892053766321665, 0.026561188503679615, 0.032542389807201505, 0.03087765174785361, 0.032172592253386895, 0.03134044210221526, 0.032095803871552926, 0.02832637807779077, 0.030388122095266323, 0.029364224137931032, 0.033057931761281314, 0.03030232241846344, 0.031923491379310345, 0.03323091367480447, 0.03557182294183483, 0.03120613421342746, 0.028433781900773194, 0.031028881517550025, 0.03276381546620392, 0.03172051450519852, 0.029143428038792194, 0.030663907920543524, 0.031095469683681678, 0.03120148256955307, 0.02607446903569582, 0.03291602560402913, 0.03247346083897372, 0.030519193300375873, 0.030203666849512846, 0.03340843108410639, 0.024032603504093628, 0.029400039452065308, 0.03159299174054294, 0.031045249737428258, 0.03202194778429969, 0.03320278347117489, 0.039003234247205004, 0.031378627594765444, 0.03055395169027359, 0.03395492134701538, 0.03311386646013502, 0.03553610107809264, 0.030676035232831196, 0.03483480756969148, 0.027031094815971837, 0.033696383020741474, 0.03142369607974416, 0.0273659695054342, 0.030466832484099, 0.030636677943466913, 0.03349954515625963, 0.03291602560402913, 0.03338479851790673, 0.03447039152219332, 0.036136562641822544, 0.029940915038259186, 0.02906768819240442, 0.035972258368104505, 0.03405736096472777, 0.02633652710613649, 0.03306369411408012, 0.032690358565494605, 0.034209119340518034, 0.029391398372116125, 0.031023910884933798, 0.029927580486991685, 0.028250695555741185, 0.03146783516571677, 0.03627687403646688, 0.03034301034873206, 0.032030162426071186, 0.03239290500573448, 0.029143428038792198, 0.030363035090931134, 0.029988144305865418, 0.030685497121971928, 0.032530400527298824, 0.03011613680620373, 0.03450695372878641, 0.031875429865838446, 0.02986780506796379, 0.026265818410638155, 0.028520749691194232, 0.028754848325233676, 0.03378672056970469, 0.03200069324227836, 0.030081174105570322, 0.02755888539611425, 0.029175783364056594, 0.030157075939167718, 0.02921586662412171, 0.031192177200725785, 0.02809129232966452, 0.0286540308798997, 0.029736303289971185, 0.028774086664287487, 0.03896297517550923, 0.02979360224865317, 0.02813130843588999, 0.029330839532247768, 0.03001596262752984, 0.028071909219350506, 0.027813155478655156, 0.028657829805700363, 0.026569725729973348, 0.02867934754676024, 0.03053613181724823, 0.0307855554225338, 0.03111880018397855, 0.032413902366493205, 0.032454179217775096, 0.028328940043886343, 0.028306194491633303, 0.033711186987172764, 0.031065989903288526, 0.032033560971998484, 0.029200647680282344, 0.030367815165754663, 0.02639845663302877, 0.031955019078036016, 0.03174081344084371, 0.03019195074454569, 0.02951982706775837, 0.02794494204709561, 0.028210848796494378, 0.029626578806730187, 0.029923639596038495, 0.029260235833770368, 0.030901146702077973, 0.03220190412625925, 0.026989783641427605, 0.030964494031320944, 0.02752759560607753, 0.02622572317821328, 0.03026367816806814, 0.028148072453406583, 0.02825872237064479, 0.030375282526742764, 0.030925797193395714, 0.028691681322347617, 0.02999540374660581, 0.0281454940236988, 0.02954777927412988, 0.02881315451193141, 0.02803925072183482, 0.030370503627222264, 0.03381973022947245, 0.030191950744545695, 0.032880729272607594, 0.03201316428454534, 0.027476137178842768, 0.030705298509091258, 0.02967155683045407, 0.03252900613819737, 0.03416984912868088, 0.030983238737243145, 0.030013544666585224, 0.028774086664287487, 0.036529814806000614, 0.02817255576588256, 0.029594409794955732, 0.02895355027515571, 0.029852310709162073, 0.03202336425218339, 0.03266620650948542, 0.030364528945147764, 0.02755888539611425, 0.032008629922272], "moving_avg_accuracy_train": [0.028235598644578308, 0.06182487763554216, 0.09449310523343371, 0.1282666862763554, 0.16575769460655118, 0.20368352529649847, 0.23857684445359562, 0.27467303802028425, 0.30826559867608716, 0.33817416682052664, 0.3667155603794378, 0.3988669523836627, 0.4249346999163808, 0.44675787149100776, 0.47236869955275035, 0.5001294764348247, 0.5197301394841134, 0.5459574267405214, 0.570274993554421, 0.5927326222110272, 0.6138622214357076, 0.6261652876957513, 0.6471401557635256, 0.6515832373257272, 0.6635404068160461, 0.6760055491163692, 0.6911633714637685, 0.7014168573595603, 0.7093978184609536, 0.7248991134220871, 0.7364147555437338, 0.7484048688447821, 0.7598477968699424, 0.7709112099540325, 0.7780939029646533, 0.7895870352585495, 0.7981353912206464, 0.8056265395985818, 0.814514657476073, 0.8218833159754536, 0.8302964527514022, 0.8384706854883102, 0.8398763466081539, 0.8472384860437241, 0.8539891291562192, 0.857968040035778, 0.8556990974779832, 0.8609824445072933, 0.8656950999059616, 0.870428300758739, 0.8765283547190097, 0.8765284748193979, 0.8773616024880605, 0.8825683074500978, 0.8878873426689434, 0.8860244367153021, 0.8913273017787117, 0.893704360757467, 0.8975991731756962, 0.9013162889906566, 0.9055935456337596, 0.9044943755583355, 0.9031474417675621, 0.9074627804221311, 0.9116477900305204, 0.9145859854250588, 0.9160231888403843, 0.9199780988720085, 0.9224409441052897, 0.9258576177670499, 0.9266571157795015, 0.9297721835690212, 0.931439167019348, 0.9340195537812687, 0.9344123084935032, 0.9354434985778878, 0.9369175033887737, 0.9388135730800168, 0.9385857361033404, 0.9400679004448136, 0.9425690170268383, 0.9448553193904194, 0.9470471217887269, 0.9452405647303361, 0.9475868019320013, 0.9489383438773553, 0.9502229733450416, 0.9518780103478868, 0.9529769186504475, 0.9528364180504629, 0.9546042634442119, 0.9552987693287063, 0.9565732975163176, 0.9572003239393846, 0.9583270535936389, 0.9582374769993353, 0.9557236878837391, 0.9547413981616302, 0.9563516898213708, 0.9554501428271854, 0.9565330464661536, 0.9550415452833936, 0.9569418523514397, 0.9562377838331632, 0.9575454813534613, 0.959087149332573, 0.9603052228029302, 0.9601590190467336, 0.9583331585577229, 0.9589912771899025, 0.9530370854648882, 0.9547307413762307, 0.9497744217566799, 0.9518955300328191, 0.9538939476620674, 0.955857244913933, 0.9569088509948289, 0.95924130926884, 0.9609546030407512, 0.9619341615619773, 0.9632393335081892, 0.9641457277176113, 0.965234449373561, 0.9656754246169277, 0.9671029875769217, 0.9665217362589886, 0.9670481206150174, 0.9671900706017085, 0.9684473436620196, 0.9695506514644924, 0.9698659176433443, 0.9709685578067206, 0.9708055310923136, 0.9615826587059738, 0.9631747693414004, 0.9644217690638869, 0.9658240951695464, 0.9664531879116278, 0.9676782569216699, 0.9685643280668522, 0.9644789795975164, 0.965910882089572, 0.9671313526155545, 0.9676344259383364, 0.9685342928324545, 0.9697112664106549, 0.9696457308840473, 0.9700362029763655, 0.9712582980401747, 0.9717063575433862, 0.9728555636565175, 0.9735721722005043, 0.9746053917274418, 0.9755894120426495, 0.9762208887600713, 0.9766221432575581, 0.976931502726983, 0.9763086649542847, 0.9771129452962056, 0.9756412968509224, 0.9754816287622157, 0.9759850472112953, 0.9769840575504067, 0.9746805124881371, 0.9748145884983596, 0.9749799669979212, 0.9755570832499363, 0.9761470827562679, 0.9768145657457014, 0.9777117989301674, 0.9783804721998012, 0.9792081817569295, 0.9799154697559352, 0.98047202142492, 0.9808787914209822, 0.9813272451102093, 0.9813214031293088, 0.9812149593525226, 0.9814839001642582, 0.9812553143646998, 0.9803836421149769, 0.9807027703733586, 0.9811076439384324, 0.9813967289421796, 0.9808191795419374, 0.9808453188166593, 0.9804852786518609, 0.9803542018408917, 0.9803727161447543, 0.9803776132049776, 0.9806596937519497, 0.9813183102201283, 0.9811392276920913, 0.9716760014590267, 0.9730965037227626, 0.972840693711932, 0.9738505814190521, 0.9754089532470264, 0.9767126550608779, 0.9775894881993684, 0.9786116011264195, 0.9793644282125729, 0.9804325975901108, 0.9810668604214612, 0.9815388641383512, 0.9758430914293353, 0.9765315609008597, 0.977473566708364, 0.9780766430194554, 0.9778522806753411, 0.9762266911620239, 0.9766203059313637, 0.9772545855791912, 0.9781125231056094, 0.9790117376625184, 0.9793033349806038, 0.9777961942536278, 0.978750573322241, 0.9793694918936313, 0.9799335780958345, 0.980662452966974, 0.981261964447385, 0.9821356738761404, 0.9822819521210565, 0.979933369107746, 0.9745816925885376, 0.9754410120345031, 0.9761108603792455, 0.9771419994919234, 0.9778700058680323, 0.9786875798294218, 0.9792139649187688, 0.980179522493157, 0.9805896575932389, 0.9815117724062042, 0.9818757495330537, 0.9825233590677002, 0.9827838243657494, 0.9832017898207407, 0.9832132185193896, 0.9834823522397398, 0.9827221252988984, 0.9830097772268398, 0.9798259870041558, 0.9795490547194028, 0.98002223659686, 0.9803892712203065, 0.981331424670565, 0.9817369681974843, 0.9815583767994227, 0.9822353704447816, 0.982623467436448, 0.983469272048225, 0.9835927891205108, 0.9839157391241223, 0.9841499182237582, 0.9847889550158402, 0.9848299202070273, 0.9853068302947583, 0.985547796361668, 0.9855011116050193, 0.9859697316192161, 0.9861302885777764, 0.9865477567079505, 0.9865728567901675], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.007175241277359413, 0.01661187411781872, 0.02455560455552564, 0.032365937088138265, 0.04177952472985772, 0.05054688995857488, 0.056450094458908764, 0.06253150172305257, 0.06643449273347149, 0.06784174549617955, 0.06838907126312352, 0.07085357220709519, 0.06988396213925144, 0.06718182328350676, 0.06636687158122936, 0.06666613102097325, 0.06345719184662166, 0.06330230803343073, 0.06229417373182393, 0.06060386212254367, 0.05856161558084984, 0.05406774297735609, 0.05262047449376531, 0.04753609580830417, 0.04406925134745565, 0.04106074416581583, 0.039022505954072084, 0.036066461115801696, 0.03303307666513912, 0.03189238030787379, 0.029896632398351004, 0.028200834511263685, 0.02655921647623832, 0.025004886810237433, 0.022968717839177085, 0.021860674864584356, 0.02033227688501837, 0.018804104932698726, 0.017634682194066467, 0.016359888127384273, 0.015360927148343218, 0.014426197161043139, 0.013001360393593387, 0.012189034227853042, 0.01138027144695823, 0.01038472988834965, 0.009392589802489831, 0.008704554624729929, 0.008033981250416308, 0.007432211838189266, 0.007023886579234265, 0.006321497921440655, 0.005695595044707211, 0.005370023529291827, 0.005087650397296527, 0.0046101191248958855, 0.004402190613332864, 0.004012825236495911, 0.003748068786805052, 0.003497614457961012, 0.0033125073316836308, 0.0029921301722076387, 0.0027092452307174173, 0.0026059200369782393, 0.0025029567820812125, 0.002330358033461467, 0.0021159122130285286, 0.002045092811949853, 0.0018951739905427253, 0.001810719521687145, 0.0016354003431656577, 0.0015591931348488222, 0.0014282833257769105, 0.001345380555769076, 0.0012122308065680106, 0.001100577902822408, 0.0010100743241828007, 0.0009414226142309776, 0.0008477475399993492, 0.0007827440862156263, 0.0007607699350059723, 0.0007317375479848296, 0.0007017997729653833, 0.0006609926313158382, 0.0006444368292425533, 0.0005964331369887615, 0.0005516422791131139, 0.0005211303785288852, 0.00047988573579292853, 0.00043207482598099975, 0.00041699483940869214, 0.00037963640128019997, 0.00035629256006132167, 0.0003242017632722077, 0.00030320726436897127, 0.00027295875362829753, 0.00030253509972467604, 0.00028096562763565443, 0.00027620641793696003, 0.00025590085898778437, 0.00024086489571062118, 0.00023679958814312756, 0.00024562013190461136, 0.00022551953102000282, 0.00021835823315934783, 0.00021791307126377838, 0.00020947509095009198, 0.0001887199617000168, 0.00019985186425798906, 0.00018376475903838667, 0.0004844598750186119, 0.0004618301206309794, 0.0006367330461081778, 0.0006135516443693175, 0.0005881395371203958, 0.0005640164083010014, 0.0005175676456152955, 0.0005147741354537908, 0.0004897151018482386, 0.00044937940573197446, 0.00041977272944138404, 0.0003851894106631098, 0.00035733830319400377, 0.00032335460536196507, 0.0003093605688684894, 0.00028146518983303146, 0.0002558123952621755, 0.00023041250392445218, 0.0002215978734656629, 0.0002103936790820716, 0.00019024884604561574, 0.00018216629941007108, 0.00016418886885555703, 0.0009133223574623836, 0.0008448034681950951, 0.0007743181961465175, 0.0007145850430913931, 0.0006466883578855105, 0.0005955266688112478, 0.0005430401005990468, 0.0006389467395822833, 0.00059350516834485, 0.0005475605862534945, 0.0004950822725409984, 0.0004528618891310676, 0.00042004310145199615, 0.0003780774454540262, 0.0003416419170025375, 0.0003209193724071659, 0.00029063425103221206, 0.0002734568981431152, 0.0002507329585766377, 0.00023526754603657898, 0.000220455455259593, 0.00020199877533544597, 0.00018324794434768218, 0.0001657844794448197, 0.00015269737352023577, 0.00014324943798381618, 0.000148416236503975, 0.00013380405794053874, 0.0001227045233603486, 0.00011941626594317752, 0.00015523151803401903, 0.00013987015361927163, 0.00012612928869039976, 0.00011651392833641951, 0.00010799543026002214, 0.000101205689104667, 9.83303666799634e-05, 9.252144548567271e-05, 8.94352289357595e-05, 8.499401286402284e-05, 7.928235941986833e-05, 7.284327994514957e-05, 6.736894835306702e-05, 6.06323606764279e-05, 5.4671097107333905e-05, 4.9854949838554015e-05, 4.53397180645362e-05, 4.7644058856517004e-05, 4.37962385785457e-05, 4.0891918153951026e-05, 3.755485759307919e-05, 3.6801441621250794e-05, 3.31274468142726e-05, 3.098136241525827e-05, 2.8037856347097206e-05, 2.523715572741515e-05, 2.2713655985463118e-05, 2.115841530173762e-05, 2.294655464096735e-05, 2.0940534143503458e-05, 0.0008248203373726015, 0.0007604987437668505, 0.0006850378182449352, 0.0006257128950493714, 0.00058499831033245, 0.0005417952250741641, 0.0004945352297415439, 0.0004544841402881944, 0.0004141364638541886, 0.00038299168984075695, 0.00034831312490977447, 0.000315486899997619, 0.000575914650772784, 0.0005225890976144941, 0.00047831656232539285, 0.0004337582154258491, 0.00039083544003637205, 0.0003755347674249979, 0.00033937568396227977, 0.0003090589116108852, 0.0002847775316429264, 0.00026357705985284623, 0.0002379846148307936, 0.00023462941188590316, 0.00021936402535677443, 0.00020087516460320397, 0.0001836513873345271, 0.00017006757580108117, 0.00015629554435727479, 0.00014753630341461334, 0.00013297524899757358, 0.00016932030363151035, 0.00041015224736457153, 0.00037578289182004486, 0.0003422428738826283, 0.0003175878173216122, 0.0002905989751423475, 0.0002675549222691924, 0.00024329316140285463, 0.00022735455812769473, 0.00020613299951779786, 0.00019317236112062779, 0.0001750474391483913, 0.00016131727821783697, 0.00014579612993944428, 0.0001327887730395948, 0.00011951107127201057, 0.00010821186077967537, 0.00010259217971593813, 9.307765442918043e-05, 0.00017499857062478526, 0.00015818893697535302, 0.00014438515308020394, 0.00013115906750546036, 0.00012603203886942045, 0.00011490902495251451, 0.00010370517644441772, 9.745954236268341e-05, 8.90691616008798e-05, 8.660071441251926e-05, 7.807795117558215e-05, 7.120882640151836e-05, 6.458150241772331e-05, 6.179866437066125e-05, 5.563390125559606e-05, 5.211750021605285e-05, 4.7428332003064974e-05, 4.270511400128864e-05, 4.041104506051263e-05, 3.660194738694063e-05, 3.451026940564667e-05, 3.1064912592227704e-05], "duration": 17110.639207, "accuracy_train": [0.28235598644578314, 0.36412838855421686, 0.3885071536144578, 0.4322289156626506, 0.5031767695783133, 0.5450160015060241, 0.5526167168674698, 0.5995387801204819, 0.6105986445783133, 0.6073512801204819, 0.6235881024096386, 0.6882294804216867, 0.6595444277108434, 0.6431664156626506, 0.7028661521084337, 0.749976468373494, 0.6961361069277109, 0.7820030120481928, 0.7891330948795181, 0.7948512801204819, 0.8040286144578314, 0.7368928840361446, 0.835913968373494, 0.6915709713855421, 0.7711549322289156, 0.7881918298192772, 0.8275837725903614, 0.7936982304216867, 0.781226468373494, 0.8644107680722891, 0.8400555346385542, 0.8563158885542169, 0.8628341490963856, 0.8704819277108434, 0.842738140060241, 0.8930252259036144, 0.8750705948795181, 0.873046875, 0.894507718373494, 0.8882012424698795, 0.9060146837349398, 0.9120387801204819, 0.852527296686747, 0.9134977409638554, 0.9147449171686747, 0.8937782379518072, 0.8352786144578314, 0.9085325677710844, 0.9081089984939759, 0.9130271084337349, 0.9314288403614458, 0.8765295557228916, 0.8848597515060241, 0.9294286521084337, 0.9357586596385542, 0.8692582831325302, 0.9390530873493976, 0.9150978915662651, 0.932652484939759, 0.9347703313253012, 0.9440888554216867, 0.8946018448795181, 0.8910250376506024, 0.946300828313253, 0.9493128765060241, 0.9410297439759037, 0.9289580195783133, 0.9555722891566265, 0.9446065512048193, 0.9566076807228916, 0.9338525978915663, 0.9578077936746988, 0.9464420180722891, 0.9572430346385542, 0.9379471009036144, 0.9447242093373494, 0.950183546686747, 0.9558782003012049, 0.936535203313253, 0.9534073795180723, 0.9650790662650602, 0.9654320406626506, 0.966773343373494, 0.9289815512048193, 0.9687029367469879, 0.9611022213855421, 0.9617846385542169, 0.966773343373494, 0.962867093373494, 0.9515719126506024, 0.9705148719879518, 0.9615493222891566, 0.9680440512048193, 0.9628435617469879, 0.9684676204819277, 0.9574312876506024, 0.9330995858433735, 0.9459007906626506, 0.9708443147590361, 0.9473362198795181, 0.9662791792168675, 0.9416180346385542, 0.9740446159638554, 0.9499011671686747, 0.9693147590361446, 0.9729621611445783, 0.9712678840361446, 0.9588431852409639, 0.9419004141566265, 0.9649143448795181, 0.899449359939759, 0.9699736445783133, 0.9051675451807228, 0.9709855045180723, 0.9718797063253012, 0.9735269201807228, 0.9663733057228916, 0.9802334337349398, 0.9763742469879518, 0.9707501882530121, 0.9749858810240963, 0.9723032756024096, 0.9750329442771084, 0.9696442018072289, 0.9799510542168675, 0.9612904743975904, 0.9717855798192772, 0.9684676204819277, 0.9797628012048193, 0.979480421686747, 0.9727033132530121, 0.9808923192771084, 0.9693382906626506, 0.8785768072289156, 0.977503765060241, 0.9756447665662651, 0.9784450301204819, 0.9721150225903614, 0.9787038780120482, 0.976538968373494, 0.927710843373494, 0.9787980045180723, 0.9781155873493976, 0.9721620858433735, 0.9766330948795181, 0.9803040286144579, 0.9690559111445783, 0.9735504518072289, 0.9822571536144579, 0.9757388930722891, 0.9831984186746988, 0.9800216490963856, 0.9839043674698795, 0.9844455948795181, 0.9819041792168675, 0.9802334337349398, 0.9797157379518072, 0.970703125, 0.984351468373494, 0.9623964608433735, 0.9740446159638554, 0.9805158132530121, 0.9859751506024096, 0.9539486069277109, 0.9760212725903614, 0.9764683734939759, 0.9807511295180723, 0.981457078313253, 0.9828219126506024, 0.9857868975903614, 0.984398531626506, 0.9866575677710844, 0.9862810617469879, 0.9854809864457831, 0.9845397213855421, 0.985363328313253, 0.9812688253012049, 0.9802569653614458, 0.9839043674698795, 0.9791980421686747, 0.9725385918674698, 0.9835749246987951, 0.9847515060240963, 0.9839984939759037, 0.975621234939759, 0.9810805722891566, 0.9772449171686747, 0.9791745105421686, 0.9805393448795181, 0.9804216867469879, 0.9831984186746988, 0.9872458584337349, 0.979527484939759, 0.8865069653614458, 0.9858810240963856, 0.9705384036144579, 0.9829395707831325, 0.9894342996987951, 0.9884459713855421, 0.9854809864457831, 0.9878106174698795, 0.9861398719879518, 0.9900461219879518, 0.9867752259036144, 0.9857868975903614, 0.9245811370481928, 0.9827277861445783, 0.9859516189759037, 0.9835043298192772, 0.9758330195783133, 0.9615963855421686, 0.9801628388554217, 0.9829631024096386, 0.9858339608433735, 0.9871046686746988, 0.9819277108433735, 0.9642319277108434, 0.987339984939759, 0.9849397590361446, 0.9850103539156626, 0.9872223268072289, 0.9866575677710844, 0.9899990587349398, 0.9835984563253012, 0.9587961219879518, 0.9264166039156626, 0.9831748870481928, 0.9821394954819277, 0.9864222515060241, 0.9844220632530121, 0.9860457454819277, 0.9839514307228916, 0.9888695406626506, 0.9842808734939759, 0.9898108057228916, 0.9851515436746988, 0.9883518448795181, 0.9851280120481928, 0.9869634789156626, 0.9833160768072289, 0.9859045557228916, 0.9758800828313253, 0.9855986445783133, 0.951171875, 0.9770566641566265, 0.9842808734939759, 0.9836925828313253, 0.9898108057228916, 0.985386859939759, 0.9799510542168675, 0.9883283132530121, 0.9861163403614458, 0.9910815135542169, 0.9847044427710844, 0.9868222891566265, 0.9862575301204819, 0.9905402861445783, 0.9851986069277109, 0.9895990210843374, 0.9877164909638554, 0.9850809487951807, 0.9901873117469879, 0.9875753012048193, 0.9903049698795181, 0.9867987575301205], "end": "2016-01-18 05:01:04.646000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0], "accuracy_valid": [0.28933189655172414, 0.36920797413793105, 0.3927801724137931, 0.4385775862068966, 0.5129310344827587, 0.5476831896551724, 0.5576508620689655, 0.5994073275862069, 0.6065463362068966, 0.6045258620689655, 0.6197467672413793, 0.6760506465517241, 0.6500538793103449, 0.6321390086206896, 0.6865571120689655, 0.7315463362068966, 0.6834590517241379, 0.7489224137931034, 0.7551185344827587, 0.7541756465517241, 0.759698275862069, 0.7073006465517241, 0.791082974137931, 0.6717403017241379, 0.7283135775862069, 0.7470366379310345, 0.7749191810344828, 0.7447467672413793, 0.7281788793103449, 0.798895474137931, 0.7757273706896551, 0.7925646551724138, 0.7959321120689655, 0.7956627155172413, 0.7784213362068966, 0.8057650862068966, 0.7945851293103449, 0.7914870689655172, 0.8048221982758621, 0.8045528017241379, 0.8125, 0.8185614224137931, 0.7784213362068966, 0.8129040948275862, 0.8114224137931034, 0.7974137931034483, 0.7489224137931034, 0.8107489224137931, 0.8052262931034483, 0.8068426724137931, 0.818426724137931, 0.7863685344827587, 0.7905441810344828, 0.8160021551724138, 0.8230064655172413, 0.7755926724137931, 0.8181573275862069, 0.802667025862069, 0.8236799568965517, 0.8150592672413793, 0.8231411637931034, 0.7886584051724138, 0.7921605603448276, 0.828125, 0.8302801724137931, 0.8213900862068966, 0.8147898706896551, 0.8292025862068966, 0.8207165948275862, 0.8333782327586207, 0.8165409482758621, 0.8282596982758621, 0.8246228448275862, 0.8294719827586207, 0.8161368534482759, 0.8235452586206896, 0.8247575431034483, 0.8305495689655172, 0.8186961206896551, 0.82421875, 0.834051724137931, 0.8335129310344828, 0.8336476293103449, 0.8114224137931034, 0.8395743534482759, 0.8292025862068966, 0.8370150862068966, 0.8362068965517241, 0.8314924568965517, 0.8267780172413793, 0.8325700431034483, 0.8235452586206896, 0.8359375, 0.8289331896551724, 0.8351293103448276, 0.8306842672413793, 0.8155980603448276, 0.8188308189655172, 0.8383620689655172, 0.8168103448275862, 0.8336476293103449, 0.8215247844827587, 0.8351293103448276, 0.8266433189655172, 0.8321659482758621, 0.8375538793103449, 0.8367456896551724, 0.8240840517241379, 0.8209859913793104, 0.8317618534482759, 0.7804418103448276, 0.8395743534482759, 0.7862338362068966, 0.8345905172413793, 0.8374191810344828, 0.8376885775862069, 0.8290678879310345, 0.8410560344827587, 0.8421336206896551, 0.8355334051724138, 0.841729525862069, 0.8391702586206896, 0.8415948275862069, 0.8341864224137931, 0.8410560344827587, 0.8292025862068966, 0.837823275862069, 0.8363415948275862, 0.8429418103448276, 0.8477909482758621, 0.8328394396551724, 0.8461745689655172, 0.8347252155172413, 0.7668372844827587, 0.8407866379310345, 0.841729525862069, 0.8425377155172413, 0.8359375, 0.8414601293103449, 0.8393049568965517, 0.802667025862069, 0.8472521551724138, 0.8436153017241379, 0.8394396551724138, 0.8389008620689655, 0.8483297413793104, 0.8278556034482759, 0.8383620689655172, 0.8459051724137931, 0.841729525862069, 0.845770474137931, 0.8452316810344828, 0.8468480603448276, 0.8500808189655172, 0.8485991379310345, 0.8403825431034483, 0.841729525862069, 0.8363415948275862, 0.8453663793103449, 0.8313577586206896, 0.8370150862068966, 0.841864224137931, 0.849542025862069, 0.8227370689655172, 0.8438846982758621, 0.8430765086206896, 0.8452316810344828, 0.8422683189655172, 0.845770474137931, 0.8488685344827587, 0.8483297413793104, 0.8508890086206896, 0.8490032327586207, 0.8527747844827587, 0.8546605603448276, 0.8531788793103449, 0.8453663793103449, 0.8442887931034483, 0.8537176724137931, 0.8438846982758621, 0.8432112068965517, 0.8490032327586207, 0.845770474137931, 0.8468480603448276, 0.8432112068965517, 0.8448275862068966, 0.8403825431034483, 0.841729525862069, 0.8444234913793104, 0.8468480603448276, 0.8471174568965517, 0.8502155172413793, 0.8411907327586207, 0.775323275862069, 0.8499461206896551, 0.8336476293103449, 0.8453663793103449, 0.8506196120689655, 0.8519665948275862, 0.8488685344827587, 0.8479256465517241, 0.8519665948275862, 0.8527747844827587, 0.8533135775862069, 0.849676724137931, 0.8013200431034483, 0.8491379310344828, 0.8504849137931034, 0.845635775862069, 0.8409213362068966, 0.8283943965517241, 0.8488685344827587, 0.845770474137931, 0.8450969827586207, 0.8550646551724138, 0.8471174568965517, 0.8316271551724138, 0.8507543103448276, 0.8481950431034483, 0.8533135775862069, 0.8533135775862069, 0.8529094827586207, 0.8533135775862069, 0.8504849137931034, 0.8302801724137931, 0.8018588362068966, 0.8465786637931034, 0.8481950431034483, 0.849542025862069, 0.8498114224137931, 0.8494073275862069, 0.8472521551724138, 0.8530441810344828, 0.8441540948275862, 0.8541217672413793, 0.8511584051724138, 0.8529094827586207, 0.8438846982758621, 0.8541217672413793, 0.8485991379310345, 0.8452316810344828, 0.8410560344827587, 0.84765625, 0.8213900862068966, 0.8403825431034483, 0.8429418103448276, 0.8484644396551724, 0.8543911637931034, 0.8518318965517241, 0.849676724137931, 0.8531788793103449, 0.8453663793103449, 0.8549299568965517, 0.8460398706896551, 0.8490032327586207, 0.8483297413793104, 0.8549299568965517, 0.8502155172413793, 0.853448275862069, 0.8511584051724138, 0.84765625, 0.8492726293103449, 0.8506196120689655, 0.8521012931034483, 0.8503502155172413], "accuracy_test": 0.8442508012820513, "start": "2016-01-18 00:15:54.007000", "learning_rate_per_epoch": [0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237, 0.0005432834732346237], "accuracy_train_last": 0.9867987575301205, "error_valid": [0.7106681034482758, 0.630792025862069, 0.6072198275862069, 0.5614224137931034, 0.4870689655172413, 0.4523168103448276, 0.4423491379310345, 0.40059267241379315, 0.3934536637931034, 0.3954741379310345, 0.38025323275862066, 0.3239493534482759, 0.34994612068965514, 0.3678609913793104, 0.3134428879310345, 0.2684536637931034, 0.3165409482758621, 0.2510775862068966, 0.24488146551724133, 0.2458243534482759, 0.24030172413793105, 0.2926993534482759, 0.20891702586206895, 0.3282596982758621, 0.27168642241379315, 0.2529633620689655, 0.22508081896551724, 0.25525323275862066, 0.27182112068965514, 0.20110452586206895, 0.22427262931034486, 0.2074353448275862, 0.20406788793103448, 0.20433728448275867, 0.22157866379310343, 0.19423491379310343, 0.20541487068965514, 0.20851293103448276, 0.1951778017241379, 0.1954471982758621, 0.1875, 0.18143857758620685, 0.22157866379310343, 0.1870959051724138, 0.18857758620689657, 0.2025862068965517, 0.2510775862068966, 0.18925107758620685, 0.1947737068965517, 0.19315732758620685, 0.18157327586206895, 0.21363146551724133, 0.20945581896551724, 0.1839978448275862, 0.17699353448275867, 0.22440732758620685, 0.18184267241379315, 0.19733297413793105, 0.1763200431034483, 0.18494073275862066, 0.17685883620689657, 0.2113415948275862, 0.20783943965517238, 0.171875, 0.16971982758620685, 0.17860991379310343, 0.18521012931034486, 0.17079741379310343, 0.1792834051724138, 0.16662176724137934, 0.1834590517241379, 0.1717403017241379, 0.1753771551724138, 0.17052801724137934, 0.1838631465517241, 0.1764547413793104, 0.1752424568965517, 0.16945043103448276, 0.18130387931034486, 0.17578125, 0.16594827586206895, 0.16648706896551724, 0.16635237068965514, 0.18857758620689657, 0.1604256465517241, 0.17079741379310343, 0.16298491379310343, 0.1637931034482759, 0.1685075431034483, 0.17322198275862066, 0.1674299568965517, 0.1764547413793104, 0.1640625, 0.17106681034482762, 0.16487068965517238, 0.16931573275862066, 0.18440193965517238, 0.18116918103448276, 0.16163793103448276, 0.1831896551724138, 0.16635237068965514, 0.17847521551724133, 0.16487068965517238, 0.17335668103448276, 0.1678340517241379, 0.16244612068965514, 0.16325431034482762, 0.1759159482758621, 0.1790140086206896, 0.1682381465517241, 0.21955818965517238, 0.1604256465517241, 0.21376616379310343, 0.16540948275862066, 0.16258081896551724, 0.16231142241379315, 0.17093211206896552, 0.15894396551724133, 0.15786637931034486, 0.1644665948275862, 0.15827047413793105, 0.1608297413793104, 0.15840517241379315, 0.16581357758620685, 0.15894396551724133, 0.17079741379310343, 0.16217672413793105, 0.1636584051724138, 0.15705818965517238, 0.1522090517241379, 0.16716056034482762, 0.15382543103448276, 0.16527478448275867, 0.23316271551724133, 0.15921336206896552, 0.15827047413793105, 0.15746228448275867, 0.1640625, 0.15853987068965514, 0.1606950431034483, 0.19733297413793105, 0.1527478448275862, 0.1563846982758621, 0.1605603448275862, 0.16109913793103448, 0.1516702586206896, 0.1721443965517241, 0.16163793103448276, 0.15409482758620685, 0.15827047413793105, 0.15422952586206895, 0.15476831896551724, 0.15315193965517238, 0.14991918103448276, 0.15140086206896552, 0.1596174568965517, 0.15827047413793105, 0.1636584051724138, 0.15463362068965514, 0.1686422413793104, 0.16298491379310343, 0.15813577586206895, 0.15045797413793105, 0.17726293103448276, 0.1561153017241379, 0.1569234913793104, 0.15476831896551724, 0.15773168103448276, 0.15422952586206895, 0.15113146551724133, 0.1516702586206896, 0.1491109913793104, 0.15099676724137934, 0.14722521551724133, 0.14533943965517238, 0.14682112068965514, 0.15463362068965514, 0.1557112068965517, 0.14628232758620685, 0.1561153017241379, 0.1567887931034483, 0.15099676724137934, 0.15422952586206895, 0.15315193965517238, 0.1567887931034483, 0.15517241379310343, 0.1596174568965517, 0.15827047413793105, 0.1555765086206896, 0.15315193965517238, 0.1528825431034483, 0.14978448275862066, 0.15880926724137934, 0.22467672413793105, 0.15005387931034486, 0.16635237068965514, 0.15463362068965514, 0.14938038793103448, 0.1480334051724138, 0.15113146551724133, 0.1520743534482759, 0.1480334051724138, 0.14722521551724133, 0.14668642241379315, 0.15032327586206895, 0.1986799568965517, 0.15086206896551724, 0.14951508620689657, 0.15436422413793105, 0.15907866379310343, 0.1716056034482759, 0.15113146551724133, 0.15422952586206895, 0.15490301724137934, 0.1449353448275862, 0.1528825431034483, 0.1683728448275862, 0.14924568965517238, 0.1518049568965517, 0.14668642241379315, 0.14668642241379315, 0.14709051724137934, 0.14668642241379315, 0.14951508620689657, 0.16971982758620685, 0.19814116379310343, 0.15342133620689657, 0.1518049568965517, 0.15045797413793105, 0.15018857758620685, 0.15059267241379315, 0.1527478448275862, 0.14695581896551724, 0.1558459051724138, 0.14587823275862066, 0.1488415948275862, 0.14709051724137934, 0.1561153017241379, 0.14587823275862066, 0.15140086206896552, 0.15476831896551724, 0.15894396551724133, 0.15234375, 0.17860991379310343, 0.1596174568965517, 0.15705818965517238, 0.15153556034482762, 0.14560883620689657, 0.1481681034482759, 0.15032327586206895, 0.14682112068965514, 0.15463362068965514, 0.1450700431034483, 0.15396012931034486, 0.15099676724137934, 0.1516702586206896, 0.1450700431034483, 0.14978448275862066, 0.14655172413793105, 0.1488415948275862, 0.15234375, 0.15072737068965514, 0.14938038793103448, 0.1478987068965517, 0.14964978448275867], "accuracy_train_std": [0.037177668772679265, 0.04324191048816873, 0.04237117502186991, 0.04429984783256449, 0.045812076135192066, 0.042996982542829694, 0.045406113334154834, 0.04414365046283651, 0.04383885809586374, 0.04361996868597579, 0.04353439941290708, 0.04386453612364135, 0.04383279469987169, 0.044762225864828385, 0.04054653572187625, 0.04233947803006299, 0.04284945069569801, 0.038771780707827684, 0.03986140148082913, 0.037574547855116124, 0.03744691467397349, 0.040650413132256716, 0.03420202714426239, 0.040388025080412365, 0.03847606591629732, 0.038184014141755915, 0.03647140214800919, 0.038584484433263996, 0.03698095991308401, 0.03213765500724787, 0.03297534941452623, 0.03408923025187414, 0.0332616606479796, 0.03257205546284412, 0.036172840451865765, 0.030622051953412947, 0.03454425939839089, 0.03208667355533405, 0.03167943415811062, 0.03139978803268717, 0.028729600802778737, 0.027891996298407683, 0.035184833873829716, 0.02772189400063782, 0.027596277933310254, 0.030667803838295336, 0.03268664050565054, 0.027342605796286126, 0.028044753164182198, 0.028441706531809156, 0.025609632482998943, 0.03184519461161391, 0.032388777195932215, 0.02585656790909917, 0.024108378172130938, 0.03303082703688509, 0.023251962017096072, 0.027165568450877788, 0.025381321869618428, 0.023731642414663433, 0.023152824599667155, 0.028450768003760445, 0.031049720355082966, 0.022964793892789343, 0.02236564428506262, 0.023719085779294616, 0.02461622967354528, 0.020497654122884124, 0.023094921793632567, 0.018846350242815436, 0.023867461875526786, 0.01933599635045501, 0.022382523141109986, 0.019736105756729676, 0.022921628207740494, 0.02406873610389959, 0.022212995403858217, 0.021726956045285427, 0.024262042696945214, 0.021581773103575598, 0.018133832326441657, 0.018095361772892816, 0.01902461785205509, 0.024843647720930905, 0.017010680607826397, 0.018996115924969345, 0.01919465412773078, 0.017208168599031595, 0.01896170228644346, 0.022691761085325984, 0.01577754758020113, 0.020037508138730325, 0.017963680555283138, 0.0200158167047183, 0.01735083700436525, 0.020988245385687138, 0.02450982419052229, 0.021959874733290495, 0.01634462464144564, 0.020837012778321708, 0.01767742081439929, 0.02325937909905052, 0.01506500168894474, 0.02309960874117564, 0.01631717664746715, 0.01591926272814218, 0.015616261794652158, 0.01915172278559289, 0.021920300583502382, 0.017558362445237233, 0.02821867871084604, 0.01668257894838677, 0.027944358844413812, 0.01690132761251292, 0.016121396930050918, 0.015405057967363044, 0.017470723263722877, 0.013399892506878931, 0.015218541625994573, 0.017705715572993923, 0.014960693061928123, 0.015626895881995378, 0.01510010006207562, 0.017095107178979014, 0.01297358986911256, 0.01882828654322299, 0.016511003928800082, 0.016889086215462205, 0.013641850345831787, 0.013957567600002016, 0.016411112212307392, 0.012977003971768796, 0.017005976144272975, 0.02865499021731478, 0.013795234157049143, 0.014618482013533302, 0.013303675336025828, 0.015680240656441385, 0.013368014429659883, 0.014342849694470987, 0.023620127252244327, 0.012918734363044287, 0.014367710497017436, 0.015995189304018755, 0.014495692029996286, 0.013067555236764759, 0.01722815608758229, 0.01448095838878136, 0.012078763485030503, 0.014736792651097046, 0.011854989614057463, 0.012704180106517086, 0.011590944487094988, 0.011734214911515915, 0.012861513946138171, 0.01342730362076554, 0.013018668999852337, 0.016021478139964018, 0.011718726373845153, 0.0174504424346241, 0.014429224200071183, 0.012624887582157455, 0.011015817666900228, 0.02072903904005099, 0.013689724702966595, 0.014207335211884447, 0.012563420575744663, 0.012860760482028112, 0.012179384302556433, 0.010634420815228052, 0.012240495268018337, 0.010314129601762003, 0.011025540134705447, 0.01078197967350088, 0.011431697095043492, 0.011087467157381148, 0.012001775466906327, 0.012387987812888097, 0.011415143266608387, 0.013842038004633413, 0.015345561653330541, 0.011948042874608643, 0.010992065807724645, 0.013056130184035921, 0.015311116391256731, 0.014329813836268903, 0.014416170419103227, 0.013032591475023635, 0.01301201070961411, 0.012997980986683502, 0.01179279661881709, 0.010066146619840568, 0.014065772625882527, 0.029447111100756148, 0.01130889917421461, 0.015199172101781244, 0.012380833819639852, 0.00925349609418789, 0.010026654577274636, 0.011167263046753605, 0.009661960906019743, 0.01079655540203101, 0.009683457304672445, 0.010331965197557814, 0.010974722746315196, 0.024061280842343772, 0.011370329984074154, 0.011027548878045476, 0.011919994125889885, 0.014603929129568318, 0.016132333052890066, 0.012679398504666808, 0.011891273868489274, 0.010714205638278095, 0.009921755298508252, 0.013445931026724204, 0.017123652715339603, 0.011050046911518573, 0.01141087367411871, 0.010853846342574027, 0.010027096379865845, 0.010278419436549082, 0.00881789421758643, 0.012230901018701248, 0.018650398797442458, 0.025542418055304446, 0.012014387572448583, 0.012645463452318597, 0.011297018981626644, 0.011311542961803308, 0.010324432411576654, 0.0120743616699878, 0.01077149761183701, 0.011989773596115343, 0.008705906783549476, 0.011534698298708079, 0.009185747562769816, 0.010735580890879351, 0.010446028006496405, 0.012418703023181857, 0.010539936085332251, 0.014855801149655606, 0.011694058306202178, 0.02239561899384918, 0.013199270867310244, 0.010914210891659126, 0.011444671325288988, 0.009057781252299894, 0.011307013874105242, 0.013917042391210402, 0.009673301844669037, 0.01039267031714665, 0.008600447331492364, 0.010514925029296443, 0.01073991270707286, 0.01038574140757106, 0.009444951167351976, 0.010635748524908936, 0.010033086406331047, 0.010355092177132288, 0.011042627878487055, 0.00856716039639054, 0.009817624702740169, 0.008877881116379214, 0.010210095878594573], "accuracy_test_std": 0.0324137222234717, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.9322800391674246, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0005432834527467554, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "optimization": "rmsprop", "nb_data_augmentation": 1, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.304070679117858e-10, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.0058400178394115605}, "accuracy_valid_max": 0.8550646551724138, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8503502155172413, "loss_train": [1.8469419479370117, 1.5548466444015503, 1.3994890451431274, 1.28676438331604, 1.193772792816162, 1.114341378211975, 1.0544240474700928, 1.0018198490142822, 0.9546464681625366, 0.9159177541732788, 0.8747135400772095, 0.8409410119056702, 0.80506432056427, 0.773072361946106, 0.7422650456428528, 0.715889573097229, 0.6893618702888489, 0.6624676585197449, 0.6401941776275635, 0.6218143105506897, 0.6012147068977356, 0.5847408771514893, 0.5697611570358276, 0.55219966173172, 0.5380240678787231, 0.5233922004699707, 0.5111871957778931, 0.4959277808666229, 0.48509448766708374, 0.47330307960510254, 0.46052151918411255, 0.4491144120693207, 0.4408947229385376, 0.43444380164146423, 0.4235461950302124, 0.411102294921875, 0.4021230638027191, 0.39414647221565247, 0.3868843615055084, 0.3800429403781891, 0.3737579882144928, 0.36648258566856384, 0.36053112149238586, 0.3501527011394501, 0.3455102741718292, 0.34189745783805847, 0.33600977063179016, 0.3287307322025299, 0.323028028011322, 0.31511038541793823, 0.31160417199134827, 0.31114935874938965, 0.3042488098144531, 0.2971014678478241, 0.2955774664878845, 0.29416149854660034, 0.2866044044494629, 0.2825862467288971, 0.2811042070388794, 0.2737749218940735, 0.2696794867515564, 0.26627153158187866, 0.264545738697052, 0.262409508228302, 0.2543966472148895, 0.25598400831222534, 0.2536487877368927, 0.24963635206222534, 0.2469145804643631, 0.2412261962890625, 0.24220170080661774, 0.23917870223522186, 0.23536768555641174, 0.23369921743869781, 0.22884871065616608, 0.2262500822544098, 0.22668994963169098, 0.22026969492435455, 0.21788384020328522, 0.22337763011455536, 0.21652323007583618, 0.21549080312252045, 0.21394748985767365, 0.207801952958107, 0.21008634567260742, 0.2090604603290558, 0.2053636908531189, 0.2041671872138977, 0.20034249126911163, 0.20138733088970184, 0.2002188265323639, 0.196010559797287, 0.19180229306221008, 0.19641442596912384, 0.19361136853694916, 0.19017542898654938, 0.1886361688375473, 0.18969422578811646, 0.1858450472354889, 0.18589752912521362, 0.18332774937152863, 0.18420909345149994, 0.18121075630187988, 0.17878775298595428, 0.17869041860103607, 0.1774006336927414, 0.17853614687919617, 0.17481045424938202, 0.17360541224479675, 0.17455720901489258, 0.17151035368442535, 0.17393746972084045, 0.16642186045646667, 0.1696605086326599, 0.1691645085811615, 0.1691870242357254, 0.16533660888671875, 0.16694886982440948, 0.1644880622625351, 0.1616237908601761, 0.16043955087661743, 0.1607486754655838, 0.16100071370601654, 0.15870530903339386, 0.15814776718616486, 0.1589488536119461, 0.15732263028621674, 0.15581607818603516, 0.15836955606937408, 0.15388578176498413, 0.15081526339054108, 0.1517835557460785, 0.15034234523773193, 0.14994551241397858, 0.15200909972190857, 0.14721311628818512, 0.14759796857833862, 0.14619070291519165, 0.14499762654304504, 0.14298255741596222, 0.1443547159433365, 0.1454613208770752, 0.14233756065368652, 0.1429206281900406, 0.14134910702705383, 0.1385202705860138, 0.13740114867687225, 0.1388288140296936, 0.1388428807258606, 0.13977527618408203, 0.13875532150268555, 0.13675272464752197, 0.1369953751564026, 0.13499847054481506, 0.13627305626869202, 0.13354137539863586, 0.13459931313991547, 0.13455601036548615, 0.1326308697462082, 0.13141432404518127, 0.1317022740840912, 0.13004761934280396, 0.1311119645833969, 0.13091163337230682, 0.12844470143318176, 0.12962433695793152, 0.1274525374174118, 0.1262589693069458, 0.12764807045459747, 0.12756015360355377, 0.12412549555301666, 0.12417127937078476, 0.1249697357416153, 0.12643368542194366, 0.12404314428567886, 0.12531778216362, 0.12354005873203278, 0.1211349219083786, 0.12149079889059067, 0.12216229736804962, 0.12220034748315811, 0.1228250041604042, 0.1237148717045784, 0.12197060137987137, 0.11841747909784317, 0.11863591521978378, 0.11729373782873154, 0.11881479620933533, 0.11930288374423981, 0.116905577480793, 0.11663313210010529, 0.11410080641508102, 0.11596173048019409, 0.11717117577791214, 0.11639875918626785, 0.11377543956041336, 0.11411088705062866, 0.11460917443037033, 0.11295323073863983, 0.11460912227630615, 0.11306315660476685, 0.11111706495285034, 0.11406954377889633, 0.11067300289869308, 0.11049901694059372, 0.11128269135951996, 0.11189351230859756, 0.10841678828001022, 0.10937391966581345, 0.10995829105377197, 0.10970662534236908, 0.10958429425954819, 0.10757207125425339, 0.10732617229223251, 0.10807211697101593, 0.10709329694509506, 0.10731332004070282, 0.10787537693977356, 0.10675949603319168, 0.10389947891235352, 0.10443326085805893, 0.10527455806732178, 0.10633765161037445, 0.10393720865249634, 0.10564099252223969, 0.10453489422798157, 0.10411001741886139, 0.10118895769119263, 0.10524014383554459, 0.10160331428050995, 0.10222634673118591, 0.10450699925422668, 0.104376420378685, 0.09902293235063553, 0.10098601877689362, 0.09881877899169922, 0.10291831940412521, 0.09818617254495621, 0.10106805711984634, 0.10460884869098663, 0.09935933351516724, 0.09591111540794373, 0.0973069965839386, 0.10024087131023407, 0.09955036640167236, 0.09883054345846176, 0.0991908460855484, 0.10067614912986755, 0.09984175860881805, 0.09553442895412445, 0.09892138093709946, 0.09183245152235031, 0.09955577552318573, 0.09625855833292007, 0.09634900093078613, 0.09546228498220444, 0.09625035524368286, 0.09401336312294006, 0.09575942903757095, 0.09556479007005692, 0.09473110735416412, 0.09442932158708572, 0.09328252822160721, 0.09181147813796997, 0.093776635825634], "accuracy_train_first": 0.28235598644578314, "model": "residual", "loss_std": [0.17636699974536896, 0.11134302616119385, 0.11076855659484863, 0.11137504875659943, 0.11257895082235336, 0.1069595217704773, 0.10506835579872131, 0.1016320139169693, 0.09598075598478317, 0.09745360165834427, 0.0962878093123436, 0.09838703274726868, 0.09339195489883423, 0.09519647061824799, 0.09541711956262589, 0.09345349669456482, 0.09182049334049225, 0.09512016922235489, 0.0891050472855568, 0.08845644444227219, 0.08927673101425171, 0.09029892086982727, 0.09186077862977982, 0.08398638665676117, 0.09397410601377487, 0.08580369502305984, 0.08747610449790955, 0.07854948192834854, 0.08631876856088638, 0.08631983399391174, 0.08110762387514114, 0.07955386489629745, 0.07929873466491699, 0.07907110452651978, 0.07524894922971725, 0.07630724459886551, 0.07686613500118256, 0.07438981533050537, 0.07173233479261398, 0.07534085214138031, 0.07222095876932144, 0.07297850400209427, 0.0713280737400055, 0.07092359662055969, 0.06609748303890228, 0.07286562770605087, 0.0629165917634964, 0.07404503226280212, 0.06355564296245575, 0.05997581407427788, 0.06115838512778282, 0.05918646976351738, 0.06679413467645645, 0.06460270285606384, 0.06399161368608475, 0.06255536526441574, 0.06373266875743866, 0.05937311053276062, 0.06658343225717545, 0.05614665523171425, 0.05482720211148262, 0.05661917105317116, 0.05936553701758385, 0.06115569546818733, 0.05847039073705673, 0.05504363030195236, 0.059284355491399765, 0.057954091578722, 0.05691046640276909, 0.05623277649283409, 0.05340613052248955, 0.058150723576545715, 0.057298269122838974, 0.05309812352061272, 0.056103143841028214, 0.05181657522916794, 0.05602637305855751, 0.05383359268307686, 0.05416135862469673, 0.05537386238574982, 0.055380020290613174, 0.05407029390335083, 0.04853932186961174, 0.05275171995162964, 0.051325105130672455, 0.050708770751953125, 0.048531051725149155, 0.04962720349431038, 0.05086977034807205, 0.04861194267868996, 0.050325118005275726, 0.04841702803969383, 0.047087494283914566, 0.04981982707977295, 0.04664384201169014, 0.0475052185356617, 0.04577226564288139, 0.0481070876121521, 0.04504551365971565, 0.048345159739255905, 0.04667910560965538, 0.047024916857481, 0.05295609310269356, 0.04738393425941467, 0.04736211523413658, 0.046438068151474, 0.04625186324119568, 0.04137368127703667, 0.04633543640375137, 0.050940949469804764, 0.04366115853190422, 0.04930822551250458, 0.04448821395635605, 0.048295725136995316, 0.046147264540195465, 0.04762550815939903, 0.04396423324942589, 0.04768284782767296, 0.04689014330506325, 0.04815639182925224, 0.04507474973797798, 0.04424040764570236, 0.04543965309858322, 0.04435141384601593, 0.041162628680467606, 0.04705512151122093, 0.0468231737613678, 0.04436741769313812, 0.045667920261621475, 0.04256803169846535, 0.04314577579498291, 0.041763439774513245, 0.04466637223958969, 0.04304657503962517, 0.049961917102336884, 0.0384342335164547, 0.04573679342865944, 0.04331086575984955, 0.04305022582411766, 0.04314605891704559, 0.042778946459293365, 0.0450114831328392, 0.043001919984817505, 0.04405142739415169, 0.043708592653274536, 0.042217083275318146, 0.04378899559378624, 0.042635221034288406, 0.041704338043928146, 0.040959686040878296, 0.04332297295331955, 0.0436515286564827, 0.04068806394934654, 0.0407693013548851, 0.040376704186201096, 0.04011620581150055, 0.04241093993186951, 0.04186892509460449, 0.03933422267436981, 0.04061313718557358, 0.04182494059205055, 0.03847581893205643, 0.0425359308719635, 0.038834348320961, 0.042886052280664444, 0.03774888813495636, 0.03912521153688431, 0.041124582290649414, 0.037853505462408066, 0.043273814022541046, 0.037894107401371, 0.04175666347146034, 0.04045867174863815, 0.04141511395573616, 0.03895947337150574, 0.0397181510925293, 0.03774052485823631, 0.03803111985325813, 0.04149724915623665, 0.03679920360445976, 0.03950382396578789, 0.04171941801905632, 0.04361158236861229, 0.038786862045526505, 0.03814106807112694, 0.03886924684047699, 0.03809700906276703, 0.037707362323999405, 0.03773404657840729, 0.038322873413562775, 0.0365157425403595, 0.03924545273184776, 0.036147549748420715, 0.038519009947776794, 0.04576089605689049, 0.03781398758292198, 0.036326814442873, 0.03513955697417259, 0.03915400058031082, 0.039203543215990067, 0.03722592443227768, 0.03812718391418457, 0.036187946796417236, 0.03625669702887535, 0.03626859933137894, 0.037839870899915695, 0.03744899854063988, 0.039121393114328384, 0.03570307418704033, 0.03341821953654289, 0.03951765224337578, 0.03574621304869652, 0.03616754710674286, 0.0375625342130661, 0.03650079295039177, 0.036465615034103394, 0.040431439876556396, 0.037915874272584915, 0.03693190589547157, 0.0357191227376461, 0.03579561039805412, 0.038928862661123276, 0.03787868842482567, 0.035912759602069855, 0.03553405776619911, 0.037394165992736816, 0.04349583014845848, 0.036330074071884155, 0.03616831451654434, 0.03749615699052811, 0.03747464716434479, 0.03874782472848892, 0.03709359094500542, 0.03409336879849434, 0.036117229610681534, 0.035933878272771835, 0.0376373827457428, 0.035984575748443604, 0.03616676479578018, 0.03717736899852753, 0.03336724638938904, 0.035575807094573975, 0.03363260254263878, 0.03536346182227135, 0.03874289616942406, 0.03623044490814209, 0.037171702831983566, 0.035284653306007385, 0.03767182677984238, 0.03351646661758423, 0.03672054782509804, 0.03331020474433899, 0.04022626578807831, 0.03839844465255737, 0.03737306222319603, 0.03495899960398674, 0.03727615624666214, 0.03639663755893707, 0.03501182794570923, 0.03433427959680557, 0.03512119874358177, 0.03564026951789856, 0.03633316233754158, 0.03287210687994957, 0.03397561237215996]}, "state": "available", "life": [{"dt": "Sun May 15 22:04:59 2016", "state": "available"}], "summary": "fc0072ee7c16fe4f405bb6ac06cb5a63"}