{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 64, "f3": 32, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4691438674926758, 1.0207841396331787, 0.8369763493537903, 0.7280266284942627, 0.6518980860710144, 0.5945073366165161, 0.544302761554718, 0.5068074464797974, 0.4704454839229584, 0.44006696343421936, 0.41121912002563477, 0.38956356048583984, 0.3640071153640747, 0.3469238877296448, 0.32598233222961426, 0.30952128767967224, 0.2921793758869171, 0.27657780051231384, 0.2638341188430786, 0.2508269250392914, 0.23684561252593994, 0.2274315506219864, 0.21451878547668457, 0.20736345648765564, 0.19661931693553925, 0.18808582425117493, 0.17755809426307678, 0.1703227162361145, 0.16456572711467743, 0.1548001617193222, 0.14984028041362762, 0.14456498622894287, 0.13928276300430298, 0.1335040181875229, 0.12741073966026306, 0.12259840965270996, 0.11774609237909317, 0.11358436942100525, 0.10942774266004562, 0.1029687449336052, 0.1001473218202591, 0.09613025933504105, 0.09352801740169525, 0.09050976485013962, 0.0856914222240448, 0.08409851044416428, 0.08047184348106384, 0.07606907933950424, 0.07380392402410507, 0.07098284363746643, 0.0703321322798729, 0.06603848934173584, 0.06431199610233307, 0.062433693557977676, 0.05846255272626877, 0.058697231113910675, 0.05745382606983185, 0.05334402620792389, 0.05221648886799812, 0.050094809383153915, 0.04939093813300133, 0.04715830087661743, 0.04683249071240425, 0.04295729845762253, 0.04255705699324608, 0.04111066088080406, 0.04092361405491829, 0.03777441382408142, 0.03680339455604553, 0.03620608523488045, 0.03592650592327118, 0.035021763294935226, 0.03276115283370018, 0.03232337534427643, 0.03236698731780052, 0.03018403984606266, 0.029716715216636658, 0.029799018055200577, 0.02885909378528595, 0.027811642736196518, 0.027620738372206688, 0.02464483678340912, 0.02396606095135212, 0.023869382217526436, 0.023425953462719917, 0.021507171913981438, 0.02208811789751053, 0.022486256435513496, 0.02024199813604355, 0.02024008519947529, 0.01948949694633484, 0.01857244409620762, 0.017715245485305786, 0.018608303740620613, 0.01730232499539852, 0.01702806167304516, 0.01573970541357994, 0.016757789999246597, 0.015328137204051018, 0.014527800492942333, 0.015479163266718388, 0.014589251950383186, 0.014281531795859337, 0.013771869242191315, 0.012687685899436474, 0.012927817180752754, 0.012387316673994064, 0.01234443113207817, 0.012011314742267132, 0.012146113440394402, 0.012621141038835049, 0.011806720867753029, 0.011376232840120792, 0.01152905821800232, 0.010916068218648434, 0.010873480699956417, 0.009666682220995426, 0.01038560550659895, 0.009933754801750183, 0.009852695278823376, 0.009743800386786461, 0.009418651461601257, 0.008805595338344574, 0.00881324801594019, 0.009092675521969795, 0.008428090251982212, 0.00836639478802681, 0.007839659228920937, 0.008487311191856861, 0.007794652134180069, 0.007541976403445005, 0.007727966643869877, 0.007538383360952139, 0.007634731009602547, 0.007645246107131243, 0.007577462587505579, 0.007215044926851988, 0.007167477626353502, 0.00711090350523591, 0.006626219488680363, 0.0068424236960709095, 0.006332492921501398, 0.006843783427029848, 0.0065058013424277306, 0.006348686758428812, 0.006207130383700132, 0.005799697712063789, 0.006172330118715763, 0.006229487247765064, 0.006164599675685167, 0.005986328702419996, 0.006177045404911041, 0.0058484626933932304, 0.006178044248372316, 0.005655807442963123, 0.005824276711791754, 0.005730098113417625, 0.005729451309889555, 0.005827595014125109, 0.005659616552293301, 0.005471530836075544, 0.005786719731986523, 0.005205483641475439, 0.005306584294885397, 0.005309185013175011, 0.00536118121817708, 0.005200937855988741, 0.00532064214348793, 0.005466041620820761, 0.005310381297022104, 0.005272017326205969, 0.0048636444844305515, 0.005101518239825964, 0.004974730312824249, 0.005055809859186411, 0.005001331679522991, 0.004957688972353935, 0.004990644287317991, 0.0050222850404679775, 0.0048354496248066425, 0.005004913080483675, 0.004677345510572195, 0.004915870726108551, 0.004949434194713831, 0.00466642901301384, 0.004781895782798529], "moving_avg_accuracy_train": [0.05058678464724067, 0.1075455566946982, 0.16457617241573225, 0.21797957976810511, 0.2716011038707058, 0.3200992449140523, 0.3672213802233115, 0.4108235265598305, 0.453578037137513, 0.4905344125777391, 0.5267265142440146, 0.5609083005733968, 0.5917858045126888, 0.6223746046388932, 0.6505509882191621, 0.6760421227282721, 0.6979471634662422, 0.7197333356220635, 0.7374905046957467, 0.7565988494250462, 0.7723456831171853, 0.7882056751829124, 0.8031958859730375, 0.8170077659757706, 0.8295849063044117, 0.8420459085680274, 0.8506663050220404, 0.8592268021211192, 0.868809717406654, 0.8778969736790931, 0.8857361767933728, 0.8932424663676346, 0.8992076484868697, 0.9059084424179447, 0.9099629607119106, 0.9158718915752433, 0.9207761970594226, 0.9262432202106232, 0.930791661432455, 0.9345782307427901, 0.938806884603035, 0.9423057894832169, 0.9455268474396571, 0.9483978978147389, 0.9509680364547305, 0.9537832852271239, 0.9562704700972686, 0.958571715498256, 0.9610776391865257, 0.9633259950595399, 0.9653169632619192, 0.9672297423821559, 0.9684630344380064, 0.9692520907037387, 0.9707202038059839, 0.971769499236109, 0.9725603692529743, 0.9737185808395816, 0.9749958112972902, 0.9758779626449513, 0.9770787638506943, 0.9776060995191963, 0.978724803889905, 0.9798176322806764, 0.9809151101240373, 0.981551742712824, 0.9823316502867796, 0.9830870455259587, 0.9836669198424104, 0.9843655180367408, 0.9852500227806857, 0.9859205190145219, 0.9865541925594983, 0.9870733815249862, 0.9875173640570114, 0.988107610538215, 0.9886272066272507, 0.9889646347740494, 0.9892823070478441, 0.9896890837835359, 0.9901900414766109, 0.9906339279539499, 0.9909334443847453, 0.9912192852141279, 0.9915834988058104, 0.9918764138061817, 0.9921330618600873, 0.9925058791859833, 0.9927042309995279, 0.9929222751614798, 0.9932394226453318, 0.9934876529998463, 0.993736636955814, 0.9939444464745183, 0.9941500762318284, 0.994293290334836, 0.994431483622781, 0.9946000354093124, 0.9947726583564764, 0.9949047675208288, 0.9950166903223173, 0.9951708992662761, 0.9953189879110771, 0.995456917989017, 0.9956577849698772, 0.9957664856395562, 0.9959270952601244, 0.996029827288883, 0.9961687890909564, 0.9962635917294798, 0.996337324408922, 0.9964478255989822, 0.9964961233962268, 0.9966256219196994, 0.99671659395392, 0.9968449717609089, 0.9969395854479133, 0.9970270629150266, 0.9971360195699525, 0.9971829272855763, 0.997199567592733, 0.9972866234822693, 0.9973463725923757, 0.9974280485771857, 0.9974829557730385, 0.9975416728445442, 0.9976293954410421, 0.9977269469683665, 0.9977845164084347, 0.9977991265235436, 0.9978541283057131, 0.9979152556537132, 0.9979563193740562, 0.9979979270199839, 0.9980609505382236, 0.9981130214070203, 0.9981389588496516, 0.9982088055242103, 0.998257716638456, 0.9982808103019913, 0.998292294003935, 0.9983351814190177, 0.9983505286044968, 0.9983852674107138, 0.9984142071874995, 0.9984611793258924, 0.9985127548456841, 0.9985196452837347, 0.9985211963803613, 0.9985551444506585, 0.998576397118688, 0.9986094754127716, 0.9986113440917325, 0.9986153510516068, 0.9986282579107317, 0.9986468855791916, 0.9986891910688914, 0.9987226157120023, 0.9987364218491354, 0.9987348964796979, 0.9987591002841091, 0.9987855340056981, 0.9988209500991759, 0.9988365485416393, 0.9988505871398563, 0.9988818230687279, 0.9989076102559027, 0.9989377941707887, 0.9989603093965669, 0.9989898736950054, 0.9989932300755048, 0.9990125268596209, 0.9990205933700874, 0.9990325035271264, 0.9990525232636994, 0.9990775164730438, 0.9990860594685965, 0.9990797972717368, 0.9990718361457536, 0.9990739717276068, 0.9990875194953224, 0.9991043627838854, 0.999110221148354, 0.9991224691228043, 0.9991148911093335, 0.9990964451531621], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04942538709525601, 0.1051848850480045, 0.16057083460796306, 0.21215879421004327, 0.2647569208131353, 0.31178079339673137, 0.3574034717754317, 0.3990101101965331, 0.4390755960236418, 0.47333907016563004, 0.5066146616901062, 0.5380173897982039, 0.5660427639584438, 0.5934863979541657, 0.6186790973436135, 0.6414450355008184, 0.6606902921634625, 0.6793182050122518, 0.6951158825814333, 0.7112533848259255, 0.7244831915334685, 0.7373554025476668, 0.7500340248023127, 0.7616878959478345, 0.7717561933730058, 0.7821645525277986, 0.7889868362151542, 0.7960933060198436, 0.8037048314984315, 0.8107108073094317, 0.8169572094004012, 0.8227610472423641, 0.8272825234669229, 0.8322572313988451, 0.8354537597649847, 0.840390682122447, 0.8443607794787265, 0.848625696918655, 0.8525872224357504, 0.8553428133039976, 0.8588655902849683, 0.8616353165539112, 0.8640740945276616, 0.8662853197699255, 0.8684269073335956, 0.8704968495539258, 0.872198017619994, 0.8735917030097266, 0.8757849317580761, 0.877617500799889, 0.8790073767552916, 0.880145313307925, 0.8803526146202048, 0.8804506480565276, 0.8817210482358145, 0.8823099444476247, 0.8827952409478923, 0.8837904427096542, 0.8851530800087188, 0.8857527769494886, 0.886583413928862, 0.8867624042848462, 0.8875297291330935, 0.888574325402766, 0.8895552011738599, 0.8897238045033866, 0.8905409042394185, 0.8912040813230067, 0.8914966473529802, 0.8920845461530738, 0.8932881303178869, 0.8938789567815801, 0.8943639314912234, 0.8952419208722215, 0.8958012072300294, 0.8964032507107162, 0.8969053802236056, 0.8969677012938655, 0.8970583523335302, 0.8977188162812766, 0.898665178723179, 0.8990255351449122, 0.8993519149417916, 0.8995835920940732, 0.9002600867532653, 0.9005108100056496, 0.9007710230092262, 0.9011537581047644, 0.9015582253383391, 0.9018520921870352, 0.9021165723508617, 0.902551976015625, 0.9029417802965926, 0.9031542087710749, 0.9035224698875668, 0.9035079899827709, 0.9036424719521143, 0.9037777717730927, 0.903628927907154, 0.9038601498566494, 0.9043287153020839, 0.9046639454755653, 0.9048781443956292, 0.9050434208352078, 0.9052308497418979, 0.9053252640617593, 0.9052393385121346, 0.9054814473472915, 0.9056749312364328, 0.9057036118703197, 0.9060712213158177, 0.9061680772056968, 0.9063326077287265, 0.9064165615172244, 0.9062245947480321, 0.906405828562009, 0.9065567319633382, 0.9066579829481037, 0.9066748371382332, 0.9066970653973014, 0.9066814792453725, 0.9067793740072057, 0.9066843738241056, 0.9068308072530655, 0.9069748043703795, 0.9067605458836427, 0.9069970183566489, 0.9072332281361949, 0.9072016763127863, 0.9071987232428781, 0.9073669639174607, 0.9073098314846755, 0.9073825416249881, 0.9073848865777001, 0.9077176163875506, 0.908151350560166, 0.9082263875203392, 0.908489233284495, 0.908430766704916, 0.9083415256895448, 0.9082357652045512, 0.9081416102767165, 0.9079225934979154, 0.9078932883085155, 0.9078791206693054, 0.9078175416690165, 0.9077753571086661, 0.907797396651941, 0.9077317830221385, 0.9078934868264759, 0.9080369612330602, 0.9082912470374651, 0.9080643260705409, 0.9079974630700379, 0.9077552104094949, 0.9076816083726871, 0.9076886087270599, 0.9077457961883147, 0.9076975496361248, 0.9077029558641538, 0.9075125089693801, 0.9076605485939029, 0.9078690854607927, 0.9081045672573339, 0.908252377191992, 0.9082633358206844, 0.9084329195014172, 0.9086231954164863, 0.9087822367087985, 0.9089264033805392, 0.9089187875153769, 0.9089506133478, 0.9089792565969809, 0.9090172425524936, 0.9088428808725455, 0.9087978776591614, 0.9087919368435465, 0.9085902481008334, 0.9086416913348013, 0.9088100605578724, 0.9089860069211364, 0.909168772710574, 0.9094197406484774, 0.9094482402752713, 0.9094138842917954, 0.909419585000417], "moving_var_accuracy_train": [0.023031205028516744, 0.04992679994405315, 0.07420654011533015, 0.0924532013553884, 0.10908529184362167, 0.11934538982120252, 0.12739531156401948, 0.13176610489397847, 0.13504102797721512, 0.1338288883506042, 0.132234813522742, 0.12952688282047567, 0.125154976784117, 0.12106055134415321, 0.11609967353469998, 0.11033788762828382, 0.10362257615304461, 0.09753205421256791, 0.09061670227291349, 0.08484119159026586, 0.07858873737319028, 0.07299371777079557, 0.06771670376950747, 0.06266194565544583, 0.057819411219518224, 0.053434959294290915, 0.04876026448008107, 0.04454377702732298, 0.04091588971291831, 0.03756750478067533, 0.03436383225181019, 0.03143454847518322, 0.028611344207105673, 0.02615431554015568, 0.023686836053505057, 0.02163239162368337, 0.01968562237185439, 0.017986055213890823, 0.01637364455043786, 0.014865323059671825, 0.013539724374932512, 0.012295932955684308, 0.0111597165893446, 0.010117931302716461, 0.009165588686103815, 0.008320360448347592, 0.0075439992007173265, 0.006837260854205686, 0.006210051650567996, 0.005634542422696649, 0.005106763769872955, 0.004629015908550979, 0.004179803401351097, 0.0037674265493304114, 0.003410082099126226, 0.0030789830773107364, 0.002776714048031851, 0.0025111157299428292, 0.002274686015727431, 0.0020542211331563112, 0.0018617763316621041, 0.0016781014446613637, 0.0015215547954166109, 0.0013801477809000338, 0.0012529731213600439, 0.0011313235187019872, 0.0010236654692470097, 0.0009264345200286799, 0.0008368173560317354, 0.000757527975362657, 0.0006888163156049418, 0.0006239807708407443, 0.0005651965732110962, 0.0005111029305269468, 0.0004617667218729436, 0.0004187255678628086, 0.0003792828319381979, 0.00034237926853264645, 0.0003090495827412232, 0.00027963383028140135, 0.0002539290747455202, 0.00023030948411384728, 0.0002080859265333108, 0.00018801267869765896, 0.00017040527469118903, 0.00015413693999905302, 0.0001393160600113097, 0.00012663538883657318, 0.00011432594093034349, 0.00010332123614636122, 9.389435527034811e-05, 8.505948452343454e-05, 7.711147316405526e-05, 6.978898901222677e-05, 6.31906424848267e-05, 5.705617075004657e-05, 5.152243013853928e-05, 4.6625874467371766e-05, 4.2231475157622825e-05, 3.816540312361344e-05, 3.446160323268951e-05, 3.122946649499239e-05, 2.830389206596401e-05, 2.5644725216972182e-05, 2.3443380591274007e-05, 2.120538505244446e-05, 1.931700559917156e-05, 1.7480289866850316e-05, 1.590605432208443e-05, 1.439633675231499e-05, 1.3005631649243035e-05, 1.1814963101361189e-05, 1.0654460886193232e-05, 9.739943605808041e-06, 8.840432444319235e-06, 8.104716951832957e-06, 7.374811004566658e-06, 6.706200669383246e-06, 6.142424576318719e-06, 5.547985122752234e-06, 4.9956787088774225e-06, 4.564319389116166e-06, 4.140017055631121e-06, 3.7860540485202318e-06, 3.434581845076033e-06, 3.1221529109442507e-06, 2.87919490527693e-06, 2.676922119099069e-06, 2.439058071056967e-06, 2.197073363122732e-06, 2.0045927911868005e-06, 1.8377624861298737e-06, 1.6691622996725382e-06, 1.5178268355021029e-06, 1.4017918266136818e-06, 1.2860150223474871e-06, 1.1634682784850086e-06, 1.0910284721586225e-06, 1.0034562988135017e-06, 9.079105245915096e-07, 8.1830635082535e-07, 7.530296890950856e-07, 6.798465451047709e-07, 6.227229525107244e-07, 5.679882533833406e-07, 5.310468641118308e-07, 5.018824858767154e-07, 4.521215405178108e-07, 4.069310395727331e-07, 3.7661017890759654e-07, 3.430142441021394e-07, 3.185603815472479e-07, 2.867357710420546e-07, 2.582066954847625e-07, 2.338853090485476e-07, 2.1361968843395084e-07, 2.083655097192845e-07, 1.9758381965115018e-07, 1.795409224888796e-07, 1.6160777100727516e-07, 1.5071941123831126e-07, 1.4193614484792765e-07, 1.3903122745819128e-07, 1.273179073779172e-07, 1.1635985679921711e-07, 1.1350502039148783e-07, 1.0813932955384675e-07, 1.0552501505902344e-07, 9.953493207974223e-08, 9.744786855124e-08, 8.78044693066308e-08, 8.237531527100802e-08, 7.472340106385907e-08, 6.852772752368828e-08, 6.528206344341703e-08, 6.437580171904911e-08, 5.859506650427501e-08, 5.308849583942836e-08, 4.835006199776913e-08, 4.3556102186658105e-08, 4.085237005865104e-08, 3.932040037933294e-08, 3.5697244249622274e-08, 3.347763572787846e-08, 3.0646708748578797e-08, 3.064431756543067e-08], "duration": 192630.422382, "accuracy_train": [0.5058678464724068, 0.6201745051218162, 0.6778517139050388, 0.698610245939461, 0.7541948207941123, 0.7565825143041712, 0.7913205980066446, 0.8032428435885014, 0.8383686323366556, 0.8231417915397747, 0.8524554292404946, 0.8685443775378369, 0.8696833399663161, 0.8976738057747323, 0.9041384404415835, 0.9054623333102622, 0.8950925301079733, 0.9158088850244556, 0.8973050263588963, 0.9285739519887413, 0.9140671863464378, 0.9309456037744556, 0.9381077830841639, 0.9413146860003692, 0.9427791692621816, 0.9541949289405685, 0.928249873108158, 0.9362712760128276, 0.9550559549764673, 0.9596822801310447, 0.95628900482189, 0.9607990725359912, 0.9528942875599853, 0.9662155877976191, 0.9464536253576044, 0.9690522693452381, 0.9649149464170359, 0.9754464285714286, 0.9717276324289406, 0.9686573545358066, 0.9768647693452381, 0.9737959334048542, 0.9745163690476191, 0.9742373511904762, 0.9740992842146549, 0.9791205241786637, 0.9786551339285714, 0.9792829241071429, 0.9836309523809523, 0.9835611979166666, 0.9832356770833334, 0.9844447544642857, 0.9795626629406607, 0.9763535970953304, 0.9839332217261905, 0.9812131581072352, 0.9796781994047619, 0.9841424851190477, 0.9864908854166666, 0.9838173247739018, 0.9878859747023809, 0.9823521205357143, 0.9887931432262828, 0.9896530877976191, 0.9907924107142857, 0.9872814360119048, 0.9893508184523809, 0.9898856026785714, 0.9888857886904762, 0.9906529017857143, 0.9932105654761905, 0.9919549851190477, 0.9922572544642857, 0.991746082214378, 0.9915132068452381, 0.9934198288690477, 0.9933035714285714, 0.9920014880952381, 0.9921413575119971, 0.9933500744047619, 0.9946986607142857, 0.99462890625, 0.9936290922619048, 0.9937918526785714, 0.9948614211309523, 0.9945126488095238, 0.9944428943452381, 0.9958612351190477, 0.9944893973214286, 0.9948846726190477, 0.99609375, 0.9957217261904762, 0.9959774925595238, 0.9958147321428571, 0.9960007440476191, 0.9955822172619048, 0.9956752232142857, 0.9961170014880952, 0.9963262648809523, 0.99609375, 0.9960239955357143, 0.9965587797619048, 0.9966517857142857, 0.9966982886904762, 0.9974655877976191, 0.9967447916666666, 0.9973725818452381, 0.9969544155477114, 0.9974194453096161, 0.9971168154761905, 0.9970009185239018, 0.9974423363095238, 0.9969308035714286, 0.9977911086309523, 0.9975353422619048, 0.9980003720238095, 0.9977911086309523, 0.9978143601190477, 0.9981166294642857, 0.9976050967261905, 0.9973493303571429, 0.9980701264880952, 0.9978841145833334, 0.9981631324404762, 0.9979771205357143, 0.9980701264880952, 0.9984188988095238, 0.9986049107142857, 0.9983026413690477, 0.9979306175595238, 0.9983491443452381, 0.9984654017857143, 0.9983258928571429, 0.9983723958333334, 0.9986281622023809, 0.9985816592261905, 0.9983723958333334, 0.9988374255952381, 0.9986979166666666, 0.9984886532738095, 0.9983956473214286, 0.9987211681547619, 0.9984886532738095, 0.9986979166666666, 0.9986746651785714, 0.9988839285714286, 0.9989769345238095, 0.9985816592261905, 0.99853515625, 0.9988606770833334, 0.9987676711309523, 0.9989071800595238, 0.9986281622023809, 0.9986514136904762, 0.9987444196428571, 0.9988145345953304, 0.9990699404761905, 0.9990234375, 0.9988606770833334, 0.9987211681547619, 0.9989769345238095, 0.9990234375, 0.9991396949404762, 0.9989769345238095, 0.9989769345238095, 0.9991629464285714, 0.9991396949404762, 0.9992094494047619, 0.9991629464285714, 0.9992559523809523, 0.9990234375, 0.9991861979166666, 0.9990931919642857, 0.9991396949404762, 0.9992327008928571, 0.9993024553571429, 0.9991629464285714, 0.9990234375, 0.9990001860119048, 0.9990931919642857, 0.9992094494047619, 0.9992559523809523, 0.9991629464285714, 0.9992327008928571, 0.9990466889880952, 0.9989304315476191], "end": "2016-02-02 21:11:29.245000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0], "moving_var_accuracy_valid": [0.0219858200056431, 0.04776933251256185, 0.07060082993923014, 0.08749260512845985, 0.10364241091500798, 0.11317937115833171, 0.12059429308451554, 0.12411487502240243, 0.12615057591122245, 0.12410138926260847, 0.12165663525808172, 0.1183661537259536, 0.1135983327247512, 0.10901687687429637, 0.10382723810961053, 0.0981091057602486, 0.09163161432032316, 0.08559144512220965, 0.07927840015920705, 0.07369433095150527, 0.06790014792602529, 0.06260137748096921, 0.05778796689335633, 0.05323148461810852, 0.04882067167367308, 0.0449136099689622, 0.04084114096446282, 0.0372115440857812, 0.03401180755820382, 0.03105238007596232, 0.0282982999201047, 0.025771630731356434, 0.02337846138346404, 0.021263344716189, 0.019228970386929913, 0.01752543216950943, 0.01591474400972352, 0.014486975295675828, 0.013179520925911624, 0.011929908362618969, 0.010848607145275987, 0.009832788883192242, 0.008903038736920272, 0.008056740516876472, 0.007292344040824622, 0.00660167158390171, 0.005967550180612634, 0.005388276393241355, 0.004892741025000505, 0.004433691706137553, 0.004007708332066456, 0.0036185915952401853, 0.003257119200222823, 0.002931493775192276, 0.0026528696472128406, 0.0023907038712261152, 0.002153753098342052, 0.001947291627427374, 0.0017692734883638578, 0.0015955828673143888, 0.0014422342007064735, 0.0012982991185636447, 0.0011737682935119202, 0.001066212096460253, 0.0009682499423190989, 0.0008716807918317364, 0.0007905215804561723, 0.000715427657008325, 0.0006446552452445422, 0.0005833003457124509, 0.0005380078447173056, 0.0004873487434373774, 0.0004407306733145811, 0.0004035953941614325, 0.00036605106581556025, 0.00033270806640774175, 0.0003017064661963968, 0.00027157077481894225, 0.0002444876558359786, 0.00022396480388883533, 0.00020962874034294416, 0.00018983457706480967, 0.00017180983330462721, 0.00015511191870016866, 0.00014371953204539038, 0.00012991333818442686, 0.00011753140163105746, 0.00010709663684816159, 9.78593168506661e-05, 8.88506046884633e-05, 8.059509203313668e-05, 7.42417699914262e-05, 6.818511938942976e-05, 6.177274016142475e-05, 5.681601239456108e-05, 5.1136298163891044e-05, 4.618543694820823e-05, 4.1731647627398314e-05, 3.775787333250692e-05, 3.446325830861249e-05, 3.2992914667647915e-05, 3.070503662379428e-05, 2.8047463557623952e-05, 2.5488563915179727e-05, 2.3255873879229017e-05, 2.1010513065460163e-05, 1.897591055961894e-05, 1.7605869696206902e-05, 1.618220686480152e-05, 1.4571389387162723e-05, 1.4330480788221606e-05, 1.2981862280037838e-05, 1.1927308689109948e-05, 1.0798011967627204e-05, 1.0049871935131723e-05, 9.340495999576105e-06, 8.61139292841304e-06, 7.842519492815732e-06, 7.060824117058418e-06, 6.359188564863426e-06, 5.72545606156465e-06, 5.239160914957669e-06, 4.7964701365633445e-06, 4.509807864959661e-06, 4.2454436066161945e-06, 4.234059538203039e-06, 4.3139266587898e-06, 4.3846895324891245e-06, 3.955180237283908e-06, 3.5597406991524582e-06, 3.458510950493521e-06, 3.1420368893278005e-06, 2.87541408093348e-06, 2.587922162069127e-06, 3.325512083130418e-06, 4.68608886726687e-06, 4.268154889068434e-06, 4.463130461773602e-06, 4.047582483945267e-06, 3.714499864970942e-06, 3.4437174001486634e-06, 3.1791320140536948e-06, 3.2929339572162743e-06, 2.971369708626558e-06, 2.676039235770957e-06, 2.4425630716831648e-06, 2.2143225987024916e-06, 1.9972620120421642e-06, 1.8362821465807204e-06, 1.887987014957212e-06, 1.8844524615640532e-06, 2.277958648303881e-06, 2.513600910541927e-06, 2.302476767013964e-06, 2.600406254173803e-06, 2.389120967156896e-06, 2.1506499150933177e-06, 1.9650185751069607e-06, 1.7894662857801787e-06, 1.6107827029156842e-06, 1.776134610185005e-06, 1.7957627230262608e-06, 2.0075750743936777e-06, 2.305882655474815e-06, 2.2719243809802485e-06, 2.045812766767579e-06, 2.1000591130286626e-06, 2.2158975164243154e-06, 2.2219549587249225e-06, 2.186815726019363e-06, 1.9686561660369665e-06, 1.7809065019181083e-06, 1.6101997732390174e-06, 1.4621661912610683e-06, 1.5895675310440517e-06, 1.4488383808736714e-06, 1.3042721823978404e-06, 1.5399501045927002e-06, 1.4097727510230795e-06, 1.523929233418788e-06, 1.6501504147892469e-06, 1.785765377408959e-06, 2.1740529923676274e-06, 1.9639577516773535e-06, 1.7781849789149981e-06, 1.6006589637326014e-06], "accuracy_test": 0.8845304528061224, "start": "2016-01-31 15:40:58.822000", "learning_rate_per_epoch": [0.0006276950589381158, 0.0006171806016936898, 0.000606842280831188, 0.0005966771277599037, 0.0005866822903044522, 0.0005768548580817878, 0.0005671920371241868, 0.000557691091671586, 0.0005483492859639227, 0.0005391639424487948, 0.0005301324999891222, 0.0005212523392401636, 0.0005125208990648389, 0.0005039357347413898, 0.0004954944015480578, 0.00048719445476308465, 0.0004790335369762033, 0.0004710093198809773, 0.0004631195042748004, 0.0004553618491627276, 0.0004477341426536441, 0.00044023420196026564, 0.0004328599025029689, 0.00042560911970213056, 0.00041847978718578815, 0.0004114698967896402, 0.0004045774112455547, 0.00039780038059689105, 0.0003911368839908391, 0.0003845850005745888, 0.00037814286770299077, 0.00037180865183472633, 0.00036558054853230715, 0.0003594567533582449, 0.00035343554918654263, 0.00034751518978737295, 0.0003416940162423998, 0.00033597034052945673, 0.00033034253283403814, 0.00032480902154929936, 0.0003193681768607348, 0.00031401848536916077, 0.000308758404571563, 0.00030358642106875777, 0.00029850107966922224, 0.00029350092518143356, 0.00028858453151769936, 0.0002837505016941577, 0.0002789974387269467, 0.0002743240038398653, 0.0002697288291528821, 0.00026521063409745693, 0.00026076813810504973, 0.0002564000606071204, 0.0002521051501389593, 0.00024788218433968723, 0.00024372994084842503, 0.00023964725551195443, 0.00023563294962514192, 0.0002316858881385997, 0.00022780495055485517, 0.00022398901637643576, 0.00022023700876161456, 0.00021654785086866468, 0.00021292048040777445, 0.00020935387874487787, 0.00020584702724590898, 0.00020239890727680176, 0.00019900854385923594, 0.00019567497656680644, 0.00019239724497310817, 0.00018917441775556654, 0.00018600557814352214, 0.00018288982391823083, 0.00017982626741286367, 0.00017681402096059173, 0.00017385222599841654, 0.00017094005306717008, 0.0001680766581557691, 0.00016526122635696083, 0.0001624929573154077, 0.00015977106522768736, 0.0001570947642903775, 0.00015446329780388623, 0.0001518759090686217, 0.00014933185593690723, 0.00014683042536489666, 0.00014437088975682855, 0.00014195255062077194, 0.00013957472401671112, 0.00013723672600463033, 0.00013493788719642907, 0.0001326775673078373, 0.00013045509695075452, 0.00012826986494474113, 0.00012612123100552708, 0.000124008598504588, 0.00012193134898552671, 0.00011988889309577644, 0.00011788064875872806, 0.00011590604844968766, 0.00011396452464396134, 0.0001120555170928128, 0.00011017848737537861, 0.00010833290434675291, 0.00010651823686202988, 0.00010473396105226129, 0.00010297957487637177, 0.00010125457629328594, 9.955847781384364e-05, 9.789078467292711e-05, 9.625103120924905e-05, 9.463874448556453e-05, 9.305346611654386e-05, 9.149473771685734e-05, 8.996212272904813e-05, 8.845517731970176e-05, 8.69734794832766e-05, 8.551659993827343e-05, 8.408412395510823e-05, 8.26756440801546e-05, 8.129075285978615e-05, 7.992906466824934e-05, 7.859018660383299e-05, 7.727373304078355e-05, 7.597933290526271e-05, 7.470661512343213e-05, 7.345521589741111e-05, 7.222477870527655e-05, 7.101495430106297e-05, 6.98253934388049e-05, 6.865575414849445e-05, 6.7505709012039e-05, 6.637493061134592e-05, 6.526309152832255e-05, 6.416987889679149e-05, 6.309497985057533e-05, 6.203808152349666e-05, 6.09988892392721e-05, 5.997710468363948e-05, 5.897243681829423e-05, 5.798459824291058e-05, 5.7013305195141584e-05, 5.605828482657671e-05, 5.511926065082662e-05, 5.419596709543839e-05, 5.328813858795911e-05, 5.2395516831893474e-05, 5.1517847168724984e-05, 5.065487857791595e-05, 4.98063673148863e-05, 4.897206599707715e-05, 4.815174179384485e-05, 4.734515823656693e-05, 4.655208613257855e-05, 4.577229992719367e-05, 4.500557406572625e-05, 4.425169026944786e-05, 4.35104375355877e-05, 4.278160122339614e-05, 4.2064973968081176e-05, 4.136034840485081e-05, 4.066752808284946e-05, 3.998631291324273e-05, 3.931650644517504e-05, 3.865791950374842e-05, 3.8010366552043706e-05, 3.7373658415162936e-05, 3.674761683214456e-05, 3.6132063542027026e-05, 3.552682028384879e-05, 3.493171607260592e-05, 3.4346579923294485e-05, 3.377124448888935e-05, 3.3205546060344204e-05, 3.264932456659153e-05, 3.210241993656382e-05, 3.1564675737172365e-05, 3.103593917330727e-05, 3.0516061087837443e-05, 3.000489050464239e-05, 2.9502281904569827e-05, 2.9008093406446278e-05, 2.8522183129098266e-05, 2.804441101034172e-05, 2.7574642444960773e-05], "accuracy_train_first": 0.5058678464724068, "accuracy_train_last": 0.9989304315476191, "batch_size_eval": 1024, "accuracy_train_std": [0.02146152393958741, 0.019871237875007927, 0.017999810256239635, 0.016773337801027684, 0.018514775934398407, 0.021262311382532234, 0.018520040438205605, 0.020782033360390348, 0.020996460884638107, 0.022306697981610862, 0.02023117407827819, 0.020381884482180503, 0.020892580406426543, 0.019587776876485993, 0.0183735826065732, 0.01868549755589462, 0.020317184149232875, 0.017097984711221717, 0.018133515548581988, 0.01440458579284852, 0.01691525128010682, 0.01595352877300577, 0.013093802659229593, 0.014116459597430223, 0.013929379824945893, 0.011949964049430287, 0.015142389815541297, 0.013810824998500601, 0.012023547977461118, 0.010286285224071537, 0.011082416434074397, 0.009847039084771664, 0.010430702526819253, 0.009807526187957208, 0.012488650759101223, 0.009353487297949535, 0.00921811238162597, 0.00870748826840948, 0.008248653589864166, 0.00966107594683063, 0.007676125859012592, 0.007598270079163934, 0.008186637308283255, 0.008086572063678316, 0.007462845873801888, 0.0066890474104060365, 0.006750944540996083, 0.007816962180996204, 0.005661534434157062, 0.00626363326982222, 0.005905374477623468, 0.0054763548295214655, 0.006466971309301715, 0.007881600792161977, 0.005520992284108983, 0.006110076081427458, 0.006631037423663991, 0.005369231294928472, 0.005486809285817705, 0.005169103713142521, 0.00483166817766942, 0.006218066998018866, 0.0038968516626906946, 0.004138046373727547, 0.003812960482342759, 0.004572983133055472, 0.004169478732595272, 0.004282378760650343, 0.004505272077672196, 0.0034172568956238533, 0.003160492250287611, 0.003086760932901058, 0.0035364435644738477, 0.0033512334345713515, 0.003885782123511342, 0.0034299688619826127, 0.0036137929260570923, 0.0032892433101313276, 0.0034364948855024257, 0.0033235804287956917, 0.002402903772835531, 0.0026637926054198287, 0.002663691125673305, 0.002590950366574033, 0.002411550369016318, 0.0025120217328998334, 0.002605515733949833, 0.0024373061163278755, 0.0022934266493824774, 0.00284961192333585, 0.0022653203048397692, 0.002583322993365169, 0.002143807377113003, 0.002505988390124159, 0.0026685578004842954, 0.0025504667412206265, 0.0022667517870078014, 0.0024621338787490714, 0.0018676604936777533, 0.0022248649021401946, 0.002299077231767693, 0.0020017897367960273, 0.0018225370109993884, 0.00208746053640843, 0.0018948179624143728, 0.001949245899845116, 0.0014685298246501235, 0.0018967382308721994, 0.0017158664135122617, 0.001782344484443527, 0.002059615346050678, 0.001704192913114648, 0.0017774846404033104, 0.0017188810991700353, 0.0015548970886626197, 0.0014756911879299137, 0.001461888198439188, 0.001780523597384361, 0.0012855781200501381, 0.0017727639617872856, 0.0016129227302850283, 0.001763591268489718, 0.0013463796216335033, 0.0014485135906968489, 0.001135520409884187, 0.0018018028056230816, 0.0012417252532383452, 0.0012081827619760583, 0.0012796770745737548, 0.0014795329492125217, 0.0011766723334151782, 0.001169991222601295, 0.0011131611982501696, 0.0013421567791724156, 0.0009056148667294665, 0.001282209419546339, 0.0012726871450338551, 0.001070578909339782, 0.0013251308453101755, 0.001264376499657973, 0.0012575164883733222, 0.001157214205555181, 0.0011711458574649395, 0.0011607127952333225, 0.0012754453266278349, 0.0013573771874373535, 0.0012954230168512018, 0.0013171511382318217, 0.0014014688584374662, 0.0011459469429270469, 0.0011683728168155796, 0.000957837143045293, 0.0011683728168155798, 0.0011855979151768937, 0.0012658721715788875, 0.0012701329630954294, 0.0010856229101496235, 0.0010439892262204078, 0.0011655931788964176, 0.0013391323102661763, 0.0013128342832489867, 0.0011475969753769592, 0.0012462884378029572, 0.001106340890380424, 0.0011466543904332174, 0.0010124414554072377, 0.0008838624353026513, 0.0008318705273436718, 0.0009665462095808466, 0.000948478332141515, 0.0009995435853889824, 0.0010201548999479307, 0.0009623419869128942, 0.0010698211560944328, 0.0008665664598950998, 0.000859990792824913, 0.000813469851401409, 0.0010439892262204078, 0.0008911722422217635, 0.0010738563280092532, 0.0007454994206604074, 0.0009952071502526364, 0.0008409198902541446, 0.0008665664598950998, 0.0009645865193773968, 0.0010398381591795898], "accuracy_test_std": 0.006279102523250017, "error_valid": [0.5057461290474398, 0.39297963337725905, 0.3409556193524097, 0.3235495693712349, 0.2618599397590362, 0.26500435335090367, 0.2319924228162651, 0.2265301440135542, 0.20033503153237953, 0.21828966255647586, 0.1939050145896084, 0.17935805722891573, 0.18172886859939763, 0.15952089608433728, 0.1545866081513554, 0.15366152108433728, 0.16610239787274095, 0.1530305793486446, 0.16270501929593373, 0.1435090949736446, 0.1564485480986446, 0.14679469832454817, 0.1358583749058735, 0.13342726374246983, 0.13762912980045183, 0.12416021507906627, 0.1496126105986446, 0.13994846573795183, 0.12779143919427716, 0.12623541039156627, 0.1268251717808735, 0.12500441217996983, 0.13202419051204817, 0.12297039721385539, 0.13577748493975905, 0.1151770166603916, 0.11990834431475905, 0.11299004612198793, 0.1117590479103916, 0.11985686888177716, 0.10942941688629515, 0.11343714702560237, 0.11397690370858427, 0.11381365304969882, 0.11229880459337349, 0.11087367046310237, 0.1124914697853916, 0.11386512848268071, 0.10447600950677716, 0.10588937782379515, 0.10848373964608427, 0.10961325771837349, 0.11778167356927716, 0.11866705101656627, 0.10684535015060237, 0.11238998964608427, 0.11283709054969882, 0.10725274143448793, 0.10258318429969882, 0.10884995058358427, 0.10594085325677716, 0.11162668251129515, 0.10556434723268071, 0.10202430817018071, 0.10161691688629515, 0.10875876553087349, 0.10210519813629515, 0.10282732492469882, 0.10587025837725905, 0.10262436464608427, 0.09587961219879515, 0.10080360504518071, 0.10127129612198793, 0.09685617469879515, 0.09916521554969882, 0.09817835796310237, 0.0985754541603916, 0.10247140907379515, 0.10212578830948793, 0.09633700818900603, 0.09281755929969882, 0.09773125705948793, 0.09771066688629515, 0.0983313135353916, 0.09365146131400603, 0.0972326807228916, 0.09688705995858427, 0.0954016260353916, 0.09480156955948793, 0.09550310617469882, 0.09550310617469882, 0.09352939100150603, 0.09354998117469882, 0.09493393495858427, 0.09316318006400603, 0.0966223291603916, 0.09514719032379515, 0.09500452983810237, 0.09771066688629515, 0.0940588525978916, 0.09145419568900603, 0.09231898296310237, 0.09319406532379515, 0.09346909120858427, 0.0930822900978916, 0.09382500705948793, 0.09553399143448793, 0.09233957313629515, 0.09258371376129515, 0.09403826242469882, 0.09062029367469882, 0.0929602197853916, 0.09218661756400603, 0.09282785438629515, 0.09550310617469882, 0.09196306711219882, 0.09208513742469882, 0.09243075818900603, 0.09317347515060237, 0.09310288027108427, 0.09345879612198793, 0.09233957313629515, 0.09417062782379515, 0.09185129188629515, 0.09172922157379515, 0.09516778049698793, 0.09087472938629515, 0.0906408838478916, 0.0930822900978916, 0.09282785438629515, 0.09111887001129515, 0.0932043604103916, 0.09196306711219882, 0.0925940088478916, 0.08928781532379515, 0.08794504188629515, 0.09109827983810237, 0.08914515483810237, 0.09209543251129515, 0.09246164344879515, 0.0927160791603916, 0.09270578407379515, 0.09404855751129515, 0.09237045839608427, 0.09224838808358427, 0.09273666933358427, 0.09260430393448793, 0.09200424745858427, 0.09285873964608427, 0.09065117893448793, 0.09067176910768071, 0.0894201807228916, 0.09397796263177716, 0.09260430393448793, 0.0944250635353916, 0.09298080995858427, 0.09224838808358427, 0.0917395166603916, 0.09273666933358427, 0.09224838808358427, 0.09420151308358427, 0.0910070947853916, 0.09025408273719882, 0.08977609657379515, 0.09041733339608427, 0.09163803652108427, 0.09004082737198793, 0.0896643213478916, 0.0897863916603916, 0.08977609657379515, 0.09114975527108427, 0.0907629541603916, 0.0907629541603916, 0.0906408838478916, 0.09272637424698793, 0.09160715126129515, 0.09126153049698793, 0.09322495058358427, 0.09089531955948793, 0.08967461643448793, 0.08943047580948793, 0.08918633518448793, 0.0883215479103916, 0.09029526308358427, 0.09089531955948793, 0.09052910862198793], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.01675086474369981, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.0006383886339642665, "optimization": "rmsprop", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.3058111596376458e-07, "rotation_range": [0, 0], "momentum": 0.7097596297704343}, "accuracy_valid_max": 0.9120549581137049, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.9094708913780121, "accuracy_valid_std": [0.019412218193598736, 0.018259026307298074, 0.015538503799592804, 0.01416332518303939, 0.02127076489008029, 0.010868950999126676, 0.016949966924824332, 0.014217808138567635, 0.011930168311035485, 0.013729155667375684, 0.01575731234357933, 0.012807102588543787, 0.012752539133329329, 0.013101490613474136, 0.01624330065338025, 0.012906885309275624, 0.014504020774174882, 0.012301213936810069, 0.014833713697676124, 0.013004149379303807, 0.013219611724731352, 0.010889411031297154, 0.012467327487202608, 0.010797662452259157, 0.007638425720387526, 0.0067103155627788475, 0.010812693459402889, 0.009081822727946514, 0.011563860851512925, 0.00858207605122168, 0.01152894727442907, 0.011600005831922885, 0.006295710654770842, 0.0070998299223199975, 0.011683526614722108, 0.011186262159861666, 0.0071760966079727284, 0.009573668708586865, 0.010209621211472618, 0.008230256673859385, 0.00970235766990117, 0.014658947062923948, 0.007753317052980268, 0.012294928273757779, 0.0055958472536758565, 0.011724666759856792, 0.00947191893530908, 0.007358801218460385, 0.004840459495774452, 0.00899534657425695, 0.008288267513969832, 0.00583809276629804, 0.0078432008997057, 0.006941545015942364, 0.011927086490103848, 0.007329654877328813, 0.012375733726922928, 0.006530055339272317, 0.008431723509920108, 0.005563080492506856, 0.007476788839640031, 0.01094644362908032, 0.004753823336102526, 0.004748211799013156, 0.008014362825512123, 0.0063869943675270695, 0.007456125076792353, 0.009491380257032162, 0.010246178331373371, 0.006006495921436486, 0.009088548123570902, 0.004173067090264908, 0.0074501380135790695, 0.00794880614345276, 0.00682642241487483, 0.008899375506172846, 0.005753760690969962, 0.00657727048690834, 0.006143964260668716, 0.008248389872388144, 0.0053667450499091055, 0.00608087387597753, 0.0070282540051304155, 0.005109208514874736, 0.007848937197715126, 0.004089542644252586, 0.003902127741426881, 0.004503809532827672, 0.006232738808849816, 0.0056429802029397, 0.0061871259245720525, 0.007591636853862367, 0.006537921107692654, 0.0028581176439059926, 0.007812345921036271, 0.003994244228717714, 0.004180183948819809, 0.005255203938658919, 0.004813554887965842, 0.005516064193176828, 0.00808731807076947, 0.006798285822162769, 0.004453343802130638, 0.0046273704907375144, 0.00498310233256993, 0.003222313102449472, 0.005614712585629253, 0.003802176017788747, 0.005310239605526459, 0.00530639156020355, 0.004458288506554027, 0.006270257984931455, 0.006444252129737282, 0.005446300583168841, 0.007775181995487751, 0.006615407465127135, 0.00597671465961203, 0.007582278038915698, 0.00820751077821497, 0.006307817524593092, 0.006689963585162262, 0.006091494683975053, 0.004441394830335409, 0.004830235127561425, 0.0051755796772861885, 0.002746700060926872, 0.005128204102587216, 0.004618721470425932, 0.006907929679043778, 0.005402346979232465, 0.005501401437132379, 0.003392458266397862, 0.005087457370538119, 0.004744504015371382, 0.003310449872629929, 0.0024725146022205394, 0.005280287836189311, 0.005178946064167619, 0.005315240931380669, 0.004186621246870046, 0.003589327313068105, 0.004831405789981903, 0.003954927822761454, 0.004247188670938529, 0.005645601274665458, 0.00413844998287072, 0.0038157483714203085, 0.00553201256379298, 0.0055738972523808735, 0.0034283363942007295, 0.004845540377063022, 0.004988791535897051, 0.0056858678676191595, 0.002765103404947349, 0.0048732485045875846, 0.005019098376367816, 0.00497194694053118, 0.0032960421599968173, 0.0035491992417717236, 0.0035103404772437842, 0.0030605023097388766, 0.002288370807163771, 0.0038660788276216307, 0.003852251734226186, 0.004908550602074712, 0.004578753566915911, 0.005035911534820196, 0.0022378777078784972, 0.004274252266494228, 0.004961351143288764, 0.006501349140264636, 0.004909511823299366, 0.0028511859889020883, 0.0031445979432192096, 0.0034415858535749924, 0.003115811046778223, 0.003130380796429772, 0.0037181735524066234, 0.0024116397032459026, 0.005302117687657444, 0.003915875111367388, 0.002978891765082205, 0.002966962393104862, 0.004145558439733752, 0.004125733786376118, 0.003259511204192707], "accuracy_valid": [0.49425387095256024, 0.607020366622741, 0.6590443806475903, 0.6764504306287651, 0.7381400602409638, 0.7349956466490963, 0.7680075771837349, 0.7734698559864458, 0.7996649684676205, 0.7817103374435241, 0.8060949854103916, 0.8206419427710843, 0.8182711314006024, 0.8404791039156627, 0.8454133918486446, 0.8463384789156627, 0.833897602127259, 0.8469694206513554, 0.8372949807040663, 0.8564909050263554, 0.8435514519013554, 0.8532053016754518, 0.8641416250941265, 0.8665727362575302, 0.8623708701995482, 0.8758397849209337, 0.8503873894013554, 0.8600515342620482, 0.8722085608057228, 0.8737645896084337, 0.8731748282191265, 0.8749955878200302, 0.8679758094879518, 0.8770296027861446, 0.864222515060241, 0.8848229833396084, 0.880091655685241, 0.8870099538780121, 0.8882409520896084, 0.8801431311182228, 0.8905705831137049, 0.8865628529743976, 0.8860230962914157, 0.8861863469503012, 0.8877011954066265, 0.8891263295368976, 0.8875085302146084, 0.8861348715173193, 0.8955239904932228, 0.8941106221762049, 0.8915162603539157, 0.8903867422816265, 0.8822183264307228, 0.8813329489834337, 0.8931546498493976, 0.8876100103539157, 0.8871629094503012, 0.8927472585655121, 0.8974168157003012, 0.8911500494164157, 0.8940591467432228, 0.8883733174887049, 0.8944356527673193, 0.8979756918298193, 0.8983830831137049, 0.8912412344691265, 0.8978948018637049, 0.8971726750753012, 0.894129741622741, 0.8973756353539157, 0.9041203878012049, 0.8991963949548193, 0.8987287038780121, 0.9031438253012049, 0.9008347844503012, 0.9018216420368976, 0.9014245458396084, 0.8975285909262049, 0.8978742116905121, 0.903662991810994, 0.9071824407003012, 0.9022687429405121, 0.9022893331137049, 0.9016686864646084, 0.906348538685994, 0.9027673192771084, 0.9031129400414157, 0.9045983739646084, 0.9051984304405121, 0.9044968938253012, 0.9044968938253012, 0.906470608998494, 0.9064500188253012, 0.9050660650414157, 0.906836819935994, 0.9033776708396084, 0.9048528096762049, 0.9049954701618976, 0.9022893331137049, 0.9059411474021084, 0.908545804310994, 0.9076810170368976, 0.9068059346762049, 0.9065309087914157, 0.9069177099021084, 0.9061749929405121, 0.9044660085655121, 0.9076604268637049, 0.9074162862387049, 0.9059617375753012, 0.9093797063253012, 0.9070397802146084, 0.907813382435994, 0.9071721456137049, 0.9044968938253012, 0.9080369328878012, 0.9079148625753012, 0.907569241810994, 0.9068265248493976, 0.9068971197289157, 0.9065412038780121, 0.9076604268637049, 0.9058293721762049, 0.9081487081137049, 0.9082707784262049, 0.9048322195030121, 0.9091252706137049, 0.9093591161521084, 0.9069177099021084, 0.9071721456137049, 0.9088811299887049, 0.9067956395896084, 0.9080369328878012, 0.9074059911521084, 0.9107121846762049, 0.9120549581137049, 0.9089017201618976, 0.9108548451618976, 0.9079045674887049, 0.9075383565512049, 0.9072839208396084, 0.9072942159262049, 0.9059514424887049, 0.9076295416039157, 0.9077516119164157, 0.9072633306664157, 0.9073956960655121, 0.9079957525414157, 0.9071412603539157, 0.9093488210655121, 0.9093282308923193, 0.9105798192771084, 0.9060220373682228, 0.9073956960655121, 0.9055749364646084, 0.9070191900414157, 0.9077516119164157, 0.9082604833396084, 0.9072633306664157, 0.9077516119164157, 0.9057984869164157, 0.9089929052146084, 0.9097459172628012, 0.9102239034262049, 0.9095826666039157, 0.9083619634789157, 0.9099591726280121, 0.9103356786521084, 0.9102136083396084, 0.9102239034262049, 0.9088502447289157, 0.9092370458396084, 0.9092370458396084, 0.9093591161521084, 0.9072736257530121, 0.9083928487387049, 0.9087384695030121, 0.9067750494164157, 0.9091046804405121, 0.9103253835655121, 0.9105695241905121, 0.9108136648155121, 0.9116784520896084, 0.9097047369164157, 0.9091046804405121, 0.9094708913780121], "seed": 474589054, "model": "residualv3", "loss_std": [0.32590532302856445, 0.19330978393554688, 0.17634059488773346, 0.17009954154491425, 0.1650596410036087, 0.16457132995128632, 0.15868836641311646, 0.15394872426986694, 0.15080159902572632, 0.14724306762218475, 0.14125485718250275, 0.1376979500055313, 0.13294439017772675, 0.12839850783348083, 0.12441449612379074, 0.1219540610909462, 0.11806239932775497, 0.11190485954284668, 0.11100758612155914, 0.10698168724775314, 0.10288423299789429, 0.10088104754686356, 0.09862564504146576, 0.09413012862205505, 0.0898098573088646, 0.09023306518793106, 0.08402104675769806, 0.08469071984291077, 0.07848427444696426, 0.07685823738574982, 0.0751740112900734, 0.0740135982632637, 0.06888475269079208, 0.0705418586730957, 0.06753131002187729, 0.06905576586723328, 0.06368085741996765, 0.06236930936574936, 0.061566922813653946, 0.058848053216934204, 0.05753784254193306, 0.05364742875099182, 0.057226166129112244, 0.05548788979649544, 0.05264882370829582, 0.05156485363841057, 0.04873994365334511, 0.04805721715092659, 0.046985093504190445, 0.04487009346485138, 0.04741889238357544, 0.042398709803819656, 0.04410737752914429, 0.043155595660209656, 0.03909025713801384, 0.04193273186683655, 0.039060767740011215, 0.038244884461164474, 0.036975469440221786, 0.03548285737633705, 0.034539323300123215, 0.03511839732527733, 0.03475549444556236, 0.032752785831689835, 0.03198922425508499, 0.032414283603429794, 0.03184228762984276, 0.030391760170459747, 0.028595400974154472, 0.029944466426968575, 0.029357504099607468, 0.02796054072678089, 0.02653413452208042, 0.027222631499171257, 0.0261488389223814, 0.025311220437288284, 0.026538167148828506, 0.026647668331861496, 0.024449678137898445, 0.023597195744514465, 0.025161800906062126, 0.021887412294745445, 0.021231364458799362, 0.0210269782692194, 0.0221084151417017, 0.02071535401046276, 0.02055988647043705, 0.0212600938975811, 0.019095195457339287, 0.018710989505052567, 0.019209634512662888, 0.018457403406500816, 0.016258083283901215, 0.018808268010616302, 0.016316214576363564, 0.016772067174315453, 0.015492637641727924, 0.01703118532896042, 0.015890581533312798, 0.014495824463665485, 0.015435355715453625, 0.0151577303186059, 0.015006056986749172, 0.014729590155184269, 0.012920765206217766, 0.01350722461938858, 0.013217021711170673, 0.013519595377147198, 0.013443759642541409, 0.012666367925703526, 0.01325757335871458, 0.012429732829332352, 0.011747986078262329, 0.012967663817107677, 0.012083311565220356, 0.011487189680337906, 0.01060224324464798, 0.011873151175677776, 0.011360864154994488, 0.010935181751847267, 0.011402343399822712, 0.010450922884047031, 0.00927783828228712, 0.009643372148275375, 0.01022285781800747, 0.009340297430753708, 0.009071852080523968, 0.008262577466666698, 0.009122501127421856, 0.008393888361752033, 0.007722921669483185, 0.008561295457184315, 0.008404338732361794, 0.008486957289278507, 0.00874029565602541, 0.00816790759563446, 0.008038366213440895, 0.007903104647994041, 0.008000819012522697, 0.006783547345548868, 0.007446925155818462, 0.006680116523057222, 0.007413318380713463, 0.007342582102864981, 0.007391862105578184, 0.0065401457250118256, 0.005649135448038578, 0.006488791201263666, 0.006510271690785885, 0.0065487464889883995, 0.005900329910218716, 0.006374822463840246, 0.005841601174324751, 0.006148471496999264, 0.0059589664451777935, 0.006262012291699648, 0.005993962753564119, 0.006479760631918907, 0.006484190467745066, 0.005652392283082008, 0.005247216671705246, 0.006200416479259729, 0.004493955988436937, 0.005371935199946165, 0.005330570042133331, 0.005433750804513693, 0.004964918829500675, 0.0052505782805383205, 0.005793602205812931, 0.005040086340159178, 0.005254244897514582, 0.004179639276117086, 0.005363373551517725, 0.004119821358472109, 0.004566170275211334, 0.005063326098024845, 0.004390941467136145, 0.004579578526318073, 0.004951719660311937, 0.004161844961345196, 0.00477329408749938, 0.0038022780790925026, 0.004304965492337942, 0.004705579951405525, 0.0037412974052131176, 0.00402639526873827]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:30 2016", "state": "available"}], "summary": "13d871c67e0d889d2feb7bbbdb0afd63"}