{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 64, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.557749629020691, 1.1460188627243042, 0.9390133619308472, 0.8171157240867615, 0.7304720282554626, 0.6693310141563416, 0.6183592677116394, 0.577146053314209, 0.5430392026901245, 0.5114654898643494, 0.4850507378578186, 0.4606618583202362, 0.44035694003105164, 0.4200076758861542, 0.4006973206996918, 0.38423413038253784, 0.36617419123649597, 0.35183435678482056, 0.3390563428401947, 0.32326754927635193, 0.31140097975730896, 0.2997244894504547, 0.2876321077346802, 0.27855169773101807, 0.2651735842227936, 0.25588902831077576, 0.2470853477716446, 0.2402687966823578, 0.23150873184204102, 0.22249522805213928, 0.2146478295326233, 0.20750585198402405, 0.20096562802791595, 0.1947135627269745, 0.18868283927440643, 0.18485349416732788, 0.17833758890628815, 0.17225290834903717, 0.16459143161773682, 0.16339582204818726, 0.15560054779052734, 0.15449942648410797, 0.14720292389392853, 0.14285661280155182, 0.14196819067001343, 0.14070013165473938, 0.13120624423027039, 0.13121791183948517, 0.12747560441493988, 0.12379523366689682, 0.12193049490451813, 0.12093427032232285, 0.11652666330337524, 0.11222892254590988, 0.11336251348257065, 0.10840320587158203, 0.10866300016641617, 0.10547003895044327, 0.10310127586126328, 0.10033708065748215, 0.10008199512958527, 0.09906099736690521, 0.09451869130134583, 0.09387759119272232, 0.09134161472320557, 0.08982278406620026, 0.09098263829946518, 0.08815911412239075, 0.0892629399895668, 0.08357387781143188, 0.08469455689191818, 0.08159545809030533, 0.08036710321903229, 0.08141207695007324, 0.08000282198190689, 0.07840880751609802, 0.07600466161966324, 0.07697445154190063, 0.07339039444923401, 0.07394764572381973, 0.07203072309494019, 0.07499891519546509, 0.07080317288637161, 0.07183068990707397, 0.07056160271167755, 0.06791894882917404, 0.06990200281143188, 0.06785009801387787, 0.06815565377473831, 0.06434830278158188, 0.06438945233821869, 0.06434871256351471, 0.06493889540433884, 0.06023670360445976, 0.06348364800214767, 0.06435688585042953, 0.06023892015218735, 0.061357274651527405, 0.0581350177526474, 0.06104375049471855, 0.057971011847257614, 0.057361457496881485, 0.061668287962675095, 0.05920867621898651, 0.05469019338488579, 0.05752824619412422, 0.056424763053655624, 0.056344203650951385, 0.05540360510349274, 0.057116519659757614, 0.0559825673699379, 0.05351734906435013, 0.054254695773124695, 0.05427466332912445, 0.055082689970731735, 0.052935127168893814, 0.05121510848402977, 0.05309133231639862, 0.05168662592768669, 0.050897009670734406, 0.053240347653627396, 0.05279119685292244, 0.04999784380197525, 0.049727797508239746, 0.05030631646513939, 0.04977644979953766, 0.04950544610619545, 0.04896233230829239, 0.04953587427735329, 0.04948294535279274, 0.0477302223443985, 0.04737287759780884, 0.04739484190940857, 0.048896659165620804, 0.04767380282282829, 0.04677855595946312, 0.04718758538365364, 0.04748110845685005, 0.04495510086417198, 0.04600633680820465, 0.046984679996967316, 0.045641522854566574, 0.04499632492661476, 0.04681173712015152, 0.04478774964809418, 0.04739018902182579, 0.04544386267662048, 0.04446790739893913, 0.04521575942635536, 0.04611344262957573, 0.04288502410054207, 0.0431940034031868, 0.046662118285894394, 0.04409142583608627, 0.04243980348110199, 0.04295426979660988, 0.04550442472100258, 0.04043390229344368, 0.047491468489170074, 0.041567761451005936, 0.04167725890874863, 0.04177049174904823, 0.04226958379149437, 0.043767642229795456, 0.041597239673137665, 0.042645931243896484, 0.04245610162615776, 0.0420471616089344, 0.04464656487107277, 0.04449792206287384, 0.03886519744992256, 0.042286038398742676, 0.04108606278896332, 0.040218401700258255, 0.041559722274541855, 0.041981372982263565, 0.04107976704835892, 0.03959621116518974, 0.04114523157477379, 0.039292290806770325, 0.04245425760746002, 0.037825968116521835, 0.04077238589525223, 0.04143039509654045, 0.042767152190208435, 0.03830345720052719, 0.0423310212790966, 0.03693098947405815, 0.04479610547423363, 0.038396771997213364, 0.039738960564136505, 0.04147690162062645, 0.037100810557603836, 0.041353777050971985, 0.039692047983407974, 0.03785106912255287, 0.03855307400226593, 0.040102992206811905, 0.03820057958364487, 0.03959507495164871, 0.03966161608695984, 0.03950463980436325, 0.03851477801799774, 0.03733604773879051, 0.04045635834336281, 0.03853485360741615, 0.04050704464316368, 0.038248460739851, 0.03713446855545044, 0.040142979472875595, 0.03719748556613922, 0.03871849924325943, 0.036632489413022995, 0.040816791355609894, 0.038545943796634674, 0.03661531209945679, 0.03876561298966408, 0.036956917494535446, 0.0411037914454937, 0.036026906222105026, 0.03646673262119293, 0.03783122077584267, 0.03752584755420685, 0.038199685513973236, 0.036937929689884186, 0.038565270602703094, 0.036914266645908356, 0.03764954209327698, 0.03969860449433327, 0.037634678184986115, 0.0376071035861969, 0.03701086342334747, 0.03636552765965462, 0.036733228713274, 0.03748950734734535, 0.03709365054965019, 0.03796353563666344, 0.03603160381317139, 0.0369805246591568, 0.037712011486291885, 0.03618660196661949, 0.04034215584397316, 0.03567252308130264, 0.034629013389348984, 0.0408179797232151, 0.03420669585466385, 0.036259397864341736, 0.03768244385719299, 0.034970931708812714, 0.03827519714832306, 0.035869140177965164, 0.038179218769073486, 0.03438560664653778, 0.038080163300037384, 0.036179278045892715, 0.03913280740380287, 0.03372013941407204, 0.037661150097846985, 0.03572368621826172, 0.03627397492527962, 0.03665872663259506, 0.036366578191518784, 0.03589656949043274, 0.037319865077733994, 0.038633428514003754, 0.03621777147054672, 0.03530150279402733, 0.03759801387786865, 0.03439529612660408, 0.039455484598875046, 0.03489263728260994, 0.034581948071718216, 0.03747180849313736, 0.03731454163789749, 0.035902053117752075, 0.038234200328588486, 0.034100186079740524, 0.03723500296473503, 0.03521762788295746, 0.036758460104465485, 0.03811316192150116, 0.03298645839095116, 0.038774602115154266, 0.03509320691227913, 0.03521665558218956, 0.03546205163002014, 0.03500228375196457, 0.03614091873168945, 0.037799395620822906, 0.03450427204370499, 0.039121948182582855, 0.0348682664334774, 0.03527066111564636, 0.036236897110939026, 0.035649679601192474, 0.03871097043156624, 0.0336613692343235, 0.03879586234688759, 0.03379319980740547, 0.0352005697786808, 0.03766797482967377, 0.03501966595649719, 0.0342770516872406, 0.03656471520662308, 0.036576852202415466, 0.03215997293591499, 0.039980608969926834, 0.034226398915052414, 0.037708088755607605, 0.03647755831480026, 0.03583070635795593, 0.034236881881952286, 0.036411676555871964, 0.03652580827474594, 0.033856093883514404, 0.03507022559642792, 0.03791395574808121, 0.0361294150352478, 0.034412626177072525, 0.0380084365606308, 0.03471117839217186, 0.035799771547317505, 0.03348773345351219, 0.03699570894241333, 0.03739122301340103, 0.035157643258571625, 0.034423425793647766, 0.036771032959222794, 0.035489559173583984, 0.03593006730079651, 0.035777702927589417, 0.03611070662736893, 0.03631706163287163, 0.03779299929738045, 0.03360903263092041, 0.036896269768476486, 0.03487377241253853, 0.03455584868788719, 0.03494793176651001, 0.03461690992116928, 0.03763792663812637, 0.03470935672521591, 0.033475469797849655, 0.03705256059765816, 0.03780779615044594], "moving_avg_accuracy_train": [0.05496470588235292, 0.11660705882352938, 0.17713458823529407, 0.23427995294117643, 0.28959313411764703, 0.341377350117647, 0.3894137327529411, 0.43409118300705873, 0.47516677058870577, 0.5123512700004234, 0.5478879077062633, 0.5796520581121075, 0.6093974405361908, 0.6365165200119836, 0.6616225150696087, 0.6852343812097066, 0.7068427077946183, 0.7263278487798623, 0.7448950639018761, 0.7611161457469826, 0.7762139429369902, 0.7904749015844676, 0.8037215290730797, 0.8153234938128305, 0.8264782032550768, 0.8364162652825103, 0.8458499328719064, 0.8543449395847157, 0.8630139750380088, 0.8696372834165609, 0.8762735550749048, 0.8817803172144731, 0.8879716972577316, 0.8930192334143114, 0.8984914277199391, 0.9029740496538275, 0.9074648799825624, 0.9107819213960708, 0.9146519645505814, 0.9178479445661115, 0.9213925618742063, 0.9240980115691386, 0.92710468100046, 0.9299471540768844, 0.9330983210221372, 0.9347014300963941, 0.937078345910284, 0.9390246289663144, 0.9413551072461536, 0.9433043024038912, 0.9451221074576197, 0.9464334261236224, 0.9482230246877308, 0.9500642516307224, 0.9511942970558854, 0.9521219261738263, 0.9537050276740908, 0.9553227602007993, 0.9566234253571899, 0.9573046122332357, 0.9585153274805004, 0.959656735908921, 0.9606416505533231, 0.9613704266744613, 0.9626592663599562, 0.9636121632533723, 0.9643568292809762, 0.9652693816469963, 0.9661165611293555, 0.9669049050164199, 0.9675720615736014, 0.9686830907103589, 0.9689441934040289, 0.9697109505342143, 0.9704480907749106, 0.9702479875797725, 0.9705573064688541, 0.9714098111160863, 0.9711982417691835, 0.9718854764157945, 0.9722828111271562, 0.9725133535438523, 0.97274672407182, 0.9733661693116967, 0.9738977876746446, 0.9743997736130625, 0.9748068550752856, 0.9752391107442276, 0.9757269643756873, 0.9759825032322362, 0.976236017614895, 0.9768712393828173, 0.9771088213268885, 0.977040292135376, 0.9777668511571325, 0.9783360483943604, 0.9787353847313949, 0.9787747874347259, 0.9791631910441946, 0.9793104013515398, 0.9792428906281505, 0.9786291898006296, 0.9789733296440961, 0.9792830555032159, 0.9792065146587766, 0.9795376278987813, 0.9799673945206678, 0.9805094785980129, 0.9806844130911527, 0.9809406776643903, 0.981505433427363, 0.9821007724375678, 0.9822012834291052, 0.9823152727332535, 0.9828155101658105, 0.9829763120904059, 0.9829798573519536, 0.983095989263817, 0.9837205079844942, 0.9841061042448683, 0.9842413761733226, 0.9840501797324609, 0.9843886911709795, 0.9847992338185874, 0.9849404869073168, 0.9847476146871734, 0.9853387355713972, 0.9858636855436692, 0.9858820228716553, 0.9859432323491957, 0.9864336149966291, 0.9863408417322602, 0.9867632281472695, 0.9871974935678366, 0.9874400971522295, 0.9872372639075948, 0.9874853022227177, 0.9878238308239754, 0.9879285065651073, 0.9878485970850672, 0.9878990314942075, 0.9880220695212574, 0.9880433919808963, 0.9883190527828066, 0.9886612651515847, 0.9886163151070144, 0.9886840953610189, 0.9887121564131522, 0.9887468231247782, 0.9887921408123005, 0.9888846914369528, 0.9892856340579633, 0.989232364769814, 0.9894597165281267, 0.9892996272282553, 0.9890214292113121, 0.9892486980548867, 0.9885967694258686, 0.9890359160126936, 0.9889793832349536, 0.9891332096173405, 0.9886363592438419, 0.9890033115547517, 0.989310039222806, 0.9896825647122901, 0.9899284258881199, 0.990161465652249, 0.9905382602634948, 0.9905009048253806, 0.9904366966957837, 0.9903553799673819, 0.9899951360882908, 0.9898826813029912, 0.9898732367021038, 0.9899000306789523, 0.9903123805522336, 0.9904787895558338, 0.9906450282473093, 0.9906252313049313, 0.990372119939144, 0.9907184373569943, 0.9910348289154125, 0.9911595813179889, 0.9911400937744252, 0.9914707902793356, 0.9915707700749314, 0.991797222479203, 0.9918269119959886, 0.9917924560905074, 0.9915990928343978, 0.9919309482568404, 0.9920837357840975, 0.9919341857350995, 0.9921619436321778, 0.9922163375042542, 0.9921194096361817, 0.9920462922019753, 0.9920440159229542, 0.9921619672718353, 0.9921951823093575, 0.9920956640784218, 0.9921943329646972, 0.992377252609404, 0.9924195273484635, 0.9926175746136171, 0.9929228759757848, 0.9930988236723239, 0.9933324707168563, 0.9933027530569354, 0.9930171836335948, 0.9931413476231765, 0.9929730952138001, 0.993205197457126, 0.9933246777114134, 0.9933875040579191, 0.9931452242403624, 0.9930942312280908, 0.9933306904582229, 0.993275268471224, 0.9935336239770428, 0.9935920262852208, 0.9932187060096399, 0.9931156589380876, 0.9932182106913376, 0.9935081543280861, 0.9935502800717482, 0.993623487358691, 0.9936846680345865, 0.9937609071134808, 0.9938601105197797, 0.9938223347619194, 0.9939412777563157, 0.9938436205689195, 0.9939086702767335, 0.9940213326608248, 0.9940450817476835, 0.993299397102327, 0.9927765162156237, 0.9930447469470025, 0.9934014487228905, 0.9934471862035426, 0.993645996994953, 0.9934719855307519, 0.9936847869776767, 0.9936104259269678, 0.9936776186283887, 0.993935739118491, 0.9936551063831125, 0.9936190075095072, 0.9936288714644388, 0.9936071607885832, 0.9938064447097249, 0.9938658002387524, 0.9940251025678183, 0.9939355334875071, 0.9941278624916976, 0.9943268409484102, 0.9942423921476868, 0.9944840352858594, 0.9944756317572734, 0.9945292450521342, 0.9943445558410385, 0.9943501002569347, 0.9944421490547707, 0.9945767576787053, 0.9942484936755407, 0.9943812913668102, 0.9945808092889526, 0.9942074342424103, 0.9941984555240516, 0.9941080217363524, 0.9942666313274231, 0.9944940858417396, 0.994651736081095, 0.994908915414162, 0.9948721415198046, 0.9949519861913535, 0.9951603169839828, 0.9946960499914668, 0.9948829155805553, 0.9949099181401468, 0.9950377498555439, 0.9952727983994013, 0.995310224441814, 0.9953886137623384, 0.9953156347390458, 0.9949958359710236, 0.994919781785686, 0.9946772153718233, 0.9945812585405234, 0.994647838568824, 0.9945265841237063, 0.9948151021819239, 0.9949147684343197, 0.9951527033555936, 0.9946539036082696, 0.9947296897180309, 0.9948331913344631, 0.9948416369068991, 0.9950586496867974, 0.9952892553063529, 0.9953815062463058, 0.9952786497393223, 0.9949696082948019, 0.9950302945241453, 0.9946919709540837, 0.9947921856233812, 0.9949906141198667, 0.9950680232961153, 0.9950153386135626, 0.9952243929875004, 0.9953984242769857, 0.9953762289081106, 0.995316253076123, 0.9952505101214519, 0.995266635579895, 0.9952293837866114, 0.9954099748197149, 0.9956030949848023, 0.9952969031333809, 0.9954942716435723, 0.9954601385968621, 0.9951400070901171, 0.995254241675223, 0.9952158763312301, 0.9948072298745776, 0.9949947421812375, 0.9947329150219373, 0.9949537411668024, 0.9952089552854162, 0.9944762950509922, 0.9947157243694223, 0.9948182695795389, 0.9948423249745262, 0.9951486807123676, 0.9951867538176014, 0.9951927843181942, 0.9953182117687278, 0.9954216847095021, 0.9955242221209049, 0.9953129763794026, 0.9953793258002859, 0.9952790402790809, 0.9953605480158786, 0.9955350814495848], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05463999999999999, 0.11513599999999996, 0.1738890666666666, 0.22919349333333328, 0.2827808106666666, 0.3325960629333333, 0.37813645664, 0.42064281097600004, 0.45928519654506667, 0.4942633435572267, 0.5268503425348373, 0.5556853082813535, 0.5828101107865515, 0.6071290997078964, 0.6298561897371068, 0.6507372374300627, 0.6694368470203897, 0.6864664956516842, 0.7024731794198491, 0.7160391948111975, 0.7286619419967444, 0.7405557477970699, 0.7517268396840296, 0.7611408223822933, 0.7700934068107306, 0.7780307327963242, 0.7855476595166917, 0.7922728935650226, 0.7991922708751871, 0.8042463771210018, 0.8087550727422349, 0.8126262321346781, 0.817590275587877, 0.8208312480290892, 0.8247614565595136, 0.8276453109035623, 0.831080779813206, 0.8335860351652188, 0.8363074316486968, 0.8382766884838272, 0.8408223529687778, 0.8425934510052334, 0.8445874392380434, 0.846168695314239, 0.8482718257828151, 0.8492846432045337, 0.8506361788840804, 0.8520258943290057, 0.8533966382294383, 0.8548436410731612, 0.8560526102991785, 0.8564740159359272, 0.8577732810090011, 0.8584626195747677, 0.8590696909506241, 0.8595227218555618, 0.8604771163366723, 0.8616560713696718, 0.8627437975660379, 0.8628294178094341, 0.8635331426951574, 0.8641798284256416, 0.864588512249744, 0.8647696610247695, 0.8656793615889592, 0.8662847587633966, 0.866696282887057, 0.8668266545983513, 0.8673706558051828, 0.8680335902246645, 0.8693902312021982, 0.870517874748645, 0.8709194206071137, 0.8715874785464023, 0.8718953973584288, 0.8716391909559192, 0.8716886051936605, 0.8722264113409611, 0.8714971035401984, 0.8718807265195119, 0.8721326538675607, 0.8719593884808047, 0.8722967829660576, 0.8729604380027851, 0.8730910608691733, 0.8738886214489227, 0.8744597593040304, 0.874640450040294, 0.8751364050362647, 0.8752494311993049, 0.875311154746041, 0.8761667059381035, 0.8761633686776266, 0.8760936984765306, 0.8764443286288777, 0.8769465624326566, 0.8772785728560575, 0.8770973822371184, 0.8772809773467398, 0.8773128796120658, 0.8776482583175259, 0.8770834324857733, 0.8774150892371959, 0.8778735803134763, 0.877459555615462, 0.8781002667205824, 0.8784902400485242, 0.8789878827103385, 0.8790357611059713, 0.8790788516620408, 0.8793976331625034, 0.8799245365129198, 0.8801587495282945, 0.8799695412421317, 0.8804525871179185, 0.8803139950727934, 0.8805759288988474, 0.8805050026756294, 0.8812278357413998, 0.8813183855005933, 0.8815065469505339, 0.8816225589221471, 0.8822603030299324, 0.8828209393936058, 0.8828188454542453, 0.8826036275754874, 0.8832232648179387, 0.8840076050028115, 0.8837668445025304, 0.883576826718944, 0.8843258107137163, 0.8843465629756779, 0.8844852400114435, 0.8845300493436324, 0.8843970444092691, 0.8836506733016756, 0.883965605971508, 0.8843023787076906, 0.8842721408369214, 0.8839249267532292, 0.8841457674112396, 0.884944524003449, 0.8847167382697707, 0.885298397776127, 0.8854618913318476, 0.8856357021986628, 0.8857254653121298, 0.8857395854475836, 0.8856056269028252, 0.886058397545876, 0.8857858911246217, 0.8859673020121595, 0.8862772384776102, 0.8863428479631825, 0.8861218965001977, 0.885629706850178, 0.8857867361651602, 0.8851280625486442, 0.8859352562937798, 0.8862217306644018, 0.8864262242646282, 0.8857969351714987, 0.8858305749876821, 0.8861008508222473, 0.8864507657400226, 0.8866056891660203, 0.8869717869160849, 0.8875279415578098, 0.8875751474020288, 0.8875909659951593, 0.8876052027289767, 0.8866980157894124, 0.8869215475438045, 0.886189392789424, 0.8861437868438149, 0.8864627414927667, 0.8866698006768234, 0.887202820609141, 0.8873358718815603, 0.8866289513600709, 0.8872860562240638, 0.887944117268324, 0.8878163722081583, 0.8880614016540092, 0.8884152614886083, 0.8886404020064141, 0.8886830284724394, 0.8888813922918621, 0.8889532530626759, 0.888764594423075, 0.8891681349807675, 0.8895979881493574, 0.8893848560010883, 0.8898997037343127, 0.890056400027548, 0.8899174266914599, 0.8896056840223139, 0.8895384489534158, 0.8898779373914076, 0.8897568103189335, 0.8892611292870402, 0.8894416830250028, 0.8895108480558358, 0.8898530965835856, 0.8898944535918938, 0.8904383415660377, 0.8906478407427673, 0.8909430566684905, 0.8910354176683081, 0.8908252092348106, 0.8904760216446629, 0.8898950861468633, 0.8899855775321769, 0.8906270197789592, 0.8906976511343966, 0.8905478860209569, 0.8903864307521945, 0.8910411210103083, 0.8909370089092774, 0.891336641351683, 0.8914296438831814, 0.8909266794948631, 0.8907806782120434, 0.8906359437241724, 0.8911856826850886, 0.8912537810832464, 0.8914350696415884, 0.8913848960107629, 0.8913264064096865, 0.8912470991020512, 0.8909890558585127, 0.8910501502726615, 0.8910518019120621, 0.8908932883875226, 0.890590626215437, 0.8905048969272267, 0.8896277405678373, 0.8885316331777202, 0.8888651365266148, 0.88972528954062, 0.8897527605865581, 0.8901908178612357, 0.8896250694084454, 0.8896625624676009, 0.8895763062208408, 0.8899120089320901, 0.8904008080388811, 0.8899073939016596, 0.889969987844827, 0.8902129890603443, 0.8899250234876432, 0.8906391878055455, 0.8907219356916576, 0.8910630754558252, 0.8911301012435761, 0.8914437577858851, 0.8918593820072966, 0.8919801104732337, 0.8925820994259103, 0.8929372228166526, 0.8930435005349873, 0.8928058171481552, 0.8926052354333397, 0.8921713785566724, 0.8920075740343385, 0.8915668166309046, 0.8917168016344809, 0.8920651214710327, 0.891165275990596, 0.8909420817248697, 0.890661206885716, 0.8908750861971445, 0.8911209109107633, 0.8915821531530203, 0.8920506045043849, 0.892352210720613, 0.8922769896485517, 0.8922759573503632, 0.8914483616153268, 0.8919035254537941, 0.8922198395750813, 0.8927045222842398, 0.8930740700558157, 0.8930466630502342, 0.8935286634118774, 0.8932957970706896, 0.8928328840302874, 0.892282928960592, 0.8918946360645328, 0.8917585057914128, 0.8919159885456048, 0.8917777230243776, 0.8922799507219399, 0.892291955649746, 0.8930760934181047, 0.8923818174096275, 0.8926636356686647, 0.8930239387684649, 0.892908211558285, 0.8933907237357899, 0.8935049846955442, 0.8936878195593231, 0.8936390376033907, 0.8929151338430515, 0.8929036204587464, 0.8927999250795384, 0.8928132659049179, 0.8931319393144261, 0.8934187453829836, 0.8933702041780186, 0.8940198504268834, 0.894017865384195, 0.8936960788457755, 0.893646470961198, 0.8933351571984115, 0.8934949748119037, 0.8936521439973799, 0.8939535962643086, 0.894171569971211, 0.8938210796407566, 0.894238971676681, 0.8942017411756795, 0.8934615670581115, 0.8937554103523003, 0.8935665359837369, 0.8933432157186966, 0.8937022274801603, 0.8930386713988109, 0.8930548042589298, 0.8937626571663702, 0.8927997247830665, 0.8934397523047598, 0.8938691104076171, 0.8940021993668553, 0.8944286460968364, 0.894039114820486, 0.894461870005104, 0.8946423496712602, 0.8951914480374675, 0.8953123032337207, 0.8949277395770152, 0.8948482989526471, 0.8948968023907157, 0.8949137888183107, 0.894915743269813], "moving_var_accuracy_train": [0.027190070034602068, 0.058669080116262956, 0.08577440845486503, 0.10658730197569327, 0.12346450388487348, 0.13525249873699804, 0.1424946953734577, 0.14620989688699437, 0.14677374225489298, 0.14454055099790397, 0.14145216947303876, 0.13638760378478076, 0.1307119333862974, 0.12425974029219691, 0.11750656515347872, 0.11077359064169198, 0.1038985095777246, 0.09692569509288568, 0.09033579888008134, 0.083670330458104, 0.07735478873220902, 0.07144968433289368, 0.06588397415800279, 0.06050702701460431, 0.05557617219781234, 0.050907440669781145, 0.04661764336048802, 0.042605365275895306, 0.039021198329519856, 0.03551389242146445, 0.03235886409302806, 0.029395897547081305, 0.02680130647393372, 0.02435047441780817, 0.022184931170694252, 0.020147283148244426, 0.01831406284679335, 0.016581681435764387, 0.015058308398347915, 0.013644406152850133, 0.012393044344312721, 0.011219615032347733, 0.010179014078736144, 0.009233829549574317, 0.008399815272668568, 0.007582963373737393, 0.006875514595440537, 0.006222055295504203, 0.005648729927069001, 0.00511805119022863, 0.004635985808126016, 0.00418786323710768, 0.00379790088058284, 0.003448621842424941, 0.003115252682148834, 0.0028114718759580165, 0.0025528805816034702, 0.002321146050194861, 0.0021042570138168136, 0.0018980074524760045, 0.0017213991899180364, 0.001560984589730458, 0.0014136166424682302, 0.0012770350099340797, 0.0011642814785548347, 0.0010560254431046905, 0.0009554136462282285, 0.0008673670479919643, 0.0007870897608707413, 0.0007139741595421141, 0.0006465826244340157, 0.0005930338336751314, 0.0005343440218573938, 0.00048620086814186504, 0.00044247116293776164, 0.0003985844182423258, 0.0003595870799943772, 0.0003301692495569127, 0.00029755517889816106, 0.0002720502841438687, 0.00024626612958515806, 0.0002221178648797072, 0.00020039623462165184, 0.0001838100228063412, 0.00016797258328011847, 0.00015344323389343025, 0.00013959034835605896, 0.00012731291819044577, 0.00011672363686295594, 0.00010563897414151731, 9.56535026072991e-05, 8.971971259654979e-05, 8.125574795823271e-05, 7.317243941321351e-05, 7.060618758075423e-05, 6.646143827648993e-05, 6.125052003952651e-05, 5.5139441192842055e-05, 5.098321334819188e-05, 4.607992988467084e-05, 4.151295617615664e-05, 4.0751318909839945e-05, 3.774207710560596e-05, 3.4831240365312864e-05, 3.140084283658883e-05, 2.9247482352287567e-05, 2.7985028260649e-05, 2.7831221756782745e-05, 2.5323518273115462e-05, 2.3382210229274074e-05, 2.3914530852644955e-05, 2.4712934601025995e-05, 2.233256327570176e-05, 2.0216249001273526e-05, 2.044676150152719e-05, 1.8634800681956793e-05, 1.6771433733676087e-05, 1.5215669948886041e-05, 1.7204315646283162e-05, 1.6822044365785316e-05, 1.530452638085659e-05, 1.4103078453754463e-05, 1.3724080554450523e-05, 1.3868579888549909e-05, 1.2661293815375534e-05, 1.172996167356555e-05, 1.3701780604099207e-05, 1.4811754804185112e-05, 1.33336056421456e-05, 1.2033964479197909e-05, 1.2994844299411988e-05, 1.1772821776705546e-05, 1.2201232151294435e-05, 1.2678387035668442e-05, 1.1940256824543729e-05, 1.1116503068250783e-05, 1.055855981334662e-05, 1.0534118356837073e-05, 9.579319618186929e-06, 8.67885738137081e-06, 7.83386430986174e-06, 7.186723083778417e-06, 6.4721426009660764e-06, 6.508828240258301e-06, 6.911929164335341e-06, 6.238920806463601e-06, 5.6563761913133915e-06, 5.0978253760035595e-06, 4.598858866457814e-06, 4.157456215033245e-06, 3.818801156641697e-06, 4.8837159090632195e-06, 4.420882871696267e-06, 4.443993982597577e-06, 4.230251839737925e-06, 4.503773885444176e-06, 4.518256642237677e-06, 7.891529414014492e-06, 8.838023995092652e-06, 7.982985190214335e-06, 7.397649674457329e-06, 8.87962734982434e-06, 9.203550601181161e-06, 9.129932302212965e-06, 9.465916234829985e-06, 9.063354071370733e-06, 8.645786449222141e-06, 9.058975415873945e-06, 8.165636733096874e-06, 7.386177214944153e-06, 6.707071186311644e-06, 7.204344939484104e-06, 6.59772515416684e-06, 5.938755443123448e-06, 5.351341153569295e-06, 6.34649880016789e-06, 5.961076528463928e-06, 5.613686598508728e-06, 5.055845209005509e-06, 5.1268489595211286e-06, 5.69358584872755e-06, 6.02515982799956e-06, 5.562712302736866e-06, 5.0098589516504645e-06, 5.4931146617251565e-06, 5.0337668312991335e-06, 4.991916370772553e-06, 4.500657940357949e-06, 4.061277031124925e-06, 3.991653467332053e-06, 4.583640313239713e-06, 4.3353725382838985e-06, 4.1031222388531995e-06, 4.159672952101579e-06, 3.770333896766535e-06, 3.477855611571572e-06, 3.178185483078762e-06, 2.860413567786521e-06, 2.6995848973336053e-06, 2.4395555560587536e-06, 2.2847349050501204e-06, 2.1438813566146813e-06, 2.2306295887300167e-06, 2.0236510119200354e-06, 2.174290383841583e-06, 2.7957416411305027e-06, 2.794785804274409e-06, 3.006625696615134e-06, 2.713911380754204e-06, 3.176469302602497e-06, 2.9975726391218324e-06, 2.9525952345585663e-06, 3.1421787733148143e-06, 2.956440676464557e-06, 2.6963209571554128e-06, 2.9549844513972505e-06, 2.6828885919622485e-06, 2.917816440397985e-06, 2.6536791661442003e-06, 2.9890393560116574e-06, 2.7208328868152365e-06, 3.7030618515719166e-06, 3.4283239570141355e-06, 3.1801433201646715e-06, 3.618734800567219e-06, 3.27283252502216e-06, 2.993783034273718e-06, 2.7280924067737442e-06, 2.5075947404522266e-06, 2.3454071087989003e-06, 2.123709468856307e-06, 2.0386654452142968e-06, 1.9206312369442305e-06, 1.7666512936299115e-06, 1.7042214793692532e-06, 1.5388755035719249e-06, 6.389398266099915e-06, 8.211098234606411e-06, 8.037517938449839e-06, 8.378891556899603e-06, 7.559829655437282e-06, 7.159578266924804e-06, 6.716140347293291e-06, 6.452086414883617e-06, 5.856643866157967e-06, 5.31161321166028e-06, 5.380087577190156e-06, 5.550871408965347e-06, 5.007512426149003e-06, 4.5076368619961425e-06, 4.061115356811511e-06, 4.012430552160793e-06, 3.6428952063799308e-06, 3.507000774154426e-06, 3.228504278069191e-06, 3.2385678629383498e-06, 3.271042912766054e-06, 3.008123020981989e-06, 3.232833374916457e-06, 2.9101856110590637e-06, 2.6450365184257346e-06, 2.6875238088398036e-06, 2.4190480928844875e-06, 2.2534001142434145e-06, 2.1911354375574084e-06, 2.941837195764845e-06, 2.8063705174468434e-06, 2.884000077006757e-06, 3.850280397730418e-06, 3.465977914407656e-06, 3.192984552585648e-06, 3.10009911874345e-06, 3.255709211615771e-06, 3.15382067217369e-06, 3.433709489167254e-06, 3.1025094140063964e-06, 2.8496350167785937e-06, 2.9552869875189176e-06, 4.599652851825044e-06, 4.453956302111467e-06, 4.0151229159207664e-06, 3.760679151480917e-06, 3.881841598058077e-06, 3.5062638161084433e-06, 3.2109414046482046e-06, 2.9377807047501467e-06, 3.5644439025319417e-06, 3.2600576642451094e-06, 3.4635980840285505e-06, 3.200107696883899e-06, 2.919993028712086e-06, 2.760317489988071e-06, 3.233469770248159e-06, 2.9995230500230446e-06, 3.209087985875332e-06, 5.127389878662761e-06, 4.666342700691217e-06, 4.296121692058818e-06, 3.867151472096889e-06, 3.904287244640017e-06, 3.992469086111434e-06, 3.6698143008001067e-06, 3.3980480199797733e-06, 3.917802747863508e-06, 3.5591678389643684e-06, 4.233416597600863e-06, 3.900461757322468e-06, 3.864780395547334e-06, 3.5322319811000262e-06, 3.2039898649711383e-06, 3.2769244598369734e-06, 3.2218140213323844e-06, 2.9040663287946348e-06, 2.6460335997185425e-06, 2.4203294645466925e-06, 2.180636791782006e-06, 1.975062377529416e-06, 2.0710742309131835e-06, 2.1996253912921027e-06, 2.8234439010546957e-06, 2.8916884702854887e-06, 2.6130052071564086e-06, 3.2740623209383916e-06, 3.0641019527534946e-06, 2.770938854055384e-06, 3.996772307460993e-06, 3.913542863055091e-06, 4.139169728874588e-06, 4.164130432290949e-06, 4.33392560612059e-06, 8.731652217464293e-06, 8.374424582433361e-06, 7.631621805250729e-06, 6.873667582977606e-06, 7.030985367655564e-06, 6.340932882969326e-06, 5.707166897108991e-06, 5.278038615524138e-06, 4.846594599224011e-06, 4.456560425936174e-06, 4.412527253068094e-06, 4.0108947386251825e-06, 3.700319936632999e-06, 3.390079543390789e-06, 3.325228864383391e-06], "duration": 333032.882755, "accuracy_train": [0.5496470588235294, 0.6713882352941176, 0.7218823529411764, 0.7485882352941177, 0.7874117647058824, 0.807435294117647, 0.8217411764705882, 0.8361882352941177, 0.8448470588235294, 0.8470117647058824, 0.8677176470588235, 0.8655294117647059, 0.8771058823529412, 0.8805882352941177, 0.8875764705882353, 0.8977411764705883, 0.9013176470588236, 0.9016941176470589, 0.912, 0.9071058823529412, 0.9120941176470588, 0.9188235294117647, 0.9229411764705883, 0.9197411764705883, 0.9268705882352941, 0.9258588235294117, 0.9307529411764706, 0.9308, 0.9410352941176471, 0.9292470588235294, 0.936, 0.9313411764705882, 0.9436941176470588, 0.9384470588235294, 0.9477411764705882, 0.9433176470588235, 0.9478823529411765, 0.940635294117647, 0.9494823529411764, 0.9466117647058824, 0.9532941176470588, 0.9484470588235294, 0.9541647058823529, 0.9555294117647058, 0.9614588235294118, 0.9491294117647059, 0.9584705882352941, 0.9565411764705882, 0.9623294117647059, 0.9608470588235294, 0.9614823529411765, 0.9582352941176471, 0.9643294117647059, 0.966635294117647, 0.9613647058823529, 0.9604705882352941, 0.9679529411764706, 0.9698823529411764, 0.9683294117647059, 0.9634352941176471, 0.9694117647058823, 0.9699294117647059, 0.9695058823529412, 0.9679294117647059, 0.9742588235294117, 0.9721882352941177, 0.9710588235294118, 0.9734823529411765, 0.9737411764705882, 0.974, 0.9735764705882353, 0.9786823529411764, 0.9712941176470589, 0.9766117647058824, 0.9770823529411765, 0.9684470588235294, 0.9733411764705883, 0.9790823529411765, 0.9692941176470589, 0.9780705882352941, 0.9758588235294118, 0.9745882352941176, 0.9748470588235294, 0.9789411764705882, 0.9786823529411764, 0.9789176470588236, 0.9784705882352941, 0.9791294117647059, 0.9801176470588235, 0.9782823529411765, 0.9785176470588235, 0.9825882352941177, 0.9792470588235294, 0.9764235294117647, 0.9843058823529411, 0.9834588235294117, 0.9823294117647059, 0.9791294117647059, 0.9826588235294118, 0.980635294117647, 0.978635294117647, 0.9731058823529412, 0.9820705882352941, 0.9820705882352941, 0.9785176470588235, 0.9825176470588235, 0.983835294117647, 0.9853882352941177, 0.9822588235294117, 0.9832470588235294, 0.9865882352941177, 0.9874588235294117, 0.9831058823529412, 0.9833411764705883, 0.9873176470588235, 0.9844235294117647, 0.9830117647058824, 0.9841411764705882, 0.9893411764705883, 0.9875764705882353, 0.9854588235294117, 0.9823294117647059, 0.9874352941176471, 0.9884941176470589, 0.9862117647058823, 0.9830117647058824, 0.9906588235294118, 0.9905882352941177, 0.9860470588235294, 0.9864941176470589, 0.9908470588235294, 0.9855058823529412, 0.9905647058823529, 0.9911058823529412, 0.9896235294117647, 0.9854117647058823, 0.9897176470588235, 0.9908705882352942, 0.9888705882352942, 0.9871294117647059, 0.9883529411764705, 0.9891294117647059, 0.9882352941176471, 0.9908, 0.9917411764705882, 0.9882117647058823, 0.9892941176470588, 0.988964705882353, 0.9890588235294118, 0.9892, 0.9897176470588235, 0.9928941176470588, 0.9887529411764706, 0.9915058823529411, 0.9878588235294118, 0.9865176470588235, 0.9912941176470588, 0.9827294117647059, 0.9929882352941176, 0.9884705882352941, 0.9905176470588235, 0.9841647058823529, 0.9923058823529411, 0.9920705882352941, 0.993035294117647, 0.9921411764705882, 0.9922588235294117, 0.9939294117647058, 0.990164705882353, 0.9898588235294118, 0.9896235294117647, 0.9867529411764706, 0.9888705882352942, 0.9897882352941176, 0.9901411764705882, 0.9940235294117648, 0.9919764705882353, 0.9921411764705882, 0.9904470588235295, 0.9880941176470588, 0.993835294117647, 0.9938823529411764, 0.9922823529411765, 0.990964705882353, 0.9944470588235295, 0.9924705882352941, 0.993835294117647, 0.9920941176470588, 0.9914823529411765, 0.9898588235294118, 0.9949176470588236, 0.9934588235294117, 0.9905882352941177, 0.9942117647058824, 0.9927058823529412, 0.9912470588235294, 0.9913882352941177, 0.9920235294117647, 0.9932235294117647, 0.9924941176470589, 0.9912, 0.9930823529411764, 0.9940235294117648, 0.9928, 0.9944, 0.9956705882352941, 0.9946823529411765, 0.9954352941176471, 0.993035294117647, 0.9904470588235295, 0.9942588235294118, 0.9914588235294117, 0.9952941176470588, 0.9944, 0.9939529411764706, 0.990964705882353, 0.9926352941176471, 0.9954588235294117, 0.9927764705882353, 0.9958588235294118, 0.9941176470588236, 0.9898588235294118, 0.9921882352941176, 0.9941411764705882, 0.9961176470588236, 0.9939294117647058, 0.9942823529411765, 0.9942352941176471, 0.9944470588235295, 0.9947529411764706, 0.9934823529411765, 0.9950117647058824, 0.992964705882353, 0.9944941176470589, 0.995035294117647, 0.9942588235294118, 0.9865882352941177, 0.9880705882352941, 0.9954588235294117, 0.9966117647058823, 0.9938588235294118, 0.9954352941176471, 0.9919058823529412, 0.9956, 0.9929411764705882, 0.9942823529411765, 0.9962588235294118, 0.9911294117647059, 0.9932941176470588, 0.9937176470588235, 0.9934117647058823, 0.9956, 0.9944, 0.9954588235294117, 0.9931294117647059, 0.9958588235294118, 0.9961176470588236, 0.9934823529411765, 0.9966588235294118, 0.9944, 0.9950117647058824, 0.9926823529411765, 0.9944, 0.9952705882352941, 0.9957882352941176, 0.9912941176470588, 0.9955764705882353, 0.9963764705882353, 0.9908470588235294, 0.9941176470588236, 0.9932941176470588, 0.9956941176470588, 0.9965411764705883, 0.9960705882352942, 0.9972235294117647, 0.9945411764705883, 0.9956705882352941, 0.997035294117647, 0.9905176470588235, 0.9965647058823529, 0.9951529411764706, 0.9961882352941176, 0.9973882352941177, 0.9956470588235294, 0.9960941176470588, 0.9946588235294118, 0.9921176470588235, 0.9942352941176471, 0.9924941176470589, 0.9937176470588235, 0.9952470588235294, 0.9934352941176471, 0.9974117647058823, 0.9958117647058824, 0.9972941176470588, 0.990164705882353, 0.9954117647058823, 0.995764705882353, 0.9949176470588236, 0.9970117647058824, 0.9973647058823529, 0.9962117647058824, 0.9943529411764706, 0.9921882352941176, 0.9955764705882353, 0.9916470588235294, 0.9956941176470588, 0.9967764705882353, 0.995764705882353, 0.9945411764705883, 0.9971058823529412, 0.996964705882353, 0.9951764705882353, 0.9947764705882353, 0.9946588235294118, 0.9954117647058823, 0.9948941176470588, 0.997035294117647, 0.9973411764705883, 0.9925411764705883, 0.9972705882352941, 0.9951529411764706, 0.9922588235294117, 0.9962823529411765, 0.9948705882352941, 0.9911294117647059, 0.9966823529411765, 0.9923764705882353, 0.9969411764705882, 0.9975058823529411, 0.9878823529411764, 0.9968705882352941, 0.9957411764705882, 0.9950588235294118, 0.9979058823529412, 0.9955294117647059, 0.9952470588235294, 0.9964470588235295, 0.9963529411764706, 0.9964470588235295, 0.9934117647058823, 0.9959764705882352, 0.9943764705882353, 0.9960941176470588, 0.9971058823529412], "end": "2016-02-08 05:05:59.767000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0, 312.0, 313.0, 314.0, 315.0, 316.0, 317.0, 318.0, 319.0, 320.0, 321.0, 322.0, 323.0, 324.0, 325.0, 326.0, 327.0, 328.0, 329.0, 330.0, 331.0, 332.0, 333.0, 334.0, 335.0, 336.0, 337.0, 338.0, 339.0, 340.0, 341.0, 342.0, 343.0, 344.0], "moving_var_accuracy_valid": [0.026869766399999995, 0.05712068390399999, 0.08247592109824, 0.1017555454687744, 0.11742439613274727, 0.12801599074499728, 0.13387973880112142, 0.13675287635144756, 0.13651669437851852, 0.13387626185630516, 0.13004584819197584, 0.12452436061920316, 0.11869371875579679, 0.11214706587962554, 0.10558104488242548, 0.09894710376898246, 0.09219947198156007, 0.08558960517595217, 0.07933656998564326, 0.07305924394946366, 0.06718732327310939, 0.06174175449354117, 0.05669071868970912, 0.05181925445292708, 0.04735866791916906, 0.04318981142146637, 0.03937936796519412, 0.03584849012571816, 0.03269454115439011, 0.029654982948446942, 0.02687243967944659, 0.02432006858687724, 0.022109837274836737, 0.019993388668635342, 0.018133068653605398, 0.01639461133114405, 0.014861372217691805, 0.013431721735331721, 0.012155203551181134, 0.010974584948407388, 0.0099354501225961, 0.008970136204629121, 0.008108906485819472, 0.007320519174244077, 0.006628275676730347, 0.005974680301224941, 0.005393652109340235, 0.004871668679566987, 0.0044014122611754514, 0.003980115390125585, 0.0035952583104181366, 0.003237330723772476, 0.0029287904589662176, 0.0026401881019938738, 0.0023794861126929462, 0.0021433846344311087, 0.0019372439904181652, 0.0017560290061048609, 0.0015910744399987254, 0.001432032973433566, 0.0012932867345232853, 0.0011677218829770645, 0.0010524528968921057, 0.0009475029411111346, 0.000860200643048405, 0.0007774791303929158, 0.0007012553862928138, 0.0006312828187114847, 0.0005708179726576438, 0.0005176915137926816, 0.0004824866350907221, 0.00044568219129223914, 0.0004025651238510966, 0.00036632532415820616, 0.0003305461176955835, 0.00029808228141220715, 0.00026829602917301053, 0.00024406954532437845, 0.00022444959960622163, 0.0002033291389579157, 0.0001835674315603783, 0.00016548087645257007, 0.00014995730415542444, 0.00013892551580984693, 0.00012518652522787335, 0.00011839279861041688, 0.0001094893047952088, 9.883421659523133e-05, 9.116453715796199e-05, 8.216305766395009e-05, 7.398104006355032e-05, 7.317064663735243e-05, 6.585368220938461e-05, 5.931199942073296e-05, 5.448727301227319e-05, 5.130869485396983e-05, 4.716990365979513e-05, 4.274838365733938e-05, 3.8776909770097815e-05, 3.490837858388442e-05, 3.2429850610180745e-05, 3.205811953109769e-05, 2.984227338486608e-05, 2.87499726496384e-05, 2.7417723439766983e-05, 2.8370547577812592e-05, 2.6902205588585084e-05, 2.6440818999444666e-05, 2.3817368166415556e-05, 2.1452342513975438e-05, 2.0221703067912474e-05, 2.069817702724078e-05, 1.912206095365481e-05, 1.7532052838263256e-05, 1.7878847417468968e-05, 1.626383247046991e-05, 1.5254933186504482e-05, 1.3774714630113854e-05, 1.7099631935841742e-05, 1.546346207226732e-05, 1.4235758446234584e-05, 1.293331159962954e-05, 1.530043836280026e-05, 1.659921271697691e-05, 1.4939330906517632e-05, 1.3862266433899144e-05, 1.5931592600602687e-05, 1.987513907099908e-05, 1.8409315730359828e-05, 1.6893344980035535e-05, 2.0252803701857174e-05, 1.82313992390602e-05, 1.6581341197392645e-05, 1.494127796391439e-05, 1.3606362980607685e-05, 1.7259355154801125e-05, 1.642606291807116e-05, 1.5804199508786854e-05, 1.4232008517365981e-05, 1.3893826244856898e-05, 1.2943378986445455e-05, 1.7391149930182225e-05, 1.6119012001369956e-05, 1.7552060833244418e-05, 1.6037426034779577e-05, 1.4705575388109202e-05, 1.3307534598151966e-05, 1.1978575542363842e-05, 1.0942222013551455e-05, 1.1693011109074142e-05, 1.1192047744790005e-05, 1.0369032161366369e-05, 1.0196674458774504e-05, 9.215748454270627e-06, 8.733549549800168e-06, 1.0040450459099418e-05, 9.258329265063486e-06, 1.2237154736405817e-05, 1.687749494243927e-05, 1.5928353533404917e-05, 1.4711876872866737e-05, 1.680473205016569e-05, 1.5134443580244834e-05, 1.4278440462969157e-05, 1.3952560463807264e-05, 1.2773315828732439e-05, 1.2702232309280682e-05, 1.4215780947961337e-05, 1.2814258378721079e-05, 1.1535084591846613e-05, 1.0383400293970043e-05, 1.6751953554417965e-05, 1.5526456205970638e-05, 1.879826584463052e-05, 1.693715838064154e-05, 1.6159031155369323e-05, 1.4928989591152255e-05, 1.5993082866268352e-05, 1.4553098349472891e-05, 1.759541812785074e-05, 1.9721957535613953e-05, 2.1647160823809126e-05, 1.9629313944998932e-05, 1.8206737414504732e-05, 1.7513014715936633e-05, 1.621790751916392e-05, 1.4612469907699747e-05, 1.3505356760633538e-05, 1.220129681800774e-05, 1.130149587687161e-05, 1.163695112450944e-05, 1.2136219730979579e-05, 1.1331425571513748e-05, 1.2583896710020065e-05, 1.1546490593841475e-05, 1.0565663827748513e-05, 1.0383748870870028e-05, 9.386058974190558e-06, 9.484724672542205e-06, 8.668298114463275e-06, 1.0012765471426625e-05, 9.304885794914534e-06, 8.417451428834319e-06, 8.629912778672756e-06, 7.78231512003125e-06, 9.666410763793842e-06, 9.094778832867717e-06, 8.969672934786775e-06, 8.149480629893895e-06, 7.73222083652565e-06, 8.056386510891686e-06, 1.0288122333235739e-05, 9.333008317256062e-06, 1.2102740889144682e-05, 1.0937365895568549e-05, 1.0045495608844039e-05, 9.275556282259745e-06, 1.2205574660656877e-05, 1.1082571160820664e-05, 1.141166884594615e-05, 1.0348347199137475e-05, 1.1590271062469851e-05, 1.0623091327487712e-05, 9.749314842552499e-06, 1.1494299684639147e-05, 1.0386606242660172e-05, 9.643735490865747e-06, 8.702018480851097e-06, 7.86260593367255e-06, 7.132952181704572e-06, 7.018933803356708e-06, 6.350633169982611e-06, 5.715594404198734e-06, 5.370173800936414e-06, 5.657595934546889e-06, 5.157981938805706e-06, 1.1566813254279424e-05, 2.1223194624874563e-05, 2.0101895515902633e-05, 2.475047483183214e-05, 2.2282219273933274e-05, 2.1781044929621042e-05, 2.2483582243169878e-05, 2.0247875584216403e-05, 1.8290049286741e-05, 1.7475311151127783e-05, 1.7878101137212057e-05, 1.8281408620780712e-05, 1.6488529774193798e-05, 1.5371123113460384e-05, 1.4580328341664004e-05, 1.7712571564181932e-05, 1.600293932166795e-05, 1.5450032437767922e-05, 1.3945461300003687e-05, 1.3436339008802787e-05, 1.36473965487376e-05, 1.2413835156251357e-05, 1.4433967932928652e-05, 1.4125584743506612e-05, 1.2814680849885913e-05, 1.2041653296280929e-05, 1.1199585185517838e-05, 1.1773712771849632e-05, 1.0837828788498037e-05, 1.1502449707784025e-05, 1.0554664248685403e-05, 1.0591138200636864e-05, 1.6819521378532727e-05, 1.5585910362957223e-05, 1.4737335404087717e-05, 1.367530110239271e-05, 1.2851639100585705e-05, 1.348117484490762e-05, 1.4108077377775078e-05, 1.3515966427004904e-05, 1.2215293671442884e-05, 1.0993773895054546e-05, 1.6058628811401817e-05, 1.6317333008896378e-05, 1.5586091317938308e-05, 1.6141738143159822e-05, 1.5756654328135074e-05, 1.41877491909161e-05, 1.4859893409442532e-05, 1.3861944664221762e-05, 1.4404346544570041e-05, 1.5685967098266188e-05, 1.5474312746609962e-05, 1.4093664533286372e-05, 1.2907505440768963e-05, 1.178881108593401e-05, 1.2880023919128629e-05, 1.1593318591840413e-05, 1.5967835090555993e-05, 1.870922416502286e-05, 1.7553095528661664e-05, 1.696615088932618e-05, 1.5390070884977596e-05, 1.594642580944395e-05, 1.4469283330815412e-05, 1.3323212284451357e-05, 1.2012308169027455e-05, 1.5527407240222104e-05, 1.3975859538363315e-05, 1.2675048169548745e-05, 1.1409145151190126e-05, 1.118220531341939e-05, 1.0804304270729536e-05, 9.745080080871693e-06, 1.2568934310761622e-05, 1.131207634323573e-05, 1.1112787895684186e-05, 1.0023657586026107e-05, 9.893538157525922e-06, 9.134059368014374e-06, 8.442972806982504e-06, 8.416536749412158e-06, 8.002495906578198e-06, 8.307837561598905e-06, 9.048757588639908e-06, 8.156356821619274e-06, 1.2271440658314737e-05, 1.1821391526341044e-05, 1.0960314117608814e-05, 1.0313130172847208e-05, 1.0441822159385765e-05, 1.3360400001308627e-05, 1.2026702423758312e-05, 1.5333533828528342e-05, 2.2145329419009695e-05, 2.361751353383316e-05, 2.291489760485331e-05, 2.0782821884008173e-05, 2.034125101721181e-05, 1.9672737452786524e-05, 1.9313961222600972e-05, 1.7675721289403773e-05, 1.8621730302407253e-05, 1.689101107831923e-05, 1.6532912825014978e-05, 1.493641885771355e-05, 1.346395022348249e-05, 1.2120152049636234e-05, 1.0908171223598682e-05], "accuracy_test": 0.8217, "start": "2016-02-04 08:35:26.884000", "learning_rate_per_epoch": [0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955, 0.00040582093060947955], "accuracy_train_first": 0.5496470588235294, "accuracy_train_last": 0.9971058823529412, "batch_size_eval": 1024, "accuracy_train_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_test_std": 0, "error_valid": [0.4536, 0.34040000000000004, 0.29733333333333334, 0.2730666666666667, 0.23493333333333333, 0.21906666666666663, 0.21199999999999997, 0.19679999999999997, 0.1929333333333333, 0.1909333333333333, 0.17986666666666662, 0.18479999999999996, 0.1730666666666667, 0.17400000000000004, 0.16559999999999997, 0.16133333333333333, 0.16226666666666667, 0.16026666666666667, 0.15346666666666664, 0.16186666666666671, 0.15773333333333328, 0.15239999999999998, 0.14773333333333338, 0.15413333333333334, 0.14933333333333332, 0.1505333333333333, 0.14680000000000004, 0.1472, 0.1385333333333333, 0.15026666666666666, 0.15066666666666662, 0.1525333333333333, 0.13773333333333337, 0.15000000000000002, 0.1398666666666667, 0.14639999999999997, 0.138, 0.1438666666666667, 0.1392, 0.14400000000000002, 0.13626666666666665, 0.14146666666666663, 0.13746666666666663, 0.13959999999999995, 0.13280000000000003, 0.14159999999999995, 0.1372, 0.13546666666666662, 0.13426666666666665, 0.13213333333333332, 0.13306666666666667, 0.13973333333333338, 0.13053333333333328, 0.1353333333333333, 0.13546666666666662, 0.13639999999999997, 0.13093333333333335, 0.12773333333333337, 0.12746666666666662, 0.13639999999999997, 0.13013333333333332, 0.13, 0.13173333333333337, 0.13360000000000005, 0.12613333333333332, 0.12826666666666664, 0.12960000000000005, 0.132, 0.12773333333333337, 0.126, 0.11839999999999995, 0.11933333333333329, 0.12546666666666662, 0.12239999999999995, 0.1253333333333333, 0.1306666666666667, 0.12786666666666668, 0.12293333333333334, 0.13506666666666667, 0.1246666666666667, 0.12560000000000004, 0.12960000000000005, 0.1246666666666667, 0.12106666666666666, 0.12573333333333336, 0.11893333333333334, 0.12039999999999995, 0.12373333333333336, 0.12039999999999995, 0.12373333333333336, 0.12413333333333332, 0.11613333333333331, 0.12386666666666668, 0.12453333333333338, 0.12039999999999995, 0.11853333333333338, 0.11973333333333336, 0.12453333333333338, 0.12106666666666666, 0.12239999999999995, 0.11933333333333329, 0.128, 0.11960000000000004, 0.118, 0.12626666666666664, 0.11613333333333331, 0.118, 0.11653333333333338, 0.12053333333333338, 0.12053333333333338, 0.11773333333333336, 0.11533333333333329, 0.11773333333333336, 0.12173333333333336, 0.11519999999999997, 0.12093333333333334, 0.11706666666666665, 0.12013333333333331, 0.11226666666666663, 0.11786666666666668, 0.11680000000000001, 0.11733333333333329, 0.11199999999999999, 0.11213333333333331, 0.11719999999999997, 0.11933333333333329, 0.11119999999999997, 0.10893333333333333, 0.11839999999999995, 0.11813333333333331, 0.10893333333333333, 0.11546666666666672, 0.11426666666666663, 0.11506666666666665, 0.11680000000000001, 0.12306666666666666, 0.11319999999999997, 0.11266666666666669, 0.11599999999999999, 0.11919999999999997, 0.11386666666666667, 0.10786666666666667, 0.11733333333333329, 0.10946666666666671, 0.11306666666666665, 0.11280000000000001, 0.11346666666666672, 0.11413333333333331, 0.11560000000000004, 0.10986666666666667, 0.1166666666666667, 0.11240000000000006, 0.11093333333333333, 0.11306666666666665, 0.11586666666666667, 0.11880000000000002, 0.11280000000000001, 0.12080000000000002, 0.1068, 0.11119999999999997, 0.11173333333333335, 0.11986666666666668, 0.11386666666666667, 0.11146666666666671, 0.11040000000000005, 0.11199999999999999, 0.10973333333333335, 0.10746666666666671, 0.11199999999999999, 0.11226666666666663, 0.11226666666666663, 0.12146666666666661, 0.11106666666666665, 0.12039999999999995, 0.11426666666666663, 0.11066666666666669, 0.11146666666666671, 0.10799999999999998, 0.11146666666666671, 0.11973333333333336, 0.1068, 0.1061333333333333, 0.11333333333333329, 0.10973333333333335, 0.10840000000000005, 0.10933333333333328, 0.11093333333333333, 0.10933333333333328, 0.11040000000000005, 0.11293333333333333, 0.10719999999999996, 0.10653333333333337, 0.11253333333333337, 0.10546666666666671, 0.10853333333333337, 0.11133333333333328, 0.11319999999999997, 0.11106666666666665, 0.10706666666666664, 0.11133333333333328, 0.11519999999999997, 0.10893333333333333, 0.10986666666666667, 0.10706666666666664, 0.10973333333333335, 0.10466666666666669, 0.10746666666666671, 0.10640000000000005, 0.1081333333333333, 0.11106666666666665, 0.11266666666666669, 0.11533333333333329, 0.10919999999999996, 0.10360000000000003, 0.10866666666666669, 0.11080000000000001, 0.11106666666666665, 0.10306666666666664, 0.10999999999999999, 0.10506666666666664, 0.10773333333333335, 0.11360000000000003, 0.11053333333333337, 0.11066666666666669, 0.10386666666666666, 0.1081333333333333, 0.10693333333333332, 0.10906666666666665, 0.10919999999999996, 0.10946666666666671, 0.11133333333333328, 0.10840000000000005, 0.10893333333333333, 0.11053333333333337, 0.11213333333333331, 0.11026666666666662, 0.11826666666666663, 0.1213333333333333, 0.1081333333333333, 0.10253333333333337, 0.10999999999999999, 0.10586666666666666, 0.11546666666666672, 0.10999999999999999, 0.11119999999999997, 0.10706666666666664, 0.10519999999999996, 0.11453333333333338, 0.10946666666666671, 0.10760000000000003, 0.11266666666666669, 0.10293333333333332, 0.10853333333333337, 0.10586666666666666, 0.10826666666666662, 0.10573333333333335, 0.10440000000000005, 0.10693333333333332, 0.10199999999999998, 0.10386666666666666, 0.10599999999999998, 0.10933333333333328, 0.10919999999999996, 0.11173333333333335, 0.10946666666666671, 0.11240000000000006, 0.10693333333333332, 0.1048, 0.11693333333333333, 0.11106666666666665, 0.11186666666666667, 0.10719999999999996, 0.10666666666666669, 0.10426666666666662, 0.10373333333333334, 0.10493333333333332, 0.10840000000000005, 0.10773333333333335, 0.11599999999999999, 0.10399999999999998, 0.10493333333333332, 0.10293333333333332, 0.10360000000000003, 0.10719999999999996, 0.1021333333333333, 0.10880000000000001, 0.11133333333333328, 0.11266666666666669, 0.11160000000000003, 0.10946666666666671, 0.10666666666666669, 0.10946666666666671, 0.10319999999999996, 0.10760000000000003, 0.09986666666666666, 0.11386666666666667, 0.1048, 0.10373333333333334, 0.1081333333333333, 0.10226666666666662, 0.10546666666666671, 0.10466666666666669, 0.1068, 0.11360000000000003, 0.10719999999999996, 0.1081333333333333, 0.10706666666666664, 0.10399999999999998, 0.10399999999999998, 0.10706666666666664, 0.1001333333333333, 0.10599999999999998, 0.10919999999999996, 0.1068, 0.10946666666666671, 0.10506666666666664, 0.10493333333333332, 0.10333333333333339, 0.10386666666666666, 0.10933333333333328, 0.10199999999999998, 0.1061333333333333, 0.11319999999999997, 0.10360000000000003, 0.1081333333333333, 0.10866666666666669, 0.10306666666666664, 0.11293333333333333, 0.1068, 0.09986666666666666, 0.11586666666666667, 0.1008, 0.10226666666666662, 0.1048, 0.10173333333333334, 0.10946666666666671, 0.10173333333333334, 0.10373333333333334, 0.09986666666666666, 0.10360000000000003, 0.10853333333333337, 0.10586666666666666, 0.10466666666666669, 0.10493333333333332, 0.10506666666666664], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.05214869589314809, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.0004058209250494107, "optimization": "adam", "nb_data_augmentation": 4, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 7.214513972635746e-07, "rotation_range": [0, 0], "momentum": 0.6278364486569106}, "accuracy_valid_max": 0.9001333333333333, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        y_pred = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            y_pred.extend((nnet.predict(X[mini_batch]) == y[mini_batch]).tolist())\n        return np.mean(y_pred)\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            acc = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = acc\n            status[\"accuracy_train_std\"] = 0\n            acc = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = acc\n            status[\"accuracy_valid_std\"] = 0\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    acc = evaluate(X_test, y_test, batch_size_eval)\n    light.set(\"accuracy_test\", acc)\n    light.set(\"accuracy_test_std\", 0)\n    print(\"Test accuracy : {}+-{}\".format(acc, 0))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8949333333333334, "accuracy_valid_std": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_valid": [0.5464, 0.6596, 0.7026666666666667, 0.7269333333333333, 0.7650666666666667, 0.7809333333333334, 0.788, 0.8032, 0.8070666666666667, 0.8090666666666667, 0.8201333333333334, 0.8152, 0.8269333333333333, 0.826, 0.8344, 0.8386666666666667, 0.8377333333333333, 0.8397333333333333, 0.8465333333333334, 0.8381333333333333, 0.8422666666666667, 0.8476, 0.8522666666666666, 0.8458666666666667, 0.8506666666666667, 0.8494666666666667, 0.8532, 0.8528, 0.8614666666666667, 0.8497333333333333, 0.8493333333333334, 0.8474666666666667, 0.8622666666666666, 0.85, 0.8601333333333333, 0.8536, 0.862, 0.8561333333333333, 0.8608, 0.856, 0.8637333333333334, 0.8585333333333334, 0.8625333333333334, 0.8604, 0.8672, 0.8584, 0.8628, 0.8645333333333334, 0.8657333333333334, 0.8678666666666667, 0.8669333333333333, 0.8602666666666666, 0.8694666666666667, 0.8646666666666667, 0.8645333333333334, 0.8636, 0.8690666666666667, 0.8722666666666666, 0.8725333333333334, 0.8636, 0.8698666666666667, 0.87, 0.8682666666666666, 0.8664, 0.8738666666666667, 0.8717333333333334, 0.8704, 0.868, 0.8722666666666666, 0.874, 0.8816, 0.8806666666666667, 0.8745333333333334, 0.8776, 0.8746666666666667, 0.8693333333333333, 0.8721333333333333, 0.8770666666666667, 0.8649333333333333, 0.8753333333333333, 0.8744, 0.8704, 0.8753333333333333, 0.8789333333333333, 0.8742666666666666, 0.8810666666666667, 0.8796, 0.8762666666666666, 0.8796, 0.8762666666666666, 0.8758666666666667, 0.8838666666666667, 0.8761333333333333, 0.8754666666666666, 0.8796, 0.8814666666666666, 0.8802666666666666, 0.8754666666666666, 0.8789333333333333, 0.8776, 0.8806666666666667, 0.872, 0.8804, 0.882, 0.8737333333333334, 0.8838666666666667, 0.882, 0.8834666666666666, 0.8794666666666666, 0.8794666666666666, 0.8822666666666666, 0.8846666666666667, 0.8822666666666666, 0.8782666666666666, 0.8848, 0.8790666666666667, 0.8829333333333333, 0.8798666666666667, 0.8877333333333334, 0.8821333333333333, 0.8832, 0.8826666666666667, 0.888, 0.8878666666666667, 0.8828, 0.8806666666666667, 0.8888, 0.8910666666666667, 0.8816, 0.8818666666666667, 0.8910666666666667, 0.8845333333333333, 0.8857333333333334, 0.8849333333333333, 0.8832, 0.8769333333333333, 0.8868, 0.8873333333333333, 0.884, 0.8808, 0.8861333333333333, 0.8921333333333333, 0.8826666666666667, 0.8905333333333333, 0.8869333333333334, 0.8872, 0.8865333333333333, 0.8858666666666667, 0.8844, 0.8901333333333333, 0.8833333333333333, 0.8876, 0.8890666666666667, 0.8869333333333334, 0.8841333333333333, 0.8812, 0.8872, 0.8792, 0.8932, 0.8888, 0.8882666666666666, 0.8801333333333333, 0.8861333333333333, 0.8885333333333333, 0.8896, 0.888, 0.8902666666666667, 0.8925333333333333, 0.888, 0.8877333333333334, 0.8877333333333334, 0.8785333333333334, 0.8889333333333334, 0.8796, 0.8857333333333334, 0.8893333333333333, 0.8885333333333333, 0.892, 0.8885333333333333, 0.8802666666666666, 0.8932, 0.8938666666666667, 0.8866666666666667, 0.8902666666666667, 0.8916, 0.8906666666666667, 0.8890666666666667, 0.8906666666666667, 0.8896, 0.8870666666666667, 0.8928, 0.8934666666666666, 0.8874666666666666, 0.8945333333333333, 0.8914666666666666, 0.8886666666666667, 0.8868, 0.8889333333333334, 0.8929333333333334, 0.8886666666666667, 0.8848, 0.8910666666666667, 0.8901333333333333, 0.8929333333333334, 0.8902666666666667, 0.8953333333333333, 0.8925333333333333, 0.8936, 0.8918666666666667, 0.8889333333333334, 0.8873333333333333, 0.8846666666666667, 0.8908, 0.8964, 0.8913333333333333, 0.8892, 0.8889333333333334, 0.8969333333333334, 0.89, 0.8949333333333334, 0.8922666666666667, 0.8864, 0.8894666666666666, 0.8893333333333333, 0.8961333333333333, 0.8918666666666667, 0.8930666666666667, 0.8909333333333334, 0.8908, 0.8905333333333333, 0.8886666666666667, 0.8916, 0.8910666666666667, 0.8894666666666666, 0.8878666666666667, 0.8897333333333334, 0.8817333333333334, 0.8786666666666667, 0.8918666666666667, 0.8974666666666666, 0.89, 0.8941333333333333, 0.8845333333333333, 0.89, 0.8888, 0.8929333333333334, 0.8948, 0.8854666666666666, 0.8905333333333333, 0.8924, 0.8873333333333333, 0.8970666666666667, 0.8914666666666666, 0.8941333333333333, 0.8917333333333334, 0.8942666666666667, 0.8956, 0.8930666666666667, 0.898, 0.8961333333333333, 0.894, 0.8906666666666667, 0.8908, 0.8882666666666666, 0.8905333333333333, 0.8876, 0.8930666666666667, 0.8952, 0.8830666666666667, 0.8889333333333334, 0.8881333333333333, 0.8928, 0.8933333333333333, 0.8957333333333334, 0.8962666666666667, 0.8950666666666667, 0.8916, 0.8922666666666667, 0.884, 0.896, 0.8950666666666667, 0.8970666666666667, 0.8964, 0.8928, 0.8978666666666667, 0.8912, 0.8886666666666667, 0.8873333333333333, 0.8884, 0.8905333333333333, 0.8933333333333333, 0.8905333333333333, 0.8968, 0.8924, 0.9001333333333333, 0.8861333333333333, 0.8952, 0.8962666666666667, 0.8918666666666667, 0.8977333333333334, 0.8945333333333333, 0.8953333333333333, 0.8932, 0.8864, 0.8928, 0.8918666666666667, 0.8929333333333334, 0.896, 0.896, 0.8929333333333334, 0.8998666666666667, 0.894, 0.8908, 0.8932, 0.8905333333333333, 0.8949333333333334, 0.8950666666666667, 0.8966666666666666, 0.8961333333333333, 0.8906666666666667, 0.898, 0.8938666666666667, 0.8868, 0.8964, 0.8918666666666667, 0.8913333333333333, 0.8969333333333334, 0.8870666666666667, 0.8932, 0.9001333333333333, 0.8841333333333333, 0.8992, 0.8977333333333334, 0.8952, 0.8982666666666667, 0.8905333333333333, 0.8982666666666667, 0.8962666666666667, 0.9001333333333333, 0.8964, 0.8914666666666666, 0.8941333333333333, 0.8953333333333333, 0.8950666666666667, 0.8949333333333334], "seed": 333345921, "model": "residualv3", "loss_std": [0.3479726314544678, 0.19088149070739746, 0.17852181196212769, 0.17122027277946472, 0.16488845646381378, 0.1585618406534195, 0.1570093184709549, 0.15290313959121704, 0.14992409944534302, 0.14740172028541565, 0.14283046126365662, 0.1389647275209427, 0.13700543344020844, 0.13310568034648895, 0.1307196468114853, 0.12789753079414368, 0.12422161549329758, 0.12238600105047226, 0.11929488927125931, 0.11566587537527084, 0.11535707861185074, 0.10874315351247787, 0.10673478245735168, 0.10608437657356262, 0.10348252207040787, 0.09922963380813599, 0.09717865288257599, 0.09608311206102371, 0.09335392713546753, 0.08834686130285263, 0.08592838793992996, 0.08527659624814987, 0.08313994109630585, 0.08071008324623108, 0.08173150569200516, 0.07943210005760193, 0.07670440524816513, 0.07525324821472168, 0.07217656821012497, 0.0718100443482399, 0.06823378056287766, 0.06972953677177429, 0.06819773465394974, 0.06466028094291687, 0.06441690772771835, 0.06479546427726746, 0.0596003532409668, 0.06069066748023033, 0.05874292925000191, 0.05832801014184952, 0.057414744049310684, 0.05698607861995697, 0.057024791836738586, 0.05368748679757118, 0.053853001445531845, 0.053224898874759674, 0.05451139807701111, 0.05137455835938454, 0.05041096732020378, 0.051468625664711, 0.051797132939100266, 0.04860100522637367, 0.04625587910413742, 0.04538002610206604, 0.046263791620731354, 0.04565760865807533, 0.04595263674855232, 0.04638167470693588, 0.04547430947422981, 0.04445474594831467, 0.04425711929798126, 0.04087688773870468, 0.042096227407455444, 0.04327821359038353, 0.04275745525956154, 0.04081970080733299, 0.04105477035045624, 0.042890481650829315, 0.03886953741312027, 0.04044359177350998, 0.03798973187804222, 0.03992554545402527, 0.03961664065718651, 0.03887222334742546, 0.039326611906290054, 0.03612866252660751, 0.03979865461587906, 0.0388374961912632, 0.038968831300735474, 0.035427823662757874, 0.034114737063646317, 0.035643648356199265, 0.03573243319988251, 0.03344060853123665, 0.03659498319029808, 0.037021782249212265, 0.03405524790287018, 0.03498067334294319, 0.033221181482076645, 0.036180928349494934, 0.03412611782550812, 0.0319378562271595, 0.0361410416662693, 0.03460276126861572, 0.029959026724100113, 0.03208903968334198, 0.03181358426809311, 0.03227356821298599, 0.032476138323545456, 0.034359585493803024, 0.03278128430247307, 0.030201664194464684, 0.03258151188492775, 0.031837839633226395, 0.03275023773312569, 0.03172152489423752, 0.030931780114769936, 0.030633609741926193, 0.030557379126548767, 0.029703935608267784, 0.03189034387469292, 0.03360368311405182, 0.030727725476026535, 0.029384685680270195, 0.030290253460407257, 0.028985733166337013, 0.028485994786024094, 0.029488569125533104, 0.029404157772660255, 0.02940172515809536, 0.028341423720121384, 0.02810775674879551, 0.028095293790102005, 0.029397722333669662, 0.02908250316977501, 0.02812577784061432, 0.02682681195437908, 0.02739204466342926, 0.027317609637975693, 0.027118362486362457, 0.026953300461173058, 0.026374561712145805, 0.02666744589805603, 0.027377493679523468, 0.02597299963235855, 0.029160641133785248, 0.027563679963350296, 0.027810165658593178, 0.027093466371297836, 0.02865125797688961, 0.025121184065937996, 0.024845615029335022, 0.02713482826948166, 0.02719411998987198, 0.025407858192920685, 0.025507722049951553, 0.02797926776111126, 0.0243169404566288, 0.02930440567433834, 0.025101831182837486, 0.024484535679221153, 0.025032855570316315, 0.025784436613321304, 0.025529565289616585, 0.023763956502079964, 0.024759571999311447, 0.02440578117966652, 0.025264037773013115, 0.02848939597606659, 0.034101586788892746, 0.022386332973837852, 0.023801349103450775, 0.024538392201066017, 0.02372380532324314, 0.024260684847831726, 0.025531411170959473, 0.024439053609967232, 0.022983083501458168, 0.024413222447037697, 0.02228865772485733, 0.023923762142658234, 0.021941684186458588, 0.024275049567222595, 0.025879118591547012, 0.028162270784378052, 0.021523945033550262, 0.028448401018977165, 0.02090201899409294, 0.03229799494147301, 0.02254609763622284, 0.023944362998008728, 0.02507179044187069, 0.0208087470382452, 0.024208253249526024, 0.023686641827225685, 0.020947009325027466, 0.021693965420126915, 0.0236358605325222, 0.022263674065470695, 0.023149987682700157, 0.02246250957250595, 0.025011776015162468, 0.02213827520608902, 0.021011648699641228, 0.024233855307102203, 0.022518856450915337, 0.025138746947050095, 0.021530289202928543, 0.022331340238451958, 0.023892054334282875, 0.020895440131425858, 0.023188516497612, 0.01937113329768181, 0.026126276701688766, 0.0228318739682436, 0.02038184367120266, 0.021842997521162033, 0.02146773971617222, 0.025412453338503838, 0.021234437823295593, 0.01939302310347557, 0.02167040854692459, 0.021325886249542236, 0.022145429626107216, 0.021717626601457596, 0.023327648639678955, 0.02159207873046398, 0.020889095962047577, 0.024546021595597267, 0.02167881652712822, 0.02235124073922634, 0.021209636703133583, 0.020992713049054146, 0.021703017875552177, 0.020155169069767, 0.020979614928364754, 0.0217392947524786, 0.020228274166584015, 0.01994260400533676, 0.021693987771868706, 0.021143635734915733, 0.02306702919304371, 0.01942109316587448, 0.018177833408117294, 0.024319415912032127, 0.017979662865400314, 0.02075614593923092, 0.02100408636033535, 0.01855301670730114, 0.022012857720255852, 0.019043298438191414, 0.023284029215574265, 0.017365017905831337, 0.02124866098165512, 0.020386844873428345, 0.025254108011722565, 0.01716204546391964, 0.021573718637228012, 0.0204915851354599, 0.019642721861600876, 0.01989537850022316, 0.01889919489622116, 0.019718946889042854, 0.02041834034025669, 0.02650969661772251, 0.01963825337588787, 0.019094573333859444, 0.02175290882587433, 0.01907547190785408, 0.0228161308914423, 0.018392741680145264, 0.01801205798983574, 0.01983095519244671, 0.022379299625754356, 0.01880635879933834, 0.021848183125257492, 0.019672928377985954, 0.020666563883423805, 0.0180100928992033, 0.02033216878771782, 0.022659659385681152, 0.01580756902694702, 0.022937020286917686, 0.018307354301214218, 0.017876727506518364, 0.01827356591820717, 0.017004556953907013, 0.018495777621865273, 0.019582711160182953, 0.017187707126140594, 0.02402598410844803, 0.019451068714261055, 0.01755679026246071, 0.019745541736483574, 0.018357308581471443, 0.02451627142727375, 0.016866525635123253, 0.02395261824131012, 0.01651165261864662, 0.0177992545068264, 0.02133871614933014, 0.019107356667518616, 0.017092455178499222, 0.021568508818745613, 0.019702477380633354, 0.014389827847480774, 0.02205519750714302, 0.020870663225650787, 0.020423952490091324, 0.022376414388418198, 0.019053494557738304, 0.01581435464322567, 0.020329460501670837, 0.020379669964313507, 0.01548601221293211, 0.01794964261353016, 0.020551772788167, 0.01973617635667324, 0.016902634873986244, 0.02362050488591194, 0.017026333138346672, 0.018473977223038673, 0.015811217948794365, 0.020204296335577965, 0.02056771144270897, 0.019164912402629852, 0.020273910835385323, 0.01972581446170807, 0.018063103780150414, 0.022169388830661774, 0.0182964988052845, 0.020892798900604248, 0.01968506909906864, 0.021848756819963455, 0.016930796205997467, 0.018576787784695625, 0.016600504517555237, 0.016262611374258995, 0.016103671863675117, 0.016527244821190834, 0.020409662276506424, 0.016509883105754852, 0.016215510666370392, 0.01972472295165062, 0.020546110346913338]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:45 2016", "state": "available"}], "summary": "80b5b00a86c046b825e9078482ec345f"}