{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 64, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.01285765332169589, 0.01896394986699268, 0.013715280815000074, 0.013088261192555245, 0.009213315461194473, 0.01761089189830704, 0.008325335566355825, 0.00828509605173614, 0.010907378095955165, 0.010399415631196014, 0.009222993821277175, 0.008823948126685984, 0.007024251946027453, 0.004430441938373793, 0.005789192439859098, 0.012212525569726249, 0.004362823802824361, 0.0107452073609156, 0.00829152319956532, 0.013099873538633231, 0.012722389073512879, 0.008614775082692825, 0.013401559569172751, 0.009491495115353209, 0.006511733081270051, 0.00887792290111932, 0.008506263926389835, 0.012586281781168083, 0.010732496045370438, 0.011124812864436524, 0.01206865130223216, 0.008411995806962417, 0.012907398788172184, 0.009293783695988152, 0.011590293464553713, 0.012053308707760354, 0.014958430988299083, 0.0068392665499678535, 0.00871430254390921, 0.0032549756076235207, 0.008027019546157376, 0.010473784196253586, 0.00902445115059952, 0.010402310532646978, 0.0053134828204162085, 0.011261936177384118, 0.013092562261927466, 0.008248833697366963, 0.01024655662759687, 0.00691829068905957, 0.011310979889135455, 0.011028899767926044, 0.009873313931498552, 0.009759375845422538, 0.0073823398120058, 0.009502171667416149, 0.00999683265992758, 0.011302751566157197, 0.012591643942949676, 0.013221891128457923, 0.0078799925724129, 0.01182974184238855, 0.011099455397644736, 0.008827193942628427, 0.010587917588460942, 0.008950273431903329, 0.009842852516104946, 0.009614546693587377, 0.011009813680690825, 0.01094209631676643, 0.01138714489973181, 0.00902148286723431, 0.00833350997139931, 0.013178152628467624, 0.008944250854901326, 0.008770751755521267, 0.00891839719279536, 0.0033162557646401977, 0.005649347108670091, 0.009096928853977766, 0.011100019067225193, 0.009199361143552052, 0.008694360321758672, 0.014060113299818698, 0.008041231720202434, 0.004243523025578622, 0.0098544199967107, 0.008175310051087402, 0.006054318228030151, 0.008471757301027508, 0.014956963483100915, 0.010486474440923323, 0.0061438304768549465, 0.008465689540454098, 0.010613898231732715, 0.005378230811708015, 0.007090813561732503, 0.008908975857882171, 0.006462406400378632, 0.008233289003139922, 0.00804685601570752, 0.010251735369410283, 0.007061522163933465, 0.01033778600305461, 0.008111089245860861, 0.009177304993477369, 0.00914940731619688, 0.010023393847481247, 0.008089460278161044, 0.007887199635152251, 0.008036106303696085, 0.013174101077412357, 0.009598912587527927, 0.010626959025706005, 0.013051092448025813, 0.008975374251380955, 0.007339801179376283, 0.012642043909029644, 0.0090749759141376, 0.010738454459616364, 0.009646759607839124, 0.010253009683510096, 0.009726243413725787, 0.007932808379892527, 0.007663552859858574, 0.007983478061499561, 0.008984561650916434, 0.008256436768698746, 0.009173330447668597, 0.00691297789442525, 0.009756173998155867, 0.008127530389710414, 0.010359808591259697, 0.010327958120186644, 0.009382759223604415, 0.012741742564331087, 0.013223957500574408, 0.01044078538868399, 0.009701334770437985, 0.009312107885100913, 0.008246133403662743, 0.013144323431960786, 0.009751233058341649, 0.011736114799852005, 0.015260425273356843, 0.008230144319576593, 0.006332822436831192, 0.009966921621656508, 0.008882602643991464, 0.011424311485171831, 0.009374787805409271, 0.011141389196727079, 0.012532419377414224, 0.012045009516388865, 0.010432542910414955, 0.010022422705595602, 0.007171501458013592, 0.01623100761472162, 0.009922960381832956, 0.011432892486465335, 0.010944433439057941, 0.0058764222958737474, 0.010253383824963871, 0.015684810922106086, 0.010722568486955847, 0.008492824384630835, 0.01458188388781676, 0.01228544555157302, 0.008920126674198274, 0.01065709238215449, 0.010454199746655722, 0.008492427568440269, 0.008419939780563074, 0.010660964591392885, 0.008333211343504274, 0.012586212264939481, 0.0082449392855908, 0.00997858621554416, 0.014466986943324909, 0.008102721020668726, 0.008010140554619825, 0.008290616354434179, 0.007104156609354196, 0.0072058300194804735, 0.011951007167514651, 0.009539188422703062, 0.010552202921880393, 0.013136399346111358, 0.007530209529304232, 0.010236940465464289, 0.010257437643018336, 0.00857242601653907, 0.010608472693719737, 0.008982186936169567, 0.011844203541726848, 0.009841434211360876, 0.009468481104026715, 0.006950165423942564, 0.012985186160045296, 0.005102169319935786, 0.0067829422309240986, 0.010522785912380834, 0.01103290164771015, 0.007757240920149893, 0.009430242323430971, 0.008836907959906626, 0.010632353159025798, 0.008072822771303102, 0.00951700651098274, 0.010265886875593816, 0.010157066904519828, 0.010792196615698406, 0.010143529568246904, 0.008047180725861395, 0.010036600345333269, 0.01006075549793109, 0.007742995795339663, 0.009398425164846343, 0.012824147382616195, 0.008175559283188362, 0.008000422091706823, 0.01049022292029454, 0.004729183482690013, 0.009491133671576415, 0.011539571308732158, 0.005543776497985746, 0.008470090386634956, 0.010433328578852642, 0.008835739948116322, 0.007879425440526609, 0.0068605708216835795, 0.010642873082594227, 0.011295642517791674, 0.009318040805301969, 0.0068213537441811686, 0.006633511194327027, 0.009298387436589539, 0.006612676869202943, 0.0039525666026956055, 0.00913455799949707, 0.009539458708113275, 0.007318515396324364, 0.009340137931873606, 0.011593603063861455, 0.013250946498154094, 0.011910012298757584, 0.015420333550423817, 0.011526829999606992, 0.012904582782289842, 0.010362640143780162, 0.00839215136581917, 0.010462171796259427, 0.009745855500342201, 0.007188010990974334, 0.00673205154290452, 0.009877897755208219, 0.00786503240375685, 0.008445530237157545, 0.009089830830781727, 0.007737809108135084, 0.011002117541485916, 0.008742955266012148, 0.011266241477884381, 0.00887127641147602, 0.006597426678024691, 0.012358660577098467, 0.009464906505391023, 0.010277354953117301, 0.008503141592401708, 0.008320395560410285, 0.009199019729859363, 0.008465030308566986, 0.00919404392724601, 0.007235360528156751, 0.010189280783830199, 0.008377535309243933, 0.008467720060907343, 0.0063410473181206885, 0.01100675597467912, 0.006977241344825507, 0.01006511857034395, 0.008877217285191497, 0.010061976071981739, 0.007139439226653844, 0.009853269314939486, 0.008913185864788358, 0.00766378599471584, 0.007120904145626179, 0.009821249539199219, 0.0074851127264772286, 0.010474193922212095, 0.009456608973916172, 0.011794015841448978, 0.006469066891748497, 0.006790530205588753, 0.009250363267259852, 0.010670285182764961, 0.010983893871612672, 0.009683834353394502, 0.012290273273511267, 0.009137645312031374, 0.013444017109424474, 0.011426525747984771, 0.007663332137271436, 0.008697532637865848, 0.011853139984930858, 0.010161899919704214, 0.011525674753763678, 0.008676180294720684, 0.009374003293446209, 0.009734319221957919, 0.00960983275240897], "moving_avg_accuracy_train": [0.05179164431639903, 0.11158276123857971, 0.17115554794925475, 0.23119646954091103, 0.28666980835186234, 0.3372492161460135, 0.38483505481541913, 0.42870597699399166, 0.47023768627479734, 0.5091229210560939, 0.5460909620127308, 0.5797409818367437, 0.6111838877366795, 0.639803229387061, 0.6662071363879083, 0.6903048612873234, 0.7127487754504422, 0.7328643404983751, 0.7512567395915332, 0.7685700782408147, 0.784022127033566, 0.798812130957655, 0.8120673669667253, 0.8247225618522787, 0.8364050618040018, 0.8468264139546278, 0.8558127528390191, 0.864869864644449, 0.8728562518014973, 0.8798974437702032, 0.8865669767729817, 0.8929858302100246, 0.8984908279902865, 0.904570517772238, 0.9095980991045565, 0.9143252462988904, 0.9168382504619139, 0.9203043812919685, 0.9243072753425428, 0.9275589267130965, 0.9306457761168144, 0.9324195483920839, 0.9355412050100552, 0.9379298079828868, 0.9404003851453309, 0.9411521574927395, 0.9424309300982552, 0.944302585525353, 0.9456174127978454, 0.947456485356193, 0.9490906882706014, 0.9505220154614445, 0.9513869247034138, 0.9520841070081278, 0.9534858095871231, 0.9539218780320191, 0.9554118098705208, 0.9570571988239448, 0.95827069281775, 0.9574889116669736, 0.9587430839288937, 0.9595369454384131, 0.9604001942719712, 0.9616583519281074, 0.9628581952317437, 0.9631661408490731, 0.9634851445832411, 0.9645766773344501, 0.9644826931558224, 0.9638794910640773, 0.9644759320981735, 0.9651894042895651, 0.9655270068654075, 0.9660168610884274, 0.966046286696316, 0.9658145340302835, 0.9665011389225209, 0.9677096350743348, 0.9689204784490535, 0.9693825554541851, 0.9707121361433089, 0.9716111036670824, 0.9728805178539455, 0.9731024119376447, 0.9730579038903365, 0.9737479073251308, 0.9742084390997698, 0.9750088923993259, 0.9748062883891828, 0.975421434772902, 0.9757565025301541, 0.9762836750438423, 0.9765464336180387, 0.9762086406276819, 0.9769067660732655, 0.9773258516302523, 0.9780447173600842, 0.9783360208467133, 0.9791678193941942, 0.9791561504750312, 0.9788294282096894, 0.978326222924481, 0.9789218721344324, 0.9790069136031597, 0.9791973111190434, 0.9788735203333665, 0.9795981265583816, 0.9799130534858768, 0.9808847678170602, 0.9812874136532483, 0.9816078701296087, 0.9823170607952193, 0.9826833981300107, 0.982971176955114, 0.9828536119370205, 0.983280154351661, 0.983496595761733, 0.9834798405379499, 0.9841576551817832, 0.9844398423790903, 0.9843428215328849, 0.9845483633748437, 0.9849914065016452, 0.9857110158514807, 0.9859239335365891, 0.9857365962460531, 0.9857656303333803, 0.9856893823667181, 0.9856882245610171, 0.9863730653858771, 0.9869521836984798, 0.9865248015631741, 0.986735395736637, 0.9866411902403543, 0.987253949936557, 0.9872823112298152, 0.9878123576365957, 0.9882568473193647, 0.9885383414933898, 0.9886359012797743, 0.9886353494327584, 0.9883139822347299, 0.9884037149636379, 0.988805381004188, 0.9886182534680918, 0.98898218961653, 0.989277180066791, 0.9897728612041687, 0.9895306941313708, 0.9897104163099189, 0.989541959090841, 0.9896135618793852, 0.989329268116465, 0.9897988501584085, 0.9898517753354432, 0.9899762100031263, 0.9897718728194895, 0.9898042081935022, 0.9899193765848847, 0.9902113291418817, 0.989906786182474, 0.9894512998630453, 0.9896714414541217, 0.9889162939230044, 0.9875834745736165, 0.988204312384112, 0.9884468822242815, 0.9887116980566245, 0.9884919419414382, 0.9889220237139794, 0.9890393439985431, 0.9885380684153646, 0.9891774872798083, 0.9894157816316078, 0.9894093213625039, 0.9895429800000631, 0.989726123889361, 0.9902094266789964, 0.9904189318527818, 0.9907632714794269, 0.9910894171362553, 0.9910318507571628, 0.990745164937399, 0.9907499616127251, 0.9904961510538428, 0.9909419786567919, 0.9911270207089791, 0.9912982088535667, 0.9915778362194098, 0.9915993111165257, 0.9916837066417779, 0.9916783905526279, 0.9921710797711747, 0.9920611146512001, 0.9921389654992029, 0.9919067258683486, 0.9919557656696182, 0.9920883292431603, 0.9912101476200623, 0.9913916242640177, 0.9919525176411874, 0.9919900388675633, 0.9922934891843876, 0.9923386938373775, 0.9921422488953157, 0.9925536750474507, 0.9922915902058194, 0.9927880996745323, 0.9930210445058978, 0.9932422845493556, 0.9935367316896582, 0.9936622972849966, 0.993526515398182, 0.993611177846459, 0.9936339677249268, 0.9938845962500532, 0.9941357385595717, 0.993724784010785, 0.9940453859668494, 0.993915400941593, 0.9936961078712432, 0.9941219200376996, 0.9943353790755963, 0.9944670743894745, 0.9944158643088695, 0.9943721364339534, 0.9944699290774721, 0.9943463539149723, 0.9943398400627884, 0.9945012801636525, 0.994425723166344, 0.9945902007009002, 0.9944755247153432, 0.9937259970569319, 0.9939791204905429, 0.9939139267819741, 0.9941598108894909, 0.994425284413637, 0.9944875353246634, 0.9945110451100727, 0.9947646467002559, 0.9950021887266589, 0.9949811365206597, 0.9952040050114508, 0.9949419180888863, 0.9950594264288072, 0.9943724163371446, 0.9946329053581919, 0.9942302547033252, 0.9944026893889542, 0.9947275804202969, 0.9947828171699338, 0.9944954197160448, 0.9948366143515832, 0.9950809465545294, 0.9950915821443237, 0.9950801917870341, 0.9953024553464259, 0.9951351190379738, 0.9953264213818231, 0.9949893498531831, 0.9953160647559693, 0.9953613172458579, 0.9953159779319863, 0.9955123377280733, 0.9947220519815211, 0.9950870863667023, 0.9949157463681366, 0.9950451724753705, 0.9952453613290239, 0.9940490792508926, 0.9942349451353271, 0.9942324885682229, 0.9944744543316479, 0.9948433221425308, 0.9949544140354206, 0.9949009369175928, 0.994971462198471, 0.9951604569381569, 0.9952584365419602, 0.9954536110794401, 0.995654808751258, 0.9955963963285132, 0.9957205364575666, 0.995748557216572, 0.9954715065544386, 0.9955639578335186, 0.995726255093033, 0.9956583728873012, 0.9958297937830949, 0.9956028202821847, 0.9957914221825377, 0.995582164636903, 0.9955264023767934, 0.9956668424962569, 0.9955653740204408, 0.9953671315957868, 0.9954979221564462, 0.9956737623812777, 0.9958274043348259, 0.995923793365629, 0.9957919795052566, 0.9958710207285497, 0.9959630481199805, 0.9958435848258396, 0.995640772808741, 0.9957976776707239, 0.9958621621357944, 0.9956597814876911, 0.9960170734282077, 0.9958247782877679, 0.9959423562625626], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 442221180, "moving_var_accuracy_train": [0.0241413697889675, 0.0539020317752877, 0.08045208084603919, 0.10485108315161404, 0.12206159670596405, 0.132879925470631, 0.1399716413004042, 0.14329639748554907, 0.14449070361906244, 0.1436501866131252, 0.14158489242135688, 0.1376173176866294, 0.13275349290085645, 0.12684974405928215, 0.12043926639753845, 0.11362164286573564, 0.10679304212581513, 0.0997554615280122, 0.09282443847482899, 0.08623975988400845, 0.07976467620264971, 0.07375690652705584, 0.06796252740925562, 0.06260766028665209, 0.05757522150408496, 0.052795140579502686, 0.04824241510045854, 0.044156455058717216, 0.04031485097124588, 0.03672957133318282, 0.0334569582341409, 0.030482077525742952, 0.027706614778214848, 0.025268616950996244, 0.022969244422374312, 0.020873433265508976, 0.018842926648268442, 0.017066760549821085, 0.015504292941860084, 0.014049022777394695, 0.012729878252826335, 0.011485206840304333, 0.010424388816638621, 0.009433298752431143, 0.00854490264082834, 0.00769549883170646, 0.00694066628292537, 0.006278127500972891, 0.0056658736876840105, 0.005129726009789415, 0.004640788981299621, 0.004195148360914882, 0.003782366136794988, 0.003408504091609546, 0.0030853366135282496, 0.002778514353373131, 0.0025206419899862467, 0.0022929435342600732, 0.002076902289891078, 0.0018747126968113547, 0.0017013979596933499, 0.0015369301085906809, 0.0013899438846693675, 0.0012651961423916784, 0.0011516331437320382, 0.0010373233038879265, 0.000934506843940852, 0.0008517791532694224, 0.0007666807351749711, 0.0006932873365288442, 0.0006271602800403429, 0.0005690256351473105, 0.0005131488511255178, 0.00046399358045126057, 0.000417602015203731, 0.0003763251973672764, 0.0003429355141329482, 0.0003217861292601963, 0.0003028027914370761, 0.0002744441487214107, 0.0002629097971292871, 0.000243892100895555, 0.00023400560220628548, 0.00021104817484508337, 0.00018996118605705176, 0.00017525001011159836, 0.00015963381473950788, 0.00014943696262848875, 0.00013486270182997407, 0.00012478207730760223, 0.0001133143031943914, 0.00010448407060764707, 9.465704216170604e-05, 8.621827488454341e-05, 8.198285963603083e-05, 7.536526800910262e-05, 7.24796526459332e-05, 6.59954068732402e-05, 6.562286559823597e-05, 5.9061804511482236e-05, 5.411635100836475e-05, 5.09836559390843e-05, 4.907847217701642e-05, 4.423571342194446e-05, 4.01384030062423e-05, 3.706812696162174e-05, 3.808680189743587e-05, 3.517073243464625e-05, 4.015171786402747e-05, 3.7595659102220727e-05, 3.4760324371169884e-05, 3.5810854535755204e-05, 3.3437596467938814e-05, 3.0839186690746e-05, 2.7879661822985394e-05, 2.6729141524073108e-05, 2.4477849327611363e-05, 2.203259103256643e-05, 2.396422615186336e-05, 2.2284470065593314e-05, 2.0140740460419766e-05, 1.8506893453540253e-05, 1.8422789018039314e-05, 2.1241048663571167e-05, 1.9524949262901653e-05, 1.7888311680439754e-05, 1.6107067316438058e-05, 1.4548684356575241e-05, 1.3093827985544088e-05, 1.6005507785542723e-05, 1.7423359186915365e-05, 1.732492267443005e-05, 1.599157956005595e-05, 1.4472293683819274e-05, 1.6404334323050707e-05, 1.4771140157343186e-05, 1.5822568881675984e-05, 1.6018451696301166e-05, 1.5129757256761934e-05, 1.3702442738360317e-05, 1.2332201205340446e-05, 1.2028472968524718e-05, 1.0898093335407677e-05, 1.126030447504847e-05, 1.0449424460432417e-05, 1.0596527695649062e-05, 1.0320049217790838e-05, 1.1499342405580615e-05, 1.0877212185349751e-05, 1.0080191519973253e-05, 9.327572879911033e-06, 8.440958225865646e-06, 8.324268895996292e-06, 9.47640765343808e-06, 8.553976557371709e-06, 7.837934780327103e-06, 7.429924463843732e-06, 6.6963422051722054e-06, 6.146081810017736e-06, 6.298600288849434e-06, 6.503457987088288e-06, 7.720322273059304e-06, 7.3844509268483275e-06, 1.177823597793547e-05, 2.6588079143067368e-05, 2.739822751122813e-05, 2.5187965906343855e-05, 2.330031614124505e-05, 2.140491927857636e-05, 2.0929160330369172e-05, 1.896012073986316e-05, 1.932560355849458e-05, 2.107275156050229e-05, 1.9476534187348118e-05, 1.7529256384305365e-05, 1.593711242842229e-05, 1.4645276343264401e-05, 1.528298298716158e-05, 1.4149716449031396e-05, 1.380187281043067e-05, 1.3379024434600143e-05, 1.207094698315651e-05, 1.1603551118124153e-05, 1.0443403079159402e-05, 9.978840969444908e-06, 1.0769817136462113e-05, 1.0001000472514687e-05, 9.264648852889025e-06, 9.041907141154957e-06, 8.141866967894696e-06, 7.391783713248581e-06, 6.652859689158389e-06, 8.172257714892259e-06, 7.463862891902301e-06, 6.77202339352505e-06, 6.580238269426244e-06, 5.943858561460689e-06, 5.507630614586804e-06, 1.1897694221449215e-05, 1.1004328750016062e-05, 1.2735308299989493e-05, 1.1474448051849309e-05, 1.115574209969144e-05, 1.0058559035589651e-05, 9.40001866938587e-06, 9.98346011039352e-06, 9.603310277270639e-06, 1.0861674122238618e-05, 1.0263876360153968e-05, 9.678013135601611e-06, 9.490503887932499e-06, 8.683353967733342e-06, 7.980949058042247e-06, 7.2473637235723716e-06, 6.527301758260327e-06, 6.439903500897433e-06, 6.363565287480228e-06, 7.247161529247933e-06, 7.447515904413757e-06, 6.854829275090479e-06, 6.602151403912318e-06, 7.5737802734412315e-06, 7.2264850938351755e-06, 6.659929485728881e-06, 6.017538788356015e-06, 5.432994052922524e-06, 4.97576525776757e-06, 4.615626119072686e-06, 4.154445379597871e-06, 3.9735669971409395e-06, 3.627590036007199e-06, 3.5083067667692615e-06, 3.2758313250635068e-06, 8.004373589070124e-06, 7.780579483950256e-06, 7.040773512287907e-06, 6.880827110023491e-06, 6.827030127224313e-06, 6.1792036978145325e-06, 5.566257718122982e-06, 5.588455845201748e-06, 5.537446189450275e-06, 4.987690328902153e-06, 4.935954573699765e-06, 5.06056511114337e-06, 4.67878248958771e-06, 8.458750035044622e-06, 8.22356580231651e-06, 8.860357170866908e-06, 8.241924941052284e-06, 8.367720087169227e-06, 7.558407965046431e-06, 7.545942837058201e-06, 7.839072567233874e-06, 7.592449339079155e-06, 6.834222447103709e-06, 6.151967864545981e-06, 5.981380886593084e-06, 5.635255759071209e-06, 5.401099464024397e-06, 5.883544456399573e-06, 6.255873660082736e-06, 5.648716384644424e-06, 5.102345626621022e-06, 4.939125589633154e-06, 1.0066177081502726e-05, 1.02588102946342e-05, 9.497145821147414e-06, 8.698191294136299e-06, 8.189052358866341e-06, 2.0249964417101875e-05, 1.8535883118361457e-05, 1.6682349119022747e-05, 1.5541041083149204e-05, 1.5211508131983644e-05, 1.3801429996777787e-05, 1.2447025216280496e-05, 1.1247087031839019e-05, 1.044384943331574e-05, 9.485864514837333e-06, 8.880115964077933e-06, 8.356428895974621e-06, 7.551494106555464e-06, 6.935041640672582e-06, 6.248603943022391e-06, 6.314557173217071e-06, 5.760026606927035e-06, 5.421087550247625e-06, 4.920450739918084e-06, 4.69287177755869e-06, 4.687237330841192e-06, 4.538649689107796e-06, 4.478883203842627e-06, 4.05897975033118e-06, 3.830592619692419e-06, 3.540196021983286e-06, 3.5398769501788415e-06, 3.339844791979393e-06, 3.2841383748008134e-06, 3.1681771863314767e-06, 2.9349770750308195e-06, 2.7978534116042576e-06, 2.5742957052608494e-06, 2.3930875016966777e-06, 2.282222059349985e-06, 2.4241942819311873e-06, 2.4033470751633432e-06, 2.2004365837658304e-06, 2.349014265929465e-06, 3.2630306161595937e-06, 3.269524343874559e-06, 3.0669931308983783e-06], "duration": 240711.584413, "accuracy_train": [0.5179164431639904, 0.649702813538206, 0.7073106283453304, 0.7715647638658176, 0.7859298576504246, 0.7924638862933739, 0.8131076028400701, 0.8235442766011444, 0.8440230698020488, 0.859090034087763, 0.8788033306224622, 0.8825911602528608, 0.8941700408361019, 0.8973773042404946, 0.9038422993955334, 0.9071843853820598, 0.9147440029185124, 0.9139044259297711, 0.9167883314299556, 0.9243901260843485, 0.9230905661683279, 0.9319221662744556, 0.9313644910483574, 0.9386193158222591, 0.9415475613695091, 0.9406185833102622, 0.9366898027985419, 0.9463838708933187, 0.9447337362149317, 0.9432681714885567, 0.9465927737979882, 0.950755511143411, 0.9480358080126431, 0.9592877258098007, 0.9548463310954227, 0.9568695710478959, 0.9394552879291252, 0.9514995587624585, 0.9603333217977114, 0.9568237890480805, 0.9584274207502769, 0.9483834988695091, 0.9636361145717978, 0.9594272347383721, 0.9626355796073275, 0.9479181086194168, 0.9539398835478959, 0.9611474843692323, 0.9574508582502769, 0.9640081383813216, 0.9637985145002769, 0.963403960179033, 0.959171107881137, 0.9583587477505537, 0.9661011327980805, 0.9578464940360835, 0.9688211964170359, 0.9718656994047619, 0.9691921387619971, 0.9504528813099853, 0.9700306342861758, 0.9666816990240864, 0.9681694337739941, 0.9729817708333334, 0.9736567849644703, 0.9659376514050388, 0.966356178190753, 0.9744004720953304, 0.9636368355481728, 0.9584506722383721, 0.9698439014050388, 0.9716106540120893, 0.9685654300479882, 0.9704255490956073, 0.9663111171673128, 0.9637287600359912, 0.9726805829526578, 0.9785861004406607, 0.9798180688215209, 0.9735412485003692, 0.9826783623454227, 0.9797018113810447, 0.9843052455357143, 0.9750994586909376, 0.9726573314645626, 0.9799579382382798, 0.9783532250715209, 0.9822129720953304, 0.9729828522978959, 0.980957752226375, 0.9787721123454227, 0.9810282276670359, 0.9789112607858066, 0.9731685037144703, 0.983189895083518, 0.9810976216431341, 0.9845145089285714, 0.980957752226375, 0.9866540063215209, 0.9790511302025655, 0.9758889278216132, 0.9737973753576044, 0.9842827150239941, 0.9797722868217055, 0.9809108887619971, 0.9759594032622739, 0.986119582583518, 0.9827473958333334, 0.9896301967977114, 0.9849112261789406, 0.9844919784168512, 0.9886997767857143, 0.9859804341431341, 0.9855611863810447, 0.9817955267741787, 0.9871190360834257, 0.9854445684523809, 0.9833290435239018, 0.9902579869762828, 0.9869795271548542, 0.9834696339170359, 0.9863982399524732, 0.9889787946428571, 0.9921875, 0.9878401927025655, 0.9840505606312293, 0.9860269371193245, 0.9850031506667589, 0.9856778043097084, 0.9925366328096161, 0.9921642485119048, 0.9826783623454227, 0.9886307432978036, 0.9857933407738095, 0.9927687872023809, 0.98753756286914, 0.9925827752976191, 0.9922572544642857, 0.9910717890596161, 0.9895139393572352, 0.9886303828096161, 0.9854216774524732, 0.9892113095238095, 0.99242037536914, 0.9869341056432264, 0.9922576149524732, 0.99193209411914, 0.9942339914405685, 0.9873511904761905, 0.9913279159168512, 0.98802584411914, 0.9902579869762828, 0.9867706242501846, 0.9940250885358989, 0.990328101928756, 0.9910961220122739, 0.9879328381667589, 0.9900952265596161, 0.9909558921073275, 0.9928389021548542, 0.9871658995478036, 0.9853519229881875, 0.9916527157738095, 0.9821199661429494, 0.9755881004291252, 0.9937918526785714, 0.9906300107858066, 0.9910950405477114, 0.9865141369047619, 0.9927927596668512, 0.9900952265596161, 0.9840265881667589, 0.9949322570598007, 0.9915604307978036, 0.9893511789405685, 0.9907459077380952, 0.9913744188930418, 0.9945591517857143, 0.9923044784168512, 0.9938623281192323, 0.9940247280477114, 0.9905137533453304, 0.9881649925595238, 0.9907931316906607, 0.9882118560239018, 0.9949544270833334, 0.9927923991786637, 0.9928389021548542, 0.9940944825119971, 0.9917925851905685, 0.9924432663690477, 0.9916305457502769, 0.9966052827380952, 0.9910714285714286, 0.9928396231312293, 0.9898165691906607, 0.9923971238810447, 0.9932814014050388, 0.9833065130121816, 0.9930249140596161, 0.9970005580357143, 0.9923277299049464, 0.9950245420358066, 0.9927455357142857, 0.9903742444167589, 0.9962565104166666, 0.989932826631137, 0.9972566848929494, 0.9951175479881875, 0.9952334449404762, 0.9961867559523809, 0.9947923876430418, 0.9923044784168512, 0.9943731398809523, 0.993839076631137, 0.9961402529761905, 0.9963960193452381, 0.9900261930717055, 0.9969308035714286, 0.9927455357142857, 0.9917224702380952, 0.9979542295358066, 0.9962565104166666, 0.995652332214378, 0.9939549735834257, 0.9939785855597084, 0.99535006286914, 0.9932341774524732, 0.9942812153931341, 0.9959542410714286, 0.9937457101905685, 0.9960704985119048, 0.9934434408453304, 0.9869802481312293, 0.9962572313930418, 0.9933271834048542, 0.9963727678571429, 0.9968145461309523, 0.9950477935239018, 0.994722633178756, 0.9970470610119048, 0.9971400669642857, 0.9947916666666666, 0.9972098214285714, 0.9925831357858066, 0.9961170014880952, 0.9881893255121816, 0.9969773065476191, 0.9906063988095238, 0.9959546015596161, 0.9976515997023809, 0.9952799479166666, 0.9919088426310447, 0.9979073660714286, 0.9972799363810447, 0.9951873024524732, 0.9949776785714286, 0.9973028273809523, 0.9936290922619048, 0.9970481424764673, 0.9919557060954227, 0.9982564988810447, 0.9957685896548542, 0.9949079241071429, 0.9972795758928571, 0.9876094802625508, 0.9983723958333334, 0.9933736863810447, 0.9962100074404762, 0.9970470610119048, 0.9832825405477114, 0.9959077380952381, 0.9942103794642857, 0.9966521462024732, 0.9981631324404762, 0.9959542410714286, 0.9944196428571429, 0.995606189726375, 0.9968614095953304, 0.9961402529761905, 0.9972101819167589, 0.9974655877976191, 0.9950706845238095, 0.9968377976190477, 0.9960007440476191, 0.9929780505952381, 0.9963960193452381, 0.9971869304286637, 0.9950474330357143, 0.9973725818452381, 0.9935600587739941, 0.9974888392857143, 0.9936988467261905, 0.9950245420358066, 0.9969308035714286, 0.9946521577380952, 0.9935829497739018, 0.9966750372023809, 0.9972563244047619, 0.9972101819167589, 0.9967912946428571, 0.9946056547619048, 0.9965823917381875, 0.9967912946428571, 0.9947684151785714, 0.9938154646548542, 0.9972098214285714, 0.9964425223214286, 0.9938383556547619, 0.9992327008928571, 0.9940941220238095, 0.9970005580357143], "end": "2016-01-26 23:18:59.079000", "learning_rate_per_epoch": [0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736, 0.002107472624629736], "accuracy_valid": [0.5078536803463856, 0.6422486822289157, 0.6949742328689759, 0.7533679640436747, 0.7624011671686747, 0.7699915874435241, 0.7819030026355422, 0.7880271084337349, 0.8112616481551205, 0.8198992258094879, 0.8436529320406627, 0.8390436746987951, 0.8447103845067772, 0.8516683923192772, 0.8480165780308735, 0.8520243081701807, 0.8571718514683735, 0.8546289650790663, 0.8567144554781627, 0.8633783179593373, 0.8638768942959337, 0.870081890060241, 0.8650049416415663, 0.8705289909638554, 0.8718011695218373, 0.8711187523531627, 0.8635400978915663, 0.8774884695030121, 0.8747514471950302, 0.8687700018825302, 0.8688920721950302, 0.8693391730986446, 0.8729409826807228, 0.881068218185241, 0.8777017248682228, 0.8808858480798193, 0.8607030661709337, 0.873377788497741, 0.8835713949548193, 0.8782297157379518, 0.8780576407191265, 0.8705495811370482, 0.8851686041039157, 0.8765310264495482, 0.8831537085843373, 0.8736631094691265, 0.8808961431664157, 0.8782708960843373, 0.8745073065700302, 0.8841714514307228, 0.8852906744164157, 0.8781488257718373, 0.8783414909638554, 0.8796136695218373, 0.8844758918486446, 0.878504741622741, 0.8867849326995482, 0.8884850927146084, 0.8887189382530121, 0.8710893378200302, 0.8880365210843373, 0.8839170157191265, 0.8842729315700302, 0.889002788497741, 0.8922692724021084, 0.8822786262236446, 0.8820138954254518, 0.8905499929405121, 0.8843847067959337, 0.8743749411709337, 0.8838052404932228, 0.8872129141566265, 0.8827977927334337, 0.8839876105986446, 0.8859819159450302, 0.8820344855986446, 0.8874364646084337, 0.8950151190700302, 0.8945062476468373, 0.8887689429593373, 0.8982610128012049, 0.8941709219691265, 0.903052640248494, 0.8892278096762049, 0.8890439688441265, 0.8927060782191265, 0.8957078313253012, 0.8983316076807228, 0.8903558570218373, 0.8968667639307228, 0.8965623235128012, 0.8981183523155121, 0.8933267248682228, 0.8874467596950302, 0.8964299581137049, 0.8945577230798193, 0.8973138648343373, 0.8968064641378012, 0.9027467291039157, 0.8921472020896084, 0.8914853750941265, 0.8885042121611446, 0.8984845632530121, 0.8994508306664157, 0.8988507741905121, 0.8896852056664157, 0.9041306828878012, 0.8989625494164157, 0.9065823842243976, 0.8983419027673193, 0.9003156179405121, 0.9044248282191265, 0.8996743811182228, 0.8972535650414157, 0.8975697712725903, 0.9022790380271084, 0.8972123846950302, 0.8950357092432228, 0.9068574101091867, 0.9013730704066265, 0.9042218679405121, 0.907447171498494, 0.9034688558923193, 0.9083825536521084, 0.8993993552334337, 0.8978742116905121, 0.8967755788780121, 0.8965314382530121, 0.8997258565512049, 0.9062058782003012, 0.9037129965173193, 0.8999699971762049, 0.9019437123493976, 0.8963475974209337, 0.9064603139118976, 0.9019231221762049, 0.9098076877823795, 0.907691312123494, 0.9031541203878012, 0.9038968373493976, 0.9047204442771084, 0.9027173145707832, 0.9020451924887049, 0.9071927357868976, 0.9010186252823795, 0.9059617375753012, 0.9048425145896084, 0.9070191900414157, 0.8996846762048193, 0.9035306264118976, 0.8966020331325302, 0.9036526967243976, 0.8994611257530121, 0.9107636601091867, 0.9020348974021084, 0.9041100927146084, 0.8952695547816265, 0.9066441547439759, 0.9014142507530121, 0.9095532520707832, 0.8953916250941265, 0.9011701101280121, 0.9049336996423193, 0.8986684040850903, 0.8906720632530121, 0.9091355657003012, 0.9077324924698795, 0.903052640248494, 0.8975182958396084, 0.9076001270707832, 0.9035512165850903, 0.8950665945030121, 0.9105092243975903, 0.9016892766378012, 0.9050660650414157, 0.9062161732868976, 0.907203030873494, 0.9113431264118976, 0.9093297016189759, 0.9097562123493976, 0.910010648060994, 0.9057278920368976, 0.9040997976280121, 0.9004582784262049, 0.9044262989457832, 0.9090237904743976, 0.9075795368975903, 0.9110283909073795, 0.9060941029743976, 0.9068265248493976, 0.9091252706137049, 0.9001935476280121, 0.9140698536332832, 0.8989625494164157, 0.9058808476091867, 0.9015466161521084, 0.906714749623494, 0.9059514424887049, 0.8927781438253012, 0.9088914250753012, 0.9130418157003012, 0.9062161732868976, 0.9096856174698795, 0.9020143072289157, 0.9024922933923193, 0.9114960819841867, 0.9005803487387049, 0.9149037556475903, 0.9137139377823795, 0.9112519413591867, 0.9093076407191265, 0.9075383565512049, 0.9051175404743976, 0.9103459737387049, 0.9077119022966867, 0.9091767460466867, 0.9114857868975903, 0.8991155049887049, 0.9110283909073795, 0.9086472844503012, 0.9069383000753012, 0.9124726444841867, 0.9162465290850903, 0.9102650837725903, 0.9052190206137049, 0.9072942159262049, 0.9108445500753012, 0.909766507435994, 0.9053205007530121, 0.909888577748494, 0.9074059911521084, 0.9089429005082832, 0.9066015036709337, 0.8995934911521084, 0.910254788685994, 0.9053513860128012, 0.9156464726091867, 0.9100709478539157, 0.9096135518637049, 0.9054837514118976, 0.9150361210466867, 0.9125844197100903, 0.9041703925075302, 0.915503812123494, 0.9058911426957832, 0.9115872670368976, 0.9013642460466867, 0.9140904438064759, 0.9062470585466867, 0.9136021625564759, 0.9151273060993976, 0.9087796498493976, 0.9054631612387049, 0.9136830525225903, 0.9148728703878012, 0.9074677616716867, 0.9064191335655121, 0.9088002400225903, 0.9096650272966867, 0.915137601185994, 0.9046498493975903, 0.9188511859939759, 0.908789944935994, 0.9049645849021084, 0.915747952748494, 0.8963990728539157, 0.9152493764118976, 0.907935452748494, 0.9091458607868976, 0.9093797063253012, 0.8912824148155121, 0.912207913685994, 0.904273343373494, 0.9124623493975903, 0.9166436252823795, 0.9099591726280121, 0.9058190770896084, 0.9082810735128012, 0.9121770284262049, 0.9088914250753012, 0.9154332172439759, 0.914649319935994, 0.9120049534073795, 0.911841702748494, 0.908912015248494, 0.9086781697100903, 0.9113740116716867, 0.9173554569841867, 0.9067044545368976, 0.9137742375753012, 0.903540921498494, 0.9130932911332832, 0.9068574101091867, 0.9096135518637049, 0.909888577748494, 0.9063382435993976, 0.9091767460466867, 0.9140698536332832, 0.9086266942771084, 0.9118931781814759, 0.9108754353350903, 0.9056572971573795, 0.9126256000564759, 0.908179593373494, 0.9073045110128012, 0.9073045110128012, 0.9149140507341867, 0.9116284473832832, 0.908057523060994, 0.9168568806475903, 0.9034791509789157, 0.913672757435994], "accuracy_test": 0.2187938456632653, "start": "2016-01-24 04:27:07.494000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0, 302.0, 303.0, 304.0, 305.0, 306.0, 307.0, 308.0, 309.0, 310.0, 311.0], "accuracy_train_last": 0.9970005580357143, "batch_size_eval": 1024, "accuracy_train_std": [0.01556252649844321, 0.01587407742823765, 0.013590138465132077, 0.012713111401658357, 0.014603141125086741, 0.015568088769364958, 0.015006888300704959, 0.015299091187407816, 0.016051882987463233, 0.014695963456475183, 0.014915889064602738, 0.014968770342140208, 0.014085088667250584, 0.016152748560019147, 0.015219426142550466, 0.018620881979813368, 0.015023721745299241, 0.01585074871442373, 0.01569952153659371, 0.014144689553080477, 0.014629484718593934, 0.014801620278422049, 0.014859323898656754, 0.013757702652438778, 0.01463360989453626, 0.013823503116405943, 0.01330468478200072, 0.013722094744846947, 0.01365806330227832, 0.013714228035199031, 0.013627601414891577, 0.012637448674026622, 0.01254264993834291, 0.01063415725408068, 0.013328966097887565, 0.012653557342623214, 0.013173954441573063, 0.013090126897264407, 0.011816293341772133, 0.011553253281497039, 0.011766791619027104, 0.012562073796456573, 0.010730819150626045, 0.01138829243297277, 0.011054958581395687, 0.012926579282895711, 0.01335060530991737, 0.01138388318731683, 0.012536733189619903, 0.009798963962437474, 0.010996712180437011, 0.01063463082438581, 0.011709854776102003, 0.010950853462572113, 0.010776385642182884, 0.012876630263471134, 0.008676943486753004, 0.009296874255654614, 0.009248934908825862, 0.012616766462473375, 0.008582790877553065, 0.0104909041825029, 0.009947494236484975, 0.008749359176594253, 0.008688247142907767, 0.011012615782463655, 0.008777498394885497, 0.00846240919037642, 0.009995802673399407, 0.009965639860913932, 0.009803592234595536, 0.008134776329818615, 0.00868181339304373, 0.0077999039642390345, 0.008720280409092984, 0.009525557854667403, 0.006933270512539564, 0.0068854144960701896, 0.007016107923243443, 0.0065231771400889454, 0.0057280276819001155, 0.0071725272625760665, 0.0057434940894981225, 0.007963496405239166, 0.008379122805073386, 0.006116294029426934, 0.0068200730210788135, 0.005939384356027798, 0.007213087559571342, 0.005669235956457901, 0.00652531548892746, 0.0049925061468134285, 0.005972081653888159, 0.00794783299026568, 0.00509645134588112, 0.005991366407559331, 0.00539775170819004, 0.006112506731193552, 0.00448959705565132, 0.006090225520852776, 0.008165309890667176, 0.0069715258537613985, 0.006020633456898239, 0.0060985234628040605, 0.005964895560794798, 0.006371702453508485, 0.005219306237920349, 0.006784814505648188, 0.0036107423444709527, 0.004307991853248532, 0.006006988768901502, 0.004465738695842261, 0.004708626691625273, 0.0051133009832534555, 0.005125495062193649, 0.004567635351959043, 0.004443650769495381, 0.005095028600162979, 0.0032571507023259837, 0.004345650845854306, 0.004988388221063272, 0.005261444668570772, 0.004139287353324714, 0.003402988537290867, 0.00407392712387108, 0.005738571873316144, 0.00464387308568658, 0.005220070683538578, 0.004873493177429643, 0.003266181041843476, 0.002902340864984085, 0.0060668484933269155, 0.004500766616612995, 0.004669845910537375, 0.0037945545232555286, 0.004439392036331072, 0.0031178676324211973, 0.0031851144131782574, 0.004146941339945482, 0.003636490345519349, 0.004031942661105466, 0.004238526709142754, 0.004098862118567766, 0.0026522512645649064, 0.004621386873580668, 0.003113679929893815, 0.0032748435310515586, 0.0024840050332096786, 0.004882591052234631, 0.0035808614711537088, 0.004630863770478902, 0.004052394689744839, 0.004857163383234051, 0.003169934203776297, 0.0036352286418108153, 0.003023318239375314, 0.004868758241703548, 0.004036033362315015, 0.003496605199482274, 0.0031947710137188927, 0.003751197486366538, 0.005268447555927711, 0.003502958415982146, 0.004991994868238234, 0.005667162622282933, 0.003173892002071746, 0.0036921504487353544, 0.0032058634721777355, 0.004879268129693541, 0.0030664513159345836, 0.004091906148554725, 0.005172069056971691, 0.0024316350117640343, 0.0033692306807062227, 0.0039978773039759325, 0.004022171422278406, 0.003508558531674388, 0.0030670819285418807, 0.0032967255001155435, 0.002604373524976579, 0.002954894961829492, 0.0034256360175048367, 0.003993641914552068, 0.0028376513648886285, 0.004307373541521852, 0.002626594964280429, 0.003043993462871894, 0.002919979196966307, 0.0023248327041690844, 0.003204773019833344, 0.0033155187118319956, 0.0029702022079828943, 0.0021335695213828983, 0.0036699069302360224, 0.002800747475812963, 0.0037115656162964856, 0.0034270946185415126, 0.0030230985875132617, 0.005039914249467607, 0.0027756772540390626, 0.0018131688722918438, 0.003519056144317849, 0.0023716564431798355, 0.003007272361276924, 0.003313010081809779, 0.0020207402653113463, 0.00344070753045074, 0.0014955360249458906, 0.002512873509918573, 0.002603024602091326, 0.0019274908645891655, 0.0023893110022772494, 0.0030086336625903135, 0.003145059229708132, 0.002472001169848607, 0.0022848062679572635, 0.002125572653559398, 0.003340580533452795, 0.0019364455741868504, 0.00292303666849288, 0.0034575205162650866, 0.0013445983725178536, 0.0019521559475960159, 0.0024598496036990795, 0.0026896924272532823, 0.0028983968834342564, 0.00240015807389931, 0.0027329578400915214, 0.0022508990390390604, 0.0020833125729726675, 0.0031473572168060496, 0.0021887296502025124, 0.0022588852863292762, 0.003946781029236017, 0.001963698685051849, 0.002890610227339173, 0.001909455465741054, 0.0019421604880730645, 0.002489213776711128, 0.002236099168490465, 0.0018637485516510182, 0.001614430369869787, 0.0028643719483695115, 0.0016169399786750101, 0.0029616497213058287, 0.0022298407414924636, 0.003794761296129562, 0.001780523597384361, 0.003369139822671123, 0.002553729107262505, 0.0014773388803594747, 0.0022943693795217193, 0.0031992726094179484, 0.0016721683962393232, 0.0015882712006201902, 0.0026224569746360086, 0.0024995079334778065, 0.0015039956872020302, 0.0027310355022369835, 0.001696157535711886, 0.0031747502302705163, 0.0013897954933406896, 0.002211587949949375, 0.001993806630574282, 0.001514919654879271, 0.0035297524128198284, 0.0014557734228514256, 0.002535930817605549, 0.0019785636532277536, 0.0017764197772427508, 0.00516500811807918, 0.0024782203486745217, 0.0022990772317676936, 0.0018103146820963808, 0.0013342789002421477, 0.0020941834540918348, 0.0023565586791889745, 0.002112476934661345, 0.0015740057471173073, 0.0017041929131146481, 0.0014544964864041873, 0.0017188810991700355, 0.0024847563257798634, 0.0013613542753259345, 0.0021816785910974516, 0.0033235804287956913, 0.0024987507854181846, 0.0018966940393000098, 0.0025160001111706803, 0.0014991350743875436, 0.0025495974069100155, 0.0016526558448583392, 0.0030969899847473584, 0.002313498629426946, 0.0021791991283221695, 0.002680685833581164, 0.0026463792635565433, 0.0020223448766801093, 0.0016539638433573976, 0.001815571441392058, 0.001735003544101342, 0.0020687292056859397, 0.0023564397635252436, 0.0020136379366267644, 0.002192185021670757, 0.0029508010239541384, 0.0019364455741868504, 0.002086035604292865, 0.00251685947422577, 0.0010116401561480232, 0.0023916277661130566, 0.0018131688722918438], "accuracy_test_std": 0.008736967585012887, "error_valid": [0.49214631965361444, 0.35775131777108427, 0.30502576713102414, 0.24663203595632532, 0.23759883283132532, 0.23000841255647586, 0.21809699736445776, 0.2119728915662651, 0.18873835184487953, 0.18010077419051207, 0.15634706795933728, 0.16095632530120485, 0.15528961549322284, 0.14833160768072284, 0.1519834219691265, 0.1479756918298193, 0.1428281485316265, 0.14537103492093373, 0.14328554452183728, 0.13662168204066272, 0.13612310570406627, 0.12991810993975905, 0.13499505835843373, 0.1294710090361446, 0.12819883047816272, 0.12888124764683728, 0.13645990210843373, 0.12251153049698793, 0.12524855280496983, 0.13122999811746983, 0.13110792780496983, 0.1306608269013554, 0.12705901731927716, 0.11893178181475905, 0.12229827513177716, 0.11911415192018071, 0.13929693382906627, 0.12662221150225905, 0.11642860504518071, 0.12177028426204817, 0.12194235928087349, 0.12945041886295183, 0.11483139589608427, 0.12346897355045183, 0.11684629141566272, 0.1263368905308735, 0.11910385683358427, 0.12172910391566272, 0.12549269342996983, 0.11582854856927716, 0.11470932558358427, 0.12185117422816272, 0.12165850903614461, 0.12038633047816272, 0.11552410815135539, 0.12149525837725905, 0.11321506730045183, 0.1115149072853916, 0.11128106174698793, 0.12891066217996983, 0.11196347891566272, 0.11608298428087349, 0.11572706842996983, 0.11099721150225905, 0.1077307275978916, 0.11772137377635539, 0.11798610457454817, 0.10945000705948793, 0.11561529320406627, 0.12562505882906627, 0.11619475950677716, 0.11278708584337349, 0.11720220726656627, 0.11601238940135539, 0.11401808405496983, 0.11796551440135539, 0.11256353539156627, 0.10498488092996983, 0.10549375235316272, 0.11123105704066272, 0.10173898719879515, 0.10582907803087349, 0.09694735975150603, 0.11077219032379515, 0.11095603115587349, 0.10729392178087349, 0.10429216867469882, 0.10166839231927716, 0.10964414297816272, 0.10313323606927716, 0.10343767648719882, 0.10188164768448793, 0.10667327513177716, 0.11255324030496983, 0.10357004188629515, 0.10544227692018071, 0.10268613516566272, 0.10319353586219882, 0.09725327089608427, 0.1078527979103916, 0.10851462490587349, 0.11149578783885539, 0.10151543674698793, 0.10054916933358427, 0.10114922580948793, 0.11031479433358427, 0.09586931711219882, 0.10103745058358427, 0.09341761577560237, 0.10165809723268071, 0.09968438205948793, 0.09557517178087349, 0.10032561888177716, 0.10274643495858427, 0.1024302287274097, 0.0977209619728916, 0.10278761530496983, 0.10496429075677716, 0.09314258989081325, 0.09862692959337349, 0.09577813205948793, 0.09255282850150603, 0.09653114410768071, 0.0916174463478916, 0.10060064476656627, 0.10212578830948793, 0.10322442112198793, 0.10346856174698793, 0.10027414344879515, 0.09379412179969882, 0.09628700348268071, 0.10003000282379515, 0.09805628765060237, 0.10365240257906627, 0.09353968608810237, 0.09807687782379515, 0.09019231221762047, 0.09230868787650603, 0.09684587961219882, 0.09610316265060237, 0.0952795557228916, 0.09728268542921681, 0.09795480751129515, 0.09280726421310237, 0.09898137471762047, 0.09403826242469882, 0.0951574854103916, 0.09298080995858427, 0.10031532379518071, 0.09646937358810237, 0.10339796686746983, 0.09634730327560237, 0.10053887424698793, 0.08923633989081325, 0.0979651025978916, 0.0958899072853916, 0.10473044521837349, 0.09335584525602414, 0.09858574924698793, 0.09044674792921681, 0.10460837490587349, 0.09882988987198793, 0.09506630035768071, 0.1013315959149097, 0.10932793674698793, 0.09086443429969882, 0.09226750753012047, 0.09694735975150603, 0.1024817041603916, 0.09239987292921681, 0.0964487834149097, 0.10493340549698793, 0.0894907756024097, 0.09831072336219882, 0.09493393495858427, 0.09378382671310237, 0.09279696912650603, 0.08865687358810237, 0.09067029838102414, 0.09024378765060237, 0.08998935193900603, 0.09427210796310237, 0.09590020237198793, 0.09954172157379515, 0.09557370105421681, 0.09097620952560237, 0.0924204631024097, 0.08897160909262047, 0.09390589702560237, 0.09317347515060237, 0.09087472938629515, 0.09980645237198793, 0.08593014636671681, 0.10103745058358427, 0.09411915239081325, 0.0984533838478916, 0.09328525037650603, 0.09404855751129515, 0.10722185617469882, 0.09110857492469882, 0.08695818429969882, 0.09378382671310237, 0.09031438253012047, 0.09798569277108427, 0.09750770660768071, 0.08850391801581325, 0.09941965126129515, 0.0850962443524097, 0.08628606221762047, 0.08874805864081325, 0.09069235928087349, 0.09246164344879515, 0.09488245952560237, 0.08965402626129515, 0.09228809770331325, 0.09082325395331325, 0.0885142131024097, 0.10088449501129515, 0.08897160909262047, 0.09135271554969882, 0.09306169992469882, 0.08752735551581325, 0.0837534709149097, 0.0897349162274097, 0.09478097938629515, 0.09270578407379515, 0.08915544992469882, 0.09023349256400603, 0.09467949924698793, 0.09011142225150603, 0.0925940088478916, 0.09105709949171681, 0.09339849632906627, 0.1004065088478916, 0.08974521131400603, 0.09464861398719882, 0.08435352739081325, 0.08992905214608427, 0.09038644813629515, 0.09451624858810237, 0.08496387895331325, 0.0874155802899097, 0.09582960749246983, 0.08449618787650603, 0.09410885730421681, 0.08841273296310237, 0.09863575395331325, 0.08590955619352414, 0.09375294145331325, 0.08639783744352414, 0.08487269390060237, 0.09122035015060237, 0.09453683876129515, 0.0863169474774097, 0.08512712961219882, 0.09253223832831325, 0.09358086643448793, 0.0911997599774097, 0.09033497270331325, 0.08486239881400603, 0.0953501506024097, 0.08114881400602414, 0.09121005506400603, 0.0950354150978916, 0.08425204725150603, 0.10360092714608427, 0.08475062358810237, 0.09206454725150603, 0.09085413921310237, 0.09062029367469882, 0.10871758518448793, 0.08779208631400603, 0.09572665662650603, 0.0875376506024097, 0.08335637471762047, 0.09004082737198793, 0.0941809229103916, 0.09171892648719882, 0.08782297157379515, 0.09110857492469882, 0.08456678275602414, 0.08535068006400603, 0.08799504659262047, 0.08815829725150603, 0.09108798475150603, 0.0913218302899097, 0.08862598832831325, 0.08264454301581325, 0.09329554546310237, 0.08622576242469882, 0.09645907850150603, 0.08690670886671681, 0.09314258989081325, 0.09038644813629515, 0.09011142225150603, 0.09366175640060237, 0.09082325395331325, 0.08593014636671681, 0.0913733057228916, 0.08810682181852414, 0.0891245646649097, 0.09434270284262047, 0.08737439994352414, 0.09182040662650603, 0.09269548898719882, 0.09269548898719882, 0.08508594926581325, 0.08837155261671681, 0.09194247693900603, 0.0831431193524097, 0.09652084902108427, 0.08632724256400603], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.6614440199912526, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.002107472675375292, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 2.1982401653129986e-08, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.05307598911023914}, "accuracy_valid_max": 0.9188511859939759, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.913672757435994, "loss_train": [1.550371766090393, 1.1181845664978027, 0.8983688354492188, 0.7723286151885986, 0.6833435893058777, 0.6163445711135864, 0.5690973401069641, 0.5248869061470032, 0.4889730215072632, 0.4564340114593506, 0.42982324957847595, 0.40270373225212097, 0.38406944274902344, 0.36284270882606506, 0.3435482978820801, 0.3241191804409027, 0.3103320598602295, 0.2968404293060303, 0.28022491931915283, 0.2716536223888397, 0.2563363313674927, 0.24921351671218872, 0.23830510675907135, 0.22759109735488892, 0.21969009935855865, 0.21061329543590546, 0.1976706087589264, 0.19572864472866058, 0.18799449503421783, 0.1802241951227188, 0.1734488159418106, 0.1666821539402008, 0.16294459998607635, 0.15789753198623657, 0.1514468491077423, 0.14771144092082977, 0.1414300948381424, 0.13940265774726868, 0.12970386445522308, 0.13019520044326782, 0.12498648464679718, 0.12249445170164108, 0.11819444596767426, 0.11924479901790619, 0.10927543044090271, 0.10891016572713852, 0.10534918308258057, 0.1020645946264267, 0.10346066951751709, 0.09891760349273682, 0.09572141617536545, 0.09048856794834137, 0.0922631174325943, 0.09961454570293427, 0.08184455335140228, 0.08542924374341965, 0.08396641165018082, 0.08143644034862518, 0.07618261873722076, 0.07754357159137726, 0.07837914675474167, 0.07491780817508698, 0.07210803031921387, 0.0727805346250534, 0.07357070595026016, 0.07126878947019577, 0.06811367720365524, 0.06937625259160995, 0.06210663169622421, 0.06469707936048508, 0.06692805141210556, 0.062014129012823105, 0.06343994289636612, 0.06057555601000786, 0.05693325027823448, 0.061143070459365845, 0.05755418539047241, 0.057245973497629166, 0.05283452197909355, 0.05687975883483887, 0.0563834048807621, 0.05535522848367691, 0.05385400727391243, 0.05221392586827278, 0.05189097672700882, 0.04832535237073898, 0.049167100340127945, 0.05030941963195801, 0.05339442193508148, 0.046683598309755325, 0.05115846171975136, 0.04532661288976669, 0.04519019275903702, 0.04575151577591896, 0.044534701853990555, 0.04704049229621887, 0.05186590179800987, 0.044042494148015976, 0.0425453744828701, 0.04205353930592537, 0.04344043508172035, 0.045001234859228134, 0.042746443301439285, 0.04206418991088867, 0.039320796728134155, 0.045067619532346725, 0.039660416543483734, 0.04274459555745125, 0.041750770062208176, 0.040582917630672455, 0.03926093876361847, 0.03769667446613312, 0.041729312390089035, 0.036430202424526215, 0.03792908415198326, 0.039277490228414536, 0.03693853318691254, 0.04004792496562004, 0.03860136494040489, 0.03556179627776146, 0.03762705996632576, 0.03598910570144653, 0.03664403408765793, 0.037878140807151794, 0.02992923930287361, 0.03751053661108017, 0.035941511392593384, 0.03350508585572243, 0.034889742732048035, 0.042395610362291336, 0.0369570218026638, 0.03193272277712822, 0.03201010078191757, 0.03409041464328766, 0.03389546275138855, 0.03205833211541176, 0.05317506566643715, 0.02058408409357071, 0.0299199391156435, 0.0333147868514061, 0.030533675104379654, 0.030387628823518753, 0.04056370630860329, 0.023872647434473038, 0.03610736131668091, 0.02930157259106636, 0.03325121849775314, 0.02585742063820362, 0.03304703161120415, 0.029958011582493782, 0.0337570421397686, 0.02889232710003853, 0.02540152333676815, 0.0361601747572422, 0.02680189721286297, 0.030910979956388474, 0.03108137659728527, 0.029295796528458595, 0.028419254347682, 0.02755117416381836, 0.027805807068943977, 0.027774635702371597, 0.03046988882124424, 0.030421653762459755, 0.026460541412234306, 0.02589942328631878, 0.02992994897067547, 0.026009369641542435, 0.032927848398685455, 0.025981493294239044, 0.025971027091145515, 0.02654292806982994, 0.030063675716519356, 0.02361096441745758, 0.029349712654948235, 0.02542909048497677, 0.03003956563770771, 0.023487510159611702, 0.025870459154248238, 0.034217964857816696, 0.022833019495010376, 0.023443350568413734, 0.029724908992648125, 0.02125370129942894, 0.030579427257180214, 0.024701599031686783, 0.024098573252558708, 0.02750830352306366, 0.02268666960299015, 0.02758127450942993, 0.025554433465003967, 0.024453813210129738, 0.027727821841835976, 0.022071318700909615, 0.028275804594159126, 0.023892289027571678, 0.02353816293179989, 0.023904120549559593, 0.026150131598114967, 0.02459505759179592, 0.02429748699069023, 0.0219765305519104, 0.02842172048985958, 0.023162512108683586, 0.02403794415295124, 0.024310247972607613, 0.024648014456033707, 0.02212631143629551, 0.025347383692860603, 0.022491110488772392, 0.0228272657841444, 0.022554069757461548, 0.023245468735694885, 0.02380642667412758, 0.023033007979393005, 0.023309044539928436, 0.02507210336625576, 0.023513182997703552, 0.02437082678079605, 0.018179668113589287, 0.030672773718833923, 0.017174072563648224, 0.02764935977756977, 0.022752603515982628, 0.022067565470933914, 0.026287393644452095, 0.01716630347073078, 0.024798469617962837, 0.02167089283466339, 0.02123538963496685, 0.021692821756005287, 0.025403348729014397, 0.02298746258020401, 0.019699398428201675, 0.02613186649978161, 0.017779482528567314, 0.025133706629276276, 0.020059876143932343, 0.0212778989225626, 0.024639949202537537, 0.021263819187879562, 0.01946638524532318, 0.025614872574806213, 0.01937454752624035, 0.020270586013793945, 0.022472653537988663, 0.022405169904232025, 0.022324176505208015, 0.021352406591176987, 0.020445257425308228, 0.02387395314872265, 0.017944596707820892, 0.025982292369008064, 0.01814093627035618, 0.020094532519578934, 0.025614703074097633, 0.020922314375638962, 0.01930656097829342, 0.01969265565276146, 0.024686351418495178, 0.02190842665731907, 0.02188302017748356, 0.016393164172768593, 0.025907164439558983, 0.01794716715812683, 0.024957291781902313, 0.018278909847140312, 0.016447076573967934, 0.02897701971232891, 0.01679668202996254, 0.018605221062898636, 0.02321726642549038, 0.021153127774596214, 0.023391608148813248, 0.018536526709794998, 0.01919460855424404, 0.01951046846807003, 0.019887076690793037, 0.024294413626194, 0.018920207396149635, 0.02164270728826523, 0.017206238582730293, 0.020450273528695107, 0.023583820089697838, 0.01858174428343773, 0.0199604369699955, 0.022209301590919495, 0.01924600638449192, 0.018112344667315483, 0.023333750665187836, 0.01762322336435318, 0.021351823583245277, 0.020751772448420525, 0.019855892285704613, 0.018889255821704865, 0.018250057473778725, 0.022234616801142693, 0.02057519741356373, 0.019571971148252487, 0.02034817449748516, 0.018040984869003296, 0.021625066176056862, 0.01801486127078533, 0.017072029411792755, 0.023025235161185265, 0.019654763862490654, 0.02157638594508171, 0.01593191735446453, 0.02474202588200569, 0.01738934963941574, 0.01654580421745777, 0.02469167485833168], "accuracy_train_first": 0.5179164431639904, "model": "residualv3", "loss_std": [0.28552231192588806, 0.15354618430137634, 0.13096840679645538, 0.12346441298723221, 0.11698687076568604, 0.1105949804186821, 0.11065222322940826, 0.10588354617357254, 0.1022309809923172, 0.10029835999011993, 0.09794554114341736, 0.09517746418714523, 0.09317339211702347, 0.09130855649709702, 0.0880587100982666, 0.08678542077541351, 0.08264541625976562, 0.08060288429260254, 0.07892801612615585, 0.07851150631904602, 0.0755949318408966, 0.07337211817502975, 0.07176115363836288, 0.06980752944946289, 0.06779967993497849, 0.06482478231191635, 0.06395754218101501, 0.06164396554231644, 0.06394156813621521, 0.058560073375701904, 0.05841971933841705, 0.05580044165253639, 0.05700669810175896, 0.055386658757925034, 0.053935933858156204, 0.053241051733493805, 0.04996837303042412, 0.049078211188316345, 0.04651568830013275, 0.048097752034664154, 0.0475609116256237, 0.04711364582180977, 0.04605884104967117, 0.04549287259578705, 0.04368843138217926, 0.044049568474292755, 0.041883111000061035, 0.04075802117586136, 0.04245913028717041, 0.03937425836920738, 0.03837590664625168, 0.03640121594071388, 0.037499092519283295, 0.05176149308681488, 0.0335904061794281, 0.036492954939603806, 0.03619767725467682, 0.03559071570634842, 0.03368530794978142, 0.03399341180920601, 0.03546265512704849, 0.03366491571068764, 0.03168630227446556, 0.03474833816289902, 0.03482552617788315, 0.032164715230464935, 0.032461389899253845, 0.03226723521947861, 0.029033835977315903, 0.0307262372225523, 0.03211183473467827, 0.029301773756742477, 0.02790779061615467, 0.029001686722040176, 0.02843736857175827, 0.03004724718630314, 0.02808770351111889, 0.026342572644352913, 0.02723403461277485, 0.030786115676164627, 0.02720305696129799, 0.027615154162049294, 0.027304181829094887, 0.027443699538707733, 0.026603080332279205, 0.02565227635204792, 0.02630934864282608, 0.026125242933630943, 0.028538323938846588, 0.025240426883101463, 0.026640869677066803, 0.022269919514656067, 0.02529229037463665, 0.024972056970000267, 0.02355555072426796, 0.024620914831757545, 0.02872793935239315, 0.023143205791711807, 0.02310587465763092, 0.02569076046347618, 0.02420561946928501, 0.0244201198220253, 0.024132443591952324, 0.024339497089385986, 0.023438232019543648, 0.026339413598179817, 0.02237599343061447, 0.02391895465552807, 0.024769321084022522, 0.02413656935095787, 0.022471880540251732, 0.021706081926822662, 0.024754120036959648, 0.020517976954579353, 0.02184928022325039, 0.0233941487967968, 0.019980426877737045, 0.023175925016403198, 0.023422569036483765, 0.021222874522209167, 0.02255178615450859, 0.02352760173380375, 0.022290602326393127, 0.022565800696611404, 0.01832161284983158, 0.02392476238310337, 0.021200427785515785, 0.01928217150270939, 0.02193925343453884, 0.03780760616064072, 0.029477087780833244, 0.020540498197078705, 0.01946881227195263, 0.021015523001551628, 0.020173849537968636, 0.02299790270626545, 0.06557917594909668, 0.011487586423754692, 0.01726372167468071, 0.019287558272480965, 0.01749734953045845, 0.017839133739471436, 0.025786586105823517, 0.015004180371761322, 0.02406289055943489, 0.018634460866451263, 0.020762762054800987, 0.016142042353749275, 0.02160770632326603, 0.019046228379011154, 0.024689005687832832, 0.01926933042705059, 0.016147930175065994, 0.024974975734949112, 0.016112715005874634, 0.019015297293663025, 0.020360810682177544, 0.01883026398718357, 0.017343731597065926, 0.017270265147089958, 0.017321396619081497, 0.019167577847838402, 0.023935265839099884, 0.025561830028891563, 0.018916821107268333, 0.016192618757486343, 0.019465003162622452, 0.01648801937699318, 0.023139819502830505, 0.016052132472395897, 0.015875302255153656, 0.016635630279779434, 0.01975543238222599, 0.013859905302524567, 0.01989389769732952, 0.015970556065440178, 0.019612960517406464, 0.01445983350276947, 0.018270013853907585, 0.028021542355418205, 0.01412457600235939, 0.015073359943926334, 0.02175988256931305, 0.01362704113125801, 0.020789282396435738, 0.015689145773649216, 0.016072489321231842, 0.017836138606071472, 0.014222195371985435, 0.02114350162446499, 0.015753351151943207, 0.01605272851884365, 0.019214443862438202, 0.013963734731078148, 0.019130004569888115, 0.015730390325188637, 0.014443318359553814, 0.016269266605377197, 0.018633462488651276, 0.015261850319802761, 0.016959883272647858, 0.015618490986526012, 0.01911907270550728, 0.017189884558320045, 0.014538551680743694, 0.01537169050425291, 0.017188657075166702, 0.014220722950994968, 0.01749700866639614, 0.014810140244662762, 0.014971209689974785, 0.014863220043480396, 0.015150939114391804, 0.016397317871451378, 0.015804726630449295, 0.016243141144514084, 0.01731719635426998, 0.01639772392809391, 0.016381926834583282, 0.011810186319053173, 0.021529855206608772, 0.0102965934202075, 0.022236090153455734, 0.014232462272047997, 0.014279939234256744, 0.01933998614549637, 0.009502104483544827, 0.017346154898405075, 0.014697963371872902, 0.013808397576212883, 0.015069489367306232, 0.01886589266359806, 0.01518645416945219, 0.012821114622056484, 0.019657431170344353, 0.00995156355202198, 0.01626003347337246, 0.012729397043585777, 0.013821766711771488, 0.016703663393855095, 0.012562066316604614, 0.011257225647568703, 0.017803071066737175, 0.01227201521396637, 0.014049841091036797, 0.015728618949651718, 0.017521806061267853, 0.015119588933885098, 0.013989899307489395, 0.014049897901713848, 0.016326075419783592, 0.011636339128017426, 0.01908736303448677, 0.010865728370845318, 0.012760380282998085, 0.018890371546149254, 0.014196287840604782, 0.012329937890172005, 0.013235717080533504, 0.016248784959316254, 0.019509563222527504, 0.01573554240167141, 0.010183875449001789, 0.017624692991375923, 0.011168529279530048, 0.020598500967025757, 0.011876702308654785, 0.009783074259757996, 0.02335069701075554, 0.009393018670380116, 0.012586967088282108, 0.016123654320836067, 0.013811690732836723, 0.01645260863006115, 0.01125594973564148, 0.011970972642302513, 0.012467024847865105, 0.013411893509328365, 0.017266297712922096, 0.01210837159305811, 0.01362411305308342, 0.00950202438980341, 0.012746703810989857, 0.015968266874551773, 0.01134161464869976, 0.013152560219168663, 0.020170439034700394, 0.012135150842368603, 0.01142676267772913, 0.015833890065550804, 0.011157859116792679, 0.01513341162353754, 0.016167771071195602, 0.01348222978413105, 0.011797214858233929, 0.010957049205899239, 0.015618233941495419, 0.014527705498039722, 0.012484997510910034, 0.01385449431836605, 0.012359809130430222, 0.014686153270304203, 0.009952106513082981, 0.00958387739956379, 0.016355305910110474, 0.012956301681697369, 0.015042079612612724, 0.008887295611202717, 0.01940508931875229, 0.010239959694445133, 0.010313495062291622, 0.01667911931872368]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:16 2016", "state": "available"}], "summary": "e63a2d824e7e056a04916782ead29791"}