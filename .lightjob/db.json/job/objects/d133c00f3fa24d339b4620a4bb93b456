{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 16, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.622940182685852, 1.2677674293518066, 1.1168978214263916, 1.0056331157684326, 0.9220218062400818, 0.8608200550079346, 0.8127373456954956, 0.7702853083610535, 0.7434465885162354, 0.7149707674980164, 0.6904142498970032, 0.6658999919891357, 0.648865818977356, 0.6317692399024963, 0.6197879910469055, 0.6038591265678406, 0.5918484926223755, 0.5803295373916626, 0.5713973641395569, 0.5602678060531616, 0.5525899529457092, 0.5439180731773376, 0.5361058712005615, 0.5331533551216125, 0.5238081812858582, 0.5194427967071533, 0.5103346705436707, 0.5097199082374573, 0.5033612847328186, 0.4987364113330841, 0.4924536943435669, 0.49120214581489563, 0.48869478702545166, 0.48617178201675415, 0.4811115562915802, 0.47935160994529724, 0.47514358162879944, 0.47400736808776855, 0.4692121148109436, 0.46857208013534546, 0.46667975187301636, 0.46530628204345703, 0.4658057987689972, 0.4632807970046997, 0.4604502320289612, 0.46070289611816406, 0.45761579275131226, 0.4568803906440735, 0.4563179016113281, 0.4545234143733978, 0.4550526440143585, 0.45350444316864014, 0.450317919254303, 0.4506087303161621, 0.45258060097694397, 0.45226529240608215, 0.4489358365535736, 0.4511761963367462, 0.4482949674129486, 0.45073509216308594, 0.4480527639389038, 0.44495853781700134, 0.44665467739105225, 0.44500187039375305, 0.44616377353668213, 0.44629809260368347, 0.44695568084716797, 0.4474436342716217, 0.44749197363853455, 0.444358766078949, 0.44608578085899353, 0.444914847612381, 0.44269174337387085, 0.44431576132774353, 0.442472904920578, 0.44221198558807373, 0.4422048330307007, 0.44237393140792847, 0.44359326362609863, 0.44377270340919495, 0.4432271420955658, 0.442674458026886, 0.4418486952781677, 0.44326287508010864, 0.4409373104572296, 0.44479772448539734, 0.4416027367115021, 0.44195088744163513, 0.4416750967502594, 0.4416438937187195, 0.4412139356136322, 0.44256591796875, 0.4423811137676239, 0.4418734908103943, 0.44330018758773804, 0.4436954855918884, 0.4422041177749634, 0.4416525065898895, 0.44263291358947754, 0.4435962438583374], "moving_avg_accuracy_train": [0.05067614966892764, 0.10132681462543833, 0.15236166067535295, 0.20568355267237098, 0.2557237483291372, 0.3021033917974878, 0.34621428940945187, 0.3862720620304299, 0.4246699162452071, 0.46113188537650035, 0.4945496548434184, 0.5248466446470057, 0.5532459585011036, 0.5795585449888023, 0.6039259359218158, 0.6264446341174249, 0.6471624332160645, 0.6662780603667264, 0.6843142757344004, 0.7004283951224776, 0.7155888673431109, 0.7294750357202339, 0.7421563461132344, 0.7542300840217523, 0.7651914187524212, 0.7754216323242998, 0.784821811890181, 0.7932494574649595, 0.8011133202905841, 0.8083441845574375, 0.814947293498796, 0.821120353375799, 0.8268387955841309, 0.832396980959734, 0.8372153726512744, 0.8417031679927361, 0.8458863790750609, 0.8497581898455726, 0.8533707387723757, 0.8567196890564984, 0.8599104195729139, 0.8626354484674129, 0.8650532774844129, 0.8674433093878265, 0.8696290711377667, 0.8716404345400938, 0.873492586378397, 0.8751920030185658, 0.8766982265066225, 0.8781841080768443, 0.8795283769364726, 0.8807498446541856, 0.8818908740834238, 0.8829271011649762, 0.8838829930752873, 0.8848176645076534, 0.8856054624718013, 0.886328359434754, 0.8870022181895068, 0.8876225338151851, 0.8882482832425905, 0.8887742192974842, 0.8893383146480975, 0.88984367531484, 0.8902939217149267, 0.8907084801190616, 0.8910722460387261, 0.8914136223081002, 0.8916929231160037, 0.8919652201824027, 0.8922311057349911, 0.8925122554108922, 0.8926978608037269, 0.8928649777549157, 0.8930735477800424, 0.8932239502752479, 0.8933384943281033, 0.8935274342375318, 0.8936419289263201, 0.8938424501521358, 0.8939508756910934, 0.8940391220320986, 0.8942092966402121, 0.894332154755353, 0.8944334985613791, 0.894536225584394, 0.8946310771515545, 0.8946467611953508, 0.8947097049597674, 0.8948174355239144, 0.8948911054947325, 0.8949457466756024, 0.8950414988122134, 0.8950671858172969, 0.8950811116730903, 0.8951237276825531, 0.8951505284446596, 0.895160734286517, 0.895174533792989, 0.8952032293904804], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.050530932323042156, 0.10017460466867467, 0.14974701736634033, 0.20141814700207072, 0.2497198328666227, 0.29450779757506584, 0.33618724183864357, 0.37476178290327317, 0.410741341623488, 0.44458984723900064, 0.4754482453276006, 0.5036246651472502, 0.5298511717123444, 0.5543208444036852, 0.5764685615917052, 0.5967484514792214, 0.615525254721736, 0.6323134848500895, 0.6479579423232884, 0.6620888411914867, 0.6756052547474134, 0.6874485261006088, 0.698106440809825, 0.7077219486019599, 0.71674623458702, 0.724977955254824, 0.7324943081197783, 0.7392468186669873, 0.7457035256368849, 0.751641779765591, 0.7570573916516072, 0.7620576306961604, 0.7665781418641197, 0.7709060380975119, 0.7745915661589956, 0.7781547410566503, 0.7813005633082895, 0.7838967812150358, 0.7865803217494057, 0.789140963096679, 0.7913733276303847, 0.7934445203756293, 0.7954275756328706, 0.7973263066802764, 0.7989476563868723, 0.8003325994266488, 0.8018262773134267, 0.8031827944427767, 0.8042917375606226, 0.8056601153388223, 0.8065732430180425, 0.8073085792019309, 0.8081901083299305, 0.808688456777811, 0.8093343418982226, 0.8098657808729335, 0.8102820112852636, 0.8106332341025203, 0.8110459613793918, 0.811530367735805, 0.8118910322517576, 0.812215630316115, 0.8125199756052867, 0.8128660990443815, 0.8132264382645668, 0.8134775013752336, 0.8137156652060836, 0.8139178056225987, 0.8141607671537124, 0.8142817762817147, 0.8143540634031667, 0.8145767837100639, 0.8148403261598407, 0.8148689653247302, 0.815003574345721, 0.8151379590045225, 0.8152222841036937, 0.8153225907554478, 0.8154362512958668, 0.8155395752909036, 0.8155715317301867, 0.8155626419231319, 0.8157011254717825, 0.8157647255093181, 0.8157853444493501, 0.8158415520977886, 0.8158433108563833, 0.8158326867078685, 0.8158953376530454, 0.8159527530123644, 0.8159423621708417, 0.8158841822884714, 0.8158562344568381, 0.8158677025021182, 0.8157803674928702, 0.8158126587744566, 0.8157796562629749, 0.8157255399401412, 0.8156890422808409, 0.8156439873562207], "moving_var_accuracy_train": [0.023112649307408, 0.043890793121497504, 0.06294271341139415, 0.08223745956552965, 0.0965499042412837, 0.10625455577141715, 0.113141041787474, 0.1162685639349124, 0.11791126441611473, 0.1180854147108857, 0.11632759908509387, 0.11295600749701253, 0.10891909599376327, 0.1042583562634406, 0.0991764483050373, 0.09382262939035795, 0.08830341124674645, 0.08276173493433991, 0.077413307024008, 0.07200895991448604, 0.06687662318461081, 0.06192439191593003, 0.05717929342388966, 0.052773340405252916, 0.04857736409642756, 0.044661543114321044, 0.04099065918572623, 0.03753082015656036, 0.034334301187766515, 0.031371439651400775, 0.028626705115483733, 0.02610699461814094, 0.023790600387937125, 0.02168958117116953, 0.01972957514049053, 0.017937880389683088, 0.01630158564534834, 0.014806345348597356, 0.01344316540147453, 0.01219978807337681, 0.011071436117094595, 0.010031124547667823, 0.009080625167300065, 0.008223972923064074, 0.0074445736206051796, 0.006736526503170649, 0.006093748050742757, 0.005510365397920425, 0.004979747240892145, 0.004501643113169455, 0.004067742330755205, 0.0036743959481484205, 0.0033186738867590658, 0.0029964703971640427, 0.0027050469215454233, 0.002442404725569212, 0.002203749883703131, 0.0019880781155042354, 0.001793357074546024, 0.0016174844903705681, 0.0014592601024465955, 0.001315823570806471, 0.0011871050458070762, 0.0010706930458577821, 0.0009654482376591232, 0.0008704501419271606, 0.0007845960585332291, 0.0007071852924955313, 0.0006371688437176383, 0.0005741192705771995, 0.000517343599663157, 0.0004663206459591746, 0.0004199986256199012, 0.00037825011573628276, 0.00034081661726108683, 0.0003069385437300543, 0.00027636277241744977, 0.00024904777978007847, 0.0002242609831059173, 0.00020219676365334949, 0.00018208289216549897, 0.00016394468969925614, 0.00014781085530454982, 0.0001331656168221985, 0.00011994149024315747, 0.00010804231679015927, 9.731905648927847e-05, 8.758936474341884e-05, 7.886608552638731e-05, 7.108392984381132e-05, 6.402438224083342e-05, 5.764881494457195e-05, 5.1966449695104976e-05, 4.6775743125665955e-05, 4.2099914178235564e-05, 3.790626787877484e-05, 3.412210561854274e-05, 3.071083248956063e-05, 2.7641463078014392e-05, 2.488472770605147e-05], "duration": 37003.459206, "accuracy_train": [0.5067614966892765, 0.5571827992340347, 0.6116752751245847, 0.6855805806455334, 0.7060855092400332, 0.7195201830126431, 0.7432123679171281, 0.7467920156192323, 0.7702506041782022, 0.7892896075581396, 0.795309580045681, 0.7975195528792912, 0.8088397831879846, 0.8163718233780916, 0.8232324543189369, 0.829112917877907, 0.8336226251038206, 0.8383187047226835, 0.8466402140434662, 0.8454554696151717, 0.8520331173288114, 0.8544505511143411, 0.85628813965024, 0.8628937251984128, 0.8638434313284422, 0.867493554471207, 0.8694234279831118, 0.8690982676379659, 0.871888085721207, 0.8734219629591177, 0.8743752739710224, 0.8766778922688261, 0.8783047754591177, 0.8824206493401624, 0.8805808978751385, 0.8820933260658915, 0.8835352788159838, 0.8846044867801772, 0.8858836791136029, 0.8868602416136029, 0.8886269942206534, 0.8871607085179033, 0.8868137386374124, 0.8889535965185493, 0.8893009268872278, 0.8897427051610374, 0.8901619529231267, 0.8904867527800849, 0.8902542378991326, 0.8915570422088409, 0.8916267966731267, 0.8917430541136029, 0.892160138946567, 0.8922531448989479, 0.8924860202680879, 0.8932297073989479, 0.8926956441491326, 0.892834432101329, 0.8930669469822813, 0.8932053744462901, 0.8938800280892396, 0.8935076437915282, 0.8944151728036176, 0.8943919213155224, 0.894346139315707, 0.8944395057562754, 0.894346139315707, 0.8944860087324659, 0.8942066303871355, 0.8944158937799926, 0.8946240757082872, 0.8950426024940015, 0.8943683093392396, 0.8943690303156147, 0.8949506780061831, 0.8945775727320967, 0.8943693908038022, 0.8952278934223883, 0.8946723811254154, 0.8956471411844776, 0.8949267055417128, 0.8948333391011444, 0.8957408681132337, 0.8954378777916205, 0.8953455928156147, 0.8954607687915282, 0.8954847412559985, 0.8947879175895165, 0.8952761988395165, 0.8957870106012367, 0.8955541352320967, 0.895437517303433, 0.8959032680417128, 0.8952983688630491, 0.8952064443752308, 0.8955072717677187, 0.8953917353036176, 0.8952525868632337, 0.8952987293512367, 0.8954614897679033], "end": "2016-02-01 20:04:45.504000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0], "moving_var_accuracy_valid": [0.0229803760929228, 0.042862786319275197, 0.06069332459335683, 0.07865314287451328, 0.09178530430328267, 0.10066042991747715, 0.1062289715928156, 0.10899803139865522, 0.10974898607010218, 0.10908557945472248, 0.10674718810260081, 0.103217664997019, 0.09908636531679749, 0.09456661271970992, 0.0895246438375036, 0.08427364485840128, 0.07901939543263412, 0.07365405792695372, 0.0684913935809349, 0.06343939494825063, 0.058739696372159096, 0.05412809442205196, 0.04973760529338711, 0.04559596667495387, 0.041769309645319844, 0.038202229707162624, 0.03489046677996093, 0.03181178769017635, 0.02900581050521484, 0.02642259521356721, 0.024044295361110128, 0.021864887339523176, 0.01986231379654766, 0.018044658589155996, 0.016362440784068254, 0.014840462643822916, 0.013445482158190799, 0.012161597069145514, 0.011010249870427419, 0.009968236840368967, 0.00901626421903419, 0.008153246351622357, 0.007373314289839573, 0.006668429477169058, 0.006025245503291858, 0.005439983557973504, 0.004916064864841197, 0.004441019626857059, 0.004007985457718912, 0.0036240390316418596, 0.003269139347904696, 0.002947091886844248, 0.0026593765405914303, 0.002395674047111831, 0.0021598611506995708, 0.0019464168820841894, 0.0017533344236811074, 0.001579111198519253, 0.0014227331729129912, 0.001282571701284894, 0.0011554852411940109, 0.0010408849922050707, 0.0009376301274799323, 0.0008449453276477566, 0.0007616193940654151, 0.0006860247488287128, 0.0006179327720387685, 0.0005565072415667919, 0.0005013877901605224, 0.0004513808000260089, 0.00040628974887475843, 0.000366107213003222, 0.0003301215833084088, 0.000297116806793458, 0.0002675682024109012, 0.00024097391529850153, 0.00021694052026980355, 0.0001953370210622983, 0.00017591958742210368, 0.00015842371131144663, 0.00014259053110640688, 0.00012833218925379142, 0.00011567156956763422, 0.00010414081729384159, 9.373056183064985e-05, 8.43859393452717e-05, 7.594737324983068e-05, 6.835365177763261e-05, 6.155361286825351e-05, 5.542792029279968e-05, 4.9886099989807636e-05, 4.492795407924048e-05, 4.044218840295346e-05, 3.639915320722102e-05, 3.282788452106199e-05, 2.955448061075426e-05, 2.6608835041555796e-05, 2.3974308724973518e-05, 2.158886656468575e-05, 1.944824942430999e-05], "accuracy_test": 0.8008051658163264, "start": "2016-02-01 09:48:02.045000", "learning_rate_per_epoch": [0.001240303972736001, 0.0011526469606906176, 0.0010711851064115763, 0.0009954804554581642, 0.0009251260780729353, 0.0008597439154982567, 0.0007989825680851936, 0.0007425154326483607, 0.0006900390726514161, 0.000641271413769573, 0.0005959503469057381, 0.0005538322729989886, 0.000514690880663693, 0.0004783157492056489, 0.00044451135909184813, 0.0004130960733164102, 0.0003839010023511946, 0.00035676927655003965, 0.0003315550566185266, 0.0003081228060182184, 0.0002863465924747288, 0.0002661093894857913, 0.0002473024360369891, 0.00022982463997323066, 0.00021358206868171692, 0.0001984874252229929, 0.00018445956811774522, 0.00017142311844509095, 0.00015930799418129027, 0.0001480491046095267, 0.00013758591376245022, 0.00012786219303961843, 0.00011882568651344627, 0.00011042782716685906, 0.0001026234749588184, 9.537068399367854e-05, 8.863047696650028e-05, 8.236662688432261e-05, 7.654546789126471e-05, 7.113571336958557e-05, 6.610828131670132e-05, 6.14361633779481e-05, 5.709423930966295e-05, 5.305917511577718e-05, 4.930928480462171e-05, 4.582441033562645e-05, 4.2585827031871304e-05, 3.957612716476433e-05, 3.6779132642550394e-05, 3.4179811336798593e-05, 3.1764193408889696e-05, 2.951929855044e-05, 2.7433057766756974e-05, 2.549426062614657e-05, 2.3692484319326468e-05, 2.2018046365701593e-05, 2.0461948224692605e-05, 1.9015824364032596e-05, 1.7671904060989618e-05, 1.642296410864219e-05, 1.5262290617101826e-05, 1.4183647181198467e-05, 1.318123577220831e-05, 1.2249668543518055e-05, 1.1383937817299739e-05, 1.0579392437648494e-05, 9.831706847762689e-06, 9.136862900049891e-06, 8.491126209264621e-06, 7.891026143624913e-06, 7.33333763491828e-06, 6.8150629886076786e-06, 6.333416877168929e-06, 5.885810423933435e-06, 5.469838015415007e-06, 5.083264113636687e-06, 4.7240105232049245e-06, 4.390146841615206e-06, 4.079878635820933e-06, 3.7915381199127296e-06, 3.5235757422924507e-06, 3.2745513180998387e-06, 3.0431265258812346e-06, 2.8280574042582884e-06, 2.628187985465047e-06, 2.442443928885041e-06, 2.2698272914567497e-06, 2.1094099338370143e-06, 1.9603298824222293e-06, 1.8217859860669705e-06, 1.6930334822973236e-06, 1.573380473018915e-06, 1.4621837181039155e-06, 1.3588456795332604e-06, 1.262810883417842e-06, 1.1735633052012417e-06, 1.0906231864282745e-06, 1.0135447610082338e-06, 9.41913754104462e-07, 8.753451652410149e-07], "accuracy_train_first": 0.5067614966892765, "accuracy_train_last": 0.8954614897679033, "batch_size_eval": 1024, "accuracy_train_std": [0.016693722922081163, 0.01962090505579898, 0.016271731297948646, 0.01721682069160141, 0.016711314426347188, 0.01802636966289886, 0.017723131677493443, 0.01786546935302085, 0.017220352759432914, 0.01594893140672036, 0.016363990485522326, 0.014260805517472478, 0.015403656714837172, 0.014521512865861362, 0.015878529626526004, 0.013414182421332209, 0.014476276405074906, 0.01438548458339754, 0.013975730525993513, 0.013355953674538209, 0.012033211266045923, 0.012394354960973353, 0.01229756454903615, 0.013179572082655652, 0.012458979647895437, 0.01145881096342227, 0.012047054928367747, 0.011013437698926693, 0.010397070056087775, 0.010103740079070197, 0.010183744140458395, 0.009517401909217524, 0.009374794114619014, 0.009623106686322578, 0.009872194100669276, 0.010081226857220148, 0.010066469037515579, 0.010707476320929606, 0.010285825874148127, 0.00975306473629599, 0.010097939194272177, 0.008930274037311326, 0.009450946871189856, 0.010058586973475586, 0.009884985878090542, 0.009380452812769741, 0.009695572600479636, 0.009297104961473714, 0.009697320716551338, 0.010134344028146561, 0.010128807507152377, 0.010398868139502311, 0.009368469666381206, 0.009696055934759612, 0.009419851584212751, 0.009842431992219656, 0.009741974638109207, 0.010123119210704303, 0.009522528283304896, 0.00935760696279144, 0.009603397732707417, 0.009592786980621548, 0.009956834687777135, 0.0094306620053904, 0.009587941814750816, 0.009523960664861249, 0.009996065589810086, 0.009861626539601799, 0.009322418810730131, 0.009872551558099997, 0.009506317280798322, 0.009389592205559502, 0.009888233964948328, 0.009810596606332185, 0.009966220083963322, 0.009858422716779633, 0.009942946639136188, 0.009723438287814249, 0.00993057443281451, 0.009429019376706085, 0.00995421880185194, 0.00965016805284599, 0.009817214252576091, 0.009666412352183159, 0.009712847214984246, 0.009909583786232077, 0.009614052907913855, 0.010264598825252791, 0.010264002907228516, 0.009415488803552502, 0.00968415565759408, 0.009383352439393736, 0.00968363524620964, 0.0095533312536818, 0.009799265610309867, 0.009445119227550211, 0.009890461371573222, 0.010012476583434996, 0.009805922396098635, 0.00975814035347655], "accuracy_test_std": 0.007096418223490289, "error_valid": [0.49469067676957834, 0.45303234422063254, 0.40410126835466864, 0.3335416862763554, 0.3155649943524097, 0.3024005200489458, 0.2886977597891567, 0.27806734751506024, 0.26544262989457834, 0.25077360222138556, 0.246826171875, 0.24278755647590367, 0.23411026920180722, 0.22545210137424698, 0.22420198371611444, 0.22073253953313254, 0.21548351609563254, 0.21659244399472888, 0.21124194041792166, 0.21073306899472888, 0.20274702324924698, 0.20596203172063254, 0.20597232680722888, 0.20573848126882532, 0.20203519154743976, 0.20093655873493976, 0.19985851609563254, 0.19998058640813254, 0.1961861116340362, 0.1949139330760542, 0.19420210137424698, 0.19294021790286142, 0.19273725762424698, 0.19014289580195776, 0.19223868128765065, 0.18977668486445776, 0.19038703642695776, 0.19273725762424698, 0.1892678134412651, 0.18781326477786142, 0.1885353915662651, 0.18791474491716864, 0.18672492705195776, 0.1855851138930723, 0.1864601962537651, 0.18720291321536142, 0.1847306217055723, 0.1846085513930723, 0.1857277743787651, 0.18202448465737953, 0.18520860786897586, 0.1860733951430723, 0.1838761295180723, 0.1868264071912651, 0.1848526920180723, 0.18535126835466864, 0.1859719150037651, 0.18620576054216864, 0.1852394931287651, 0.18410997505647586, 0.18486298710466864, 0.18486298710466864, 0.18474091679216864, 0.1840187900037651, 0.1835305087537651, 0.1842629306287651, 0.1841408603162651, 0.1842629306287651, 0.1836525790662651, 0.1846291415662651, 0.1849953525037651, 0.18341873352786142, 0.18278779179216864, 0.1848732821912651, 0.18378494446536142, 0.1836525790662651, 0.1840187900037651, 0.1837746493787651, 0.18354080384036142, 0.1835305087537651, 0.1841408603162651, 0.18451736634036142, 0.18305252259036142, 0.18366287415286142, 0.18402908509036142, 0.1836525790662651, 0.1841408603162651, 0.1842629306287651, 0.18354080384036142, 0.1835305087537651, 0.18415115540286142, 0.18463943665286142, 0.18439529602786142, 0.18402908509036142, 0.18500564759036142, 0.1838967196912651, 0.18451736634036142, 0.18476150696536142, 0.18463943665286142, 0.18476150696536142], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.0706737713919147, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.0013346272120488443, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.432056212578778e-08, "rotation_range": [0, 0], "momentum": 0.5457480331389069}, "accuracy_valid_max": 0.8179755153426205, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8152384930346386, "accuracy_valid_std": [0.018263308810993088, 0.018530979793993825, 0.024386823578381626, 0.022614681938479014, 0.015795829966304242, 0.014664274910805361, 0.018891537432101056, 0.016394712974234924, 0.011950433771047705, 0.012766430256190323, 0.009261267938667314, 0.010155447543105937, 0.008707761063480892, 0.00855364091144875, 0.009557572484355993, 0.009856841213984363, 0.010133924286493005, 0.011563148818260763, 0.013707636294679547, 0.012007719934346786, 0.00825952430291255, 0.01171457250613884, 0.013038393869775266, 0.01271957394176615, 0.011875710313006056, 0.012029242261825527, 0.014943284522277849, 0.013640255467102527, 0.013950041043720449, 0.009006350467704715, 0.011354937814042248, 0.01080034356368988, 0.011750713080496945, 0.01024836263068187, 0.009550082658459183, 0.008783360846496462, 0.00913308689741583, 0.010462744783658563, 0.008800768835135767, 0.009251320879285627, 0.0083362509819976, 0.00849729352649804, 0.010222473182221161, 0.007997920821241495, 0.008007465658364035, 0.010001056759692569, 0.007843072796542554, 0.008338168271282129, 0.008559531977028618, 0.008516016746719014, 0.01030348858083518, 0.009755112949430007, 0.008591448882626992, 0.007964651194090396, 0.00976905314055579, 0.00923486483399185, 0.010226871744948143, 0.009102763447533663, 0.011059749361137034, 0.009259275363615751, 0.009416367934296184, 0.008581818839304577, 0.00860591628236104, 0.009501324823545465, 0.010058860224283208, 0.010836335464080426, 0.009918767246395196, 0.010421356862872001, 0.010100280819596553, 0.00987973874608195, 0.00971863196680996, 0.010489820418930977, 0.009435747602674866, 0.009971371848891096, 0.00986280963424838, 0.01020595119754274, 0.010547796374762776, 0.010128299726818118, 0.010777004855627118, 0.010327840835867038, 0.010132792216955316, 0.010880855266851433, 0.010562299722184499, 0.010179630808761685, 0.010790456777696394, 0.00981293160764267, 0.009687723710203157, 0.009710796265870044, 0.011535664383745802, 0.009256536143183652, 0.010281203555959555, 0.010809316154194032, 0.010472005812224428, 0.00986714098121685, 0.011459464204040037, 0.009167657793968163, 0.010260603758433644, 0.010802329806883941, 0.010090636513021448, 0.010385992577983841], "accuracy_valid": [0.5053093232304217, 0.5469676557793675, 0.5958987316453314, 0.6664583137236446, 0.6844350056475903, 0.6975994799510542, 0.7113022402108433, 0.7219326524849398, 0.7345573701054217, 0.7492263977786144, 0.753173828125, 0.7572124435240963, 0.7658897307981928, 0.774547898625753, 0.7757980162838856, 0.7792674604668675, 0.7845164839043675, 0.7834075560052711, 0.7887580595820783, 0.7892669310052711, 0.797252976750753, 0.7940379682793675, 0.7940276731927711, 0.7942615187311747, 0.7979648084525602, 0.7990634412650602, 0.8001414839043675, 0.8000194135918675, 0.8038138883659638, 0.8050860669239458, 0.805797898625753, 0.8070597820971386, 0.807262742375753, 0.8098571041980422, 0.8077613187123494, 0.8102233151355422, 0.8096129635730422, 0.807262742375753, 0.8107321865587349, 0.8121867352221386, 0.8114646084337349, 0.8120852550828314, 0.8132750729480422, 0.8144148861069277, 0.8135398037462349, 0.8127970867846386, 0.8152693782944277, 0.8153914486069277, 0.8142722256212349, 0.8179755153426205, 0.8147913921310241, 0.8139266048569277, 0.8161238704819277, 0.8131735928087349, 0.8151473079819277, 0.8146487316453314, 0.8140280849962349, 0.8137942394578314, 0.8147605068712349, 0.8158900249435241, 0.8151370128953314, 0.8151370128953314, 0.8152590832078314, 0.8159812099962349, 0.8164694912462349, 0.8157370693712349, 0.8158591396837349, 0.8157370693712349, 0.8163474209337349, 0.8153708584337349, 0.8150046474962349, 0.8165812664721386, 0.8172122082078314, 0.8151267178087349, 0.8162150555346386, 0.8163474209337349, 0.8159812099962349, 0.8162253506212349, 0.8164591961596386, 0.8164694912462349, 0.8158591396837349, 0.8154826336596386, 0.8169474774096386, 0.8163371258471386, 0.8159709149096386, 0.8163474209337349, 0.8158591396837349, 0.8157370693712349, 0.8164591961596386, 0.8164694912462349, 0.8158488445971386, 0.8153605633471386, 0.8156047039721386, 0.8159709149096386, 0.8149943524096386, 0.8161032803087349, 0.8154826336596386, 0.8152384930346386, 0.8153605633471386, 0.8152384930346386], "seed": 35812468, "model": "residualv4", "loss_std": [0.24227991700172424, 0.10373878479003906, 0.0991302952170372, 0.09146105498075485, 0.0858880952000618, 0.08590882271528244, 0.08428572863340378, 0.08313237875699997, 0.08580555766820908, 0.0821438580751419, 0.08179681748151779, 0.08255685120820999, 0.07766979932785034, 0.0823734924197197, 0.07952180504798889, 0.07932707667350769, 0.07820148020982742, 0.0772014856338501, 0.07775948196649551, 0.074996717274189, 0.07647384703159332, 0.07563775777816772, 0.0748857855796814, 0.07359439134597778, 0.07343102246522903, 0.07392904907464981, 0.07224828749895096, 0.07334773987531662, 0.07309151440858841, 0.0706452801823616, 0.07015164196491241, 0.07231290638446808, 0.07186844944953918, 0.07166392356157303, 0.0716552734375, 0.06823493540287018, 0.06992434710264206, 0.06907021254301071, 0.06844484806060791, 0.06865349411964417, 0.06629599630832672, 0.06952156126499176, 0.06901049613952637, 0.07009059935808182, 0.06848683208227158, 0.07036565244197845, 0.06969288736581802, 0.07016100734472275, 0.07030624151229858, 0.06901883333921432, 0.06890888512134552, 0.06814625859260559, 0.06740643829107285, 0.06802826374769211, 0.06635881215333939, 0.06944186240434647, 0.06687408685684204, 0.0661068856716156, 0.06791487336158752, 0.06969889253377914, 0.06820530444383621, 0.06649146974086761, 0.06742303818464279, 0.06684020906686783, 0.06692096590995789, 0.06849264353513718, 0.06845778226852417, 0.0693497359752655, 0.06598691642284393, 0.06589851528406143, 0.06758776307106018, 0.06717118620872498, 0.06749524921178818, 0.06688079237937927, 0.06678754091262817, 0.0669785588979721, 0.06591413170099258, 0.06707695871591568, 0.06555651873350143, 0.06600330024957657, 0.06855396181344986, 0.06874861568212509, 0.06722061336040497, 0.06664104014635086, 0.06770182400941849, 0.06591418385505676, 0.06839290261268616, 0.06870570033788681, 0.06811569631099701, 0.06574676185846329, 0.06506761908531189, 0.06879912316799164, 0.06446708738803864, 0.06646384298801422, 0.0661541074514389, 0.06690927594900131, 0.0667150542140007, 0.06667248904705048, 0.06649711728096008, 0.0668688639998436]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:29 2016", "state": "available"}], "summary": "c7c265d5214041e2c766405bca579426"}