{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.014861959136394867, 0.013455502477603225, 0.004322527444928942, 0.010402126401811844, 0.013151006428815212, 0.012159562419738385, 0.0055199659200747125, 0.011027112242895232, 0.013408042160390425, 0.00725143772871925, 0.00726384480992169, 0.010685648403695992, 0.005594702195459982, 0.009224258301740606, 0.01141262800509698, 0.006569439485506637, 0.01320303815480991, 0.010926199674646682, 0.00752536439641689, 0.01078012221120769, 0.012889925003166604, 0.013823479237013863, 0.01284650058711257, 0.011567823044662171, 0.010911786418956602, 0.008887079735670841, 0.010993757606198893, 0.01153364023775046, 0.008603796194273951, 0.008720650116055459, 0.01018788045223179, 0.011329573908394024, 0.007985912485159225, 0.00966546296356683, 0.007138266635920031, 0.013263215461536682, 0.011793336228646027, 0.01359154484066775, 0.011766027609469628, 0.011099014185648591, 0.008143869683813471, 0.01722439808174627, 0.0072584303196553115, 0.011777152973911638, 0.014871515252282084, 0.007226965675463831, 0.014080815047629196, 0.014239718277737706, 0.014815608336559654, 0.014647754688899206, 0.010569666158291555, 0.011134464151024766, 0.012718399227312507, 0.008732773635461884, 0.011383412066227089, 0.009804400784059754, 0.011566502744934334, 0.014431122493225717, 0.014594569810025096, 0.012338458082946254, 0.012901754425963478, 0.015747226216720794, 0.009951370420161554, 0.009138914619320275, 0.01656408180649546, 0.014425348892155581, 0.014991565683958713, 0.014914504946069608, 0.01912436921647324, 0.013774100690383822, 0.009221759660010504, 0.015369297913987022, 0.015338362227558628, 0.016550035245811952, 0.015087174552733435, 0.01011024316034838, 0.015595473885970818, 0.012524496473904335, 0.010507659991613629, 0.013449078547896306, 0.01523809292450977, 0.007241721706083644, 0.0137446477800875, 0.009629095197110702, 0.014782118372626236, 0.013099297921450854, 0.015221814779808138, 0.014158611429202425, 0.01239518994183197, 0.01331721117341131, 0.008739665047543142, 0.016531893929881962, 0.021288005798451286, 0.010006581965754564, 0.017873123071023282, 0.012364306545741341, 0.012291577685414053, 0.015450134379859167, 0.009559743971355889, 0.01526987034855764, 0.014718828698338004, 0.015307225186532115, 0.012188678999220458, 0.008922433905723037, 0.009869732543323946, 0.01367829107418358, 0.011790034629408813, 0.009006110896969483, 0.01632560216498398, 0.01434780745147607, 0.012113528929572563, 0.012324027274493152, 0.011113995154978244, 0.012373023895582671, 0.010442454231791775, 0.011739081844270199, 0.01291143183667881, 0.008963389670706916, 0.009432260584188853, 0.006985029335075665, 0.014762906565260496, 0.010247671696896915, 0.0074910932043946755, 0.011238789930023467, 0.011671186733692069, 0.014801891976918106, 0.012456998869578536, 0.008281138766146457, 0.012396688597318961, 0.009859605836317351, 0.02662930858078214, 0.011032848223053553, 0.012735201309670778, 0.011242853986857173, 0.010116402368013097, 0.010447373032867769, 0.009179489264566534, 0.012168676017164816, 0.010324106309378528, 0.01201328713458391, 0.011175375800591535, 0.011419596795727006, 0.012891116303415351, 0.011295700731525114, 0.013010627237799631, 0.012427854241731394, 0.007373023663463212, 0.007386618738364165, 0.009207538118793832, 0.008241399986634805, 0.010629923919772247, 0.012723618670275267, 0.011975248182478453, 0.008500236065996624, 0.013215750059161561, 0.013196322663913884, 0.011543730342442066, 0.010953963351314355, 0.009052792570599495, 0.011233235651850498, 0.011294961260766236, 0.014029695974059134, 0.00641227377186021, 0.0063469036335983015, 0.006760694646636099, 0.010799313401006663, 0.00828997138004621, 0.00928486302201676, 0.009128362233168721, 0.006464698595149457, 0.010464875612097564, 0.01123326877158641, 0.01028412847314667, 0.00984604023617823, 0.008743529223071127, 0.012455572159253261, 0.012824219572771177, 0.011874193084447713, 0.008936676263408334, 0.013228216820228199, 0.009398504450796413, 0.0081222149593713, 0.00897550728065485, 0.01502953581986835, 0.007704252895286517, 0.012940037774951714, 0.008358935472854333, 0.010988940470739318, 0.013224823736588225, 0.0081146011484468, 0.011381855058990536, 0.008975505232211778, 0.009353156910581016, 0.014657128083118738, 0.011938100535107127, 0.012139867462194328, 0.007412025787518313, 0.011087557287883546, 0.008731581165456742, 0.012123949801248503, 0.01015326956498441, 0.011773128487497873, 0.013003974477545314, 0.013395757852617691, 0.008267947041199566, 0.011387010886199433, 0.010203843460617496, 0.009417410416880486, 0.014441169739878471, 0.008802731277950207, 0.012419476339429318, 0.012088298025735215, 0.009262723703792566, 0.011270509532662752, 0.014338827646440094, 0.010834889095989442, 0.00951514455468648, 0.009636372996611263, 0.0066299313678425675, 0.01162864487482767, 0.011142780250670808, 0.008765720264519924, 0.00948523501950641, 0.010759874716824696, 0.010587819935981423, 0.014348880728023022, 0.01002479126344456, 0.010841443468237793, 0.013218241881046904, 0.010599727612423407, 0.010448113282538326, 0.01107368056100263, 0.009620034640626633, 0.015030620067072835, 0.011800041324864249, 0.01197472824027872, 0.010460353493141391, 0.012888148461669887, 0.011118255799213274, 0.00860261287553247, 0.009644823573985677, 0.010647546531926502, 0.014170285106111359, 0.009203900952840616, 0.010267083589883565, 0.011914274403450697, 0.015587220442038476, 0.010745882105645966, 0.012394972592514188, 0.011685906475821815, 0.00995287650720348, 0.008415155558060444, 0.009722226744190569, 0.011910635312724403, 0.012047419232360702, 0.01056470438151934, 0.009808958595254309, 0.00982069947314919, 0.013923795773355542, 0.00895495872290355], "moving_avg_accuracy_train": [0.05170772266634366, 0.10321980659087761, 0.1600301712390988, 0.21625972234839305, 0.26925399383240756, 0.315179832509798, 0.36014417668591303, 0.40236023786099095, 0.4383113917984522, 0.4734268412467908, 0.5065720310204598, 0.5379949601166419, 0.5661084018818326, 0.5918777462347623, 0.615755858758296, 0.6387641577627267, 0.6610433553643148, 0.6812526351783355, 0.7006102484715946, 0.7182573514795015, 0.734665263866389, 0.7502229716586445, 0.7644593521644302, 0.7778976677958553, 0.7894110088570321, 0.8005237504870173, 0.8095975556766416, 0.8198260268531635, 0.8276484397120978, 0.8376249497921985, 0.8458131140737759, 0.8542449828355105, 0.8595834614057339, 0.8656293971438519, 0.8704733202593854, 0.8766600575394639, 0.8828837770070015, 0.886627727165982, 0.8917338440304101, 0.89500651977987, 0.8987215161615176, 0.9000028943015028, 0.9044109464238166, 0.9073900771874889, 0.9116894542509475, 0.9153705926033076, 0.9174001349775744, 0.9202706788810721, 0.9228752028799618, 0.9248635267111056, 0.9271040249305451, 0.9299876817363555, 0.9320550919841855, 0.9322580743013169, 0.9328387553701701, 0.9358184377938858, 0.9377981733276664, 0.9388382849354682, 0.9402067549146049, 0.942231217591057, 0.9438626438951204, 0.945898155731845, 0.9462165526563534, 0.947267975700288, 0.9467845062148845, 0.9480815834922979, 0.949520887306228, 0.9503698682161552, 0.9516267744362524, 0.9529440379879206, 0.955057165364147, 0.9558569676134927, 0.9573115006128947, 0.9582973846278326, 0.9595427531579435, 0.9599217902671675, 0.9600654662607534, 0.9612850531537349, 0.9626363028217502, 0.9641522275241174, 0.962538620912348, 0.9637109272354266, 0.9645567034845215, 0.9656341583956208, 0.9664201450108391, 0.9661185625764772, 0.965126378303418, 0.966305011900494, 0.966907763871205, 0.9676850446257881, 0.9683404555263506, 0.9687141946440274, 0.9690038766296524, 0.9702899089440773, 0.9705498666354022, 0.9719161760278329, 0.9708954348727701, 0.9708881901177282, 0.9720696045869447, 0.9724075393271243, 0.9738112596872783, 0.9724708378817565, 0.9738054854174089, 0.9749625624697525, 0.9760248221073288, 0.9752651843502689, 0.9760157666962036, 0.9763472769301916, 0.9769734821229237, 0.9772579768416021, 0.9775721508086508, 0.9781316000873279, 0.9783677844226797, 0.9788081788590108, 0.9798648040159761, 0.9802857048263109, 0.9810434427139272, 0.9817579228472963, 0.9821359601006804, 0.9830760820215831, 0.9827410522039763, 0.983253255353826, 0.9837095878910718, 0.9843388151138693, 0.9844123322620432, 0.9802009448622507, 0.9806230006736447, 0.9813447198765367, 0.9817106350531964, 0.9795198578908538, 0.965233863934548, 0.9667086325625495, 0.9682916546479796, 0.9707951714748484, 0.9727693187618873, 0.9747204735297554, 0.9764974031113037, 0.977961889250201, 0.9793031061656663, 0.9807450053705282, 0.9817010259263602, 0.9825730701706566, 0.9832346771036187, 0.9842485419825425, 0.9847285787438214, 0.9856349061372964, 0.9864599013866621, 0.9868978386658622, 0.9875896012647614, 0.9881168204537614, 0.9884285933560135, 0.9889812674275735, 0.989311227328873, 0.9899639029590809, 0.9901584690239147, 0.9899150516965509, 0.9901260925828667, 0.9905647482055323, 0.9911432610707026, 0.9912779118981562, 0.9910527225678828, 0.9912872161956461, 0.9915958085641767, 0.9914666767030064, 0.9915852620088962, 0.9919710066413399, 0.9923205019593487, 0.9925908699181758, 0.9928574525692154, 0.9929625543730174, 0.9917482314119523, 0.9917225119529277, 0.9920039228850344, 0.9923640774715309, 0.9924743029089016, 0.9927293628704109, 0.993030924351227, 0.9932930290887233, 0.9934080516631936, 0.9933790384980739, 0.9934180308161329, 0.993550780152386, 0.9937608993097664, 0.9937617055466562, 0.9940065357360381, 0.9939386365517384, 0.9940750928370408, 0.994160773210498, 0.9942006471168384, 0.9940551720254018, 0.9943288563847849, 0.9943867992058394, 0.9943971671638545, 0.994655181102231, 0.9946386748217882, 0.9946609855015234, 0.9949879847561421, 0.9951358357591178, 0.9954153499879771, 0.9953785943415696, 0.995022318575279, 0.9952271179677511, 0.995357958998357, 0.9956152609032924, 0.9951911406534486, 0.9953279045642942, 0.9952091766078648, 0.9952232291851736, 0.9953195818618943, 0.9955783602828477, 0.995174206136715, 0.995191863907595, 0.9953588184763684, 0.9954835370001786, 0.9956003618715893, 0.9955381656392107, 0.9957867114264801, 0.9954523669207369, 0.9956606644548537, 0.9950902418701103, 0.9952371317081085, 0.9953786331575449, 0.9947154699156184, 0.9948811997097708, 0.995128012774508, 0.9950176482530096, 0.9947555597669944, 0.9948847284926758, 0.9949823791553131, 0.9950749510981244, 0.9952187197157022, 0.9948855150048831, 0.9946994549103564, 0.9949621173062255, 0.9951310841470316, 0.9953645345120903, 0.9955002350787384, 0.9956200404399123, 0.995862723895921, 0.9960486229718144, 0.9962647242162996, 0.9963778711768217, 0.996110076878215, 0.9963781614522982, 0.9965729345927826, 0.9967831076513616, 0.9968722820052731, 0.9970525203226029, 0.9970775510284379, 0.9971070901589366, 0.9971568908156621, 0.9971505941817241, 0.9971797683945041, 0.9973013562871965, 0.9973806305537334, 0.9975542478924169, 0.9976616393234132, 0.9976978737910811, 0.9977048721262587, 0.9977855753898233], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 394292625, "moving_var_accuracy_train": [0.024063197250055592, 0.0455383306372841, 0.07003125535673045, 0.09148399158263201, 0.10761112771546172, 0.1158326588679108, 0.12244552320581292, 0.12624073327547294, 0.12524902917284098, 0.1238219793651863, 0.12132721387486047, 0.11808109674422763, 0.11338627754076781, 0.10802418176210987, 0.10235324190507773, 0.09688235412226552, 0.09166138252197448, 0.0861709791851895, 0.0809263359983728, 0.07563648459968064, 0.07049581243977456, 0.06562461164153999, 0.06088622124653561, 0.05642289406497031, 0.051973617859992084, 0.047887693312806144, 0.043839929447098795, 0.04039753110586937, 0.03690848928170302, 0.03411341713393787, 0.031305489729262996, 0.028814808453672746, 0.026189821789308083, 0.023899819660922347, 0.02172101001517292, 0.01989339047721004, 0.01825266358558449, 0.016553551692162414, 0.015132848387844938, 0.01371595720811037, 0.012468572270340221, 0.011236492412744886, 0.010287721483087707, 0.009338826315742461, 0.008571305472372358, 0.007836131941258066, 0.007089590127372763, 0.006454791315352654, 0.005870364091164527, 0.00531890856696552, 0.004832196200710771, 0.004423815869802963, 0.004019901949018157, 0.0036182825705059537, 0.0032594890279888785, 0.003013446691305795, 0.0027473761972286338, 0.0024823750669159274, 0.0022509919509785237, 0.0020627787980357975, 0.0018804548843025268, 0.001729699171809287, 0.001557641644042186, 0.001411826893393818, 0.001272747888744283, 0.0011606147850420929, 0.001063197665757026, 0.0009633648164501113, 0.0008812466540201738, 0.0008087386379991388, 0.0007680525399726421, 0.0006970044387179044, 0.0006463449910632566, 0.0005904581975751219, 0.0005453708627997225, 0.0004921267986912711, 0.00044309990394234016, 0.0004121764432538967, 0.00038739167991630816, 0.0003693347612539026, 0.00035583482180642664, 0.0003326200586619548, 0.00030579608996755576, 0.0002856646627398692, 0.00026265817109960294, 0.00023721092167208326, 0.00022234969619023097, 0.00021261732097661629, 0.00019462537832271902, 0.00018060032883345444, 0.0001664063669872953, 0.0001510228586413028, 0.00013667581365233304, 0.0001378931443108064, 0.0001247120318912371, 0.0001290420409047105, 0.0001255150493649886, 0.0001129640168067703, 0.00011422927645875977, 0.00010383414781046643, 0.00011118461067501596, 0.00011623672515798051, 0.00012064460904198803, 0.00012062959388333154, 0.00011872219433361096, 0.00011204342059780939, 0.00010590944326028832, 9.63075902514084e-05, 9.020602771690875e-05, 8.191386014982139e-05, 7.461082166897947e-05, 6.996659096079344e-05, 6.347197922710399e-05, 5.887030664035646e-05, 6.303138647730807e-05, 5.832266525884203e-05, 5.765789908991974e-05, 5.6486445929741064e-05, 5.2124010821282493e-05, 5.4866072774612074e-05, 5.038967030532176e-05, 4.7711871875233066e-05, 4.481483914865139e-05, 4.389669731497239e-05, 3.955567052315562e-05, 0.0001952221579510071, 0.0001773031221272892, 0.00016426071738496898, 0.0001490396908950614, 0.00017733126298092976, 0.001996404746559276, 0.0018163387544585842, 0.0016572585093193632, 0.0015479410269091593, 0.0014282222418165536, 0.0013196630619884684, 0.0012161140644296534, 0.0011138051348458895, 0.0010186143866902733, 0.0009354646078740794, 0.0008501439248152315, 0.0007719736828098032, 0.0006987158281325136, 0.0006380955432536995, 0.0005763599065579408, 0.0005261167799996154, 0.000479630656452936, 0.0004333936923522616, 0.00039436114255615734, 0.0003574266689597905, 0.0003225588231470199, 0.00029305197849668993, 0.0002647266424752111, 0.00024208784753209595, 0.00021821976636115088, 0.00019693105768238414, 0.00017763879621541815, 0.0001616066853915426, 0.00014845811106889618, 0.0001337754775700119, 0.00012085432192323132, 0.00010926377508406219, 9.919446082489403e-05, 8.94250900805285e-05, 8.060914334543254e-05, 7.388741930402156e-05, 6.759800016941053e-05, 6.149608965091214e-05, 5.598607747433842e-05, 5.048688722936644e-05, 5.870942079035947e-05, 5.284443212647623e-05, 4.827271792821076e-05, 4.461284807096029e-05, 4.0260910087256374e-05, 3.6820319334216625e-05, 3.395674134120267e-05, 3.117935724784468e-05, 2.8180493256800054e-05, 2.537001980487239e-05, 2.2846701432193664e-05, 2.0720632765454998e-05, 1.9045920031593934e-05, 1.7141333878595843e-05, 1.5966676885431687e-05, 1.4411501889945515e-05, 1.3137934561137597e-05, 1.1890211242585791e-05, 1.0715499473988785e-05, 9.834416546646073e-06, 9.525103049119625e-06, 8.602809078813507e-06, 7.743495621912797e-06, 7.5682867912902884e-06, 6.813910227807746e-06, 6.136999102899181e-06, 6.485655805300521e-06, 6.033829496498686e-06, 6.133600384062401e-06, 5.532399143541679e-06, 6.121551024001046e-06, 5.886881042013413e-06, 5.452267315422058e-06, 5.502879016430488e-06, 6.571492991735762e-06, 6.082682998350277e-06, 5.601281647256407e-06, 5.042930756891932e-06, 4.622192226003995e-06, 4.762669443763954e-06, 5.756467663913705e-06, 5.18362706937439e-06, 4.916128814746215e-06, 4.5645083249041266e-06, 4.230889947634881e-06, 3.842616294770188e-06, 4.014329740617485e-06, 4.618973003242e-06, 4.547566467390004e-06, 7.021247147318987e-06, 6.513312053151329e-06, 6.0421847895698085e-06, 9.39603567959517e-06, 8.70362939366397e-06, 8.38151665462233e-06, 7.652987937610275e-06, 7.505902514365159e-06, 6.905473300176331e-06, 6.300746837380023e-06, 5.7477982350046755e-06, 5.35904315010614e-06, 5.822367248903334e-06, 5.551695752990548e-06, 5.617449985524888e-06, 5.312653126600092e-06, 5.2718794704546675e-06, 4.910423317506765e-06, 4.548560906849888e-06, 4.623762154548168e-06, 4.472412136855231e-06, 4.445468653982264e-06, 4.1161419006625985e-06, 4.349951787893476e-06, 4.561780658856822e-06, 4.447031779258802e-06, 4.399883032304508e-06, 4.031463317633785e-06, 3.920689645175398e-06, 3.5342595067692152e-06, 3.18868659816791e-06, 2.8921388870436327e-06, 2.6032818267298045e-06, 2.350613856278804e-06, 2.2486050114954495e-06, 2.0803041943605777e-06, 2.1435605975484164e-06, 2.033000812856683e-06, 1.8415171613956048e-06, 1.6578062355133667e-06, 1.5506427627118394e-06], "duration": 124927.347055, "accuracy_train": [0.5170772266634367, 0.5668285619116833, 0.6713234530730897, 0.7223256823320414, 0.7462024371885383, 0.7285123806063123, 0.7648232742709486, 0.7823047884366926, 0.7618717772356035, 0.7894658862818383, 0.804878738983481, 0.8208013219822813, 0.8191293777685493, 0.8238018454111297, 0.8306588714700996, 0.8458388488026025, 0.8615561337786084, 0.863136153504522, 0.8748287681109265, 0.8770812785506644, 0.8823364753483758, 0.8902423417889442, 0.8925867767165007, 0.8988425084786821, 0.8930310784076227, 0.9005384251568845, 0.8912618023832595, 0.9118822674418604, 0.8980501554425065, 0.9274135405131044, 0.9195065926079733, 0.9301318016911223, 0.9076297685377446, 0.920042818786914, 0.9140686282991879, 0.9323406930601699, 0.9388972522148394, 0.920323278596807, 0.9376888958102622, 0.9244606015250092, 0.9321564835963455, 0.9115352975613695, 0.94408341552464, 0.9342022540605389, 0.9503838478220746, 0.9485008377745479, 0.9356660163459765, 0.9461055740125508, 0.9463159188699704, 0.942758441191399, 0.9472685089055003, 0.955940592988649, 0.9506617842146549, 0.9340849151555003, 0.9380648849898486, 0.9626355796073275, 0.9556157931316908, 0.9481992894056847, 0.9525229847268365, 0.9604513816791252, 0.9585454806316908, 0.9642177622623662, 0.9490821249769288, 0.9567307830956996, 0.9424332808462532, 0.959755278989018, 0.9624746216315985, 0.9580106964055003, 0.9629389304171282, 0.9647994099529347, 0.9740753117501846, 0.9630551878576044, 0.9704022976075121, 0.9671703407622739, 0.9707510699289406, 0.9633331242501846, 0.9613585502030271, 0.9722613351905685, 0.9747975498338871, 0.9777955498454227, 0.9480161614064231, 0.9742616841431341, 0.972168689726375, 0.975331252595515, 0.9734940245478036, 0.9634043206672205, 0.9561967198458842, 0.9769127142741787, 0.9723325316076044, 0.9746805714170359, 0.9742391536314139, 0.9720778467031194, 0.9716110145002769, 0.9818641997739018, 0.9728894858573275, 0.9842129605597084, 0.9617087644772055, 0.9708229873223514, 0.982702334809893, 0.9754489519887413, 0.9864447429286637, 0.9604070416320598, 0.9858173132382798, 0.9853762559408453, 0.985585158845515, 0.9684284445367294, 0.9827710078096161, 0.9793308690360835, 0.9826093288575121, 0.9798184293097084, 0.9803997165120893, 0.9831666435954227, 0.9804934434408453, 0.9827717287859912, 0.9893744304286637, 0.9840738121193245, 0.9878630837024732, 0.9881882440476191, 0.985538295381137, 0.9915371793097084, 0.979725783845515, 0.9878630837024732, 0.9878165807262828, 0.9900018601190477, 0.9850739865956073, 0.9422984582641197, 0.9844215029761905, 0.9878401927025655, 0.9850038716431341, 0.9598028634297711, 0.8366599183277963, 0.9799815502145626, 0.9825388534168512, 0.9933268229166666, 0.9905366443452381, 0.9922808664405685, 0.9924897693452381, 0.9911422645002769, 0.9913740584048542, 0.9937220982142857, 0.9903052109288483, 0.9904214683693245, 0.9891891395002769, 0.9933733258928571, 0.9890489095953304, 0.9937918526785714, 0.9938848586309523, 0.9908392741786637, 0.9938154646548542, 0.9928617931547619, 0.9912345494762828, 0.9939553340716132, 0.9922808664405685, 0.9958379836309523, 0.9919095636074198, 0.9877242957502769, 0.9920254605597084, 0.9945126488095238, 0.9963498768572352, 0.9924897693452381, 0.9890260185954227, 0.993397658845515, 0.9943731398809523, 0.9903044899524732, 0.9926525297619048, 0.9954427083333334, 0.9954659598214286, 0.9950241815476191, 0.9952566964285714, 0.9939084706072352, 0.9808193247623662, 0.9914910368217055, 0.9945366212739941, 0.99560546875, 0.9934663318452381, 0.9950249025239941, 0.9957449776785714, 0.9956519717261905, 0.9944432548334257, 0.9931179200119971, 0.9937689616786637, 0.9947455241786637, 0.9956519717261905, 0.9937689616786637, 0.9962100074404762, 0.9933275438930418, 0.9953031994047619, 0.9949318965716132, 0.9945595122739018, 0.9927458962024732, 0.9967920156192323, 0.9949082845953304, 0.9944904787859912, 0.9969773065476191, 0.9944901182978036, 0.99486178161914, 0.9979309780477114, 0.9964664947858989, 0.9979309780477114, 0.9950477935239018, 0.9918158366786637, 0.9970703125, 0.9965355282738095, 0.9979309780477114, 0.9913740584048542, 0.9965587797619048, 0.994140625, 0.9953497023809523, 0.9961867559523809, 0.9979073660714286, 0.9915368188215209, 0.995350783845515, 0.9968614095953304, 0.9966060037144703, 0.9966517857142857, 0.9949783995478036, 0.9980236235119048, 0.9924432663690477, 0.9975353422619048, 0.9899564386074198, 0.9965591402500923, 0.9966521462024732, 0.9887470007382798, 0.9963727678571429, 0.9973493303571429, 0.9940243675595238, 0.9923967633928571, 0.9960472470238095, 0.9958612351190477, 0.9959080985834257, 0.9965126372739018, 0.9918866726075121, 0.9930249140596161, 0.9973260788690477, 0.9966517857142857, 0.9974655877976191, 0.9967215401785714, 0.9966982886904762, 0.998046875, 0.9977217146548542, 0.9982096354166666, 0.9973961938215209, 0.993699928190753, 0.9987909226190477, 0.9983258928571429, 0.9986746651785714, 0.9976748511904762, 0.9986746651785714, 0.9973028273809523, 0.9973729423334257, 0.9976050967261905, 0.9970939244762828, 0.9974423363095238, 0.9983956473214286, 0.9980940989525655, 0.9991168039405685, 0.9986281622023809, 0.9980239840000923, 0.9977678571428571, 0.9985119047619048], "end": "2016-01-24 21:24:40.624000", "learning_rate_per_epoch": [0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931, 0.009807269088923931], "accuracy_valid": [0.511974656438253, 0.5633162532944277, 0.6593797063253012, 0.6998570453689759, 0.7250344150037651, 0.712390577936747, 0.7434890930911144, 0.7572624482304217, 0.7430022825677711, 0.7574565841490963, 0.7758597868034638, 0.7875491222703314, 0.7848120999623494, 0.7849650555346386, 0.7890345561935241, 0.7956160579819277, 0.8053110881024097, 0.8077319041792168, 0.8110881024096386, 0.8136324595256024, 0.8153826242469879, 0.8210287438817772, 0.8239687264683735, 0.8216185052710843, 0.8162062311746988, 0.8221979715737951, 0.817162203501506, 0.8304281579442772, 0.8204683970256024, 0.8438764824924698, 0.8347006188817772, 0.843907367752259, 0.8247511530496988, 0.8289221338478916, 0.8234892695783133, 0.8459016730986446, 0.8483121940888554, 0.8294515954442772, 0.8398584572665663, 0.8354330407567772, 0.8412821206701807, 0.827061664627259, 0.8446692041603916, 0.8390142601656627, 0.8513948371611446, 0.851719867752259, 0.8397466820406627, 0.8530832313629518, 0.8509271460843373, 0.848597515060241, 0.8520757836031627, 0.8489019554781627, 0.8535921027861446, 0.8336931711219879, 0.8447309746799698, 0.8578439735504518, 0.853184711502259, 0.850550640060241, 0.8511301063629518, 0.860804546310241, 0.8578542686370482, 0.8612119375941265, 0.8480474632906627, 0.8575895378388554, 0.8452913215361446, 0.854945171310241, 0.8578645637236446, 0.8581395896084337, 0.8600015295557228, 0.8599809393825302, 0.864710796310241, 0.8597367987575302, 0.8644872458584337, 0.8651284826807228, 0.8657491293298193, 0.8554834572665663, 0.8577733786709337, 0.863001811935241, 0.8671830878200302, 0.8694112387048193, 0.8521478492093373, 0.8700510048004518, 0.8648843420557228, 0.8670095420745482, 0.8698892248682228, 0.8606927710843373, 0.853602397872741, 0.8695333090173193, 0.8649652320218373, 0.8696553793298193, 0.8629915168486446, 0.8665830313441265, 0.8662682958396084, 0.8698274543486446, 0.8631959478539157, 0.8734292639307228, 0.8585969855986446, 0.860560405685241, 0.8768369375941265, 0.8679463949548193, 0.8762677663780121, 0.8548436911709337, 0.8745278967432228, 0.874110210372741, 0.8767251623682228, 0.8626561911709337, 0.8724424063441265, 0.8685964561370482, 0.8749249929405121, 0.8680581701807228, 0.869227397872741, 0.8733071936182228, 0.8685258612575302, 0.8707334219691265, 0.8810182134789157, 0.872523296310241, 0.8770913733057228, 0.8707937217620482, 0.8732660132718373, 0.879969585372741, 0.866175640060241, 0.8719026496611446, 0.8733571983245482, 0.8792577536709337, 0.8764913168298193, 0.839634906814759, 0.8732763083584337, 0.8740793251129518, 0.8742940512048193, 0.8500917733433735, 0.7590155544051205, 0.872889507247741, 0.8735513342432228, 0.8797666250941265, 0.8780576407191265, 0.8780061652861446, 0.8770296027861446, 0.8776605445218373, 0.8819638907191265, 0.8828595632530121, 0.8807637777673193, 0.8808961431664157, 0.8770604880459337, 0.8757280096950302, 0.8773561041039157, 0.8813844244164157, 0.8812005835843373, 0.8747102668486446, 0.8845582525414157, 0.878870952560241, 0.8780473456325302, 0.8805299322289157, 0.8822389166039157, 0.8814550192959337, 0.8769384177334337, 0.8748838125941265, 0.8759927404932228, 0.8786576971950302, 0.8829198630459337, 0.8808755529932228, 0.8802857916039157, 0.8799092855798193, 0.880824077560241, 0.8799489951995482, 0.878504741622741, 0.8857892507530121, 0.8803255012236446, 0.8816991599209337, 0.8831845938441265, 0.8791459784450302, 0.8671213173004518, 0.8778135000941265, 0.8823301016566265, 0.8849847632718373, 0.8813535391566265, 0.8860539815512049, 0.8844670674887049, 0.8852803793298193, 0.8836728750941265, 0.8801637212914157, 0.8795121893825302, 0.8803769766566265, 0.882288921310241, 0.8774884695030121, 0.8846700277673193, 0.8838464208396084, 0.8830419333584337, 0.8795121893825302, 0.8798784003200302, 0.8762162909450302, 0.8808858480798193, 0.8803460913968373, 0.8828389730798193, 0.889502835560994, 0.8829713384789157, 0.8817506353539157, 0.8884542074548193, 0.8865216726280121, 0.8867658132530121, 0.8786474021084337, 0.8749955878200302, 0.8878850362387049, 0.8780885259789157, 0.8848332784262049, 0.8760324501129518, 0.8834390295557228, 0.8782003012048193, 0.8824624670557228, 0.8842523413968373, 0.8898175710655121, 0.8753823889307228, 0.8849141683923193, 0.8838052404932228, 0.8835919851280121, 0.8821271413780121, 0.8815976797816265, 0.8863481268825302, 0.8792680487575302, 0.8854833396084337, 0.8796548498682228, 0.8865319677146084, 0.878748882247741, 0.8758603750941265, 0.8812314688441265, 0.8848832831325302, 0.8798784003200302, 0.8784135565700302, 0.8865113775414157, 0.8821065512048193, 0.8803255012236446, 0.8838052404932228, 0.8755956442959337, 0.8806417074548193, 0.8876511907003012, 0.8858804358057228, 0.8844052969691265, 0.8856568853539157, 0.8839684911521084, 0.8858392554593373, 0.8872232092432228, 0.8862569418298193, 0.8844258871423193, 0.8790342032191265, 0.8893189947289157, 0.8891763342432228, 0.8855142248682228, 0.8869187688253012, 0.8877114904932228, 0.8845685476280121, 0.8867658132530121, 0.8834287344691265, 0.8858804358057228, 0.8863687170557228, 0.8864098974021084, 0.8848023931664157, 0.8862878270896084, 0.8887086431664157, 0.8847509177334337, 0.8892278096762049, 0.8851583090173193], "accuracy_test": 0.862440664556962, "start": "2016-01-23 10:42:33.277000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0], "accuracy_train_last": 0.9985119047619048, "batch_size_eval": 1024, "accuracy_train_std": [0.01564809686901191, 0.01553673635560899, 0.01482810728600355, 0.01831755170067689, 0.016236908129395555, 0.015018012884123702, 0.016861925179899366, 0.018938551578818304, 0.015679387312561813, 0.01609597809856406, 0.016923800900677702, 0.016427593154582993, 0.014593228910298343, 0.01669318741223021, 0.018624230987543844, 0.018673386399531672, 0.016135905071725003, 0.01632326476042465, 0.01648185998899334, 0.017254754022300325, 0.01635360061171951, 0.016313498910717802, 0.018376554939012097, 0.016303324208939266, 0.01575116398592069, 0.01587949531060978, 0.0173867786391922, 0.016108481964977335, 0.01650790871197275, 0.01634577893374835, 0.016257628712724133, 0.015853595447902154, 0.015361745994105218, 0.016924603786851802, 0.01698725113967463, 0.015190688191830748, 0.015008065915670362, 0.016123688794360175, 0.015920372839885667, 0.015005555574720402, 0.013976912522835581, 0.016231983102697026, 0.013924554757168061, 0.014074033763494241, 0.012362273049589414, 0.012868735387583027, 0.014893468781991305, 0.013551289355412617, 0.012250985770014912, 0.013145132324449417, 0.012390677159972585, 0.011678547900323386, 0.013460777808508961, 0.01319632443370012, 0.010992244393020783, 0.010286787331656265, 0.011237771180925471, 0.01166454122315834, 0.010397863734373632, 0.010376419177004699, 0.011111030255764593, 0.010612228153139376, 0.011895793735505032, 0.010801527713304037, 0.01198745699759136, 0.009158083914315999, 0.009702174283915198, 0.010685720488204594, 0.010211461199381959, 0.010908300319571655, 0.008529201369323343, 0.009938657769137632, 0.008595423703122992, 0.00972495025451099, 0.008930827091178907, 0.009902415949725775, 0.010631540459443138, 0.008479986895237221, 0.007532917403437181, 0.007362533153381258, 0.010024150042768432, 0.008007044960905376, 0.008937675236091108, 0.008231300823931597, 0.008245999162489281, 0.009562651145515126, 0.009354550330928756, 0.007668150630079011, 0.007973857958294747, 0.008607654196044293, 0.00801117235912257, 0.0072506198981019615, 0.008243733972156773, 0.006092670408720878, 0.00821360029376533, 0.006362107223243799, 0.007932159103327912, 0.007706409869022066, 0.006219882252375683, 0.007539725318232753, 0.005307886590277946, 0.0077959096025782375, 0.004344200057158469, 0.0054951043588046715, 0.00516844134245927, 0.007822500855451017, 0.006688406117866889, 0.006160624127186519, 0.005523648218661188, 0.006719295887030126, 0.006765459879218505, 0.005212199536413181, 0.005910432471767565, 0.006137097025409243, 0.0044258873655033774, 0.006117102302915156, 0.005035307778084356, 0.005214765041854029, 0.005628406536901669, 0.003893509722718304, 0.006051901105341642, 0.005075730684759675, 0.004852026431681167, 0.004371527111162955, 0.004579192195818387, 0.00878132296792561, 0.005981916989542969, 0.004502814707289147, 0.006275733288991674, 0.00830554873893691, 0.01411988705763091, 0.007163335564158515, 0.005965499701963589, 0.003355391947931039, 0.004380237248499376, 0.00358432830204451, 0.0035753652281149836, 0.0038684976415045745, 0.004181514228514442, 0.0031618604288150254, 0.004157300889623219, 0.004542734601200086, 0.004254762014332742, 0.0032981889588675453, 0.004657558613272773, 0.0031379173232233093, 0.0037584791676744623, 0.004099496647744369, 0.002759948039095031, 0.0032702042185247635, 0.0036762430048999963, 0.002955203295225907, 0.0037514746526345613, 0.0027378565524302364, 0.0037179863012525797, 0.00454789615748322, 0.003660458673899727, 0.0031170872442092433, 0.002256146108482452, 0.0034722654724887495, 0.004037926829888559, 0.002928493813367768, 0.003145059229708132, 0.004216626141942891, 0.003350796788439699, 0.002792115523117202, 0.002150354137925558, 0.0029819976826416287, 0.0027503670168566303, 0.002761110954632902, 0.005401958590271622, 0.0033856828145004503, 0.0029690242466720224, 0.00279685538554741, 0.0030098779666559126, 0.002564723681324955, 0.002192185021670757, 0.002336398566426191, 0.003171916844146811, 0.0028830517152437893, 0.003369598345066088, 0.0023634783619608936, 0.002175350375967552, 0.0031824582188223296, 0.002143807377113003, 0.0032036820746368664, 0.0029003843246861376, 0.00229791766497293, 0.003233266443123381, 0.00335749230749928, 0.001760704094697468, 0.0028318361352017312, 0.0029667015805409564, 0.0020418990327474096, 0.002582623753512183, 0.0024678645674800024, 0.001464135865283193, 0.002203751358919088, 0.001171183916533335, 0.002480075031825139, 0.0034033316731527487, 0.002098825166740468, 0.002012698019557825, 0.0015976268012845402, 0.0037400876214930866, 0.0024132311654258038, 0.003203646698223556, 0.002492576875605915, 0.0020418990327474096, 0.0015451309268820824, 0.003910724181306251, 0.0027102949749913635, 0.0023591486503836767, 0.0020241719249509764, 0.0021537455686215425, 0.002499834103269353, 0.0015730452265237023, 0.003211147518912502, 0.001811229733458933, 0.003311589294890087, 0.0018487483725362153, 0.0020122776433375, 0.003914796390127995, 0.001681839780508289, 0.0020471875653883128, 0.002938991774268719, 0.0035373606919696793, 0.002556818042018466, 0.0023616004325882852, 0.002207160605068993, 0.0021853994828162932, 0.0038270261364543277, 0.0037560119884416645, 0.0017709332239889896, 0.0022058298410772737, 0.001783708929874504, 0.0018556086033043877, 0.0021727392831517238, 0.0013810679320049757, 0.0015318556044752066, 0.001396057761558601, 0.0016599800751715746, 0.0027225949834637085, 0.0012019017841629542, 0.0014653972522868984, 0.0012393283083367214, 0.0018572103373991685, 0.0015778494770576218, 0.0016202800772120857, 0.0019238283329514703, 0.0017855265685219487, 0.0017247340713785005, 0.0015940417132628915, 0.0014425295172289898, 0.0014900387538063736, 0.0008468725348205056, 0.0010878615667122011, 0.0015874213174736208, 0.0018118266126095758, 0.0014333179880415218], "accuracy_test_std": 0.03162887712439593, "error_valid": [0.488025343561747, 0.4366837467055723, 0.3406202936746988, 0.30014295463102414, 0.2749655849962349, 0.287609422063253, 0.25651090690888556, 0.24273755176957834, 0.2569977174322289, 0.24254341585090367, 0.2241402131965362, 0.21245087772966864, 0.21518790003765065, 0.21503494446536142, 0.21096544380647586, 0.2043839420180723, 0.1946889118975903, 0.1922680958207832, 0.18891189759036142, 0.18636754047439763, 0.18461737575301207, 0.17897125611822284, 0.1760312735316265, 0.17838149472891573, 0.18379376882530118, 0.17780202842620485, 0.18283779649849397, 0.16957184205572284, 0.17953160297439763, 0.15612351750753017, 0.16529938111822284, 0.15609263224774095, 0.17524884695030118, 0.1710778661521084, 0.17651073042168675, 0.1540983269013554, 0.1516878059111446, 0.17054840455572284, 0.16014154273343373, 0.16456695924322284, 0.1587178793298193, 0.17293833537274095, 0.1553307958396084, 0.16098573983433728, 0.1486051628388554, 0.14828013224774095, 0.16025331795933728, 0.14691676863704817, 0.14907285391566272, 0.15140248493975905, 0.14792421639683728, 0.15109804452183728, 0.1464078972138554, 0.16630682887801207, 0.15526902532003017, 0.14215602644954817, 0.14681528849774095, 0.14944935993975905, 0.14886989363704817, 0.13919545368975905, 0.14214573136295183, 0.1387880624058735, 0.15195253670933728, 0.1424104621611446, 0.1547086784638554, 0.14505482868975905, 0.1421354362763554, 0.14186041039156627, 0.13999847044427716, 0.14001906061746983, 0.13528920368975905, 0.14026320124246983, 0.13551275414156627, 0.13487151731927716, 0.1342508706701807, 0.14451654273343373, 0.14222662132906627, 0.13699818806475905, 0.13281691217996983, 0.1305887612951807, 0.14785215079066272, 0.12994899519954817, 0.13511565794427716, 0.13299045792545183, 0.13011077513177716, 0.13930722891566272, 0.14639760212725905, 0.1304666909826807, 0.13503476797816272, 0.1303446206701807, 0.1370084831513554, 0.1334169686558735, 0.1337317041603916, 0.1301725456513554, 0.13680405214608427, 0.12657073606927716, 0.1414030144013554, 0.13943959431475905, 0.12316306240587349, 0.1320536050451807, 0.12373223362198793, 0.14515630882906627, 0.12547210325677716, 0.12588978962725905, 0.12327483763177716, 0.13734380882906627, 0.1275575936558735, 0.13140354386295183, 0.12507500705948793, 0.13194182981927716, 0.13077260212725905, 0.12669280638177716, 0.13147413874246983, 0.1292665780308735, 0.11898178652108427, 0.12747670368975905, 0.12290862669427716, 0.12920627823795183, 0.12673398672816272, 0.12003041462725905, 0.13382435993975905, 0.1280973503388554, 0.12664280167545183, 0.12074224632906627, 0.12350868317018071, 0.16036509318524095, 0.12672369164156627, 0.12592067488704817, 0.1257059487951807, 0.1499082266566265, 0.24098444559487953, 0.12711049275225905, 0.12644866575677716, 0.12023337490587349, 0.12194235928087349, 0.12199383471385539, 0.12297039721385539, 0.12233945547816272, 0.11803610928087349, 0.11714043674698793, 0.11923622223268071, 0.11910385683358427, 0.12293951195406627, 0.12427199030496983, 0.12264389589608427, 0.11861557558358427, 0.11879941641566272, 0.1252897331513554, 0.11544174745858427, 0.12112904743975905, 0.12195265436746983, 0.11947006777108427, 0.11776108339608427, 0.11854498070406627, 0.12306158226656627, 0.1251161874058735, 0.12400725950677716, 0.12134230280496983, 0.11708013695406627, 0.11912444700677716, 0.11971420839608427, 0.12009071442018071, 0.11917592243975905, 0.12005100480045183, 0.12149525837725905, 0.11421074924698793, 0.11967449877635539, 0.11830084007906627, 0.11681540615587349, 0.12085402155496983, 0.13287868269954817, 0.12218649990587349, 0.11766989834337349, 0.11501523672816272, 0.11864646084337349, 0.11394601844879515, 0.11553293251129515, 0.11471962067018071, 0.11632712490587349, 0.11983627870858427, 0.12048781061746983, 0.11962302334337349, 0.11771107868975905, 0.12251153049698793, 0.11532997223268071, 0.1161535791603916, 0.11695806664156627, 0.12048781061746983, 0.12012159967996983, 0.12378370905496983, 0.11911415192018071, 0.11965390860316272, 0.11716102692018071, 0.11049716443900603, 0.11702866152108427, 0.11824936464608427, 0.11154579254518071, 0.11347832737198793, 0.11323418674698793, 0.12135259789156627, 0.12500441217996983, 0.11211496376129515, 0.12191147402108427, 0.11516672157379515, 0.12396754988704817, 0.11656097044427716, 0.12179969879518071, 0.11753753294427716, 0.11574765860316272, 0.11018242893448793, 0.12461761106927716, 0.11508583160768071, 0.11619475950677716, 0.11640801487198793, 0.11787285862198793, 0.11840232021837349, 0.11365187311746983, 0.12073195124246983, 0.11451666039156627, 0.12034515013177716, 0.1134680322853916, 0.12125111775225905, 0.12413962490587349, 0.11876853115587349, 0.11511671686746983, 0.12012159967996983, 0.12158644342996983, 0.11348862245858427, 0.11789344879518071, 0.11967449877635539, 0.11619475950677716, 0.12440435570406627, 0.11935829254518071, 0.11234880929969882, 0.11411956419427716, 0.11559470303087349, 0.11434311464608427, 0.1160315088478916, 0.11416074454066272, 0.11277679075677716, 0.11374305817018071, 0.11557411285768071, 0.12096579678087349, 0.11068100527108427, 0.11082366575677716, 0.11448577513177716, 0.11308123117469882, 0.11228850950677716, 0.11543145237198793, 0.11323418674698793, 0.11657126553087349, 0.11411956419427716, 0.11363128294427716, 0.1135901025978916, 0.11519760683358427, 0.1137121729103916, 0.11129135683358427, 0.11524908226656627, 0.11077219032379515, 0.11484169098268071], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.8865605415350108, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.009807268733365857, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "optimization": "nesterov_momentum", "nb_data_augmentation": 2, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 2.236536110317596e-06, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.07791155077503348}, "accuracy_valid_max": 0.8898175710655121, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8851583090173193, "loss_train": [1.6017695665359497, 1.2414357662200928, 1.0768356323242188, 0.9627177119255066, 0.8755003809928894, 0.8003620505332947, 0.748364269733429, 0.6982613205909729, 0.6564380526542664, 0.6228110790252686, 0.5918318629264832, 0.5652827620506287, 0.5416382551193237, 0.5184685587882996, 0.4998566806316376, 0.48247915506362915, 0.4664163589477539, 0.44840729236602783, 0.43422871828079224, 0.4189368784427643, 0.4058099687099457, 0.39337149262428284, 0.38135284185409546, 0.36992061138153076, 0.355837881565094, 0.34818559885025024, 0.3371768295764923, 0.3266640901565552, 0.31768327951431274, 0.30971378087997437, 0.30378320813179016, 0.29536738991737366, 0.2842269539833069, 0.27945056557655334, 0.27314987778663635, 0.2677755057811737, 0.261872798204422, 0.25554850697517395, 0.24676263332366943, 0.24376323819160461, 0.23578180372714996, 0.23315690457820892, 0.23125629127025604, 0.2256879359483719, 0.21869488060474396, 0.21534422039985657, 0.2134462147951126, 0.20847785472869873, 0.20325332880020142, 0.1999586671590805, 0.19707541167736053, 0.19709104299545288, 0.1886291205883026, 0.18585051596164703, 0.18458504974842072, 0.1811988800764084, 0.1806117296218872, 0.18007872998714447, 0.17478232085704803, 0.1734485626220703, 0.16895867884159088, 0.17066547274589539, 0.16503453254699707, 0.1644682139158249, 0.1610388606786728, 0.16227838397026062, 0.15650838613510132, 0.15451662242412567, 0.1541736125946045, 0.15016616880893707, 0.15035384893417358, 0.15006297826766968, 0.14619693160057068, 0.14435094594955444, 0.14255546033382416, 0.14447887241840363, 0.14466483891010284, 0.1467370092868805, 0.13583871722221375, 0.13834547996520996, 0.13526520133018494, 0.1374160647392273, 0.13636374473571777, 0.13150855898857117, 0.13219724595546722, 0.1326545774936676, 0.1298326849937439, 0.12626338005065918, 0.12843330204486847, 0.1282098889350891, 0.12365051358938217, 0.12435755133628845, 0.1222393587231636, 0.12434076517820358, 0.1215224489569664, 0.12100006639957428, 0.11852926760911942, 0.11975276470184326, 0.12188360840082169, 0.12161819636821747, 0.11561258137226105, 0.11579091101884842, 0.11580482870340347, 0.11425783485174179, 0.11422834545373917, 0.11262748390436172, 0.11437758058309555, 0.1121925637125969, 0.109908826649189, 0.11106477677822113, 0.11014612019062042, 0.11318495124578476, 0.1106845960021019, 0.11173032969236374, 0.10827363282442093, 0.10773821175098419, 0.10830924659967422, 0.10871075838804245, 0.11003807932138443, 0.10824764519929886, 0.10970331728458405, 0.1087137833237648, 0.10281586647033691, 0.10659649968147278, 0.10318698734045029, 0.12674188613891602, 0.16903497278690338, 0.10751675069332123, 0.10375655442476273, 0.10027528554201126, 0.13239890336990356, 0.17816762626171112, 0.11424867063760757, 0.10352678596973419, 0.10076904296875, 0.09774217009544373, 0.09718109667301178, 0.09609691798686981, 0.096221923828125, 0.09595884382724762, 0.09532532840967178, 0.0961424931883812, 0.09968332946300507, 0.09630687534809113, 0.09792590141296387, 0.09699354320764542, 0.09545447677373886, 0.09353151172399521, 0.09474663436412811, 0.09652146697044373, 0.0950326919555664, 0.09378715604543686, 0.09391944110393524, 0.09349114447832108, 0.0936177670955658, 0.09404972195625305, 0.09507695585489273, 0.09456714987754822, 0.0931600034236908, 0.09428862482309341, 0.09481687843799591, 0.09460655599832535, 0.09425994008779526, 0.09425471723079681, 0.09519975632429123, 0.09208656847476959, 0.09008938819169998, 0.09064089506864548, 0.09035144001245499, 0.09046068787574768, 0.09045993536710739, 0.09467155486345291, 0.0914655551314354, 0.09022922068834305, 0.0930832102894783, 0.09166417270898819, 0.0912339985370636, 0.09116272628307343, 0.09478860348463058, 0.09271866083145142, 0.09120959788560867, 0.08837897330522537, 0.09045922011137009, 0.09234914928674698, 0.09094531834125519, 0.09243159741163254, 0.09068317711353302, 0.09080042690038681, 0.0901750773191452, 0.09119042009115219, 0.09038160741329193, 0.09372958540916443, 0.09198389947414398, 0.08990103751420975, 0.08916734904050827, 0.08935662358999252, 0.0871206521987915, 0.08693261444568634, 0.08537540584802628, 0.08906256407499313, 0.0899098664522171, 0.0885220468044281, 0.0873989388346672, 0.08644074201583862, 0.0873238742351532, 0.0886353850364685, 0.08630293607711792, 0.08737272024154663, 0.0889386385679245, 0.0867559015750885, 0.08852989226579666, 0.08727139234542847, 0.08590114861726761, 0.08496694266796112, 0.08615568280220032, 0.08619656413793564, 0.08638565242290497, 0.08724315464496613, 0.08687402307987213, 0.08789239823818207, 0.08625590801239014, 0.08572421222925186, 0.08743815124034882, 0.08952894806861877, 0.08476406335830688, 0.08800522983074188, 0.08618899434804916, 0.09013276547193527, 0.08780018240213394, 0.08571752160787582, 0.08549186587333679, 0.08361238986253738, 0.12438870966434479, 0.09109554439783096, 0.08684933930635452, 0.08503081649541855, 0.0834706649184227, 0.08401376754045486, 0.08212316781282425, 0.08227922022342682, 0.08308134973049164, 0.08324939012527466, 0.08219102025032043, 0.08339403569698334, 0.08278384804725647, 0.08190986514091492, 0.0818362757563591, 0.08160717785358429, 0.08386091887950897, 0.09054356813430786, 0.0842539593577385, 0.08446605503559113, 0.08483558148145676, 0.08261222392320633, 0.08113300800323486, 0.07993004471063614, 0.08030926436185837, 0.0791945680975914, 0.07911168783903122, 0.07978148758411407], "accuracy_train_first": 0.5170772266634367, "model": "residualv3", "loss_std": [0.3104528486728668, 0.12857714295387268, 0.10713054239749908, 0.09853322803974152, 0.09594809263944626, 0.09162948280572891, 0.08888047933578491, 0.08782805502414703, 0.08019711822271347, 0.08257212489843369, 0.08256854861974716, 0.0780705139040947, 0.07749810069799423, 0.07750142365694046, 0.07219316810369492, 0.07089905440807343, 0.07103876769542694, 0.06688674539327621, 0.06501521170139313, 0.06573747098445892, 0.06400991976261139, 0.062119461596012115, 0.05819142982363701, 0.057811375707387924, 0.05350898578763008, 0.056040335446596146, 0.056632235646247864, 0.05121642351150513, 0.05031503364443779, 0.048299409449100494, 0.047974538058042526, 0.04991232603788376, 0.04558459669351578, 0.046287935227155685, 0.04339461401104927, 0.04393911734223366, 0.04273989051580429, 0.04156619310379028, 0.03901291638612747, 0.038631241768598557, 0.038194309920072556, 0.03768504038453102, 0.036699675023555756, 0.03548683971166611, 0.03403301537036896, 0.03583486005663872, 0.03265554830431938, 0.030735773965716362, 0.03145908936858177, 0.031742580235004425, 0.030670925974845886, 0.029207125306129456, 0.028690911829471588, 0.028966346755623817, 0.02885909005999565, 0.02596408687531948, 0.028339970856904984, 0.029044372960925102, 0.027708277106285095, 0.026129329577088356, 0.025572216138243675, 0.026189260184764862, 0.026183566078543663, 0.026278838515281677, 0.025171983987092972, 0.023760788142681122, 0.024710072204470634, 0.023983489722013474, 0.02381758578121662, 0.023064803332090378, 0.021265311166644096, 0.021830659359693527, 0.02197801135480404, 0.02140083909034729, 0.022069105878472328, 0.021778838708996773, 0.02131025120615959, 0.023669082671403885, 0.018955959007143974, 0.02091030962765217, 0.02055181935429573, 0.02164553292095661, 0.019228100776672363, 0.018918441608548164, 0.019751138985157013, 0.019784042611718178, 0.018895959481596947, 0.016874689608812332, 0.01923631690442562, 0.01844329759478569, 0.01690633036196232, 0.01811171881854534, 0.01745973713696003, 0.017054863274097443, 0.017511382699012756, 0.01779094524681568, 0.016641411930322647, 0.015421637333929539, 0.017206605523824692, 0.01684708520770073, 0.015463236719369888, 0.014770225621759892, 0.015307285822927952, 0.015395818278193474, 0.015130947344005108, 0.014726266264915466, 0.015295008197426796, 0.015142404474318027, 0.013770066201686859, 0.014458416029810905, 0.014406627044081688, 0.015439024195075035, 0.013390691950917244, 0.01512464415282011, 0.013894135132431984, 0.014087272807955742, 0.013629662804305553, 0.013461193069815636, 0.014565449208021164, 0.013793876394629478, 0.01412532664835453, 0.014688940718770027, 0.011265329085290432, 0.013887465000152588, 0.013045256026089191, 0.05576449632644653, 0.0907856896519661, 0.01320318877696991, 0.01136066485196352, 0.01168603915721178, 0.07524999976158142, 0.09758761525154114, 0.016674568876624107, 0.011087733320891857, 0.01050191093236208, 0.009584877640008926, 0.009115180931985378, 0.009617996402084827, 0.00962052121758461, 0.010020301677286625, 0.009699353016912937, 0.009219963103532791, 0.011895603500306606, 0.01005118153989315, 0.011100110597908497, 0.010259563103318214, 0.010287071578204632, 0.008672787807881832, 0.009442961774766445, 0.00944621954113245, 0.009891573339700699, 0.010117494501173496, 0.009705225937068462, 0.009525812231004238, 0.009038095362484455, 0.009161768481135368, 0.010468618012964725, 0.009636410512030125, 0.009340429678559303, 0.009488365612924099, 0.009995059110224247, 0.010210887528955936, 0.010507326573133469, 0.009833996184170246, 0.009612859226763248, 0.008566176518797874, 0.00823035929352045, 0.008675441145896912, 0.008343270979821682, 0.008384950459003448, 0.008127760142087936, 0.010790310800075531, 0.009883864782750607, 0.00876530073583126, 0.010187812149524689, 0.008011633530259132, 0.00844426266849041, 0.009130826219916344, 0.010686861351132393, 0.010022125206887722, 0.00920136645436287, 0.007262764498591423, 0.008461489342153072, 0.009675543755292892, 0.00856515858322382, 0.010339343920350075, 0.010070555843412876, 0.010309482924640179, 0.008450494147837162, 0.009203244931995869, 0.009121173061430454, 0.010856871493160725, 0.010325166396796703, 0.009771263226866722, 0.008526301942765713, 0.00851540919393301, 0.00700136786326766, 0.007519010454416275, 0.006757108028978109, 0.009529249742627144, 0.008709313347935677, 0.00892984215170145, 0.007734333164989948, 0.007388394791632891, 0.008148081600666046, 0.00795806385576725, 0.007018556352704763, 0.009026061743497849, 0.008812177926301956, 0.008026204071938992, 0.009361627511680126, 0.00835880171507597, 0.0075555965304374695, 0.006742381490767002, 0.007428298704326153, 0.00802255142480135, 0.008165871724486351, 0.00868014432489872, 0.007892854511737823, 0.009437263943254948, 0.007457320112735033, 0.0073073860257864, 0.008738980628550053, 0.010396288707852364, 0.007172135170549154, 0.00935438834130764, 0.008272322826087475, 0.011199402622878551, 0.008692079223692417, 0.008158489130437374, 0.00794208887964487, 0.00847536325454712, 0.036797475069761276, 0.009649252519011497, 0.009280003607273102, 0.00760595453903079, 0.005830166395753622, 0.00671013118699193, 0.00565160159021616, 0.0064726523123681545, 0.006525608245283365, 0.006481746677309275, 0.006040510255843401, 0.007044168189167976, 0.006743020378053188, 0.00555012933909893, 0.006540399976074696, 0.00596047006547451, 0.007658712100237608, 0.01270986720919609, 0.00753389298915863, 0.007515995763242245, 0.008364134468138218, 0.006027427967637777, 0.0056510563008487225, 0.005128346383571625, 0.005107466131448746, 0.004422515165060759, 0.004550528712570667, 0.005352305248379707]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:11 2016", "state": "available"}], "summary": "6e4c583cccb71ed6f74def30e14da20e"}