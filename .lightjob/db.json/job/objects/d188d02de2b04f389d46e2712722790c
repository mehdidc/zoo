{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 32, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.764713168144226, 1.5120441913604736, 1.3714362382888794, 1.2640761137008667, 1.1729227304458618, 1.097258448600769, 1.0305171012878418, 0.9796827435493469, 0.9354891777038574, 0.8976616263389587, 0.8663022518157959, 0.8389900326728821, 0.8161947131156921, 0.7945903539657593, 0.7755563855171204, 0.7561439275741577, 0.7398251891136169, 0.7238857746124268, 0.7098932266235352, 0.6980834007263184, 0.68519127368927, 0.6722174286842346, 0.6591652631759644, 0.6458352208137512, 0.638269305229187, 0.6268012523651123, 0.6167107224464417, 0.606945276260376, 0.5988274216651917, 0.5874356031417847, 0.577642023563385, 0.5736897587776184, 0.5608635544776917, 0.557626485824585, 0.5491371154785156, 0.5417658686637878, 0.5327443480491638, 0.527052104473114, 0.5190050005912781, 0.5165301561355591, 0.5098206400871277, 0.5046079158782959, 0.4973565340042114, 0.49172908067703247, 0.4868384599685669, 0.4810802638530731, 0.47781503200531006, 0.4719831347465515, 0.46948131918907166, 0.4644603133201599, 0.46152934432029724, 0.4553505778312683, 0.4510606527328491, 0.44779783487319946, 0.44589242339134216, 0.44087570905685425, 0.43983715772628784, 0.4349711537361145, 0.4327528178691864, 0.4297855496406555, 0.42730748653411865, 0.42315858602523804, 0.42237362265586853, 0.4181120991706848, 0.41506102681159973, 0.4145220220088959, 0.41333502531051636, 0.4113861322402954, 0.40844249725341797, 0.40619081258773804, 0.40585508942604065, 0.4030820429325104, 0.40079960227012634, 0.39864644408226013, 0.3967501223087311, 0.3960813581943512, 0.39395463466644287, 0.39352115988731384, 0.3923467695713043, 0.39047518372535706, 0.3888973593711853, 0.38674888014793396, 0.3869260549545288, 0.3861968517303467, 0.38340139389038086, 0.3825578987598419, 0.38135087490081787, 0.38227275013923645, 0.38178789615631104, 0.3798070549964905, 0.37923872470855713, 0.3777901530265808, 0.37714505195617676, 0.3753511905670166, 0.37705451250076294, 0.37529510259628296, 0.3745228946208954, 0.37625372409820557, 0.3741776943206787, 0.37217310070991516, 0.3712330162525177, 0.37212416529655457, 0.3696911931037903, 0.3708816170692444, 0.36951372027397156, 0.37032419443130493, 0.3685954511165619, 0.37001800537109375, 0.3708173632621765, 0.36733028292655945, 0.3670734763145447, 0.36842331290245056, 0.3681316077709198, 0.36606818437576294, 0.36745503544807434, 0.36585649847984314, 0.36439549922943115, 0.36494526267051697, 0.36574751138687134, 0.36499467492103577, 0.36358070373535156, 0.36358383297920227, 0.36470431089401245, 0.36322423815727234, 0.36381587386131287, 0.36445316672325134, 0.36392441391944885, 0.3639971911907196, 0.3637455701828003, 0.362398236989975, 0.3624437153339386, 0.3611828088760376, 0.3626415431499481, 0.36393052339553833, 0.36148548126220703, 0.3639889657497406, 0.36061692237854004, 0.36148449778556824, 0.36308276653289795, 0.362001895904541, 0.3616064488887787, 0.3627050220966339, 0.3601573705673218, 0.36240115761756897, 0.35986194014549255, 0.3609568774700165, 0.36191704869270325, 0.36035674810409546, 0.35920777916908264, 0.3621208369731903, 0.3608653247356415, 0.3587401509284973, 0.36102890968322754, 0.3597598671913147, 0.36047548055648804, 0.3585982918739319, 0.3616119623184204, 0.36076533794403076, 0.36004742980003357, 0.3585048317909241, 0.3602677583694458, 0.359437495470047, 0.35984179377555847, 0.3585245907306671, 0.3611198663711548, 0.36028853058815, 0.35932624340057373, 0.35878056287765503, 0.35961246490478516, 0.35828831791877747, 0.35878437757492065, 0.36065900325775146, 0.3591889441013336, 0.36081641912460327, 0.35831138491630554, 0.3591262102127075, 0.3603211045265198, 0.35905060172080994, 0.3592972755432129, 0.3569815456867218, 0.3602670729160309, 0.36073264479637146, 0.35970667004585266, 0.35930731892585754, 0.3602127432823181, 0.3592873811721802, 0.35947251319885254, 0.35845544934272766, 0.35998520255088806, 0.35820290446281433, 0.3582671880722046, 0.359346479177475, 0.3607242703437805, 0.3581724762916565, 0.3572619557380676], "moving_avg_accuracy_train": [0.04396093966292911, 0.09053946156042356, 0.14061480665576548, 0.19002055184613206, 0.23849395462571227, 0.2850374300045493, 0.32949777589182966, 0.37212036342238647, 0.41151313036895365, 0.4480405149314953, 0.4809316173235433, 0.5124467743607994, 0.5406944466444039, 0.56673558894125, 0.5909936108310859, 0.6138485715687599, 0.6351920944933254, 0.6542943082801962, 0.6726719102883246, 0.6895953295515741, 0.7048799574087551, 0.719265949417049, 0.7324622773424077, 0.7446784442014209, 0.7559682882733423, 0.7664521633785016, 0.7763991837112403, 0.785937439510705, 0.7946125505337948, 0.8025223849045571, 0.8101247946929866, 0.8173832011882967, 0.8238088462376564, 0.8301383007034995, 0.8360814557406615, 0.8416581959062595, 0.8467722687171193, 0.8516144966719117, 0.8561097577086242, 0.8601229045095133, 0.8642601481636285, 0.8680231589332753, 0.8712169894212232, 0.8744191386472441, 0.8775221062828427, 0.8804215898048445, 0.8832800600925402, 0.8860270695121806, 0.8886225748279429, 0.8908235988835391, 0.8931230659204805, 0.8953762730096801, 0.8975551498673038, 0.8995652195058964, 0.9016414940496312, 0.9034754801997622, 0.9052329524824807, 0.9068843238547568, 0.9084032183195949, 0.9098097508677111, 0.91121274184314, 0.9125337066365392, 0.9140060989100853, 0.9153405886003337, 0.9164183603858337, 0.9176766013475272, 0.9188022230107165, 0.9199662369361121, 0.9210371370058823, 0.9219753704317706, 0.9228989797698689, 0.9238556420145967, 0.9247353473717842, 0.925659579626577, 0.9264774017142146, 0.9271599271216506, 0.9277836087300375, 0.9284845032037946, 0.9290988879932343, 0.929626293715644, 0.9302288060015177, 0.9308246536278795, 0.931337628954691, 0.9318179079392975, 0.9322804580576047, 0.9326244572580734, 0.933101611448056, 0.9334890893940126, 0.9339494987858683, 0.9342964018742435, 0.9346527564323434, 0.9350269539572522, 0.9354311970939652, 0.9357300198967964, 0.9361244463574212, 0.9363980139148315, 0.936667476204596, 0.936898438618974, 0.9371807456026378, 0.9374812167176694, 0.9376587429152731, 0.9379719402657262, 0.9381980143097054, 0.938499101150468, 0.9387398884214493, 0.9390611565641235, 0.9392897719258451, 0.9395467150740228, 0.939815202337154, 0.9399870503608675, 0.940185963507228, 0.9403649492901339, 0.9405120135042546, 0.9407049333124671, 0.9408552736029442, 0.9410115062036594, 0.9411847397252738, 0.9413615401851938, 0.9415904150634076, 0.9417707897680765, 0.9418751064284966, 0.9419386923907134, 0.9420238215424227, 0.9421422183598951, 0.9422371858003914, 0.9423668703730378, 0.9424742137955439, 0.9425639195270084, 0.9426423655853355, 0.9427315321794875, 0.9428024454701673, 0.9428779292246456, 0.9429760554893811, 0.9430225524978905, 0.9431481051626917, 0.9432238641312416, 0.943315262642213, 0.9433348143818677, 0.9433849269820715, 0.9435067582329693, 0.9435583136873578, 0.9436070026962983, 0.9436554370531449, 0.9436920525278785, 0.9436622634861003, 0.9437331095984998, 0.9438062077437163, 0.9438324685446492, 0.9438769575071371, 0.9438682415460136, 0.9438836486690977, 0.943899840228683, 0.9439074011370624, 0.9438840511177176, 0.9439420190621935, 0.9439686496241358, 0.9439809913858362, 0.9439990744177952, 0.9440060125025014, 0.944026243720413, 0.9440281397260479, 0.9440089197918338, 0.9439985972974695, 0.9440451106239702, 0.9440567096344783, 0.9440602093463258, 0.9440703345334172, 0.9440980483922755, 0.9440880775842864, 0.9440930907987721, 0.9441069032870474, 0.9441286351217332, 0.944155169219379, 0.9441627738655937, 0.9441743043936246, 0.9442102224569384, 0.9442193332746444, 0.944241447854618, 0.9442218234468325, 0.9442367135631589, 0.9442129122869002, 0.9441961414358864, 0.9442136358021261, 0.9442688722126851, 0.9442697208083694, 0.9442844354373423, 0.9443023649498558, 0.9442301098075372, 0.9442208837508791, 0.9442660947713246, 0.9442649320111541, 0.9442615964270099, 0.9442864961869945, 0.9443204956662093, 0.9443231934117885], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04282608951430722, 0.08962696489081323, 0.13952789674322286, 0.18894739504894575, 0.23652464702560239, 0.28241034473832827, 0.3263747825442394, 0.36792134514071906, 0.40640291285744534, 0.44228041148133934, 0.4747309106664132, 0.505000430669049, 0.5317597178920537, 0.556855377550514, 0.5802034547239264, 0.601615438176609, 0.621720419443662, 0.6391770484330307, 0.6563559467994415, 0.6716959145253708, 0.6860542904109361, 0.6993206846002642, 0.7110436542614726, 0.7217561068887892, 0.7318704470188109, 0.7409468800560111, 0.7494411415986028, 0.7573168810720257, 0.7648161146986333, 0.7713854080198091, 0.7781787372761867, 0.7844137744107669, 0.7898014632347504, 0.7947592169489259, 0.799450040359455, 0.8037888512707986, 0.807873798033779, 0.8117873312575095, 0.8154193744401169, 0.8183321503808944, 0.8215894438612538, 0.8243379025248272, 0.8270221233792723, 0.8292506986448842, 0.8313540726339349, 0.8333468244913997, 0.8354597429929375, 0.8371203175453003, 0.8389026558491286, 0.8404264586471224, 0.8418700938441571, 0.8432171641378288, 0.8442890730064254, 0.8453688018127106, 0.8466519105715751, 0.8473904928107278, 0.8482790614231037, 0.8490798026829017, 0.8498768005301989, 0.8507354354244682, 0.8514624672302894, 0.8522988718156188, 0.853272392013575, 0.8542838670441453, 0.8549347583894294, 0.8554605549525949, 0.8564638217464919, 0.8569312796979722, 0.8575412743750124, 0.8581970443396195, 0.8586550189813353, 0.8591474978343314, 0.8596416159443471, 0.8601138248318401, 0.8602204005094242, 0.8605604592442498, 0.8607434122844333, 0.8610444063816677, 0.86131118303454, 0.8615014243884656, 0.861798829954137, 0.8621641512132414, 0.8625295614401853, 0.8626865026982752, 0.8628298088478753, 0.8629933464589462, 0.8632280385449793, 0.8633161616012495, 0.8633598807668021, 0.8633971689984804, 0.8634073438531504, 0.8635375420261938, 0.8637157555381828, 0.8639026207787922, 0.8640066758131117, 0.864028112665159, 0.8642060972382516, 0.8642818636439444, 0.8643856449941584, 0.8645177283204203, 0.8646477808366464, 0.8645674565839305, 0.8644097155377363, 0.8643287837524114, 0.8644258140744594, 0.8645141708729623, 0.8646170765454553, 0.8646629225430181, 0.8648018401908247, 0.8649146590426007, 0.864955160852949, 0.8649905829736029, 0.8650011373456703, 0.864983133692052, 0.8651022372562053, 0.8650232364692142, 0.8649908158719916, 0.8650715006157412, 0.8649223313052967, 0.8649742729206255, 0.8648714474734424, 0.8648897973608873, 0.8647710054071781, 0.8647638079161591, 0.8647573301742421, 0.8648990140901763, 0.8648291580971978, 0.8648151158285172, 0.864914400085274, 0.8649416912514454, 0.8649662533009996, 0.8649649745917581, 0.8649373506736215, 0.8650010268920274, 0.8649575907126138, 0.8649662967674819, 0.8650870840240922, 0.8651581419526317, 0.8651610589320674, 0.8651270631198095, 0.865170738584937, 0.865172395901142, 0.8649887229996573, 0.8650818240618905, 0.8652042951289695, 0.8651527391571117, 0.8650941317511897, 0.8651034497507695, 0.8650253572229817, 0.8650039020729726, 0.8649845924379644, 0.8650170714001169, 0.8649964448323942, 0.8650531821262633, 0.8650655655796761, 0.8651275978300669, 0.8651345987304186, 0.8650167702109159, 0.8649717596996135, 0.8648569785432817, 0.8648147106588331, 0.8648652073075581, 0.8648607966577511, 0.8648202059791747, 0.8647958813997061, 0.8647739892781843, 0.8647054582438147, 0.8647536435941321, 0.8648590750743274, 0.8648064495228435, 0.8648201216827579, 0.8649056688141809, 0.8647985262550519, 0.8648119612330859, 0.864812875190726, 0.8649357680651022, 0.8649243013395408, 0.8649750164427855, 0.8649219742770462, 0.8649617445639499, 0.8649100295860941, 0.8649509943420931, 0.8649369754801729, 0.8648267022544448, 0.8648261421099491, 0.864813430948653, 0.8647775768409864, 0.8647819292378366, 0.8647858463950017, 0.8648504069927002, 0.864884097468129, 0.8648411767085148, 0.864875790212362, 0.864857084732165, 0.8649267285273974], "moving_var_accuracy_train": [0.01739307794442925, 0.03517979846938466, 0.05422968030020445, 0.0707750611905229, 0.08484459206475335, 0.0958567887613417, 0.10406161109295703, 0.11000561469386111, 0.112971164013834, 0.1136822960192689, 0.11205048796641964, 0.10978428527752397, 0.10598723565474881, 0.1014917819183952, 0.09663866836062548, 0.09167594459744852, 0.08660826387518675, 0.08123148863170196, 0.07614796606865425, 0.07111078853782633, 0.06610228832263634, 0.06135467038493698, 0.056786490982865666, 0.052450954479124366, 0.04835300424372662, 0.04450690855433917, 0.04094670662040449, 0.03767084087162825, 0.03458107474583182, 0.031686056589204675, 0.02903762064160508, 0.026608018761105006, 0.024318817113697752, 0.022247493346844605, 0.02034063383832185, 0.018586470732361006, 0.01696320732555789, 0.015477911137097653, 0.014111986369481556, 0.012845735857742784, 0.011715213337450146, 0.010671134254177428, 0.009695825807431393, 0.00881852706367961, 0.0080233300306398, 0.00729666006982506, 0.006640531734313305, 0.006044393107646313, 0.005500583627479039, 0.004994125826770956, 0.004542301181979681, 0.004133763543463088, 0.0037631147283629734, 0.003423166675094603, 0.0031196482514137948, 0.002837954973062267, 0.0025819578551767542, 0.0023483053163416367, 0.0021342381482653155, 0.0019386193377189758, 0.0017624728570412942, 0.001601930103205766, 0.0014612485439499752, 0.0013311514541553906, 0.0012084906369344312, 0.0011018901061001381, 0.0010031043126478944, 0.0009149882371497405, 0.0008338108560696691, 0.0007583523081157895, 0.0006901945651890123, 0.0006294119325244992, 0.0005734356729112277, 0.0005237799529672992, 0.00047742145437382075, 0.0004338718773226004, 0.0003939854983280999, 0.00035900822606537846, 0.00032650462148429396, 0.00029635757050013896, 0.0002699890029417846, 0.0002461854121921741, 0.00022393516414621336, 0.00020361765885908454, 0.00018518146648069045, 0.00016772833888192975, 0.00015300459008289852, 0.0001390553835020339, 0.00012705763642481058, 0.00011543494855684748, 0.00010503435084086948, 9.579112984561403e-05, 8.768272948326831e-05, 7.971811214236878e-05, 7.314645102370177e-05, 6.650535879753875e-05, 6.050831224823123e-05, 5.493757375510584e-05, 5.0161091476822885e-05, 4.595752834785519e-05, 4.164541547059027e-05, 3.836370714650901e-05, 3.498732169210831e-05, 3.230446909402098e-05, 2.959582877341828e-05, 2.7565164871552376e-05, 2.5279033236933245e-05, 2.3345307945799463e-05, 2.1659545845392314e-05, 1.975937695014133e-05, 1.813953721328304e-05, 1.6613906686296475e-05, 1.514716696534102e-05, 1.396741274041333e-05, 1.2774091292838874e-05, 1.1716359793291041e-05, 1.0814812491060602e-05, 1.00146568656059e-05, 9.484644567941476e-06, 8.828995417906655e-06, 8.044033566886835e-06, 7.27601878151746e-06, 6.613639655602571e-06, 6.078435947530624e-06, 5.551761685567279e-06, 5.147948312452741e-06, 4.736856974405403e-06, 4.33559534128299e-06, 3.957419863758391e-06, 3.6332340109964556e-06, 3.3151688630522758e-06, 3.0349321514582793e-06, 2.8180978107909433e-06, 2.555745775914657e-06, 2.4420424430713583e-06, 2.249492990606001e-06, 2.0997268818155746e-06, 1.8931946283457304e-06, 1.7264766198038081e-06, 1.6874146410810788e-06, 1.5425948608678749e-06, 1.4096709511055448e-06, 1.289816838303399e-06, 1.172901391382688e-06, 1.0635977353350176e-06, 1.0024105065807134e-06, 9.502595054294275e-07, 8.614402218772305e-07, 7.931096097386989e-07, 7.144823605695782e-07, 6.45170539488187e-07, 5.830129849555895e-07, 5.252261924797242e-07, 4.776105838623949e-07, 4.600920687570369e-07, 4.2046554334561314e-07, 3.7978986074789696e-07, 3.447538390765856e-07, 3.107116883434493e-07, 2.83324239112764e-07, 2.5502416873779783e-07, 2.32846404704818e-07, 2.1052074924343695e-07, 2.0894008019857418e-07, 1.8925690558162294e-07, 1.7044144687059874e-07, 1.5431997690624382e-07, 1.4580050097100838e-07, 1.3211520398150476e-07, 1.1912987445867328e-07, 1.0893395050398966e-07, 1.0229100920289432e-07, 9.83984333234964e-08, 8.907906578758294e-08, 8.136773689886434e-08, 8.484192865890447e-08, 7.710479878645141e-08, 7.379581073453791e-08, 6.988228608948393e-08, 6.488949755844497e-08, 6.349905456647532e-08, 5.96805021033581e-08, 5.646692754418389e-08, 7.827978425263517e-08, 7.045828685908948e-08, 6.536114092548636e-08, 6.171823360367057e-08, 1.0253366056656022e-07, 9.304637560303365e-08, 1.0213806537024121e-07, 9.193642693414361e-08, 8.284291933497676e-08, 8.013860982704845e-08, 8.252843012631573e-08, 7.4341087594572e-08], "duration": 286617.295612, "accuracy_train": [0.4396093966292912, 0.5097461586378738, 0.5912929125138427, 0.6346722585594315, 0.6747545796419343, 0.7039287084140826, 0.7296408888773532, 0.7557236511973976, 0.7660480328880583, 0.7767869759943706, 0.7769515388519748, 0.7960831876961055, 0.7949234971968439, 0.8011058696128645, 0.8093158078396088, 0.8195432182078257, 0.827283800814415, 0.8262142323620341, 0.8380703283614802, 0.8419061029208195, 0.842441608123385, 0.8487398774916944, 0.8512292286706349, 0.8546239459325397, 0.8575768849206349, 0.8608070393249354, 0.8659223667058878, 0.8717817417058878, 0.8726885497416021, 0.8737108942414176, 0.878546482788852, 0.8827088596460871, 0.8816396516818937, 0.8871033908960871, 0.8895698510751201, 0.8918488573966408, 0.8927989240148578, 0.8951945482650425, 0.8965671070390366, 0.8962412257175157, 0.9014953410506644, 0.901890255860096, 0.8999614638127538, 0.9032384816814323, 0.90544881500323, 0.9065169415028608, 0.9090062926818014, 0.9107501542889442, 0.9119821226698044, 0.9106328153839055, 0.9138182692529531, 0.9156551368124769, 0.9171650415859173, 0.91765584625323, 0.9203279649432448, 0.9199813555509413, 0.9210502030269472, 0.9217466662052418, 0.9220732685031378, 0.9224685438007567, 0.9238396606220007, 0.9244223897771319, 0.9272576293720007, 0.9273509958125692, 0.9261183064553341, 0.9290007700027685, 0.9289328179794205, 0.9304423622646733, 0.9306752376338132, 0.9304194712647655, 0.9312114638127538, 0.9324656022171466, 0.932652695586471, 0.9339776699197121, 0.9338378005029531, 0.9333026557885751, 0.9333967432055187, 0.934792553467608, 0.9346283510981912, 0.9343729452173312, 0.9356514165743817, 0.9361872822651348, 0.9359544068959949, 0.9361404188007567, 0.9364434091223699, 0.9357204500622923, 0.9373959991578996, 0.9369763909076227, 0.9380931833125692, 0.9374185296696198, 0.9378599474552418, 0.9383947316814323, 0.9390693853243817, 0.9384194251222776, 0.9396742845030455, 0.9388601219315246, 0.9390926368124769, 0.9389771003483758, 0.939721508455611, 0.9401854567529531, 0.9392564786937062, 0.9407907164198044, 0.9402326807055187, 0.9412088827173312, 0.9409069738602805, 0.9419525698481912, 0.94134731018134, 0.9418592034076227, 0.9422315877053341, 0.9415336825742894, 0.941976181824474, 0.9419758213362864, 0.94183559143134, 0.9424412115863787, 0.9422083362172389, 0.942417599610096, 0.9427438414198044, 0.942952744324474, 0.9436502889673312, 0.943394162110096, 0.9428139563722776, 0.9425109660506644, 0.9427899839078073, 0.9432077897171466, 0.9430918927648578, 0.9435340315268549, 0.9434403045980989, 0.9433712711101883, 0.9433483801102805, 0.9435340315268549, 0.9434406650862864, 0.9435572830149501, 0.9438591918720007, 0.943441025574474, 0.9442780791459026, 0.9439056948481912, 0.944137849240956, 0.9435107800387597, 0.9438359403839055, 0.9446032394910484, 0.9440223127768549, 0.9440452037767626, 0.9440913462647655, 0.9440215918004798, 0.943394162110096, 0.944370724610096, 0.9444640910506644, 0.9440688157530455, 0.9442773581695275, 0.9437897978959026, 0.9440223127768549, 0.9440455642649501, 0.9439754493124769, 0.9436739009436139, 0.9444637305624769, 0.9442083246816169, 0.9440920672411407, 0.9441618217054264, 0.9440684552648578, 0.9442083246816169, 0.9440452037767626, 0.9438359403839055, 0.9439056948481912, 0.9444637305624769, 0.9441611007290514, 0.9440917067529531, 0.9441614612172389, 0.9443474731220007, 0.9439983403123846, 0.9441382097291436, 0.9442312156815246, 0.9443242216339055, 0.9443939760981912, 0.9442312156815246, 0.9442780791459026, 0.9445334850267626, 0.9443013306339978, 0.9444404790743817, 0.9440452037767626, 0.944370724610096, 0.9439987008005721, 0.9440452037767626, 0.9443710850982835, 0.944765999907715, 0.9442773581695275, 0.9444168670980989, 0.9444637305624769, 0.9435798135266703, 0.944137849240956, 0.9446729939553341, 0.9442544671696198, 0.9442315761697121, 0.9445105940268549, 0.9446264909791436, 0.9443474731220007], "end": "2016-02-04 23:39:12.978000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0], "moving_var_accuracy_valid": [0.0165066654877871, 0.034568896363073615, 0.05352293372441573, 0.0701512216670783, 0.08350845365122296, 0.0941070835773536, 0.1020922213439267, 0.10741805098178288, 0.11000372536903749, 0.1105881069997014, 0.10900661037597559, 0.10635214390908775, 0.10216146459232836, 0.09761344733633498, 0.0927582969719621, 0.0876087245931675, 0.0824857445795877, 0.07697977518268115, 0.07193782860616427, 0.06686187723404083, 0.0620311561332774, 0.0574120154530294, 0.052907666066825, 0.04864970923177502, 0.04470543719498942, 0.0409763282055995, 0.037528067697425116, 0.03433350637796168, 0.03140630228504351, 0.028654072589195966, 0.026204009231746362, 0.023933489501198064, 0.021801385268854955, 0.019842460638983254, 0.01805624899350384, 0.016420051615273008, 0.014928227564253162, 0.01357324648846703, 0.012334647478743258, 0.011177541103999482, 0.010155276640954258, 0.009207735202087178, 0.008351807056237398, 0.0075613252800441335, 0.006845010391280057, 0.006196248891840922, 0.005616803824004094, 0.005079941012199282, 0.004600537479442999, 0.004161381506203262, 0.003764000098821994, 0.003403931474324628, 0.0030738792244953505, 0.0027769836307019137, 0.002514102580415395, 0.002267601855889782, 0.0020479476579109025, 0.001848923571206099, 0.0016697480642028561, 0.0015094085427174817, 0.001363224865665815, 0.0012331985327724752, 0.0011184083536776857, 0.0010157752539471203, 0.000918010664442702, 0.0008286977562309615, 0.0007548868789454953, 0.0006813648434785654, 0.0006165772006848644, 0.0005587897888347063, 0.0005047984769033278, 0.0004565014479988291, 0.00041304867755875515, 0.00037375064090372614, 0.000336477802188826, 0.0003038707814581244, 0.00027378494964652326, 0.00024722183170100044, 0.00022314017657356058, 0.00020115188487089522, 0.00018183274701823727, 0.00016485060891759595, 0.0001495672697314333, 0.00013483221778470752, 0.0001215338258788559, 0.00010962114424308328, 9.915475319599405e-05, 8.930916893381217e-05, 8.039545432936062e-05, 7.236842260641976e-05, 6.513251209478578e-05, 5.8771824963681714e-05, 5.318048297001278e-05, 4.817670223634371e-05, 4.345647906421457e-05, 3.9114967005424376e-05, 3.548857687921229e-05, 3.199138412537567e-05, 2.8889180830708247e-05, 2.6157276793325036e-05, 2.369377202678305e-05, 2.1382462694273977e-05, 1.9468156563736717e-05, 1.758029049224583e-05, 1.590699539359193e-05, 1.4386558168807794e-05, 1.3043208548808004e-05, 1.1757804393360041e-05, 1.075570696987314e-05, 9.794689112730229e-06, 8.829983771230658e-06, 7.958277933792164e-06, 7.163452693340587e-06, 6.450024607898977e-06, 5.932693078055085e-06, 5.395593889356365e-06, 4.865494356539174e-06, 4.437535171750756e-06, 4.194045003182374e-06, 3.79892188549078e-06, 3.5141873502372067e-06, 3.1657990805366575e-06, 2.976222926877469e-06, 2.6790668690824416e-06, 2.4115378324373012e-06, 2.351053037503662e-06, 2.159866471548372e-06, 1.9456544921808245e-06, 1.8398053157203173e-06, 1.6625280539072377e-06, 1.5017048970212652e-06, 1.3515491231950585e-06, 1.2232619385545393e-06, 1.1374276918133914e-06, 1.0406652377704904e-06, 9.372808725157441e-07, 9.74858837499005e-07, 9.228160166241236e-07, 8.306109938829614e-07, 7.579513317543643e-07, 6.993241148658416e-07, 6.294164236522906e-07, 8.700963939452975e-07, 8.610970246510741e-07, 9.099797826292419e-07, 8.429039684741249e-07, 7.89527023886874e-07, 7.113557475437137e-07, 6.951061588559196e-07, 6.297384541275081e-07, 5.701203667520711e-07, 5.226022769193054e-07, 4.7417114689148057e-07, 4.557261168425298e-07, 4.1153365442412766e-07, 4.0501228977866e-07, 3.649521742524086e-07, 4.5340899690096194e-07, 4.263016123602241e-07, 5.02243875764062e-07, 4.6809865468954104e-07, 4.4423799301280305e-07, 3.99989278197004e-07, 3.748187790628738e-07, 3.42662067653541e-07, 3.127092457507205e-07, 3.237068452216026e-07, 3.12232612566266e-07, 3.81051524455025e-07, 3.678714100304271e-07, 3.3276662063792026e-07, 3.653547638264735e-07, 4.321350392340849e-07, 3.9054602302363475e-07, 3.514989385883841e-07, 4.522729718815273e-07, 4.0822904684928444e-07, 3.905543374384534e-07, 3.768201458115384e-07, 3.533732127140878e-07, 3.421058418543421e-07, 3.229982587754395e-07, 2.9246718930372107e-07, 3.7266212918573717e-07, 3.353987401238679e-07, 3.0331302870494524e-07, 2.845513791635033e-07, 2.562667314722237e-07, 2.3077815540730877e-07, 2.4521297684341776e-07, 2.3090711237062549e-07, 2.2439612558622613e-07, 2.1273936486489757e-07, 1.9461448328302717e-07, 2.1880535888393328e-07], "accuracy_test": 0.8617586096938776, "start": "2016-02-01 16:02:15.683000", "learning_rate_per_epoch": [0.007088458631187677, 0.006765610072761774, 0.006457465700805187, 0.006163355894386768, 0.005882641766220331, 0.005614712834358215, 0.005358987022191286, 0.005114908330142498, 0.004881946370005608, 0.004659594967961311, 0.0044473703019320965, 0.004244811832904816, 0.004051479045301676, 0.0038669516798108816, 0.003690828802064061, 0.003522727405652404, 0.0033622824121266603, 0.003209145041182637, 0.0030629823449999094, 0.002923476742580533, 0.0027903250884264708, 0.002663237741217017, 0.0025419387966394424, 0.0024261644575744867, 0.00231566303409636, 0.0022101944778114557, 0.002109529683366418, 0.002013449789956212, 0.0019217458320781589, 0.0018342186231166124, 0.0017506778240203857, 0.0016709419433027506, 0.0015948377549648285, 0.0015221997164189816, 0.0014528700849041343, 0.0013866981025785208, 0.0013235399965196848, 0.0012632583966478705, 0.0012057224521413445, 0.0011508070165291429, 0.0010983927641063929, 0.001048365724273026, 0.0010006171651184559, 0.0009550433605909348, 0.0009115452412515879, 0.0008700282778590918, 0.0008304022485390306, 0.0007925810059532523, 0.0007564823608845472, 0.000722027849406004, 0.0006891426164656878, 0.000657755124848336, 0.000627797213383019, 0.0005992037476971745, 0.000571912620216608, 0.0005458644591271877, 0.0005210026865825057, 0.0004972732858732343, 0.0004746246268041432, 0.0004530075239017606, 0.0004323749744798988, 0.0004126821586396545, 0.00039388626464642584, 0.00037594643072225153, 0.00035882368683815, 0.00034248080919496715, 0.0003268822911195457, 0.0003119941975455731, 0.00029778419411741197, 0.00028422140167094767, 0.00027127633802592754, 0.00025892085977829993, 0.0002471281331963837, 0.00023587251780554652, 0.00022512953728437424, 0.00021487585036084056, 0.00020508917805273086, 0.00019574824545998126, 0.0001868327526608482, 0.00017832333105616271, 0.00017020147060975432, 0.00016244953440036625, 0.0001550506567582488, 0.00014798877236898988, 0.00014124851441010833, 0.00013481525820679963, 0.0001286750048166141, 0.0001228144101332873, 0.00011722074123099446, 0.00011188183998456225, 0.00010678610124159604, 0.00010192245099460706, 9.728032455313951e-05, 9.28496228880249e-05, 8.862071990733966e-05, 8.458442607661709e-05, 8.073196659097448e-05, 7.705497409915552e-05, 7.354545232374221e-05, 7.01957760611549e-05, 6.699866207782179e-05, 6.394716183422133e-05, 6.10346432949882e-05, 5.825478001497686e-05, 5.5601525673409924e-05, 5.3069114073878154e-05, 5.065204459242523e-05, 4.83450639876537e-05, 4.61431554867886e-05, 4.4041535147698596e-05, 4.203563366900198e-05, 4.012109275208786e-05, 3.829375054920092e-05, 3.654963438748382e-05, 3.488495713099837e-05, 3.3296098990831524e-05, 3.1779603887116536e-05, 3.0332179449032992e-05, 2.8950678824912757e-05, 2.763210068223998e-05, 2.6373578293714672e-05, 2.5172375899273902e-05, 2.402588324912358e-05, 2.293160832778085e-05, 2.1887171897105873e-05, 2.0890305677312426e-05, 1.9938841433031484e-05, 1.903071279230062e-05, 1.8163946151616983e-05, 1.7336657037958503e-05, 1.654704647080507e-05, 1.5793399143149145e-05, 1.5074077964527532e-05, 1.4387518604053184e-05, 1.3732229490415193e-05, 1.310678544541588e-05, 1.2509827683970798e-05, 1.1940059266635217e-05, 1.1396241461625323e-05, 1.087719192582881e-05, 1.0381782885815483e-05, 9.908937499858439e-06, 9.457628038944677e-06, 9.026874067785684e-06, 8.615738806838635e-06, 8.22332913230639e-06, 7.848791938158683e-06, 7.4913132266374305e-06, 7.1501162892673165e-06, 6.8244594331190456e-06, 6.513634616567288e-06, 6.216966539795976e-06, 5.933810371061554e-06, 5.663550837198272e-06, 5.405600404628785e-06, 5.159398824616801e-06, 4.924410404782975e-06, 4.700124918599613e-06, 4.4860544221592136e-06, 4.281734163669171e-06, 4.086719400220318e-06, 3.900586762028979e-06, 3.7229317513265414e-06, 3.553368287612102e-06, 3.391527570784092e-06, 3.237058081140276e-06, 3.0896239877620246e-06, 2.948904921140638e-06, 2.8145950636826456e-06, 2.6864024675887777e-06, 2.564048372732941e-06, 2.4472669792885426e-06, 2.3358045382337878e-06, 2.229418669230654e-06, 2.1278783606248908e-06, 2.0309626052039675e-06, 1.9384610823180992e-06, 1.8501725662645185e-06, 1.7659051536611514e-06, 1.685475808699266e-06, 1.6087096810224466e-06, 1.5354398783529177e-06, 1.4655072391178692e-06, 1.3987596503284294e-06, 1.3350521612665034e-06, 1.2742463013637462e-06, 1.2162098528278875e-06, 1.1608167369558942e-06, 1.107946559386619e-06, 1.0574843827271252e-06, 1.0093204991790117e-06, 9.633503168515745e-07, 9.194738481710374e-07, 8.775957667239709e-07, 8.376250661967788e-07], "accuracy_train_first": 0.4396093966292912, "accuracy_train_last": 0.9443474731220007, "batch_size_eval": 1024, "accuracy_train_std": [0.024299071039236918, 0.023266652777982903, 0.02244428138348658, 0.022751169494497056, 0.021063757908928515, 0.020706396531451985, 0.02043164469455625, 0.02058853501682779, 0.017465301417099437, 0.018786031602605606, 0.019305639062808445, 0.018238059862232227, 0.01747460345370155, 0.018950082990826362, 0.016263477740338133, 0.01682674969240507, 0.0169692080518265, 0.01670649295515137, 0.01630557147768158, 0.016254934067563002, 0.016469960689216776, 0.018128185432796363, 0.017031317801186267, 0.01619633563843718, 0.01502446000122393, 0.016220484810596996, 0.01516298941069509, 0.013733589595561618, 0.013881458840656096, 0.015239231279956538, 0.01420108098398668, 0.013672775940088575, 0.01415038116413768, 0.014556461344794595, 0.012446993054831738, 0.013495166865130711, 0.01457597909904267, 0.01384112156930605, 0.012263137033787798, 0.01277888630129003, 0.012631076425870722, 0.012029408894615855, 0.012199041137648832, 0.011866532733677477, 0.010724461818524938, 0.012797542760721967, 0.011165003527094562, 0.009617596064497637, 0.010812513428279527, 0.010997072205630534, 0.010204998195416369, 0.011057122986469138, 0.00947897146438365, 0.010005853315394615, 0.010122320852943192, 0.009157644471074925, 0.010338226997826697, 0.009226181567647757, 0.009221737963986914, 0.008465885169911579, 0.008856147631876733, 0.009777773754677659, 0.008268795169873546, 0.00924850968313996, 0.008105146359358526, 0.007719830691197362, 0.008927967394302157, 0.008682864670794236, 0.008525303875767765, 0.008782921263605938, 0.008334472888014047, 0.008504064627335679, 0.007913968294965715, 0.007970490526382521, 0.008280366052067306, 0.00848042685080908, 0.007835091896226654, 0.007832173501962471, 0.008152527808439393, 0.00799147653104223, 0.007397097303724762, 0.007854373489410893, 0.00806682263620819, 0.008437999239169963, 0.008537731494578633, 0.008200288481691681, 0.00793160532574777, 0.008562779135111172, 0.0071186092110795485, 0.0076032743176021565, 0.0078029720276158255, 0.00845042660489004, 0.008115822292218326, 0.007814757650655386, 0.008420975621506824, 0.008202093556138195, 0.007431992511049652, 0.007499564025561816, 0.007650145358548791, 0.0070576207885132275, 0.007174513651626457, 0.007360799246452422, 0.006912223071222321, 0.007430263272080902, 0.007544681674906871, 0.007540568085791495, 0.007538957900455514, 0.006967981150379649, 0.007359441820420361, 0.006668797578877919, 0.007112383311214331, 0.007192026930823424, 0.007029341545548938, 0.007834193710086304, 0.007304730130293832, 0.007093865827271763, 0.006875762920838774, 0.007860011975746196, 0.006974618597968965, 0.006847950216098464, 0.007093767323637402, 0.00717525170803716, 0.006682750304781598, 0.006776510924748869, 0.006857728803413142, 0.006931157277987762, 0.006867581925531899, 0.007286250614955708, 0.007091462055184288, 0.007226267569036993, 0.006686493641523544, 0.006692177863008751, 0.006368709837928686, 0.006451056068338743, 0.006581937816166313, 0.0067895230494577465, 0.006401437514303273, 0.006750815559058496, 0.0067427792177169425, 0.00640579366495126, 0.006493049019138078, 0.006893125901840207, 0.006640129340674144, 0.006423350057348471, 0.007294301740092649, 0.006859558579178899, 0.006959921390072627, 0.006735399497596451, 0.006340092628786546, 0.006633503251344992, 0.006658792125743116, 0.006502865681603726, 0.006629498224220157, 0.00657585202141536, 0.006363877901925267, 0.00622819140973888, 0.006574219895864216, 0.006417416090623975, 0.006393367685878112, 0.006180614728441421, 0.00645773278131039, 0.006453710120020151, 0.0066064603120031965, 0.006259549754792143, 0.0063932417954203425, 0.0066296629014188785, 0.006509183754177885, 0.0064131284326073, 0.006508216910396187, 0.006408318543969258, 0.006728497450411674, 0.006397175417329567, 0.006584088468149992, 0.00650195476783095, 0.006512575846941051, 0.006281278061164356, 0.0066898854134023805, 0.00621447519708513, 0.006793584681008989, 0.0063686321872979245, 0.006473034488910697, 0.006478795493834244, 0.006117215011929237, 0.006458747382799832, 0.006502751373468775, 0.006121182297444092, 0.0064454202649936645, 0.006500956872053296, 0.006257945329106734, 0.006322202295706021, 0.006148703796157365, 0.006385235329049581, 0.006290538686185234, 0.006328099292864834, 0.006549757685431625], "accuracy_test_std": 0.008554405717670483, "error_valid": [0.5717391048569277, 0.48916515672063254, 0.4113637165850903, 0.36627712019954817, 0.33528008518448793, 0.3046183758471386, 0.27794527720256024, 0.2581595914909638, 0.2472629776920181, 0.23482210090361444, 0.23321459666792166, 0.22257388930722888, 0.22740669710090367, 0.21728368552334332, 0.20966385071536142, 0.20567671074924698, 0.19733474915286142, 0.20371329066265065, 0.18903396790286142, 0.1902443759412651, 0.18472032661897586, 0.1812817676957832, 0.18344961878765065, 0.18183181946536142, 0.17710049181099397, 0.17736522260918675, 0.1741105045180723, 0.17180146366716864, 0.16769078266189763, 0.1694909520896084, 0.16068129941641573, 0.15947089137801207, 0.16170933734939763, 0.16062099962349397, 0.1583325489457832, 0.1571618505271084, 0.15536168109939763, 0.15299086972891573, 0.15189223691641573, 0.1554528661521084, 0.14909491481551207, 0.15092596950301207, 0.14881988893072284, 0.1506921239646084, 0.1497155614646084, 0.14871840879141573, 0.14552399049322284, 0.14793451148343373, 0.14505629941641573, 0.14585931617093373, 0.14513718938253017, 0.1446592032191265, 0.14606374717620485, 0.14491363893072284, 0.1418001105986446, 0.14596226703689763, 0.14372382106551207, 0.14371352597891573, 0.1429502188441265, 0.1415368505271084, 0.1419942465173193, 0.14017348691641573, 0.1379659262048193, 0.13661285768072284, 0.13920721950301207, 0.13980727597891573, 0.13450677710843373, 0.13886159873870485, 0.1369687735316265, 0.13590102597891573, 0.13722320924322284, 0.13642019248870485, 0.13591132106551207, 0.13563629518072284, 0.1388204183923193, 0.1363790121423193, 0.13761001035391573, 0.13624664674322284, 0.1362878270896084, 0.13678640342620485, 0.1355245199548193, 0.1345479574548193, 0.1341817465173193, 0.13590102597891573, 0.13588043580572284, 0.13553481504141573, 0.13465973268072284, 0.1358907308923193, 0.13624664674322284, 0.13626723691641573, 0.1365010824548193, 0.13529067441641573, 0.13468032285391573, 0.13441559205572284, 0.13505682887801207, 0.13577895566641573, 0.13419204160391573, 0.1350362387048193, 0.13468032285391573, 0.13429352174322284, 0.1341817465173193, 0.13615546169051207, 0.13700995387801207, 0.13639960231551207, 0.1347009130271084, 0.13469061794051207, 0.1344567724021084, 0.13492446347891573, 0.13394790097891573, 0.13406997129141573, 0.13468032285391573, 0.13469061794051207, 0.13490387330572284, 0.13517889919051207, 0.13382583066641573, 0.13568777061370485, 0.13530096950301207, 0.13420233669051207, 0.13642019248870485, 0.13455825254141573, 0.13605398155120485, 0.1349450536521084, 0.13629812217620485, 0.13530096950301207, 0.13530096950301207, 0.13382583066641573, 0.1357995458396084, 0.1353112645896084, 0.13419204160391573, 0.13481268825301207, 0.13481268825301207, 0.13504653379141573, 0.1353112645896084, 0.1344258871423193, 0.1354333349021084, 0.13495534873870485, 0.13382583066641573, 0.13420233669051207, 0.13481268825301207, 0.13517889919051207, 0.13443618222891573, 0.13481268825301207, 0.13666433311370485, 0.13408026637801207, 0.1336934652673193, 0.1353112645896084, 0.1354333349021084, 0.13481268825301207, 0.1356774755271084, 0.1351891942771084, 0.1351891942771084, 0.13469061794051207, 0.1351891942771084, 0.13443618222891573, 0.1348229833396084, 0.13431411191641573, 0.13480239316641573, 0.1360436864646084, 0.1354333349021084, 0.13617605186370485, 0.13556570030120485, 0.13468032285391573, 0.13517889919051207, 0.13554511012801207, 0.13542303981551207, 0.13542303981551207, 0.13591132106551207, 0.13481268825301207, 0.13419204160391573, 0.13566718044051207, 0.13505682887801207, 0.13432440700301207, 0.1361657567771084, 0.1350671239646084, 0.13517889919051207, 0.13395819606551207, 0.13517889919051207, 0.13456854762801207, 0.1355554052146084, 0.13468032285391573, 0.1355554052146084, 0.13468032285391573, 0.1351891942771084, 0.1361657567771084, 0.13517889919051207, 0.13530096950301207, 0.13554511012801207, 0.13517889919051207, 0.13517889919051207, 0.13456854762801207, 0.13481268825301207, 0.13554511012801207, 0.13481268825301207, 0.1353112645896084, 0.13444647731551207], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.04554568997381449, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.007426713820663609, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 3.950468499046834e-06, "rotation_range": [0, 0], "momentum": 0.9644556642821462}, "accuracy_valid_max": 0.8663065347326807, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8655535226844879, "accuracy_valid_std": [0.01534512947856443, 0.013968570560914391, 0.012072147170346388, 0.012299942201224765, 0.015204902741049593, 0.012447237068142743, 0.013412644504403102, 0.015597544833241302, 0.016209124424851513, 0.014961411324732965, 0.013990704665028705, 0.012596334820635952, 0.019401075737222263, 0.013038501287961612, 0.013606278845586241, 0.012298713247725399, 0.010980429754654792, 0.012001801419481217, 0.010084158164981642, 0.008234190209448985, 0.01303710610981519, 0.010414266861298758, 0.01547097489845133, 0.013139516068734414, 0.012000100596131503, 0.008828696414833808, 0.012369299083114, 0.011829168876354552, 0.010568071438569453, 0.009266580661275642, 0.008108713343615983, 0.01022552362748595, 0.011999479883818116, 0.014048585495493626, 0.012408658077154657, 0.009917430791688641, 0.014815343203325407, 0.011156880846618344, 0.01101062308443853, 0.010094025095455695, 0.010447917019520891, 0.00798135266722489, 0.009414626683926291, 0.009315275559387017, 0.006981361908546986, 0.008792051558672504, 0.008461122922446445, 0.008858650958597355, 0.009272201659668022, 0.006456260029006525, 0.008584160682990614, 0.005948870803692093, 0.011328534972148701, 0.007709481236779719, 0.008574673810911454, 0.010409917454730083, 0.008768236864304292, 0.00907535548145082, 0.006748478424196464, 0.009290834409933633, 0.007655723058647901, 0.007566090211748257, 0.008769178306386021, 0.0064022513576397645, 0.00935172713490594, 0.006812466835984182, 0.005884635946881475, 0.010751103905707899, 0.007844850471908202, 0.010170574099709347, 0.007741979857845463, 0.012493602553510402, 0.010836662020512536, 0.008097995661697688, 0.006569758034367201, 0.007341703513845201, 0.007694638909012299, 0.006069863885578222, 0.011379559398391095, 0.01120436865477053, 0.008415988842530963, 0.008887452116387508, 0.008715013283931372, 0.008398738810182334, 0.006695313132653713, 0.008503480421023477, 0.006063042413557649, 0.006435020411730328, 0.0059106597733784546, 0.007878002627275829, 0.006076324936272067, 0.008076767902367617, 0.00949625732166517, 0.0067431936689197475, 0.00948322860322586, 0.00857571708982725, 0.00913344841926641, 0.0073272493556111595, 0.008819361485164223, 0.008035110332239059, 0.007698191735855305, 0.008909685756305316, 0.009548732658503544, 0.009377771004868711, 0.011127455291475293, 0.009935445461469976, 0.011440350359540547, 0.008445465183398618, 0.00872731726082306, 0.008662534437356812, 0.008232105240078778, 0.009643185709059369, 0.007310395641478988, 0.00926885766035336, 0.009544166046817838, 0.0113319654958128, 0.00930754474468884, 0.010157252602906104, 0.011237783695079129, 0.008797032582461714, 0.011142121096593854, 0.010325992280004236, 0.011239181486582428, 0.010199752224872861, 0.009622414128061828, 0.009187784570525511, 0.010199980301018614, 0.010603785287021156, 0.008539874855460783, 0.009953598118051866, 0.010352794172837533, 0.0088759443057619, 0.010659847808892682, 0.008506600469286854, 0.011021400262989766, 0.012049972789759462, 0.009618815779701771, 0.009871561909890721, 0.01034127306505525, 0.009383895222124192, 0.008745729702386025, 0.010096293302242383, 0.011514028001705732, 0.010603532033837928, 0.008473782155674877, 0.0107600242806728, 0.010083775170619444, 0.009037121179959444, 0.01094959067687504, 0.010341940699578464, 0.010364968624737878, 0.009531278162318671, 0.010524753427003528, 0.0087593496680004, 0.010482064302734122, 0.008855451113542004, 0.007762943771540424, 0.010160547758724712, 0.010546054468646732, 0.011218020285179436, 0.011513365302931402, 0.008488762637013748, 0.009634617850326835, 0.009264585726749737, 0.009483768136590432, 0.009780792604234355, 0.00916813190746076, 0.009361090945974761, 0.008935524681901822, 0.00918237667250214, 0.009545874377790068, 0.009426986623642681, 0.01016205839089829, 0.010236174590098727, 0.009434572796698931, 0.00969606338922361, 0.009100125317794852, 0.009535788340009803, 0.010009660495367929, 0.008530788172546853, 0.010279928528538769, 0.008641857177579237, 0.010272547199160884, 0.009960638277505101, 0.009217269010476202, 0.009757738366140028, 0.009212973155930105, 0.009307361498577128, 0.009510082824603626, 0.009548281407906267, 0.009953598118051866, 0.009043198153505672, 0.009525201584592892, 0.010479392064577464, 0.009625818555051008], "accuracy_valid": [0.4282608951430723, 0.5108348432793675, 0.5886362834149097, 0.6337228798004518, 0.6647199148155121, 0.6953816241528614, 0.7220547227974398, 0.7418404085090362, 0.7527370223079819, 0.7651778990963856, 0.7667854033320783, 0.7774261106927711, 0.7725933028990963, 0.7827163144766567, 0.7903361492846386, 0.794323289250753, 0.8026652508471386, 0.7962867093373494, 0.8109660320971386, 0.8097556240587349, 0.8152796733810241, 0.8187182323042168, 0.8165503812123494, 0.8181681805346386, 0.822899508189006, 0.8226347773908133, 0.8258894954819277, 0.8281985363328314, 0.8323092173381024, 0.8305090479103916, 0.8393187005835843, 0.8405291086219879, 0.8382906626506024, 0.839379000376506, 0.8416674510542168, 0.8428381494728916, 0.8446383189006024, 0.8470091302710843, 0.8481077630835843, 0.8445471338478916, 0.8509050851844879, 0.8490740304969879, 0.8511801110692772, 0.8493078760353916, 0.8502844385353916, 0.8512815912085843, 0.8544760095067772, 0.8520654885165663, 0.8549437005835843, 0.8541406838290663, 0.8548628106174698, 0.8553407967808735, 0.8539362528237951, 0.8550863610692772, 0.8581998894013554, 0.8540377329631024, 0.8562761789344879, 0.8562864740210843, 0.8570497811558735, 0.8584631494728916, 0.8580057534826807, 0.8598265130835843, 0.8620340737951807, 0.8633871423192772, 0.8607927804969879, 0.8601927240210843, 0.8654932228915663, 0.8611384012612951, 0.8630312264683735, 0.8640989740210843, 0.8627767907567772, 0.8635798075112951, 0.8640886789344879, 0.8643637048192772, 0.8611795816076807, 0.8636209878576807, 0.8623899896460843, 0.8637533532567772, 0.8637121729103916, 0.8632135965737951, 0.8644754800451807, 0.8654520425451807, 0.8658182534826807, 0.8640989740210843, 0.8641195641942772, 0.8644651849585843, 0.8653402673192772, 0.8641092691076807, 0.8637533532567772, 0.8637327630835843, 0.8634989175451807, 0.8647093255835843, 0.8653196771460843, 0.8655844079442772, 0.8649431711219879, 0.8642210443335843, 0.8658079583960843, 0.8649637612951807, 0.8653196771460843, 0.8657064782567772, 0.8658182534826807, 0.8638445383094879, 0.8629900461219879, 0.8636003976844879, 0.8652990869728916, 0.8653093820594879, 0.8655432275978916, 0.8650755365210843, 0.8660520990210843, 0.8659300287085843, 0.8653196771460843, 0.8653093820594879, 0.8650961266942772, 0.8648211008094879, 0.8661741693335843, 0.8643122293862951, 0.8646990304969879, 0.8657976633094879, 0.8635798075112951, 0.8654417474585843, 0.8639460184487951, 0.8650549463478916, 0.8637018778237951, 0.8646990304969879, 0.8646990304969879, 0.8661741693335843, 0.8642004541603916, 0.8646887354103916, 0.8658079583960843, 0.8651873117469879, 0.8651873117469879, 0.8649534662085843, 0.8646887354103916, 0.8655741128576807, 0.8645666650978916, 0.8650446512612951, 0.8661741693335843, 0.8657976633094879, 0.8651873117469879, 0.8648211008094879, 0.8655638177710843, 0.8651873117469879, 0.8633356668862951, 0.8659197336219879, 0.8663065347326807, 0.8646887354103916, 0.8645666650978916, 0.8651873117469879, 0.8643225244728916, 0.8648108057228916, 0.8648108057228916, 0.8653093820594879, 0.8648108057228916, 0.8655638177710843, 0.8651770166603916, 0.8656858880835843, 0.8651976068335843, 0.8639563135353916, 0.8645666650978916, 0.8638239481362951, 0.8644342996987951, 0.8653196771460843, 0.8648211008094879, 0.8644548898719879, 0.8645769601844879, 0.8645769601844879, 0.8640886789344879, 0.8651873117469879, 0.8658079583960843, 0.8643328195594879, 0.8649431711219879, 0.8656755929969879, 0.8638342432228916, 0.8649328760353916, 0.8648211008094879, 0.8660418039344879, 0.8648211008094879, 0.8654314523719879, 0.8644445947853916, 0.8653196771460843, 0.8644445947853916, 0.8653196771460843, 0.8648108057228916, 0.8638342432228916, 0.8648211008094879, 0.8646990304969879, 0.8644548898719879, 0.8648211008094879, 0.8648211008094879, 0.8654314523719879, 0.8651873117469879, 0.8644548898719879, 0.8651873117469879, 0.8646887354103916, 0.8655535226844879], "seed": 155286665, "model": "residualv3", "loss_std": [0.26942920684814453, 0.25869399309158325, 0.2696518301963806, 0.2725908160209656, 0.2715947926044464, 0.26947182416915894, 0.2705105245113373, 0.26718568801879883, 0.2624044418334961, 0.25762245059013367, 0.25837182998657227, 0.2544201910495758, 0.25082799792289734, 0.2495710700750351, 0.2459641844034195, 0.24505427479743958, 0.2400248646736145, 0.23768995702266693, 0.23466889560222626, 0.23283888399600983, 0.23054802417755127, 0.2272271066904068, 0.22310328483581543, 0.22386328876018524, 0.22040195763111115, 0.21802480518817902, 0.2162163108587265, 0.21597999334335327, 0.21363599598407745, 0.20863516628742218, 0.20758646726608276, 0.20646953582763672, 0.2031964510679245, 0.20121024549007416, 0.20209051668643951, 0.19979189336299896, 0.1968807429075241, 0.19482620060443878, 0.19337745010852814, 0.1919122189283371, 0.19196881353855133, 0.18891936540603638, 0.18845348060131073, 0.18670396506786346, 0.18690504133701324, 0.1827445924282074, 0.184255912899971, 0.18202681839466095, 0.1815536916255951, 0.1782432496547699, 0.1811830848455429, 0.1790282130241394, 0.17722803354263306, 0.17472775280475616, 0.17389875650405884, 0.17231391370296478, 0.17219549417495728, 0.171603724360466, 0.17012055218219757, 0.17207872867584229, 0.16833344101905823, 0.1660960167646408, 0.16841425001621246, 0.16542188823223114, 0.1641741544008255, 0.1656254380941391, 0.1657668501138687, 0.16304931044578552, 0.16386784613132477, 0.1627195030450821, 0.16378386318683624, 0.1624814122915268, 0.16230498254299164, 0.15896445512771606, 0.16074493527412415, 0.15995602309703827, 0.1605282574892044, 0.1582009196281433, 0.15814459323883057, 0.16047272086143494, 0.15822111070156097, 0.1567489504814148, 0.15644201636314392, 0.15571673214435577, 0.1549915224313736, 0.1540943682193756, 0.15628866851329803, 0.15699191391468048, 0.15633787214756012, 0.1550336480140686, 0.1532900631427765, 0.1529366672039032, 0.15550023317337036, 0.1530434489250183, 0.1525517702102661, 0.1522666960954666, 0.1534690409898758, 0.15203110873699188, 0.15140075981616974, 0.15234190225601196, 0.15030337870121002, 0.1504235416650772, 0.15096135437488556, 0.15156123042106628, 0.1496448665857315, 0.15231718122959137, 0.15066497027873993, 0.15206773579120636, 0.15147191286087036, 0.1504862904548645, 0.14959925413131714, 0.1483679860830307, 0.15025413036346436, 0.1503659188747406, 0.15094830095767975, 0.1495155692100525, 0.14874298870563507, 0.14831915497779846, 0.14922893047332764, 0.14845091104507446, 0.150032639503479, 0.14926877617835999, 0.1473737359046936, 0.14888805150985718, 0.15004901587963104, 0.14826807379722595, 0.14857229590415955, 0.14918974041938782, 0.15040098130702972, 0.14763519167900085, 0.14734306931495667, 0.14785215258598328, 0.1479085236787796, 0.14879384636878967, 0.14663180708885193, 0.14926329255104065, 0.1480921357870102, 0.14921796321868896, 0.14893358945846558, 0.14749018847942352, 0.14635206758975983, 0.1490965485572815, 0.14694970846176147, 0.14693956077098846, 0.14749906957149506, 0.1480846256017685, 0.1477603167295456, 0.14828427135944366, 0.1480957716703415, 0.14797969162464142, 0.14653615653514862, 0.14760397374629974, 0.14681974053382874, 0.14615042507648468, 0.1477270871400833, 0.1462927907705307, 0.14948619902133942, 0.14503681659698486, 0.14731279015541077, 0.1475757509469986, 0.1475553959608078, 0.14698176085948944, 0.14638341963291168, 0.1459025740623474, 0.14824597537517548, 0.1495109498500824, 0.14572519063949585, 0.14727556705474854, 0.14696601033210754, 0.14501547813415527, 0.1488117128610611, 0.14850647747516632, 0.14452053606510162, 0.14506013691425323, 0.14675216376781464, 0.1472693830728531, 0.1469656080007553, 0.148763507604599, 0.1469435840845108, 0.14507132768630981, 0.14682446420192719, 0.14942258596420288, 0.14910893142223358, 0.14719974994659424, 0.14611628651618958, 0.1466515064239502, 0.14577117562294006, 0.14707988500595093, 0.14661933481693268, 0.14562976360321045, 0.14632904529571533, 0.1472306102514267, 0.14695295691490173, 0.14473223686218262, 0.14714966714382172]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:38 2016", "state": "available"}], "summary": "4d97559cf8f7bc3d76d79fd924d981e1"}