{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 64, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4651631116867065, 1.0099042654037476, 0.7583917379379272, 0.64910888671875, 0.5798797011375427, 0.5317270159721375, 0.4968683421611786, 0.46750369668006897, 0.44579625129699707, 0.42694881558418274, 0.4111579656600952, 0.3972172439098358, 0.3843185305595398, 0.37180399894714355, 0.36216801404953003, 0.3523018956184387, 0.34652575850486755, 0.338274747133255, 0.3307189643383026, 0.3250216543674469, 0.3183186948299408, 0.3132856488227844, 0.3071814477443695, 0.30374544858932495, 0.29801446199417114, 0.294060617685318, 0.2898336946964264, 0.28427654504776, 0.2819386422634125, 0.2779087722301483, 0.2742440104484558, 0.2703484296798706, 0.26786279678344727, 0.26524442434310913, 0.26179346442222595, 0.2597978711128235, 0.25669121742248535, 0.2544552981853485, 0.2506840229034424, 0.24966754019260406, 0.24720816314220428, 0.24522925913333893, 0.24216026067733765, 0.24103271961212158, 0.2379465252161026, 0.23545534908771515, 0.23356451094150543, 0.23238688707351685, 0.2304084450006485, 0.2280019223690033, 0.22675864398479462, 0.2240845412015915, 0.22266079485416412, 0.2215251326560974, 0.2196066975593567, 0.21853604912757874, 0.21769608557224274, 0.2160090208053589, 0.21389494836330414, 0.21334293484687805, 0.21139144897460938, 0.2109547257423401, 0.20893338322639465, 0.2073354572057724, 0.20761695504188538, 0.20493808388710022, 0.20404580235481262, 0.20298324525356293, 0.2018771469593048, 0.20000246167182922, 0.19947633147239685, 0.1982853263616562, 0.19687052071094513, 0.19659194350242615, 0.19550958275794983, 0.19442009925842285, 0.19323119521141052, 0.19205698370933533, 0.1898737996816635, 0.1896914541721344, 0.18881438672542572, 0.18814803659915924, 0.18704766035079956, 0.1867305189371109, 0.18599030375480652, 0.18600107729434967, 0.18284521996974945, 0.18289326131343842, 0.18220371007919312, 0.18264807760715485, 0.18164975941181183, 0.17898546159267426, 0.17895758152008057, 0.17912223935127258, 0.17770518362522125, 0.17735721170902252, 0.17717327177524567, 0.17452247440814972, 0.17475947737693787, 0.17493605613708496, 0.17287831008434296, 0.17352847754955292, 0.17320041358470917, 0.17249292135238647, 0.1695043295621872, 0.17060936987400055, 0.1696210354566574, 0.16953937709331512, 0.16895924508571625, 0.1675238311290741, 0.16780993342399597, 0.16583986580371857, 0.16623446345329285, 0.1647273749113083, 0.1647992879152298, 0.1637168973684311, 0.1626238077878952, 0.16385668516159058, 0.16277578473091125, 0.16331209242343903, 0.16189593076705933, 0.16121508181095123, 0.16049610078334808, 0.16025401651859283, 0.15815766155719757, 0.15813405811786652, 0.15699832141399384, 0.15768851339817047, 0.1580621898174286, 0.157834991812706, 0.15510885417461395, 0.15608644485473633, 0.15609727799892426, 0.15541528165340424, 0.15507330000400543, 0.15441642701625824, 0.1536826491355896, 0.15294767916202545, 0.1520131528377533, 0.15208980441093445, 0.1523318886756897, 0.15134164690971375, 0.1506614238023758, 0.14954224228858948, 0.14951187372207642, 0.14989733695983887, 0.14807073771953583, 0.14894385635852814, 0.14780262112617493, 0.14739704132080078, 0.14721497893333435, 0.14688488841056824, 0.14731252193450928, 0.14642737805843353, 0.14580637216567993, 0.14591768383979797, 0.14572684466838837, 0.1461499035358429, 0.14451850950717926, 0.14425550401210785, 0.14473606646060944, 0.1433509886264801, 0.14415498077869415, 0.14310577511787415, 0.14194037020206451, 0.14321118593215942, 0.14094099402427673, 0.14152821898460388, 0.14203505218029022, 0.14114227890968323, 0.1408749520778656, 0.14064109325408936, 0.1402846723794937, 0.13879306614398956, 0.13979113101959229, 0.13916677236557007, 0.13766302168369293, 0.13745693862438202, 0.13787081837654114, 0.13696250319480896, 0.13722217082977295, 0.13729573786258698, 0.13604454696178436, 0.1362878382205963, 0.134842187166214, 0.13598187267780304, 0.13517509400844574, 0.13465365767478943, 0.1353452503681183, 0.13535316288471222, 0.13364671170711517, 0.13481281697750092, 0.13402484357357025, 0.13445067405700684, 0.1322772204875946, 0.13412028551101685, 0.13204623758792877, 0.13150633871555328, 0.13114912807941437, 0.13232043385505676, 0.13109269738197327, 0.13241441547870636, 0.13139568269252777, 0.1314322054386139, 0.12947003543376923, 0.1298125833272934, 0.13067908585071564, 0.12857529520988464], "moving_avg_accuracy_train": [0.05888408718623107, 0.11866546912490769, 0.1813026201002445, 0.243525193113522, 0.30167376608137797, 0.35606734730477396, 0.4059468354367458, 0.45186591028523626, 0.4942043731857455, 0.5328483882711945, 0.5684601888289957, 0.6010989998821888, 0.6308669881253284, 0.6581416643012599, 0.6831538665726843, 0.7060204882383672, 0.7268864049922344, 0.7458681622124186, 0.7632933603414904, 0.7793200885838272, 0.794013861263835, 0.8075009984913182, 0.8198112667150453, 0.8311162638438362, 0.8414603168787493, 0.8509513262173141, 0.8594979209684601, 0.8673966502932642, 0.8746428707094435, 0.8813340607518251, 0.887386394773311, 0.8931030324104595, 0.898361902526741, 0.9030578274457169, 0.9074862675751301, 0.9115347148070966, 0.9153317771372951, 0.9188236100940159, 0.922101118386017, 0.9251136188178565, 0.9278922985219881, 0.9304977059033164, 0.9328240074048545, 0.9351268700514583, 0.9371622440524494, 0.9391871401021694, 0.9410326898885564, 0.9427495603653708, 0.9443086946873609, 0.9457932597366666, 0.9472479869191461, 0.9485850710714544, 0.9497861216597224, 0.9509415079998871, 0.9520603747167403, 0.9531417595238131, 0.9542056866537499, 0.9550842020599881, 0.9559514876898605, 0.9568994554710314, 0.9577480843229224, 0.9583979179979575, 0.959117554838804, 0.9598209955181757, 0.9604680790712861, 0.9610690554595617, 0.9616912783685243, 0.9623814512711053, 0.96298175264178, 0.9635917783396729, 0.9642081586856152, 0.9648163794195822, 0.9652894093670666, 0.9658151537674309, 0.9663370797551212, 0.9668254143345186, 0.967243917019053, 0.9676090518375426, 0.9681096260396319, 0.968508953498884, 0.9689080199372477, 0.9692973706174801, 0.9697290943403851, 0.9701083450957615, 0.9705054022493913, 0.9708325267531344, 0.9712129693124555, 0.9715484642670534, 0.9718874679118689, 0.9721950044874687, 0.9725461200697757, 0.9728435950010133, 0.9731345739272224, 0.9733103163084019, 0.973631280916949, 0.9739318829551451, 0.9742139784359318, 0.974509608900755, 0.9748664292203049, 0.9751898566078905, 0.9754600149174318, 0.9756985070983999, 0.9759526415422144, 0.9762069031297335, 0.9764614233418616, 0.9766997560791963, 0.9768840286082738, 0.9771266037951578, 0.9773496078097912, 0.977531710232485, 0.9777559481355008, 0.9780159270172719, 0.9782592086061039, 0.9783921675789191, 0.9785351181913668, 0.9786614125449414, 0.9787820168607685, 0.9789858918462032, 0.9791646569378379, 0.9793162809738899, 0.9794759940944319, 0.9796476737374527, 0.9798300511530669, 0.9799337369580721, 0.9801061452909193, 0.9803078157666724, 0.9804427801698409, 0.9806339665481595, 0.9807572061636463, 0.9809193111402126, 0.9810512547262651, 0.9811979057394267, 0.9813019538167391, 0.9813863325399009, 0.981534316955023, 0.981623325101252, 0.9818033777828489, 0.9819910378820096, 0.9820925387045967, 0.9821978403377822, 0.9822832391147737, 0.982422877031923, 0.9825811392895095, 0.9827096244284803, 0.9827949980702114, 0.9829136509775221, 0.9830530267262539, 0.9832040415370172, 0.9833028245833894, 0.9834637007917632, 0.9835503606590615, 0.9836005609003721, 0.9837270492282474, 0.9838385635745257, 0.9839226504445096, 0.9840796727870095, 0.9841977774559829, 0.9843204197973632, 0.9844330509557775, 0.9845019029638358, 0.9845754234174984, 0.9846950341995949, 0.9847724930177768, 0.9848608071446167, 0.9849402898587726, 0.9850141854991412, 0.9850760052290352, 0.9851804711109396, 0.9852931276439487, 0.9853898682260378, 0.9854699593034894, 0.9855885082005675, 0.9857115142984233, 0.985780367107922, 0.985828347694795, 0.9859157440991804, 0.985996689963118, 0.9860393503549567, 0.9861567997671354, 0.9862159291642684, 0.9862971555538586, 0.9863399602723284, 0.9864087114534751, 0.9864519863260309, 0.9865351475875308, 0.9866308830133477, 0.9867333569870683, 0.9868068742264844, 0.9868917130300725, 0.986954081011626, 0.9870242351855187, 0.9871035778860514, 0.9871609993748549, 0.9872290268540823, 0.987276264643711, 0.9873118032079482, 0.987392579991943, 0.987460664848738, 0.9874917142853296, 0.9875661617544526, 0.9876029735909582, 0.987677920873566, 0.9877221579886365, 0.9877573210945809, 0.9878052078827787, 0.9878924838195378, 0.9879268543352399, 0.9879903038338864], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05806414133094878, 0.11599519660673943, 0.1762064061911709, 0.2350241362422345, 0.2895602438906014, 0.34038231626358945, 0.386670468296869, 0.42936343182109776, 0.46834862243040365, 0.50371296717155, 0.5363903691554492, 0.5659821069010489, 0.592528192144679, 0.6169710442875153, 0.6391913967958872, 0.659186625527443, 0.6772820466531626, 0.6936533748850602, 0.7085594982399276, 0.7220991385891276, 0.7345248374937691, 0.7454882399454464, 0.755391923245706, 0.7644527520995993, 0.7729523834690821, 0.7802704028405474, 0.7869797200960258, 0.7932134181259562, 0.7987627111966438, 0.8039788605400818, 0.8084617573832874, 0.8125360741619014, 0.8163748872088137, 0.8198298189510347, 0.8232220782551029, 0.826065533080195, 0.8287121506588472, 0.8312039697608842, 0.833496464586377, 0.8354467581220917, 0.837003621278256, 0.838800570662102, 0.8401594184339942, 0.8416540246421761, 0.8429960817035609, 0.8443311509146054, 0.8454696190309762, 0.8466183696655292, 0.8475657665092172, 0.8483166493838978, 0.8489080242610201, 0.8494911487927493, 0.8501136171213057, 0.8507094302020969, 0.8511612422647186, 0.851607582740807, 0.8520692948168769, 0.8525204272704302, 0.8529620380637185, 0.853213003402678, 0.8535152029212205, 0.8538593951667491, 0.8543288891026344, 0.8545906832213619, 0.8548893921017859, 0.8551094019691676, 0.8553674164974014, 0.8557858235675408, 0.8559253087936181, 0.8560661410543164, 0.8562193631687643, 0.8565169839866771, 0.8568194047992292, 0.8570214298690051, 0.8572378145082341, 0.8575068323796998, 0.8578598412539287, 0.857932379107075, 0.8581441475499066, 0.8584100403532744, 0.858622870796486, 0.8588764828602862, 0.8591037042090467, 0.8593315879767716, 0.8593769624528143, 0.859432065529822, 0.8597166804188578, 0.8598375269665806, 0.8597865679446213, 0.8599736679272675, 0.8601166143404895, 0.86014555084507, 0.8601471796366926, 0.8600743738529932, 0.8602438707673927, 0.8602865547091023, 0.8603239407479812, 0.8603586176916319, 0.8604152705120771, 0.8605008201269085, 0.8604191233740068, 0.8604432525463953, 0.8603805490914546, 0.8603119089507579, 0.8603742621539502, 0.8603143397036154, 0.8603499767517027, 0.860355577015162, 0.8604694510248656, 0.8604508968297585, 0.8605583273839814, 0.8606814879626014, 0.860793361992019, 0.8605959323251966, 0.860468103258716, 0.8605382215849529, 0.8605524999535661, 0.8605877055304986, 0.8607058692771474, 0.8606901463366314, 0.8605915759800767, 0.8608090679490872, 0.8608695038687869, 0.8609371327364264, 0.8608982834499825, 0.8609121472171831, 0.860923595099004, 0.861082441584962, 0.8611776048059839, 0.8613476714149939, 0.8614529327467626, 0.8616717972751737, 0.8616968474045841, 0.8617804276773033, 0.8618800639852507, 0.8617347145426745, 0.8618399516727443, 0.8618461273450784, 0.8617174081064289, 0.8618477604339638, 0.8618053566138355, 0.8618658789343797, 0.8619325560541194, 0.8619671218907256, 0.8619494030186711, 0.8619191899852527, 0.8618818502412455, 0.8618726585341391, 0.8619641012650625, 0.862130819432984, 0.8621333519004537, 0.8620379748711764, 0.8620609693174172, 0.8621457880012627, 0.8621743262003834, 0.8621826560050438, 0.8620436684542382, 0.8622533170455614, 0.8622924278767733, 0.8622533559287044, 0.8623067289201714, 0.8624768349249915, 0.86251903753942, 0.8624949552274961, 0.8624143050078338, 0.8624006959490684, 0.8624393349384989, 0.8625229381539864, 0.8623875729906961, 0.8624031102134638, 0.8623641475543162, 0.8624054118745623, 0.8624160766829646, 0.8624267045191862, 0.8624118555092857, 0.8624340829854655, 0.8624917383164371, 0.8624449423556518, 0.8624282695621047, 0.8624010570166624, 0.8624518669305835, 0.8625453944694529, 0.8626417762856853, 0.8626664552553848, 0.8627486719757047, 0.8627494248364926, 0.8626025885275422, 0.8625691216081464, 0.8625379718720305, 0.8624489019532763, 0.8624806613249667, 0.8623871744469881, 0.8623884854755574, 0.8623621628127908, 0.86229170330862, 0.8622750588625472, 0.8623384685918798, 0.8624311289333695, 0.8623517137998217, 0.8623789259382882, 0.8623169381354985, 0.8623608643803071, 0.8623414218617041, 0.8624459939074615, 0.8624281864500737, 0.8623887751845843, 0.8623024179033247, 0.8623244116175104], "moving_var_accuracy_train": [0.031206021513800964, 0.06024974200090226, 0.0895354819415763, 0.11542677107895251, 0.13431540281483992, 0.1475118176381115, 0.15515230590106802, 0.1586141282254326, 0.15888562436988954, 0.15643730105022033, 0.15220737399591575, 0.14657426447901853, 0.13989203614750992, 0.1325980041772763, 0.1249686961217485, 0.11717776798718695, 0.10937846952628212, 0.101683386538148, 0.09424778565286991, 0.08713471125096635, 0.08036440272601542, 0.07396508828875055, 0.06793246379353646, 0.062289444054920526, 0.05702349454813034, 0.052131858417699815, 0.047576071112492686, 0.04337997332576209, 0.039514545386064574, 0.035966039065107515, 0.032699111882565496, 0.0297233202071791, 0.026999889620560456, 0.024498366056106346, 0.022225029188313882, 0.02015003559439265, 0.018264791176008092, 0.01654804813498606, 0.014989921866924681, 0.013572606109898707, 0.012284835046992217, 0.011117444870897117, 0.010054405491891929, 0.009096693530024848, 0.00822430890293756, 0.007438779848753348, 0.006725556350004311, 0.006079529513111291, 0.005493454660306228, 0.004963944594746184, 0.00448659621585057, 0.004054026740538701, 0.0036616067691250414, 0.00330746035056789, 0.0029879810800818403, 0.002699707509982366, 0.002439924227424471, 0.0022028779085530043, 0.0019893597769717517, 0.001798511585501818, 0.0016251419653059921, 0.0014664283230222807, 0.0013244463853643853, 0.0011964552059325014, 0.0010805781394616057, 0.0009757708790888284, 0.0008816782433158868, 0.0007977974667034111, 0.0007212609756537745, 0.0006524840602572042, 0.000590654976809259, 0.0005349188712793805, 0.0004834408001323961, 0.00043758438468978543, 0.0003962776068504452, 0.0003587960821183182, 0.00032449277437914946, 0.00029324340786229596, 0.0002661742378622417, 0.00024099197585343156, 0.0002183260644681432, 0.0001978578035911058, 0.00017974949158826577, 0.00016306902264852136, 0.00014818100983290684, 0.00013432600281815832, 0.00012219603140482767, 0.00011098944004539094, 0.00010092480728163565, 9.168353526145663e-05, 8.362472110456018e-05, 7.605867100653774e-05, 6.921482252536427e-05, 6.257130873371182e-05, 5.724134237979835e-05, 5.233046241012796e-05, 4.781361691163769e-05, 4.3818831566058186e-05, 4.0582835073445085e-05, 3.746599904146462e-05, 3.437626874724618e-05, 3.145054855596806e-05, 2.8886752540167355e-05, 2.6579917880140066e-05, 2.450495093756195e-05, 2.2565678286974755e-05, 2.06147177430305e-05, 1.9082830460353454e-05, 1.7622124529201395e-05, 1.6158363707439888e-05, 1.4995071071036248e-05, 1.4103865134634999e-05, 1.3226152004353303e-05, 1.2062639599986691e-05, 1.1040289538380541e-05, 1.0079812958246023e-05, 9.202740271386302e-06, 8.656551331421934e-06, 8.078508820164399e-06, 7.477566572926091e-06, 6.959384443492837e-06, 6.528711097593355e-06, 6.175193683369351e-06, 5.654431030468701e-06, 5.35650962653842e-06, 5.186897490998635e-06, 4.832146253002442e-06, 4.6779017089935125e-06, 4.346803563522077e-06, 4.148625418018088e-06, 3.890444865320005e-06, 3.6949590557399604e-06, 3.422897171697649e-06, 3.1446853748296673e-06, 3.0273113214180778e-06, 2.7958822401323325e-06, 2.80806472947103e-06, 2.8442050718768486e-06, 2.6525063175620097e-06, 2.4870515913697944e-06, 2.303982992237521e-06, 2.249073424166284e-06, 2.249588561337316e-06, 2.1732055836307027e-06, 2.0214829535895954e-06, 1.94604126995022e-06, 1.92626753696596e-06, 1.9388900408982908e-06, 1.832823849063448e-06, 1.882471853943932e-06, 1.7618140619511262e-06, 1.6083132338047408e-06, 1.5914755842225125e-06, 1.5442470706330703e-06, 1.4534577789027434e-06, 1.5300161454100395e-06, 1.5025529463690427e-06, 1.4876679468253397e-06, 1.4530731527545295e-06, 1.350431228601999e-06, 1.2640354197025447e-06, 1.266392530476144e-06, 1.193752094055756e-06, 1.1445713496456212e-06, 1.0869717313273685e-06, 1.0274196491839884e-06, 9.590727953030156e-07, 9.613836001115515e-07, 9.794686899669384e-07, 9.65750482976636e-07, 9.26906660865191e-07, 9.6070056376471e-07, 1.0008050083755725e-06, 9.433908919208751e-07, 8.697710331788757e-07, 8.515371133564543e-07, 8.253534980182984e-07, 7.591973295030482e-07, 8.074268763429502e-07, 7.581507591563502e-07, 7.417152205333698e-07, 6.840338937895512e-07, 6.58171028592119e-07, 6.092083570853815e-07, 6.105296801051523e-07, 6.319641579016896e-07, 6.632759797223411e-07, 6.455914421723853e-07, 6.458109013036212e-07, 6.162376972807569e-07, 5.989084005838845e-07, 5.956749376758314e-07, 5.657824902959421e-07, 5.50853882636564e-07, 5.158511732939429e-07, 4.7563296189695445e-07, 4.867936652001049e-07, 4.7983422820326e-07, 4.4052741299688925e-07, 4.4635650262659066e-07, 4.139168541262062e-07, 4.2307902524618744e-07, 3.9838342386941423e-07, 3.6967307765938745e-07, 3.533440702486225e-07, 3.8656346545828004e-07, 3.585391100591635e-07, 3.5891774895974743e-07], "duration": 317057.864022, "accuracy_train": [0.5888408718623108, 0.6566979065729974, 0.7450369788782761, 0.8035283502330195, 0.825010922792082, 0.8456095783153378, 0.8548622286244923, 0.8651375839216501, 0.8752505392903286, 0.8806445240402363, 0.8889663938492063, 0.8948482993609265, 0.8987788823135843, 0.9036137498846438, 0.908263687015504, 0.9118200832295128, 0.9146796557770396, 0.9167039771940754, 0.9201201435031378, 0.9235606427648578, 0.9262578153839055, 0.9288852335386674, 0.9306036807285898, 0.9328612380029531, 0.9345567941929678, 0.9363704102643964, 0.9364172737287744, 0.9384852142165007, 0.9398588544550572, 0.9415547711332595, 0.941857400966685, 0.9445527711447952, 0.9456917335732743, 0.9453211517165007, 0.9473422287398486, 0.9479707398947952, 0.9495053381090809, 0.9502501067045036, 0.9515986930140274, 0.9522261227044113, 0.9529004158591732, 0.9539463723352714, 0.953760720918697, 0.9558526338708934, 0.9554806100613695, 0.9574112045496493, 0.9576426379660392, 0.9582013946567, 0.9583409035852714, 0.9591543451804172, 0.9603405315614618, 0.9606188284422297, 0.9605955769541344, 0.9613399850613695, 0.9621301751684201, 0.9628742227874677, 0.963781030823182, 0.9629908407161315, 0.9637570583587117, 0.9654311655015688, 0.9653857439899409, 0.9642464210732743, 0.9655942864064231, 0.9661519616325213, 0.9662918310492802, 0.9664778429540422, 0.9672912845491879, 0.9685930073943337, 0.9683844649778516, 0.9690820096207088, 0.9697555817990956, 0.9702903660252861, 0.969546678894426, 0.9705468533707088, 0.9710344136443337, 0.9712204255490956, 0.9710104411798633, 0.9708952652039498, 0.9726147938584349, 0.9721029006321521, 0.9724996178825213, 0.9728015267395718, 0.9736146078465301, 0.9735216018941492, 0.9740789166320598, 0.9737766472868217, 0.9746369523463455, 0.9745679188584349, 0.9749385007152085, 0.9749628336678663, 0.9757061603105389, 0.9755208693821521, 0.9757533842631044, 0.974891997739018, 0.9765199623938722, 0.976637301298911, 0.9767528377630121, 0.9771702830841639, 0.9780778120962532, 0.9781007030961609, 0.9778914397033037, 0.9778449367271133, 0.9782398515365448, 0.9784952574174051, 0.9787521052510151, 0.9788447507152085, 0.9785424813699704, 0.9793097804771133, 0.9793566439414912, 0.9791706320367294, 0.9797740892626431, 0.9803557369532114, 0.9804487429055924, 0.9795887983342562, 0.979821673703396, 0.9797980617271133, 0.9798674557032114, 0.9808207667151162, 0.9807735427625508, 0.9806808972983574, 0.9809134121793098, 0.98119279052464, 0.9814714478935955, 0.9808669092031194, 0.9816578202865448, 0.9821228500484496, 0.9816574597983574, 0.9823546439530271, 0.9818663627030271, 0.9823782559293098, 0.9822387470007383, 0.9825177648578812, 0.9822383865125508, 0.9821457410483574, 0.9828661766911223, 0.9824243984173128, 0.9834238519172205, 0.9836799787744556, 0.9830060461078812, 0.9831455550364526, 0.9830518281076966, 0.983679618286268, 0.9840054996077889, 0.9838659906792175, 0.9835633608457919, 0.9839815271433187, 0.9843074084648394, 0.9845631748338871, 0.9841918720007383, 0.9849115866671282, 0.9843302994647471, 0.9840523630721669, 0.9848654441791252, 0.98484219269103, 0.9846794322743633, 0.9854928738695091, 0.9852607194767442, 0.985424200869786, 0.9854467313815062, 0.9851215710363603, 0.9852371075004615, 0.9857715312384644, 0.9854696223814139, 0.9856556342861758, 0.9856556342861758, 0.9856792462624585, 0.9856323827980805, 0.9861206640480805, 0.98630703644103, 0.9862605334648394, 0.9861907790005537, 0.986655448274271, 0.9868185691791252, 0.986400042393411, 0.9862601729766519, 0.986702311738649, 0.9867252027385567, 0.9864232938815062, 0.9872138444767442, 0.9867480937384644, 0.9870281930601699, 0.9867252027385567, 0.9870274720837948, 0.986841460179033, 0.98728359894103, 0.9874925018456996, 0.9876556227505537, 0.9874685293812293, 0.9876552622623662, 0.9875153928456073, 0.9876556227505537, 0.9878176621908453, 0.9876777927740864, 0.9878412741671282, 0.9877014047503692, 0.9876316502860835, 0.9881195710478959, 0.988073428559893, 0.9877711592146549, 0.9882361889765596, 0.9879342801195091, 0.9883524464170359, 0.988120292024271, 0.9880737890480805, 0.9882361889765596, 0.9886779672503692, 0.9882361889765596, 0.9885613493217055], "end": "2016-02-04 07:53:47.578000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0], "moving_var_accuracy_valid": [0.030343000576503555, 0.05751276500715361, 0.08438999634302125, 0.10708672502395726, 0.12314573585846991, 0.13407710963519004, 0.1399527358395751, 0.14236166446594775, 0.14180410380094818, 0.1388794253315892, 0.13460179620218635, 0.12902265506720684, 0.12246264133634481, 0.11559345439059936, 0.10847780554190622, 0.10122830753596074, 0.0940524751738189, 0.08705941114912576, 0.08035320265544792, 0.07396777913697429, 0.06796058316269614, 0.062246290586283524, 0.056904408013861735, 0.05195285478815147, 0.04740776291009019, 0.04314896728677144, 0.03923920500040624, 0.035665015420520856, 0.032375665760728194, 0.029382973110412818, 0.026625543076332945, 0.02411238928361211, 0.021833778725733194, 0.019757829833250532, 0.017885613658599815, 0.01616981941082089, 0.014615878731207477, 0.013210173320022216, 0.0119364557807442, 0.010777043006548836, 0.00972115311187715, 0.008778099044482377, 0.007916907345438729, 0.007145321240352678, 0.0064469991707215265, 0.005818340941833885, 0.005248171834518432, 0.004735231303250062, 0.004269786219939927, 0.003847882023769333, 0.003466241339600022, 0.0031226775136155606, 0.0028138969636345066, 0.002535702206316232, 0.0022839691929439827, 0.002057365252034938, 0.001853547329202143, 0.0016700242806977697, 0.0015047770334627312, 0.0013548661825286894, 0.001220201485216886, 0.0010992475514121354, 0.0009913066172734198, 0.0008927927809914808, 0.0008043165458495304, 0.000724320530340285, 0.0006524876207772742, 0.0005888144389866304, 0.0005301081002426117, 0.0004772757937492314, 0.00042975950752151113, 0.00038758076013065536, 0.0003496458092483723, 0.00031504855548289656, 0.0002839651007434553, 0.00025621992620562144, 0.00023171947097261792, 0.00020859487953660779, 0.00018813900444336113, 0.00016996139484496995, 0.00015337292653849223, 0.00013861450559478794, 0.0001252177209073022, 0.00011316332792090423, 0.00010186552471649917, 9.170629938671074e-05, 8.326472016358779e-05, 7.506968314009733e-05, 6.758608622335899e-05, 6.114253523257932e-05, 5.521218480279882e-05, 4.969850221419501e-05, 4.472867586943486e-05, 4.03035144217521e-05, 3.653172581549536e-05, 3.2894950503864575e-05, 2.961803489660563e-05, 2.6667053820733634e-05, 2.4029234317239873e-05, 2.169217951489617e-05, 1.958303079831868e-05, 1.7629967671128187e-05, 1.5902356413368912e-05, 1.4354523992265742e-05, 1.2954062890574206e-05, 1.1690972902003902e-05, 1.0533305604570872e-05, 9.480257310671101e-06, 8.64893719037795e-06, 7.787141794744786e-06, 7.112299531096148e-06, 6.537586331120495e-06, 5.996469884131574e-06, 5.747629155792786e-06, 5.319928672348985e-06, 4.832185022182369e-06, 4.350801366256405e-06, 3.926876123455151e-06, 3.6598525503086706e-06, 3.296092193004016e-06, 3.0539280104255327e-06, 3.1742600186391455e-06, 2.889706520284776e-06, 2.641898841899957e-06, 2.3912923612247238e-06, 2.1538929614711676e-06, 1.939683151307708e-06, 1.9728046910878604e-06, 1.8570285696963813e-06, 1.9316295762282965e-06, 1.838186150296911e-06, 2.085482671436686e-06, 1.8825819851442914e-06, 1.7571947445203712e-06, 1.670821814820801e-06, 1.693877777453844e-06, 1.6241636816166126e-06, 1.4620905638139429e-06, 1.4649992890189013e-06, 1.4714249237607115e-06, 1.3404651870379076e-06, 1.2393852298905705e-06, 1.155459251572608e-06, 1.0506664999578806e-06, 9.484254758040412e-07, 8.61798374718662e-07, 7.881668455895066e-07, 7.101105483463384e-07, 7.143554508603373e-07, 8.930744334101107e-07, 8.038247105924641e-07, 8.053132389570819e-07, 7.295406160826584e-07, 7.213344366381467e-07, 6.565308522558135e-07, 5.915022378413642e-07, 7.062098675676506e-07, 1.0311616674049564e-06, 9.418124147272556e-07, 8.613707273876236e-07, 8.008717406119976e-07, 9.812090424338615e-07, 8.991176841719316e-07, 8.144255354831525e-07, 7.9152310331897e-07, 7.140376513113706e-07, 6.560706297181321e-07, 6.533690455048992e-07, 7.529456878476763e-07, 6.798237666849177e-07, 6.255041892870869e-07, 5.782784674867271e-07, 5.214742639823531e-07, 4.7034339570889796e-07, 4.252934939932484e-07, 3.872106908698594e-07, 3.784068564877876e-07, 3.6027492835137e-07, 3.267492739182146e-07, 3.00739050191487e-07, 2.9389997134637454e-07, 3.432365789543806e-07, 3.925180115612977e-07, 3.58747674314048e-07, 3.8370920878416365e-07, 3.453433891000417e-07, 5.048571648258306e-07, 4.6445176058784794e-07, 4.2673933906984306e-07, 4.55466459004873e-07, 4.189977323159318e-07, 4.557561262720069e-07, 4.1019598280799107e-07, 3.7541232770329757e-07, 3.8255197048472714e-07, 3.4679011170190066e-07, 3.482982444980495e-07, 3.907418700131998e-07, 4.084285539395963e-07, 3.742502028649795e-07, 3.714075718306887e-07, 3.516324494944655e-07, 3.1987130831167027e-07, 3.86301992265305e-07, 3.505257428863126e-07, 3.2945239922489063e-07, 3.636253795414157e-07, 3.3161635276037264e-07], "accuracy_test": 0.8605189732142857, "start": "2016-01-31 15:49:29.714000", "learning_rate_per_epoch": [0.0004505846300162375, 0.00022529231500811875, 0.00015019487182144076, 0.00011264615750405937, 9.01169260032475e-05, 7.509743591072038e-05, 6.43692328594625e-05, 5.632307875202969e-05, 5.006495848647319e-05, 4.505846300162375e-05, 4.096223710803315e-05, 3.754871795536019e-05, 3.4660355595406145e-05, 3.218461642973125e-05, 3.0038974728086032e-05, 2.8161539376014844e-05, 2.6504978450248018e-05, 2.5032479243236594e-05, 2.371497976128012e-05, 2.2529231500811875e-05, 2.1456411559483968e-05, 2.0481118554016575e-05, 1.9590635929489508e-05, 1.8774358977680095e-05, 1.802338556444738e-05, 1.7330177797703072e-05, 1.6688320101820864e-05, 1.6092308214865625e-05, 1.5537400031462312e-05, 1.5019487364043016e-05, 1.4534987712977454e-05, 1.4080769688007422e-05, 1.365407933917595e-05, 1.3252489225124009e-05, 1.28738465718925e-05, 1.2516239621618297e-05, 1.2177963071735576e-05, 1.185748988064006e-05, 1.1553452168300282e-05, 1.1264615750405937e-05, 1.0989869224431459e-05, 1.0728205779741984e-05, 1.0478712283656932e-05, 1.0240559277008288e-05, 1.0012991879193578e-05, 9.795317964744754e-06, 9.586907253833488e-06, 9.387179488840047e-06, 9.1956044343533e-06, 9.01169278222369e-06, 8.834992513584439e-06, 8.665088898851536e-06, 8.501596312271431e-06, 8.344160050910432e-06, 8.192448149202392e-06, 8.046154107432812e-06, 7.90499325376004e-06, 7.768700015731156e-06, 7.63702792028198e-06, 7.509743682021508e-06, 7.386633114947472e-06, 7.267493856488727e-06, 7.152136731747305e-06, 7.040384844003711e-06, 6.932071300980169e-06, 6.827039669587975e-06, 6.725143521180144e-06, 6.6262446125620045e-06, 6.530211976496503e-06, 6.43692328594625e-06, 6.346262125589419e-06, 6.2581198108091485e-06, 6.172392204462085e-06, 6.088981535867788e-06, 6.0077950365666766e-06, 5.92874494032003e-06, 5.851748483109986e-06, 5.776726084150141e-06, 5.703602710127598e-06, 5.632307875202969e-06, 5.562773367273621e-06, 5.4949346122157294e-06, 5.4287302191369236e-06, 5.364102889870992e-06, 5.300995780999074e-06, 5.239356141828466e-06, 5.179133495403221e-06, 5.120279638504144e-06, 5.0627486416487955e-06, 5.006495939596789e-06, 4.951479240844492e-06, 4.897658982372377e-06, 4.844996055908268e-06, 4.793453626916744e-06, 4.742996225104434e-06, 4.693589744420024e-06, 4.645202352548949e-06, 4.59780221717665e-06, 4.551359779725317e-06, 4.505846391111845e-06, 4.4612338570004795e-06, 4.417496256792219e-06, 4.374608124635415e-06, 4.332544449425768e-06, 4.291282039048383e-06, 4.2507981561357155e-06, 4.211071427562274e-06, 4.172080025455216e-06, 4.133803940931102e-06, 4.096224074601196e-06, 4.059320872329408e-06, 4.023077053716406e-06, 3.987474428868154e-06, 3.95249662688002e-06, 3.918127276847372e-06, 3.884350007865578e-06, 3.851150722766761e-06, 3.81851396014099e-06, 3.786425395446713e-06, 3.754871841010754e-06, 3.7238398817862617e-06, 3.693316557473736e-06, 3.6632895898947027e-06, 3.6337469282443635e-06, 3.604676976465271e-06, 3.5760683658736525e-06, 3.5479104099067627e-06, 3.5201924220018554e-06, 3.492904170343536e-06, 3.4660356504900847e-06, 3.439577312747133e-06, 3.4135198347939877e-06, 3.3878543490573065e-06, 3.362571760590072e-06, 3.3376638839399675e-06, 3.3131223062810022e-06, 3.28893884216086e-06, 3.2651059882482514e-06, 3.241616013838211e-06, 3.218461642973125e-06, 3.195635599695379e-06, 3.1731310627947096e-06, 3.150941438434529e-06, 3.1290599054045742e-06, 3.1074800972419325e-06, 3.0861961022310425e-06, 3.0652015539089916e-06, 3.044490767933894e-06, 3.024057832590188e-06, 3.0038975182833383e-06, 2.984004140671459e-06, 2.964372470160015e-06, 2.9449975045281462e-06, 2.925874241554993e-06, 2.906997679019696e-06, 2.8883630420750706e-06, 2.8699657832476078e-06, 2.851801355063799e-06, 2.833865664797486e-06, 2.8161539376014844e-06, 2.798662308123312e-06, 2.7813866836368106e-06, 2.764322744042147e-06, 2.7474673061078647e-06, 2.730815822360455e-06, 2.7143651095684618e-06, 2.6981115297530778e-06, 2.682051444935496e-06, 2.6661812171369093e-06, 2.650497890499537e-06, 2.6349978270445717e-06, 2.619678070914233e-06, 2.6045354388770647e-06, 2.5895667477016104e-06, 2.574769268903765e-06, 2.560139819252072e-06, 2.5456758976361016e-06, 2.5313743208243977e-06, 2.5172325877065305e-06, 2.5032479697983945e-06, 2.4894177386158844e-06, 2.475739620422246e-06, 2.462211114107049e-06, 2.4488294911861885e-06, 2.43559247792291e-06, 2.422498027954134e-06, 2.409543412795756e-06, 2.396726813458372e-06, 2.384045728831552e-06, 2.371498112552217e-06, 2.359081690883613e-06, 2.346794872210012e-06, 2.3346353827946587e-06, 2.3226011762744747e-06, 2.3106904336600564e-06, 2.298901108588325e-06, 2.287231609443552e-06, 2.2756798898626585e-06, 2.2642443582299165e-06, 2.2529231955559226e-06, 2.241714582851273e-06, 2.2306169285002397e-06, 2.2196286408870947e-06, 2.2087481283961097e-06, 2.1979737994115567e-06, 2.1873040623177076e-06, 2.1767373254988343e-06, 2.166272224712884e-06], "accuracy_train_first": 0.5888408718623108, "accuracy_train_last": 0.9885613493217055, "batch_size_eval": 1024, "accuracy_train_std": [0.02062966161135524, 0.020565812854339813, 0.01968657295157231, 0.018934127181958294, 0.018058780656990382, 0.016913270066275927, 0.016715051805958062, 0.016997265244785325, 0.01705576120066024, 0.01611927571339703, 0.014733413674913124, 0.01441092115310044, 0.014277262232041931, 0.013299905091626965, 0.012700277431273123, 0.012009392271241467, 0.01254512747473631, 0.012600316834027774, 0.011369926930606568, 0.010403928702632004, 0.010857980392773504, 0.010499359117588276, 0.010912392533196058, 0.009950565032578646, 0.010237895511408572, 0.009234232278943464, 0.009784795680384097, 0.010141234925031948, 0.00965519467218664, 0.009564676753051277, 0.009374913152265223, 0.009179295203030926, 0.00929835014569888, 0.008799504798683166, 0.0089785282503397, 0.008794258634132836, 0.008304200551502975, 0.007753510350813135, 0.008099270990550198, 0.007812879876067477, 0.007737478862647619, 0.007791110090194289, 0.007419008655149863, 0.007299217860055936, 0.007245018871093716, 0.006848810783029746, 0.006917101016924597, 0.006737416511463477, 0.00697058434728674, 0.006913660748371077, 0.006642384043779249, 0.006652091620735878, 0.006690083209048406, 0.00693808194900206, 0.0065016083414862254, 0.006233183490279119, 0.006427056628672071, 0.0060131678689740314, 0.00674921864160285, 0.0065213253020847605, 0.006045677204174257, 0.006023521371541235, 0.006071147102409457, 0.0058743773549313014, 0.005843325566947341, 0.0060584349422528, 0.006128907834020354, 0.005901802790191923, 0.006449610573556424, 0.006025573307200013, 0.0058019889561369085, 0.0058079303185007945, 0.0058730445208244435, 0.0059261401600884, 0.005400049999391666, 0.005807378997710156, 0.0052019847828410955, 0.005622730645655751, 0.005507747000839034, 0.005485833742670316, 0.005615641182323939, 0.00609704373357004, 0.005392397231730426, 0.005207028886018369, 0.00565705566440415, 0.005654753792944553, 0.005361033992686903, 0.0054687151382497605, 0.005363931540946567, 0.004886388543399992, 0.005192503652853263, 0.005155277268946516, 0.005309232469754849, 0.005391909501825763, 0.005012760153742246, 0.005239623611407598, 0.004640663989119492, 0.004982760157280246, 0.005137930369193577, 0.0052266021568373585, 0.004911758076452551, 0.0052801372323497305, 0.005122880167790077, 0.004855965737329282, 0.004891097484594122, 0.0050516602207199505, 0.004937409668393191, 0.0045925361630791495, 0.004912666571629931, 0.004890094865771643, 0.004579879023484323, 0.005235181648319685, 0.005046457852823353, 0.00437231658502766, 0.0048709559947953665, 0.004950272819133898, 0.00474281890950446, 0.004510851857572641, 0.004440082083583009, 0.004377772530707726, 0.004739574571335268, 0.005030527503584104, 0.004849517921944628, 0.004945252522917947, 0.0046817555523075635, 0.0043960334930954765, 0.0045550759485105735, 0.004539855234790168, 0.004513793443265822, 0.004342364903769187, 0.00414055749837123, 0.004272993201615425, 0.004281727564727208, 0.004259812524508596, 0.0044271849346335795, 0.004926515071033256, 0.004673505062561136, 0.004401429134880471, 0.004566787976889314, 0.004425288918197275, 0.00456719927313447, 0.0044227479339828246, 0.004050178862397183, 0.0042754606332878475, 0.0038023912998619855, 0.004035252170076356, 0.004298015325362327, 0.003797767572779346, 0.004220680878927985, 0.00393882886605996, 0.004167379345855419, 0.003990872818221575, 0.004184538189198526, 0.004029684113251993, 0.003911104330026497, 0.004043077055339556, 0.003635906858903103, 0.0037838157496105414, 0.003848177649160207, 0.003980812964315585, 0.004162898254749397, 0.004178958734685619, 0.0036637904279200363, 0.0035713399403097547, 0.0038350007385592765, 0.003917388743146196, 0.003731769242474549, 0.003628177598031859, 0.0036705822137637757, 0.0038805292285593557, 0.0035517056370233295, 0.003659884849419611, 0.003681164823976613, 0.0040014469775644995, 0.0035894573145745026, 0.003673220456130931, 0.0040788079080987935, 0.0037821558744983675, 0.003481588177866428, 0.0037851523703683826, 0.003424366512850882, 0.0040114482670149335, 0.0033731203709002153, 0.003694198450954155, 0.003700812698648974, 0.003700022747148172, 0.0037026400035350157, 0.0034966857167762523, 0.00352767725215375, 0.003659143640039152, 0.003461769289497688, 0.003372946769749133, 0.0037293784461352513, 0.0033922650460082426, 0.0033717941383710676, 0.0034687969054229256, 0.003022799130322048, 0.003428243369347751, 0.003393102298753746, 0.0033027953512493415, 0.0033014325432488465, 0.0032712474556630487, 0.0033565482034011865, 0.0033404276881505977, 0.0031623086311291667, 0.003155689220173954, 0.003343790589787335, 0.0032567371149343272], "accuracy_test_std": 0.005107170173503374, "error_valid": [0.41935858669051207, 0.3626253059111446, 0.2818927075489458, 0.23561629329819278, 0.21961478727409633, 0.2022190323795181, 0.19673616340361444, 0.18639989646084332, 0.18078466208584332, 0.17800793015813254, 0.16951301298945776, 0.1676922533885542, 0.16855704066265065, 0.16304328642695776, 0.1608254306287651, 0.1608563158885542, 0.15985916321536142, 0.15900467102786142, 0.1572853915662651, 0.1560440982680723, 0.15364387236445776, 0.15584113798945776, 0.15547492705195776, 0.15399978821536142, 0.1505509342055723, 0.1538674228162651, 0.15263642460466864, 0.15068329960466864, 0.15129365116716864, 0.14907579536897586, 0.15119217102786142, 0.1507950748305723, 0.14907579536897586, 0.14907579536897586, 0.1462475880082832, 0.14834337349397586, 0.1474682911332832, 0.1463696583207832, 0.14587108198418675, 0.14700060005647586, 0.1489846103162651, 0.1450268848832832, 0.14761095161897586, 0.14489451948418675, 0.14492540474397586, 0.14365322618599397, 0.14428416792168675, 0.14304287462349397, 0.1439076618975903, 0.14492540474397586, 0.14576960184487953, 0.14526073042168675, 0.14428416792168675, 0.1439282520707832, 0.14477244917168675, 0.14437535297439763, 0.14377529649849397, 0.1434193806475903, 0.14306346479668675, 0.14452830854668675, 0.14376500141189763, 0.14304287462349397, 0.14144566547439763, 0.1430531697100903, 0.14242222797439763, 0.14291050922439763, 0.14231045274849397, 0.14044851280120485, 0.14281932417168675, 0.14266636859939763, 0.14240163780120485, 0.1408044286521084, 0.14045880788780118, 0.14116034450301207, 0.14081472373870485, 0.1400720067771084, 0.13896307887801207, 0.1414147802146084, 0.1399499364646084, 0.13919692441641573, 0.1394616552146084, 0.13884100856551207, 0.1388513036521084, 0.13861745811370485, 0.14021466726280118, 0.1400720067771084, 0.1377217855798193, 0.13907485410391573, 0.14067206325301207, 0.13834243222891573, 0.13859686794051207, 0.13959402061370485, 0.13983816123870485, 0.14058087820030118, 0.13823065700301207, 0.13932928981551207, 0.1393395849021084, 0.13932928981551207, 0.13907485410391573, 0.1387292333396084, 0.1403161474021084, 0.1393395849021084, 0.14018378200301207, 0.14030585231551207, 0.1390645590173193, 0.14022496234939763, 0.13932928981551207, 0.13959402061370485, 0.13850568288780118, 0.13971609092620485, 0.13847479762801207, 0.1382100668298193, 0.13819977174322284, 0.14118093467620485, 0.1406823583396084, 0.13883071347891573, 0.13931899472891573, 0.1390954442771084, 0.13823065700301207, 0.13945136012801207, 0.14029555722891573, 0.1372335043298193, 0.13858657285391573, 0.1384542074548193, 0.13945136012801207, 0.13896307887801207, 0.1389733739646084, 0.13748794004141573, 0.1379659262048193, 0.13712172910391573, 0.1375997152673193, 0.1363584219691265, 0.13807770143072284, 0.13746734986822284, 0.13722320924322284, 0.13957343044051207, 0.1372129141566265, 0.13809829160391573, 0.13944106504141573, 0.13697906861822284, 0.1385762777673193, 0.13758942018072284, 0.13746734986822284, 0.1377217855798193, 0.1382100668298193, 0.13835272731551207, 0.1384542074548193, 0.1382100668298193, 0.1372129141566265, 0.13636871705572284, 0.1378438558923193, 0.1388204183923193, 0.13773208066641573, 0.1370908438441265, 0.13756883000753017, 0.13774237575301207, 0.13920721950301207, 0.13585984563253017, 0.1373555746423193, 0.13809829160391573, 0.1372129141566265, 0.1359922110316265, 0.13710113893072284, 0.1377217855798193, 0.1383115469691265, 0.1377217855798193, 0.1372129141566265, 0.1367246329066265, 0.13883071347891573, 0.1374570547816265, 0.13798651637801207, 0.13722320924322284, 0.13748794004141573, 0.1374776449548193, 0.1377217855798193, 0.13736586972891573, 0.1369893637048193, 0.13797622129141573, 0.1377217855798193, 0.1378438558923193, 0.1370908438441265, 0.13661285768072284, 0.13649078736822284, 0.1371114340173193, 0.13651137754141573, 0.13724379941641573, 0.13871893825301207, 0.13773208066641573, 0.13774237575301207, 0.13835272731551207, 0.1372335043298193, 0.1384542074548193, 0.1375997152673193, 0.1378747411521084, 0.13834243222891573, 0.1378747411521084, 0.1370908438441265, 0.13673492799322284, 0.1383630224021084, 0.13737616481551207, 0.1382409520896084, 0.13724379941641573, 0.13783356080572284, 0.13661285768072284, 0.13773208066641573, 0.1379659262048193, 0.13847479762801207, 0.1374776449548193], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.06248099316885596, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.00045058462464273887, "optimization": "adam", "nb_data_augmentation": 4, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.6217377170268074e-07, "rotation_range": [0, 0], "momentum": 0.7925928100125568}, "accuracy_valid_max": 0.8641401543674698, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8625223550451807, "accuracy_valid_std": [0.014921334179594608, 0.017976548195727308, 0.017950652043514592, 0.015256444721314495, 0.020671769629276446, 0.01947153136816908, 0.02165962151225961, 0.01781456321736897, 0.0175647561397567, 0.022321447695138604, 0.018121285977767645, 0.01770409899834717, 0.01915317110106238, 0.018823083896353048, 0.017901267698589792, 0.020219718671136772, 0.020122724189966835, 0.01897198845637628, 0.018045918440051115, 0.016475580745454188, 0.021113024087723427, 0.02108921820994348, 0.020647541065543895, 0.021399713697034913, 0.019322439670437744, 0.01953481131456898, 0.018471112188295755, 0.02021399541499229, 0.019991257384765773, 0.018997498451715094, 0.02103133724590445, 0.01910167908653825, 0.018469331481065786, 0.0174811852307375, 0.01684304979140666, 0.018780853009226734, 0.01718063064940274, 0.01715636503484288, 0.016269012548779514, 0.018517991637454014, 0.02051939531491149, 0.016574256487727517, 0.017107889733419916, 0.015074591449435622, 0.018391539338892114, 0.014426108128496951, 0.016127516149692118, 0.014829042161643305, 0.015281825791592766, 0.018136989680458418, 0.01740338463648561, 0.016500359684526948, 0.01605342927126676, 0.016717523932312673, 0.01632595942991785, 0.01413073406320877, 0.014486606801482824, 0.014541924035325926, 0.01595824467795617, 0.015891142927071233, 0.012416638433501511, 0.015256968725906176, 0.014115276234949944, 0.015179823388879687, 0.013749730618692267, 0.013134612089382736, 0.014368541199485673, 0.014296018699460988, 0.01597126699602895, 0.013300836872249092, 0.013274671585555056, 0.01189446580601893, 0.014632575113124326, 0.01146204155931424, 0.013270972144726757, 0.011982858412674442, 0.011499602981671332, 0.011834369169394227, 0.011504456638091546, 0.011548725498977877, 0.01250954887398064, 0.011149441235853404, 0.013004634151767926, 0.013273190580363057, 0.01267145372818034, 0.012062182404980252, 0.010883742549607832, 0.010522232228858494, 0.011370074305102512, 0.010671020205449975, 0.012202054483701465, 0.012931510552051701, 0.013248984169620897, 0.01366890632856356, 0.011306611370783877, 0.011786722287322918, 0.011653544681046058, 0.011674939738960438, 0.011106464593668463, 0.011779263357610878, 0.012070901206966892, 0.012672830617494238, 0.012774192269728594, 0.0127451300971583, 0.010340491488865258, 0.015032648754929495, 0.01303538405884836, 0.013232224993105886, 0.014263571999351467, 0.01237078994699685, 0.01215664577857253, 0.010412320536118132, 0.009950241275915256, 0.012582601791162662, 0.011027205907103028, 0.011388134233616155, 0.011660694115554886, 0.011987532012272184, 0.011285505018905274, 0.011382983095741091, 0.010563204029230258, 0.010884930156099074, 0.011209569067738123, 0.01068016544310171, 0.010635855499202668, 0.011735608039441337, 0.011755279513614887, 0.011343313310833776, 0.010647841601551475, 0.01111292857083462, 0.010373011545837679, 0.009684011145769809, 0.00934418747763196, 0.009532322033322166, 0.010812968719299907, 0.011379205082076398, 0.008725935158111583, 0.010849116217324076, 0.0107430958930418, 0.009767851103052075, 0.009754480877154793, 0.009652507116113871, 0.008681471978032162, 0.010413561905701543, 0.009955807067330423, 0.011326513436841174, 0.00977083848613322, 0.010039274098042016, 0.009165683689388335, 0.009648377137676831, 0.00970747144172409, 0.010312256983417667, 0.009727206767347604, 0.009471976482638861, 0.008927524991351929, 0.011202733376589091, 0.01058356811539459, 0.00939514186298499, 0.01032179302411312, 0.010285056817632372, 0.009034687139182172, 0.009343574022908578, 0.009999081055403551, 0.009763669889610792, 0.008086116549636058, 0.010275273651570532, 0.009585278848540138, 0.009709145246688249, 0.010171703771821531, 0.008790424342504691, 0.011678437609407772, 0.010823987763465916, 0.010014936143313785, 0.00974905907243981, 0.009677826184613025, 0.0106183987566226, 0.009920073866779112, 0.010869426524649527, 0.009957105351401953, 0.009241943213693263, 0.008967720663730708, 0.009015628780876254, 0.009306192914728588, 0.009909979176193111, 0.010830442183765828, 0.009667593548124607, 0.010172256652953675, 0.00962866568439888, 0.010779745382984807, 0.012207879546292206, 0.009654498180557566, 0.008644470390964745, 0.009408819384064975, 0.01123909218709835, 0.010014030817624467, 0.012513846440483182, 0.008233093538295305, 0.00883594154306774, 0.011760158052985522, 0.011476919759169037, 0.01178164077077035, 0.010195723735577053, 0.010015765152444542, 0.009678808213196784, 0.010718401500147579, 0.009360946759209858, 0.011036141149134286, 0.009272769100547128], "accuracy_valid": [0.5806414133094879, 0.6373746940888554, 0.7181072924510542, 0.7643837067018072, 0.7803852127259037, 0.7977809676204819, 0.8032638365963856, 0.8136001035391567, 0.8192153379141567, 0.8219920698418675, 0.8304869870105422, 0.8323077466114458, 0.8314429593373494, 0.8369567135730422, 0.8391745693712349, 0.8391436841114458, 0.8401408367846386, 0.8409953289721386, 0.8427146084337349, 0.8439559017319277, 0.8463561276355422, 0.8441588620105422, 0.8445250729480422, 0.8460002117846386, 0.8494490657944277, 0.8461325771837349, 0.8473635753953314, 0.8493167003953314, 0.8487063488328314, 0.8509242046310241, 0.8488078289721386, 0.8492049251694277, 0.8509242046310241, 0.8509242046310241, 0.8537524119917168, 0.8516566265060241, 0.8525317088667168, 0.8536303416792168, 0.8541289180158133, 0.8529993999435241, 0.8510153896837349, 0.8549731151167168, 0.8523890483810241, 0.8551054805158133, 0.8550745952560241, 0.856346773814006, 0.8557158320783133, 0.856957125376506, 0.8560923381024097, 0.8550745952560241, 0.8542303981551205, 0.8547392695783133, 0.8557158320783133, 0.8560717479292168, 0.8552275508283133, 0.8556246470256024, 0.856224703501506, 0.8565806193524097, 0.8569365352033133, 0.8554716914533133, 0.8562349985881024, 0.856957125376506, 0.8585543345256024, 0.8569468302899097, 0.8575777720256024, 0.8570894907756024, 0.857689547251506, 0.8595514871987951, 0.8571806758283133, 0.8573336314006024, 0.8575983621987951, 0.8591955713478916, 0.8595411921121988, 0.8588396554969879, 0.8591852762612951, 0.8599279932228916, 0.8610369211219879, 0.8585852197853916, 0.8600500635353916, 0.8608030755835843, 0.8605383447853916, 0.8611589914344879, 0.8611486963478916, 0.8613825418862951, 0.8597853327371988, 0.8599279932228916, 0.8622782144201807, 0.8609251458960843, 0.8593279367469879, 0.8616575677710843, 0.8614031320594879, 0.8604059793862951, 0.8601618387612951, 0.8594191217996988, 0.8617693429969879, 0.8606707101844879, 0.8606604150978916, 0.8606707101844879, 0.8609251458960843, 0.8612707666603916, 0.8596838525978916, 0.8606604150978916, 0.8598162179969879, 0.8596941476844879, 0.8609354409826807, 0.8597750376506024, 0.8606707101844879, 0.8604059793862951, 0.8614943171121988, 0.8602839090737951, 0.8615252023719879, 0.8617899331701807, 0.8618002282567772, 0.8588190653237951, 0.8593176416603916, 0.8611692865210843, 0.8606810052710843, 0.8609045557228916, 0.8617693429969879, 0.8605486398719879, 0.8597044427710843, 0.8627664956701807, 0.8614134271460843, 0.8615457925451807, 0.8605486398719879, 0.8610369211219879, 0.8610266260353916, 0.8625120599585843, 0.8620340737951807, 0.8628782708960843, 0.8624002847326807, 0.8636415780308735, 0.8619222985692772, 0.8625326501317772, 0.8627767907567772, 0.8604265695594879, 0.8627870858433735, 0.8619017083960843, 0.8605589349585843, 0.8630209313817772, 0.8614237222326807, 0.8624105798192772, 0.8625326501317772, 0.8622782144201807, 0.8617899331701807, 0.8616472726844879, 0.8615457925451807, 0.8617899331701807, 0.8627870858433735, 0.8636312829442772, 0.8621561441076807, 0.8611795816076807, 0.8622679193335843, 0.8629091561558735, 0.8624311699924698, 0.8622576242469879, 0.8607927804969879, 0.8641401543674698, 0.8626444253576807, 0.8619017083960843, 0.8627870858433735, 0.8640077889683735, 0.8628988610692772, 0.8622782144201807, 0.8616884530308735, 0.8622782144201807, 0.8627870858433735, 0.8632753670933735, 0.8611692865210843, 0.8625429452183735, 0.8620134836219879, 0.8627767907567772, 0.8625120599585843, 0.8625223550451807, 0.8622782144201807, 0.8626341302710843, 0.8630106362951807, 0.8620237787085843, 0.8622782144201807, 0.8621561441076807, 0.8629091561558735, 0.8633871423192772, 0.8635092126317772, 0.8628885659826807, 0.8634886224585843, 0.8627562005835843, 0.8612810617469879, 0.8622679193335843, 0.8622576242469879, 0.8616472726844879, 0.8627664956701807, 0.8615457925451807, 0.8624002847326807, 0.8621252588478916, 0.8616575677710843, 0.8621252588478916, 0.8629091561558735, 0.8632650720067772, 0.8616369775978916, 0.8626238351844879, 0.8617590479103916, 0.8627562005835843, 0.8621664391942772, 0.8633871423192772, 0.8622679193335843, 0.8620340737951807, 0.8615252023719879, 0.8625223550451807], "seed": 35717224, "model": "residualv3", "loss_std": [0.3021235167980194, 0.15324532985687256, 0.126135915517807, 0.11978940665721893, 0.1151127889752388, 0.110979825258255, 0.10800893604755402, 0.1036737710237503, 0.1005529835820198, 0.09886527806520462, 0.09769126027822495, 0.09492572396993637, 0.09395307302474976, 0.0924755334854126, 0.0902036651968956, 0.08839786797761917, 0.08799028396606445, 0.08646709471940994, 0.0862959623336792, 0.08390559256076813, 0.08351043611764908, 0.08399771898984909, 0.07975201308727264, 0.08189938962459564, 0.08009971678256989, 0.0790252611041069, 0.07898867875337601, 0.07613637298345566, 0.07551655918359756, 0.07579448074102402, 0.07556825876235962, 0.07419144362211227, 0.07328823208808899, 0.07310235500335693, 0.0736466720700264, 0.07164697349071503, 0.07190240174531937, 0.07160874456167221, 0.07034599781036377, 0.06951358169317245, 0.0698845311999321, 0.06873699277639389, 0.06784497946500778, 0.06796225160360336, 0.06717441231012344, 0.06561712175607681, 0.06545548141002655, 0.06543929874897003, 0.0654682070016861, 0.0650329664349556, 0.06362554430961609, 0.06225724518299103, 0.06264130771160126, 0.06380804628133774, 0.06323942542076111, 0.06323046237230301, 0.06331327557563782, 0.06193576380610466, 0.062299955636262894, 0.06299203634262085, 0.060799308121204376, 0.06143304705619812, 0.062407027930021286, 0.06097349524497986, 0.059649914503097534, 0.0617518313229084, 0.059065647423267365, 0.05965759605169296, 0.05812906101346016, 0.058714479207992554, 0.058334533125162125, 0.057313647121191025, 0.05765694007277489, 0.057086195796728134, 0.05708759278059006, 0.05761672556400299, 0.057280171662569046, 0.05572158470749855, 0.056300342082977295, 0.05516468361020088, 0.05543670430779457, 0.056016646325588226, 0.05425724759697914, 0.0553160235285759, 0.055192895233631134, 0.056244123727083206, 0.05378827080130577, 0.05497852712869644, 0.053793374449014664, 0.05416179820895195, 0.05407482385635376, 0.052766457200050354, 0.052557867020368576, 0.05353119969367981, 0.053124893456697464, 0.05336344242095947, 0.05324878916144371, 0.05326399952173233, 0.053414929658174515, 0.0524328388273716, 0.053272709250450134, 0.05145692825317383, 0.05266844853758812, 0.05142362788319588, 0.05150028318166733, 0.05086548253893852, 0.0512380450963974, 0.05001482740044594, 0.05150356516242027, 0.051092565059661865, 0.049277909100055695, 0.05009033530950546, 0.05093717575073242, 0.04928485304117203, 0.04833872988820076, 0.05012428015470505, 0.04831107705831528, 0.04867265745997429, 0.04958023503422737, 0.04992244392633438, 0.0491294227540493, 0.04874136298894882, 0.04939756914973259, 0.04939589276909828, 0.04752997308969498, 0.04817015677690506, 0.04731776937842369, 0.048493120819330215, 0.04687442630529404, 0.048125267028808594, 0.046732645481824875, 0.04735527187585831, 0.04813186451792717, 0.047454241663217545, 0.04686184227466583, 0.04725886508822441, 0.047354865819215775, 0.04587708041071892, 0.04670708253979683, 0.046592630445957184, 0.047482650727033615, 0.04646334424614906, 0.04642414674162865, 0.045569997280836105, 0.04412918537855148, 0.04539726302027702, 0.043864332139492035, 0.044905442744493484, 0.044904351234436035, 0.044674262404441833, 0.04540572687983513, 0.045270927250385284, 0.04597616195678711, 0.044632360339164734, 0.04500899463891983, 0.04632406309247017, 0.04491877555847168, 0.0441596582531929, 0.0437755323946476, 0.04432681202888489, 0.044861119240522385, 0.044541146606206894, 0.04605899378657341, 0.044575035572052, 0.04396599158644676, 0.04350494220852852, 0.043025001883506775, 0.043797388672828674, 0.04501853138208389, 0.042707692831754684, 0.04347676411271095, 0.042868733406066895, 0.043641891330480576, 0.04340508580207825, 0.04278809577226639, 0.043724581599235535, 0.042788781225681305, 0.043012380599975586, 0.04254714399576187, 0.042336996644735336, 0.041471533477306366, 0.04314834997057915, 0.0408795066177845, 0.04219755157828331, 0.04101935774087906, 0.04266703501343727, 0.043199554085731506, 0.041162170469760895, 0.0415266677737236, 0.042270489037036896, 0.04196638613939285, 0.04148038476705551, 0.04157288745045662, 0.04238602891564369, 0.040086060762405396, 0.04164551943540573, 0.041929394006729126, 0.04125317931175232, 0.04102317988872528, 0.040085818618535995, 0.0389825701713562, 0.0406322181224823, 0.040983423590660095, 0.04155377671122551, 0.04041646793484688, 0.04068862274289131, 0.040884364396333694, 0.03823293745517731]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:35 2016", "state": "available"}], "summary": "c5ce3ebf8ff6238a3bc3402f198235e3"}