{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.77314293384552, 1.3248043060302734, 1.053845763206482, 0.9131793975830078, 0.8267143368721008, 0.7672629356384277, 0.723947286605835, 0.6868047118186951, 0.6563938856124878, 0.6307308673858643, 0.6110819578170776, 0.593142569065094, 0.5759501457214355, 0.5609986782073975, 0.5469062328338623, 0.5342177748680115, 0.5215989947319031, 0.510786235332489, 0.501975953578949, 0.49219703674316406, 0.48191556334495544, 0.47460561990737915, 0.46636563539505005, 0.4592932164669037, 0.4529193043708801, 0.4447330832481384, 0.4406066834926605, 0.43192198872566223, 0.42898595333099365, 0.4192963242530823, 0.4160059988498688, 0.41042229533195496, 0.40609195828437805, 0.4010043740272522, 0.3947615325450897, 0.3911650478839874, 0.38578760623931885, 0.3831106126308441, 0.37934550642967224, 0.37584277987480164, 0.3704317808151245, 0.3681613504886627, 0.36254286766052246, 0.36051422357559204, 0.356120228767395, 0.3524063527584076, 0.3503304421901703, 0.34633669257164, 0.34428274631500244, 0.341225266456604, 0.3400391638278961, 0.336002916097641, 0.3328556716442108, 0.3304089307785034, 0.3257753849029541, 0.32419076561927795, 0.32127681374549866, 0.3203710913658142, 0.3170962631702423, 0.3149665892124176, 0.31308630108833313, 0.3117918074131012, 0.3084889054298401, 0.30785563588142395, 0.30256718397140503, 0.30262792110443115, 0.29905736446380615, 0.2987322509288788, 0.2954648435115814, 0.29439958930015564, 0.2919163405895233, 0.2918683588504791, 0.2891639769077301, 0.2877010405063629, 0.28649473190307617, 0.2849906086921692, 0.28304746747016907, 0.281374990940094, 0.2815781533718109, 0.2789677381515503, 0.2759583294391632, 0.2758042812347412, 0.27473384141921997, 0.2731130123138428, 0.27095267176628113, 0.2711748480796814, 0.2684592306613922, 0.26642483472824097, 0.2636842131614685, 0.2651022672653198, 0.2641981542110443, 0.26077741384506226, 0.2615167498588562, 0.26019152998924255, 0.25857603549957275, 0.2584340572357178, 0.2547946274280548, 0.2538991868495941, 0.2547764480113983, 0.25385764241218567, 0.25103631615638733, 0.249638170003891, 0.2488591969013214, 0.24861982464790344, 0.24688579142093658, 0.24657957255840302, 0.24602550268173218, 0.24416813254356384, 0.24391081929206848, 0.24384187161922455, 0.24096636474132538, 0.240839421749115, 0.23847709596157074, 0.23950257897377014, 0.23847250640392303, 0.23792621493339539, 0.23574107885360718, 0.23495721817016602, 0.2349199801683426, 0.2336576133966446, 0.23254355788230896, 0.23199394345283508, 0.2307586371898651, 0.2300892323255539, 0.22973361611366272, 0.22923915088176727, 0.2289738953113556, 0.22725853323936462, 0.22722934186458588, 0.22586147487163544, 0.2245330810546875, 0.22544996440410614, 0.22389225661754608, 0.22302700579166412, 0.22126707434654236, 0.22071656584739685, 0.22012147307395935, 0.2206743061542511, 0.22001613676548004, 0.2184954434633255, 0.21876585483551025, 0.217041477560997, 0.21681518852710724, 0.21675258874893188, 0.2159530520439148, 0.21507522463798523, 0.21538595855236053, 0.21378128230571747, 0.21472282707691193, 0.21353226900100708, 0.21114547550678253, 0.2111412137746811, 0.2101801186800003, 0.2108001410961151, 0.20926502346992493, 0.2095789909362793, 0.20980778336524963, 0.20809689164161682, 0.20644426345825195, 0.20820894837379456, 0.20642098784446716, 0.20580802857875824, 0.20696218311786652, 0.20600415766239166, 0.2037402093410492, 0.2026917189359665, 0.2041853368282318, 0.20317694544792175, 0.20343150198459625, 0.2026957869529724, 0.20061244070529938, 0.20235709846019745, 0.20164762437343597, 0.19894631206989288, 0.20047295093536377, 0.2003244012594223, 0.1993403136730194, 0.19829161465168, 0.1972609907388687, 0.19752918183803558, 0.19704300165176392, 0.1962965428829193, 0.19667133688926697, 0.19646038115024567, 0.19557656347751617, 0.19590499997138977, 0.19525422155857086, 0.19457626342773438, 0.19368818402290344, 0.19255122542381287, 0.19310979545116425, 0.19277039170265198, 0.19260208308696747, 0.1930004209280014, 0.1914900839328766, 0.19063693284988403, 0.19035732746124268, 0.18955956399440765, 0.18992622196674347, 0.18868835270404816, 0.19107165932655334, 0.1887880265712738, 0.1874518245458603, 0.18803800642490387, 0.18720464408397675, 0.18664239346981049, 0.18741804361343384, 0.18625622987747192, 0.18827392160892487, 0.18449276685714722, 0.1865382045507431, 0.1850689947605133, 0.18603239953517914, 0.18405817449092865, 0.18427564203739166, 0.1816110461950302, 0.18302133679389954, 0.18250568211078644, 0.18416844308376312, 0.1829434186220169, 0.18324780464172363, 0.1806313395500183, 0.18212877213954926, 0.1813277006149292, 0.18213169276714325, 0.18036407232284546, 0.18133313953876495, 0.17967937886714935, 0.17993278801441193, 0.17873339354991913, 0.18037933111190796, 0.17872029542922974, 0.17838244140148163, 0.17915140092372894, 0.1782681792974472, 0.1770021617412567, 0.1779552549123764, 0.1776942014694214], "moving_avg_accuracy_train": [0.030783275943613873, 0.08201153850590623, 0.13894840116279067, 0.19863439114987075, 0.25404935706210774, 0.3041504386247231, 0.3534722816439414, 0.3988776699028123, 0.44056333291437677, 0.48016551132582763, 0.5154192441425804, 0.5490399143204228, 0.5790826030805639, 0.6073996385170165, 0.6324873699633953, 0.6563007299412621, 0.6783094268749229, 0.6984494620044296, 0.7171103138959948, 0.7338423736781838, 0.749180209290478, 0.7632678573986672, 0.7762954409198285, 0.7886455869233606, 0.7997978846586732, 0.8104464667573592, 0.8202205644580076, 0.8285430301779045, 0.837028268821013, 0.8444953558831716, 0.8514109025438393, 0.8579744744110871, 0.8641675021510876, 0.8695785748468777, 0.8748017826480426, 0.8798072641631387, 0.8844773551898388, 0.8888896284090886, 0.8928467234135562, 0.8967476887902238, 0.9002816649220449, 0.903478591579988, 0.9067045978935654, 0.9095498388067282, 0.912371044392879, 0.915068131393006, 0.9176676067538438, 0.9202815381869405, 0.9226270649814801, 0.9248520074370512, 0.9268660813911127, 0.9287694287533396, 0.9304195542150303, 0.9322070085734275, 0.9337645642221757, 0.9355080169857739, 0.9370958698587636, 0.9385946919087399, 0.9399227414632516, 0.9413620545896747, 0.9426225591713125, 0.9439546509435962, 0.9450907184719756, 0.9462642418224985, 0.9472717289082442, 0.9483992482758637, 0.9495836794721791, 0.9505614200405573, 0.9515669085389933, 0.9523741919375857, 0.9533425264236906, 0.9542373149980988, 0.9549635696555425, 0.9558891331114998, 0.9567848831908998, 0.9577608662230925, 0.958639250952066, 0.9592693979891038, 0.9598131706878864, 0.9605489597929626, 0.9613181989304068, 0.9619361814898394, 0.9625829744992626, 0.9631000561387143, 0.963595620499926, 0.9640671690131024, 0.9645543777416371, 0.9652556074127946, 0.965893653514446, 0.9663005563892841, 0.9667899658147245, 0.9673350659940495, 0.9677442398982898, 0.9681078821633058, 0.968425859606582, 0.9689142912031404, 0.9690935350710139, 0.9694850082354242, 0.9698791146643273, 0.9703500318419975, 0.9707762545483478, 0.9711761310257297, 0.9715220689625164, 0.97195199569491, 0.9724784386826357, 0.972801066650151, 0.9731542829364094, 0.9735627862999758, 0.9738118927867188, 0.9741360700235968, 0.9745533875725014, 0.9749150224736585, 0.9752614202239855, 0.9756057302826132, 0.9760038928925026, 0.9762320669568884, 0.9764607111517496, 0.9766991151080955, 0.9769740243913982, 0.9772865469130373, 0.9775934298682359, 0.9778998514624386, 0.9780895282936312, 0.9784300093536183, 0.9787179492635869, 0.9789305201087306, 0.9791799265407792, 0.97941372897368, 0.9797101456204242, 0.9798327613763036, 0.9799686921934997, 0.9802537542968242, 0.9804312551302924, 0.9806561460958992, 0.9808328992304031, 0.9810989699455134, 0.9814127662533799, 0.9816719674911832, 0.9817913163135396, 0.9819383298810597, 0.9821217593168187, 0.9822914961066207, 0.9824070568364902, 0.9826110068433636, 0.9826736901602731, 0.9828324477419295, 0.9830101707487443, 0.9832143353310774, 0.983349255330177, 0.9834892484710243, 0.983480419715653, 0.983751455644143, 0.9838373139095552, 0.9839587281269884, 0.9841283466452696, 0.9842159712426934, 0.9842878939827652, 0.9844503167476485, 0.9846685768491388, 0.9848091352714139, 0.9849565641907472, 0.9849496331431196, 0.984987645125273, 0.9851265236544586, 0.9853375808854967, 0.9854855715684032, 0.9855932946925706, 0.9857763120590924, 0.985917740152048, 0.9860613014773748, 0.9861416785451689, 0.986204645213308, 0.986393848696776, 0.9864990997628681, 0.986630919956847, 0.9867612199242946, 0.9868575996045302, 0.9869303543750665, 0.9871563410340438, 0.987343416936638, 0.9874141650477914, 0.9875150046799632, 0.9875150795453463, 0.9874779445432389, 0.9874933511663421, 0.9875164095759168, 0.9875908208112468, 0.9877041857527781, 0.987829537785889, 0.9878888401442509, 0.9879817037477199, 0.988130457255146, 0.9880899132022966, 0.9882487000059132, 0.9883567669458443, 0.988328469156068, 0.9883122656916885, 0.9883813879308898, 0.988511063310466, 0.988590604819951, 0.9886877688153922, 0.988742664327956, 0.9888083463309301, 0.9889162161609693, 0.9890226356520614, 0.9890951977547677, 0.9892534375019468, 0.9893377606029887, 0.9894624795189265, 0.9895328378158803, 0.9895427179093385, 0.9896677953362893, 0.9897059963074593, 0.9898310940339023, 0.9898366890936443, 0.9899439590973936, 0.9900034078662718, 0.9900638872046909, 0.9901624243390114, 0.9901882566444051, 0.9902441659490491, 0.990299098572029, 0.9903323700375006, 0.9903342683754357, 0.9903384822724806, 0.9903840193119361, 0.9903901254153031, 0.9904467741821431, 0.9905093477675279, 0.9905191970670024, 0.9905722392639105, 0.9906153269435087, 0.9906657676480136, 0.9907297294237254, 0.9907687298802086, 0.9908386354255487, 0.9908713595306499, 0.9909263518133269], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.030703036756400598, 0.0822380194606551, 0.13778948459855042, 0.195838619958349, 0.249525330486987, 0.2981617822839208, 0.3459986478714173, 0.3898626385059623, 0.43034429516553174, 0.4684186758899424, 0.502160716198162, 0.5339608931664482, 0.5626054665004059, 0.589110944888016, 0.6122028624474071, 0.6338044888532687, 0.653664080207023, 0.6718195036528117, 0.6884655900439312, 0.7035844336656676, 0.7171516833055015, 0.7295575204813519, 0.7410157426896173, 0.7513881483246466, 0.7606877218110826, 0.7693554542421731, 0.7770444911315852, 0.7838334355142851, 0.7904551512625554, 0.7961705548109986, 0.8014507543656668, 0.8063748619110278, 0.8109652501081027, 0.8149898247301991, 0.8186332674266069, 0.8219336913898949, 0.8251349770419446, 0.8280558437485181, 0.8305716719772055, 0.833034318409003, 0.8350055300639612, 0.8369068384092216, 0.8388122989112965, 0.8403277828285253, 0.8418890898713505, 0.843614737548372, 0.8451709089836704, 0.8466283803970504, 0.8478170048479327, 0.8490454582599767, 0.8500025229384971, 0.8507428403453251, 0.851309410744151, 0.8523371669588925, 0.8531400772396599, 0.8536663544836909, 0.8543485530432284, 0.8548526684655622, 0.8557377364740512, 0.8562992755619623, 0.8568321633295612, 0.8574073595530811, 0.857802965841749, 0.8582779932880711, 0.8586608078993995, 0.8589178328135257, 0.8593322607049894, 0.8599280608957856, 0.8601407212030444, 0.8603463815281466, 0.8607044332755578, 0.8610856559871587, 0.8614165493963495, 0.8618506898256905, 0.8621549374846876, 0.8622090338152851, 0.8623533177455035, 0.862535089933679, 0.8627953116443773, 0.8629440619652557, 0.8631664749987754, 0.8634490074217142, 0.8638508004860187, 0.8636966304054138, 0.8638406980689386, 0.8641209613757496, 0.8642225959422408, 0.8643537766718119, 0.8644606618058356, 0.8646137755480683, 0.8648014355497374, 0.8651046068949896, 0.8649868361057165, 0.8649784986453707, 0.8653047028094482, 0.8654873937672081, 0.8653669358758035, 0.8653073518985395, 0.8654012402026615, 0.8655244197874405, 0.8657207306324917, 0.8659940371343781, 0.8661291201961662, 0.8662781975402544, 0.8663604504989548, 0.8665474299690142, 0.8668224862473387, 0.8668910494637193, 0.8668520115824829, 0.8669908644528491, 0.8671483350952901, 0.8671425447898273, 0.8671251264836608, 0.8672946144941802, 0.8673505269623074, 0.8674852678937122, 0.8674732868968862, 0.8673241086213542, 0.8674136927705139, 0.8676041817860077, 0.8677898879485214, 0.8678664267327355, 0.8678000047861186, 0.8678500883154133, 0.867811773290348, 0.868012311887518, 0.8679292424081035, 0.8681292116160884, 0.8680996053547054, 0.8680241315944608, 0.8681647542501503, 0.8681804218503612, 0.8684874914405509, 0.8686428132678814, 0.868638177554798, 0.8685179650798152, 0.8685105186283095, 0.8685170533618641, 0.868548378193223, 0.8684259681318073, 0.8684786085174216, 0.8685015708019747, 0.8683970780195934, 0.8683926017688388, 0.8682867988585212, 0.8681936352565547, 0.8682928934835348, 0.8682713330979073, 0.8684869508705713, 0.8684979013972189, 0.868516875376473, 0.8685471884977113, 0.8685134351505757, 0.8687282272718133, 0.8686000393337886, 0.8687451358804549, 0.8686437891787047, 0.8686094942687408, 0.868518623202183, 0.8683869816086214, 0.8684913192628948, 0.8683421120354005, 0.8682576831643152, 0.8683281815553384, 0.8684495767375305, 0.8684967677365938, 0.8685901267780699, 0.86860899672451, 0.8687552565494234, 0.8689326299908666, 0.8690932955968251, 0.8690537596647782, 0.869252169937005, 0.8693697040257593, 0.8693401778532286, 0.8695842180027702, 0.8693714605003094, 0.8692898420293448, 0.8691543207405669, 0.869364000441736, 0.869370636212698, 0.8694599986079945, 0.8697164707445595, 0.8696156468063987, 0.869659182605804, 0.8695752650041091, 0.8696716671087433, 0.8699812440913931, 0.8701245565233682, 0.8702036800784861, 0.870101933823273, 0.870093752395012, 0.8698300414533271, 0.8700759823851781, 0.8701711408767056, 0.8700360274479205, 0.8700009040894237, 0.8701422505215958, 0.8702094566629602, 0.870096984735369, 0.8700282630596483, 0.8699674430601594, 0.8700877215327579, 0.8700565472710484, 0.8701323237374676, 0.8700031510399258, 0.869972344830888, 0.8701318427461425, 0.870014925178983, 0.8701304554396992, 0.8700248541257745, 0.8701749830769019, 0.8701758217891665, 0.8702742328802047, 0.8703495663222294, 0.8702597045224613, 0.8702642781214199, 0.8700323427320942, 0.87010745112643, 0.8702768229659708, 0.8704149915729881, 0.8705138997481441, 0.8707158689130133, 0.8706351164531879, 0.8705512617167547, 0.8705388866275341, 0.870678351456874, 0.870751953152301, 0.8705984681156853, 0.8703860598865716, 0.8702528391106403, 0.8701970640945311, 0.8702699664011925, 0.870224685687278, 0.8701096613485954, 0.8702889601798504, 0.8703282588154798, 0.8705212894851366], "moving_var_accuracy_train": [0.008528490700386093, 0.03129465559670797, 0.057341446999917486, 0.08366905890656617, 0.10293951903939905, 0.11523663249915367, 0.12560676703855006, 0.13160093388114436, 0.13408009099945337, 0.1347870747138995, 0.13249379834014446, 0.12941756367499535, 0.12459887563894424, 0.11935567853823366, 0.11308465910654092, 0.10687987821680606, 0.10055133506158502, 0.09414679069058636, 0.08786615816139812, 0.08159919876625103, 0.07555652170105377, 0.0697870259939299, 0.06433578478614442, 0.05927494126430702, 0.05446681084086983, 0.050040660463194955, 0.04589639128963184, 0.041930123081598394, 0.038385104246913056, 0.03504841032496645, 0.031973992363012654, 0.029164317407620117, 0.026593068000153854, 0.024197278569610594, 0.02202308781025689, 0.020046272636012916, 0.018237933124190614, 0.016589353206423334, 0.015071345293650448, 0.01370116854211504, 0.012443452573606068, 0.011291090376751871, 0.010255645389693856, 0.009302939413409891, 0.008444278280702856, 0.007665318957208858, 0.006959602510852399, 0.006325135997599533, 0.00574213586133471, 0.005212475595576662, 0.0047277364810508595, 0.004287567413577437, 0.0038833168985735753, 0.0035237401464663994, 0.0031931999482102823, 0.002901236601239339, 0.002633804431831757, 0.0023906421964860394, 0.0021674514174105856, 0.001969350876152571, 0.0017867156347402856, 0.0016240142876743295, 0.001473228703768239, 0.0013383002468794199, 0.0012136054942429775, 0.0011036866441378967, 0.0010059438750533538, 0.0009139532771194919, 0.0008316570134919258, 0.0007543566705135187, 0.0006873600485549862, 0.0006258298630355131, 0.0005679938891790901, 0.0005189045096602149, 0.0004742353725369002, 0.00043538472119536404, 0.0003987902866646723, 0.0003624850255927923, 0.0003288977217649838, 0.0003008804200528257, 0.00027611793770272687, 0.0002519432659263194, 0.00023051401010703635, 0.00020986896989305553, 0.00019109232922867768, 0.00017398431830832045, 0.00015872223758393216, 0.00014727552129094296, 0.0001362118946123431, 0.0001240808346970728, 0.00011382844549875412, 0.00010511980879837877, 9.611463747374222e-05, 8.769329499852153e-05, 7.98339523885621e-05, 7.399764597035603e-05, 6.68870366508526e-05, 6.157759413184754e-05, 5.6817713614387866e-05, 5.31318091469735e-05, 4.945362039095314e-05, 4.594736912632811e-05, 4.2429689718668676e-05, 3.985025370384176e-05, 3.835950830738756e-05, 3.546035672545643e-05, 3.3037176756814564e-05, 3.123533406353962e-05, 2.867028703282228e-05, 2.6749076257729675e-05, 2.564155406157061e-05, 2.4254416871027215e-05, 2.290889779680914e-05, 2.1684952765377875e-05, 2.0943258664064776e-05, 1.931750343058322e-05, 1.78562565981184e-05, 1.6582158955918918e-05, 1.5604119086740955e-05, 1.4922740116851649e-05, 1.4278060438889792e-05, 1.3695302135543877e-05, 1.264956762461041e-05, 1.2427957032039488e-05, 1.1931345854609738e-05, 1.1144888546994817e-05, 1.0590231807420688e-05, 1.0023180825351085e-05, 9.811628199019831e-06, 8.965776991426578e-06, 8.235493975856447e-06, 8.143288203036641e-06, 7.612518295670131e-06, 7.306449983807113e-06, 6.856980020438789e-06, 6.808424647348723e-06, 7.013795288089851e-06, 6.917083294390204e-06, 6.35357223753191e-06, 5.912731915093798e-06, 5.624275944709962e-06, 5.321143550549805e-06, 4.909217736086571e-06, 4.7926564102105605e-06, 4.34875355315849e-06, 4.140713925442968e-06, 4.010911737260344e-06, 3.984969153647296e-06, 3.7503028936962057e-06, 3.5516553196849422e-06, 3.19719131000908e-06, 3.53861644980047e-06, 3.251099580476764e-06, 3.0586623321833185e-06, 3.0117300746602778e-06, 2.7796596978576468e-06, 2.5482496529267406e-06, 2.5308550786051776e-06, 2.7065068178673803e-06, 2.6136661667329016e-06, 2.5479171263617477e-06, 2.2935577685165292e-06, 2.0772061887500407e-06, 2.0430707826936146e-06, 2.239670097385408e-06, 2.2128142676912958e-06, 2.095971284245705e-06, 2.1878323638584143e-06, 2.1490662767662387e-06, 2.119648336255818e-06, 1.9658277598748206e-06, 1.8049281955561648e-06, 1.946616999408459e-06, 1.8516553816892513e-06, 1.8228789153862108e-06, 1.7933937574988551e-06, 1.6976557666100604e-06, 1.575529499671132e-06, 1.877606280025494e-06, 2.0048221920056775e-06, 1.8493876298911824e-06, 1.7559665496508994e-06, 1.58036994512924e-06, 1.4347440260500595e-06, 1.2934058997640532e-06, 1.168850522056691e-06, 1.1017987573411544e-06, 1.1072833713225572e-06, 1.1379732240356326e-06, 1.0558268289977426e-06, 1.0278569857411363e-06, 1.1242197409115305e-06, 1.0265921488134777e-06, 1.1508521749576597e-06, 1.1408731290163786e-06, 1.033992700270795e-06, 9.329564005647662e-07, 8.826617160782394e-07, 9.457368810845258e-07, 9.08104858556402e-07, 9.022619507916903e-07, 8.391574114092825e-07, 7.940687999005201e-07, 8.19385022004547e-07, 8.393724925627622e-07, 8.028225720490383e-07, 9.478986731301532e-07, 9.171022741411027e-07, 9.653853186611734e-07, 9.133993963471922e-07, 8.229380029331424e-07, 8.814434672339419e-07, 8.064329482954506e-07, 8.666346239169526e-07, 7.802529037668986e-07, 8.057892967295209e-07, 7.570177721467851e-07, 7.14235748312461e-07, 7.301982750420968e-07, 6.631842195555161e-07, 6.249984507119689e-07, 5.896569432478562e-07, 5.406541626546695e-07, 4.866211795714436e-07, 4.381188739690403e-07, 4.129695842335103e-07, 3.720081862951294e-07, 3.636891127259871e-07, 3.625592837445788e-07, 3.2717643367138576e-07, 3.197800621797929e-07, 3.045109891602682e-07, 2.969582722826973e-07, 3.0408242382423e-07, 2.873635018948365e-07, 3.0260821912910765e-07, 2.8198520070819986e-07, 2.810040410236129e-07], "duration": 135356.645764, "accuracy_train": [0.3078327594361388, 0.5430659015665376, 0.6513801650747508, 0.7358083010335917, 0.7527840502722407, 0.7550601726882613, 0.7973688688169066, 0.8075261642326504, 0.815734300018457, 0.8365851170288853, 0.8327028394933554, 0.851625945921004, 0.8494668019218347, 0.8622529574450905, 0.8582769529808048, 0.8706209697420635, 0.87638769927787, 0.879709778169989, 0.8850579809200813, 0.8844309117178849, 0.887220729801126, 0.8900566903723699, 0.8935436926102805, 0.8997969009551495, 0.9001685642764857, 0.9062837056455334, 0.9081874437638427, 0.9034452216569768, 0.9133954166089886, 0.9116991394425988, 0.9136508224898486, 0.9170466212163161, 0.9199047518110927, 0.9182782291089886, 0.9218106528585271, 0.9248565977990033, 0.9265081744301403, 0.9286000873823367, 0.9284605784537652, 0.9318563771802326, 0.9320874501084349, 0.9322509315014765, 0.9357386547157622, 0.9351570070251938, 0.9377618946682356, 0.9393419143941492, 0.9410628850013842, 0.9438069210848099, 0.9437368061323367, 0.9448764895371908, 0.944992746977667, 0.9458995550133813, 0.9452706833702473, 0.9482940977990033, 0.9477825650609081, 0.951199091858158, 0.9513865457156699, 0.9520840903585271, 0.9518751874538575, 0.9543158727274824, 0.9539671004060539, 0.9559434768941492, 0.9553153262273901, 0.9568259519772055, 0.9563391126799556, 0.9585469225844407, 0.960243560239018, 0.9593610851559615, 0.9606163050249169, 0.9596397425249169, 0.9620575367986341, 0.962290412167774, 0.961499861572536, 0.9642192042151162, 0.9648466339055003, 0.9665447135128276, 0.9665447135128276, 0.9649407213224437, 0.9647071249769288, 0.967171061738649, 0.9682413511674051, 0.9674980245247323, 0.9684041115840717, 0.9677537908937799, 0.9680556997508305, 0.9683111056316908, 0.9689392562984496, 0.9715666744532114, 0.9716360684293098, 0.9699626822628276, 0.9711946506436876, 0.9722409676079733, 0.9714268050364526, 0.9713806625484496, 0.9712876565960686, 0.9733101755721669, 0.9707067298818751, 0.9730082667151162, 0.9734260725244556, 0.97458828644103, 0.9746122589055003, 0.9747750193221669, 0.9746355103935955, 0.9758213362864526, 0.9772164255721669, 0.9757047183577889, 0.9763332295127353, 0.9772393165720746, 0.9760538511674051, 0.9770536651555003, 0.9783092455126431, 0.9781697365840717, 0.9783789999769288, 0.9787045208102622, 0.9795873563815062, 0.9782856335363603, 0.9785185089055003, 0.9788447507152085, 0.9794482079411223, 0.9800992496077889, 0.9803553764650241, 0.9806576458102622, 0.9797966197743633, 0.9814943388935032, 0.9813094084533037, 0.9808436577150241, 0.9814245844292175, 0.981517950869786, 0.9823778954411223, 0.9809363031792175, 0.9811920695482651, 0.9828193132267442, 0.9820287626315062, 0.9826801647863603, 0.9824236774409376, 0.9834936063815062, 0.9842369330241787, 0.9840047786314139, 0.9828654557147471, 0.9832614519887413, 0.983772624238649, 0.9838191272148394, 0.9834471034053157, 0.9844465569052234, 0.9832378400124585, 0.9842612659768365, 0.9846096778100776, 0.9850518165720746, 0.9845635353220746, 0.984749186738649, 0.9834009609173128, 0.9861907790005537, 0.9846100382982651, 0.9850514560838871, 0.9856549133098007, 0.9850045926195091, 0.984935198643411, 0.9859121216315985, 0.9866329177625508, 0.98607416107189, 0.9862834244647471, 0.9848872537144703, 0.9853297529646549, 0.9863764304171282, 0.9872370959648394, 0.9868174877145626, 0.9865628028100776, 0.9874234683577889, 0.987190592988649, 0.9873533534053157, 0.9868650721553157, 0.9867713452265596, 0.9880966800479882, 0.9874463593576966, 0.9878173017026578, 0.9879339196313216, 0.9877250167266519, 0.987585147309893, 0.9891902209648394, 0.9890271000599853, 0.9880508980481728, 0.9884225613695091, 0.9875157533337948, 0.987143729524271, 0.987632010774271, 0.9877239352620893, 0.9882605219292175, 0.9887244702265596, 0.9889577060838871, 0.9884225613695091, 0.9888174761789406, 0.9894692388219823, 0.9877250167266519, 0.9896777812384644, 0.9893293694052234, 0.9880737890480805, 0.9881664345122739, 0.9890034880837025, 0.9896781417266519, 0.9893064784053157, 0.9895622447743633, 0.98923672394103, 0.9893994843576966, 0.9898870446313216, 0.98998041107189, 0.9897482566791252, 0.9906775952265596, 0.9900966685123662, 0.9905849497623662, 0.9901660624884644, 0.9896316387504615, 0.9907934921788483, 0.9900498050479882, 0.99095697357189, 0.9898870446313216, 0.990909389131137, 0.9905384467861758, 0.9906082012504615, 0.9910492585478959, 0.9904207473929494, 0.9907473496908453, 0.9907934921788483, 0.9906318132267442, 0.9903513534168512, 0.9903764073458842, 0.9907938526670359, 0.9904450803456073, 0.9909566130837025, 0.9910725100359912, 0.9906078407622739, 0.9910496190360835, 0.991003116059893, 0.9911197339885567, 0.9913053854051311, 0.9911197339885567, 0.9914677853336102, 0.9911658764765596, 0.9914212823574198], "end": "2016-02-05 11:07:46.200000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0], "moving_var_accuracy_valid": [0.008484088194583976, 0.03153836935607589, 0.0561582199311695, 0.0808697169822345, 0.09872311127048296, 0.11014034013399387, 0.11972159750372033, 0.12506588482283537, 0.1273081770736812, 0.12762428557423947, 0.12510858457426918, 0.12169898741377115, 0.1169136929057543, 0.11154518707618342, 0.10518979827769255, 0.09887049082032909, 0.09253307205693925, 0.08624633945570837, 0.08011553523940303, 0.07416119660758941, 0.06840170931193662, 0.06294668154504637, 0.05783363109610762, 0.05301854917441513, 0.04849503286024022, 0.04432169584368901, 0.04042161785390078, 0.036794263960993244, 0.033509461639951936, 0.030452508015450762, 0.027658181779939752, 0.02511058511801031, 0.022789171580407882, 0.020656029230366493, 0.018709898379467908, 0.016936943726558133, 0.015335483422336491, 0.013878718240960973, 0.012547810941951216, 0.011347611494788499, 0.010247821423807434, 0.009255574042240507, 0.008362693655541162, 0.007547094513517458, 0.006814324179303491, 0.006159692500520032, 0.005565518276292375, 0.005028084454950514, 0.00453799146222258, 0.0040977741960703876, 0.003696240531653191, 0.0033315491072535446, 0.003001283214679622, 0.0027106614387441184, 0.002445397279140364, 0.0022033502608645914, 0.001987203788649848, 0.0017907706010161762, 0.0016187436493314141, 0.0014597072197235416, 0.0013162922221068968, 0.00118764065615617, 0.0010702851295612545, 0.0009652874762779627, 0.0008700776518899853, 0.0007836644429593216, 0.0007068437529583969, 0.0006393541784687328, 0.0005758257802784101, 0.0005186238677744593, 0.00046791529048143167, 0.0004224317382358512, 0.00038117397844647906, 0.0003447528818133263, 0.0003111106933740413, 0.00028002596175349427, 0.00025221072625081843, 0.00022728702378128378, 0.0002051677594516245, 0.0001848501234281153, 0.0001668103191026183, 0.00015084770832246114, 0.00013721587648892375, 0.00012370820456381482, 0.00011152418353249505, 0.00010107869286954705, 9.106378984854526e-05, 8.211228631798798e-05, 7.400387757306641e-05, 6.681448417830432e-05, 6.044998224651182e-05, 5.52321998030987e-05, 4.9833809452042804e-05, 4.4851054126043675e-05, 4.132363112339216e-05, 3.7491651885478355e-05, 3.387307762934516e-05, 3.05177221195301e-05, 2.7545285030435155e-05, 2.4927315418348653e-05, 2.2781425407475984e-05, 2.117555086248867e-05, 1.922222267847823e-05, 1.750001690131393e-05, 1.581090515411737e-05, 1.4544466538718641e-05, 1.3770923491058212e-05, 1.2436139373716455e-05, 1.120624104188765e-05, 1.0259138014179198e-05, 9.456397241838293e-06, 8.51105926639063e-06, 7.662683916258943e-06, 7.154951196021653e-06, 6.467591913248124e-06, 5.98422878928581e-06, 5.387097808921739e-06, 5.048675449045859e-06, 4.616035782167381e-06, 4.481006789164779e-06, 4.343287119408346e-06, 3.96168207686831e-06, 3.605220744112915e-06, 3.267273908861203e-06, 2.9537588882869645e-06, 3.020324560052532e-06, 2.7803969497389722e-06, 2.862246412043796e-06, 2.583910547257086e-06, 2.376786088900563e-06, 2.317080061648911e-06, 2.0875813187513313e-06, 2.727448785850133e-06, 2.6718277376725354e-06, 2.4048383724274e-06, 2.294413887458107e-06, 2.065471545472525e-06, 1.8593087156089372e-06, 1.6822090495849405e-06, 1.648846152848534e-06, 1.5089006293424323e-06, 1.3627559650152336e-06, 1.3247490426415781e-06, 1.1924544697647764e-06, 1.1739573252733862e-06, 1.1346767033285442e-06, 1.1098787936047318e-06, 1.003074566299947e-06, 1.3211863246675806e-06, 1.190146918505579e-06, 1.074372333653604e-06, 9.752050681610785e-07, 8.879381573306703e-07, 1.2143652397093922e-06, 1.2408180428336802e-06, 1.3062133092407517e-06, 1.268032363917672e-06, 1.1518143951707542e-06, 1.1109509122898596e-06, 1.155821403459988e-06, 1.1382163780074686e-06, 1.2247599108355287e-06, 1.1664380282065075e-06, 1.0945244336177266e-06, 1.1177031025909456e-06, 1.0259757058651112e-06, 1.0018213309067303e-06, 9.048438717238894e-07, 1.006886912004956e-06, 1.1893502603690863e-06, 1.302736166774348e-06, 1.18653035940232e-06, 1.4221770485888434e-06, 1.4042877019037238e-06, 1.2717050854921915e-06, 1.6805349282375605e-06, 1.9198732290938193e-06, 1.7878400794079383e-06, 1.7743502488752231e-06, 1.9926054177294324e-06, 1.7937411770628228e-06, 1.6862377985946484e-06, 2.1096156302431855e-06, 1.9901432657750766e-06, 1.8081872316663073e-06, 1.6907479833676282e-06, 1.605313477032127e-06, 2.3073233030076892e-06, 2.2614370511346222e-06, 2.091638178791762e-06, 1.9756450649615435e-06, 1.7786829803809028e-06, 2.2267058292219752e-06, 2.5484177239374987e-06, 2.3750721981316248e-06, 2.301865726060854e-06, 2.0827820062636648e-06, 2.054313130627323e-06, 1.8895318064985622e-06, 1.8144280363134382e-06, 1.675489251106751e-06, 1.5412319770365726e-06, 1.5173109780686153e-06, 1.3743263915999575e-06, 1.2885724082068585e-06, 1.3098854394985502e-06, 1.1874380981861992e-06, 1.297650553102576e-06, 1.290912955386644e-06, 1.281946830118263e-06, 1.254116884630118e-06, 1.331553513866538e-06, 1.1984044934242497e-06, 1.1657267296357234e-06, 1.100230204057774e-06, 1.0628834711700898e-06, 9.567833843199952e-07, 1.3452512692830536e-06, 1.2614975804520192e-06, 1.3935292026715118e-06, 1.4259913580904934e-06, 1.3714376662956708e-06, 1.6014177916882122e-06, 1.4999646504301086e-06, 1.4132527367877118e-06, 1.273305748607913e-06, 1.321029121352556e-06, 1.237681095344944e-06, 1.325931893994581e-06, 1.5993940067521373e-06, 1.59918458233445e-06, 1.4672637958988557e-06, 1.3683701331578783e-06, 1.2499862073154911e-06, 1.2440629729882937e-06, 1.408989313693892e-06, 1.2819898271855108e-06, 1.48913839932046e-06], "accuracy_test": 0.8476303411989796, "start": "2016-02-03 21:31:49.554000", "learning_rate_per_epoch": [0.003589558880776167, 0.0017947794403880835, 0.0011965195881202817, 0.0008973897201940417, 0.000717911752872169, 0.0005982597940601408, 0.0005127941258251667, 0.00044869486009702086, 0.0003988398821093142, 0.0003589558764360845, 0.00032632352667860687, 0.0002991298970300704, 0.000276119913905859, 0.00025639706291258335, 0.00023930393217597157, 0.00022434743004851043, 0.00021115051640663296, 0.0001994199410546571, 0.00018892415391746908, 0.00017947793821804225, 0.00017093138012569398, 0.00016316176333930343, 0.00015606777742505074, 0.0001495649485150352, 0.0001435823505744338, 0.0001380599569529295, 0.0001329466322204098, 0.00012819853145629168, 0.00012377789244055748, 0.00011965196608798578, 0.00011579222336877137, 0.00011217371502425522, 0.00010877451131818816, 0.00010557525820331648, 0.00010255882807541639, 9.970997052732855e-05, 9.701510862214491e-05, 9.446207695873454e-05, 9.203996887663379e-05, 8.973896910902113e-05, 8.755021553952247e-05, 8.546569006284699e-05, 8.34781167213805e-05, 8.158088166965172e-05, 7.976797496667132e-05, 7.803388871252537e-05, 7.637359522050247e-05, 7.47824742575176e-05, 7.325630576815456e-05, 7.17911752872169e-05, 7.038351031951606e-05, 6.902997847646475e-05, 6.7727523855865e-05, 6.64733161102049e-05, 6.52647067909129e-05, 6.409926572814584e-05, 6.297471554717049e-05, 6.188894622027874e-05, 6.083998232497834e-05, 5.982598304399289e-05, 5.884522761334665e-05, 5.789611168438569e-05, 5.6977125495905057e-05, 5.608685751212761e-05, 5.522398350876756e-05, 5.438725565909408e-05, 5.357550617191009e-05, 5.278762910165824e-05, 5.202259126235731e-05, 5.127941403770819e-05, 5.0557166105136275e-05, 4.9854985263664275e-05, 4.917203841614537e-05, 4.8507554311072454e-05, 4.786078352481127e-05, 4.723103847936727e-05, 4.661764978663996e-05, 4.6019984438316897e-05, 4.5437453081831336e-05, 4.4869484554510564e-05, 4.431554043549113e-05, 4.3775107769761235e-05, 4.324769906816073e-05, 4.2732845031423494e-05, 4.2230105464113876e-05, 4.173905836069025e-05, 4.1259296267526224e-05, 4.079044083482586e-05, 4.033212098875083e-05, 3.988398748333566e-05, 3.9445701986551285e-05, 3.9016944356262684e-05, 3.859740900225006e-05, 3.818679761025123e-05, 3.7784830055898055e-05, 3.73912371287588e-05, 3.700576053233817e-05, 3.662815288407728e-05, 3.6258170439396054e-05, 3.589558764360845e-05, 3.554018621798605e-05, 3.519175515975803e-05, 3.48500871041324e-05, 3.4514989238232374e-05, 3.4186276025138795e-05, 3.38637619279325e-05, 3.3547279599588364e-05, 3.323665805510245e-05, 3.2931733585428447e-05, 3.263235339545645e-05, 3.233836832805537e-05, 3.204963286407292e-05, 3.1766008760314435e-05, 3.1487357773585245e-05, 3.121355621260591e-05, 3.094447311013937e-05, 3.06799920508638e-05, 3.041999116248917e-05, 3.0164361305651255e-05, 2.9912991521996446e-05, 2.9665776310139336e-05, 2.9422613806673326e-05, 2.9183405786170624e-05, 2.8948055842192844e-05, 2.8716471206280403e-05, 2.8488562747952528e-05, 2.826424315571785e-05, 2.8043428756063804e-05, 2.782603769446723e-05, 2.761199175438378e-05, 2.7401212719269097e-05, 2.719362782954704e-05, 2.6989164325641468e-05, 2.6787753085955046e-05, 2.658932498889044e-05, 2.639381455082912e-05, 2.6201159926131368e-05, 2.6011295631178655e-05, 2.582416527729947e-05, 2.5639707018854097e-05, 2.545786446717102e-05, 2.5278583052568138e-05, 2.5101810024352744e-05, 2.4927492631832138e-05, 2.4755578124313615e-05, 2.4586019208072685e-05, 2.4418768589384854e-05, 2.4253777155536227e-05, 2.4090999431791715e-05, 2.3930391762405634e-05, 2.37719123106217e-05, 2.3615519239683636e-05, 2.3461168893845752e-05, 2.330882489331998e-05, 2.3158443582360633e-05, 2.3009992219158448e-05, 2.286343260493595e-05, 2.2718726540915668e-05, 2.2575841285288334e-05, 2.2434742277255282e-05, 2.2295396775007248e-05, 2.2157770217745565e-05, 2.2021833501639776e-05, 2.1887553884880617e-05, 2.1754902263637632e-05, 2.1623849534080364e-05, 2.1494364773388952e-05, 2.1366422515711747e-05, 2.1239993657218292e-05, 2.1115052732056938e-05, 2.099157245538663e-05, 2.0869529180345125e-05, 2.0748895622091368e-05, 2.0629648133763112e-05, 2.0511764887487516e-05, 2.039522041741293e-05, 2.027999289566651e-05, 2.0166060494375415e-05, 2.0053401385666803e-05, 1.994199374166783e-05, 1.9831817553495057e-05, 1.9722850993275642e-05, 1.961507587111555e-05, 1.9508472178131342e-05, 1.940302172442898e-05, 1.929870450112503e-05, 1.9195502318325453e-05, 1.9093398805125616e-05, 1.8992375771631487e-05, 1.8892415027949028e-05, 1.879350202216301e-05, 1.86956185643794e-05, 1.859875010268297e-05, 1.8502880266169086e-05, 1.840799450292252e-05, 1.831407644203864e-05, 1.822111153160222e-05, 1.8129085219698027e-05, 1.803798477340024e-05, 1.7947793821804225e-05, 1.7858501450973563e-05, 1.7770093108993024e-05, 1.7682556062936783e-05, 1.7595877579879016e-05, 1.7510043107904494e-05, 1.74250435520662e-05, 1.7340864360448904e-05, 1.7257494619116187e-05, 1.7174923414131626e-05, 1.7093138012569398e-05, 1.701212750049308e-05, 1.693188096396625e-05, 1.6852389308041893e-05, 1.6773639799794182e-05, 1.66956233442761e-05, 1.6618329027551226e-05, 1.654174593568314e-05, 1.6465866792714223e-05, 1.639068068470806e-05, 1.6316176697728224e-05, 1.6242347555817105e-05, 1.6169184164027683e-05, 1.6096677427412942e-05, 1.602481643203646e-05, 1.5953595720930025e-05, 1.5883004380157217e-05, 1.5813035133760422e-05, 1.5743678886792623e-05, 1.5674930182285607e-05, 1.5606778106302954e-05, 1.553921538288705e-05, 1.5472236555069685e-05, 1.540583252790384e-05, 1.53399960254319e-05, 1.527471795270685e-05, 1.5209995581244584e-05, 1.514581799710868e-05, 1.5082180652825627e-05], "accuracy_train_first": 0.3078327594361388, "accuracy_train_last": 0.9914212823574198, "batch_size_eval": 1024, "accuracy_train_std": [0.014091821707640066, 0.01828681066730565, 0.01673552244902541, 0.01732403319028224, 0.018290179198041656, 0.01802126276059228, 0.01706948088753008, 0.01816482119566062, 0.01623268835867146, 0.01664402494244151, 0.017651233907408588, 0.01679930868048603, 0.01625309172397703, 0.01629164683827081, 0.014366487941137067, 0.015929343552179825, 0.015286534776898114, 0.01529447419507359, 0.013974974378244666, 0.013278243842508445, 0.014808296152824429, 0.013921818121192595, 0.013837368441370823, 0.013035730384289703, 0.012956964455619687, 0.013137719408423764, 0.014246847945660022, 0.014463117182689679, 0.013631345456577291, 0.013998554576316637, 0.013948167742748102, 0.012716716981035658, 0.013250473548517156, 0.013133261468618878, 0.013456031252414161, 0.013177819118611251, 0.012549544939805337, 0.014026440545713677, 0.012674094472833217, 0.01231767619389695, 0.012537370793439893, 0.012042238123859116, 0.01194644666842612, 0.012981045303610795, 0.010959673100255874, 0.012192850880311414, 0.011251996437485437, 0.010848553923025802, 0.010869113285305732, 0.011122891774204563, 0.010419716983579665, 0.010306134241778238, 0.010744360909341952, 0.010816581003716349, 0.010015234632676402, 0.010666402349387557, 0.010160281189071226, 0.010215312483210712, 0.010276808143706259, 0.00991248443634935, 0.010454561885661262, 0.009746868936456975, 0.010609922789229894, 0.010077647326664942, 0.009839134694810575, 0.009725205313648741, 0.009447739506525414, 0.008932872512316673, 0.008944562940493669, 0.008932333951712607, 0.008450458368351614, 0.008757199545559627, 0.009203082779172178, 0.00842885877935714, 0.008146818520799428, 0.007813320746590394, 0.00797440358895363, 0.009036677799338822, 0.009098984702875295, 0.00891212538247789, 0.008717193002720636, 0.008215840483213586, 0.008272304670406518, 0.007610862325823762, 0.008722539808618954, 0.00817953648343333, 0.008688177896467015, 0.008111275001853222, 0.007886491019742953, 0.008355963094540371, 0.00829698944592826, 0.007857731293015228, 0.008252666928372602, 0.008072866989524325, 0.00800389959212294, 0.008156823127172832, 0.00793237791640519, 0.007942717233868277, 0.007464631173090669, 0.007901502132645679, 0.0069487653468219375, 0.007360999578940538, 0.007958586267907065, 0.007341725667801982, 0.00692039574843784, 0.007318447032518708, 0.0070443150762728585, 0.0068442504328535304, 0.006912907778779772, 0.006722687206645195, 0.006283168833520642, 0.005934910489631694, 0.006319300656078547, 0.006599211359442153, 0.00636691538544876, 0.006598327581949522, 0.006680551198710498, 0.006161367556117034, 0.006445182106050576, 0.006771360840754229, 0.006011332433850995, 0.006356478898367825, 0.006793624143186887, 0.006070626033528742, 0.006055476013721522, 0.005922621683752401, 0.006467395514224932, 0.006270325080570187, 0.005794678659061785, 0.005601188385394828, 0.00604115776371999, 0.006037202014361542, 0.0056529049847057, 0.005380474751330309, 0.005992046049733456, 0.00601340665711349, 0.005504004738464755, 0.005575210220932484, 0.005506941740397447, 0.005932234961660571, 0.005221626176397821, 0.005942385124119954, 0.005342130084360898, 0.005445012563437785, 0.005509460925930304, 0.005775212866587308, 0.005825031466473386, 0.004806112448747658, 0.0052392253145777425, 0.004785551320092415, 0.005375663176730126, 0.0040533085495294205, 0.005233007873130392, 0.005170997926412395, 0.005228175672088742, 0.005164140854686044, 0.005125418375318112, 0.005133072885394934, 0.004912762741630339, 0.004912451142013058, 0.0049898475160296985, 0.005539026226410816, 0.004835736409425262, 0.004501789706748031, 0.004632226728203577, 0.004729743103534506, 0.004619861932946126, 0.004760783003951589, 0.004522166310574643, 0.004444854874576147, 0.004537359968697307, 0.004553378570801232, 0.0041239768456544125, 0.004412091786783709, 0.0044575832262795, 0.004315507218902372, 0.0043898532774483655, 0.00453354625562309, 0.003948517498136865, 0.004256248781051629, 0.004303612099607615, 0.004499048153669991, 0.004960114449048009, 0.0044249888932913935, 0.004175284337336799, 0.004709581021729507, 0.004506919817443128, 0.004343465000546837, 0.004379926171214895, 0.00450409228943273, 0.0045676684149336235, 0.004237634986811635, 0.004577236624526484, 0.003994220797816107, 0.004253897263858978, 0.005086481047839557, 0.004395614651001744, 0.004215267780935688, 0.004155189075653125, 0.003769335785845408, 0.004167087185213538, 0.004482277047139558, 0.004472478255435272, 0.0045852875864908485, 0.003854066665860083, 0.003998825631793015, 0.004045038582673179, 0.004069022149482344, 0.003708223892362561, 0.004184230995263064, 0.004267409999213932, 0.0039021985447415517, 0.004017300611670658, 0.003758151203645402, 0.004356750443846483, 0.0036889252632538363, 0.003908963867495702, 0.0038354219953105366, 0.0037524660836081815, 0.004253318166886637, 0.004353424219879109, 0.0039080131198946984, 0.0042718599368689525, 0.004384885274588526, 0.00451622168015921, 0.003424495044145367, 0.004458133151964352, 0.003566791258108204, 0.0037805209180056566, 0.004066059183739262, 0.003469012559485132, 0.003400404594579549, 0.003551496783480938, 0.00352019166353587, 0.0034673851225609903, 0.003907342277696603, 0.0038241181114855973, 0.0041028153330349895], "accuracy_test_std": 0.009190992220087832, "error_valid": [0.692969632435994, 0.4539471362010542, 0.3622473291603916, 0.2817191618034638, 0.2672942747552711, 0.2641101515436747, 0.22346956184111444, 0.21536144578313254, 0.20532079489834332, 0.18891189759036142, 0.19416092102786142, 0.17983751411897586, 0.17959337349397586, 0.17233974962349397, 0.1799698795180723, 0.17178087349397586, 0.16759959760918675, 0.1647816853350903, 0.16171963243599397, 0.16034597373870485, 0.16074306993599397, 0.15878994493599397, 0.15586025743599397, 0.1552602009600903, 0.15561611681099397, 0.15263495387801207, 0.15375417686370485, 0.15506606504141573, 0.14994940700301207, 0.15239081325301207, 0.1510274496423193, 0.14930817018072284, 0.14772125611822284, 0.14878900367093373, 0.14857574830572284, 0.14836249294051207, 0.1460534520896084, 0.1456563558923193, 0.1467858739646084, 0.1448018637048193, 0.14725356504141573, 0.14598138648343373, 0.14403855657003017, 0.14603286191641573, 0.14405914674322284, 0.14085443335843373, 0.1408235480986446, 0.14025437688253017, 0.1414853750941265, 0.1398984610316265, 0.1413838949548193, 0.14259430299322284, 0.14359145566641573, 0.13841302710843373, 0.13963373023343373, 0.14159715032003017, 0.13951165992093373, 0.14061029273343373, 0.13629665144954817, 0.13864687264683728, 0.13837184676204817, 0.13741587443524095, 0.13863657756024095, 0.13744675969503017, 0.1378938605986446, 0.13876894295933728, 0.13693788827183728, 0.13470973738704817, 0.1379453360316265, 0.13780267554593373, 0.13607310099774095, 0.13548333960843373, 0.13560540992093373, 0.13424204631024095, 0.13510683358433728, 0.13730409920933728, 0.13634812688253017, 0.13582896037274095, 0.13486269295933728, 0.13571718514683728, 0.13483180769954817, 0.13400820077183728, 0.13253306193524095, 0.13769090032003017, 0.13486269295933728, 0.13335666886295183, 0.13486269295933728, 0.13446559676204817, 0.13457737198795183, 0.13400820077183728, 0.13350962443524095, 0.13216685099774095, 0.13607310099774095, 0.13509653849774095, 0.1317594597138554, 0.13286838761295183, 0.13571718514683728, 0.13522890389683728, 0.13375376506024095, 0.13336696394954817, 0.13251247176204817, 0.1315462043486446, 0.13265513224774095, 0.13238010636295183, 0.13289927287274095, 0.13176975480045183, 0.13070200724774095, 0.1324918815888554, 0.1334993293486446, 0.1317594597138554, 0.13143442912274095, 0.13290956795933728, 0.13303163827183728, 0.1311799934111446, 0.13214626082454817, 0.1313020637236446, 0.13263454207454817, 0.13401849585843373, 0.13178004988704817, 0.13068141707454817, 0.1305387565888554, 0.13144472420933728, 0.13279779273343373, 0.13169915992093373, 0.13253306193524095, 0.13018284073795183, 0.1328183829066265, 0.13007106551204817, 0.13216685099774095, 0.13265513224774095, 0.1305696418486446, 0.13167856974774095, 0.12874888224774095, 0.1299592902861446, 0.13140354386295183, 0.13256394719503017, 0.13155649943524095, 0.1314241340361446, 0.13116969832454817, 0.13267572242093373, 0.13104762801204817, 0.13129176863704817, 0.13254335702183728, 0.13164768448795183, 0.13266542733433728, 0.1326448371611446, 0.1308137824736446, 0.13192271037274095, 0.12957248917545183, 0.13140354386295183, 0.13131235881024095, 0.1311799934111446, 0.1317903449736446, 0.12933864363704817, 0.13255365210843373, 0.12994899519954817, 0.13226833113704817, 0.13169915992093373, 0.13229921639683728, 0.13279779273343373, 0.1305696418486446, 0.13300075301204817, 0.13250217667545183, 0.13103733292545183, 0.13045786662274095, 0.13107851327183728, 0.1305696418486446, 0.13122117375753017, 0.1299284050263554, 0.1294710090361446, 0.12946071394954817, 0.1313020637236446, 0.12896213761295183, 0.12957248917545183, 0.13092555769954817, 0.1282194206513554, 0.13254335702183728, 0.13144472420933728, 0.13206537085843373, 0.12874888224774095, 0.1305696418486446, 0.12973573983433728, 0.1279752800263554, 0.13129176863704817, 0.12994899519954817, 0.1311799934111446, 0.12946071394954817, 0.12723256306475905, 0.1285856315888554, 0.12908420792545183, 0.1308137824736446, 0.12997988045933728, 0.13254335702183728, 0.12771054922816272, 0.12897243269954817, 0.1311799934111446, 0.13031520613704817, 0.1285856315888554, 0.12918568806475905, 0.13091526261295183, 0.13059023202183728, 0.13057993693524095, 0.1288297722138554, 0.13022402108433728, 0.12918568806475905, 0.13115940323795183, 0.13030491105045183, 0.12843267601656627, 0.13103733292545183, 0.1288297722138554, 0.13092555769954817, 0.12847385636295183, 0.12981662980045183, 0.12884006730045183, 0.12897243269954817, 0.13054905167545183, 0.12969455948795183, 0.13205507577183728, 0.12921657332454817, 0.12819883047816272, 0.1283414909638554, 0.12859592667545183, 0.12746640860316272, 0.13009165568524095, 0.1302034309111446, 0.12957248917545183, 0.12806646507906627, 0.1285856315888554, 0.1307828972138554, 0.13152561417545183, 0.13094614787274095, 0.13030491105045183, 0.1290739128388554, 0.13018284073795183, 0.13092555769954817, 0.1280973503388554, 0.1293180534638554, 0.12774143448795183], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.03368953018447174, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.0035895588946166933, "optimization": "rmsprop", "nb_data_augmentation": 3, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.0217427453048082e-05, "rotation_range": [0, 0], "momentum": 0.7446170599438149}, "accuracy_valid_max": 0.872767436935241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8722585655120482, "accuracy_valid_std": [0.016681237124220396, 0.012771799008207794, 0.012044166899858315, 0.008261131066580512, 0.005402912298031816, 0.005588658343366516, 0.006222183887414334, 0.008440808696248449, 0.0070529964582401955, 0.009167837580124261, 0.008447363189773766, 0.01136798261998267, 0.01097374985400278, 0.010485123806229102, 0.013397490332812729, 0.01278814816514071, 0.013686583135790029, 0.011216062625427412, 0.008882878175655994, 0.007775961883320095, 0.011593579835675865, 0.011084903301034064, 0.010146351980085625, 0.011418229899089383, 0.011056621245163876, 0.010186965440892497, 0.011079272657371481, 0.009420950918178848, 0.01015544072733502, 0.009748608219431399, 0.011281542894279246, 0.01002103370125645, 0.010849567093340461, 0.011050634828344055, 0.010475835969455545, 0.009563771547656147, 0.012211327053718194, 0.011487747062673455, 0.013792001194437992, 0.010415596052586067, 0.012006876862712427, 0.011261315114312826, 0.012506968777823778, 0.009572040361958224, 0.009385567619024258, 0.009354472703143378, 0.011789872446868221, 0.010264229048345098, 0.009129542206893519, 0.008541153351126454, 0.00864928732424248, 0.009834599373815544, 0.008528188695462175, 0.009539948921003056, 0.008402507879788254, 0.007948651441171557, 0.006862901487414374, 0.0068053044554638835, 0.008902745553551798, 0.00725278990382679, 0.00960836789491524, 0.009018808130605184, 0.008108579031543021, 0.00925929778991615, 0.009159567424881443, 0.008287787304663473, 0.007517380882143502, 0.00822510243570131, 0.00943124198985866, 0.007538190073989714, 0.00930236633289862, 0.007297555380212182, 0.009252476756002067, 0.007618913738486514, 0.008020721324746032, 0.006664434225573935, 0.007607537746187376, 0.0084060661907449, 0.009866140866344192, 0.008829906635398623, 0.008586659834908533, 0.007664770248035477, 0.007853807587998115, 0.008050808632114846, 0.007662697030425632, 0.010532448123167584, 0.010198845807707394, 0.009963688452576204, 0.009153967173657894, 0.007507630595877385, 0.009959063754202573, 0.008440254004467507, 0.008720298269610792, 0.008223746793912912, 0.010137726418589984, 0.009661473301765314, 0.00926472149069837, 0.009353051801065186, 0.008247845580559172, 0.007904462660493692, 0.008943337758565446, 0.008519978167908197, 0.009308617306990079, 0.010638956065948243, 0.00816335902686335, 0.009114864614431444, 0.008800714149322039, 0.008475346896572818, 0.0078461742632913, 0.0079495919899903, 0.008931363349095367, 0.0070398405047410574, 0.008114950869056196, 0.008177976070100543, 0.008520333590003861, 0.0088784150447751, 0.009470881196474436, 0.006425752708995831, 0.006466378865468133, 0.006753536932226889, 0.009341755182288948, 0.007964520834808773, 0.009707879308580953, 0.007821427653053513, 0.007138169062842827, 0.009661584794715352, 0.009475416013367379, 0.009165257004170386, 0.008608072409613463, 0.008074198662954401, 0.009766737616642741, 0.009681630711249669, 0.008086640832814343, 0.008701073464846065, 0.009254187511145543, 0.009721779430437904, 0.007571117413792977, 0.008507948160292971, 0.008857053317466293, 0.00943919643914911, 0.007747955534028508, 0.008402864151944786, 0.007470905629468217, 0.009236594307105491, 0.009615741801349435, 0.010084779011806426, 0.00947359405898531, 0.008696631318809676, 0.009379526592184679, 0.008939683472752525, 0.008605433690251565, 0.010306229094819062, 0.009836268148613323, 0.009445892372717847, 0.008693646276032507, 0.010206829328121544, 0.00813555950424773, 0.010260709900671553, 0.010877844230983888, 0.008042326582611555, 0.009188139585012436, 0.009798566875345105, 0.008366903713910209, 0.009171493764723147, 0.008071974828772654, 0.008621938935808498, 0.009730051795085145, 0.009462508097772188, 0.0095224369829281, 0.00937777757855558, 0.008627958859906224, 0.009834004633917254, 0.01011749757521919, 0.010018646875041599, 0.008463165784181149, 0.009065868211689468, 0.008639994136192647, 0.009655874611644372, 0.008498662418307124, 0.00934495956311658, 0.007243881517119335, 0.010244616972807685, 0.010161331999949317, 0.008402864151944786, 0.008184501609356451, 0.00813412791058958, 0.007327977736483535, 0.010040358221645479, 0.009013745205809717, 0.008730886391140103, 0.008956128696617709, 0.008886886967758969, 0.0067323111517480485, 0.009728347902159921, 0.00929662490293332, 0.010024784898263774, 0.00958940261857499, 0.010075375023238116, 0.009496341143537151, 0.01036294624789242, 0.009247653100656058, 0.00920168545311616, 0.009266849677855933, 0.009093099368975002, 0.010116315665726143, 0.008708186319608366, 0.008865400605049032, 0.01074105459412501, 0.009210404638975437, 0.008530034062147272, 0.00898248746708805, 0.009090082115479473, 0.009560611885070985, 0.007931218419563263, 0.01085810697254573, 0.010260161785949923, 0.00967673586864908, 0.010415398242283144, 0.006820514017274641, 0.00918500613192946, 0.008773729548327155, 0.008835784869793991, 0.008390105521513454, 0.008443050668590553, 0.008010470668442772, 0.009468075260960407, 0.010578707631821671, 0.010594433345793478, 0.009308602551527753, 0.008625877791605853, 0.010065369467945064, 0.008945716257662833, 0.008142598939521154, 0.008265123709891511, 0.008420802773680774, 0.008822417876625658, 0.009661271357443537, 0.008252776594378642], "accuracy_valid": [0.30703036756400603, 0.5460528637989458, 0.6377526708396084, 0.7182808381965362, 0.7327057252447289, 0.7358898484563253, 0.7765304381588856, 0.7846385542168675, 0.7946792051016567, 0.8110881024096386, 0.8058390789721386, 0.8201624858810241, 0.8204066265060241, 0.827660250376506, 0.8200301204819277, 0.8282191265060241, 0.8324004023908133, 0.8352183146649097, 0.838280367564006, 0.8396540262612951, 0.839256930064006, 0.841210055064006, 0.844139742564006, 0.8447397990399097, 0.844383883189006, 0.8473650461219879, 0.8462458231362951, 0.8449339349585843, 0.8500505929969879, 0.8476091867469879, 0.8489725503576807, 0.8506918298192772, 0.8522787438817772, 0.8512109963290663, 0.8514242516942772, 0.8516375070594879, 0.8539465479103916, 0.8543436441076807, 0.8532141260353916, 0.8551981362951807, 0.8527464349585843, 0.8540186135165663, 0.8559614434299698, 0.8539671380835843, 0.8559408532567772, 0.8591455666415663, 0.8591764519013554, 0.8597456231174698, 0.8585146249058735, 0.8601015389683735, 0.8586161050451807, 0.8574056970067772, 0.8564085443335843, 0.8615869728915663, 0.8603662697665663, 0.8584028496799698, 0.8604883400790663, 0.8593897072665663, 0.8637033485504518, 0.8613531273531627, 0.8616281532379518, 0.862584125564759, 0.861363422439759, 0.8625532403049698, 0.8621061394013554, 0.8612310570406627, 0.8630621117281627, 0.8652902626129518, 0.8620546639683735, 0.8621973244540663, 0.863926899002259, 0.8645166603915663, 0.8643945900790663, 0.865757953689759, 0.8648931664156627, 0.8626959007906627, 0.8636518731174698, 0.864171039627259, 0.8651373070406627, 0.8642828148531627, 0.8651681923004518, 0.8659917992281627, 0.867466938064759, 0.8623090996799698, 0.8651373070406627, 0.8666433311370482, 0.8651373070406627, 0.8655344032379518, 0.8654226280120482, 0.8659917992281627, 0.866490375564759, 0.867833149002259, 0.863926899002259, 0.864903461502259, 0.8682405402861446, 0.8671316123870482, 0.8642828148531627, 0.8647710961031627, 0.866246234939759, 0.8666330360504518, 0.8674875282379518, 0.8684537956513554, 0.867344867752259, 0.8676198936370482, 0.867100727127259, 0.8682302451995482, 0.869297992752259, 0.8675081184111446, 0.8665006706513554, 0.8682405402861446, 0.868565570877259, 0.8670904320406627, 0.8669683617281627, 0.8688200065888554, 0.8678537391754518, 0.8686979362763554, 0.8673654579254518, 0.8659815041415663, 0.8682199501129518, 0.8693185829254518, 0.8694612434111446, 0.8685552757906627, 0.8672022072665663, 0.8683008400790663, 0.867466938064759, 0.8698171592620482, 0.8671816170933735, 0.8699289344879518, 0.867833149002259, 0.867344867752259, 0.8694303581513554, 0.868321430252259, 0.871251117752259, 0.8700407097138554, 0.8685964561370482, 0.8674360528049698, 0.868443500564759, 0.8685758659638554, 0.8688303016754518, 0.8673242775790663, 0.8689523719879518, 0.8687082313629518, 0.8674566429781627, 0.8683523155120482, 0.8673345726656627, 0.8673551628388554, 0.8691862175263554, 0.868077289627259, 0.8704275108245482, 0.8685964561370482, 0.868687641189759, 0.8688200065888554, 0.8682096550263554, 0.8706613563629518, 0.8674463478915663, 0.8700510048004518, 0.8677316688629518, 0.8683008400790663, 0.8677007836031627, 0.8672022072665663, 0.8694303581513554, 0.8669992469879518, 0.8674978233245482, 0.8689626670745482, 0.869542133377259, 0.8689214867281627, 0.8694303581513554, 0.8687788262424698, 0.8700715949736446, 0.8705289909638554, 0.8705392860504518, 0.8686979362763554, 0.8710378623870482, 0.8704275108245482, 0.8690744423004518, 0.8717805793486446, 0.8674566429781627, 0.8685552757906627, 0.8679346291415663, 0.871251117752259, 0.8694303581513554, 0.8702642601656627, 0.8720247199736446, 0.8687082313629518, 0.8700510048004518, 0.8688200065888554, 0.8705392860504518, 0.872767436935241, 0.8714143684111446, 0.8709157920745482, 0.8691862175263554, 0.8700201195406627, 0.8674566429781627, 0.8722894507718373, 0.8710275673004518, 0.8688200065888554, 0.8696847938629518, 0.8714143684111446, 0.870814311935241, 0.8690847373870482, 0.8694097679781627, 0.869420063064759, 0.8711702277861446, 0.8697759789156627, 0.870814311935241, 0.8688405967620482, 0.8696950889495482, 0.8715673239834337, 0.8689626670745482, 0.8711702277861446, 0.8690744423004518, 0.8715261436370482, 0.8701833701995482, 0.8711599326995482, 0.8710275673004518, 0.8694509483245482, 0.8703054405120482, 0.8679449242281627, 0.8707834266754518, 0.8718011695218373, 0.8716585090361446, 0.8714040733245482, 0.8725335913968373, 0.869908344314759, 0.8697965690888554, 0.8704275108245482, 0.8719335349209337, 0.8714143684111446, 0.8692171027861446, 0.8684743858245482, 0.869053852127259, 0.8696950889495482, 0.8709260871611446, 0.8698171592620482, 0.8690744423004518, 0.8719026496611446, 0.8706819465361446, 0.8722585655120482], "seed": 495603856, "model": "residualv3", "loss_std": [0.41251540184020996, 0.16282564401626587, 0.14197950065135956, 0.13153718411922455, 0.1274837702512741, 0.1244119182229042, 0.12368452548980713, 0.11723721027374268, 0.11517300456762314, 0.1133587658405304, 0.11445090174674988, 0.1117946207523346, 0.11038405448198318, 0.10619695484638214, 0.1071094274520874, 0.10440080612897873, 0.10332261025905609, 0.10141216963529587, 0.10215706378221512, 0.10199174284934998, 0.09917350113391876, 0.09705416858196259, 0.09666486829519272, 0.09397610276937485, 0.09485363960266113, 0.09290078282356262, 0.09317602217197418, 0.09197317063808441, 0.08995525538921356, 0.08923491090536118, 0.08920161426067352, 0.08906395733356476, 0.08848918229341507, 0.08793523162603378, 0.08672745525836945, 0.08525672554969788, 0.08436433970928192, 0.08347547054290771, 0.08277586102485657, 0.08407742530107498, 0.08331494778394699, 0.0799817368388176, 0.0816413164138794, 0.07925931364297867, 0.07789085060358047, 0.07813266664743423, 0.07812543213367462, 0.07659038156270981, 0.07799223065376282, 0.07488950341939926, 0.0757192000746727, 0.07471421360969543, 0.07401082664728165, 0.0752430260181427, 0.07223083823919296, 0.07263495773077011, 0.07236220687627792, 0.07109609246253967, 0.07140669226646423, 0.06867583841085434, 0.07067300379276276, 0.07071860879659653, 0.06933237612247467, 0.06964943557977676, 0.06771163642406464, 0.06846114248037338, 0.06691209971904755, 0.06598636507987976, 0.06724183261394501, 0.06742797791957855, 0.06707100570201874, 0.06720413267612457, 0.06536955386400223, 0.06490420550107956, 0.06648034602403641, 0.06418298184871674, 0.0653473511338234, 0.06573512405157089, 0.06259021162986755, 0.06142619997262955, 0.06220577284693718, 0.06122491881251335, 0.0631934329867363, 0.06211007013916969, 0.058920376002788544, 0.060620877891778946, 0.0618913471698761, 0.05945093557238579, 0.06008070707321167, 0.06069207936525345, 0.05933655798435211, 0.0586138516664505, 0.060558099299669266, 0.056924816220998764, 0.05769450590014458, 0.057847760617733, 0.057944267988204956, 0.05674171820282936, 0.05565100163221359, 0.05717288330197334, 0.05461392179131508, 0.05639348551630974, 0.05601285770535469, 0.05506817623972893, 0.05518490821123123, 0.055111583322286606, 0.05554584413766861, 0.05391320586204529, 0.0545521154999733, 0.053024038672447205, 0.05496798828244209, 0.05376452952623367, 0.05355267971754074, 0.05138636752963066, 0.05369824543595314, 0.05251413583755493, 0.051625266671180725, 0.051519282162189484, 0.051137544214725494, 0.05177508294582367, 0.05187510326504707, 0.05118320509791374, 0.05059289559721947, 0.04970106482505798, 0.050707705318927765, 0.05030447244644165, 0.05056452751159668, 0.05027366057038307, 0.050849754363298416, 0.04922095686197281, 0.0488908477127552, 0.04913138970732689, 0.048322707414627075, 0.04658810794353485, 0.049582064151763916, 0.04702513664960861, 0.046119071543216705, 0.047832682728767395, 0.047413814812898636, 0.04753263294696808, 0.04788554832339287, 0.047593262046575546, 0.0470583513379097, 0.04793987423181534, 0.047156061977148056, 0.046763185411691666, 0.04603554680943489, 0.047061871737241745, 0.04717632010579109, 0.04645077511668205, 0.046032048761844635, 0.047093603760004044, 0.04456396400928497, 0.045249152928590775, 0.046390824019908905, 0.04497609660029411, 0.044779207557439804, 0.044030919671058655, 0.044402364641427994, 0.04623548686504364, 0.04356749355792999, 0.04262206703424454, 0.044777803122997284, 0.04301130771636963, 0.04415539279580116, 0.04445122554898262, 0.04431208223104477, 0.0432361364364624, 0.04233307018876076, 0.04437778517603874, 0.04177336022257805, 0.04383064806461334, 0.04333723336458206, 0.04179774597287178, 0.043555691838264465, 0.04277902841567993, 0.04032958298921585, 0.041484586894512177, 0.04284700006246567, 0.0432109460234642, 0.0429040901362896, 0.04200967773795128, 0.041035883128643036, 0.042920518666505814, 0.041105687618255615, 0.040920183062553406, 0.04111991077661514, 0.040454693138599396, 0.040623776614665985, 0.039568349719047546, 0.04007616639137268, 0.039621297270059586, 0.03929489105939865, 0.04079246148467064, 0.0383448451757431, 0.03949824348092079, 0.03997664153575897, 0.03946232050657272, 0.03992830961942673, 0.039411090314388275, 0.04069993272423744, 0.04037242382764816, 0.039495062083005905, 0.039146773517131805, 0.03795323148369789, 0.03688887506723404, 0.03796529397368431, 0.03898713365197182, 0.03963065519928932, 0.03819612041115761, 0.03816377744078636, 0.037939444184303284, 0.038279224187135696, 0.038757771253585815, 0.039479855448007584, 0.03744656592607498, 0.036988288164138794, 0.03593186289072037, 0.03809693828225136, 0.037162747234106064, 0.038623590022325516, 0.03667823597788811, 0.037528540939092636, 0.037260089069604874, 0.03779705986380577, 0.03568843752145767, 0.03788450360298157, 0.036750663071870804, 0.0365518294274807, 0.03580773249268532, 0.03878254070878029, 0.03614974766969681, 0.03657178208231926, 0.037202369421720505, 0.036700230091810226, 0.036887891590595245, 0.03724873438477516, 0.0365886315703392]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:39 2016", "state": "available"}], "summary": "979e60a21e9fe9faeb4aa33ec23c6cf9"}