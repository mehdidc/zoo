{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 32, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [2.4561545848846436, 1.9712657928466797, 1.9005922079086304, 1.8486970663070679, 1.7986363172531128, 1.7596110105514526, 1.7296863794326782, 1.7070415019989014, 1.691565752029419, 1.6786943674087524, 1.6664491891860962, 1.6572076082229614, 1.6492022275924683, 1.642104148864746, 1.6352603435516357, 1.630071759223938, 1.6248222589492798, 1.620105266571045, 1.6159586906433105, 1.6117099523544312, 1.6082093715667725, 1.6050443649291992, 1.6030977964401245, 1.6005022525787354, 1.5991860628128052, 1.5963610410690308, 1.595771074295044, 1.5929063558578491, 1.5921859741210938, 1.59019136428833, 1.5895377397537231, 1.5885119438171387, 1.5856213569641113, 1.5859042406082153, 1.5848456621170044, 1.5859133005142212, 1.5838547945022583, 1.582913875579834, 1.5842502117156982, 1.5829854011535645, 1.5827932357788086, 1.5828391313552856, 1.5814199447631836, 1.5801855325698853, 1.5804437398910522, 1.5801939964294434, 1.580247402191162, 1.5803987979888916, 1.5802403688430786, 1.5803552865982056, 1.5791727304458618, 1.579014539718628, 1.5802161693572998, 1.5801632404327393, 1.5793038606643677, 1.579061508178711, 1.579251766204834, 1.5775996446609497, 1.5788875818252563, 1.5776748657226562, 1.5786975622177124, 1.578821063041687, 1.578942060470581, 1.5782521963119507, 1.5779542922973633, 1.5788339376449585, 1.5785255432128906, 1.5786564350128174, 1.5769652128219604, 1.5785633325576782, 1.5776489973068237, 1.578809142112732, 1.577610969543457, 1.5778136253356934, 1.5783517360687256, 1.5785725116729736, 1.5782831907272339, 1.577602744102478, 1.5777332782745361, 1.5794472694396973, 1.576982855796814, 1.5778921842575073, 1.5784000158309937, 1.5778311491012573, 1.5794398784637451, 1.5785218477249146, 1.5777556896209717, 1.5779412984848022, 1.5788568258285522, 1.578552484512329, 1.5783265829086304, 1.578401803970337, 1.5785572528839111, 1.578019618988037, 1.5778342485427856, 1.577541470527649, 1.578843116760254, 1.5775527954101562, 1.5780104398727417, 1.5775830745697021, 1.5781136751174927, 1.5782946348190308, 1.5779263973236084, 1.5783048868179321, 1.5788036584854126, 1.5775452852249146, 1.5786540508270264, 1.5783144235610962, 1.5778911113739014, 1.578098177909851, 1.577405571937561, 1.57805597782135, 1.5782358646392822, 1.5779811143875122, 1.5785704851150513, 1.5776517391204834, 1.5782997608184814, 1.5767760276794434, 1.578129768371582, 1.5790178775787354, 1.5778168439865112, 1.578627586364746, 1.57764732837677, 1.577366828918457, 1.5783919095993042, 1.578847885131836, 1.5791015625, 1.5788060426712036, 1.5777661800384521, 1.5782344341278076, 1.57815420627594, 1.5782325267791748, 1.5773096084594727, 1.5777119398117065, 1.5775190591812134, 1.5790399312973022, 1.5774208307266235, 1.5784471035003662, 1.5776809453964233, 1.5788302421569824, 1.5776057243347168, 1.577866554260254, 1.5774868726730347, 1.5784567594528198, 1.5783637762069702, 1.5787891149520874, 1.5773690938949585, 1.577492117881775, 1.5777724981307983], "moving_avg_accuracy_train": [0.02821238233665559, 0.05727915412167773, 0.08575713370074288, 0.11309797596697349, 0.13924140502794502, 0.16402821644467802, 0.1872525995459651, 0.20891472380256276, 0.22901281312634858, 0.24766116599030102, 0.2649422654130963, 0.280855400617357, 0.29547491344644816, 0.30897645282116476, 0.32135098044648647, 0.3326763202652099, 0.3430295613699181, 0.35259619718913704, 0.36129230807884277, 0.36933969701648267, 0.3767172417401297, 0.383424497355707, 0.389581899099003, 0.39518633968582656, 0.4003163667199202, 0.40507293602799466, 0.40938872563740447, 0.41335882259655066, 0.4169970861240864, 0.4202714512012311, 0.42330444632543246, 0.4260758504205101, 0.4286236285775178, 0.43090514737005214, 0.433030485749972, 0.43489914851333766, 0.4366831794503483, 0.43830054118416173, 0.43976539524219443, 0.4411326280682426, 0.44237243820692407, 0.44350454337340406, 0.44453037742084583, 0.4454861801468768, 0.44633012655863796, 0.44706875198993734, 0.44779160754952607, 0.44843523815554615, 0.4490238062962023, 0.44954421702755476, 0.45004048847148626, 0.4504592670341291, 0.45091747585120345, 0.4513136237937224, 0.4517026729765041, 0.452011000611255, 0.4522977600289501, 0.45258138409296167, 0.45282741725297154, 0.4530813991803137, 0.4532518541946836, 0.45344235794211263, 0.45360694401482643, 0.45372716969455457, 0.4538190967646432, 0.45395992379914235, 0.45403326180521003, 0.45415503353328074, 0.454271603534973, 0.4543555901972103, 0.454426491846786, 0.4545182051171185, 0.45461705915090317, 0.4546293339194138, 0.45465197090630227, 0.4546723802433206, 0.4546767617049612, 0.45467140442519965, 0.45468750921269996, 0.4547461092511937, 0.45481981167394253, 0.4548814935567974, 0.4549044551680335, 0.454953058452679, 0.4549386726886219, 0.454948940940247, 0.45496522991077565, 0.45494261550566156, 0.45495713977320174, 0.45498416250684504, 0.45500851901594275, 0.455055944413398, 0.45507777302945945, 0.45507409519818204, 0.4551312029702612, 0.4551337718401325, 0.45515475711113035, 0.45510853968836174, 0.4550833281959929, 0.45507211940163356, 0.455071368130767, 0.4550777395310532, 0.45508579894012025, 0.4550580670296815, 0.45505882914246637, 0.45508727263441207, 0.45499436128551496, 0.4549897600822126, 0.4549624396087828, 0.45500295534936264, 0.454990519293247, 0.4550537316046477, 0.4550803597015657, 0.45507882044952463, 0.4551192517524404, 0.4551068478488833, 0.45509096194042536, 0.45509304881093615, 0.4551460081705679, 0.4551635167573502, 0.45512812121164464, 0.4551310343061963, 0.4551406315377214, 0.4551167890603981, 0.455106920526036, 0.45514218062367234, 0.4551274117353546, 0.4551025660894585, 0.45509880619862814, 0.45510243379212817, 0.4550940368334118, 0.45510976710748113, 0.4551192380077057, 0.4551719396452888, 0.45514961665482784, 0.4551504162538799, 0.4551859770763509, 0.45515992519397425, 0.455141164846273, 0.4551428096261806, 0.4551606020185828, 0.45519281911577403, 0.4551753115270556, 0.4551736137365224, 0.455197554215491, 0.4552005715537242, 0.4551730602236102, 0.45518321330746914, 0.45518530353887615], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.02820544874811746, 0.057615731480609916, 0.0864655041062688, 0.11423091011506961, 0.14144160228315603, 0.1672944417724609, 0.19139619347247383, 0.21352722312748548, 0.23403314633431524, 0.2528435106353717, 0.27025097174239177, 0.28632154827861944, 0.30113804155881474, 0.31473026267590015, 0.32707106594520774, 0.3383120662313346, 0.34871487575089694, 0.3581984451223434, 0.36676924914173553, 0.3745460669327577, 0.38176389999851806, 0.38830980739136206, 0.3943984955622409, 0.40004921335353183, 0.40528237324935334, 0.4100532523118427, 0.41439690110174277, 0.4184913494987221, 0.4221885600872535, 0.42561370586693176, 0.4287339876710518, 0.4316409270534195, 0.4343537992388908, 0.43678317717456494, 0.43887093155801205, 0.4409096314180241, 0.44281976249685423, 0.444414751137982, 0.44596010419624704, 0.4472542952073452, 0.44844245167117397, 0.4496115077559391, 0.4507246933884777, 0.45158007608276246, 0.45247199082011874, 0.45322485645007976, 0.45401332830695434, 0.45464765177332217, 0.4553161991430532, 0.45591892128447076, 0.45631385732808694, 0.45681681365100113, 0.4571463745204643, 0.4576403508203004, 0.45796182966899324, 0.4582501311241572, 0.45855946006746434, 0.4588378561164408, 0.45900193383310994, 0.45919946141177187, 0.4594993065450676, 0.45972033904003373, 0.45989485422300325, 0.45998882371410654, 0.46013649042966875, 0.46029277502751514, 0.4604588747367365, 0.46044967306878576, 0.46046580563013007, 0.46050370948918035, 0.46063753822964487, 0.46068268289124364, 0.46065007089918253, 0.46073058338757755, 0.4608529022607927, 0.46090092458177667, 0.4608454589120026, 0.4608820185366156, 0.46096477983242695, 0.4609527862712475, 0.460917578003686, 0.46091030462538063, 0.4609902373123155, 0.46104996969930684, 0.46111490637018937, 0.46110113669514335, 0.4610521228938519, 0.46107007513759923, 0.46102313798340255, 0.46101751563837556, 0.46106128365285126, 0.4611372959596294, 0.4610714296919797, 0.46107318520734497, 0.4610991792336738, 0.46118463852227926, 0.4611628661233646, 0.461241956723001, 0.46138638045017377, 0.46134340434980997, 0.46134237646189225, 0.46126820917526623, 0.4612146951572125, 0.4611288819385545, 0.4611370992605123, 0.4612065595151839, 0.46124465968188844, 0.46124129922951285, 0.46118841718871517, 0.46111640928949726, 0.4610648387201108, 0.460981804113913, 0.46090810247699454, 0.460976048347518, 0.46101278556848907, 0.46112012076352266, 0.4612523140241433, 0.46121156704379224, 0.4613102016138859, 0.4612636658745606, 0.46113530498175814, 0.4611439095080552, 0.4611760676442226, 0.4611429453018636, 0.46108975063990015, 0.4611751232792234, 0.46122857410077395, 0.46130109390266943, 0.46124326190321574, 0.461204449643617, 0.4611684891013186, 0.4611483316445, 0.46117901805836325, 0.4611456006745902, 0.4611531756316041, 0.4611345495217569, 0.46113102256280414, 0.4611899129646563, 0.46108113439409426, 0.4611429545954981, 0.4612484504104212, 0.46133118961260194, 0.4613690338008146, 0.46134205841395604, 0.46141646632444294, 0.4615200545376312, 0.4614403264746813, 0.461442842914186, 0.46139627958474033], "moving_var_accuracy_train": [0.007163446653986729, 0.014050996986611091, 0.019944855176100847, 0.024678064560932887, 0.028361568052434054, 0.031054885429068816, 0.03280374462008007, 0.033746598803846554, 0.034007337673663755, 0.03373645348714373, 0.03305053571377418, 0.032024532990658494, 0.030745651089832297, 0.029311710070232266, 0.027758699468757687, 0.026137199419967984, 0.02448818589032117, 0.022863051989367125, 0.021257347891884937, 0.019714457321119285, 0.018232865084352068, 0.016814464076951096, 0.015474240035311093, 0.014209503820401103, 0.013025408034695775, 0.011926491795468838, 0.010901476975496163, 0.009953184306731746, 0.009076998529520746, 0.008265791876494495, 0.007522004223655909, 0.0068389299272142365, 0.006213457496328742, 0.0056389596987020535, 0.005115717297894291, 0.004635572672813567, 0.004200660302990111, 0.0038041370034931363, 0.0034430354798458363, 0.003115555862266866, 0.0028178344386599755, 0.0025475859537657138, 0.00230229837782516, 0.0020802905697024383, 0.0018786717226455159, 0.0016957146581308238, 0.001530845873757997, 0.0013814896295952493, 0.0012464583787414835, 0.0011242499868310963, 0.0010140415562625434, 0.0009142157799970517, 0.0008246837998777487, 0.0007436278186212322, 0.0006706272701587168, 0.0006044201365160046, 0.0005447182015371356, 0.0004909703648706002, 0.0004424181192259601, 0.00039875686867811225, 0.0003591426760176156, 0.00032355503351591455, 0.0002914433273423053, 0.00026242908253466964, 0.00023626222955713846, 0.000212814496884237, 0.00019158145336401912, 0.0001725567632114332, 0.00015542338397794066, 0.00013994452941505045, 0.0001259953198687585, 0.00011347148979747834, 0.00010221228989768996, 9.199241693739888e-05, 8.279778714223749e-05, 7.452175729735148e-05, 6.70697543424713e-05, 6.036303721224216e-05, 5.432906776864183e-05, 4.892706667238088e-05, 4.408324842921425e-05, 3.970916547834558e-05, 3.5742994050826046e-05, 3.218995515924845e-05, 2.8972822195191165e-05, 2.607648890859497e-05, 2.347122799278342e-05, 2.1128707895373066e-05, 1.9017735694963965e-05, 1.712253417866957e-05, 1.5415619916621455e-05, 1.3894300439873354e-05, 1.2509158792198449e-05, 1.1258364650964751e-05, 1.0161879864554897e-05, 9.145751269931146e-06, 8.235139577327701e-06, 7.430850071101295e-06, 6.693485638118343e-06, 6.02526780794542e-06, 5.422746106822113e-06, 4.880836848814361e-06, 4.393337750603518e-06, 3.960925505252412e-06, 3.5648381820702427e-06, 3.215635653969796e-06, 2.9717647573577063e-06, 2.6747788212683993e-06, 2.4140186135574287e-06, 2.187390479314268e-06, 1.970043330808249e-06, 1.8090011645409527e-06, 1.6344825479961422e-06, 1.47105561686814e-06, 1.3386622674805163e-06, 1.2061807521435414e-06, 1.0878339357169843e-06, 9.790897374020457e-07, 9.064230076152864e-07, 8.18539662353765e-07, 7.479612980204927e-07, 6.732415432972462e-07, 6.067463506440347e-07, 5.511878891038222e-07, 4.969455919275377e-07, 4.5844050310270353e-07, 4.1455953335171765e-07, 3.786593350964972e-07, 3.4092063259834945e-07, 3.0694700424992895e-07, 2.7688688406608843e-07, 2.514251693601363e-07, 2.2708993398369703e-07, 2.2937810402076092e-07, 2.1092513674676363e-07, 1.8983837729988442e-07, 1.822356884232215e-07, 1.7012042475921937e-07, 1.5627593809613618e-07, 1.4067269199502223e-07, 1.294545458420808e-07, 1.258505634207079e-07, 1.160241480432346e-07, 1.0444767567316184e-07, 9.916122690508539e-08, 8.932704318469347e-08, 8.720619842800671e-08, 7.941334459183434e-08, 7.151133173866496e-08], "duration": 81119.042338, "accuracy_train": [0.28212382336655595, 0.31888010018687707, 0.34205894991232927, 0.3591655563630491, 0.3745322665766888, 0.38710951919527503, 0.3962720474575489, 0.4038738421119417, 0.4098956170404208, 0.415496341765873, 0.420472160218254, 0.42407361745570327, 0.4270505289082687, 0.4304903071936139, 0.43272172907438167, 0.4346043786337209, 0.4362087313122923, 0.43869591956210785, 0.43955730608619414, 0.44176619745524176, 0.4431151442529531, 0.44378979789590256, 0.4449985147886674, 0.4456263049672388, 0.44648661002676265, 0.4478820598006645, 0.448230832122093, 0.4490896952288667, 0.44974145787190845, 0.4497407368955334, 0.4506014024432447, 0.45101848727620897, 0.45155363199058696, 0.45143881650286083, 0.4521585311692507, 0.45171711338362863, 0.4527394578834441, 0.4528567967884828, 0.4529490817644888, 0.45343772350267625, 0.4535307294550572, 0.45369348987172387, 0.4537628838478221, 0.45408840468115547, 0.4539256442644888, 0.45371638087163163, 0.45429730758582504, 0.45422791360972686, 0.45432091956210785, 0.45422791360972686, 0.4545069314668697, 0.45422827409791433, 0.45504135520487266, 0.45487895527639355, 0.45520411562153934, 0.4547859493240126, 0.454878594788206, 0.4551340006690661, 0.45504171569306023, 0.45536723652639355, 0.4547859493240126, 0.4551568916689738, 0.4550882186692507, 0.45480920081210785, 0.45464644039544116, 0.4552273671096346, 0.4546933038598191, 0.45525097908591733, 0.4553207335502031, 0.45511147015734593, 0.4550646066929679, 0.4553436245501108, 0.45550674545496495, 0.45473980683600956, 0.4548557037882983, 0.4548560642764857, 0.45471619485972686, 0.45462318890734593, 0.4548324523002031, 0.4552735095976375, 0.4554831334786822, 0.4554366305024917, 0.4551111096691584, 0.4553904880144888, 0.45480920081210785, 0.45504135520487266, 0.4551118306455334, 0.4547390858596346, 0.4550878581810632, 0.4552273671096346, 0.4552277275978221, 0.45548277299049467, 0.4552742305740126, 0.45504099471668513, 0.4556451729189738, 0.4551568916689738, 0.4553436245501108, 0.4546925828834441, 0.4548564247646733, 0.45497124025239943, 0.4550646066929679, 0.45513508213362863, 0.45515833362172387, 0.45480847983573275, 0.45506568815753046, 0.4553432640619232, 0.45415815914544116, 0.4549483492524917, 0.45471655534791433, 0.455367597014581, 0.454878594788206, 0.45562264240725364, 0.455320012573828, 0.45506496718115547, 0.4554831334786822, 0.4549952127168697, 0.4549479887643042, 0.4551118306455334, 0.45562264240725364, 0.4553210940383905, 0.45480956130029526, 0.45515725215716135, 0.45522700662144705, 0.4549022067644888, 0.4550181037167774, 0.45545952150239943, 0.45499449174049467, 0.45487895527639355, 0.45506496718115547, 0.45513508213362863, 0.45501846420496495, 0.4552513395741048, 0.45520447610972686, 0.4556462543835364, 0.45494870974067925, 0.4551576126453489, 0.4555060244785899, 0.454925458252584, 0.45497232171696195, 0.4551576126453489, 0.4553207335502031, 0.45548277299049467, 0.4550177432285899, 0.45515833362172387, 0.45541301852620897, 0.4552277275978221, 0.454925458252584, 0.45527459106220003, 0.45520411562153934], "end": "2016-01-30 14:15:32.813000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0], "moving_var_accuracy_valid": [0.007159926051744129, 0.014228616020216016, 0.020296538843164364, 0.025205144896349906, 0.029348426321112148, 0.03242890747593879, 0.034414066643426604, 0.035380702241402995, 0.03562706799634229, 0.03524882944295419, 0.034451123818390515, 0.03333038230841223, 0.031973100335669656, 0.03043852657616437, 0.028765332746533707, 0.027026040258774666, 0.025297402245999866, 0.023577104813607214, 0.021880522466095953, 0.0202367802740792, 0.018681976274157932, 0.017199418779103345, 0.015813126013972813, 0.014519188916586843, 0.013313743687385271, 0.012187220901906838, 0.011138304375006158, 0.010175354506585283, 0.009280843351150295, 0.008458343628543696, 0.007700134692523433, 0.007006173892425933, 0.006371793582635675, 0.005787731118761172, 0.005248186472175479, 0.004760774499030849, 0.004317534455772579, 0.0039086769090832625, 0.003539302262847139, 0.003200446409921291, 0.002893107210972004, 0.0026160967190387414, 0.002365639687407281, 0.0021356608346496894, 0.0019292543582731404, 0.0017414301823568158, 0.0015728823549428833, 0.001419215415788459, 0.0012813164744797816, 0.0011564542928495984, 0.0010422126338715636, 0.0009402680560492416, 0.0008472187437444492, 0.0007646929826332022, 0.000689153822221294, 0.0006209864995606113, 0.000559749009161058, 0.0005044716474857235, 0.0004542667762111175, 0.000409191252888994, 0.00036908129153574465, 0.0003326128606566488, 0.00029962567453276583, 0.0002697425794668132, 0.0002429645706500963, 0.0002188879374648027, 0.00019724744573895324, 0.0001775234632012956, 0.0001597734592169858, 0.00014380904361806533, 0.0001295893304422276, 0.00011664873976224266, 0.00010499343766425414, 9.455243424491673e-05, 8.523184798112664e-05, 7.672941847282818e-05, 6.908416459025673e-05, 6.218777758659764e-05, 5.603064471669721e-05, 5.042887485461537e-05, 4.5397143968095975e-05, 4.085790568957413e-05, 3.6829618230582304e-05, 3.3178768030025225e-05, 2.9898842168050507e-05, 2.691066438680332e-05, 2.4241219122576326e-05, 2.181999775781877e-05, 1.965782585003363e-05, 1.769232776190269e-05, 1.5940335737532725e-05, 1.4398303000815044e-05, 1.2997517987660436e-05, 1.1697793925402171e-05, 1.0534095737504975e-05, 9.54641577383512e-06, 8.596040532642105e-06, 7.792734385935543e-06, 7.20118486407631e-06, 6.497688884490963e-06, 5.84792950502401e-06, 5.312643632170735e-06, 4.80715302010796e-06, 4.392712894565167e-06, 3.954049324530075e-06, 3.602066934888537e-06, 3.254924845725876e-06, 2.929533994914806e-06, 2.6617491875736625e-06, 2.4422405067642756e-06, 2.2219521687294523e-06, 2.0618096642943586e-06, 1.9045160794249995e-06, 1.7556142433731837e-06, 1.5921994296779733e-06, 1.536667083546338e-06, 1.5402758985733078e-06, 1.401191156385556e-06, 1.3486310465050562e-06, 1.2332581171655523e-06, 1.2582209746583595e-06, 1.1330652180476967e-06, 1.0290660077387564e-06, 9.360332130350058e-07, 8.6789694028418e-07, 8.467036341609052e-07, 7.877461836646719e-07, 7.563036603008592e-07, 7.107741557180765e-07, 6.532542636026694e-07, 5.995672826639884e-07, 5.432674619861344e-07, 4.974156197496039e-07, 4.577245516187747e-07, 4.124685162207547e-07, 3.743440523110231e-07, 3.3702160203501377e-07, 3.3453215670424723e-07, 4.0757393775545463e-07, 4.012121796943982e-07, 4.612552644215184e-07, 4.767417181769603e-07, 4.4195718959256476e-07, 4.043105140988357e-07, 4.1370829697623107e-07, 4.6891212848239545e-07, 4.792299918297915e-07, 4.3136398485684245e-07, 4.077408792127906e-07], "accuracy_test": 0.4554488201530612, "start": "2016-01-29 15:43:33.771000", "learning_rate_per_epoch": [0.00014994703815318644, 0.00013618756202049553, 0.0001236906973645091, 0.00011234056728426367, 0.00010203194688074291, 9.266927372664213e-05, 8.416573837166652e-05, 7.64425058150664e-05, 6.942797335796058e-05, 6.30571084911935e-05, 5.727084862883203e-05, 5.201555177336559e-05, 4.7242490836651996e-05, 4.29074170824606e-05, 3.897013812093064e-05, 3.539415411069058e-05, 3.2146308512892574e-05, 2.9196493414929137e-05, 2.651735849212855e-05, 2.4084067263174802e-05, 2.1874060621485114e-05, 1.9866849470417947e-05, 1.8043823729385622e-05, 1.6388083167839795e-05, 1.4884276424709242e-05, 1.3518462765205186e-05, 1.2277979294594843e-05, 1.1151324542879593e-05, 1.0128054782398976e-05, 9.198682164424099e-06, 8.354591045645066e-06, 7.58795522415312e-06, 6.891667908348609e-06, 6.2592735048383474e-06, 5.684908956027357e-06, 5.163249170436757e-06, 4.689457909989869e-06, 4.259142770024482e-06, 3.8683147067786194e-06, 3.5133496112393914e-06, 3.1909569315757835e-06, 2.898147613450419e-06, 2.632207269925857e-06, 2.3906702608655905e-06, 2.1712971829401795e-06, 1.972054178622784e-06, 1.7910941778609413e-06, 1.6267395039903931e-06, 1.4774662986383191e-06, 1.3418907656159718e-06, 1.2187558695586631e-06, 1.1069201946156682e-06, 1.005346803140128e-06, 9.130939702117757e-07, 8.293064865938504e-07, 7.532075301242003e-07, 6.84091560287925e-07, 6.213178380676254e-07, 5.643043436975859e-07, 5.125225470692385e-07, 4.6549234866688494e-07, 4.227777594678628e-07, 3.839827513729688e-07, 3.4874764764936117e-07, 3.167457975905563e-07, 2.8768050697181025e-07, 2.612823095660133e-07, 2.3730646603326022e-07, 2.155307043949506e-07, 1.957531310381455e-07, 1.7779039751530945e-07, 1.6147596682003496e-07, 1.4665857861473341e-07, 1.332008707777277e-07, 1.209780720046183e-07, 1.0987685783447887e-07, 9.979431325746191e-08, 9.063696637667817e-08, 8.231992154605905e-08, 7.476606356249249e-08, 6.790536843936934e-08, 6.1674221285557e-08, 5.601485852935184e-08, 5.087481369514535e-08, 4.620643068165009e-08, 4.196642677811724e-08, 3.8115494760404545e-08, 3.461793340875374e-08, 3.144131710541842e-08, 2.8556192077644482e-08, 2.5935813496857918e-08, 2.355588613056625e-08, 2.139434585046729e-08, 1.943115357505576e-08, 1.7648108752155167e-08, 1.6028678828661214e-08, 1.4557851812924127e-08, 1.3221991501666253e-08, 1.200871224682487e-08, 1.09067661568929e-08, 9.905937403686949e-09, 8.99694718725641e-09, 8.17136758257675e-09, 7.421545156205411e-09, 6.7405276915621926e-09, 6.122002016439865e-09, 5.560233606871634e-09, 5.050014184604379e-09, 4.586613755463986e-09, 4.165736200434367e-09, 3.783479307628568e-09, 3.436299023107381e-09, 3.120976588277813e-09, 2.8345890079606306e-09, 2.5744808507255357e-09, 2.338240934207647e-09, 2.1236787883793795e-09, 1.9288053376698144e-09, 1.7518139161509794e-09, 1.5910636141924783e-09, 1.445064179428357e-09, 1.3124619169246898e-09, 1.192027587748612e-09, 1.0826445295819553e-09, 9.832986647140274e-10, 8.930690076347503e-10, 8.111190608062202e-10, 7.366889875903837e-10, 6.690887843774362e-10, 6.076917302699769e-10, 5.519286139232804e-10, 5.0128245998593e-10, 4.552836718740849e-10, 4.135058406795622e-10, 3.7556163734464576e-10, 3.410992877039831e-10, 3.0979926957108717e-10, 2.813713984028965e-10, 2.555521350089407e-10, 2.321021153051106e-10, 2.1080391598982118e-10, 1.9146008389814284e-10, 1.73891290256023e-10, 1.5793463759017357e-10, 1.43442202560351e-10, 1.3027963430278788e-10, 1.1832489155150228e-10, 1.0746713935416707e-10, 9.76057221158122e-11], "accuracy_train_first": 0.28212382336655595, "accuracy_train_last": 0.45520411562153934, "batch_size_eval": 1024, "accuracy_train_std": [0.014219067609037789, 0.01296235485795527, 0.012029971622794865, 0.011819849849996402, 0.012523239218310195, 0.011461391786552389, 0.010864460002292697, 0.01033726639773875, 0.010537117369023066, 0.011146315448082577, 0.012121421465923408, 0.011767433447669536, 0.012020425742320788, 0.012387625287742454, 0.01289471631910109, 0.012363374597533332, 0.013006734504479657, 0.012804967692920553, 0.012172806371482194, 0.011973304251292078, 0.012362446034524905, 0.012258463691298042, 0.012396654414116371, 0.012320410371291746, 0.012317300722184699, 0.012196561524599926, 0.012347088784787469, 0.01228081616717708, 0.012389893172601738, 0.012386430216008984, 0.012392638053098868, 0.01247202505641637, 0.012151013624011317, 0.012839863148317924, 0.012834157367527237, 0.012072750903078681, 0.01222478779232539, 0.012434986161659882, 0.012619860590895472, 0.012403920859599283, 0.012893161422459372, 0.012806590208553932, 0.012402474602530713, 0.012812253723370309, 0.012705156203085816, 0.012799375041877495, 0.01292101631348027, 0.012915782000938177, 0.01270179925269132, 0.012980666701488836, 0.013461101194141236, 0.0125700338192376, 0.012381489599650792, 0.012645814883056898, 0.012543971946627458, 0.01300694483190955, 0.012647578865730097, 0.012737442064915392, 0.012805234595485748, 0.012777166756787639, 0.012357009027483804, 0.012601761742024252, 0.012494750776074643, 0.012675910658154568, 0.013072725476946443, 0.012852182147034073, 0.012684477744850563, 0.012933806100891588, 0.013530735834681064, 0.012797260956995892, 0.013161158078500754, 0.012767876163317884, 0.013011019321085109, 0.013014470156293409, 0.012849382363268607, 0.01288107407423946, 0.01304093381796727, 0.013090163226760066, 0.01293438350976726, 0.012869085321339922, 0.012588671086413226, 0.012859530234809194, 0.012749239467211303, 0.013369763126544362, 0.0130935712038428, 0.01313607335869931, 0.012959387039025895, 0.012925222622298282, 0.012447385759506985, 0.012715415058649027, 0.012609637342644177, 0.0129897970012914, 0.013028805521255876, 0.012294852032218353, 0.01300008399435506, 0.012617968004671758, 0.013030165312153058, 0.012522369805539205, 0.012806635860971688, 0.012628801914896612, 0.013178399470123286, 0.0133042666234784, 0.013124582127823553, 0.012962682169186767, 0.012444387216769732, 0.01272856268421188, 0.01280415778713504, 0.013008680947053904, 0.012972777383533063, 0.01261251865492552, 0.013259351795705579, 0.01300404045823772, 0.01274774232120729, 0.012690391759579858, 0.012530818876511784, 0.012698177053231, 0.012488459246718908, 0.012915509508343912, 0.012828240797977028, 0.01287540706654734, 0.013166130642321552, 0.013030754631934802, 0.012668768303516983, 0.01307953601238115, 0.01282549625245576, 0.012795896194175836, 0.012842037557329012, 0.012809942850132332, 0.012845115003973123, 0.013056187397621698, 0.013135149850264592, 0.012689131557394187, 0.012972907984204692, 0.012893453077423525, 0.012964999000313842, 0.012630938783703211, 0.012996916055329434, 0.013091107183750854, 0.012978258660261695, 0.013143660669664575, 0.012847249757888868, 0.012739158968838774, 0.013228010832040372, 0.012950418902930678, 0.01315590920008579, 0.012697566459153544, 0.012955109741215793, 0.012762840834132988, 0.012948358870046093], "accuracy_test_std": 0.02065360953047881, "error_valid": [0.7179455125188253, 0.6776917239269579, 0.6538865422628012, 0.6358804358057228, 0.6136621682040663, 0.6000300028237951, 0.5916880412274097, 0.5872935099774097, 0.5814135448042168, 0.5778632106551205, 0.5730818782944277, 0.5690432628953314, 0.5655135189194277, 0.5629397472703314, 0.5618617046310241, 0.5605189311935241, 0.5576598385730421, 0.5564494305346386, 0.5560935146837349, 0.5554625729480421, 0.5532756024096386, 0.5527770260730421, 0.5508033108998494, 0.5490943265248494, 0.547619187688253, 0.547008836125753, 0.5465102597891567, 0.5446586149284638, 0.5445365446159638, 0.5435599821159638, 0.5431834760918675, 0.5421966185052711, 0.5412303510918675, 0.5413524214043675, 0.5423392789909638, 0.5407420698418675, 0.5399890577936747, 0.5412303510918675, 0.5401317182793675, 0.5410979856927711, 0.5408641401543675, 0.5398669874811747, 0.5392566359186747, 0.5407214796686747, 0.5395007765436747, 0.5399993528802711, 0.5388904249811747, 0.5396434370293675, 0.5386668745293675, 0.5386565794427711, 0.5401317182793675, 0.5386565794427711, 0.5398875776543675, 0.5379138624811747, 0.5391448606927711, 0.5391551557793675, 0.5386565794427711, 0.5386565794427711, 0.5395213667168675, 0.5390227903802711, 0.5378020872552711, 0.5382903685052711, 0.5385345091302711, 0.5391654508659638, 0.5385345091302711, 0.5383006635918675, 0.5380462278802711, 0.5396331419427711, 0.5393890013177711, 0.5391551557793675, 0.5381580031061747, 0.5389110151543675, 0.5396434370293675, 0.5385448042168675, 0.5380462278802711, 0.5386668745293675, 0.5396537321159638, 0.5387889448418675, 0.5382903685052711, 0.5391551557793675, 0.5393992964043675, 0.5391551557793675, 0.5382903685052711, 0.5384124388177711, 0.5383006635918675, 0.5390227903802711, 0.5393890013177711, 0.5387683546686747, 0.5393992964043675, 0.5390330854668675, 0.5385448042168675, 0.5381785932793675, 0.5395213667168675, 0.5389110151543675, 0.5386668745293675, 0.5380462278802711, 0.5390330854668675, 0.5380462278802711, 0.5373138060052711, 0.5390433805534638, 0.5386668745293675, 0.5393992964043675, 0.5392669310052711, 0.5396434370293675, 0.5387889448418675, 0.5381682981927711, 0.5384124388177711, 0.5387889448418675, 0.5392875211784638, 0.5395316618034638, 0.5393992964043675, 0.5397655073418675, 0.5397552122552711, 0.5384124388177711, 0.5386565794427711, 0.5379138624811747, 0.5375579466302711, 0.5391551557793675, 0.5378020872552711, 0.5391551557793675, 0.5400199430534638, 0.5387786497552711, 0.5385345091302711, 0.5391551557793675, 0.5393890013177711, 0.5380565229668675, 0.5382903685052711, 0.5380462278802711, 0.5392772260918675, 0.5391448606927711, 0.5391551557793675, 0.5390330854668675, 0.5385448042168675, 0.5391551557793675, 0.5387786497552711, 0.5390330854668675, 0.5389007200677711, 0.5382800734186747, 0.5398978727409638, 0.5383006635918675, 0.5378020872552711, 0.5379241575677711, 0.5382903685052711, 0.5389007200677711, 0.5379138624811747, 0.5375476515436747, 0.5392772260918675, 0.5385345091302711, 0.5390227903802711], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.09176219311512403, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.00016509667665130242, "optimization": "nesterov_momentum", "nb_data_augmentation": 4, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 8.083809958520662e-08, "rotation_range": [0, 0], "momentum": 0.8286042109590881}, "accuracy_valid_max": 0.4626861939947289, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.4609772096197289, "accuracy_valid_std": [0.018412578572596948, 0.016357920859210735, 0.016461102766049587, 0.016744693908717148, 0.01790506575448573, 0.018829318387784434, 0.017473462452142124, 0.01627230343578173, 0.01820237952808051, 0.01941160829068416, 0.01887011874971503, 0.019052299183507967, 0.01834200326928537, 0.019398080590719846, 0.017797757376144682, 0.016639835385880125, 0.01846813329655998, 0.01861458727467761, 0.017892856394316523, 0.01617306306387692, 0.01663024555553968, 0.015809355694324952, 0.016517969281311204, 0.016293192813187314, 0.015601412638843522, 0.015683320358158233, 0.014760392096020165, 0.015026620240321403, 0.014296212063957736, 0.01468973888486483, 0.014999782763073833, 0.0151896523070666, 0.013365080548715552, 0.014676298035314627, 0.014409563438209597, 0.015278511908461568, 0.015307882326350589, 0.014633856168480938, 0.015038947986660188, 0.015324989828545414, 0.015299701217698353, 0.015020049062461169, 0.015604381826142653, 0.0163841009080656, 0.015796873667244287, 0.016092931603738665, 0.015229626063447561, 0.014986377502628783, 0.014597601467172566, 0.014808221374134945, 0.014999262103515716, 0.015228906886502717, 0.014919092307977083, 0.014813712515001713, 0.01478939325135246, 0.015100326318270694, 0.014022612283406349, 0.014816269397000334, 0.015223396069965329, 0.015308421737857783, 0.015657537443168446, 0.01481377909808195, 0.014808397168336679, 0.014192761571956152, 0.014523910507389085, 0.015219079158517767, 0.014991113203795814, 0.014851029291329537, 0.016150121405653077, 0.014446728003635702, 0.015537213524791777, 0.014675466182062825, 0.015517859840525831, 0.015291831311354614, 0.015453160558798753, 0.014548520788031658, 0.01502173885246684, 0.01539137109888123, 0.014545797951862872, 0.014363974527268432, 0.014946071563818506, 0.014028079735158119, 0.01423933813875, 0.014823659061137095, 0.015429117669814175, 0.015009592602674376, 0.015456128627181839, 0.015610455407646884, 0.014393491300302298, 0.014360093133721535, 0.014687419543378157, 0.014026031897722514, 0.014526161623815146, 0.014396634188983775, 0.013877534751953038, 0.015094135172885577, 0.015088735763088206, 0.015030820602499686, 0.01448563944572949, 0.014306060435487935, 0.014317253120097637, 0.015292987696040723, 0.015623147015414776, 0.014994329902679869, 0.014299278916982629, 0.014794830633407677, 0.014686311726097377, 0.014975250235341433, 0.014828077598556456, 0.014628067579256738, 0.01426871799165414, 0.014334591104112272, 0.015214641530394245, 0.014596751273690601, 0.014358634977420421, 0.01596032669415478, 0.014397574097364132, 0.015029108014328213, 0.014404455674761717, 0.013959930960543515, 0.014806898432083758, 0.013944636219228602, 0.014048278094409223, 0.01448792748831039, 0.014978263544710203, 0.014629512557138857, 0.014205811357090944, 0.014718262241160403, 0.014808107731238758, 0.014981595330324043, 0.014355672942809572, 0.014209881786465652, 0.014499540183187559, 0.014610828915330686, 0.015568397916485698, 0.01368857943908472, 0.015131383353208608, 0.015669870259383885, 0.014377332742215837, 0.01378031636394667, 0.014528063256081261, 0.014721476040008551, 0.013985928401669066, 0.015543324833321262, 0.014781488563764886, 0.014961119570771618, 0.01513457023912926, 0.01467090695391649, 0.015206851566836457], "accuracy_valid": [0.2820544874811747, 0.32230827607304213, 0.3461134577371988, 0.3641195641942771, 0.38633783179593373, 0.39996999717620485, 0.40831195877259036, 0.41270649002259036, 0.41858645519578314, 0.4221367893448795, 0.4269181217055723, 0.43095673710466864, 0.4344864810805723, 0.43706025272966864, 0.4381382953689759, 0.4394810688064759, 0.44234016142695787, 0.4435505694653614, 0.4439064853162651, 0.44453742705195787, 0.4467243975903614, 0.44722297392695787, 0.4491966891001506, 0.4509056734751506, 0.452380812311747, 0.452991163874247, 0.4534897402108434, 0.45534138507153615, 0.45546345538403615, 0.45644001788403615, 0.45681652390813254, 0.4578033814947289, 0.45876964890813254, 0.45864757859563254, 0.45766072100903615, 0.45925793015813254, 0.4600109422063253, 0.45876964890813254, 0.45986828172063254, 0.4589020143072289, 0.45913585984563254, 0.4601330125188253, 0.4607433640813253, 0.4592785203313253, 0.4604992234563253, 0.4600006471197289, 0.4611095750188253, 0.46035656297063254, 0.46133312547063254, 0.4613434205572289, 0.45986828172063254, 0.4613434205572289, 0.46011242234563254, 0.4620861375188253, 0.4608551393072289, 0.46084484422063254, 0.4613434205572289, 0.4613434205572289, 0.46047863328313254, 0.4609772096197289, 0.4621979127447289, 0.4617096314947289, 0.4614654908697289, 0.46083454913403615, 0.4614654908697289, 0.46169933640813254, 0.4619537721197289, 0.4603668580572289, 0.4606109986822289, 0.46084484422063254, 0.4618419968938253, 0.46108898484563254, 0.46035656297063254, 0.46145519578313254, 0.4619537721197289, 0.46133312547063254, 0.46034626788403615, 0.46121105515813254, 0.4617096314947289, 0.46084484422063254, 0.46060070359563254, 0.46084484422063254, 0.4617096314947289, 0.4615875611822289, 0.46169933640813254, 0.4609772096197289, 0.4606109986822289, 0.4612316453313253, 0.46060070359563254, 0.46096691453313254, 0.46145519578313254, 0.46182140672063254, 0.46047863328313254, 0.46108898484563254, 0.46133312547063254, 0.4619537721197289, 0.46096691453313254, 0.4619537721197289, 0.4626861939947289, 0.46095661944653615, 0.46133312547063254, 0.46060070359563254, 0.4607330689947289, 0.46035656297063254, 0.46121105515813254, 0.4618317018072289, 0.4615875611822289, 0.46121105515813254, 0.46071247882153615, 0.46046833819653615, 0.46060070359563254, 0.46023449265813254, 0.4602447877447289, 0.4615875611822289, 0.4613434205572289, 0.4620861375188253, 0.4624420533697289, 0.46084484422063254, 0.4621979127447289, 0.46084484422063254, 0.45998005694653615, 0.4612213502447289, 0.4614654908697289, 0.46084484422063254, 0.4606109986822289, 0.46194347703313254, 0.4617096314947289, 0.4619537721197289, 0.46072277390813254, 0.4608551393072289, 0.46084484422063254, 0.46096691453313254, 0.46145519578313254, 0.46084484422063254, 0.4612213502447289, 0.46096691453313254, 0.4610992799322289, 0.4617199265813253, 0.46010212725903615, 0.46169933640813254, 0.4621979127447289, 0.4620758424322289, 0.4617096314947289, 0.4610992799322289, 0.4620861375188253, 0.4624523484563253, 0.46072277390813254, 0.4614654908697289, 0.4609772096197289], "seed": 144974612, "model": "residualv3", "loss_std": [0.5685800909996033, 0.0863981768488884, 0.08565976470708847, 0.08698926120996475, 0.08821574598550797, 0.08844952285289764, 0.0900019034743309, 0.09185343980789185, 0.09299980103969574, 0.09363584965467453, 0.0941806212067604, 0.09536243230104446, 0.09628541767597198, 0.09630116075277328, 0.09694273769855499, 0.09744657576084137, 0.09879013895988464, 0.09814972430467606, 0.09871508181095123, 0.0986795648932457, 0.09949873387813568, 0.09934107959270477, 0.09974686056375504, 0.10024634003639221, 0.09941892325878143, 0.10014715790748596, 0.09977574646472931, 0.10037645697593689, 0.09968576580286026, 0.10043627768754959, 0.0994030088186264, 0.1010688915848732, 0.09889259934425354, 0.10087758302688599, 0.09973154962062836, 0.10117774456739426, 0.10058358311653137, 0.10166459530591965, 0.10029922425746918, 0.09945105016231537, 0.10070588439702988, 0.1012103259563446, 0.10125386714935303, 0.10106094926595688, 0.10138897597789764, 0.10095734149217606, 0.10156808793544769, 0.10181696712970734, 0.09992723166942596, 0.10065171122550964, 0.10100449621677399, 0.10132358968257904, 0.10183573514223099, 0.10163673758506775, 0.10131293535232544, 0.1019459143280983, 0.1016799658536911, 0.10043654590845108, 0.10083694756031036, 0.10152864456176758, 0.10170365869998932, 0.10209697484970093, 0.10165463387966156, 0.10006269067525864, 0.10129885375499725, 0.10116294026374817, 0.10075036436319351, 0.10209555923938751, 0.10156039148569107, 0.10083276033401489, 0.10151850432157516, 0.10195215791463852, 0.1006244421005249, 0.100984588265419, 0.10047894716262817, 0.10151366889476776, 0.10163746029138565, 0.10045590251684189, 0.10053636878728867, 0.10053457319736481, 0.10064427554607391, 0.10064971446990967, 0.10098842531442642, 0.10069283843040466, 0.10137228667736053, 0.10146690905094147, 0.10036525130271912, 0.10053520649671555, 0.10132720321416855, 0.10122548788785934, 0.10063405334949493, 0.10134340077638626, 0.1012721061706543, 0.10119056701660156, 0.10042928159236908, 0.10083196312189102, 0.1012880951166153, 0.10146826505661011, 0.10122644156217575, 0.10072340071201324, 0.10105888545513153, 0.10118990391492844, 0.10136580467224121, 0.1009972020983696, 0.10184694081544876, 0.1016814261674881, 0.10094728320837021, 0.1016368716955185, 0.1012076660990715, 0.1014116182923317, 0.09965476393699646, 0.10171801596879959, 0.10097946971654892, 0.10082834213972092, 0.10088998079299927, 0.1015205830335617, 0.10169361531734467, 0.10075420141220093, 0.10146775841712952, 0.10138137638568878, 0.100525863468647, 0.10126708447933197, 0.10074656456708908, 0.10160908102989197, 0.10070524364709854, 0.10185373574495316, 0.10147467255592346, 0.10160516947507858, 0.10057759284973145, 0.10154014080762863, 0.10071214288473129, 0.10089699923992157, 0.10138701647520065, 0.10104537010192871, 0.1002531349658966, 0.10147322714328766, 0.10077384859323502, 0.10102874785661697, 0.10190965235233307, 0.1010529100894928, 0.10119360685348511, 0.10069232434034348, 0.09960712492465973, 0.10239244252443314, 0.10157261043787003, 0.10149522125720978, 0.1011480838060379, 0.10230165719985962, 0.1014702171087265]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:23 2016", "state": "available"}], "summary": "8e922c519dc706e4615d0966be232493"}