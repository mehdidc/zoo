{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 16, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.014474969683992445, 0.007651121948400619, 0.008363416158335484, 0.013322501577008374, 0.008919400146122369, 0.006842685336506389, 0.004088116429873741, 0.006054050446927848, 0.006821401942890591, 0.006641415976606163, 0.011396562832312978, 0.008711217034295284, 0.00829855336299633, 0.012333319684295749, 0.009635044066995248, 0.009524302282839148, 0.01066246275073855, 0.009222050389987496, 0.01041880867203319, 0.010815639336714972, 0.009788634146640366, 0.010184886374841318, 0.012134174730379612, 0.010534692463037579, 0.010988208111966697, 0.008780957830485606, 0.009016630634485408, 0.00869022687596624, 0.00708308981615666, 0.008699338601163462, 0.006981299942227911, 0.008945562474192339, 0.008344961500121704, 0.008843920006296593, 0.009217151321611031, 0.006779744887848828, 0.009753965521123925, 0.009217151321611031, 0.008783610555950066, 0.008772780334823765, 0.008014052035329771, 0.010236762551672439, 0.00905536315563089, 0.009280674320060965, 0.008047358128192208, 0.010031733162057185, 0.009144461169371246, 0.009019901717490307, 0.008697681853863132, 0.010623618878621802, 0.009061643326916818, 0.0081366509783282, 0.009930966284449703, 0.01025086984258909, 0.010392265702600165, 0.009215262462000606, 0.007874283155620884, 0.008313485860519396, 0.009799277555269057, 0.00886230741622008, 0.010448148891045101, 0.007121887192945435, 0.011755288345878905, 0.008480637386629717, 0.01013651912702945, 0.009990226472367829, 0.010223625893550551, 0.009734703188618573, 0.010483155972324187, 0.010912036878931814, 0.010545050642386743, 0.010853192260989665, 0.00934027815560694, 0.00810069994260641, 0.009498563975396257, 0.00932310599188739, 0.009182180798990483, 0.007899277664718004, 0.008995864393759944, 0.010135408902146217, 0.009346350105129622, 0.009435819010206391, 0.009861630540062317, 0.008718627890503455, 0.010493336113688774, 0.008132873064706045, 0.008954628281506278, 0.009071962647045196, 0.008087603713375772, 0.006799853602210202, 0.009681081649415862, 0.010287985895542513, 0.008585755946196453, 0.00875553212601563, 0.009498976030353545, 0.008057335418076317, 0.008868878802376237, 0.01001472545153704, 0.008656549552230141, 0.010225041637916538, 0.008851684426230223, 0.008936243605679833, 0.008625165725316374, 0.009332211115139474, 0.008167950840186651, 0.008772504550556165, 0.010004943868566565, 0.00839052225790644, 0.009744591223709824, 0.0083867275558104, 0.008953002588312766, 0.01082248248396923, 0.008746146063977797, 0.009732500062927153, 0.010244686226124481, 0.009096192073316897, 0.008774377296771023, 0.009135577117391016, 0.01005636461408029, 0.009538734339578475, 0.010096492008532042, 0.010113650624473874, 0.007831714870566978, 0.008094519844732945, 0.009598062673043795, 0.008776750445615307, 0.00945168318765175, 0.010267446474356314, 0.009434476160132389, 0.010499743698466625, 0.011010009357535936, 0.008162326774945673, 0.011695135422884724, 0.010554102956132265, 0.009206393633803583, 0.008532635892307716, 0.008836115471627975, 0.008764144431237107, 0.010327360794019934, 0.011591048617450295, 0.011454277161487557, 0.009618868512883677, 0.010639879879609097, 0.01059250368694966, 0.010020443119134446, 0.009161171219018808, 0.00996839465516781, 0.009991430657901696, 0.009572265429900027, 0.010570777837682342, 0.01089507755646087, 0.009689691465659752, 0.009710262552805562, 0.009880905171694723, 0.010896612806418638, 0.012701839471840707, 0.012208646816062697, 0.011148668296874794, 0.011006037477690713, 0.011268677218837134, 0.011434659707461797, 0.010500630630787024, 0.011532591457655271, 0.011205785188085965, 0.01160956623986624, 0.011684170035839153, 0.011120394359420313, 0.010810399087578103, 0.011345335951772317, 0.010587774173840084, 0.010447435559130261, 0.010533657676319313, 0.010042421331071255, 0.010543492820032956, 0.010298175079306094, 0.011156084283988007, 0.010695395959881799, 0.012050160910099191, 0.011560655374228507, 0.010638643264469401, 0.010480377516219209, 0.011128822042412457, 0.01132556236075872, 0.011416881784765898, 0.011972883469027558, 0.010348400222134957, 0.010798282639262729, 0.010837713980298902, 0.010977943457022807, 0.010550700279299436, 0.011082243701506027, 0.010777321870101712, 0.0110198154646145, 0.010998705576755221, 0.010968519572371731, 0.009899179474641862, 0.0104275677445538, 0.011792448757311936, 0.011216834873529606, 0.010846589449677178, 0.01071774530810537, 0.01091399437199724, 0.010660420823830409, 0.010990320511062466, 0.01153640380042411, 0.009069692142389668, 0.010185422931517205, 0.011416200468016726, 0.011393469380712113, 0.011207131288612053, 0.011118020296096258, 0.01144897885224407, 0.01170490281264626, 0.010273564597917095, 0.010599348860406657, 0.010886780465424704, 0.010572417057317643, 0.012164399203391055, 0.011382973974598443, 0.010670300893238806, 0.011245592259514563, 0.011454758601442502, 0.011329717574427653, 0.011022588736768953, 0.011000937473767528, 0.011141398030287972, 0.01150099509482867, 0.010771113553652362, 0.010694545001221648, 0.011189956377362094, 0.009870770423946186, 0.011384473164298994, 0.012541011592508894, 0.011625573082404137, 0.01203060158560638, 0.010227551182941674, 0.010122904205184186, 0.010489128377408606, 0.011168372376629508, 0.010362405523937784, 0.01035139799061109, 0.010562146948902295, 0.011627707349814028, 0.010732508137817554, 0.01116253270429805, 0.010672447131968027, 0.010773464477951794, 0.009557790651027005, 0.01002847591691218, 0.011386147691080196, 0.01119530578470303, 0.010945539464730588, 0.009985490051681045, 0.00997269879748261, 0.010146008002348307, 0.011118214068541321, 0.010928467755537172, 0.011358023382449893, 0.01032764322971971, 0.011650216926489031, 0.011884321755480168], "moving_avg_accuracy_train": [0.03774361791712808, 0.08209460940383903, 0.13654219514234955, 0.19032244608538662, 0.24324371580409046, 0.29437592053758876, 0.3419688502976911, 0.38536767848659126, 0.42664645604214035, 0.4647948086326015, 0.49973976800328374, 0.5321853590785551, 0.5620674433545774, 0.5891403917101495, 0.6141546896503841, 0.6372279547085092, 0.6581890255167281, 0.6774029057608286, 0.6952229904673685, 0.7112447546127689, 0.7259922604234097, 0.7396485931089204, 0.7520950053984805, 0.7635362667864657, 0.774047243628491, 0.7835699018041709, 0.7921009108277959, 0.8001763472978495, 0.8076022781423078, 0.8143646349130254, 0.8207437247566711, 0.8265918985100092, 0.8320831555201655, 0.8370786210566502, 0.8417350113561624, 0.845993264038837, 0.84979778966753, 0.8534381015726392, 0.8568515660669995, 0.8599886080344966, 0.8628492563326527, 0.8654982445628979, 0.8679079466558421, 0.8703231082644828, 0.8725571354836694, 0.8745653987833091, 0.87652407857206, 0.8783496333509744, 0.880092578001988, 0.8816356155021768, 0.8831080906583084, 0.8845146624583414, 0.885780721273646, 0.8870037353692881, 0.8881835391637085, 0.8893172979965072, 0.890454082581777, 0.8915398956287397, 0.892514874319834, 0.8935665610584393, 0.8944458300518018, 0.8953673083815237, 0.8961128614234931, 0.8969373910803318, 0.8977468249893252, 0.8985265769276851, 0.8992237033745899, 0.8999486292315292, 0.9007127417432692, 0.9014702695657584, 0.9021659234012184, 0.9027502312721984, 0.9033805958572341, 0.9039107937004512, 0.904539070383147, 0.9050603776190109, 0.9055411077776987, 0.906066698775261, 0.9065630182099811, 0.9070215477381893, 0.9074922088385398, 0.9079995812836356, 0.908472420428251, 0.908958357429815, 0.909386472233622, 0.9098530836677441, 0.910296321495368, 0.9106558522057426, 0.9109979589379185, 0.9113848740075818, 0.9119260488726506, 0.9123038242571648, 0.9125392625044365, 0.9128580777234004, 0.9132449567704587, 0.913672202972335, 0.9140265697171374, 0.914475672071974, 0.9149053326817755, 0.9153525531972819, 0.9157968682909904, 0.9161966797776906, 0.9165031037907392, 0.9168160877834353, 0.9170279468149385, 0.9173628152183008, 0.9176014538122883, 0.9179464729290292, 0.9182685798293249, 0.9185700296860011, 0.9188414427034659, 0.9191252059001275, 0.9193734731354193, 0.9196946059460007, 0.9199488203410185, 0.9202868952905822, 0.9205261306761604, 0.9207065652910379, 0.9209479754551327, 0.9212140006301806, 0.9214882644710477, 0.9217212591814272, 0.9219100641303019, 0.9222030772759188, 0.922441248518888, 0.9227695349292269, 0.9229511325045028, 0.9230959691317749, 0.9232169854522629, 0.9234352181835686, 0.9237245614964871, 0.9238618457376652, 0.9241014787511079, 0.9243102090655966, 0.9245306184319697, 0.9247592858938669, 0.9250092283881365, 0.9252248399889224, 0.9254026504367817, 0.9256416628017414, 0.9257336131409378, 0.9259233252914527, 0.9260405517554784, 0.9262437478719202, 0.9264754164528991, 0.9266258976019983, 0.9268380605469019, 0.9270452111413442, 0.9271921551953991, 0.927284841265468, 0.9274101474559201, 0.9276181459820612, 0.9278565339782164, 0.9281128277068713, 0.9283250350674596, 0.9284299911860365, 0.9286360227867942, 0.9287563110119907, 0.9288576670658766, 0.9289790784000789, 0.9290906737496705, 0.9291563404786163, 0.9293083743894109, 0.9293730531983935, 0.9294568047145637, 0.9296228618826884, 0.9297514230435335, 0.9299321962061422, 0.93009489205249, 0.9302761955463458, 0.9304742819717776, 0.930596720134419, 0.9306836990415197, 0.9308107721340917, 0.9309531118007581, 0.9311345877769208, 0.931346780329286, 0.9314796249061764, 0.9316409656063118, 0.9317327298626333, 0.931889794552865, 0.9320427424693024, 0.9321455183619531, 0.9322194154748626, 0.9323649058383676, 0.9324911968679029, 0.9326583732659225, 0.932820421719369, 0.9329314962417842, 0.9331035068762343, 0.9331908150341259, 0.9333414359405048, 0.9334909456491028, 0.9335721341106784, 0.933717211241554, 0.9338362270129321, 0.9339596532976577, 0.9339986573408156, 0.9341359954296391, 0.9342596357583991, 0.9344034280887976, 0.9344258482920995, 0.934583210254833, 0.9347039817796451, 0.9348591070305288, 0.9349964306563333, 0.9351433094564715, 0.9352963546182441, 0.9354039043781344, 0.9355007352108544, 0.935594858406731, 0.9357330116568201, 0.9357573681830909, 0.9358838486555255, 0.9360139931712022, 0.9360498511734341, 0.9361913693206717, 0.9363093990091287, 0.9363713758037215, 0.936424901867683, 0.9365009771109627, 0.936578673327515, 0.9367462922212308, 0.93686695833987, 0.9369825693418925, 0.9370610065579894, 0.937171055484601, 0.9373143854923885, 0.9374014577231885, 0.9374450175964031, 0.937521351765611, 0.9376714687750503, 0.9378065740835456, 0.9378956167778582, 0.9380152466836824, 0.9380787357715434, 0.9381033238672849, 0.9380859616725092, 0.9381610165007825, 0.9382749606759626, 0.9383612704407769, 0.9384156616921957, 0.9384623968161193, 0.9385532505038319, 0.9386257903251726, 0.9386933292155512, 0.93876341481213, 0.9388659833299942, 0.9389978946234713, 0.9391327826828111, 0.9392426282898068, 0.9393833059658556, 0.9394844113350324, 0.939563744374425, 0.9396281686634498, 0.9397163774580959, 0.9398305705077828, 0.9399171042596531, 0.9399950206851551, 0.9400581700216784, 0.9401010535316922], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 735074811, "moving_var_accuracy_train": [0.01282122624126737, 0.02924219762982941, 0.05299883420161855, 0.07372978930492108, 0.0915627574721872, 0.10593700297314394, 0.11572908534417986, 0.12110730140328893, 0.12433200855128455, 0.12499647894445137, 0.12348718271877394, 0.12061291186891018, 0.11658807132813286, 0.11152576498929087, 0.1060046244033472, 0.10019554200699494, 0.09413028621113992, 0.08803981633633766, 0.0820938334732382, 0.07619472246289194, 0.07053265056531671, 0.06515784431054115, 0.06003627848942247, 0.05521077279981401, 0.05068402122739494, 0.046431748273233035, 0.042443576480560276, 0.03878613290014109, 0.03540381965028708, 0.032275002907108594, 0.029413737701497477, 0.02678017415759082, 0.02437354187379606, 0.022160779769752316, 0.020139839528369605, 0.0182890500187182, 0.016590414754180806, 0.015050640115661052, 0.013650441762783273, 0.012373966877257492, 0.011210219967703433, 0.01015235221872889, 0.00918937697444666, 0.008322936327364656, 0.0075355605931727914, 0.00681830262718163, 0.006171000203097223, 0.005583894035044853, 0.005052845336048843, 0.004568989484986858, 0.004131604184256993, 0.0037362497638891248, 0.003377050931814508, 0.0030528077099363092, 0.002760054371882637, 0.002495617616512913, 0.0022576863676013873, 0.0020425286405978352, 0.001846831027570843, 0.0016721023297791846, 0.001511850122465463, 0.001368307211028242, 0.001236479133970927, 0.0011189498629688912, 0.001012951525949257, 0.0009171284911227145, 0.00082978950955721, 0.0007515402160840219, 0.0006816410058509987, 0.0006186415408825066, 0.0005611327951233675, 0.0005080922568038338, 0.00046085926671405437, 0.0004173033278192182, 0.000379125579347469, 0.00034365887252019937, 0.00031137289863742643, 0.0002827218218441512, 0.0002566666364912642, 0.00023289221679628766, 0.00021159669195910732, 0.0001927538639455791, 0.00017549066926114684, 0.00016006681526043302, 0.000145709674301538, 0.00013309824294546564, 0.00012155655659744987, 0.00011056426192302704, 0.00010056116887652462, 9.18523814290652e-05, 8.530297539739772e-05, 7.805710602796161e-05, 7.075027593967085e-05, 6.459003664029067e-05, 5.9478111549736e-05, 5.5173154247921546e-05, 5.0786020931525466e-05, 4.752265516445144e-05, 4.4431863804541224e-05, 4.178873312949594e-05, 3.938660293902113e-05, 3.688658566919547e-05, 3.404298818423114e-05, 3.152032018296405e-05, 2.877224640773323e-05, 2.6904253395092942e-05, 2.4726363462446944e-05, 2.3325070834452342e-05, 2.1926339447969946e-05, 2.0551553647984013e-05, 1.9159383517630055e-05, 1.7968139131883198e-05, 1.6726054799769776e-05, 1.598158585807979e-05, 1.4965051899980542e-05, 1.4497198753685033e-05, 1.3562581005731202e-05, 1.2499332757372011e-05, 1.1773909287589363e-05, 1.1233442902663457e-05, 1.078708450206187e-05, 1.0196954867439306e-05, 9.498085159171349e-06, 9.320986974793093e-06, 8.899418146111317e-06, 8.979424036419388e-06, 8.378280746892277e-06, 7.72925150959916e-06, 7.088130907059483e-06, 6.80794754147164e-06, 6.880628761900467e-06, 6.362188551593225e-06, 6.242785526618942e-06, 6.010622071635992e-06, 5.846782463537578e-06, 5.732703490358206e-06, 5.721674395297961e-06, 5.567902217309037e-06, 5.295660993889578e-06, 5.280237089933281e-06, 4.828307164845087e-06, 4.669392748837586e-06, 4.326131868765424e-06, 4.2651166375222536e-06, 4.321637956484999e-06, 4.093275346944349e-06, 4.089065848961184e-06, 4.066361583065404e-06, 3.854058419957817e-06, 3.545968946225224e-06, 3.3326868238932607e-06, 3.3887886233957973e-06, 3.5613692914545683e-06, 3.796410640439652e-06, 3.822057251386154e-06, 3.538993607688382e-06, 3.5671354315167155e-06, 3.3406452024534533e-06, 3.0990381291418653e-06, 2.9218007248827314e-06, 2.7417023508486967e-06, 2.5063411893778536e-06, 2.463735860723858e-06, 2.2550124096340215e-06, 2.0926400168179606e-06, 2.1315508629063827e-06, 2.067147525316616e-06, 2.154543199660673e-06, 2.1773183254639316e-06, 2.2554251048765707e-06, 2.383026681852282e-06, 2.279643946705981e-06, 2.1197675245593403e-06, 2.053118909805516e-06, 2.0301522451855523e-06, 2.123538789984664e-06, 2.316416024499254e-06, 2.2436035565323375e-06, 2.2535205945607448e-06, 2.1039546437489313e-06, 2.1155830316321946e-06, 2.1145623147518103e-06, 1.998172040268128e-06, 1.8475018859085869e-06, 1.8532587101727378e-06, 1.8114776564253086e-06, 1.8818614232760464e-06, 1.9300125923280873e-06, 1.8480492788633006e-06, 1.929533276252705e-06, 1.8051843785371216e-06, 1.8288458576288571e-06, 1.8471396485517608e-06, 1.7217497803335454e-06, 1.739001167428274e-06, 1.6925838352157548e-06, 1.6604318815446942e-06, 1.5080805318341386e-06, 1.5270282344261508e-06, 1.511907789046411e-06, 1.5468031186747895e-06, 1.3966467964521778e-06, 1.4798472026452228e-06, 1.46313433322944e-06, 1.5333954910622822e-06, 1.5497759457932382e-06, 1.5889587885841744e-06, 1.6408683036036447e-06, 1.5808840309153272e-06, 1.5071815193109794e-06, 1.4361959513980008e-06, 1.4643532408500347e-06, 1.323257080112827e-06, 1.334907161267365e-06, 1.3538547997870907e-06, 1.2300414867249793e-06, 1.287283812030595e-06, 1.2839344970428709e-06, 1.1901111549506283e-06, 1.096885395164514e-06, 1.039283839408629e-06, 9.896857740666485e-07, 1.1435820384346353e-06, 1.1602666442782006e-06, 1.1645331139484124e-06, 1.1034513743747482e-06, 1.1021031331724343e-06, 1.1767842400467125e-06, 1.1273399764302768e-06, 1.0316831417774654e-06, 9.809569760977603e-07, 1.0856773271948865e-06, 1.1413905939279897e-06, 1.0986089472289989e-06, 1.117549881814041e-06, 1.04207267212942e-06, 9.433065749862414e-07, 8.516889297544948e-07, 8.172190820031958e-07, 8.523466493202179e-07, 8.341563639087629e-07, 7.773664015960085e-07, 7.192873077098468e-07, 7.216481100775779e-07, 6.968415301910865e-07, 6.682108925941806e-07, 6.455977209651282e-07, 6.75720656580237e-07, 7.647538950435214e-07, 8.520316025113683e-07, 8.754229586466016e-07, 9.659925396284875e-07, 9.61393946752871e-07, 9.218981323310783e-07, 8.670627202451596e-07, 8.503835712970055e-07, 8.8270568753844e-07, 8.618279306993331e-07, 8.302838618965013e-07, 7.831460240367878e-07, 7.213823805130261e-07], "duration": 171713.234756, "accuracy_train": [0.3774361791712809, 0.4812535327842377, 0.6265704667889442, 0.6743447045727206, 0.7195351432724253, 0.7545657631390734, 0.7703052181386121, 0.7759571321866926, 0.798155454042082, 0.8081299819467516, 0.8142444023394242, 0.8241956787559985, 0.831006201838778, 0.8327969269102989, 0.8392833711124953, 0.8448873402316353, 0.8468386627906977, 0.8503278279577334, 0.8556037528262275, 0.8554406319213732, 0.8587198127191769, 0.8625555872785161, 0.864112716004522, 0.8665076192783315, 0.8686460352067183, 0.8692738253852897, 0.8688799920404209, 0.8728552755283315, 0.8744356557424326, 0.8752258458494832, 0.8781555333494832, 0.8792254622900517, 0.8815044686115725, 0.8820378108850129, 0.8836425240517718, 0.8843175381829088, 0.8840385203257659, 0.8862009087186231, 0.8875727465162422, 0.8882219857419711, 0.8885950910160576, 0.8893391386351052, 0.8895952654923404, 0.8920595627422481, 0.8926633804563492, 0.8926397684800664, 0.8941521966708195, 0.8947796263612033, 0.895779079861111, 0.8955229530038759, 0.896360367063492, 0.8971738086586378, 0.8971752506113879, 0.8980108622300664, 0.898801773313492, 0.8995211274916944, 0.9006851438492063, 0.9013122130514026, 0.9012896825396824, 0.9030317417058878, 0.9023592509920635, 0.9036606133490217, 0.9028228388012183, 0.9043581579918788, 0.9050317301702658, 0.9055443443729235, 0.9054978413967331, 0.9064729619439831, 0.9075897543489295, 0.9082880199681617, 0.9084268079203581, 0.9080090021110188, 0.9090538771225545, 0.9086825742894058, 0.9101935605274087, 0.9097521427417867, 0.9098676792058878, 0.9107970177533223, 0.9110298931224622, 0.9111483134920635, 0.9117281587416944, 0.9125659332894979, 0.9127279727297897, 0.9133317904438908, 0.9132395054678849, 0.9140525865748431, 0.9142854619439831, 0.913891628599114, 0.914076919527501, 0.9148671096345515, 0.9167966226582688, 0.9157038027177926, 0.914658206729882, 0.9157274146940754, 0.9167268681939831, 0.9175174187892212, 0.9172158704203581, 0.918517593265504, 0.918772278169989, 0.9193775378368402, 0.919795704134367, 0.9197949831579919, 0.9192609199081765, 0.9196329437177003, 0.9189346780984681, 0.9203766308485604, 0.9197492011581765, 0.9210516449796974, 0.921167541931986, 0.9212830783960871, 0.9212841598606497, 0.9216790746700813, 0.9216078782530455, 0.922584801241233, 0.9222367498961794, 0.9233295698366556, 0.922679249146364, 0.9223304768249354, 0.923120666931986, 0.923608227205611, 0.923956639038852, 0.9238182115748431, 0.9236093086701735, 0.924840195586471, 0.924584789705611, 0.9257241126222776, 0.924585510681986, 0.9243994987772242, 0.9243061323366556, 0.9253993127653194, 0.9263286513127538, 0.9250974039082688, 0.926258175872093, 0.9261887818959949, 0.9265143027293282, 0.9268172930509413, 0.9272587108365633, 0.9271653443959949, 0.9270029444675157, 0.9277927740863787, 0.9265611661937062, 0.9276307346460871, 0.9270955899317092, 0.9280725129198967, 0.9285604336817092, 0.9279802279438908, 0.9287475270510337, 0.9289095664913253, 0.9285146516818937, 0.9281190158960871, 0.928537903169989, 0.9294901327173312, 0.9300020259436139, 0.9304194712647655, 0.9302349013127538, 0.92937459625323, 0.9304903071936139, 0.9298389050387597, 0.929769871550849, 0.9300717804078996, 0.9300950318959949, 0.9297473410391289, 0.9306766795865633, 0.9299551624792359, 0.930210568360096, 0.9311173763958103, 0.9309084734911407, 0.9315591546696198, 0.9315591546696198, 0.9319079269910484, 0.9322570598006644, 0.9316986635981912, 0.9314665092054264, 0.9319544299672389, 0.9322341688007567, 0.9327678715623846, 0.9332565133005721, 0.9326752260981912, 0.9330930319075305, 0.9325586081695275, 0.9333033767649501, 0.9334192737172389, 0.9330705013958103, 0.9328844894910484, 0.9336743191099114, 0.9336278161337209, 0.9341629608480989, 0.9342788578003876, 0.9339311669435216, 0.9346516025862864, 0.9339765884551495, 0.9346970240979143, 0.9348365330264857, 0.9343028302648578, 0.9350229054194352, 0.9349073689553341, 0.9350704898601883, 0.9343496937292359, 0.9353720382290514, 0.9353723987172389, 0.9356975590623846, 0.9346276301218162, 0.9359994679194352, 0.9357909255029531, 0.9362552342884828, 0.9362323432885751, 0.936465218657715, 0.9366737610741971, 0.9363718522171466, 0.9363722127053341, 0.9364419671696198, 0.9369763909076227, 0.9359765769195275, 0.9370221729074382, 0.9371852938122923, 0.9363725731935216, 0.9374650326458103, 0.9373716662052418, 0.9369291669550572, 0.936906636443337, 0.9371856543004798, 0.9372779392764857, 0.9382548622646733, 0.9379529534076227, 0.938023068360096, 0.9377669415028608, 0.9381614958241048, 0.9386043555624769, 0.9381851078003876, 0.9378370564553341, 0.9382083592884828, 0.9390225218600037, 0.9390225218600037, 0.9386970010266703, 0.9390919158361019, 0.9386501375622923, 0.938324616728959, 0.9379297019195275, 0.9388365099552418, 0.9393004582525839, 0.9391380583241048, 0.9389051829549648, 0.9388830129314323, 0.9393709336932448, 0.9392786487172389, 0.939301179228959, 0.93939418518134, 0.9397890999907714, 0.9401850962647655, 0.9403467752168696, 0.9402312387527685, 0.9406494050502953, 0.9403943596576227, 0.940277741728959, 0.9402079872646733, 0.9405102566099114, 0.9408583079549648, 0.9406959080264857, 0.9406962685146733, 0.9406265140503876, 0.9404870051218162], "end": "2016-01-25 10:24:35.387000", "learning_rate_per_epoch": [0.007366668898612261, 0.0036833344493061304, 0.0024555562995374203, 0.0018416672246530652, 0.0014733338030055165, 0.0012277781497687101, 0.0010523813543841243, 0.0009208336123265326, 0.0008185188053175807, 0.0007366669015027583, 0.0006696971831843257, 0.0006138890748843551, 0.0005666668293997645, 0.0005261906771920621, 0.0004911112482659519, 0.0004604168061632663, 0.0004333334800321609, 0.00040925940265879035, 0.0003877194249071181, 0.00036833345075137913, 0.00035079376539215446, 0.00033484859159216285, 0.0003202899533789605, 0.00030694453744217753, 0.0002946667664218694, 0.00028333341469988227, 0.0002728395920712501, 0.00026309533859603107, 0.0002540230634622276, 0.00024555562413297594, 0.00023763449280522764, 0.00023020840308163315, 0.00022323240409605205, 0.00021666674001608044, 0.00021047625341452658, 0.00020462970132939517, 0.00019909915863536298, 0.00019385971245355904, 0.00018888895283453166, 0.00018416672537568957, 0.00017967485473491251, 0.00017539688269607723, 0.00017131789354607463, 0.00016742429579608142, 0.00016370376397389919, 0.00016014497668948025, 0.00015673764573875815, 0.00015347226872108877, 0.00015034018724691123, 0.0001473333832109347, 0.00014444449334405363, 0.00014166670734994113, 0.0001389937533531338, 0.00013641979603562504, 0.00013393943663686514, 0.00013154766929801553, 0.0001292398083023727, 0.0001270115317311138, 0.00012485879415180534, 0.00012277781206648797, 0.00012076507118763402, 0.00011881724640261382, 0.00011693125270539895, 0.00011510420154081658, 0.000113333371700719, 0.00011161620204802603, 0.00010995028424076736, 0.00010833337000804022, 0.00010676332021830603, 0.00010523812670726329, 0.00010375590500188991, 0.00010231485066469759, 0.00010091327567351982, 9.954957931768149e-05, 9.822225547395647e-05, 9.692985622677952e-05, 9.567102824803442e-05, 9.444447641726583e-05, 9.324897837359458e-05, 9.208336268784478e-05, 9.09465306904167e-05, 8.983742736745626e-05, 8.875504863681272e-05, 8.769844134803861e-05, 8.666669600643218e-05, 8.565894677303731e-05, 8.46743569127284e-05, 8.371214789804071e-05, 8.277156302938238e-05, 8.185188198694959e-05, 8.09524062788114e-05, 8.007248834474012e-05, 7.921149517642334e-05, 7.836882286937907e-05, 7.754388207104057e-05, 7.673613436054438e-05, 7.594504131702706e-05, 7.517009362345561e-05, 7.441079651471227e-05, 7.366669160546735e-05, 7.293732051039115e-05, 7.222224667202681e-05, 7.152106263674796e-05, 7.083335367497057e-05, 7.015875598881394e-05, 6.94968766765669e-05, 6.884737376822159e-05, 6.820989801781252e-05, 6.758412200724706e-05, 6.696971831843257e-05, 6.636638863710687e-05, 6.577383464900777e-05, 6.519176531583071e-05, 6.461990415118635e-05, 6.405798922060058e-05, 6.35057658655569e-05, 6.296298670349643e-05, 6.242939707590267e-05, 6.190478598000482e-05, 6.138890603324398e-05, 6.0881564422743395e-05, 6.038253559381701e-05, 5.989161945763044e-05, 5.940862320130691e-05, 5.893335401196964e-05, 5.8465626352699474e-05, 5.8005269238492474e-05, 5.755210077040829e-05, 5.71059608773794e-05, 5.66666858503595e-05, 5.6234115618281066e-05, 5.580810102401301e-05, 5.538848927244544e-05, 5.497514212038368e-05, 5.4567917686654255e-05, 5.416668500402011e-05, 5.3771305829286575e-05, 5.338166010915302e-05, 5.299762051436119e-05, 5.2619063353631645e-05, 5.224587948760018e-05, 5.187795250094496e-05, 5.1515169616322964e-05, 5.1157425332348794e-05, 5.080461414763704e-05, 5.045663783675991e-05, 5.011339453631081e-05, 4.9774789658840746e-05, 4.944073225487955e-05, 4.911112773697823e-05, 4.878588879364543e-05, 4.846492811338976e-05, 4.814816566067748e-05, 4.783551412401721e-05, 4.7526897105854005e-05, 4.7222238208632916e-05, 4.6921461034798995e-05, 4.662448918679729e-05, 4.633125354303047e-05, 4.604168134392239e-05, 4.5755707105854526e-05, 4.547326534520835e-05, 4.5194290578365326e-05, 4.491871368372813e-05, 4.464648009161465e-05, 4.437752431840636e-05, 4.411179179442115e-05, 4.384922067401931e-05, 4.358975638751872e-05, 4.333334800321609e-05, 4.30799373134505e-05, 4.282947338651866e-05, 4.258190165273845e-05, 4.23371784563642e-05, 4.20952528656926e-05, 4.1856073949020356e-05, 4.161959805060178e-05, 4.138578151469119e-05, 4.115457704756409e-05, 4.0925940993474796e-05, 4.0699829696677625e-05, 4.04762031394057e-05, 4.0255021303892136e-05, 4.003624417237006e-05, 3.9819831727072597e-05, 3.960574758821167e-05, 3.9393951738020405e-05, 3.918441143468954e-05, 3.897708666045219e-05, 3.8771941035520285e-05, 3.856894909404218e-05, 3.836806718027219e-05, 3.8169269828358665e-05, 3.797252065851353e-05, 3.777779056690633e-05, 3.758504681172781e-05, 3.7394260289147496e-05, 3.720539825735614e-05, 3.701843888848089e-05, 3.6833345802733675e-05, 3.665009353426285e-05, 3.646866025519557e-05, 3.628900958574377e-05, 3.6111123336013407e-05, 3.5934972402174026e-05, 3.576053131837398e-05, 3.5587774618761614e-05, 3.5416676837485284e-05, 3.524721978465095e-05, 3.507937799440697e-05, 3.491312236292288e-05, 3.474843833828345e-05, 3.4585300454637036e-05, 3.4423686884110793e-05, 3.426357579883188e-05, 3.410494900890626e-05, 3.394778468646109e-05, 3.379206100362353e-05, 3.363775977049954e-05, 3.3484859159216285e-05, 3.333334461785853e-05, 3.318319431855343e-05, 3.303439007140696e-05, 3.2886917324503884e-05, 3.274075061199255e-05, 3.2595882657915354e-05, 3.245228799642064e-05, 3.2309952075593174e-05, 3.2168860343517736e-05, 3.202899461030029e-05, 3.189034396200441e-05, 3.175288293277845e-05, 3.161660424666479e-05, 3.148149335174821e-05, 3.134752842015587e-05, 3.1214698537951335e-05, 3.1082992791198194e-05, 3.095239299000241e-05, 3.082288458244875e-05, 3.069445301662199e-05, 3.056709101656452e-05, 3.0440782211371697e-05, 3.0315510230138898e-05, 3.0191267796908505e-05, 3.0068036721786484e-05, 2.994580972881522e-05, 2.9824570447090082e-05, 2.9704311600653455e-05, 2.9585016818600707e-05, 2.946667700598482e-05, 2.934927942987997e-05, 2.9232813176349737e-05, 2.91172691504471e-05, 2.9002634619246237e-05, 2.8888898668810725e-05, 2.8776050385204144e-05, 2.866408249246888e-05, 2.85529804386897e-05, 2.84427387668984e-05, 2.833334292517975e-05, 2.8224785637576133e-05], "accuracy_valid": [0.3714334878576807, 0.47229886342243976, 0.6173757530120482, 0.6652802616716867, 0.7082504823983433, 0.7392166321536144, 0.7587184676204819, 0.7618922957454819, 0.7812308805534638, 0.789074265813253, 0.791515672063253, 0.8007327160203314, 0.8069685970444277, 0.8058802593185241, 0.8101733104292168, 0.8114646084337349, 0.8133059582078314, 0.8163783061935241, 0.8183417262801205, 0.8159812099962349, 0.8215258494917168, 0.8222376811935241, 0.8247908626694277, 0.8267645778426205, 0.8261645213667168, 0.8283823771649097, 0.8292368693524097, 0.8297148555158133, 0.829857516001506, 0.8330519342996988, 0.8340387918862951, 0.8379450418862951, 0.8371008447853916, 0.8340284967996988, 0.8372229150978916, 0.8385759836219879, 0.8387186441076807, 0.8372229150978916, 0.8380877023719879, 0.8381994775978916, 0.8382200677710843, 0.8383524331701807, 0.8398069818335843, 0.8395422510353916, 0.8389421945594879, 0.8407629541603916, 0.8387892389871988, 0.8397760965737951, 0.8406511789344879, 0.8427675545933735, 0.8405085184487951, 0.8422483880835843, 0.8423704583960843, 0.8399496423192772, 0.8415262612951807, 0.8439882577183735, 0.8437029367469879, 0.8431028802710843, 0.8430925851844879, 0.8437441170933735, 0.8438661874058735, 0.8449442300451807, 0.8438867775790663, 0.8423704583960843, 0.8433470208960843, 0.8432352456701807, 0.8425131188817772, 0.8447206795933735, 0.8448530449924698, 0.8450868905308735, 0.8432558358433735, 0.8447412697665663, 0.8448427499058735, 0.8436117516942772, 0.8453413262424698, 0.8423910485692772, 0.8444559487951807, 0.8434587961219879, 0.8450868905308735, 0.8438661874058735, 0.8443544686558735, 0.8453310311558735, 0.8458296074924698, 0.8442118081701807, 0.8443441735692772, 0.8450868905308735, 0.8457781320594879, 0.8464399590549698, 0.8445780191076807, 0.8448015695594879, 0.8444353586219879, 0.8448015695594879, 0.8438455972326807, 0.8428381494728916, 0.8435808664344879, 0.8449236398719879, 0.8439470773719879, 0.8467855798192772, 0.8469988351844879, 0.8447809793862951, 0.8465414391942772, 0.8457678369728916, 0.8461443429969879, 0.8473856362951807, 0.8455236963478916, 0.8465311441076807, 0.8461237528237951, 0.8473856362951807, 0.8471517907567772, 0.8473753412085843, 0.8470297204442772, 0.8449339349585843, 0.8449133447853916, 0.8451471903237951, 0.8452795557228916, 0.8466429193335843, 0.8460222726844879, 0.8477518472326807, 0.8460428628576807, 0.8452898508094879, 0.8459104974585843, 0.8473547510353916, 0.8473650461219879, 0.8477415521460843, 0.8478739175451807, 0.8477312570594879, 0.8481180581701807, 0.8472532708960843, 0.8480062829442772, 0.8471003153237951, 0.8492578713290663, 0.8465208490210843, 0.8461340479103916, 0.8470297204442772, 0.8483621987951807, 0.8466532144201807, 0.8471414956701807, 0.8472532708960843, 0.8476194818335843, 0.8467649896460843, 0.8465002588478916, 0.8468767648719879, 0.8455236963478916, 0.8479959878576807, 0.8472326807228916, 0.8473753412085843, 0.8468664697853916, 0.8496034920933735, 0.8483519037085843, 0.8462561182228916, 0.8463884836219879, 0.8486063394201807, 0.8486166345067772, 0.8483621987951807, 0.8473753412085843, 0.8481180581701807, 0.8472532708960843, 0.8457781320594879, 0.8468767648719879, 0.8479959878576807, 0.8481283532567772, 0.8486166345067772, 0.8461237528237951, 0.8462561182228916, 0.8483519037085843, 0.8479959878576807, 0.8461340479103916, 0.8478636224585843, 0.8492166909826807, 0.8490740304969879, 0.8486063394201807, 0.8479856927710843, 0.8474871164344879, 0.8473650461219879, 0.8477415521460843, 0.8473753412085843, 0.8490843255835843, 0.8466429193335843, 0.8455545816076807, 0.8463987787085843, 0.8481180581701807, 0.8488401849585843, 0.8474871164344879, 0.8467546945594879, 0.8478430322853916, 0.8472532708960843, 0.8468767648719879, 0.8483416086219879, 0.8486166345067772, 0.8484945641942772, 0.8478842126317772, 0.8491961008094879, 0.8476194818335843, 0.8479856927710843, 0.8495931970067772, 0.8473753412085843, 0.8497152673192772, 0.8469782450112951, 0.8493387612951807, 0.8478533273719879, 0.8480974679969879, 0.8479959878576807, 0.8482401284826807, 0.8493284662085843, 0.8484842691076807, 0.8495829019201807, 0.8500711831701807, 0.8485960443335843, 0.8488401849585843, 0.8486063394201807, 0.8503256188817772, 0.8482195383094879, 0.8481386483433735, 0.8489622552710843, 0.8484842691076807, 0.8487181146460843, 0.8489725503576807, 0.8485960443335843, 0.8489828454442772, 0.8491049157567772, 0.8488710702183735, 0.8476194818335843, 0.8479856927710843, 0.8499594079442772, 0.8499594079442772, 0.8485960443335843, 0.8490843255835843, 0.8495931970067772, 0.8493387612951807, 0.8471312005835843, 0.8482401284826807, 0.8488504800451807, 0.8499697030308735, 0.8492166909826807, 0.8497152673192772, 0.8500917733433735, 0.8486063394201807, 0.8490137307040663, 0.8478636224585843, 0.8484636789344879, 0.8488710702183735, 0.8490946206701807, 0.8493696465549698, 0.8478842126317772, 0.8489931405308735, 0.8500917733433735, 0.8489725503576807, 0.8497255624058735, 0.8489725503576807, 0.8492063958960843, 0.8489622552710843, 0.8492269860692772, 0.8484842691076807, 0.8494814217808735, 0.8492063958960843, 0.8486166345067772, 0.8487387048192772, 0.8493696465549698, 0.8482504235692772, 0.8473856362951807, 0.8479856927710843], "accuracy_test": 0.8410543130990416, "start": "2016-01-23 10:42:42.152000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0], "accuracy_train_last": 0.9404870051218162, "batch_size_eval": 1024, "accuracy_train_std": [0.016989992234555128, 0.021272555775313437, 0.02007000895251704, 0.01834794371665588, 0.018570631353875943, 0.021302393617738807, 0.019468037179366068, 0.019030788484161135, 0.01934475766339214, 0.018061787348151115, 0.017576720883016633, 0.01758055804556199, 0.016094848024863988, 0.01726255367993823, 0.016066572819423832, 0.015797493843484472, 0.016926390959369327, 0.01561221899528701, 0.015417109669344306, 0.014742177871578726, 0.01492121066110638, 0.015276354109221794, 0.015614056723837524, 0.015318234482318952, 0.015251455626763881, 0.015061937382452303, 0.014495918401021634, 0.014441259162222837, 0.014901289357797227, 0.014661306297916425, 0.014488157774429269, 0.01364424787505902, 0.013581831350414611, 0.014032251714123579, 0.013036814302500442, 0.014286406451603612, 0.013620479385432895, 0.012883315613162132, 0.013147352598720487, 0.013207753187245526, 0.01397226881386091, 0.013067572103009273, 0.013773915023010886, 0.013522877231773764, 0.012872155317148139, 0.013034298105404261, 0.013051844643045247, 0.012642471108556506, 0.012339960477681067, 0.012684905344856367, 0.012537322739215108, 0.013012525872955219, 0.012672448962117975, 0.012603273510881752, 0.011691203876692783, 0.012280834679821762, 0.012111285289051636, 0.011942754976141627, 0.011724735627014886, 0.012368060386190954, 0.011833573486461718, 0.0119631671774231, 0.012275997406865718, 0.012040417775323982, 0.011625146824912416, 0.011610833274622144, 0.011773010106125789, 0.01149842846907312, 0.01153732089166923, 0.011304658648791953, 0.011276921575208916, 0.011794833457781524, 0.011302199010630346, 0.011528899657889526, 0.010920623972009835, 0.011085552901580822, 0.011161546528585477, 0.0106759862035285, 0.010614995495334394, 0.011208814414915788, 0.01133409370137645, 0.010824724584222357, 0.010588928746274848, 0.01045171355225772, 0.011069721445427705, 0.010645988905625004, 0.010880068868865023, 0.010184857635941182, 0.010418444435569432, 0.010530788152124958, 0.010807796676277157, 0.010195442424988592, 0.011362307918671405, 0.010871805983264605, 0.0100812233316765, 0.010397178006793519, 0.010031018326239831, 0.010241559181828562, 0.010460829337729249, 0.010111041071808784, 0.010041678496299477, 0.010324644167785816, 0.009987786294671272, 0.009583531604094872, 0.010314510969643052, 0.009905717933509129, 0.010097362844915405, 0.0092044945259513, 0.009961496896094761, 0.009915283613897746, 0.009999621918910509, 0.009442335518866356, 0.010410973836440001, 0.009514465559640528, 0.010000521465974384, 0.009723755440857821, 0.009635213616542605, 0.008709809954740484, 0.009237333732377487, 0.010030412135885214, 0.009550615233419633, 0.008801859439407825, 0.009775612235723631, 0.009213747988128717, 0.009660146729670182, 0.010105756284482178, 0.009078374409119953, 0.009124385831663426, 0.009334010061603048, 0.00937073532603804, 0.009665842434426874, 0.00962009294219656, 0.009146676599435249, 0.008638442682665686, 0.008995950652311391, 0.00809162445629565, 0.00969054936009647, 0.008979904824119086, 0.008655087369732315, 0.008907490009115933, 0.009321925729546609, 0.009300154162304775, 0.009196384950771274, 0.00870025834387498, 0.008624176214788469, 0.00885298749312833, 0.009237636796481114, 0.008521222620863427, 0.008649388013683368, 0.008851003026921312, 0.008784035119613674, 0.009090909682820905, 0.008415747666190894, 0.008676276295310958, 0.009059111404120189, 0.00840361757196032, 0.008376497078335937, 0.00884750296244726, 0.008775056761077182, 0.00817605247023086, 0.00854300258548276, 0.008624604277810104, 0.008071771891272833, 0.008543089617535906, 0.008540283212381357, 0.00808269217492343, 0.008399015016032359, 0.008524012888850975, 0.008280798275985018, 0.00859054299510751, 0.008576743563684914, 0.008593183594860877, 0.008469378885244907, 0.008631165318236093, 0.0079677185601055, 0.008137034513012363, 0.00809821903072099, 0.008657690243385715, 0.008101597009969992, 0.008299835479199824, 0.007961622845763601, 0.00786879027653746, 0.008777632653899635, 0.008522885184720034, 0.007879600916564693, 0.008289978807963873, 0.008069460134614114, 0.008622116146267716, 0.007753120067301479, 0.008357256920679, 0.009162459581053037, 0.008366294442107586, 0.00860126896053245, 0.008508234580375331, 0.007997352072023279, 0.007772024181659994, 0.008515164168857479, 0.00843461765046634, 0.008215861551719874, 0.008279403336444833, 0.008456038834065094, 0.00855416203657732, 0.008305261450869844, 0.008868286977301139, 0.008343344834148407, 0.008151564623592292, 0.007841639521668154, 0.008489265641360167, 0.008127461653412372, 0.008230360474094244, 0.008538702926802446, 0.00852557350792843, 0.008220302336732457, 0.008591189708282664, 0.008197663959030477, 0.008533768697527788, 0.007867805964137832, 0.008035196979058135, 0.00804200282854794, 0.008160285473219602, 0.007921890585855549, 0.008023882203214908, 0.007900422544140907, 0.008441313420469339, 0.008275709356993887, 0.007739520426135084, 0.008455032536535881, 0.008536826080458845, 0.008195850147590663, 0.008578891691207123, 0.008069614499392544, 0.008350642852667204, 0.007814047675806284, 0.008004937000523824, 0.00784488437708485, 0.007646048396592709, 0.007877609334064837, 0.007976477559037834, 0.00794862329133245, 0.007545442667795168, 0.008004050705724823, 0.007928155823435477, 0.007983441755267863, 0.008529168472623498, 0.008205063740977445, 0.007965137249832808, 0.007917765022916853, 0.007595616284384573, 0.00787565597454587, 0.007821543639553737, 0.00777814622221074, 0.007558074854724359, 0.007575241372874154, 0.008077054634046803, 0.007989220842638343, 0.007591179958741082, 0.007495726730144704, 0.008146542992628743, 0.008003468440256362, 0.007898407559116012, 0.007972178116312886], "accuracy_test_std": 0.06662390452323505, "error_valid": [0.6285665121423193, 0.5277011365775602, 0.38262424698795183, 0.33471973832831325, 0.2917495176016567, 0.26078336784638556, 0.2412815323795181, 0.2381077042545181, 0.2187691194465362, 0.21092573418674698, 0.20848432793674698, 0.19926728397966864, 0.1930314029555723, 0.19411974068147586, 0.1898266895707832, 0.1885353915662651, 0.18669404179216864, 0.18362169380647586, 0.18165827371987953, 0.1840187900037651, 0.1784741505082832, 0.17776231880647586, 0.1752091373305723, 0.17323542215737953, 0.1738354786332832, 0.1716176228350903, 0.1707631306475903, 0.17028514448418675, 0.17014248399849397, 0.16694806570030118, 0.16596120811370485, 0.16205495811370485, 0.1628991552146084, 0.16597150320030118, 0.1627770849021084, 0.16142401637801207, 0.1612813558923193, 0.1627770849021084, 0.16191229762801207, 0.1618005224021084, 0.16177993222891573, 0.1616475668298193, 0.16019301816641573, 0.1604577489646084, 0.16105780544051207, 0.1592370458396084, 0.16121076101280118, 0.16022390342620485, 0.15934882106551207, 0.1572324454066265, 0.15949148155120485, 0.15775161191641573, 0.15762954160391573, 0.16005035768072284, 0.1584737387048193, 0.1560117422816265, 0.15629706325301207, 0.15689711972891573, 0.15690741481551207, 0.1562558829066265, 0.1561338125941265, 0.1550557699548193, 0.15611322242093373, 0.15762954160391573, 0.15665297910391573, 0.1567647543298193, 0.15748688111822284, 0.1552793204066265, 0.15514695500753017, 0.1549131094691265, 0.1567441641566265, 0.15525873023343373, 0.1551572500941265, 0.15638824830572284, 0.15465867375753017, 0.15760895143072284, 0.1555440512048193, 0.15654120387801207, 0.1549131094691265, 0.1561338125941265, 0.1556455313441265, 0.1546689688441265, 0.15417039250753017, 0.1557881918298193, 0.15565582643072284, 0.1549131094691265, 0.15422186794051207, 0.15356004094503017, 0.1554219808923193, 0.15519843044051207, 0.15556464137801207, 0.15519843044051207, 0.1561544027673193, 0.1571618505271084, 0.15641913356551207, 0.15507636012801207, 0.15605292262801207, 0.15321442018072284, 0.15300116481551207, 0.15521902061370485, 0.15345856080572284, 0.1542321630271084, 0.15385565700301207, 0.1526143637048193, 0.1544763036521084, 0.1534688558923193, 0.15387624717620485, 0.1526143637048193, 0.15284820924322284, 0.15262465879141573, 0.15297027955572284, 0.15506606504141573, 0.1550866552146084, 0.15485280967620485, 0.1547204442771084, 0.15335708066641573, 0.15397772731551207, 0.1522481527673193, 0.1539571371423193, 0.15471014919051207, 0.15408950254141573, 0.1526452489646084, 0.15263495387801207, 0.15225844785391573, 0.1521260824548193, 0.15226874294051207, 0.1518819418298193, 0.15274672910391573, 0.15199371705572284, 0.15289968467620485, 0.15074212867093373, 0.15347915097891573, 0.1538659520896084, 0.15297027955572284, 0.1516378012048193, 0.1533467855798193, 0.1528585043298193, 0.15274672910391573, 0.15238051816641573, 0.15323501035391573, 0.1534997411521084, 0.15312323512801207, 0.1544763036521084, 0.1520040121423193, 0.1527673192771084, 0.15262465879141573, 0.1531335302146084, 0.1503965079066265, 0.15164809629141573, 0.1537438817771084, 0.15361151637801207, 0.1513936605798193, 0.15138336549322284, 0.1516378012048193, 0.15262465879141573, 0.1518819418298193, 0.15274672910391573, 0.15422186794051207, 0.15312323512801207, 0.1520040121423193, 0.15187164674322284, 0.15138336549322284, 0.15387624717620485, 0.1537438817771084, 0.15164809629141573, 0.1520040121423193, 0.1538659520896084, 0.15213637754141573, 0.1507833090173193, 0.15092596950301207, 0.1513936605798193, 0.15201430722891573, 0.15251288356551207, 0.15263495387801207, 0.15225844785391573, 0.15262465879141573, 0.15091567441641573, 0.15335708066641573, 0.1544454183923193, 0.15360122129141573, 0.1518819418298193, 0.15115981504141573, 0.15251288356551207, 0.15324530544051207, 0.1521569677146084, 0.15274672910391573, 0.15312323512801207, 0.15165839137801207, 0.15138336549322284, 0.15150543580572284, 0.15211578736822284, 0.15080389919051207, 0.15238051816641573, 0.15201430722891573, 0.15040680299322284, 0.15262465879141573, 0.15028473268072284, 0.15302175498870485, 0.1506612387048193, 0.15214667262801207, 0.15190253200301207, 0.1520040121423193, 0.1517598715173193, 0.15067153379141573, 0.1515157308923193, 0.1504170980798193, 0.1499288168298193, 0.15140395566641573, 0.15115981504141573, 0.1513936605798193, 0.14967438111822284, 0.15178046169051207, 0.1518613516566265, 0.15103774472891573, 0.1515157308923193, 0.15128188535391573, 0.1510274496423193, 0.15140395566641573, 0.15101715455572284, 0.15089508424322284, 0.1511289297816265, 0.15238051816641573, 0.15201430722891573, 0.15004059205572284, 0.15004059205572284, 0.15140395566641573, 0.15091567441641573, 0.15040680299322284, 0.1506612387048193, 0.15286879941641573, 0.1517598715173193, 0.1511495199548193, 0.1500302969691265, 0.1507833090173193, 0.15028473268072284, 0.1499082266566265, 0.1513936605798193, 0.15098626929593373, 0.15213637754141573, 0.15153632106551207, 0.1511289297816265, 0.1509053793298193, 0.15063035344503017, 0.15211578736822284, 0.1510068594691265, 0.1499082266566265, 0.1510274496423193, 0.1502744375941265, 0.1510274496423193, 0.15079360410391573, 0.15103774472891573, 0.15077301393072284, 0.1515157308923193, 0.1505185782191265, 0.15079360410391573, 0.15138336549322284, 0.15126129518072284, 0.15063035344503017, 0.15174957643072284, 0.1526143637048193, 0.15201430722891573], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.8010971321799796, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.007366669123230858, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "optimization": "rmsprop", "nb_data_augmentation": 4, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.3843778149614887e-10, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.06322516099261893}, "accuracy_valid_max": 0.8503256188817772, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8479856927710843, "loss_train": [1.6679761409759521, 1.3156516551971436, 1.0736994743347168, 0.9498929381370544, 0.86270672082901, 0.7983695864677429, 0.7464502453804016, 0.7066625356674194, 0.674720823764801, 0.6474860310554504, 0.626446545124054, 0.6059590578079224, 0.5898073315620422, 0.5740367770195007, 0.561815083026886, 0.5487606525421143, 0.5378017425537109, 0.5265858769416809, 0.5177276730537415, 0.5104421973228455, 0.5023263096809387, 0.49402695894241333, 0.48667338490486145, 0.48121893405914307, 0.4753402769565582, 0.47021934390068054, 0.46350494027137756, 0.4578518569469452, 0.4535400867462158, 0.44952553510665894, 0.44274213910102844, 0.4406059980392456, 0.43561649322509766, 0.43255096673965454, 0.42691296339035034, 0.42674678564071655, 0.42088043689727783, 0.41911405324935913, 0.41552799940109253, 0.4132120907306671, 0.41125065088272095, 0.40636250376701355, 0.40357762575149536, 0.4024757444858551, 0.40052473545074463, 0.3957113027572632, 0.39469268918037415, 0.3918260931968689, 0.3914669156074524, 0.38660916686058044, 0.38563597202301025, 0.3834303617477417, 0.38008391857147217, 0.3793945908546448, 0.3764619529247284, 0.375592976808548, 0.3746825158596039, 0.37159764766693115, 0.3714682161808014, 0.3683858811855316, 0.3667719066143036, 0.3640964925289154, 0.3641197979450226, 0.3619316518306732, 0.358918696641922, 0.3596365451812744, 0.35685861110687256, 0.3549697995185852, 0.3563404083251953, 0.3531735837459564, 0.3511255085468292, 0.3502577543258667, 0.3476947844028473, 0.3486495018005371, 0.34660831093788147, 0.3464333415031433, 0.34443235397338867, 0.34267163276672363, 0.34236782789230347, 0.3409326374530792, 0.34060224890708923, 0.33885422348976135, 0.3375668525695801, 0.33705398440361023, 0.3344569504261017, 0.3334941267967224, 0.3344722092151642, 0.3319297432899475, 0.33177611231803894, 0.329368531703949, 0.32980361580848694, 0.32770660519599915, 0.3270202875137329, 0.32551008462905884, 0.32545360922813416, 0.32446953654289246, 0.32484710216522217, 0.3228684365749359, 0.32225656509399414, 0.3223661780357361, 0.3212345540523529, 0.32018396258354187, 0.319355309009552, 0.31988635659217834, 0.3168797791004181, 0.3162248432636261, 0.3166590631008148, 0.3148328363895416, 0.3142530918121338, 0.3126641511917114, 0.31413528323173523, 0.3121294379234314, 0.311343789100647, 0.3102184236049652, 0.31085458397865295, 0.3097233474254608, 0.3087291419506073, 0.30801889300346375, 0.3066890239715576, 0.30616679787635803, 0.30479368567466736, 0.3053014874458313, 0.30303293466567993, 0.3050566017627716, 0.3025680184364319, 0.30272242426872253, 0.3020572364330292, 0.30212166905403137, 0.30133360624313354, 0.30037879943847656, 0.3007420003414154, 0.2967368960380554, 0.2971950173377991, 0.29850977659225464, 0.29834794998168945, 0.29636216163635254, 0.29682016372680664, 0.2948913872241974, 0.2958603799343109, 0.2929423153400421, 0.2946321368217468, 0.2945259213447571, 0.2935401201248169, 0.29258477687835693, 0.2923629581928253, 0.2916722297668457, 0.29141220450401306, 0.2887321412563324, 0.289185106754303, 0.2899632751941681, 0.290990948677063, 0.28749382495880127, 0.2876057028770447, 0.28821709752082825, 0.2868331968784332, 0.28465962409973145, 0.2859621047973633, 0.28503358364105225, 0.286565899848938, 0.2843038737773895, 0.28328782320022583, 0.2840966582298279, 0.2839120924472809, 0.284268319606781, 0.281449556350708, 0.2829599976539612, 0.28052982687950134, 0.28076568245887756, 0.27993670105934143, 0.2811208963394165, 0.2790786027908325, 0.2798258066177368, 0.27913346886634827, 0.2779636085033417, 0.27759280800819397, 0.27794763445854187, 0.2772829830646515, 0.277407705783844, 0.2767178416252136, 0.2751919627189636, 0.27720504999160767, 0.27668142318725586, 0.27577969431877136, 0.275560587644577, 0.27457135915756226, 0.2738112509250641, 0.2736565172672272, 0.27543726563453674, 0.2743702530860901, 0.273365318775177, 0.2734387516975403, 0.2712518870830536, 0.2720426321029663, 0.2713814675807953, 0.2712857127189636, 0.2713821828365326, 0.2709881067276001, 0.2701953649520874, 0.26974213123321533, 0.27028799057006836, 0.2699642777442932, 0.26675063371658325, 0.2691715955734253, 0.26830407977104187, 0.26760587096214294, 0.2671434283256531, 0.26627492904663086, 0.26665112376213074, 0.2672151029109955, 0.26603594422340393, 0.2663278579711914, 0.26408955454826355, 0.26487448811531067, 0.2658763825893402, 0.26493412256240845, 0.263455867767334, 0.26358485221862793, 0.2639842629432678, 0.26408201456069946, 0.26438239216804504, 0.26204296946525574, 0.26174724102020264, 0.2635672092437744, 0.26133477687835693, 0.2607571482658386, 0.26036086678504944, 0.26060712337493896, 0.2614006996154785, 0.25988447666168213, 0.2614041864871979, 0.2592271566390991, 0.2586064040660858, 0.25935786962509155, 0.258128821849823, 0.25845178961753845, 0.25911518931388855, 0.25954023003578186, 0.2568330764770508, 0.25705528259277344, 0.2575841546058655, 0.25764262676239014, 0.2577703297138214, 0.2556562125682831, 0.25548210740089417, 0.2571093738079071, 0.2574043571949005, 0.25531572103500366, 0.25540727376937866, 0.2562618553638458, 0.2537133991718292, 0.255010724067688, 0.25417137145996094, 0.25563859939575195, 0.2541612684726715, 0.2531478703022003, 0.25295916199684143, 0.25431305170059204, 0.2539525032043457, 0.2531697452068329, 0.2522887885570526, 0.2521895170211792], "accuracy_train_first": 0.3774361791712809, "model": "residualv3", "loss_std": [0.3013629615306854, 0.2048676311969757, 0.1955726444721222, 0.18979617953300476, 0.18448762595653534, 0.1817324459552765, 0.17759932577610016, 0.17474284768104553, 0.17162887752056122, 0.1698928028345108, 0.16884221136569977, 0.16564558446407318, 0.16358721256256104, 0.16208265721797943, 0.1604873687028885, 0.1576387733221054, 0.15676695108413696, 0.15587037801742554, 0.15510007739067078, 0.1536615639925003, 0.1542729288339615, 0.15170349180698395, 0.15173527598381042, 0.149168461561203, 0.14894428849220276, 0.149351567029953, 0.14756274223327637, 0.14652352035045624, 0.14625895023345947, 0.14596432447433472, 0.14518243074417114, 0.14385022222995758, 0.14240053296089172, 0.1428736448287964, 0.14247871935367584, 0.14171120524406433, 0.14084458351135254, 0.14123450219631195, 0.1387311816215515, 0.13841260969638824, 0.1405685693025589, 0.13870610296726227, 0.13717356324195862, 0.13790461421012878, 0.13642460107803345, 0.13596391677856445, 0.13357989490032196, 0.1346493363380432, 0.13518984615802765, 0.1337904930114746, 0.13357779383659363, 0.1340567171573639, 0.13423587381839752, 0.13227853178977966, 0.1324172466993332, 0.1321517378091812, 0.13069385290145874, 0.13125818967819214, 0.13299404084682465, 0.13048282265663147, 0.1306380033493042, 0.12938405573368073, 0.12990878522396088, 0.1298459768295288, 0.1286786049604416, 0.12792925536632538, 0.12700903415679932, 0.1283593475818634, 0.12844419479370117, 0.12730614840984344, 0.1273614764213562, 0.12636974453926086, 0.12749958038330078, 0.12725929915905, 0.12599705159664154, 0.12588414549827576, 0.12456587702035904, 0.12552431225776672, 0.12530528008937836, 0.12381164729595184, 0.12546108663082123, 0.12465129792690277, 0.12425552308559418, 0.12527790665626526, 0.12420050799846649, 0.12368141114711761, 0.12352931499481201, 0.1233140230178833, 0.12310653179883957, 0.12262900918722153, 0.1219378188252449, 0.12322135269641876, 0.12285710126161575, 0.12130036950111389, 0.1221366599202156, 0.12320858985185623, 0.12129105627536774, 0.11928155273199081, 0.12174157798290253, 0.12266290187835693, 0.12280191481113434, 0.1214108094573021, 0.12097928673028946, 0.12208154797554016, 0.12052247673273087, 0.12075796723365784, 0.12066835165023804, 0.1196560338139534, 0.1194882020354271, 0.11808699369430542, 0.11897041648626328, 0.11888584494590759, 0.11818365007638931, 0.12064395844936371, 0.11948401480913162, 0.11819188296794891, 0.11853387206792831, 0.11851385980844498, 0.1179608479142189, 0.11854550242424011, 0.1185370683670044, 0.11672467738389969, 0.11778257042169571, 0.1169871985912323, 0.11711610108613968, 0.1160711795091629, 0.11729007959365845, 0.11551769822835922, 0.11571313440799713, 0.1168251782655716, 0.11623381823301315, 0.11543437838554382, 0.11361578106880188, 0.11591891944408417, 0.11615066230297089, 0.11606026440858841, 0.1152271255850792, 0.11481912434101105, 0.11545205861330032, 0.11396036297082901, 0.11565715819597244, 0.11420562118291855, 0.11547967791557312, 0.11427309364080429, 0.11570971459150314, 0.1133091077208519, 0.11485839635133743, 0.11425706744194031, 0.11348769813776016, 0.11316699534654617, 0.11544928699731827, 0.11350584030151367, 0.11347522586584091, 0.11374785006046295, 0.1142352744936943, 0.11150121688842773, 0.11277603358030319, 0.11349222809076309, 0.11305925250053406, 0.11231069266796112, 0.11070064455270767, 0.1128963828086853, 0.11121808737516403, 0.11200693994760513, 0.11246927082538605, 0.11277325451374054, 0.11116430908441544, 0.11137543618679047, 0.11106998473405838, 0.1121291071176529, 0.11052297800779343, 0.11108408868312836, 0.11127220094203949, 0.11075519770383835, 0.11280392110347748, 0.11215456575155258, 0.1114058643579483, 0.11219902336597443, 0.11109510064125061, 0.10957232862710953, 0.11111146956682205, 0.11161340028047562, 0.11054041236639023, 0.11073838919401169, 0.11078815162181854, 0.10887563973665237, 0.10921382158994675, 0.11237452924251556, 0.10963916033506393, 0.10924455523490906, 0.10908406227827072, 0.11064413189888, 0.11015813797712326, 0.10971586406230927, 0.11000233143568039, 0.10732315480709076, 0.11051356792449951, 0.1102033257484436, 0.10996244102716446, 0.10952526330947876, 0.10891684889793396, 0.10824934393167496, 0.10927679389715195, 0.1081143245100975, 0.10920523852109909, 0.10813400149345398, 0.10858987271785736, 0.10907047986984253, 0.10861999541521072, 0.10709673166275024, 0.11054746806621552, 0.10882864892482758, 0.10737069696187973, 0.10725253820419312, 0.10782414674758911, 0.10768494755029678, 0.10867530107498169, 0.10652565211057663, 0.10794112086296082, 0.10786831378936768, 0.10762420296669006, 0.10653452575206757, 0.10783298313617706, 0.10602695494890213, 0.10664190351963043, 0.10823749005794525, 0.10670056194067001, 0.10796115547418594, 0.10559356957674026, 0.1073494702577591, 0.10740836709737778, 0.10657575726509094, 0.10623324662446976, 0.107939712703228, 0.10649226605892181, 0.10539349168539047, 0.10680408775806427, 0.10548008978366852, 0.1070113331079483, 0.10840535908937454, 0.10582377016544342, 0.10604150593280792, 0.10712652653455734, 0.10424792021512985, 0.1059536263346672, 0.10577139258384705, 0.105576291680336, 0.10586094111204147, 0.10663832724094391, 0.10528723150491714, 0.10696235299110413, 0.10535845160484314, 0.10662813484668732, 0.10470467805862427, 0.10321593284606934, 0.10528234392404556, 0.10502540320158005, 0.10478959232568741, 0.10553853213787079, 0.10490472614765167, 0.10617998987436295]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:12 2016", "state": "available"}], "summary": "e70c19ce6cfcb21ea3dda6f0db4a9930"}