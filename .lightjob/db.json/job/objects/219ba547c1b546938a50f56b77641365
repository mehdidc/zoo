{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [2.0832507610321045, 1.7889496088027954, 1.6978709697723389, 1.6527634859085083, 1.6175769567489624, 1.587775707244873, 1.5607155561447144, 1.5355075597763062, 1.513119101524353, 1.4893652200698853, 1.4670027494430542, 1.4463285207748413, 1.4270408153533936, 1.4109169244766235, 1.3912832736968994, 1.3772064447402954, 1.3643872737884521, 1.3505892753601074, 1.3387709856033325, 1.326418161392212, 1.3134032487869263, 1.303268551826477, 1.2911274433135986, 1.2804840803146362, 1.269888162612915, 1.2610317468643188, 1.250943899154663, 1.2413341999053955, 1.2318956851959229, 1.2238155603408813, 1.21480393409729, 1.2059205770492554, 1.1972471475601196, 1.1891957521438599, 1.1810678243637085, 1.173548936843872, 1.1639777421951294, 1.1565791368484497, 1.1489149332046509, 1.1427210569381714, 1.1350619792938232, 1.1257364749908447, 1.1210259199142456, 1.112675666809082, 1.1055283546447754, 1.0973719358444214, 1.0919392108917236, 1.0845422744750977, 1.0794733762741089, 1.0719996690750122, 1.0656646490097046, 1.059809684753418, 1.0527067184448242, 1.0482597351074219, 1.041109323501587, 1.037056565284729, 1.030040979385376, 1.0231820344924927, 1.0183225870132446, 1.0138194561004639, 1.0072641372680664, 1.0015652179718018, 0.9955961108207703, 0.9905032515525818, 0.9876846671104431, 0.9810059666633606, 0.977849543094635, 0.9720240235328674, 0.9656788110733032, 0.9614408016204834, 0.9559914469718933, 0.9505658149719238, 0.9462814331054688, 0.9414398074150085, 0.9359331727027893, 0.9312258362770081, 0.9284878969192505, 0.9243677258491516, 0.918146550655365, 0.9133957028388977, 0.9113321304321289, 0.9061726331710815, 0.899810254573822, 0.8984608054161072, 0.8929888606071472, 0.8891775012016296, 0.8830978870391846, 0.880013108253479, 0.8760262131690979, 0.8739290237426758, 0.868069052696228, 0.8628809452056885, 0.8584886193275452, 0.8569174408912659, 0.8542006611824036, 0.8466193079948425, 0.8459269404411316, 0.8401760458946228, 0.8379316926002502, 0.8333102464675903, 0.829308032989502, 0.8278554677963257, 0.8209323883056641, 0.8215128779411316, 0.8134663105010986, 0.8105587959289551, 0.8064457774162292, 0.8058531880378723, 0.7995584607124329, 0.7981875538825989, 0.7959359288215637, 0.7922313809394836, 0.7874057292938232, 0.7832370400428772, 0.7805094122886658, 0.7795678377151489, 0.775263786315918, 0.7714775800704956, 0.7684720158576965, 0.7659786343574524, 0.7609911561012268, 0.7591400742530823, 0.7543672919273376, 0.7525238990783691, 0.7506394386291504, 0.7467371225357056, 0.7444308400154114, 0.7416035532951355, 0.7375888228416443, 0.7339420914649963, 0.7306852340698242, 0.7165676951408386, 0.7132385969161987, 0.7121908068656921, 0.7138146758079529, 0.7136988639831543, 0.7133675813674927, 0.7104984521865845, 0.7098572254180908, 0.7102324962615967, 0.7099000811576843, 0.7090129256248474, 0.7107235193252563, 0.7089648246765137, 0.7087454795837402, 0.7085152864456177, 0.7097302079200745, 0.7066977024078369, 0.7069395780563354, 0.705173134803772, 0.7050954699516296, 0.708276629447937, 0.7047156691551208, 0.7065410614013672, 0.7065712809562683, 0.7060750126838684, 0.7056107521057129, 0.7055691480636597, 0.7052801847457886, 0.7058362364768982, 0.7051559090614319, 0.7048318386077881, 0.7050669193267822, 0.7067146301269531, 0.7046740651130676, 0.705578088760376, 0.7036290168762207, 0.7036967873573303, 0.7046722173690796, 0.7054135203361511, 0.7073671221733093, 0.7046219706535339, 0.7065480947494507, 0.7064628005027771, 0.7040166854858398, 0.7047212719917297, 0.7068257927894592, 0.705721914768219, 0.7057821750640869, 0.7073178887367249, 0.7068402767181396, 0.7048828601837158, 0.7052692770957947, 0.7041627764701843, 0.7060204744338989, 0.7051766514778137, 0.7052058577537537, 0.7056961059570312, 0.7051069736480713, 0.7051852941513062, 0.7044525146484375, 0.7069978713989258, 0.7045996785163879, 0.7083223462104797, 0.7044881582260132, 0.706307590007782, 0.7065756320953369, 0.705970823764801, 0.7050605416297913, 0.7069304585456848, 0.7055413126945496, 0.7054527401924133, 0.7047374248504639, 0.7049480080604553, 0.7047133445739746, 0.704646110534668, 0.705829381942749, 0.7052835822105408, 0.7052205801010132, 0.7044472694396973, 0.7046605944633484, 0.7054393887519836, 0.706313967704773, 0.7040043473243713, 0.7061578631401062, 0.7052960991859436, 0.7065514922142029, 0.7064803838729858, 0.705757737159729, 0.7058267593383789, 0.7050855755805969, 0.7055764198303223], "moving_avg_accuracy_train": [0.03373149253645256, 0.06830940412744553, 0.10188430492109632, 0.1335990033222591, 0.1635648264177279, 0.19158489027027958, 0.21811443981260378, 0.24289279560178453, 0.2664391990369457, 0.2884354275678672, 0.3086085271087457, 0.327371180534822, 0.34534555801705413, 0.3613922173200922, 0.3764177869951981, 0.38948325007077983, 0.4022648718268063, 0.41564901630594736, 0.4269763835014877, 0.43753144809176897, 0.44901145622763633, 0.4573767120964286, 0.46692799740325863, 0.47482650139009225, 0.48244894076750977, 0.49031356444408103, 0.49702191894582465, 0.5048447196972832, 0.5102533824463164, 0.5154999618834861, 0.522279423780455, 0.526939671665191, 0.532537816007762, 0.5387524909696011, 0.5425047934080323, 0.5481180098786447, 0.552253868168881, 0.5564085101622088, 0.5600988958800227, 0.5654217635652301, 0.5711097437759367, 0.5754779389489153, 0.5787677537772611, 0.5827048972810411, 0.5854182483094431, 0.5896134624862046, 0.5941399980666724, 0.5972280890914928, 0.6009418284935285, 0.6041029044458552, 0.6074987528267127, 0.6097203960933216, 0.6129474094094232, 0.6161609661855812, 0.6189971474197824, 0.6216498000758293, 0.6252298446102822, 0.6282332125567383, 0.6302109775240711, 0.6338859262256138, 0.6372767609747763, 0.6393568523883728, 0.6417936934795927, 0.6444217614355279, 0.6477263466660984, 0.6502143370283275, 0.6529232805114952, 0.65416391405826, 0.6566894162824636, 0.6597412570866185, 0.6617113501567957, 0.6634681939271073, 0.6660489510155705, 0.6682811318357097, 0.6702108592702174, 0.6720708107993603, 0.6743700159124383, 0.6771415675523222, 0.6785921524568354, 0.6809228892518033, 0.6823462952613314, 0.684475859741289, 0.6866063814637271, 0.6878984220329782, 0.6892890510310001, 0.6912777613994763, 0.6932093266620296, 0.6957009394173382, 0.6966019963269332, 0.6986776843026747, 0.7004179923939559, 0.7026467207939106, 0.7042549038098037, 0.706179068225335, 0.707617739302857, 0.7092357389571504, 0.7111174769269761, 0.7117460147986012, 0.7137299675592358, 0.7155970494474152, 0.7171587684598535, 0.7180319285913044, 0.7196336115512031, 0.7209614462651766, 0.7227374602707649, 0.724445154869842, 0.7256963390471711, 0.7271221327102835, 0.7274755398250063, 0.7291651916841446, 0.7309255489288439, 0.7329164831001899, 0.7347664525746394, 0.7363941145742352, 0.7383100171452817, 0.7399160352604877, 0.7412170760450701, 0.7426414900202513, 0.744125714495524, 0.7451732701685261, 0.7466716005956104, 0.7478365554193089, 0.7498406509213518, 0.7516485906338031, 0.7532804227214471, 0.7540958489801256, 0.7557781770343095, 0.757376229981949, 0.7586330078812255, 0.7599175678120029, 0.7608154720853891, 0.7636022515195228, 0.7661663007769466, 0.7685321459265038, 0.7706451305194384, 0.7725746102923376, 0.774285601499861, 0.7758464559747364, 0.7773047394735623, 0.7785892567879724, 0.7797360217757033, 0.7808052765967949, 0.781783881977444, 0.7826761083688007, 0.7835047969043829, 0.7842157754030826, 0.7848881360376083, 0.7855049224015478, 0.7860577770779212, 0.7865948017187818, 0.7870711124003089, 0.7875927619172456, 0.787985552620593, 0.7883506899976533, 0.7887071433250844, 0.7890210479709813, 0.7893244524427554, 0.7895882879697516, 0.7898326793416579, 0.790017718295412, 0.7902144802883145, 0.7903590500474121, 0.7905310155091715, 0.7907020244176027, 0.7908140437078008, 0.7909102828689976, 0.791020113553351, 0.7910376170097545, 0.7910906085502888, 0.7911266751927221, 0.791221806042313, 0.7912795580700491, 0.7912827067700117, 0.7913809077499873, 0.7914506874414892, 0.7914367592531264, 0.7914753771574096, 0.7914775811879311, 0.7915097557011055, 0.7915224367212959, 0.7915850389620953, 0.7916041425490438, 0.7916214078749348, 0.7916253209241892, 0.79162648147089, 0.791669378641492, 0.7916940352021766, 0.791672048279412, 0.7917081357179898, 0.7917661550007958, 0.7917531600421983, 0.7917554875699553, 0.7917714250913374, 0.7917579752213232, 0.7917411839918727, 0.7917214936853857, 0.7916897854678715, 0.7917286413387661, 0.7917427213321043, 0.7917158657963469, 0.7916684803748887, 0.791676950720567, 0.7917054643221445, 0.7917358489588208, 0.7917003800651534, 0.7916987210441955, 0.7916855300836483, 0.7917201611953463, 0.7917281498054167, 0.7916701993389947, 0.7916808229370721, 0.7916764332824845, 0.7917422370576414, 0.7917875095624254, 0.7917818239381781, 0.7917534193394415, 0.7917557209374742, 0.7917438054340276, 0.791798221696411, 0.7918216196956515, 0.7918845305735391, 0.7918992255874292], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.034259400884789154, 0.06992405167545179, 0.10493265836784636, 0.1377252311982304, 0.16858646772637423, 0.19779495080125184, 0.225073414117211, 0.25054161746264353, 0.2747285607615599, 0.296959647409425, 0.3171813219757114, 0.33560555611850174, 0.3528678720710341, 0.36830938870429214, 0.3830358022905647, 0.3956740754124119, 0.40827746041635143, 0.42182600861417413, 0.4327897332892778, 0.4430437395348982, 0.4546069766506855, 0.46230790007936695, 0.47178705924311704, 0.4792877643221939, 0.4865531532231823, 0.4938672232547798, 0.49995645748991924, 0.5074103364020719, 0.5123782224248918, 0.5169703606492702, 0.5229558123478973, 0.5273020326944329, 0.5326968588395227, 0.5384697887311728, 0.5418780515278597, 0.547434839983884, 0.5513534947750287, 0.5552119329481282, 0.5590792703385563, 0.5643848986981495, 0.569817084891964, 0.574468088893355, 0.5778045007777394, 0.5818347211160046, 0.5847162610055336, 0.5886555088695887, 0.5926127824837594, 0.5957013430437419, 0.5990924286188858, 0.6022044112841056, 0.6049410720005746, 0.6070632992790563, 0.609727051241211, 0.6127186015764272, 0.6152990745795526, 0.617830049322275, 0.6211353762330446, 0.6238701478623757, 0.6258756641378851, 0.62935108012244, 0.6323558546873798, 0.6344375932020755, 0.6364280806345035, 0.6390690110405561, 0.6419931057949342, 0.6441863674575342, 0.6464207686447627, 0.6470308625728317, 0.6493327591374611, 0.651818475599468, 0.6536446993874128, 0.6549556224268341, 0.6571049561743616, 0.6587666838249977, 0.6604881423250281, 0.661965242296215, 0.6640483796818043, 0.6663382423913347, 0.6679801088054391, 0.6698066449410849, 0.6708565009665548, 0.6728124959659083, 0.6746430451268477, 0.675903002897672, 0.6773309631500735, 0.6788540909502769, 0.6805240517724178, 0.6825579488353869, 0.6833682131103572, 0.6849620911592613, 0.6862846591047056, 0.6880853218181056, 0.6891566018539155, 0.6906609517871234, 0.6916761583779893, 0.6927363286847688, 0.6939009429454335, 0.6941119581670798, 0.6957942182050405, 0.6973916424406359, 0.6982291207041025, 0.6989249045109512, 0.6998064280847055, 0.7004878770025151, 0.7022711440838901, 0.7040693379398083, 0.7047415939519269, 0.7057525449200626, 0.7055850935154058, 0.7070142418257628, 0.7082119375603552, 0.7099643389662172, 0.7113695722853335, 0.7129201915345863, 0.7145518004873024, 0.7157709603764487, 0.7163402134069514, 0.7172166930545847, 0.7183493806297738, 0.7189537603849441, 0.7199249482583473, 0.7205803202905698, 0.7221589246508201, 0.723287729333705, 0.724548823681961, 0.725318627166551, 0.7265617962175916, 0.7276500572490704, 0.7284494752346302, 0.7291821879615437, 0.7295354241258561, 0.7319144130103339, 0.7341816913535023, 0.7360981125325345, 0.7378717197186637, 0.7394801732174299, 0.7409521954288194, 0.7422759859104104, 0.743456219821252, 0.7446160865910094, 0.7454758317063814, 0.7463859386712854, 0.7472528335560393, 0.7480340684609775, 0.748761593937922, 0.7493390066450334, 0.7498617666074125, 0.7504919714884635, 0.75089840545784, 0.7515124546899176, 0.7520762765213775, 0.7524972374422819, 0.7528140376061863, 0.7530635661686098, 0.7533990346647007, 0.7535900635212729, 0.7539736270580764, 0.7542923611613801, 0.7544906841096246, 0.7547088843827736, 0.7546570059689692, 0.7548829881186837, 0.7549998933260171, 0.7550918714727075, 0.7551756813133885, 0.7552266961075015, 0.7552227517885435, 0.7553799523250506, 0.7555448173617474, 0.7555558300250456, 0.7556776637205832, 0.755900265853796, 0.7559398573501181, 0.7558737154121696, 0.7559281689839045, 0.7559649701672158, 0.7558739619023767, 0.7557055757366118, 0.7558246418922427, 0.7558951803385607, 0.7559352803864064, 0.7560324055857176, 0.7560211325064381, 0.7560720218913364, 0.7560669351954257, 0.756016617570085, 0.7560557514173687, 0.756078764848674, 0.7561360980305988, 0.7561022486755811, 0.7561938545685651, 0.7562783588895701, 0.7561814553236552, 0.7562173419354916, 0.7563350891048943, 0.7563434053073568, 0.7562898547333229, 0.756389173100352, 0.756479589139338, 0.7565599340657656, 0.7565447362634812, 0.7565554723039252, 0.7565295431552345, 0.7565550350464129, 0.7565535636859735, 0.7564779677654183, 0.7564719961018284, 0.7564411780334377, 0.7563757911694764, 0.7563281205145017, 0.7564002277495727, 0.756265693726498, 0.75621991431055, 0.7562875466087872, 0.7562487004098813, 0.756314483606845, 0.7564092800692026, 0.7564356207463938, 0.7565071259722063, 0.7564972089792779, 0.7564150414981422, 0.7563909483987798], "moving_var_accuracy_train": [0.010240322298630793, 0.019976977798718452, 0.02812474568857804, 0.034364669971810695, 0.03900975795873001, 0.04217489796756667, 0.04429176116107771, 0.045388287285506985, 0.04583935658953861, 0.04560992755684549, 0.044711520306936654, 0.04340870274852648, 0.04197553668653778, 0.040095440490973994, 0.03811780613842977, 0.035842382453001295, 0.03372847290012833, 0.0319678435210622, 0.02992584239719942, 0.027935942654024565, 0.026328463669818343, 0.024325414854589784, 0.02271391682824301, 0.021004002432488945, 0.01942651642780169, 0.018040535535188293, 0.01664150016275904, 0.015528116050856314, 0.0142385871403657, 0.013062467788443926, 0.012169870942111605, 0.01114834504102512, 0.010315563517644942, 0.009631606829812244, 0.008795164109136128, 0.008199221490536108, 0.007533247255654745, 0.006935271980923779, 0.006364315303547598, 0.005982880056740865, 0.005675770120963286, 0.005279923270490051, 0.004849336877884284, 0.004503913080820067, 0.004119782236968031, 0.0038662024111713327, 0.003663987889305365, 0.003383415855973015, 0.0031692010134918027, 0.0029422125227300273, 0.0027517773464889738, 0.0025210209010766947, 0.002362641345449698, 0.002219319735287052, 0.0020697830776974626, 0.0019261338649504086, 0.0018488709482733607, 0.0017451658246422238, 0.0016058532305720824, 0.001566815139145607, 0.0015136134678961982, 0.001401193143706842, 0.0013145175798708795, 0.0012452264925129101, 0.0012189863951765619, 0.0011527986200418148, 0.0011035641311925998, 0.0010070602624495646, 0.0009637576895647206, 0.0009512055112533923, 0.0008910163604744951, 0.0008296932247265886, 0.0008066666666008042, 0.000770843680864897, 0.0007272739445218307, 0.0006856813272864969, 0.0006646902919258836, 0.0006673547491661831, 0.0006195570433363754, 0.0006064923450694973, 0.0005640778725741927, 0.0005484854891854499, 0.0005344890455549301, 0.0004960644604927544, 0.0004638626555347322, 0.00045307111034842217, 0.000441342498585103, 0.00045308145582834456, 0.0004150804422344715, 0.00041234872316476585, 0.00039837190112149417, 0.00040323978353622766, 0.0003861920786960706, 0.0003808945491084342, 0.00036143306442127206, 0.00034885106391078927, 0.00034583439760346577, 0.0003148064965477214, 0.00031875046390081324, 0.00031824937050524025, 0.0003083751299190163, 0.00028439929446351397, 0.00027904785975343195, 0.00026701137902678543, 0.00026869827285651857, 0.0002680744331643197, 0.0002553561464582786, 0.00024811651994039244, 0.0002244289372449838, 0.00022768035416629245, 0.0002328020374103491, 0.00024519620354101134, 0.00025147806669446323, 0.0002501738122893726, 0.00025819257501611477, 0.00025558696519183344, 0.00024526263278097264, 0.00023899696605709527, 0.00023492357008837424, 0.00022130756907188587, 0.00021938175878323597, 0.00020965766057623716, 0.00022483948355039046, 0.00023177334923008051, 0.00023256189796745536, 0.0002152899880207912, 0.00021923303835575699, 0.0002202936935313168, 0.00021247974037117372, 0.00020608261427588624, 0.0001927304416057855, 0.00024335265397579974, 0.00027818652592868313, 0.00030074288278096037, 0.00031085092951267955, 0.0003132718663076587, 0.00030829209788689227, 0.00029938928832385226, 0.0002885896763579936, 0.00027458057130136837, 0.00025895814360500267, 0.00024335208209634983, 0.00022763589030603217, 0.0002120369126763302, 0.00019701374360974383, 0.00018186178307928982, 0.00016774422417709813, 0.00015439363052806285, 0.0001417051021139486, 0.000130130151086576, 0.00011915898276595003, 0.00010969214845603684, 0.00010011149444015863, 9.130027273328102e-05, 8.331377623168285e-05, 7.586922374895536e-05, 6.911078983549279e-05, 6.282619351969153e-05, 5.708111845168279e-05, 5.168116133617223e-05, 4.686148273921369e-05, 4.2363438202502354e-05, 3.839324346259504e-05, 3.481711553720137e-05, 3.144833887586941e-05, 2.8386862773612982e-05, 2.565674150928166e-05, 2.309382469722813e-05, 2.0809715157819137e-05, 1.874045086630492e-05, 1.69478546865693e-05, 1.5283086888281173e-05, 1.3754867428256147e-05, 1.2466171577643993e-05, 1.1263377267994399e-05, 1.0138785491074548e-05, 9.138329024748092e-06, 8.22453984202814e-06, 7.411402651507413e-06, 6.671709660814272e-06, 6.039810059710958e-06, 5.439113577048537e-06, 4.897885042646821e-06, 4.408234345972345e-06, 3.9674230331929096e-06, 3.587242235084556e-06, 3.2339895254392813e-06, 2.9149413958493133e-06, 2.6351679852723478e-06, 2.401947321341063e-06, 2.1632724097475107e-06, 1.946993925241892e-06, 1.754580574007945e-06, 1.5807506076377246e-06, 1.4252130553520919e-06, 1.2861811233428543e-06, 1.1666117105299217e-06, 1.0635385478037672e-06, 9.589689089350328e-07, 8.695629962489314e-07, 8.028151001250202e-07, 7.231793109157146e-07, 6.58178609098418e-07, 6.006697835021249e-07, 5.519251869137067e-07, 4.967574393771861e-07, 4.486477084009056e-07, 4.1457676263772e-07, 3.7369344739165926e-07, 3.665484116793221e-07, 3.3090931803635413e-07, 2.979918078393056e-07, 3.0716385847943846e-07, 2.9489386983627724e-07, 2.6569541976038747e-07, 2.4638726884883444e-07, 2.217962181454833e-07, 2.0089440933240148e-07, 2.074551349052789e-07, 1.916368187308356e-07, 2.080931438672704e-07, 1.8922732037961232e-07], "duration": 106442.330679, "accuracy_train": [0.3373149253645257, 0.3795106084463824, 0.4040584120639535, 0.41903128893272423, 0.43325723427694723, 0.4437654649432447, 0.45688038569352163, 0.4658979977044112, 0.4783568299533961, 0.486401484346161, 0.49016642297665186, 0.496235061369509, 0.5071149553571429, 0.5058121510474345, 0.5116479140711517, 0.5070724177510152, 0.5172994676310447, 0.5361063166182171, 0.528922688261351, 0.5325270294043005, 0.552331529450443, 0.5326640149155593, 0.5528895651647288, 0.5459130372715947, 0.5510508951642672, 0.5610951775332226, 0.5573971094615172, 0.5752499264604097, 0.5589313471876154, 0.5627191768180141, 0.5832945808531745, 0.5688819026278147, 0.5829211150909007, 0.5946845656261536, 0.5762755153539129, 0.5986369581141565, 0.5894765927810077, 0.5938002881021595, 0.593312367340347, 0.6133275727320967, 0.622301565672296, 0.6147916955057217, 0.6083760872323736, 0.6181391888150609, 0.6098384075650609, 0.627370390077058, 0.6348788182908822, 0.6250209083148763, 0.6343654831118494, 0.6325525880167958, 0.6380613882544297, 0.6297151854928018, 0.6419905292543374, 0.645082977171004, 0.6445227785275932, 0.645523673980251, 0.657450245420358, 0.6552635240748431, 0.6480108622300664, 0.666960464539498, 0.6677942737172389, 0.658077675110742, 0.6637252633005721, 0.6680743730389442, 0.677467613741233, 0.6726062502883905, 0.6773037718600037, 0.6653296159791436, 0.6794189363002953, 0.6872078243240126, 0.6794421877883905, 0.6792797878599114, 0.6892757648117387, 0.6883707592169619, 0.6875784061807863, 0.6888103745616464, 0.6950628619301403, 0.7020855323112772, 0.6916474165974529, 0.7018995204065154, 0.6951569493470838, 0.7036419400609081, 0.7057810769656699, 0.6995267871562385, 0.7018047120131967, 0.7091761547157622, 0.7105934140250092, 0.7181254542151163, 0.704711508513289, 0.7173588760843485, 0.7160807652154854, 0.7227052763935031, 0.7187285509528424, 0.7234965479651163, 0.7205657790005537, 0.7237977358457918, 0.7280531186554079, 0.7174028556432264, 0.7315855424049464, 0.7324007864410299, 0.7312142395717978, 0.7258903697743632, 0.7340487581902916, 0.7329119586909376, 0.7387215863210594, 0.7398144062615356, 0.7369569966431341, 0.7399542756782945, 0.7306562038575121, 0.7443720584163898, 0.746768764131137, 0.7508348906423035, 0.7514161778446844, 0.751043072570598, 0.7555531402846991, 0.7543701982973422, 0.7529264431063123, 0.7554612157968807, 0.7574837347729789, 0.7546012712255445, 0.7601565744393688, 0.758321148832595, 0.7678775104397378, 0.7679200480458656, 0.7679669115102437, 0.7614346853082319, 0.7709191295219637, 0.7717587065107051, 0.7699440089747139, 0.7714786071889996, 0.7688966105458656, 0.7886832664267257, 0.7892427440937615, 0.7898247522725176, 0.7896619918558508, 0.7899399282484312, 0.789684522367571, 0.7898941462486158, 0.7904292909629937, 0.7901499126176633, 0.7900569066652824, 0.7904285699866187, 0.7905913304032853, 0.7907061458910114, 0.7909629937246216, 0.7906145818913806, 0.7909393817483389, 0.7910559996770026, 0.7910334691652824, 0.7914280234865264, 0.7913579085340532, 0.7922876075696751, 0.7915206689507198, 0.791636926391196, 0.7919152232719637, 0.7918461897840532, 0.7920550926887228, 0.7919628077127169, 0.792032201688815, 0.7916830688791989, 0.7919853382244371, 0.7916601778792912, 0.7920787046650055, 0.7922411045934846, 0.7918222173195828, 0.7917764353197674, 0.7920085897125323, 0.7911951481173864, 0.7915675324150978, 0.7914512749746216, 0.7920779836886305, 0.7917993263196751, 0.7913110450696751, 0.7922647165697674, 0.7920787046650055, 0.7913114055578626, 0.7918229382959578, 0.7914974174626246, 0.7917993263196751, 0.7916365659030085, 0.7921484591292912, 0.7917760748315799, 0.7917767958079549, 0.7916605383674787, 0.791636926391196, 0.7920554531769103, 0.7919159442483389, 0.7914741659745294, 0.7920329226651901, 0.7922883285460502, 0.7916362054148209, 0.7917764353197674, 0.7919148627837762, 0.791636926391196, 0.791590062926818, 0.7915442809270026, 0.7914044115102437, 0.792078344176818, 0.7918694412721484, 0.7914741659745294, 0.7912420115817644, 0.7917531838316721, 0.7919620867363418, 0.7920093106889073, 0.7913811600221484, 0.791683789855574, 0.7915668114387228, 0.7920318412006275, 0.7918000472960502, 0.791148645141196, 0.7917764353197674, 0.791636926391196, 0.7923344710340532, 0.7921949621054817, 0.791730653319952, 0.7914977779508121, 0.7917764353197674, 0.7916365659030085, 0.7922879680578626, 0.792032201688815, 0.7924507284745294, 0.79203148071244], "end": "2016-02-01 21:13:15.327000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0], "moving_var_accuracy_valid": [0.010563358940862229, 0.020954728890955232, 0.029889678884744676, 0.03657888649179458, 0.04149274112302947, 0.04502168636254524, 0.047216548774211886, 0.04833255833158939, 0.048764376533735415, 0.048335929802265844, 0.04718258192242241, 0.04551939536391541, 0.04364934379592934, 0.04143037333975307, 0.03923914131980335, 0.03675276071534465, 0.034507092465827935, 0.032708451643663664, 0.03051943580806059, 0.028413794024021537, 0.02677579069498267, 0.024631949620374134, 0.022977444784402078, 0.021186045496111472, 0.01954251382944378, 0.018069723030343404, 0.016596459689442615, 0.01543685651803166, 0.01411528989005006, 0.01289355050229122, 0.011926626140391491, 0.010903970208058101, 0.010075510529473995, 0.009367899952331766, 0.008535656254720114, 0.007959991710753143, 0.007302195238027284, 0.006705963620445241, 0.00616997394482335, 0.005806323780952088, 0.005491269224455306, 0.005136828845998367, 0.004723330759758883, 0.0043971817675576945, 0.004032193040016449, 0.0037686327996249657, 0.0035327096497791695, 0.003265291541795367, 0.0030422575400173703, 0.002825191710993293, 0.002610076346787543, 0.002389603349702575, 0.00221450318537526, 0.0020735972275109263, 0.0019261670730385625, 0.0017912028640693974, 0.0017104092515459696, 0.00160667910917272, 0.0014822100580374465, 0.0014426956986249967, 0.0013796841604374755, 0.0012807184615858372, 0.0011883049773951373, 0.0011322451003421452, 0.0010959735615011655, 0.0010296697758367254, 0.0009716357362424462, 0.0008778220940278005, 0.0008377284347732976, 0.000809564668261397, 0.0007586240413481554, 0.0006982283101509119, 0.0006699821991601633, 0.0006278360283081448, 0.0005917231997832709, 0.0005521872987288685, 0.0005360237211611416, 0.0005296125901015092, 0.0005009128589872372, 0.0004808476813818944, 0.00044268269231164265, 0.00043284767101794334, 0.00041972109599168857, 0.00039203642865086357, 0.00037118442012772356, 0.00035494524277672587, 0.0003445496408264255, 0.0003473253121085704, 0.0003185015346553523, 0.0003095154063028203, 0.00029430653940539045, 0.0002940573613317104, 0.00027498039343466367, 0.00026784997258507933, 0.00025034077512581097, 0.00023542234732762009, 0.0002240870499801503, 0.00020207909179603364, 0.00020734117213430588, 0.0002095729326170816, 0.0001949279679313836, 0.00017979220709110212, 0.00016880674068175245, 0.00015610542026183165, 0.00016911525158728972, 0.00018130523671971906, 0.00016724206636021312, 0.00015971605646396104, 0.00014399681057385895, 0.00014797931355343968, 0.00014609165785204313, 0.000159120688252245, 0.00016098074555741018, 0.00016652245150704882, 0.00017382953632759292, 0.00016982374021256186, 0.00015575780730593442, 0.0001470959757297775, 0.00014393320844368994, 0.00013282736159545727, 0.00012803347840491998, 0.00011909574307000301, 0.0001296140942988125, 0.00012812048497785617, 0.00012962166707689972, 0.00012199287701319245, 0.00012370281291706155, 0.00012199134027907292, 0.0001155438282918944, 0.00010882125692433397, 9.906211332190444e-05, 0.00014009219500192723, 0.0001723479352703394, 0.00018816717296229758, 0.00019766159772226601, 0.00020117954186927737, 0.00020056323219976716, 0.00019627870013214747, 0.0001891873988776344, 0.00018237627730215668, 0.00017079110454259422, 0.00016116664627643612, 0.00015181354231970628, 0.00014212513987798032, 0.00013267626576661103, 0.00012240928809895363, 0.00011262786109345855, 0.00010493949871301623, 9.593224598488314e-05, 8.973252952112882e-05, 8.362033208769471e-05, 7.685317175128346e-05, 7.007111567080348e-05, 6.362438463490955e-05, 5.8274798178243556e-05, 5.2775746576808366e-05, 4.8822260800013944e-05, 4.485435757749252e-05, 4.072290974594687e-05, 3.7079121004172796e-05, 3.3395431232125334e-05, 3.051549949681918e-05, 2.7586950994652337e-05, 2.4904395710404603e-05, 2.2477172943919007e-05, 2.0252878232492594e-05, 1.8227730428111716e-05, 1.6627365463403608e-05, 1.5209253239988425e-05, 1.3689419424765847e-05, 1.2454068526604418e-05, 1.16546270613418e-05, 1.0503271734436907e-05, 9.49231736459354e-06, 8.569772351406325e-06, 7.724984060103745e-06, 7.027028192514486e-06, 6.579510480651691e-06, 6.049150177337208e-06, 5.489016211283958e-06, 4.9545867146906375e-06, 4.544027782292678e-06, 4.0907687449114074e-06, 3.704999435878268e-06, 3.334732362568037e-06, 3.024045897090632e-06, 2.73542442941056e-06, 2.4666485486534967e-06, 2.2495675375347123e-06, 2.0349227932972774e-06, 1.9069552706322106e-06, 1.780528565985528e-06, 1.6869884191700814e-06, 1.5298802174348655e-06, 1.5016717588123959e-06, 1.352127015941713e-06, 1.2427232901617509e-06, 1.207228203409619e-06, 1.1600809240217054e-06, 1.1021705964435101e-06, 9.940322955476384e-07, 8.956664290726214e-07, 8.121506729317821e-07, 7.367841342812491e-07, 6.6312520496701e-07, 6.482453733115791e-07, 5.837417828747131e-07, 5.3391538464123e-07, 5.190028239852705e-07, 4.875549636982431e-07, 4.8559454747455e-07, 5.99929723009167e-07, 5.587985450291018e-07, 5.440858404097589e-07, 5.032585008936643e-07, 4.918795118291588e-07, 5.235688841260086e-07, 4.774564771874183e-07, 4.757278053350535e-07, 4.2904014554023685e-07, 4.468995855917625e-07, 4.074339239645703e-07], "accuracy_test": 0.7477240114795919, "start": "2016-01-31 15:39:12.996000", "learning_rate_per_epoch": [0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 0.0008435227209702134, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435227209702134e-05, 8.435226845904253e-06, 8.435226845904253e-07, 8.435226561687159e-08, 8.435226739322843e-09, 8.435226961367448e-10, 8.43522682258957e-11, 8.435226475644875e-12, 8.43522625880444e-13, 8.435226394329712e-14, 8.43522673314289e-15, 8.435226839022009e-16, 8.435226574324213e-17, 8.43522640888809e-18, 8.435226512285667e-19, 8.435226641532638e-20, 8.435226803091351e-21, 8.435226803091351e-22, 8.435226550655862e-23, 8.435226550655862e-24, 8.435226550655862e-25, 8.435226797174894e-26, 8.435226489026103e-27, 8.435226489026103e-28, 8.435226489026103e-29, 8.435226338562826e-30, 8.43522615048373e-31, 8.4352263855826e-32, 8.435226238645807e-33, 8.435226238645807e-34, 8.435226353440177e-35, 8.435226640426102e-36, 8.435226640426102e-37, 8.435226528322225e-38, 8.435226808581918e-39, 8.435228209880382e-40, 8.435256235849669e-41, 8.435816755235399e-42, 8.435816755235399e-43, 8.407790785948902e-44, 8.407790785948902e-45, 1.401298464324817e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_train_first": 0.3373149253645257, "accuracy_train_last": 0.79203148071244, "batch_size_eval": 1024, "accuracy_train_std": [0.01677154005587776, 0.013474440154257986, 0.012659513964612458, 0.01226908869107269, 0.011631513787252287, 0.012899441030047589, 0.014927698132327976, 0.014157118014601485, 0.013450791531367115, 0.012157102659287173, 0.012151382320353954, 0.012007952876415014, 0.013528770002679305, 0.012337957455254586, 0.013697874772863132, 0.013802188696392105, 0.014016276583455896, 0.013473032931946863, 0.013478846319997694, 0.014198666025714683, 0.014379169589620704, 0.013794191789313544, 0.014206071083019713, 0.012754541537344646, 0.013085451980219763, 0.013053025493513724, 0.01334931957261118, 0.013588727599239398, 0.013305137521040247, 0.01173689205074838, 0.014061990894599967, 0.013151572764701545, 0.014426710166105854, 0.014159984239176889, 0.013258306586692662, 0.01505320105432387, 0.013638513615983346, 0.014168970249228032, 0.012958900804680153, 0.015746383753878736, 0.01564573999803947, 0.01461212666130322, 0.013265502942201544, 0.015081297546894065, 0.014202234259077273, 0.01431112156005585, 0.01419547701484766, 0.013950031971748263, 0.0137024630736691, 0.01303481263112768, 0.013810622591170075, 0.013705545728069934, 0.012882310884735055, 0.012334737602262858, 0.013543769616048352, 0.011945559752979645, 0.01544359219859414, 0.013678277903483764, 0.012599669720461787, 0.013731677985862776, 0.012552089631567587, 0.012121652078224845, 0.013018552857467322, 0.012909034193432742, 0.012612292112194445, 0.01212016677408165, 0.012894605311753219, 0.011626690259866172, 0.012831953068330057, 0.013493312222033212, 0.012089877786103117, 0.011907178793633448, 0.010925755535298702, 0.011837510971229271, 0.012255553388633994, 0.012112584561230207, 0.013145148469383451, 0.013333355180389547, 0.011351139886471557, 0.012428550583817973, 0.012558602638316565, 0.012448465697426015, 0.012536688829624491, 0.013394024056333753, 0.013710815748604976, 0.012067565464870209, 0.01196748773573489, 0.012300837708283522, 0.012399960339678651, 0.01258412366660068, 0.012516701789979441, 0.012595605521176976, 0.013223059281756662, 0.012191408677374099, 0.013397178199641355, 0.013610787633570154, 0.012188255166925191, 0.01287562306039735, 0.013245079875804885, 0.01161179465753735, 0.012027621951186611, 0.012662490532091853, 0.012978394109608297, 0.012999018524549634, 0.012069993451287345, 0.012738169343569649, 0.01269202946112727, 0.01183161426477815, 0.012324992447509198, 0.012719013180384497, 0.013375472658304853, 0.012353638052885748, 0.011236483069323875, 0.012639817312099438, 0.01332487886563274, 0.013214418941797887, 0.013239736744617125, 0.012728851429948727, 0.012975240424935324, 0.013079904102582748, 0.012160994051084943, 0.012913993273722746, 0.012069598486086746, 0.012128331715657897, 0.012666998598878272, 0.013340296901172364, 0.01313732166400713, 0.012490763069268473, 0.012000773200742306, 0.012276216542365069, 0.01299995784266337, 0.010177514444149563, 0.010086569223901772, 0.010617456624216854, 0.010959223539188344, 0.010098635935718022, 0.01047895881967263, 0.010385643842772978, 0.010857805996561963, 0.010582069418282119, 0.010653205788697195, 0.010890027306157311, 0.010598648689465844, 0.01076131954981495, 0.010636149444384742, 0.010783263619836354, 0.010249111679825508, 0.010771965974314787, 0.01091062548167582, 0.010624008020392893, 0.010585971664565302, 0.01017352746887959, 0.01056334637973969, 0.010497832228034075, 0.010619624876812875, 0.010165553181603792, 0.010022498480394564, 0.01021316359040895, 0.010365585431007324, 0.01015301247372987, 0.009889273065932206, 0.010620089434505531, 0.009995044213864148, 0.010033192488384085, 0.010250788192156397, 0.010386397383970332, 0.010763326254939117, 0.01065091535209714, 0.010643306529761037, 0.010707177219266123, 0.010042612512466985, 0.010811081011678833, 0.01089498323397185, 0.010383969423867231, 0.010001857228792923, 0.010628043853564402, 0.01028179591895421, 0.010740289094110662, 0.010598970061873061, 0.009966387447462624, 0.010554439095741774, 0.010667923024619249, 0.010114861265477412, 0.010420265980216335, 0.010150330910052194, 0.010527403910131442, 0.010421093154169921, 0.010640420738824494, 0.009960670583986444, 0.010295289389908114, 0.011041734354692568, 0.010194425641695697, 0.010534611154468512, 0.010338729511495694, 0.010810573368712554, 0.010764336330396716, 0.010610078034696453, 0.009745498233833652, 0.010335319031365447, 0.010625472321756068, 0.010868304565486656, 0.01071622984028663, 0.010248914387758053, 0.010345726859622682, 0.009967616928208368, 0.0104089890620413, 0.010456260998302942, 0.010579208796716519, 0.010327479926361396, 0.010692024140464945, 0.010113923269798238, 0.010564671619658475, 0.010233208360073989, 0.010452036833123627, 0.01068231350710526, 0.0102700018421271, 0.0100711764812425, 0.010115638432161232, 0.01066702510986446, 0.01095558212472238, 0.009916437987051453, 0.010288601459890426], "accuracy_test_std": 0.008510048376785493, "error_valid": [0.6574059911521084, 0.6090940912085843, 0.5799898814006024, 0.5671416133283133, 0.5536624035203314, 0.5393287015248494, 0.5294204160391567, 0.5202445524284638, 0.5075889495481928, 0.5029605727597892, 0.5008236069277108, 0.49857633659638556, 0.4917712843561747, 0.49271696159638556, 0.4844264754329819, 0.4905814664909638, 0.4782920745481928, 0.45623705760542166, 0.4685367446347892, 0.4646702042545181, 0.4413238893072289, 0.4683837890625, 0.44290050828313254, 0.45320588996611444, 0.44805834666792166, 0.4403061464608433, 0.4452404343938253, 0.4255047533885542, 0.4429108033697289, 0.4417003953313253, 0.42317512236445776, 0.433581984186747, 0.41874970585466864, 0.40957384224397586, 0.42744758330195776, 0.40255406391189763, 0.41337861210466864, 0.41006212349397586, 0.4061146931475903, 0.38786444606551207, 0.38129323936370485, 0.3836728750941265, 0.3921677922628012, 0.3818932958396084, 0.38934987998870485, 0.37589126035391573, 0.37177175498870485, 0.37650161191641573, 0.3703878012048193, 0.36978774472891573, 0.37042898155120485, 0.3738366552146084, 0.36629918109939763, 0.3603574454066265, 0.3614766683923193, 0.35939117799322284, 0.3491166815700302, 0.3515169074736446, 0.3560746893825302, 0.33937017601656627, 0.3406011742281627, 0.3468267601656627, 0.3456575324736446, 0.3371626153049698, 0.3316900414156627, 0.33607427757906627, 0.3334696206701807, 0.34747829207454817, 0.3299501717808735, 0.3258100762424698, 0.32991928652108427, 0.3332460702183735, 0.3235510400978916, 0.32627776731927716, 0.3240187311746988, 0.32474085796310237, 0.3172033838478916, 0.3130529932228916, 0.3172430934676205, 0.31375452983810237, 0.3196947948042168, 0.3095835490399097, 0.3088820124246988, 0.3127573771649097, 0.30981739457831325, 0.3074377588478916, 0.30444630082831325, 0.2991369775978916, 0.3093394084149097, 0.30069300640060237, 0.30181222938629515, 0.29570871376129515, 0.30120187782379515, 0.29579989881400603, 0.2991869823042168, 0.2977221385542168, 0.29561752870858427, 0.30398890483810237, 0.28906544145331325, 0.28823153943900603, 0.2942335749246988, 0.2948130412274097, 0.29225985975150603, 0.2933790827371988, 0.2816794521837349, 0.2797469173569277, 0.28920810193900603, 0.2851488963667168, 0.29592196912650603, 0.28012342338102414, 0.28100880082831325, 0.27426404838102414, 0.2759833278426205, 0.2731242352221386, 0.270763718938253, 0.2732566006212349, 0.27853650931852414, 0.2748949901167168, 0.27145643119352414, 0.27560682181852414, 0.27133436088102414, 0.2735213314194277, 0.2636336361069277, 0.26655302852033136, 0.2641013271837349, 0.2677531414721386, 0.26224968232304224, 0.2625555934676205, 0.26435576289533136, 0.2642233974962349, 0.26728545039533136, 0.24667468702936746, 0.2454128035579819, 0.24665409685617468, 0.24616581560617468, 0.24604374529367468, 0.24579960466867468, 0.24580989975527112, 0.24592167498117468, 0.24494511248117468, 0.24678646225527112, 0.24542309864457834, 0.24494511248117468, 0.24493481739457834, 0.24469067676957834, 0.2454642789909638, 0.24543339373117468, 0.24383618458207834, 0.24544368881777112, 0.24296110222138556, 0.2428493269954819, 0.24371411426957834, 0.24433476091867468, 0.24469067676957834, 0.2435817488704819, 0.24469067676957834, 0.24257430111069278, 0.24283903190888556, 0.24372440935617468, 0.24332731315888556, 0.24580989975527112, 0.24308317253388556, 0.2439479598079819, 0.24408032520707834, 0.2440700301204819, 0.2443141707454819, 0.24481274708207834, 0.24320524284638556, 0.2429713973079819, 0.24434505600527112, 0.24322583301957834, 0.24209631494728923, 0.2437038191829819, 0.24472156202936746, 0.2435817488704819, 0.2437038191829819, 0.24494511248117468, 0.24580989975527112, 0.24310376270707834, 0.24346997364457834, 0.2437038191829819, 0.2430934676204819, 0.24408032520707834, 0.24346997364457834, 0.24397884506777112, 0.2444362410579819, 0.24359204395707834, 0.24371411426957834, 0.24334790333207834, 0.24420239551957834, 0.24298169239457834, 0.24296110222138556, 0.24469067676957834, 0.2434596785579819, 0.2426051863704819, 0.2435817488704819, 0.2441921004329819, 0.24271696159638556, 0.24270666650978923, 0.24271696159638556, 0.24359204395707834, 0.24334790333207834, 0.2437038191829819, 0.2432155379329819, 0.2434596785579819, 0.24420239551957834, 0.2435817488704819, 0.24383618458207834, 0.24421269060617468, 0.24410091538027112, 0.24295080713478923, 0.24494511248117468, 0.2441921004329819, 0.24310376270707834, 0.24410091538027112, 0.2430934676204819, 0.24273755176957834, 0.24332731315888556, 0.2428493269954819, 0.24359204395707834, 0.24432446583207834, 0.2438258894954819], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.08442015807553842, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.0008435227022369367, "optimization": "nesterov_momentum", "nb_data_augmentation": 3, "learning_rate_decay_method": "discrete", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 8.579693348703924e-08, "rotation_range": [0, 0], "momentum": 0.6229254076881431}, "accuracy_valid_max": 0.7579036850527108, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7561741105045181, "accuracy_valid_std": [0.012699209872625326, 0.011926763583136135, 0.011035403004407935, 0.0115329174299239, 0.009524348499026728, 0.010622348196829142, 0.011425368027554008, 0.011891982443473928, 0.009710136136920951, 0.009348336499352716, 0.011123428411389073, 0.013738016684146632, 0.01632326587163674, 0.01179609185225211, 0.016795385145823856, 0.018584123449209518, 0.015590840250670243, 0.013366121802245588, 0.019006718511760307, 0.012271384701592648, 0.01708921595841603, 0.017611577733125983, 0.014421870903489387, 0.018525012762249143, 0.017932459997324932, 0.01514574847900109, 0.016826159333571695, 0.014589421033489649, 0.01558637718397945, 0.01710579103572738, 0.015212449211204748, 0.015581492078454858, 0.014364606379071738, 0.01491684611175279, 0.016142707507671127, 0.012139874143804448, 0.017710866748211124, 0.015530642855583131, 0.013123496277268257, 0.01177739678510838, 0.014863324474463898, 0.010528940968595515, 0.014666203544225246, 0.01444564395368865, 0.015487267557376425, 0.014721081084967221, 0.01787404589866782, 0.014780676094109876, 0.016123925601886822, 0.016603939882933044, 0.01887052045795157, 0.020255609081279817, 0.02373841393785327, 0.016484014592867913, 0.018924320296943395, 0.01842688535577553, 0.017614899429006136, 0.014094589115076559, 0.01728835124878405, 0.012860601374363652, 0.015158244688024503, 0.01257375888380953, 0.016558341753871532, 0.013589111204360958, 0.016082117242390854, 0.015093825634938954, 0.012142821978745071, 0.014300365213680291, 0.013212312108836471, 0.01628360791889237, 0.012499609553628874, 0.013953696164003425, 0.010515094122469187, 0.014945581886299788, 0.010814211402502846, 0.009364755756050983, 0.01401799471614945, 0.01357300030083672, 0.01029536298423505, 0.010192130106429316, 0.007307299436241181, 0.008785536454013549, 0.01284573580249485, 0.009084363073659908, 0.009983620138318671, 0.014447675806897252, 0.01117929506248141, 0.018250261956453382, 0.010317848347585389, 0.012993200717711375, 0.014746862804516361, 0.017045640926901535, 0.015068451527653732, 0.01392106285227485, 0.011967340309615696, 0.011535289360342336, 0.02077378068559645, 0.012548669995549775, 0.01458171270559836, 0.01747155518007675, 0.016868941116514213, 0.013696420872303463, 0.015978444145977683, 0.01687250074358533, 0.01106769252466084, 0.013673404811868989, 0.01725050392513787, 0.014833572544238565, 0.015171156198034693, 0.013824902856750757, 0.019748355883463208, 0.01710570681944546, 0.01717310019472707, 0.013186550540460515, 0.011477842934580514, 0.01518434719086673, 0.016555465003828658, 0.01979955256070076, 0.01901903765074166, 0.01617900926255208, 0.017837900075253307, 0.01604370612548142, 0.019719592299696467, 0.017001518153576818, 0.016964535094981217, 0.016689025810639573, 0.016015375062575905, 0.02150920066411315, 0.01896283335328479, 0.016723895500247797, 0.019114315443952135, 0.0150054370392382, 0.012140012407764588, 0.013324052265105505, 0.013398063067645473, 0.013570554492651534, 0.013066158111818924, 0.01512317656245589, 0.013800396090068107, 0.01418034212775897, 0.014448559324227346, 0.013339769351348061, 0.014330863103251107, 0.013171173680324055, 0.012704732764382321, 0.016321807175028763, 0.013991658856316196, 0.013959924762698025, 0.014512280200469551, 0.011547554929618106, 0.011824580490059489, 0.013215290462604556, 0.013429562590909397, 0.012629445196902244, 0.01239248069950097, 0.012515664705973008, 0.009938030638424192, 0.0115705496537475, 0.013736137165666821, 0.011788273985554579, 0.014495303383140807, 0.011419301305327536, 0.012398773780091441, 0.013441109795591051, 0.012913386079960568, 0.011568432981408631, 0.012341812944379768, 0.010780509459714867, 0.0129298712149276, 0.014433591144931077, 0.013035944660898243, 0.009956608304140014, 0.010788077375717778, 0.015222482072032027, 0.01222785598716216, 0.01153568004070775, 0.013286270703731536, 0.014111929900995874, 0.012082009995623947, 0.012773815677230882, 0.011781084835447908, 0.011532590332303506, 0.012243669214456595, 0.012876061949446602, 0.014087221216257025, 0.011976114702648534, 0.012376849737470715, 0.012681310043647556, 0.012966022212085303, 0.012584558627900902, 0.012906143879421034, 0.011742060204899187, 0.012362328492914004, 0.011346625464063769, 0.01203547375119854, 0.011951767309813796, 0.012293960185220242, 0.011765735304241048, 0.010463386475756339, 0.011279488199013765, 0.012653084533736201, 0.012929194007666648, 0.012139894099524793, 0.012708028717790597, 0.0127234465423822, 0.01292107521480822, 0.012041200481673236, 0.012278927569067278, 0.013497176965193172, 0.014285560335430382, 0.011101173306948209, 0.013429061265719949, 0.012476834936742178, 0.012479989073613848, 0.014607380281288726, 0.011908909572227766, 0.013363354549763446, 0.011666292496302504, 0.012308664189987153, 0.012858684106785912, 0.012512113916575529, 0.011769794939392312], "accuracy_valid": [0.3425940088478916, 0.3909059087914157, 0.4200101185993976, 0.43285838667168675, 0.44633759647966864, 0.4606712984751506, 0.4705795839608434, 0.47975544757153615, 0.4924110504518072, 0.49703942724021083, 0.49917639307228917, 0.5014236634036144, 0.5082287156438253, 0.5072830384036144, 0.5155735245670181, 0.5094185335090362, 0.5217079254518072, 0.5437629423945783, 0.5314632553652108, 0.5353297957454819, 0.5586761106927711, 0.5316162109375, 0.5570994917168675, 0.5467941100338856, 0.5519416533320783, 0.5596938535391567, 0.5547595656061747, 0.5744952466114458, 0.5570891966302711, 0.5582996046686747, 0.5768248776355422, 0.566418015813253, 0.5812502941453314, 0.5904261577560241, 0.5725524166980422, 0.5974459360881024, 0.5866213878953314, 0.5899378765060241, 0.5938853068524097, 0.6121355539344879, 0.6187067606362951, 0.6163271249058735, 0.6078322077371988, 0.6181067041603916, 0.6106501200112951, 0.6241087396460843, 0.6282282450112951, 0.6234983880835843, 0.6296121987951807, 0.6302122552710843, 0.6295710184487951, 0.6261633447853916, 0.6337008189006024, 0.6396425545933735, 0.6385233316076807, 0.6406088220067772, 0.6508833184299698, 0.6484830925263554, 0.6439253106174698, 0.6606298239834337, 0.6593988257718373, 0.6531732398343373, 0.6543424675263554, 0.6628373846950302, 0.6683099585843373, 0.6639257224209337, 0.6665303793298193, 0.6525217079254518, 0.6700498282191265, 0.6741899237575302, 0.6700807134789157, 0.6667539297816265, 0.6764489599021084, 0.6737222326807228, 0.6759812688253012, 0.6752591420368976, 0.6827966161521084, 0.6869470067771084, 0.6827569065323795, 0.6862454701618976, 0.6803052051957832, 0.6904164509600903, 0.6911179875753012, 0.6872426228350903, 0.6901826054216867, 0.6925622411521084, 0.6955536991716867, 0.7008630224021084, 0.6906605915850903, 0.6993069935993976, 0.6981877706137049, 0.7042912862387049, 0.6987981221762049, 0.704200101185994, 0.7008130176957832, 0.7022778614457832, 0.7043824712914157, 0.6960110951618976, 0.7109345585466867, 0.711768460560994, 0.7057664250753012, 0.7051869587725903, 0.707740140248494, 0.7066209172628012, 0.7183205478162651, 0.7202530826430723, 0.710791898060994, 0.7148511036332832, 0.704078030873494, 0.7198765766189759, 0.7189911991716867, 0.7257359516189759, 0.7240166721573795, 0.7268757647778614, 0.729236281061747, 0.7267433993787651, 0.7214634906814759, 0.7251050098832832, 0.7285435688064759, 0.7243931781814759, 0.7286656391189759, 0.7264786685805723, 0.7363663638930723, 0.7334469714796686, 0.7358986728162651, 0.7322468585278614, 0.7377503176769578, 0.7374444065323795, 0.7356442371046686, 0.7357766025037651, 0.7327145496046686, 0.7533253129706325, 0.7545871964420181, 0.7533459031438253, 0.7538341843938253, 0.7539562547063253, 0.7542003953313253, 0.7541901002447289, 0.7540783250188253, 0.7550548875188253, 0.7532135377447289, 0.7545769013554217, 0.7550548875188253, 0.7550651826054217, 0.7553093232304217, 0.7545357210090362, 0.7545666062688253, 0.7561638154179217, 0.7545563111822289, 0.7570388977786144, 0.7571506730045181, 0.7562858857304217, 0.7556652390813253, 0.7553093232304217, 0.7564182511295181, 0.7553093232304217, 0.7574256988893072, 0.7571609680911144, 0.7562755906438253, 0.7566726868411144, 0.7541901002447289, 0.7569168274661144, 0.7560520401920181, 0.7559196747929217, 0.7559299698795181, 0.7556858292545181, 0.7551872529179217, 0.7567947571536144, 0.7570286026920181, 0.7556549439947289, 0.7567741669804217, 0.7579036850527108, 0.7562961808170181, 0.7552784379706325, 0.7564182511295181, 0.7562961808170181, 0.7550548875188253, 0.7541901002447289, 0.7568962372929217, 0.7565300263554217, 0.7562961808170181, 0.7569065323795181, 0.7559196747929217, 0.7565300263554217, 0.7560211549322289, 0.7555637589420181, 0.7564079560429217, 0.7562858857304217, 0.7566520966679217, 0.7557976044804217, 0.7570183076054217, 0.7570388977786144, 0.7553093232304217, 0.7565403214420181, 0.7573948136295181, 0.7564182511295181, 0.7558078995670181, 0.7572830384036144, 0.7572933334902108, 0.7572830384036144, 0.7564079560429217, 0.7566520966679217, 0.7562961808170181, 0.7567844620670181, 0.7565403214420181, 0.7557976044804217, 0.7564182511295181, 0.7561638154179217, 0.7557873093938253, 0.7558990846197289, 0.7570491928652108, 0.7550548875188253, 0.7558078995670181, 0.7568962372929217, 0.7558990846197289, 0.7569065323795181, 0.7572624482304217, 0.7566726868411144, 0.7571506730045181, 0.7564079560429217, 0.7556755341679217, 0.7561741105045181], "seed": 644347184, "model": "residualv3", "loss_std": [0.26829439401626587, 0.07872369140386581, 0.07459399849176407, 0.07807990908622742, 0.07946430146694183, 0.08007114380598068, 0.08099407702684402, 0.08141031861305237, 0.08170832693576813, 0.08322256058454514, 0.08353634923696518, 0.08370649069547653, 0.08416255563497543, 0.08342617005109787, 0.08623559772968292, 0.0864429622888565, 0.08612190932035446, 0.08582031726837158, 0.08602578938007355, 0.08813970535993576, 0.0874057188630104, 0.08631116896867752, 0.08741042762994766, 0.08947645127773285, 0.0896335169672966, 0.0909571424126625, 0.08797229081392288, 0.08892825245857239, 0.08806094527244568, 0.09049370139837265, 0.09122905135154724, 0.09031432121992111, 0.09298134595155716, 0.09082914888858795, 0.09015713632106781, 0.09129706770181656, 0.08914188295602798, 0.09043702483177185, 0.0897715613245964, 0.09004763513803482, 0.0916907861828804, 0.09014463424682617, 0.09175462275743484, 0.09256085008382797, 0.09266574680805206, 0.09202992171049118, 0.09162559360265732, 0.09383561462163925, 0.09158056974411011, 0.08980654180049896, 0.09279187768697739, 0.09448971599340439, 0.09114587306976318, 0.0936633050441742, 0.09210382401943207, 0.0937470868229866, 0.09115315973758698, 0.09309201687574387, 0.09528142958879471, 0.09199212491512299, 0.09192690253257751, 0.09216701239347458, 0.09439698606729507, 0.09393735229969025, 0.09106144309043884, 0.09589371830224991, 0.09347589313983917, 0.09329065680503845, 0.09198640286922455, 0.09466492384672165, 0.09418834000825882, 0.09334605187177658, 0.09353803843259811, 0.09482640773057938, 0.09460306912660599, 0.09481088817119598, 0.09398142993450165, 0.09377159923315048, 0.09706638753414154, 0.09552894532680511, 0.09471790492534637, 0.0962735190987587, 0.09196163713932037, 0.0983705148100853, 0.09461212903261185, 0.09319135546684265, 0.09543555229902267, 0.09128379821777344, 0.09561900794506073, 0.09518644958734512, 0.0949203372001648, 0.09457726776599884, 0.09455855935811996, 0.09302838891744614, 0.0933723896741867, 0.09392623603343964, 0.09320319443941116, 0.09443787485361099, 0.09616246074438095, 0.09430976957082748, 0.0936041846871376, 0.09447053074836731, 0.09319707751274109, 0.09369846433401108, 0.09331440180540085, 0.09438695758581161, 0.09385589510202408, 0.09105736762285233, 0.09311249852180481, 0.09319194406270981, 0.08936135470867157, 0.09255852550268173, 0.09188274294137955, 0.09408452361822128, 0.09272165596485138, 0.09170814603567123, 0.08932853490114212, 0.09255075454711914, 0.09161702543497086, 0.09048040211200714, 0.09038333594799042, 0.09236783534288406, 0.08844255656003952, 0.09221935272216797, 0.08986213058233261, 0.09087866544723511, 0.09026196599006653, 0.08780451864004135, 0.09012165665626526, 0.08942235261201859, 0.08916346728801727, 0.08897623419761658, 0.08854498714208603, 0.08792882412672043, 0.08589732646942139, 0.08749058842658997, 0.08537276834249496, 0.0871882513165474, 0.08948109298944473, 0.08877022564411163, 0.08562998473644257, 0.08669756352901459, 0.08722864836454391, 0.08833858370780945, 0.08726280182600021, 0.08741483092308044, 0.08797702193260193, 0.08783077448606491, 0.08718719333410263, 0.08876178413629532, 0.08870842307806015, 0.08607044816017151, 0.08549132198095322, 0.08827783912420273, 0.08710997551679611, 0.0879049301147461, 0.0860413983464241, 0.08632603287696838, 0.08711571991443634, 0.088206946849823, 0.08685542643070221, 0.0871170312166214, 0.08607131242752075, 0.08736182004213333, 0.08655029535293579, 0.08767075836658478, 0.08885477483272552, 0.0865696519613266, 0.08792312443256378, 0.088445283472538, 0.0867801308631897, 0.08724809437990189, 0.08884277939796448, 0.08701851218938828, 0.08736039698123932, 0.08720150589942932, 0.08770494908094406, 0.08767767995595932, 0.08398979157209396, 0.08598529547452927, 0.08710350841283798, 0.08764169365167618, 0.08641639351844788, 0.08792518079280853, 0.08667510002851486, 0.08721106499433517, 0.0866723507642746, 0.08735111355781555, 0.08801062405109406, 0.08843529224395752, 0.08660592883825302, 0.08716106414794922, 0.08353950828313828, 0.08861898630857468, 0.08734317123889923, 0.08774850517511368, 0.08538069576025009, 0.08600588142871857, 0.08804317563772202, 0.08594151586294174, 0.08562644571065903, 0.08548523485660553, 0.084708072245121, 0.08680759370326996, 0.08686205744743347, 0.08935920149087906, 0.08767367899417877, 0.08735717087984085, 0.08744311332702637, 0.08613359183073044, 0.08894728869199753, 0.08740995079278946, 0.08925218880176544, 0.08467235416173935, 0.08663885295391083, 0.08763579279184341, 0.08854001015424728, 0.08655209094285965, 0.087879478931427, 0.08818002790212631, 0.08518748730421066, 0.08754955977201462]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:29 2016", "state": "available"}], "summary": "e9c4ec60b417123d36c25f694aa3bffc"}