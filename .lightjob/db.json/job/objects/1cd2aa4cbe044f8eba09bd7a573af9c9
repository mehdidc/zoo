{"content": {"hp_model": {"f0": 64, "f1": 64, "f2": 16, "f3": 16, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.645923137664795, 1.2711329460144043, 1.081868052482605, 0.9765160083770752, 0.9045924544334412, 0.8479839563369751, 0.8049964904785156, 0.7684877514839172, 0.7346850633621216, 0.7073159217834473, 0.6841610670089722, 0.6635659337043762, 0.644359290599823, 0.627011239528656, 0.6093595027923584, 0.5954958200454712, 0.5798606276512146, 0.5658546686172485, 0.5543823838233948, 0.5444824695587158, 0.5312833786010742, 0.5202258229255676, 0.5132620334625244, 0.499881386756897, 0.4928390085697174, 0.4832571744918823, 0.4749344289302826, 0.46753424406051636, 0.4592916965484619, 0.4515194296836853, 0.4440881609916687, 0.4371858835220337, 0.4322632849216461, 0.42274394631385803, 0.4174406826496124, 0.412029504776001, 0.40590083599090576, 0.40155649185180664, 0.3942759931087494, 0.3897395133972168, 0.3826989233493805, 0.3781103491783142, 0.37533947825431824, 0.36842602491378784, 0.36524322628974915, 0.3596651554107666, 0.3562317490577698, 0.3526574671268463, 0.34646281599998474, 0.34252750873565674, 0.33602264523506165, 0.33268898725509644, 0.331164687871933, 0.32471349835395813, 0.323214590549469, 0.31723418831825256, 0.3171338140964508, 0.31099796295166016, 0.3092328608036041, 0.30381476879119873, 0.3026427924633026, 0.298940509557724, 0.2955569326877594, 0.292667418718338, 0.29029008746147156, 0.28787556290626526, 0.28439587354660034, 0.27974438667297363, 0.27978190779685974, 0.2760799527168274, 0.27477243542671204, 0.2706499397754669, 0.26827192306518555, 0.2656848132610321, 0.2639240324497223, 0.261536180973053, 0.25906896591186523, 0.25755104422569275, 0.2559346556663513, 0.2526126503944397, 0.2515570819377899, 0.24843460321426392, 0.246319979429245, 0.24441081285476685, 0.24535053968429565, 0.23967382311820984, 0.23898255825042725, 0.23820087313652039, 0.23388193547725677, 0.23212383687496185, 0.23071162402629852, 0.2295774221420288, 0.22961294651031494, 0.2269967943429947, 0.22510598599910736, 0.2231847643852234, 0.22151771187782288, 0.22136364877223969, 0.21885335445404053, 0.2182931751012802, 0.21595041453838348, 0.21327117085456848, 0.21157149970531464, 0.20990385115146637, 0.20999647676944733, 0.20907282829284668, 0.20690752565860748, 0.2040393352508545, 0.206177219748497, 0.204521045088768, 0.20168009400367737, 0.2022864669561386, 0.1991453319787979, 0.19686290621757507, 0.19789627194404602, 0.1951984167098999, 0.1949908435344696, 0.19441956281661987, 0.1941239833831787, 0.19269537925720215, 0.19070382416248322, 0.1890806257724762, 0.1890595257282257, 0.1872067004442215, 0.18836891651153564, 0.18535037338733673, 0.184729665517807, 0.18305084109306335, 0.1826835721731186, 0.18235352635383606, 0.1801307648420334, 0.1806892454624176, 0.1777295470237732, 0.17760364711284637, 0.17586301267147064, 0.17683453857898712, 0.1747138500213623, 0.17410776019096375, 0.17611241340637207, 0.17399263381958008, 0.17128658294677734, 0.17111922800540924, 0.17166945338249207, 0.17005722224712372, 0.16877752542495728, 0.16794365644454956, 0.16906985640525818, 0.16570857167243958, 0.16648200154304504, 0.1643841564655304, 0.1627179980278015, 0.1640108823776245, 0.16531537473201752, 0.1612291932106018, 0.16462445259094238, 0.16096724569797516, 0.16259922087192535, 0.16084447503089905, 0.1595878303050995, 0.15988722443580627, 0.15615807473659515, 0.1593814343214035, 0.15578031539916992, 0.1554919332265854, 0.1560046374797821, 0.15580716729164124, 0.15366698801517487, 0.15357178449630737, 0.15305690467357635, 0.15412311255931854, 0.15009890496730804, 0.15195079147815704, 0.15117749571800232, 0.15119168162345886, 0.15129075944423676, 0.15078793466091156, 0.14903554320335388, 0.1491185873746872, 0.1486133188009262, 0.14843876659870148, 0.14686241745948792, 0.1460537314414978, 0.1466517448425293, 0.14656147360801697, 0.14458462595939636, 0.14364296197891235, 0.14343614876270294, 0.143773153424263, 0.14306378364562988, 0.14368122816085815, 0.14289377629756927, 0.14294761419296265, 0.14212094247341156, 0.14148233830928802, 0.1411440074443817, 0.1430259495973587, 0.1409331113100052, 0.14006204903125763, 0.14040496945381165, 0.13973374664783478, 0.13832570612430573, 0.13811369240283966, 0.13949845731258392, 0.13814102113246918, 0.13780753314495087, 0.1365637481212616, 0.1363925337791443, 0.13704480230808258], "moving_avg_accuracy_train": [0.054301903810215935, 0.11423480073654944, 0.17384443654975312, 0.2303526813291632, 0.28245347946262744, 0.3321015719291093, 0.3782753115846664, 0.42104976686030826, 0.46077402259398953, 0.4975209082983226, 0.5310976266750702, 0.562750893492613, 0.5919850261521649, 0.6182420868790488, 0.642891820662997, 0.6656649518638162, 0.6864188254135919, 0.7055738229190673, 0.7234036921787018, 0.7399389639088291, 0.7550366589146792, 0.7692755539889735, 0.7817907956035037, 0.7936473178565532, 0.8044435296270994, 0.8144975551885221, 0.823522674363976, 0.8323939434897323, 0.8404848623040573, 0.848059621938131, 0.8548909646481108, 0.8612205346942354, 0.8673123148869105, 0.8729855432138802, 0.8782495948760194, 0.8831220279052594, 0.8875444560613467, 0.8916873297208543, 0.8956158067143928, 0.8993257861204729, 0.902739424689581, 0.905846468487465, 0.9090007366269521, 0.9112769640382233, 0.9140554851904641, 0.9167236009905853, 0.9191459396964362, 0.92148876889955, 0.9236855266418393, 0.9257998284384805, 0.9276794125185435, 0.9295802294858199, 0.931144552479006, 0.9325106265431208, 0.9338400025019962, 0.9352828345411561, 0.9368695936823248, 0.9385419617296515, 0.9400261305841412, 0.9411363791674768, 0.9424146207496218, 0.9439672168199623, 0.9454435722939738, 0.9466399029337164, 0.9474956753237611, 0.9486656879235833, 0.9494769198360514, 0.9503488626346538, 0.9512870349260057, 0.9518570584775173, 0.9528071355524308, 0.953297264703214, 0.9540730581722152, 0.9548945772788586, 0.9554362707772094, 0.9559982357364486, 0.9564854030092877, 0.9570005474167385, 0.9576455389905869, 0.958195768423708, 0.9584793863718504, 0.9590904263418544, 0.9597449579624677, 0.9602038641365052, 0.9606913205038624, 0.9613042731999232, 0.961993222552596, 0.9624529137997819, 0.9629524861841079, 0.963660264945496, 0.964141480860507, 0.9645931403256744, 0.9648090797884005, 0.9649824629167494, 0.9652780527096536, 0.965458053017315, 0.9658199800430106, 0.9661874949470706, 0.9666602005845617, 0.96728076791421, 0.9676463272085217, 0.9677338034877618, 0.9681378727283175, 0.9686596451638653, 0.9690501852963344, 0.9695017249120036, 0.9698126352696405, 0.9702576122546274, 0.9705696277398974, 0.9708899692064024, 0.9712179482512937, 0.9713223950916774, 0.9717372317349183, 0.9720245542078827, 0.9721041079752174, 0.9723826446098662, 0.9726031366953451, 0.9728666476901241, 0.9729085671830626, 0.9726927453600128, 0.9729611382347257, 0.9729820189779752, 0.9731936548028152, 0.9731563706082941, 0.9736575269617781, 0.9740946167870566, 0.9740021496750729, 0.9738398381659451, 0.9738355558362922, 0.9740084490979473, 0.9744499381905519, 0.9744776878596382, 0.9745747061260922, 0.974866635661139, 0.9750782550176902, 0.9750896759802531, 0.975237066528684, 0.9754790000163195, 0.9760175746420869, 0.975993228411267, 0.97627118890232, 0.9759957976156779, 0.9762199867148521, 0.9761613762862609, 0.9763342023838714, 0.9762014274193398, 0.9765539351595948, 0.9768245810031776, 0.9770495610719259, 0.9771893362135797, 0.9773663231636964, 0.9779742569925833, 0.9782144417469056, 0.9784329331746053, 0.9783786396322002, 0.9785737718737605, 0.9788051944625933, 0.9789553821211235, 0.9792765268697439, 0.9791750763387772, 0.9791998480572897, 0.9793175818515976, 0.9794631779426929, 0.979514979121061, 0.9797082648006862, 0.9796612967266253, 0.979784074976628, 0.9799339947849361, 0.9800131911386223, 0.9802402167783592, 0.9805002713279134, 0.98054369426895, 0.9806734917682732, 0.980736831095045, 0.9811285858200735, 0.9809859083761705, 0.9810086693980957, 0.9809733146975811, 0.9810880158909367, 0.9813307558935283, 0.9814562519922984, 0.9812227873573911, 0.981447399915718, 0.9817007765896594, 0.981919442903331, 0.9815420389761393, 0.9816719473547344, 0.981728447075241, 0.9816793154248874, 0.9818164224978934, 0.981558602605293, 0.9814845666745441, 0.9816342092249745, 0.9820246178405907, 0.9817807835482261, 0.9814382079446493, 0.9812971203716222, 0.9811353364213924, 0.9814129079495189, 0.9816534217295947, 0.9817697945863971, 0.9817629951122997, 0.9821428142391742, 0.9822802186022168, 0.9824735288467847, 0.9827381528216486, 0.9819859812502626, 0.9823388514657216], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05454439829631023, 0.11464656967714607, 0.17337425434158504, 0.22891074645260723, 0.27985397385930433, 0.327841168011401, 0.3723063805589055, 0.4130961738377288, 0.4506014743285794, 0.48514058329632387, 0.5166652344922938, 0.5457342508585765, 0.5723246411906405, 0.5963292346769982, 0.618534601871949, 0.6387594549377662, 0.6566759134349535, 0.673581093646428, 0.6890398964617551, 0.7032671132820706, 0.7159292420799931, 0.7281705316803522, 0.7388183928571964, 0.7486731111298351, 0.7575545646064601, 0.7656821500791725, 0.7730387456416619, 0.7801723769604023, 0.7858886082967416, 0.7915245862754259, 0.7965237242687416, 0.8013556268324548, 0.8057643447873869, 0.8098319062141452, 0.8134947705155471, 0.8166661895483297, 0.8195163486431956, 0.8220510477867826, 0.8243312475073513, 0.8263213625909535, 0.8284583810758339, 0.8302534503477685, 0.8322159571108079, 0.8329730005657662, 0.8342352767045962, 0.8353305861011546, 0.8364415233965362, 0.8377353652210392, 0.8391582295366611, 0.8400105318183113, 0.8408854081357271, 0.8414866028266725, 0.842175191932183, 0.8425263674396425, 0.8430774475160849, 0.843475763334883, 0.844006175517961, 0.8447754857240715, 0.8451026834807306, 0.8454784926458352, 0.846431190491568, 0.8472428789537064, 0.8477251399099923, 0.8481062286110113, 0.8481471211866571, 0.8485023368258982, 0.8485667127536246, 0.8490305716458073, 0.8493392108761815, 0.84919679957772, 0.8493748346990143, 0.8492878371572002, 0.8495178036767965, 0.8498346368256832, 0.8496203278870907, 0.8499055830784268, 0.84984287092081, 0.8498942342428857, 0.8500167919462327, 0.8501260643705854, 0.8499670323875931, 0.8501911440490597, 0.8507631735165182, 0.850896493542502, 0.8508567606509776, 0.8508168830139672, 0.8506986324478867, 0.8505830884331432, 0.8504149751376452, 0.8506156180606276, 0.8507992852172908, 0.8509269350558779, 0.8508607734591757, 0.8505875314389358, 0.8506672325024971, 0.8502211206039041, 0.8504849766346282, 0.8506227317949606, 0.8507924510382808, 0.8507234127774498, 0.8509186555076114, 0.8507749321349376, 0.8505530723928293, 0.8507276985590434, 0.8511341502769343, 0.851719683385536, 0.8515070347476602, 0.8515353775360719, 0.8512445327418021, 0.8512432381178479, 0.8510426424216504, 0.8507359179479341, 0.8512381744682763, 0.8512598707168553, 0.8510179021410281, 0.8514288660684916, 0.8513083933358894, 0.8517991419164571, 0.8519387283836969, 0.8517835944854627, 0.8515432292010731, 0.8512648357802127, 0.851909513017327, 0.8517796557009105, 0.852165331414705, 0.8521899092013218, 0.8517878716415058, 0.8514605999141022, 0.8511538483281889, 0.8511005869893459, 0.8511075098886793, 0.8511097695361066, 0.8511697498490621, 0.8511494604345625, 0.8513062164336515, 0.8512122747131026, 0.8511103725900604, 0.8513167769726206, 0.8518087462068344, 0.851760148741648, 0.8523074960662783, 0.8520147406238071, 0.8525436882481734, 0.8526911807750127, 0.8526499370856891, 0.852673852921548, 0.8532996987570286, 0.8531843667295937, 0.8533002944674024, 0.8532978546761592, 0.8534442022563594, 0.8537712275785397, 0.8539047999449327, 0.8539995715035268, 0.8534836328490325, 0.8534252086172166, 0.8538853221210823, 0.8543991395418806, 0.854465802677301, 0.8545034444539986, 0.8548120537924843, 0.8548252184715942, 0.8549144269049317, 0.8548176390054777, 0.8552138106753365, 0.8551166460046402, 0.8553862902332424, 0.8551630438341652, 0.8550963994187456, 0.8551299576602295, 0.8549394040064053, 0.8546824564992136, 0.8549049229163103, 0.8544805250806281, 0.8547018591030623, 0.8547382502823645, 0.8546886416509654, 0.854419119776908, 0.8545520266056931, 0.8549534339790094, 0.8548446563755362, 0.8547376380271392, 0.8547145637010819, 0.8545309873667417, 0.8546485894019049, 0.8540474529297114, 0.8541463432730354, 0.8540398850093613, 0.8540946749816933, 0.8543434164914305, 0.8543353502564441, 0.8541704287473659, 0.854188779792057, 0.8541920591923694, 0.8540749993574698, 0.8538343386536505, 0.8540104280375325, 0.8538535846878454, 0.8537296331750097, 0.8540657660077347, 0.8541312044201389, 0.8545736645033509, 0.8549799675748532, 0.8550822331950034, 0.855438708906, 0.8553006703290296, 0.8551592281078736, 0.8553116623189235], "moving_var_accuracy_train": [0.0265382708167255, 0.0562120129408956, 0.082570589782851, 0.10305216635701342, 0.11717738821660802, 0.12764404716499017, 0.13406777055250368, 0.13712787971440432, 0.13761724018531807, 0.1360085186474921, 0.13255423093530572, 0.12831617154377814, 0.12317626500060685, 0.1170635376426836, 0.11082566825899089, 0.10441064097529931, 0.09784608628365007, 0.091363703020198, 0.0850884708585191, 0.07904036067336949, 0.07318778815643961, 0.06769372453722654, 0.06233403353753448, 0.05736582426321453, 0.0526782655342434, 0.04832018985072671, 0.04422124585083434, 0.04050741600886529, 0.03704584111331875, 0.03385764985361282, 0.030891890057242292, 0.028163272164237255, 0.025680933021056337, 0.02340250939580009, 0.021311650615335104, 0.01939415098642146, 0.01763075672494109, 0.016022151671874763, 0.014558832888086131, 0.013226825124019365, 0.012009018966141953, 0.010895000559985477, 0.009895045171448983, 0.008952171555354486, 0.008126436017960084, 0.0073778619934697824, 0.0066928853173755815, 0.0060729964237126914, 0.005509128482546197, 0.004998448083077095, 0.004530398801595621, 0.004109876867723829, 0.003720913138794545, 0.0033656172500529176, 0.0030449606890079494, 0.002759200498746192, 0.002505940690020313, 0.002280517954989757, 0.002072290974188515, 0.0018761557440208519, 0.0017032452834996852, 0.0015546157461684485, 0.001418770800922398, 0.0012897745838264388, 0.001167388242895861, 0.0010629697839599575, 0.0009625956805062229, 0.0008731786706519106, 0.0007937823088210637, 0.000717328419582459, 0.0006537193956586982, 0.0005905094953528549, 0.0005368752453764742, 0.0004892617636220479, 0.0004429764738752425, 0.00040152106802643275, 0.00036350494878931866, 0.00032954281775513644, 0.0003003326631526429, 0.00027302416869903333, 0.00024644570409370606, 0.00022516146228881748, 0.0002065010208413808, 0.00018774627264637008, 0.00017111016877242714, 0.00015738055096365812, 0.0001459143567622277, 0.00013322476547065936, 0.0001221484420282238, 0.0001144421548010492, 0.00010508205813268436, 9.640981877169417e-05, 8.718850555858639e-05, 7.87402103854924e-05, 7.165254927796576e-05, 6.477889534699313e-05, 5.947992635965357e-05, 5.4747538566044046e-05, 5.128384028688313e-05, 4.9621390553836225e-05, 4.586195387737193e-05, 4.134462738450198e-05, 3.867961220652099e-05, 3.726186925634557e-05, 3.490837668633216e-05, 3.325253123836774e-05, 3.0797265368903836e-05, 2.9499579486525456e-05, 2.7425804505307427e-05, 2.560679195123928e-05, 2.4014245041105846e-05, 2.1711002819190593e-05, 2.108870750244993e-05, 1.9722824583438482e-05, 1.7807501342168867e-05, 1.6724995119525324e-05, 1.5490046445402143e-05, 1.456598420018617e-05, 1.3125200975161542e-05, 1.2231892411385876e-05, 1.1657015787017725e-05, 1.0495238257263808e-05, 9.848821932738735e-06, 8.876450739914634e-06, 1.024922488165958e-05, 1.0943730031751108e-05, 9.926308529763296e-06, 9.17078291074509e-06, 8.25386966479588e-06, 7.697511417647678e-06, 8.681973845883097e-06, 7.820706858504327e-06, 7.123349068885641e-06, 7.178019842890538e-06, 6.863262627206158e-06, 6.178110309958299e-06, 5.755815042863451e-06, 5.707019850532322e-06, 7.746881513164159e-06, 6.977528012444004e-06, 6.9751335224778255e-06, 6.960183417055627e-06, 6.716511845046864e-06, 6.075777301598923e-06, 5.737019311576612e-06, 5.321980101275931e-06, 5.9081374536057e-06, 5.976566262082907e-06, 5.834453917880595e-06, 5.426842338111726e-06, 5.1660775289051955e-06, 7.975721638760549e-06, 7.697347920764382e-06, 7.357259664491886e-06, 6.648063796764805e-06, 6.325946742355623e-06, 6.1753597997191155e-06, 5.760830814720437e-06, 6.112953279346522e-06, 5.594287843512566e-06, 5.0403818015038554e-06, 4.661094838252796e-06, 4.385769350107657e-06, 3.971342673819918e-06, 3.9104425919714255e-06, 3.539252332603159e-06, 3.3209975874062856e-06, 3.19118136897372e-06, 2.9285117940110028e-06, 3.099526384491399e-06, 3.39822906473712e-06, 3.0753761245378524e-06, 2.919465029558973e-06, 2.6636253594462178e-06, 3.7785087047413526e-06, 3.5838695112551214e-06, 3.230145137201333e-06, 2.918380217117515e-06, 2.74494946922053e-06, 3.000758902021321e-06, 2.8424264490778345e-06, 3.0487354259412033e-06, 3.197919095570741e-06, 3.4559248360917024e-06, 3.54066696309493e-06, 4.468503785122992e-06, 4.173539088073324e-06, 3.7849151450219404e-06, 3.428148902117917e-06, 3.2545191571203353e-06, 3.5273071145923186e-06, 3.2239082745098413e-06, 3.103053483152745e-06, 4.16451811916409e-06, 4.283162766444734e-06, 4.911068887294068e-06, 4.5991133279288406e-06, 4.374768414103475e-06, 4.630705151731678e-06, 4.688256542215662e-06, 4.341314664197343e-06, 3.907599293409625e-06, 4.815202486326069e-06, 4.5036018685420655e-06, 4.389561337582012e-06, 4.580837836478249e-06, 9.214612708041472e-06, 9.413807937861082e-06], "duration": 219950.952518, "accuracy_train": [0.5430190381021595, 0.6536308730735512, 0.7103311588685862, 0.7389268843438538, 0.7513606626638059, 0.7789344041274455, 0.7938389684846806, 0.8060198643410853, 0.8182923241971208, 0.8282428796373201, 0.8332880920657992, 0.8476302948504982, 0.8550922200881322, 0.854555633421004, 0.8647394247185308, 0.8706231326711886, 0.8732036873615725, 0.8779688004683462, 0.8838725155154117, 0.888756409479974, 0.8909159139673312, 0.8974256096576227, 0.8944279701342747, 0.9003560181339978, 0.9016094355620154, 0.9049837852413253, 0.9047487469430602, 0.9122353656215393, 0.9133031316329827, 0.9162324586447952, 0.9163730490379292, 0.9181866651093578, 0.9221383366209857, 0.9240445981566077, 0.9256260598352714, 0.9269739251684201, 0.9273463094661315, 0.9289731926564231, 0.9309720996562385, 0.9327156007751938, 0.9334621718115541, 0.9338098626684201, 0.9373891498823367, 0.931763010739664, 0.9390621755606312, 0.9407366431916758, 0.9409469880490956, 0.9425742317275747, 0.9434563463224437, 0.9448285446082503, 0.9445956692391103, 0.9466875821913067, 0.9452234594176817, 0.944805293120155, 0.9458043861318751, 0.9482683228935955, 0.9511504259528424, 0.9535932741555924, 0.9533836502745479, 0.9511286164174971, 0.9539187949889257, 0.9579405814530271, 0.9587307715600776, 0.957406878691399, 0.9551976268341639, 0.9591958013219823, 0.9567780070482651, 0.9581963478220746, 0.9597305855481728, 0.9569872704411223, 0.9613578292266519, 0.9577084270602622, 0.9610551993932264, 0.962288249238649, 0.9603115122623662, 0.9610559203696014, 0.9608699084648394, 0.9616368470837948, 0.9634504631552234, 0.9631478333217978, 0.9610319479051311, 0.96458978607189, 0.9656357425479882, 0.9643340197028424, 0.9650784278100776, 0.9668208474644703, 0.9681937667266519, 0.9665901350244556, 0.9674486376430418, 0.9700302737979882, 0.9684724240956073, 0.9686580755121816, 0.9667525349529347, 0.96654291107189, 0.9679383608457919, 0.967078055786268, 0.969077323274271, 0.9694951290836102, 0.9709145513219823, 0.9728658738810447, 0.9709363608573275, 0.9685210900009228, 0.9717744958933187, 0.9733555970837948, 0.9725650464885567, 0.9735655814530271, 0.9726108284883721, 0.9742624051195091, 0.9733777671073275, 0.9737730424049464, 0.9741697596553157, 0.9722624166551311, 0.9754707615240864, 0.9746104564645626, 0.9728200918812293, 0.9748894743217055, 0.9745875654646549, 0.9752382466431341, 0.9732858426195091, 0.9707503489525655, 0.9753766741071429, 0.9731699456672205, 0.975098377226375, 0.9728208128576044, 0.9781679341431341, 0.9780284252145626, 0.9731699456672205, 0.9723790345837948, 0.9737970148694168, 0.9755644884528424, 0.9784233400239941, 0.9747274348814139, 0.9754478705241787, 0.9774940014765596, 0.9769828292266519, 0.9751924646433187, 0.9765635814645626, 0.9776564014050388, 0.9808647462739941, 0.9757741123338871, 0.9787728333217978, 0.9735172760358989, 0.9782376886074198, 0.9756338824289406, 0.9778896372623662, 0.9750064527385567, 0.97972650482189, 0.9792603935954227, 0.9790743816906607, 0.9784473124884644, 0.9789592057147471, 0.9834456614525655, 0.9803761045358066, 0.9803993560239018, 0.9778899977505537, 0.9803299620478036, 0.9808879977620893, 0.9803070710478959, 0.9821668296073275, 0.9782620215600776, 0.9794227935239018, 0.9803771860003692, 0.9807735427625508, 0.979981189726375, 0.9814478359173128, 0.9792385840600776, 0.9808890792266519, 0.9812832730597084, 0.9807259583217978, 0.9822834475359912, 0.9828407622739018, 0.9809345007382798, 0.9818416692621816, 0.9813068850359912, 0.9846543783453304, 0.9797018113810447, 0.9812135185954227, 0.9806551223929494, 0.982120326631137, 0.9835154159168512, 0.9825857168812293, 0.9791216056432264, 0.9834689129406607, 0.9839811666551311, 0.983887439726375, 0.9781454036314139, 0.9828411227620893, 0.9822369445598007, 0.9812371305717055, 0.9830503861549464, 0.97923822357189, 0.9808182432978036, 0.9829809921788483, 0.985538295381137, 0.9795862749169435, 0.9783550275124585, 0.980027332214378, 0.9796792808693245, 0.9839110517026578, 0.9838180457502769, 0.9828171502976191, 0.9817017998454227, 0.9855611863810447, 0.9835168578696014, 0.9842133210478959, 0.9851197685954227, 0.9752164371077889, 0.9855146834048542], "end": "2016-02-06 00:45:16.035000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0], "moving_var_accuracy_valid": [0.026775822469558775, 0.05660867926482516, 0.08198827985275471, 0.10154816947145794, 0.11475026429180624, 0.1240001750859448, 0.12939455371940306, 0.131429363469025, 0.13094625520630349, 0.12858818012024467, 0.12467359480546839, 0.11981130473745043, 0.11419361398580911, 0.10796023716323576, 0.10160191843727555, 0.09512312872735303, 0.08849981122035062, 0.08222189616015745, 0.07615047780449018, 0.07035715331011157, 0.064764403530357, 0.059636605717040055, 0.05469333767410818, 0.05009804315679509, 0.045798160783832656, 0.041812863515995606, 0.03811865264882639, 0.03476478564606918, 0.031582384787677185, 0.028710024538895394, 0.026063944511091782, 0.023667675601449566, 0.021475839187359888, 0.01947716077226797, 0.01765019386905552, 0.015975695570283433, 0.014451236675049507, 0.013063935305281067, 0.011804335571644094, 0.010659547036893514, 0.009634693965246655, 0.008700225031941386, 0.007864865423902027, 0.0070835369146460825, 0.006389523292637411, 0.005761368287441373, 0.005196339093765662, 0.0046917714243905955, 0.0042408151676975704, 0.003823271423541568, 0.003447832958324388, 0.003106302577999737, 0.0027999397148058126, 0.0025210556614585857, 0.002271683298568593, 0.0020459428681352775, 0.0018438806150773675, 0.0016648190973086632, 0.0014993007129254618, 0.0013506417343901054, 0.0012237462596184692, 0.0011073011770927393, 0.0009986642400530864, 0.0009001048734301757, 0.0008101094359118448, 0.0007302340956739122, 0.0006572479844471567, 0.0005934596716491539, 0.0005349710280549717, 0.00048165645405084007, 0.00043377607718548443, 0.00039046658661747124, 0.00035189588935694103, 0.00031760974961934766, 0.00028626212954785835, 0.00025836825131073034, 0.00023256682151207386, 0.00020933388307855827, 0.0001885356782865496, 0.00016978957462240976, 0.00015303823770469887, 0.00013818644826547684, 0.00012731276284369677, 0.00011474145462328179, 0.00010328151748497354, 9.296767776987799e-05, 8.37967587602953e-05, 7.553723665835316e-05, 6.823787171362678e-05, 6.177640278515064e-05, 5.5902365126566095e-05, 5.045877894553153e-05, 4.54522972628821e-05, 4.1579018351216694e-05, 3.7478286851890144e-05, 3.552160060129809e-05, 3.2596020585713334e-05, 2.9507206884925753e-05, 2.681572779041184e-05, 2.4177051544497907e-05, 2.21024239031769e-05, 2.0078089183533767e-05, 1.8513275971695312e-05, 1.6936397055865334e-05, 1.6729584341066543e-05, 1.8142267098379388e-05, 1.67350153772557e-05, 1.5068743662424682e-05, 1.4323185545367023e-05, 1.289088207529097e-05, 1.1963941567758276e-05, 1.161426653597102e-05, 1.2723194392409506e-05, 1.145511149799017e-05, 1.08365394733813e-05, 1.1272907673128907e-05, 1.0276240019521725e-05, 1.1416123541532351e-05, 1.0449870623907583e-05, 9.621482298948732e-06, 9.179313298511286e-06, 8.958908039664972e-06, 1.1803495896178035e-05, 1.077491261020211e-05, 1.1036133155079897e-05, 9.93795644792676e-06, 1.0398868598658612e-05, 1.0322942790812357e-05, 1.0137517330873657e-05, 9.149296529724412e-06, 8.234798215568605e-06, 7.411364348070204e-06, 6.702606654743466e-06, 6.0360509323357435e-06, 5.653597828355489e-06, 5.167663467257083e-06, 4.744353504655918e-06, 4.653343076450959e-06, 6.366312315522458e-06, 5.750936506573155e-06, 7.87214469993624e-06, 7.856281971811211e-06, 9.588724078534585e-06, 8.825638079942065e-06, 7.95838364912902e-06, 7.167692989059545e-06, 9.976070778250954e-06, 9.098176989395821e-06, 8.30931245399722e-06, 7.478434781829294e-06, 6.923349831720876e-06, 7.193524900673129e-06, 6.634746604180272e-06, 6.052106778627399e-06, 7.842630357576697e-06, 7.089087839588531e-06, 8.285518983585746e-06, 9.833042162470481e-06, 8.889733708840097e-06, 8.013512468132665e-06, 8.069318735524514e-06, 7.263946640956687e-06, 6.6091752780679054e-06, 6.032568827587591e-06, 6.841879872817644e-06, 6.2426606446195685e-06, 6.272766670324148e-06, 6.094040595600408e-06, 5.52460983899987e-06, 4.982284255243288e-06, 4.810852084590584e-06, 4.923965069199971e-06, 4.876990322902616e-06, 6.010312996998261e-06, 5.850180442680447e-06, 5.2770812597914444e-06, 4.771522280595925e-06, 4.948148417894937e-06, 4.612311602344868e-06, 5.601231356284087e-06, 5.147601323812079e-06, 4.735917533473451e-06, 4.2671176008330904e-06, 4.1437082755175645e-06, 3.853809596036498e-06, 6.72071416024416e-06, 6.136656444244472e-06, 5.624991056960416e-06, 5.089509420877581e-06, 5.137409526787341e-06, 4.624254151430314e-06, 4.406620673696776e-06, 3.9689894538984e-06, 3.572187298706239e-06, 3.3382956133560867e-06, 3.5257242212855294e-06, 3.452219039200231e-06, 3.3283956623494764e-06, 3.133831893922975e-06, 3.837316235651871e-06, 3.492124284448583e-06, 4.90485018312757e-06, 5.9001048380243255e-06, 5.404218667804274e-06, 6.007471193798893e-06, 5.5782159130073444e-06, 5.200447439036429e-06, 4.88952839341869e-06], "accuracy_test": 0.7381397480867347, "start": "2016-02-03 11:39:25.082000", "learning_rate_per_epoch": [0.00048533850349485874, 0.0003431861405260861, 0.00028021031175740063, 0.00024266925174742937, 0.0002170499792555347, 0.00019813861581496894, 0.00018344071577303112, 0.00017159307026304305, 0.00016177950601559132, 0.00015347750741057098, 0.00014633506361860782, 0.00014010515587870032, 0.00013460867921821773, 0.0001297121780226007, 0.00012531386164482683, 0.00012133462587371469, 0.00011771187564590946, 0.00011439538502600044, 0.00011134429223602638, 0.00010852498962776735, 0.00010590954479994252, 0.00010347451461711898, 0.00010120007209479809, 9.906930790748447e-05, 9.706769924378023e-05, 9.518270962871611e-05, 9.340343967778608e-05, 9.172035788651556e-05, 9.012509690364823e-05, 8.861028618412092e-05, 8.716937009012327e-05, 8.579653513152152e-05, 8.448658627457917e-05, 8.323486690642312e-05, 8.203717879951e-05, 8.088975300779566e-05, 7.978916255524382e-05, 7.873230060795322e-05, 7.771635864628479e-05, 7.673875370528549e-05, 7.579714292660356e-05, 7.488935807486996e-05, 7.401342736557126e-05, 7.316753180930391e-05, 7.234999065985903e-05, 7.155926141422242e-05, 7.079389615682885e-05, 7.005257793935016e-05, 6.933406984899193e-05, 6.863722956040874e-05, 6.79609875078313e-05, 6.730433960910887e-05, 6.666636909358203e-05, 6.604620284633711e-05, 6.544303323607892e-05, 6.485608901130036e-05, 6.428465712815523e-05, 6.372806819854304e-05, 6.318568921415135e-05, 6.265693082241341e-05, 6.214122549863532e-05, 6.163804937386885e-05, 6.114690768299624e-05, 6.066731293685734e-05, 6.019883221597411e-05, 5.974103987682611e-05, 5.929353574174456e-05, 5.885593782295473e-05, 5.842788959853351e-05, 5.8009045460494235e-05, 5.759908526670188e-05, 5.719769251300022e-05, 5.68045761610847e-05, 5.641945608658716e-05, 5.604206307907589e-05, 5.567214611801319e-05, 5.530945782084018e-05, 5.495376535691321e-05, 5.460484680952504e-05, 5.426249481388368e-05, 5.392650200519711e-05, 5.359667193260975e-05, 5.3272822697181255e-05, 5.295477239997126e-05, 5.2642353693954647e-05, 5.2335395594127476e-05, 5.203374894335866e-05, 5.173725730855949e-05, 5.14457788085565e-05, 5.11591715621762e-05, 5.087730096420273e-05, 5.0600036047399044e-05, 5.032726039644331e-05, 5.005884304409847e-05, 4.9794678488979116e-05, 4.9534653953742236e-05, 4.927866029902361e-05, 4.902659202343784e-05, 4.877835453953594e-05, 4.853384962189011e-05, 4.8292986321030185e-05, 4.805567368748598e-05, 4.782182440976612e-05, 4.7591354814358056e-05, 4.736418850370683e-05, 4.7140241804299876e-05, 4.6919445594539866e-05, 4.670171983889304e-05, 4.6486999053740874e-05, 4.627521047950722e-05, 4.606629227055237e-05, 4.586017894325778e-05, 4.565680501400493e-05, 4.5456115913111717e-05, 4.5258049794938415e-05, 4.5062548451824114e-05, 4.486956095206551e-05, 4.4679032725980505e-05, 4.4490909203886986e-05, 4.430514309206046e-05, 4.4121683458797634e-05, 4.394048301037401e-05, 4.3761498091043904e-05, 4.358468504506163e-05, 4.34099965787027e-05, 4.323738903622143e-05, 4.306682967580855e-05, 4.289826756576076e-05, 4.273167360224761e-05, 4.256700412952341e-05, 4.240422276780009e-05, 4.2243293137289584e-05, 4.208418613416143e-05, 4.1926861740648746e-05, 4.1771287214942276e-05, 4.161743345321156e-05, 4.1465267713647336e-05, 4.131475725444034e-05, 4.1165876609738916e-05, 4.1018589399755e-05, 4.087287743459456e-05, 4.072870433446951e-05, 4.058604463352822e-05, 4.044487650389783e-05, 4.0305170841747895e-05, 4.016690218122676e-05, 4.003004505648278e-05, 3.989458127762191e-05, 3.9760478102834895e-05, 3.962772461818531e-05, 3.9496288081863895e-05, 3.936615030397661e-05, 3.923729309462942e-05, 3.910969098797068e-05, 3.898332579410635e-05, 3.8858179323142394e-05, 3.873422974720597e-05, 3.861145887640305e-05, 3.848984852083959e-05, 3.8369376852642745e-05, 3.82500329578761e-05, 3.813179500866681e-05, 3.8014644815120846e-05, 3.789857146330178e-05, 3.7783553125336766e-05, 3.766957524931058e-05, 3.755661964532919e-05, 3.744467903743498e-05, 3.7333731597755104e-05, 3.7223762774374336e-05, 3.7114761653356254e-05, 3.700671368278563e-05, 3.6899604310747236e-05, 3.679341898532584e-05, 3.668814315460622e-05, 3.6583765904651955e-05, 3.648027632152662e-05, 3.637765985331498e-05, 3.627590194810182e-05, 3.6174995329929516e-05, 3.6074925446882844e-05, 3.597568502300419e-05, 3.5877255868399516e-05, 3.577963070711121e-05, 3.568279498722404e-05, 3.558674507075921e-05, 3.5491466405801475e-05, 3.5396948078414425e-05, 3.5303182812640443e-05, 3.52101560565643e-05, 3.5117860534228384e-05, 3.502628896967508e-05, 3.4935430448967963e-05, 3.484527405817062e-05, 3.4755812521325424e-05, 3.4667034924495965e-05, 3.457893762970343e-05, 3.44915060850326e-05, 3.4404733014525846e-05, 3.431861478020437e-05, 3.423314046813175e-05, 3.4148299164371565e-05, 3.40640835929662e-05, 3.398049375391565e-05, 3.389751145732589e-05, 3.381513670319691e-05, 3.37333585775923e-05, 3.365216980455443e-05], "accuracy_train_first": 0.5430190381021595, "accuracy_train_last": 0.9855146834048542, "batch_size_eval": 1024, "accuracy_train_std": [0.018690290750124558, 0.016615697506049975, 0.019558007337542652, 0.01775431584666298, 0.01896865625044716, 0.016651654965395602, 0.016264802455170906, 0.015895046657289393, 0.014881283929457843, 0.016047857381156164, 0.015218963296286683, 0.015659101676478944, 0.015536357964811858, 0.016929660075763523, 0.015491703389788402, 0.015282264859482015, 0.015768266638698267, 0.015248348253128964, 0.015272027960245444, 0.014508079043040217, 0.01586984127908177, 0.015292682308895765, 0.015228343175774324, 0.01389676576608355, 0.015701064915328182, 0.014316760470803396, 0.014940556009029752, 0.014865865031680574, 0.015425902409244395, 0.014454701094608982, 0.014190024001472184, 0.01478102032718716, 0.01428651048992754, 0.014608544301822476, 0.013457766971349507, 0.01337368496653335, 0.014056386430419817, 0.012712024736260258, 0.014332080794101176, 0.013546545594303015, 0.012122312016813885, 0.012443035124486903, 0.013248732378500426, 0.011564062462487087, 0.013117932499973128, 0.012057773890321113, 0.011968620490761687, 0.012036031424815779, 0.01323464304254941, 0.011365253319446808, 0.011652680751939856, 0.012560769979034013, 0.012078731290130564, 0.011283027429668637, 0.012379759372513996, 0.011535336508867022, 0.011622624826493868, 0.011242830120636762, 0.011967997346860652, 0.013003558187111582, 0.011208349335221544, 0.010609369068890833, 0.010909726560125808, 0.010382370898560962, 0.010995190600348292, 0.01162793178291171, 0.011297193389727024, 0.01130527231338493, 0.01100021045506123, 0.011044882838165456, 0.011039164138474097, 0.011378370742185999, 0.010839364824654786, 0.01075999773868721, 0.011664759246983677, 0.01005161629337674, 0.010184488969804159, 0.010127589791682183, 0.009847296219070363, 0.010986520591788382, 0.010665373170721675, 0.00928920241724131, 0.010270890579416882, 0.009893363635106242, 0.009904206805914272, 0.009701280905962234, 0.009662531336293256, 0.009373486742688598, 0.009588651022910576, 0.009128433521498064, 0.009716192042371572, 0.009742402428748844, 0.008945286978933308, 0.00891970332948577, 0.008967726863025544, 0.007610238310195383, 0.00848501985722447, 0.009301138532417964, 0.009126685395544886, 0.008929860801559067, 0.008560310632419623, 0.008557949081316412, 0.007985772487556877, 0.00799245356153626, 0.00782183915766653, 0.007629629436554088, 0.008812228964277646, 0.008084156816258126, 0.009300642571261468, 0.009196296414187715, 0.007880652247129272, 0.008369096977684032, 0.007167034495303172, 0.007756880020855338, 0.008159198337243911, 0.008357902947210085, 0.00851776143721584, 0.007706341430999613, 0.007010324417842782, 0.008832249568689906, 0.008152523482706097, 0.007629226920066783, 0.008579674323901757, 0.007669656591169682, 0.007584156246715477, 0.006547577507451706, 0.006861406782854284, 0.008130687203267909, 0.0074953243349458794, 0.007028070495014416, 0.007722965974773788, 0.007107682025001067, 0.006525407413483921, 0.007378695727501503, 0.006429220132897847, 0.0072588433527462195, 0.006825427271891454, 0.007425021230653082, 0.006583976520040954, 0.007389601219945273, 0.005862913489633559, 0.00789322977252134, 0.006484944514870422, 0.006759126714909334, 0.006186625115972406, 0.007669565882973016, 0.006774700180418276, 0.007186814135837676, 0.006731112430718581, 0.006668697846064513, 0.006688529716867717, 0.005639613608322496, 0.00637920056554475, 0.006284466672072026, 0.006281367779833932, 0.006235132068141197, 0.006391774343878484, 0.005608210609891333, 0.0054100665283472755, 0.006993618629574641, 0.006744608936434259, 0.006455174483481419, 0.005483475832112835, 0.006508424048210927, 0.005712397292624419, 0.005981814268993021, 0.0058356404890699, 0.006055240335888699, 0.006208552466244463, 0.0059674177774378945, 0.004884599709955393, 0.006030186071394711, 0.005368541418515804, 0.005655010358175716, 0.005165278716494576, 0.006560772114277765, 0.00597177386072472, 0.005603907884742749, 0.005087471860948049, 0.005807223343993123, 0.005363555443638503, 0.005673451865160638, 0.005673492398687687, 0.004598209760782004, 0.005347316426913472, 0.0062853407194232444, 0.00546461359833276, 0.0060455530881771006, 0.006647840626284472, 0.005782277659148692, 0.006550756739429596, 0.005770763760886725, 0.0061934885382596205, 0.004553505466924198, 0.005783329002290926, 0.006064529980783189, 0.006359230596698756, 0.006128077313998933, 0.004937042674214858, 0.005231398342316274, 0.0061691854964307236, 0.006040709176840372, 0.004265977141908835, 0.004867258740664727, 0.004607129062512788, 0.0047420103581457445, 0.005758499182148978, 0.0051591967702448276], "accuracy_test_std": 0.011468668301245225, "error_valid": [0.45455601703689763, 0.34443388789533136, 0.2980765836784638, 0.2712608245481928, 0.26165697948042166, 0.24027408461972888, 0.2275067065135542, 0.21979568665286142, 0.2118508212537651, 0.20400743599397586, 0.19961290474397586, 0.19264460184487953, 0.1883618458207832, 0.1876294239457832, 0.18161709337349397, 0.17921686746987953, 0.18207596009036142, 0.17427228445030118, 0.17183087820030118, 0.1686879353350903, 0.17011159873870485, 0.16165786191641573, 0.16535085655120485, 0.16263442441641573, 0.16251235410391573, 0.16116958066641573, 0.16075189429593373, 0.15562494117093373, 0.16266530967620485, 0.15775161191641573, 0.15848403379141573, 0.1551572500941265, 0.15455719361822284, 0.15356004094503017, 0.15353945077183728, 0.1547910391566265, 0.15483221950301207, 0.15513665992093373, 0.15514695500753017, 0.1557676016566265, 0.15230845256024095, 0.1535909262048193, 0.15012148202183728, 0.1602136083396084, 0.15440423804593373, 0.1548116293298193, 0.15356004094503017, 0.15062005835843373, 0.14803599162274095, 0.15231874764683728, 0.15124070500753017, 0.1531026449548193, 0.15162750611822284, 0.15431305299322284, 0.15196283179593373, 0.15293939429593373, 0.15122011483433728, 0.14830072242093373, 0.15195253670933728, 0.15113922486822284, 0.14499452889683728, 0.14545192488704817, 0.14793451148343373, 0.1484639730798193, 0.15148484563253017, 0.14830072242093373, 0.15085390389683728, 0.14679469832454817, 0.14788303605045183, 0.15208490210843373, 0.14902284920933728, 0.1514951407191265, 0.14841249764683728, 0.14731386483433728, 0.15230845256024095, 0.14752712019954817, 0.15072153849774095, 0.14964349585843373, 0.1488801887236446, 0.14889048381024095, 0.15146425545933728, 0.14779185099774095, 0.1440885612763554, 0.1479036262236446, 0.14950083537274095, 0.1495420157191265, 0.15036562264683728, 0.15045680769954817, 0.15109804452183728, 0.14757859563253017, 0.14754771037274095, 0.14792421639683728, 0.1497346809111446, 0.15187164674322284, 0.14861545792545183, 0.15379388648343373, 0.1471403190888554, 0.14813747176204817, 0.14768007577183728, 0.14989793157003017, 0.14732415992093373, 0.1505185782191265, 0.1514436652861446, 0.14770066594503017, 0.14520778426204817, 0.14301051863704817, 0.15040680299322284, 0.14820953736822284, 0.1513730704066265, 0.14876841349774095, 0.1507627188441265, 0.15202460231551207, 0.1442415168486446, 0.14854486304593373, 0.15115981504141573, 0.14487245858433728, 0.14977586125753017, 0.14378412085843373, 0.1468049934111446, 0.1496126105986446, 0.15062005835843373, 0.15124070500753017, 0.1422883918486446, 0.14938906014683728, 0.1443635871611446, 0.1475888907191265, 0.15183046639683728, 0.15148484563253017, 0.15160691594503017, 0.14937876506024095, 0.1488301840173193, 0.14886989363704817, 0.14829042733433728, 0.14903314429593373, 0.14728297957454817, 0.14963320077183728, 0.1498067465173193, 0.14682558358433728, 0.14376353068524095, 0.14867722844503017, 0.14276637801204817, 0.15062005835843373, 0.14269578313253017, 0.14598138648343373, 0.14772125611822284, 0.14711090455572284, 0.1410676887236446, 0.1478536215173193, 0.1456563558923193, 0.14672410344503017, 0.14523866952183728, 0.14328554452183728, 0.14489304875753017, 0.1451474844691265, 0.15115981504141573, 0.1471006094691265, 0.1419736563441265, 0.14097650367093373, 0.14493422910391573, 0.14515777955572284, 0.1424104621611446, 0.14505629941641573, 0.14428269719503017, 0.1460534520896084, 0.14122064429593373, 0.1457578360316265, 0.14218691170933728, 0.14684617375753017, 0.14550340032003017, 0.14456801816641573, 0.14677557887801207, 0.14763007106551207, 0.1430928793298193, 0.14933905544051207, 0.14330613469503017, 0.14493422910391573, 0.1457578360316265, 0.1480065770896084, 0.14425181193524095, 0.1414338996611446, 0.14613434205572284, 0.14622552710843373, 0.14549310523343373, 0.1471211996423193, 0.1442929922816265, 0.15136277532003017, 0.14496364363704817, 0.14691823936370485, 0.1454122152673193, 0.14341790992093373, 0.14573724585843373, 0.14731386483433728, 0.14564606080572284, 0.1457784262048193, 0.1469785391566265, 0.14833160768072284, 0.14440476750753017, 0.14755800545933728, 0.14738593044051207, 0.14290903849774095, 0.14527984986822284, 0.14144419474774095, 0.1413633047816265, 0.1439973762236446, 0.14135300969503017, 0.14594167686370485, 0.14611375188253017, 0.1433164297816265], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.08024886231004338, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.00048533850735510366, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.7001593976950986e-05, "rotation_range": [0, 0], "momentum": 0.8220861699044633}, "accuracy_valid_max": 0.8590234963290663, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8566835702183735, "accuracy_valid_std": [0.02414968204928522, 0.021338662672581825, 0.016512421284969037, 0.01605477230206562, 0.01906357026963791, 0.011587468366363936, 0.011305868691589314, 0.010871058218034252, 0.012308238469744524, 0.010690667453466767, 0.010391316544929486, 0.008519378613394331, 0.009302554792865136, 0.00966759723985014, 0.011219253578101341, 0.01227189551195518, 0.012084264931014266, 0.00701035587580188, 0.007246097550876718, 0.0068023279739830135, 0.00848639089965625, 0.007850242252260674, 0.0098153419033326, 0.008859018552320515, 0.010530964433996847, 0.010826529395995658, 0.010936516355898799, 0.011890798642127507, 0.008567315417725313, 0.006917142368948967, 0.00944554006144871, 0.006420748418798746, 0.008312216975884643, 0.009445350446824544, 0.010048471105603881, 0.0076816277136599566, 0.00570774141235916, 0.012014864211525022, 0.009505063684886501, 0.008603271747577327, 0.011217933227487934, 0.00838744052297251, 0.00889408603164716, 0.009797636920438542, 0.009178994293509603, 0.011156394986047416, 0.010103922423238066, 0.008100647072767198, 0.009334887232029316, 0.011203903290867715, 0.007433991819325857, 0.008417353996453726, 0.009495713714311457, 0.007919795039896638, 0.009711586535014124, 0.008551279706397213, 0.008689586794376177, 0.009870453110541218, 0.011213057303815107, 0.007877244786832832, 0.008596581241204233, 0.010274701051316854, 0.010138756919594098, 0.006412200234022532, 0.010927075845480116, 0.01102298149760992, 0.011179327471336641, 0.014002332334884212, 0.014036805599617596, 0.011106793724344043, 0.011078137613622618, 0.010255012294080573, 0.010480215189843751, 0.010252605042651793, 0.011898640767628922, 0.012725333446947651, 0.013294234564497147, 0.010575677860696336, 0.010889264833689273, 0.011164544795372036, 0.012522853600952333, 0.01354414967850429, 0.011387640289715454, 0.011346322735430677, 0.013693010721348138, 0.009202405090682497, 0.013381852032021815, 0.014701842629245397, 0.011134464151024766, 0.011735618729648668, 0.011302920738265205, 0.012766277343241832, 0.011916548372919876, 0.011234833760342015, 0.014097453109132256, 0.015112078456059993, 0.01364290281926596, 0.01040164604516034, 0.011772311978162137, 0.012556594527935856, 0.01282157323439365, 0.014403414096606363, 0.014082170796183156, 0.009518059219395305, 0.012548220528018515, 0.01266377845397164, 0.014265921131001216, 0.013098851330110689, 0.01201671630819523, 0.011877475478639352, 0.013431118955518573, 0.010434711725710342, 0.014885132507441591, 0.014449031190025356, 0.008561888885179142, 0.011218531723422798, 0.012228894312077696, 0.011245201791761942, 0.015328360833557398, 0.012940598078008035, 0.014371007732464525, 0.012146284389973276, 0.011926194099388946, 0.013705714812174644, 0.013274195452708536, 0.011953299664017888, 0.012566939139998193, 0.012456475159454595, 0.010864900278263503, 0.013282257425186524, 0.009818102238661452, 0.015551530986079315, 0.011871290146688529, 0.014511271627207362, 0.01494720093765706, 0.013564089530171873, 0.008681163019656381, 0.011619510552400418, 0.011790142963901502, 0.013056503852178157, 0.012735452086431868, 0.011700753742767982, 0.008206593595256275, 0.009969908801346723, 0.013502760497373105, 0.010697649181756674, 0.012210509377426602, 0.012280320551108889, 0.012737640759648589, 0.010241579395337715, 0.010761760194967147, 0.010533254267789536, 0.00840156049304715, 0.009641649530347237, 0.012699700664607442, 0.010063949315780063, 0.010031357977178914, 0.011700730727296953, 0.015219774994740892, 0.011464319099631562, 0.009434160680132695, 0.011363427583037315, 0.01254274659178924, 0.009660567317870324, 0.011158696820056225, 0.010604708595067033, 0.010034301831267207, 0.011760711299117148, 0.011295510003832285, 0.011002597927671238, 0.010237315299841851, 0.010539686428642682, 0.008466395347148523, 0.012219227492824489, 0.010332818384027933, 0.012540133739751446, 0.009413712682896817, 0.011182602312906338, 0.008777990128659551, 0.009898194069696917, 0.010908769346809124, 0.01171559696396419, 0.011737551285405157, 0.00751207657304457, 0.013432288505993359, 0.012023642151898412, 0.01224176293104057, 0.01026240718408469, 0.01377238378157704, 0.011016464743582187, 0.012654210099835977, 0.015700258837606326, 0.010991141288631077, 0.01130242632375239, 0.009921612283246393, 0.007081411857412428, 0.008436702934001098, 0.01341609302959527, 0.007705266929385734, 0.011471742494828041, 0.010393119766329343, 0.011209648085984285, 0.008706037470552838, 0.013456349950333658, 0.010180886953059541, 0.012499291746280753, 0.006479719218445947, 0.009236279093808433], "accuracy_valid": [0.5454439829631024, 0.6555661121046686, 0.7019234163215362, 0.7287391754518072, 0.7383430205195783, 0.7597259153802711, 0.7724932934864458, 0.7802043133471386, 0.7881491787462349, 0.7959925640060241, 0.8003870952560241, 0.8073553981551205, 0.8116381541792168, 0.8123705760542168, 0.818382906626506, 0.8207831325301205, 0.8179240399096386, 0.8257277155496988, 0.8281691217996988, 0.8313120646649097, 0.8298884012612951, 0.8383421380835843, 0.8346491434487951, 0.8373655755835843, 0.8374876458960843, 0.8388304193335843, 0.8392481057040663, 0.8443750588290663, 0.8373346903237951, 0.8422483880835843, 0.8415159662085843, 0.8448427499058735, 0.8454428063817772, 0.8464399590549698, 0.8464605492281627, 0.8452089608433735, 0.8451677804969879, 0.8448633400790663, 0.8448530449924698, 0.8442323983433735, 0.847691547439759, 0.8464090737951807, 0.8498785179781627, 0.8397863916603916, 0.8455957619540663, 0.8451883706701807, 0.8464399590549698, 0.8493799416415663, 0.851964008377259, 0.8476812523531627, 0.8487592949924698, 0.8468973550451807, 0.8483724938817772, 0.8456869470067772, 0.8480371682040663, 0.8470606057040663, 0.8487798851656627, 0.8516992775790663, 0.8480474632906627, 0.8488607751317772, 0.8550054711031627, 0.8545480751129518, 0.8520654885165663, 0.8515360269201807, 0.8485151543674698, 0.8516992775790663, 0.8491460961031627, 0.8532053016754518, 0.8521169639495482, 0.8479150978915663, 0.8509771507906627, 0.8485048592808735, 0.8515875023531627, 0.8526861351656627, 0.847691547439759, 0.8524728798004518, 0.849278461502259, 0.8503565041415663, 0.8511198112763554, 0.851109516189759, 0.8485357445406627, 0.852208149002259, 0.8559114387236446, 0.8520963737763554, 0.850499164627259, 0.8504579842808735, 0.8496343773531627, 0.8495431923004518, 0.8489019554781627, 0.8524214043674698, 0.852452289627259, 0.8520757836031627, 0.8502653190888554, 0.8481283532567772, 0.8513845420745482, 0.8462061135165663, 0.8528596809111446, 0.8518625282379518, 0.8523199242281627, 0.8501020684299698, 0.8526758400790663, 0.8494814217808735, 0.8485563347138554, 0.8522993340549698, 0.8547922157379518, 0.8569894813629518, 0.8495931970067772, 0.8517904626317772, 0.8486269295933735, 0.851231586502259, 0.8492372811558735, 0.8479753976844879, 0.8557584831513554, 0.8514551369540663, 0.8488401849585843, 0.8551275414156627, 0.8502241387424698, 0.8562158791415663, 0.8531950065888554, 0.8503873894013554, 0.8493799416415663, 0.8487592949924698, 0.8577116081513554, 0.8506109398531627, 0.8556364128388554, 0.8524111092808735, 0.8481695336031627, 0.8485151543674698, 0.8483930840549698, 0.850621234939759, 0.8511698159826807, 0.8511301063629518, 0.8517095726656627, 0.8509668557040663, 0.8527170204254518, 0.8503667992281627, 0.8501932534826807, 0.8531744164156627, 0.856236469314759, 0.8513227715549698, 0.8572336219879518, 0.8493799416415663, 0.8573042168674698, 0.8540186135165663, 0.8522787438817772, 0.8528890954442772, 0.8589323112763554, 0.8521463784826807, 0.8543436441076807, 0.8532758965549698, 0.8547613304781627, 0.8567144554781627, 0.8551069512424698, 0.8548525155308735, 0.8488401849585843, 0.8528993905308735, 0.8580263436558735, 0.8590234963290663, 0.8550657708960843, 0.8548422204442772, 0.8575895378388554, 0.8549437005835843, 0.8557173028049698, 0.8539465479103916, 0.8587793557040663, 0.8542421639683735, 0.8578130882906627, 0.8531538262424698, 0.8544965996799698, 0.8554319818335843, 0.8532244211219879, 0.8523699289344879, 0.8569071206701807, 0.8506609445594879, 0.8566938653049698, 0.8550657708960843, 0.8542421639683735, 0.8519934229103916, 0.855748188064759, 0.8585661003388554, 0.8538656579442772, 0.8537744728915663, 0.8545068947665663, 0.8528788003576807, 0.8557070077183735, 0.8486372246799698, 0.8550363563629518, 0.8530817606362951, 0.8545877847326807, 0.8565820900790663, 0.8542627541415663, 0.8526861351656627, 0.8543539391942772, 0.8542215737951807, 0.8530214608433735, 0.8516683923192772, 0.8555952324924698, 0.8524419945406627, 0.8526140695594879, 0.857090961502259, 0.8547201501317772, 0.858555805252259, 0.8586366952183735, 0.8560026237763554, 0.8586469903049698, 0.8540583231362951, 0.8538862481174698, 0.8566835702183735], "seed": 321310085, "model": "residualv3", "loss_std": [0.27026769518852234, 0.18482574820518494, 0.17656832933425903, 0.1737125962972641, 0.16947445273399353, 0.1699647456407547, 0.16461418569087982, 0.1638781726360321, 0.16018031537532806, 0.15764065086841583, 0.15389391779899597, 0.15319712460041046, 0.15317484736442566, 0.15037304162979126, 0.14441916346549988, 0.14498460292816162, 0.1432468444108963, 0.14254680275917053, 0.13903136551380157, 0.13673610985279083, 0.1363903284072876, 0.13435891270637512, 0.13377569615840912, 0.12835532426834106, 0.12812979519367218, 0.1253224015235901, 0.1262245923280716, 0.12563064694404602, 0.12207882106304169, 0.12142056971788406, 0.12011836469173431, 0.11892429739236832, 0.11845763772726059, 0.11602712422609329, 0.11378637701272964, 0.11185970157384872, 0.11296617984771729, 0.10962218791246414, 0.10671194642782211, 0.10934517532587051, 0.10619951039552689, 0.10585889220237732, 0.10378557443618774, 0.10274071246385574, 0.1031143069267273, 0.10111217200756073, 0.09877247363328934, 0.09947164356708527, 0.09967426210641861, 0.09605135023593903, 0.09535734355449677, 0.09362644702196121, 0.09483510255813599, 0.09156742691993713, 0.09362992644309998, 0.09012828767299652, 0.090618796646595, 0.08864261209964752, 0.08901724219322205, 0.08700702339410782, 0.08552306145429611, 0.08255384862422943, 0.08378961682319641, 0.08439097553491592, 0.08151722699403763, 0.08273640275001526, 0.08331850916147232, 0.07842312753200531, 0.07865916192531586, 0.07979448139667511, 0.07627768069505692, 0.07699678093194962, 0.07574646919965744, 0.07402300089597702, 0.07084900885820389, 0.0739947035908699, 0.07307185977697372, 0.0740828663110733, 0.07050374150276184, 0.0709170326590538, 0.07228046655654907, 0.07053405046463013, 0.06977541744709015, 0.07195828855037689, 0.06893519312143326, 0.06814562529325485, 0.06830328702926636, 0.06591200083494186, 0.06458492577075958, 0.06492677330970764, 0.0646679475903511, 0.06359335035085678, 0.06223536655306816, 0.06414598226547241, 0.06412323564291, 0.063363216817379, 0.0604720376431942, 0.06215377524495125, 0.05985341966152191, 0.06026971712708473, 0.06027356535196304, 0.05866885557770729, 0.05945335328578949, 0.057635463774204254, 0.05785248056054115, 0.05676904693245888, 0.05627383664250374, 0.05578826367855072, 0.055585600435733795, 0.05539978668093681, 0.05371841788291931, 0.05493217706680298, 0.05494820699095726, 0.05424036830663681, 0.05391782522201538, 0.05098103731870651, 0.053344886749982834, 0.05256007984280586, 0.05091268941760063, 0.05300656333565712, 0.052465829998254776, 0.05158325657248497, 0.05173050984740257, 0.05140319839119911, 0.0511782169342041, 0.04982040077447891, 0.049162980169057846, 0.04961402714252472, 0.04974929243326187, 0.05019286647439003, 0.047411274164915085, 0.048295360058546066, 0.048152461647987366, 0.04601447656750679, 0.046434178948402405, 0.04813944548368454, 0.044748783111572266, 0.04530707746744156, 0.04640982672572136, 0.04587498679757118, 0.04386428743600845, 0.04306329786777496, 0.04390259087085724, 0.04569099470973015, 0.04245251417160034, 0.042870692908763885, 0.04497949406504631, 0.041686050593853, 0.04231497272849083, 0.04098533093929291, 0.04126889258623123, 0.04271809384226799, 0.04158772900700569, 0.041237324476242065, 0.04272457957267761, 0.0389908142387867, 0.041529033333063126, 0.040839117020368576, 0.039767589420080185, 0.04133499041199684, 0.039013899862766266, 0.03919418901205063, 0.037668224424123764, 0.03948011249303818, 0.0389280691742897, 0.03826669231057167, 0.0382639616727829, 0.03862486779689789, 0.03741683438420296, 0.03942577913403511, 0.03702540323138237, 0.03604649752378464, 0.03812253475189209, 0.037131670862436295, 0.037000395357608795, 0.036766089498996735, 0.03581593558192253, 0.03625386953353882, 0.03767935186624527, 0.037320882081985474, 0.03675944358110428, 0.034550853073596954, 0.035669729113578796, 0.035205163061618805, 0.03497086092829704, 0.0335729718208313, 0.03499336540699005, 0.0340481661260128, 0.03289918601512909, 0.03451712429523468, 0.034283097833395004, 0.03330261632800102, 0.032606419175863266, 0.03414588421583176, 0.032402921468019485, 0.03443913534283638, 0.03327513858675957, 0.033691853284835815, 0.03389416262507439, 0.03144436329603195, 0.031924039125442505, 0.03186626732349396, 0.03438638523221016, 0.032917216420173645, 0.032723601907491684, 0.03235336020588875, 0.0319836363196373, 0.03174208477139473]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:41 2016", "state": "available"}], "summary": "3ee17d67d11527d4c7340913cc0282d4"}