{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 16, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.8006129264831543, 1.5240811109542847, 1.4185835123062134, 1.3450566530227661, 1.282860279083252, 1.2292953729629517, 1.184511423110962, 1.145288109779358, 1.1085710525512695, 1.0764498710632324, 1.0513306856155396, 1.0208618640899658, 1.0013540983200073, 0.9792029857635498, 0.9578403234481812, 0.9399452805519104, 0.9230149984359741, 0.9066476225852966, 0.8926870822906494, 0.8781149983406067, 0.8643571138381958, 0.8507500290870667, 0.8397055268287659, 0.8307813405990601, 0.8207711577415466, 0.8085041642189026, 0.798622727394104, 0.7927567362785339, 0.7823205590248108, 0.7744187712669373, 0.7669737339019775, 0.7587019205093384, 0.7542639374732971, 0.7451761364936829, 0.7388240694999695, 0.7345930933952332, 0.728455662727356, 0.7257398962974548, 0.718630313873291, 0.7145599126815796, 0.7113937735557556, 0.7046432495117188, 0.7026077508926392, 0.6981192231178284, 0.6933042407035828, 0.6893075704574585, 0.6850223541259766, 0.6829615831375122, 0.6821275353431702, 0.6768075823783875, 0.6759223937988281, 0.6710250973701477, 0.6709663271903992, 0.66817307472229, 0.6631797552108765, 0.662159264087677, 0.6600576639175415, 0.6586143374443054, 0.65543532371521, 0.6534398794174194, 0.6556670069694519, 0.6539767980575562, 0.6508501768112183, 0.647917628288269, 0.6474042534828186, 0.6462467312812805, 0.6437809467315674, 0.6427058577537537, 0.6415771245956421, 0.6416952013969421, 0.6401745080947876, 0.6412215232849121, 0.6369256973266602, 0.6364985704421997, 0.6372500061988831, 0.6356223225593567, 0.6366336941719055, 0.6326690316200256, 0.6326137185096741, 0.6328582763671875, 0.6316495537757874, 0.6314088106155396, 0.6304154992103577, 0.6300171613693237, 0.6294982433319092, 0.6291047930717468, 0.6303861737251282, 0.6264855861663818, 0.6286094188690186, 0.6266692280769348, 0.6259366869926453, 0.6271131038665771, 0.6243213415145874, 0.6243218183517456, 0.626488447189331, 0.6263667941093445, 0.6239204406738281, 0.6264693140983582, 0.62259441614151, 0.624603271484375, 0.623150110244751, 0.622795045375824, 0.622802734375, 0.6226953268051147, 0.6213541626930237, 0.6243727803230286, 0.6205680966377258, 0.6216660141944885, 0.6218103170394897, 0.6213173270225525, 0.6232135891914368, 0.6226744055747986, 0.6235636472702026, 0.6212745904922485, 0.6208863854408264, 0.6215806603431702, 0.6209357976913452, 0.6207530498504639, 0.6202293634414673, 0.6196122169494629, 0.6192465424537659, 0.6203110814094543, 0.6218023896217346, 0.6213318109512329, 0.617898166179657, 0.6214506030082703, 0.6183755397796631, 0.6202461123466492, 0.6192506551742554, 0.6205602288246155, 0.6184669733047485, 0.6185491681098938, 0.6197163462638855, 0.6202669739723206, 0.619380533695221, 0.6184139847755432, 0.6193699836730957, 0.6188596487045288, 0.6196802854537964, 0.6170694828033447, 0.6187959909439087, 0.6188914179801941, 0.6196504831314087, 0.6207121014595032, 0.6183307766914368, 0.6185811161994934, 0.6215754151344299, 0.6182932257652283, 0.6177730560302734, 0.6192061305046082, 0.6185560822486877, 0.6218827962875366, 0.6193016171455383, 0.6192082166671753, 0.6178122758865356, 0.6193690896034241, 0.6190354228019714, 0.617571234703064, 0.6187925338745117, 0.6176016330718994, 0.6193481683731079, 0.6187838912010193, 0.6180387139320374, 0.6178261041641235, 0.6176164746284485, 0.6192716956138611, 0.6175568103790283, 0.6179044246673584, 0.618108332157135, 0.6193099617958069, 0.6211587190628052, 0.6181100010871887, 0.6185882687568665, 0.6172395348548889, 0.6172460317611694, 0.6194502711296082, 0.61684650182724, 0.61788409948349, 0.6183069944381714, 0.619516909122467, 0.6187965273857117, 0.6171721816062927, 0.6183568239212036, 0.6164965629577637, 0.6175740361213684, 0.6178668737411499, 0.6166764497756958, 0.6185586452484131, 0.6189228892326355, 0.6195853352546692, 0.6193834543228149, 0.6174233555793762, 0.6191858649253845, 0.6187143325805664, 0.6179802417755127, 0.6187915802001953], "moving_avg_accuracy_train": [0.04111443481220006, 0.08452899694882796, 0.12646360403112308, 0.16625466648353865, 0.20759550212039152, 0.24496726766139776, 0.2795153517398962, 0.31330533139494865, 0.3455296047165557, 0.37541471886307104, 0.4039782730472697, 0.4305295729285431, 0.4555321171180162, 0.47841104494686615, 0.4999784622487373, 0.5204005775525642, 0.5392989174128947, 0.5572119061740969, 0.5735961576305614, 0.5892160236008478, 0.6037879771539227, 0.6177834981158561, 0.6300237192137389, 0.6413747756792236, 0.6523998061862367, 0.6629080908984547, 0.672832793903709, 0.6820694408583916, 0.6906849448045753, 0.698884930390563, 0.7063674042096646, 0.713857195863495, 0.7203726131126936, 0.7269546712285653, 0.7331876241292414, 0.7389274179755458, 0.7443746475408096, 0.7490889252424319, 0.7540804009929211, 0.7584796511183428, 0.7628016273478707, 0.7669540756722844, 0.7707029770059419, 0.7742418935276161, 0.7778478063804654, 0.7812094574861435, 0.7842326183324443, 0.7869743173357632, 0.7896603022803891, 0.7921940182686661, 0.7947160699878497, 0.7970416840577248, 0.7991277612741838, 0.8010914775678618, 0.8028331013999922, 0.8045562757215101, 0.8062490748347135, 0.8079749901294814, 0.8095677332780781, 0.8110035633094433, 0.81240970658052, 0.813812419304251, 0.8150818722508562, 0.8162267771492479, 0.8174268913720768, 0.8185953137785661, 0.8195771394801207, 0.820484034099615, 0.8213605849797514, 0.8222542566635777, 0.823130712889754, 0.8239893140064173, 0.8248270149828059, 0.8255438155782407, 0.8262772557200753, 0.8269374599941826, 0.8275314635967853, 0.8280731864808314, 0.8287024990562163, 0.829296782159777, 0.8298176500113058, 0.8302701550360151, 0.8307192982856435, 0.8310584951412799, 0.8314474776684956, 0.8317743465037132, 0.8322032789399052, 0.8325777644860679, 0.8329147293799768, 0.8332318765797144, 0.8335244287011819, 0.83374590898075, 0.8340565599846683, 0.8343015209977832, 0.8345450571535881, 0.834778406879582, 0.8349999392305681, 0.8351644411143127, 0.8353845363739593, 0.8356198244885936, 0.8358525101310502, 0.8361200198806805, 0.836332948967271, 0.8364733958225741, 0.8366625770102041, 0.8368188891862138, 0.8369410050029653, 0.837067077133252, 0.8372364537683948, 0.8373911457911953, 0.8375674988950308, 0.8377193493885103, 0.8378210655028615, 0.8379498484355488, 0.8380494409844819, 0.8381320627832743, 0.8382342881390831, 0.8382937749247964, 0.8384031526521857, 0.8385573961782646, 0.8386379784850414, 0.8387199834004723, 0.8387774757338746, 0.8388710354636895, 0.8389342768324183, 0.8389982416083404, 0.8390093069304798, 0.8390888399405972, 0.8391488660032927, 0.8391401464906802, 0.8391881385495764, 0.8392383428978303, 0.8392718650183923, 0.8393135525244897, 0.8393162300966531, 0.8393442886461425, 0.8393718664894925, 0.8393780853580313, 0.8394394138135072, 0.8394947175698917, 0.8395258537113428, 0.8395259744529346, 0.8395748751965485, 0.8395979595265153, 0.8396303611675331, 0.8396735456349437, 0.8396518856889281, 0.8396324638351516, 0.8396870277310291, 0.8397803130646999, 0.839771227863804, 0.8397816523734738, 0.8397585544464807, 0.8397377302633683, 0.8397491793842722, 0.8397222812121333, 0.839758526726256, 0.8397424277104226, 0.8397627437306778, 0.8397577766608123, 0.839767329288428, 0.8397455915723021, 0.8397562906111313, 0.8398193260710591, 0.8398156762135841, 0.8398125355371315, 0.8398444780140109, 0.8398732262432023, 0.8399292544863608, 0.8399355020778226, 0.8398807431387281, 0.8398290628470959, 0.8398662919905886, 0.8398928227733035, 0.8399096529336807, 0.8399597854566194, 0.8399978932320169, 0.8400135890393985, 0.8399882237850987, 0.8399327708752581, 0.8399270050349638, 0.8400218692751458, 0.8400490823222528, 0.8401502679265447, 0.8401506902156547, 0.840148781175863, 0.8401167640078891, 0.8400810091591029, 0.8400906824737666, 0.8401250011426875, 0.8401582130935258, 0.8401346254266612, 0.8400784832455215, 0.8400419782729904, 0.8399904865584175, 0.8400278854212634], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03955842902861445, 0.08269701854292166, 0.12370592526355417, 0.16315726891942767, 0.20396971291415655, 0.24102035433923186, 0.2749824602362575, 0.3086470295364269, 0.3398830242955101, 0.3689649225907332, 0.39640213232714183, 0.42197864537454816, 0.4456597753306927, 0.46765741554988244, 0.4881409445144725, 0.507413405268221, 0.5249142228268657, 0.5420271456590136, 0.5577248334839254, 0.5725109027051865, 0.5858092464990503, 0.5983219247764796, 0.609717612569916, 0.6198272472090087, 0.6298343862399904, 0.6394542514563528, 0.648453927026079, 0.6568099826950825, 0.6643904384447761, 0.671393895070931, 0.6777977508104494, 0.6842112821582448, 0.6895806283400107, 0.6949400012646691, 0.6999343353343619, 0.7046632286081547, 0.7090799829781373, 0.7129675536750526, 0.7167949276373666, 0.7200585177520186, 0.7233640188100245, 0.7266339975295493, 0.7296237474848022, 0.7322545167969394, 0.7348297287091129, 0.7373071403449787, 0.7395988754821676, 0.7415759878868877, 0.7436330622439068, 0.7454997247224529, 0.7472397266007347, 0.7488667634474383, 0.7503809542431312, 0.7515422364072971, 0.7527146082108446, 0.7538429850215371, 0.7550050085261606, 0.7561749590101409, 0.7572380624596539, 0.7583301624166252, 0.7593751170428091, 0.7603033691751246, 0.761003489241799, 0.7615725621455558, 0.7621691474690273, 0.7627346063572902, 0.7631163015009286, 0.7636073410138629, 0.7641011932264826, 0.7646443459765, 0.7651280359082175, 0.7656152734977422, 0.7660649648509047, 0.7665449882735702, 0.7668030223904904, 0.7670484896356281, 0.7674413381024117, 0.7677115115210862, 0.7681123294954836, 0.7683876164536911, 0.7685865465910781, 0.7688510329334762, 0.7691856973829749, 0.7694513038024334, 0.7696669650261058, 0.769784729413932, 0.7698418892379755, 0.7698943625882743, 0.7698795239386336, 0.7701489898900262, 0.7702795869477104, 0.7704968395669454, 0.7706425092905972, 0.7708468542293839, 0.7709951730892016, 0.7711530741255375, 0.7712453274245802, 0.7713060003485378, 0.7713351624089401, 0.7714092068796424, 0.7714524623494342, 0.7714171205760871, 0.7713964905026652, 0.7715030822750644, 0.7714026728615639, 0.7715187944120039, 0.7715978602362402, 0.7715856292766221, 0.7715247637793062, 0.7717405985365412, 0.7718595486132335, 0.7718943910034162, 0.7718636844896709, 0.7719703259710502, 0.7720418892417916, 0.7720829116316185, 0.772131009305053, 0.772137676117394, 0.7721426467398413, 0.7721247652548633, 0.772230742230883, 0.7721409570232314, 0.7722839949334837, 0.7723374278478913, 0.7723844879621985, 0.7723281563064154, 0.7723517295123702, 0.7724228030313891, 0.7725233902922563, 0.7725762682246271, 0.7725994443012607, 0.772534853551481, 0.7725998216978389, 0.7726084353959014, 0.772712814465498, 0.7728088146454541, 0.7727843220175051, 0.7728375798571703, 0.7729333105292093, 0.7730916808128848, 0.7731864154518523, 0.7732096119620134, 0.773194897236068, 0.7731562104115576, 0.7731712499031578, 0.7733322993292577, 0.7732676652641783, 0.7732339086681069, 0.7732411783340523, 0.7733331702521531, 0.7732928631572842, 0.7732942373743117, 0.773270030598477, 0.7732726585627258, 0.7733004673017092, 0.7732624009932251, 0.7732902059804989, 0.7732806683926147, 0.773369740813519, 0.7733746047875134, 0.7734522245516084, 0.7734488401517939, 0.773396966066961, 0.7734367581180209, 0.7735478721687941, 0.7735125679620803, 0.7734421140649687, 0.7733410549551586, 0.7732765748361488, 0.7732175132203803, 0.7732742210474387, 0.7732886369980412, 0.7732405761973334, 0.7732461496016965, 0.7731036517819636, 0.7730252613778636, 0.7730900168665833, 0.773099468681431, 0.7731944540422035, 0.7732534677870796, 0.773306580157468, 0.7732078969158176, 0.7732289452795822, 0.7731136114632204, 0.7731705614520641, 0.7733184431833637, 0.7733172593977833, 0.7733161939907609, 0.7733264126470312, 0.7733234024064245, 0.7733573142836285, 0.7732779716918621, 0.7732177408818627, 0.7733364906076824, 0.7733558571248509, 0.7733153403600315], "moving_var_accuracy_train": [0.01521357074933984, 0.03065563152404198, 0.04341666981195607, 0.053324960690588785, 0.06337404684190945, 0.06960648189458599, 0.07338796472658238, 0.07632503277972387, 0.0780381636217022, 0.07827242768748424, 0.07778807456743866, 0.07635401083916257, 0.07434475469876532, 0.07162128727626829, 0.06864553995029893, 0.06553455109661424, 0.062195421232241824, 0.05886375560624826, 0.055393373307721344, 0.05204985789331662, 0.048755948577161756, 0.04564322518240881, 0.042427309776893435, 0.0393441971451477, 0.03650373910975804, 0.03384718162711955, 0.03134896103209011, 0.02898190575157013, 0.026751757350633485, 0.02468173948806378, 0.022717452269339283, 0.020950579853565455, 0.01923757782558931, 0.01770373144439679, 0.016283005616715536, 0.014951212155626642, 0.013723141729494135, 0.012550847284776838, 0.01151999602780865, 0.010542177040022001, 0.009656074642777235, 0.00884565262228185, 0.008087575710939156, 0.007391533511171646, 0.006769403627575577, 0.006194169548224779, 0.0056570081069257545, 0.005158959517056376, 0.0047079942014555546, 0.004294972231693257, 0.003922721712392064, 0.0035791258683708655, 0.003260378744911042, 0.0029690465055584444, 0.002699441137156401, 0.0024562209911218108, 0.002236389011548588, 0.0020395591628361515, 0.0018584347231891522, 0.0016911457217809718, 0.0015398262996920231, 0.001403552096590671, 0.0012777004839844047, 0.0011617277006232157, 0.0010585173978914222, 0.000964952556382155, 0.0008771331361180383, 0.0007968219431640454, 0.0007240548218568508, 0.0006588371813774216, 0.0005998670428873095, 0.0005465151014963963, 0.0004981792776793374, 0.0004529855777539449, 0.00041252842995343777, 0.0003751984141100397, 0.0003408541352181814, 0.0003094098948442562, 0.00028203321421766905, 0.00025700844446050207, 0.00023374932988325754, 0.00021221724407141545, 0.00019281108659245525, 0.00017456546849507269, 0.00015847068830387727, 0.00014358520859241827, 0.00013088253504653477, 0.00011905643636044408, 0.000108172700781943, 9.826067182046156e-05, 8.92048853323914e-05, 8.072587842729007e-05, 7.352182700068044e-05, 6.670969738212904e-05, 6.057251637657427e-05, 5.500533359051053e-05, 4.994648947426014e-05, 4.519538835463379e-05, 4.11118268290406e-05, 3.7498888618130155e-05, 3.4236283230166204e-05, 3.145670810247498e-05, 2.8719086455473823e-05, 2.6024705682407387e-05, 2.37443408099445e-05, 2.1589808196270486e-05, 1.9565037830951286e-05, 1.7751581686171405e-05, 1.6234619518345126e-05, 1.482652416377389e-05, 1.3623775502488025e-05, 1.2468925103569116e-05, 1.1315148104480656e-05, 1.0332898687796388e-05, 9.388876901243703e-06, 8.511426465840717e-06, 7.75433402958874e-06, 7.010748725700407e-06, 6.417345238370009e-06, 5.989730302568404e-06, 5.449198845800679e-06, 4.964802216614058e-06, 4.498070310553103e-06, 4.1270440868849865e-06, 3.7503349146648155e-06, 3.4121248562271733e-06, 3.0720143427908896e-06, 2.8217424057967997e-06, 2.571996319041681e-06, 2.315480956239292e-06, 2.1046620000691972e-06, 1.9168800893146388e-06, 1.7353056734860039e-06, 1.577415739618895e-06, 1.4197386901912197e-06, 1.284850360967114e-06, 1.1632101618649043e-06, 1.047237214611533e-06, 9.763641082099734e-07, 9.062542466212116e-07, 8.24353955699318e-07, 7.419186913361741e-07, 6.892483667364799e-07, 6.251195066729745e-07, 5.720563530714524e-07, 5.316348017941293e-07, 4.826937009672993e-07, 4.378192065076229e-07, 4.2083225445693956e-07, 4.5706841031389803e-07, 4.121044371603907e-07, 3.718720270610563e-07, 3.394864524373191e-07, 3.094406266142972e-07, 2.796763052781082e-07, 2.582202797300296e-07, 2.4422188740312354e-07, 2.2213230346005695e-07, 2.036337392251581e-07, 1.8349241135008123e-07, 1.6596444446435014e-07, 1.536207547392572e-07, 1.3928890415215173e-07, 1.6112123661178134e-07, 1.4512900608689782e-07, 1.3070488011542377e-07, 1.2681728856654818e-07, 1.2157370584465222e-07, 1.3766881154309756e-07, 1.2425322198044363e-07, 1.388147724792627e-07, 1.4897096811995996e-07, 1.4654795343475749e-07, 1.3822809997444513e-07, 1.269545786619329e-07, 1.3687854950151645e-07, 1.362605174630664e-07, 1.248516910409858e-07, 1.181570870681156e-07, 1.340166052494232e-07, 1.2091414895318028e-07, 1.8981575064579854e-07, 1.7749912497688142e-07, 2.5189595112242654e-07, 2.267079609630159e-07, 2.040699647630531e-07, 1.9288885969236094e-07, 1.8510565662871898e-07, 1.6743724811509843e-07, 1.6129346263207848e-07, 1.5509141947524026e-07, 1.4458967978074894e-07, 1.5849821233079926e-07, 1.5464190827319896e-07, 1.6304028747283615e-07, 1.5932433320508488e-07], "duration": 116745.929604, "accuracy_train": [0.41114434812200074, 0.4752600561784791, 0.5038750677717793, 0.5243742285552787, 0.5796630228520672, 0.581313157530454, 0.5904481084463824, 0.6174151482904209, 0.6355480646110189, 0.6443807461817092, 0.6610502607050572, 0.6694912718600037, 0.6805550148232743, 0.6843213954065154, 0.6940852179655776, 0.7041996152870063, 0.7093839761558692, 0.7184288050249169, 0.7210544207387413, 0.7297948173334257, 0.7349355591315984, 0.7437431867732558, 0.7401857090946844, 0.7435342838685862, 0.751625080749354, 0.7574826533084165, 0.7621551209509967, 0.7651992634505352, 0.7682244803202289, 0.7726848006644518, 0.7737096685815799, 0.7812653207479696, 0.7790113683554817, 0.7861931942714102, 0.7892842002353267, 0.790585562592285, 0.7933997136281838, 0.7915174245570322, 0.7990036827473238, 0.7980729022471392, 0.8016994134136213, 0.8043261105920081, 0.8044430890088593, 0.8060921422226835, 0.8103010220561092, 0.8114643174372462, 0.811441065949151, 0.811649608365633, 0.8138341667820228, 0.8149974621631598, 0.8174145354605021, 0.8179722106866003, 0.8179024562223146, 0.8187649242109634, 0.8185077158891657, 0.8200648446151717, 0.8214842668535437, 0.823508227782392, 0.8239024216154485, 0.8239260335917312, 0.8250649960202103, 0.8264368338178294, 0.8265069487703026, 0.8265309212347729, 0.8282279193775378, 0.8291111154369692, 0.8284135707941122, 0.8286460856750646, 0.8292495429009783, 0.830297301818014, 0.8310188189253415, 0.8317167240563861, 0.8323663237703026, 0.8319950209371539, 0.8328782169965854, 0.832879298461148, 0.8328774960202103, 0.8329486924372462, 0.8343663122346806, 0.8346453300918235, 0.8345054606750646, 0.8343427002583979, 0.8347615875322997, 0.8341112668420081, 0.8349483204134367, 0.8347161660206718, 0.836063670865633, 0.8359481344015319, 0.8359474134251569, 0.8360862013773532, 0.836157397794389, 0.8357392314968622, 0.8368524190199336, 0.8365061701158176, 0.8367368825558323, 0.836878554413529, 0.8369937303894426, 0.836644958068014, 0.8373653937107788, 0.8377374175203026, 0.8379466809131598, 0.8385276076273532, 0.8382493107465854, 0.8377374175203026, 0.838365207698874, 0.8382256987703026, 0.8380400473537283, 0.8382017263058323, 0.8387608434846806, 0.8387833739964008, 0.8391546768295497, 0.8390860038298265, 0.8387365105320228, 0.8391088948297342, 0.8389457739248799, 0.8388756589724069, 0.8391543163413622, 0.8388291559962164, 0.8393875521986894, 0.8399455879129751, 0.8393632192460319, 0.8394580276393503, 0.839294906734496, 0.8397130730320228, 0.8395034491509783, 0.8395739245916389, 0.8391088948297342, 0.8398046370316538, 0.8396891005675526, 0.8390616708771688, 0.8396200670796419, 0.8396901820321151, 0.8395735641034514, 0.8396887400793651, 0.8393403282461241, 0.8395968155915466, 0.8396200670796419, 0.8394340551748799, 0.8399913699127908, 0.8399924513773532, 0.8398060789844037, 0.8395270611272609, 0.8400149818890735, 0.8398057184962164, 0.8399219759366926, 0.8400622058416389, 0.8394569461747878, 0.8394576671511628, 0.8401781027939276, 0.8406198810677371, 0.8396894610557402, 0.8398754729605021, 0.8395506731035437, 0.8395503126153562, 0.8398522214724069, 0.8394801976628831, 0.8400847363533592, 0.8395975365679217, 0.8399455879129751, 0.8397130730320228, 0.8398533029369692, 0.8395499521271688, 0.8398525819605942, 0.8403866452104098, 0.8397828274963085, 0.8397842694490587, 0.8401319603059246, 0.8401319603059246, 0.8404335086747878, 0.8399917304009783, 0.839387912686877, 0.8393639402224069, 0.8402013542820228, 0.8401315998177371, 0.8400611243770765, 0.8404109781630675, 0.8403408632105942, 0.8401548513058323, 0.8397599364964008, 0.8394336946866926, 0.8398751124723146, 0.8408756474367847, 0.8402939997462164, 0.8410609383651717, 0.8401544908176449, 0.8401315998177371, 0.8398286094961241, 0.839759215520026, 0.8401777423057402, 0.8404338691629751, 0.8404571206510705, 0.8399223364248799, 0.839573203615264, 0.8397134335202103, 0.8395270611272609, 0.840364475186877], "end": "2016-01-30 20:32:04.117000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0], "moving_var_accuracy_valid": [0.014083823764907341, 0.029423882535971682, 0.04161706815616837, 0.051463037986836005, 0.06130763445155837, 0.0675316212764881, 0.07115928088148632, 0.07424308182883088, 0.07559995996325306, 0.07565177524301105, 0.07486180202178701, 0.0732630439965856, 0.07098390284092532, 0.06824057813374902, 0.06519269494996292, 0.06201627514650963, 0.058571155168847394, 0.05534970880269405, 0.05203249454986013, 0.048796895682017435, 0.04550881964275388, 0.04236704173754855, 0.039299092866362975, 0.036289025992550177, 0.03356140887756373, 0.03103814425083617, 0.028663277268995487, 0.026425362539187314, 0.024299996069626142, 0.02231143210509343, 0.020449373209577144, 0.01877463634776182, 0.017156641618762434, 0.015699483360196262, 0.014354025379373877, 0.013119884725790789, 0.011983465725694564, 0.01092113800643673, 0.00996086332881965, 0.009060636179865767, 0.008252909597079498, 0.007523853484806845, 0.006851915579480573, 0.006229012546095663, 0.005665796739019501, 0.005154455180839262, 0.00468627811220657, 0.004252831062133992, 0.0038656319501133413, 0.0035104286143813127, 0.0031866342117710003, 0.002891796030698682, 0.0026232513915206645, 0.002373063438751884, 0.0021481271956884725, 0.0019447735841618056, 0.0017624489133733002, 0.0015985230792506624, 0.0014488424718248948, 0.001314692365486557, 0.0011930505004749488, 0.0010815003186177877, 0.000977761799725849, 0.0008829002154813765, 0.0007978134203668736, 0.0007209097721190263, 0.0006501300155512184, 0.0005872870922254609, 0.0005307533930740994, 0.0004803331879553528, 0.0004344054727102211, 0.0003931015296570109, 0.00035561137750929214, 0.00032212404213513096, 0.00029051087237107046, 0.0002620020726498829, 0.00023719083464558244, 0.0002141286942664486, 0.00019416172027720408, 0.00017542759443371677, 0.00015824099378639208, 0.00014304647163558958, 0.00012974982711585537, 0.00011740976533478808, 0.00010608737667187188, 9.560345506404534e-05, 8.607251476700302e-05, 7.749004436272697e-05, 6.974302159616271e-05, 6.342222652718604e-05, 5.7233504197749184e-05, 5.1934942083054424e-05, 4.6932424890248226e-05, 4.2614994087292906e-05, 3.8551481036162025e-05, 3.492072756802928e-05, 3.150525085188459e-05, 2.838785660001027e-05, 2.555672477191138e-05, 2.305039554749459e-05, 2.07621953137473e-05, 1.8697217150862393e-05, 1.6831325835140717e-05, 1.5250449505115367e-05, 1.38161430074793e-05, 1.2555886637020648e-05, 1.1356560614378155e-05, 1.0222250920298933e-05, 9.233367307140569e-06, 8.729292358302927e-06, 7.983705209178483e-06, 7.196260617643411e-06, 6.485120565756548e-06, 5.938960159137814e-06, 5.391155858696838e-06, 4.867185801031118e-06, 4.401287696636342e-06, 3.961558944453829e-06, 3.5656254137960725e-06, 3.211940599961668e-06, 2.9918266149820158e-06, 2.7651964051010987e-06, 2.672815358514728e-06, 2.4312295097421223e-06, 2.208038447995416e-06, 2.0157939021852685e-06, 1.8192157763176466e-06, 1.682757204637592e-06, 1.6055416576125676e-06, 1.4701521734375598e-06, 1.3279711308469725e-06, 1.2327217023761985e-06, 1.1474372725092408e-06, 1.033361307407122e-06, 1.0280800881950873e-06, 1.008216390340232e-06, 9.127937507208582e-07, 8.470419530209673e-07, 8.448170118402057e-07, 9.860656314191501e-07, 9.682309346600361e-07, 8.762505439469397e-07, 7.905741979890575e-07, 7.249868117064541e-07, 6.5452380730416e-07, 8.225036853976706e-07, 7.778513781760898e-07, 7.103218103634646e-07, 6.397652617137285e-07, 6.519513525051276e-07, 6.01378174325572e-07, 5.412573531449657e-07, 4.924053297973131e-07, 4.432269525824126e-07, 4.0586419099881724e-07, 3.7831916647344844e-07, 3.47445305681806e-07, 3.1351946535746874e-07, 3.535725843133321e-07, 3.184282500691702e-07, 3.408088750657777e-07, 3.068310750181372e-07, 3.0036625361169034e-07, 2.8458029419852285e-07, 3.672392552917604e-07, 3.4173281286776203e-07, 3.5223329614496086e-07, 4.089264596109952e-07, 4.0545298537759855e-07, 3.963021569545135e-07, 3.856139401061733e-07, 3.4892292278152224e-07, 3.348191955853909e-07, 3.01616841552597e-07, 4.542058150550161e-07, 4.64090732644142e-07, 4.5542111925362535e-07, 4.1068303856349876e-07, 4.50814703557007e-07, 4.3707683195993724e-07, 4.187574637584341e-07, 4.6452715702631075e-07, 4.220617438781899e-07, 4.995725722596609e-07, 4.788050260972939e-07, 6.277455815571034e-07, 5.649836355360951e-07, 5.084954878115941e-07, 4.585857274541677e-07, 4.128087086453452e-07, 3.8187797652025673e-07, 4.0034740068222437e-07, 3.929624148727275e-07, 4.805796498258642e-07, 4.3589724272842047e-07, 4.0708199253846847e-07], "accuracy_test": 0.7614875637755102, "start": "2016-01-29 12:06:18.187000", "learning_rate_per_epoch": [0.0013416779693216085, 0.0012760283425450325, 0.001213591080158949, 0.0011542089050635695, 0.0010977323399856687, 0.0010440192418172956, 0.0009929343359544873, 0.000944349099881947, 0.0008981411810964346, 0.0008541942806914449, 0.0008123977459035814, 0.0007726463372819126, 0.0007348399958573282, 0.0006988835521042347, 0.0006646864931099117, 0.0006321627297438681, 0.0006012304220348597, 0.0005718116299249232, 0.0005438323714770377, 0.0005172221572138369, 0.0004919139901176095, 0.00046784416190348566, 0.0004449521075002849, 0.0004231801722198725, 0.0004024735535494983, 0.00038278012652881444, 0.000364050327334553, 0.0003462370077613741, 0.0003292952897027135, 0.00031318256515078247, 0.0002978582342620939, 0.0002832837344612926, 0.00026942239492200315, 0.0002562392910476774, 0.00024370125902350992, 0.00023177672119345516, 0.00022043567150831223, 0.00020964954455848783, 0.00019939118647016585, 0.00018963478214573115, 0.00018035576795227826, 0.00017153078806586564, 0.00016313762171193957, 0.00015515513950958848, 0.00014756324526388198, 0.00014034283231012523, 0.000133475725306198, 0.000126944636576809, 0.00012073311518179253, 0.00011482553236419335, 0.00010920700879069045, 0.00010386340727563947, 9.878127457341179e-05, 9.394781227456406e-05, 8.935085497796535e-05, 8.497883391100913e-05, 8.082074054982513e-05, 7.686610479140654e-05, 7.310497312573716e-05, 6.952787953196093e-05, 6.61258163745515e-05, 6.289021985139698e-05, 5.981294088996947e-05, 5.6886237871367484e-05, 5.410274025052786e-05, 5.145544128026813e-05, 4.8937676183413714e-05, 4.654310760088265e-05, 4.426570740179159e-05, 4.209974576951936e-05, 4.0039765735855326e-05, 3.808058318099938e-05, 3.6217265005689114e-05, 3.444511821726337e-05, 3.2759686291683465e-05, 3.115672370768152e-05, 2.9632195946760476e-05, 2.8182264941278845e-05, 2.6803279979503714e-05, 2.5491770429653116e-05, 2.4244433006970212e-05, 2.3058129954733886e-05, 2.1929874492343515e-05, 2.085682535835076e-05, 1.983628135349136e-05, 1.88656740647275e-05, 1.794255877030082e-05, 1.706461262074299e-05, 1.6229625543928705e-05, 1.5435494788107462e-05, 1.4680221283924766e-05, 1.396190418745391e-05, 1.327873451373307e-05, 1.2628993317775894e-05, 1.2011044418613892e-05, 1.1423332580307033e-05, 1.0864378054975532e-05, 1.0332773854315747e-05, 9.827181202126667e-06, 9.346327715320513e-06, 8.889002856449224e-06, 8.454055205220357e-06, 8.040390639507677e-06, 7.646966878382955e-06, 7.272793482115958e-06, 6.916928668943001e-06, 6.578476586582838e-06, 6.2565854932472575e-06, 5.950445029156981e-06, 5.659283942804905e-06, 5.38236963620875e-06, 5.119004981679609e-06, 4.868527412327239e-06, 4.630305738828611e-06, 4.403740604175255e-06, 4.188261300441809e-06, 3.983325768786017e-06, 3.788417870964622e-06, 3.6030469345860183e-06, 3.426746388868196e-06, 3.2590724003966898e-06, 3.099602963629877e-06, 2.9479365366569255e-06, 2.80369113170309e-06, 2.666503860382363e-06, 2.536029342081747e-06, 2.411939021840226e-06, 2.293920488227741e-06, 2.181676791224163e-06, 2.0749253053509165e-06, 1.9733972749236273e-06, 1.8768370182442595e-06, 1.7850015865406021e-06, 1.6976597407847294e-06, 1.6145916106324876e-06, 1.5355881259893067e-06, 1.460450334889174e-06, 1.3889890624341206e-06, 1.321024456046871e-06, 1.2563855307234917e-06, 1.1949093732255278e-06, 1.136441369453678e-06, 1.0808341812662547e-06, 1.0279479738528607e-06, 9.776495062396862e-07, 9.29812188132928e-07, 8.843155683280202e-07, 8.41045164179377e-07, 7.998920068530424e-07, 7.607525276398519e-07, 7.235281600515009e-07, 6.881252261337067e-07, 6.544545954056957e-07, 6.224315143299464e-07, 5.919753220950952e-07, 5.630093937725178e-07, 5.354607992558158e-07, 5.09260189573979e-07, 4.843416263611289e-07, 4.6064232606113364e-07, 4.3810265992760833e-07, 4.166658698068204e-07, 3.96278011294271e-07, 3.7688775478272873e-07, 3.5844627177539223e-07, 3.4090714962076163e-07, 3.242262494040915e-07, 3.083615638388437e-07, 2.9327313200155913e-07, 2.7892301091014815e-07, 2.652750481502153e-07, 2.522948818750592e-07, 2.399498555405444e-07, 2.282088757965539e-07, 2.1704239827613492e-07, 2.0642231390866073e-07, 1.9632187786555733e-07, 1.8671566692773922e-07, 1.7757949422048114e-07, 1.6889036658085388e-07, 1.6062639929259603e-07, 1.5276680187525926e-07, 1.4529177860822529e-07, 1.3818251431985118e-07, 1.314211175440505e-07, 1.2499056367687444e-07, 1.1887465944937503e-07, 1.1305800740046834e-07, 1.0752597034979772e-07, 1.0226462165974226e-07, 9.72607168137074e-08, 9.250165788898812e-08, 8.79754651350595e-08, 8.367074144643993e-08, 7.95766510464091e-08, 7.568289106529846e-08], "accuracy_train_first": 0.41114434812200074, "accuracy_train_last": 0.840364475186877, "batch_size_eval": 1024, "accuracy_train_std": [0.015096561146615724, 0.014097467794077022, 0.015494967538603603, 0.0177041823181327, 0.015226373958823048, 0.015095069851330677, 0.01451243659830776, 0.015128173528991564, 0.015234092670629645, 0.016225589707961098, 0.01539336687108213, 0.015248654492114154, 0.016333926032730237, 0.014160912566240838, 0.014331000524361046, 0.013736388299037658, 0.01354900334809264, 0.013043310820329009, 0.013061213518594659, 0.014658940287669665, 0.012410055801913017, 0.014475905565591387, 0.012849809796551316, 0.01317397448579915, 0.013100806385799421, 0.013584644128838853, 0.013046642373590647, 0.013304233760100115, 0.014572609507005337, 0.015404979006968474, 0.011913392001550645, 0.014010572647927563, 0.014088326729980522, 0.012975625661377945, 0.013285632065273043, 0.014483407627998079, 0.013318667272792415, 0.01300545438528856, 0.01301645929409234, 0.012916578259873288, 0.012665595621688586, 0.01358887174460352, 0.013537852875346775, 0.012721121381975635, 0.012286201297163337, 0.01337174527315248, 0.012430888936589897, 0.012801297377274735, 0.012502604662896894, 0.013275431502421834, 0.011603703289714386, 0.012005488379204949, 0.01138857490291349, 0.011535997949995951, 0.011922380947413824, 0.011531331415912451, 0.011656231415304896, 0.011014110359547321, 0.011981776023500156, 0.011327176463285531, 0.011692959352084083, 0.010682066185627098, 0.012501343333542615, 0.012259774252251523, 0.011702992622964465, 0.01195207573847531, 0.011003642430111264, 0.011554943573160073, 0.011219007341651507, 0.01190272842881975, 0.011433694270813661, 0.011424200575914863, 0.011457978805664903, 0.011486500123683572, 0.011137797774556923, 0.011806075947445902, 0.010888189955678017, 0.011525742314396355, 0.011075917269425726, 0.011066877784739611, 0.011679128162499131, 0.01172889431431911, 0.010990325227918664, 0.011325548682338758, 0.01171558839329286, 0.011463765388996782, 0.011813014122929264, 0.011569399898691195, 0.011180708246305139, 0.010883394494776827, 0.011685472277955149, 0.01143993393449023, 0.010673022367493139, 0.010950060392523145, 0.010434632756211457, 0.011078674056696058, 0.010441261154656706, 0.010329855646333071, 0.0111678121032417, 0.01030615484355492, 0.01033024661293082, 0.010285422332800978, 0.010169989986559318, 0.010733527568845243, 0.010605962138620513, 0.010263201116738173, 0.010505698010411848, 0.01017390277824442, 0.010562423617657109, 0.010095769379575601, 0.010618032094895296, 0.01047887429735798, 0.011136846057601454, 0.010585163564035337, 0.010415674091701327, 0.010174257027732015, 0.010564115974927742, 0.01046463834594739, 0.010179009643793506, 0.00997930698856606, 0.009853901527939184, 0.010479670151992523, 0.010933917911632616, 0.01040014092742301, 0.010126355991180558, 0.010023893077834444, 0.010173889713006085, 0.010384124074055888, 0.010909759565486897, 0.010577295053326077, 0.010260065827378505, 0.010175835284374154, 0.010194557645842806, 0.010564628332242929, 0.010499189227988051, 0.01041003376665579, 0.010295414502831652, 0.010238810650777164, 0.010429972816328003, 0.010645919864656276, 0.010271281223699802, 0.010703914419603782, 0.01058013458415157, 0.010251197139182568, 0.010122801923383062, 0.010711699696321448, 0.010725822972159467, 0.010658080170977075, 0.010214907970665162, 0.010158507163787002, 0.010450836298551145, 0.010871483404777674, 0.010712037730253232, 0.010532436503458637, 0.010811836741006744, 0.010235949717984045, 0.010112379439840698, 0.010772298298995625, 0.010242065041108984, 0.010476277416347353, 0.010440105178000564, 0.010471724352603108, 0.010282393903738868, 0.010301805841088831, 0.010187930883136312, 0.010889648070261241, 0.010544460906101935, 0.009959749356846532, 0.010159691741740796, 0.01045635782072689, 0.010865290837265423, 0.010278764534514647, 0.010352128874551385, 0.010229650898173926, 0.010229808932482562, 0.01076765573777494, 0.009927491565919861, 0.010294246759371404, 0.010315158678855331, 0.010223092793158004, 0.010421169905592975, 0.010109925058579146, 0.010608386560183885, 0.010095564501901256, 0.01017428153672872, 0.010129272909623871, 0.010495026474591341, 0.0106677388015959, 0.009951272637683271, 0.010067790508396145, 0.010224189146882568, 0.010252241229250197, 0.010034991424022248, 0.010263919351138092, 0.010541460578974097, 0.010446800021555817], "accuracy_test_std": 0.01091251921695491, "error_valid": [0.6044157097138554, 0.5290556758283133, 0.507213914250753, 0.4817806381777108, 0.4287182911332832, 0.4255238728350903, 0.41935858669051207, 0.38837184676204817, 0.37899302287274095, 0.36929799275225905, 0.3566629800451807, 0.34783273719879515, 0.34121005506400603, 0.3343638224774097, 0.3275072948042168, 0.31913444794804224, 0.31757841914533136, 0.3039565488516567, 0.30099597609186746, 0.2944144743034638, 0.2945056593561747, 0.2890639707266567, 0.2877211972891567, 0.2891860410391567, 0.2801013624811747, 0.27396696159638556, 0.27054899284638556, 0.26798551628388556, 0.2673854598079819, 0.2655749952936747, 0.26456754753388556, 0.25806693571159633, 0.26209525602409633, 0.25682564241340367, 0.25511665803840367, 0.2527767319277108, 0.2511692276920181, 0.2520443100527108, 0.24875870670180722, 0.25056917121611444, 0.24688647166792166, 0.24393619399472888, 0.24346850291792166, 0.24406855939382532, 0.24199336408132532, 0.24039615493222888, 0.23977550828313254, 0.24063000047063254, 0.23785326854292166, 0.23770031297063254, 0.23710025649472888, 0.23648990493222888, 0.23599132859563254, 0.23800622411521077, 0.23673404555722888, 0.23600162368222888, 0.23453677993222888, 0.2332954866340362, 0.23319400649472888, 0.23184093797063254, 0.2312202913215362, 0.2313423616340362, 0.23269543015813254, 0.23330578172063254, 0.23246158461972888, 0.23217626364834332, 0.23344844220632532, 0.23197330336972888, 0.23145413685993976, 0.23046727927334332, 0.23051875470632532, 0.2299995881965362, 0.22988781297063254, 0.22913480092243976, 0.23087467055722888, 0.23074230515813254, 0.2290230256965362, 0.22985692771084332, 0.22828030873493976, 0.22913480092243976, 0.22962308217243976, 0.22876858998493976, 0.2278023225715362, 0.22815823842243976, 0.22839208396084332, 0.22915539109563254, 0.22964367234563254, 0.2296333772590362, 0.23025402390813254, 0.22742581654743976, 0.22854503953313254, 0.22754788685993976, 0.2280464631965362, 0.2273140413215362, 0.22766995717243976, 0.22742581654743976, 0.2279243928840362, 0.22814794333584332, 0.22840237904743976, 0.2279243928840362, 0.22815823842243976, 0.2289009553840362, 0.22878918015813254, 0.22753759177334332, 0.22950101185993976, 0.2274361116340362, 0.22769054734563254, 0.22852444935993976, 0.2290230256965362, 0.22631688864834332, 0.2270699006965362, 0.22779202748493976, 0.2284126741340362, 0.2270699006965362, 0.2273140413215362, 0.22754788685993976, 0.2274361116340362, 0.2278023225715362, 0.22781261765813254, 0.22803616810993976, 0.22681546498493976, 0.22866710984563254, 0.22642866387424698, 0.22718167592243976, 0.2271919710090362, 0.22817882859563254, 0.2274361116340362, 0.22693753529743976, 0.22657132435993976, 0.2269478303840362, 0.2271919710090362, 0.2280464631965362, 0.22681546498493976, 0.2273140413215362, 0.22634777390813254, 0.22632718373493976, 0.2274361116340362, 0.22668309958584332, 0.22620511342243976, 0.2254829866340362, 0.22596097279743976, 0.2265816194465362, 0.22693753529743976, 0.2271919710090362, 0.22669339467243976, 0.22521825583584332, 0.2273140413215362, 0.2270699006965362, 0.22669339467243976, 0.22583890248493976, 0.2270699006965362, 0.22669339467243976, 0.2269478303840362, 0.2267036897590362, 0.22644925404743976, 0.22708019578313254, 0.2264595491340362, 0.22680516989834332, 0.22582860739834332, 0.2265816194465362, 0.2258491975715362, 0.2265816194465362, 0.2270699006965362, 0.22620511342243976, 0.22545210137424698, 0.22680516989834332, 0.2271919710090362, 0.22756847703313254, 0.22730374623493976, 0.2273140413215362, 0.2262154085090362, 0.2265816194465362, 0.2271919710090362, 0.2267036897590362, 0.22817882859563254, 0.2276802522590362, 0.22632718373493976, 0.22681546498493976, 0.22595067771084332, 0.2262154085090362, 0.2262154085090362, 0.2276802522590362, 0.2265816194465362, 0.2279243928840362, 0.22631688864834332, 0.22535062123493976, 0.22669339467243976, 0.22669339467243976, 0.2265816194465362, 0.2267036897590362, 0.2263374788215362, 0.2274361116340362, 0.22732433640813254, 0.22559476185993976, 0.22646984422063254, 0.22704931052334332], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.04893094935656911, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.001410705099354554, "optimization": "nesterov_momentum", "nb_data_augmentation": 1, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 8.160535101711784e-06, "rotation_range": [0, 0], "momentum": 0.8052178946282369}, "accuracy_valid_max": 0.7747817441641567, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7729506894766567, "accuracy_valid_std": [0.011744368163513678, 0.0170186611797216, 0.01469788320478044, 0.01201539285820857, 0.008186862915000382, 0.010424964428247073, 0.011727351830651303, 0.010811005839028064, 0.006665595252939537, 0.011250190968734664, 0.009609876981667, 0.010759541909700077, 0.00975799805377592, 0.014092020861712929, 0.011682516471132554, 0.015224700295817168, 0.012917733654277489, 0.011508636631446805, 0.014799181848462451, 0.011598933960862937, 0.011633895106123891, 0.008052406542014605, 0.011799020990817415, 0.011994238194430216, 0.010643483592221805, 0.0096407163303401, 0.008748463699364412, 0.01032153903403888, 0.00744798036584598, 0.0076679682340645, 0.00972301997743385, 0.00783246869334879, 0.011274433614820362, 0.010850906751456868, 0.009257391360429917, 0.010557155822287922, 0.009749500919220822, 0.009546869526324622, 0.006915063338592294, 0.010655795243301899, 0.01114604642393866, 0.011695298179377658, 0.008690933736103936, 0.011472093953119511, 0.008992741996286477, 0.009699035862924657, 0.010146485965159014, 0.010248501086225615, 0.011594967101762067, 0.01009288190691931, 0.010357710340369091, 0.012370630482453803, 0.011644046667519942, 0.00852684635975546, 0.01201294430743146, 0.01109728551411045, 0.009487185608681179, 0.010986599822147253, 0.01033814002428949, 0.011184773146600515, 0.010939247768202631, 0.01125790946257683, 0.00991470105552548, 0.008961556302860364, 0.008340455339843332, 0.012059419694463287, 0.008897245725745505, 0.008554428846390688, 0.010840700945573586, 0.010565450434402233, 0.008751740105899094, 0.009572880046317678, 0.010186087509040178, 0.009863125768071745, 0.008966781010051841, 0.008894059401266691, 0.010013013727038392, 0.010301864835099265, 0.0077034455310158, 0.009328946940326849, 0.010107433563935961, 0.008935236612035408, 0.008435665411748094, 0.009544611146514434, 0.010682281250325481, 0.009585329283950788, 0.008880090077849276, 0.009714985763270177, 0.007749808477320434, 0.01012113683110733, 0.009587979195611225, 0.009202606879975577, 0.008494962874132577, 0.008236580732685695, 0.009025090970375755, 0.010226591708184667, 0.009117094687673032, 0.009912395223786787, 0.009063917279651064, 0.009234023107828455, 0.01054166792223597, 0.008768420029762448, 0.008628488950637772, 0.010068173937782338, 0.009935803913038508, 0.00831820894189743, 0.008375524633359291, 0.011442200079314712, 0.009989174477385815, 0.009172720068774587, 0.008759662659305802, 0.00815501367021404, 0.008387332724266653, 0.008867865500651715, 0.008521128666325869, 0.009828982772517814, 0.009707036149449863, 0.00979571248891706, 0.00826494941150047, 0.010621334576330535, 0.00896380279944153, 0.008111746310145287, 0.010369186483839733, 0.009482865817919555, 0.009439803336049794, 0.008047128041991806, 0.00900630495575963, 0.010127449707727595, 0.00921648669746139, 0.008580327211065393, 0.010063261626206311, 0.009749491157318971, 0.00980231538198904, 0.008337277266575712, 0.008341921664712901, 0.009277953657176619, 0.00988953130806763, 0.009475621918636464, 0.01011631085484999, 0.008045951300881983, 0.009926195485473402, 0.009467046240028022, 0.009533243267984678, 0.008947065497549318, 0.010050861932585357, 0.008884540315982637, 0.008673651948181784, 0.00858092351536337, 0.010331595786050233, 0.00946917738191888, 0.00959116671564708, 0.00920909128030487, 0.009171283036163368, 0.009034288744339841, 0.008906629197353683, 0.009237954331488473, 0.008941967274020218, 0.009981855406596624, 0.009739927785315955, 0.009391190182091903, 0.008934103487460349, 0.008962513036301134, 0.009197798813585126, 0.00873797002683606, 0.010005302208353647, 0.010550826874429264, 0.009325455474741314, 0.008580708870756416, 0.009366542533956732, 0.008604658344332437, 0.008427776556162008, 0.009133787902846666, 0.009013438517732578, 0.008656942468404292, 0.009207791829138088, 0.01076630418656814, 0.010172756771845627, 0.009455668492133975, 0.009519439131957741, 0.009028722786810032, 0.008568057158516718, 0.010044547543534064, 0.008399492733653844, 0.009699931452472626, 0.010276014090066279, 0.009619509383459561, 0.010582394824734396, 0.009931547704002525, 0.009592140027222515, 0.010034533344617005, 0.008946393260372852, 0.009533556036406592, 0.008381256620429104, 0.009535267515913182, 0.008134378271528336, 0.009779807988222538], "accuracy_valid": [0.3955842902861446, 0.47094432417168675, 0.492786085749247, 0.5182193618222892, 0.5712817088667168, 0.5744761271649097, 0.5806414133094879, 0.6116281532379518, 0.621006977127259, 0.630702007247741, 0.6433370199548193, 0.6521672628012049, 0.658789944935994, 0.6656361775225903, 0.6724927051957832, 0.6808655520519578, 0.6824215808546686, 0.6960434511483433, 0.6990040239081325, 0.7055855256965362, 0.7054943406438253, 0.7109360292733433, 0.7122788027108433, 0.7108139589608433, 0.7198986375188253, 0.7260330384036144, 0.7294510071536144, 0.7320144837161144, 0.7326145401920181, 0.7344250047063253, 0.7354324524661144, 0.7419330642884037, 0.7379047439759037, 0.7431743575865963, 0.7448833419615963, 0.7472232680722892, 0.7488307723079819, 0.7479556899472892, 0.7512412932981928, 0.7494308287838856, 0.7531135283320783, 0.7560638060052711, 0.7565314970820783, 0.7559314406061747, 0.7580066359186747, 0.7596038450677711, 0.7602244917168675, 0.7593699995293675, 0.7621467314570783, 0.7622996870293675, 0.7628997435052711, 0.7635100950677711, 0.7640086714043675, 0.7619937758847892, 0.7632659544427711, 0.7639983763177711, 0.7654632200677711, 0.7667045133659638, 0.7668059935052711, 0.7681590620293675, 0.7687797086784638, 0.7686576383659638, 0.7673045698418675, 0.7666942182793675, 0.7675384153802711, 0.7678237363516567, 0.7665515577936747, 0.7680266966302711, 0.7685458631400602, 0.7695327207266567, 0.7694812452936747, 0.7700004118034638, 0.7701121870293675, 0.7708651990775602, 0.7691253294427711, 0.7692576948418675, 0.7709769743034638, 0.7701430722891567, 0.7717196912650602, 0.7708651990775602, 0.7703769178275602, 0.7712314100150602, 0.7721976774284638, 0.7718417615775602, 0.7716079160391567, 0.7708446089043675, 0.7703563276543675, 0.7703666227409638, 0.7697459760918675, 0.7725741834525602, 0.7714549604668675, 0.7724521131400602, 0.7719535368034638, 0.7726859586784638, 0.7723300428275602, 0.7725741834525602, 0.7720756071159638, 0.7718520566641567, 0.7715976209525602, 0.7720756071159638, 0.7718417615775602, 0.7710990446159638, 0.7712108198418675, 0.7724624082266567, 0.7704989881400602, 0.7725638883659638, 0.7723094526543675, 0.7714755506400602, 0.7709769743034638, 0.7736831113516567, 0.7729300993034638, 0.7722079725150602, 0.7715873258659638, 0.7729300993034638, 0.7726859586784638, 0.7724521131400602, 0.7725638883659638, 0.7721976774284638, 0.7721873823418675, 0.7719638318900602, 0.7731845350150602, 0.7713328901543675, 0.773571336125753, 0.7728183240775602, 0.7728080289909638, 0.7718211714043675, 0.7725638883659638, 0.7730624647025602, 0.7734286756400602, 0.7730521696159638, 0.7728080289909638, 0.7719535368034638, 0.7731845350150602, 0.7726859586784638, 0.7736522260918675, 0.7736728162650602, 0.7725638883659638, 0.7733169004141567, 0.7737948865775602, 0.7745170133659638, 0.7740390272025602, 0.7734183805534638, 0.7730624647025602, 0.7728080289909638, 0.7733066053275602, 0.7747817441641567, 0.7726859586784638, 0.7729300993034638, 0.7733066053275602, 0.7741610975150602, 0.7729300993034638, 0.7733066053275602, 0.7730521696159638, 0.7732963102409638, 0.7735507459525602, 0.7729198042168675, 0.7735404508659638, 0.7731948301016567, 0.7741713926016567, 0.7734183805534638, 0.7741508024284638, 0.7734183805534638, 0.7729300993034638, 0.7737948865775602, 0.774547898625753, 0.7731948301016567, 0.7728080289909638, 0.7724315229668675, 0.7726962537650602, 0.7726859586784638, 0.7737845914909638, 0.7734183805534638, 0.7728080289909638, 0.7732963102409638, 0.7718211714043675, 0.7723197477409638, 0.7736728162650602, 0.7731845350150602, 0.7740493222891567, 0.7737845914909638, 0.7737845914909638, 0.7723197477409638, 0.7734183805534638, 0.7720756071159638, 0.7736831113516567, 0.7746493787650602, 0.7733066053275602, 0.7733066053275602, 0.7734183805534638, 0.7732963102409638, 0.7736625211784638, 0.7725638883659638, 0.7726756635918675, 0.7744052381400602, 0.7735301557793675, 0.7729506894766567], "seed": 745520297, "model": "residualv3", "loss_std": [0.2783399522304535, 0.12152498215436935, 0.1234627440571785, 0.12405966967344284, 0.12576250731945038, 0.1250004917383194, 0.1260865479707718, 0.126059427857399, 0.1263759583234787, 0.13023622334003448, 0.12749920785427094, 0.12671619653701782, 0.13035042583942413, 0.12795527279376984, 0.12844474613666534, 0.12731793522834778, 0.12719927728176117, 0.12638574838638306, 0.12455136328935623, 0.12349466234445572, 0.12161808460950851, 0.12218327820301056, 0.12204577028751373, 0.12229377031326294, 0.1218365728855133, 0.12416929751634598, 0.12139992415904999, 0.11856960505247116, 0.11932525783777237, 0.11945497244596481, 0.11901437491178513, 0.11787804961204529, 0.11680097877979279, 0.11594550311565399, 0.11794600635766983, 0.11613930016756058, 0.11496231704950333, 0.11552252620458603, 0.11698883771896362, 0.11477842926979065, 0.11521964520215988, 0.11306621134281158, 0.11610139161348343, 0.11407048255205154, 0.11468607187271118, 0.11278949677944183, 0.1136758103966713, 0.11313644051551819, 0.1138606145977974, 0.11257752776145935, 0.11432900279760361, 0.11149511486291885, 0.11171513050794601, 0.11201708763837814, 0.10927709192037582, 0.11192972958087921, 0.1108364686369896, 0.11253390461206436, 0.11189277470111847, 0.11112338304519653, 0.11101053655147552, 0.10978703200817108, 0.1116262823343277, 0.11219780147075653, 0.11053963750600815, 0.10968253761529922, 0.1086498573422432, 0.10972034186124802, 0.11057237535715103, 0.109771728515625, 0.10973849147558212, 0.10766486823558807, 0.10995595902204514, 0.11244717240333557, 0.10784139484167099, 0.1065090224146843, 0.10967444628477097, 0.10891351103782654, 0.10663682222366333, 0.1088801696896553, 0.10696210712194443, 0.10951545089483261, 0.10937199741601944, 0.1091916486620903, 0.1077503189444542, 0.10610439628362656, 0.10770648717880249, 0.10761605203151703, 0.10715372115373611, 0.10835358500480652, 0.1085876077413559, 0.10804601013660431, 0.10784772038459778, 0.10691516846418381, 0.10658250749111176, 0.10794912278652191, 0.10840634256601334, 0.10613998770713806, 0.10783959925174713, 0.10752230882644653, 0.10900607705116272, 0.10850221663713455, 0.10706432908773422, 0.11001991480588913, 0.10851272940635681, 0.10767035186290741, 0.1071963906288147, 0.11005716025829315, 0.10849520564079285, 0.10781169682741165, 0.11041253805160522, 0.10704214125871658, 0.10637631267309189, 0.1051410436630249, 0.10666648298501968, 0.10693208128213882, 0.10806125402450562, 0.10636071860790253, 0.10852847248315811, 0.10656909644603729, 0.10845708847045898, 0.10565176606178284, 0.11029902845621109, 0.10765332728624344, 0.10467890650033951, 0.10607640445232391, 0.10642222315073013, 0.1072145476937294, 0.10670196264982224, 0.10725387185811996, 0.1078307256102562, 0.10874046385288239, 0.10803558677434921, 0.10795631259679794, 0.10835088044404984, 0.11005494743585587, 0.10598038882017136, 0.10649173706769943, 0.10778983682394028, 0.10600146651268005, 0.10653859376907349, 0.10620313137769699, 0.10762359946966171, 0.10747221112251282, 0.10897255688905716, 0.10993130505084991, 0.10973299294710159, 0.10626305639743805, 0.1080775260925293, 0.10823158919811249, 0.1065906509757042, 0.10667560994625092, 0.10804557800292969, 0.10856609791517258, 0.10714349150657654, 0.10724815726280212, 0.10994990915060043, 0.10822684317827225, 0.10679075121879578, 0.1094566285610199, 0.10711729526519775, 0.10965235531330109, 0.10775706171989441, 0.10697315633296967, 0.11072174459695816, 0.10812050849199295, 0.10447059571743011, 0.10852786153554916, 0.10648640990257263, 0.10554932802915573, 0.10754766315221786, 0.10697080194950104, 0.10758637636899948, 0.10459195822477341, 0.10456967353820801, 0.10544579476118088, 0.10794872045516968, 0.10951674729585648, 0.10861002653837204, 0.10636666417121887, 0.10836738348007202, 0.10514890402555466, 0.10843473672866821, 0.10829336196184158, 0.10833669453859329, 0.10807815939188004, 0.10707981884479523, 0.10595239698886871, 0.10866180807352066, 0.10709024965763092, 0.10931208729743958, 0.10773357003927231, 0.10786529630422592, 0.10771811008453369, 0.1080087348818779, 0.1063467338681221]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:24 2016", "state": "available"}], "summary": "24cfe3fd3d1166eb1074489634880664"}