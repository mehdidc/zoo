{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.5351721048355103, 1.1130772829055786, 0.8991356492042542, 0.7680310606956482, 0.6717631220817566, 0.599063515663147, 0.5400992035865784, 0.48881247639656067, 0.4401914179325104, 0.39625057578086853, 0.35339459776878357, 0.3203495740890503, 0.30058491230010986, 0.26042309403419495, 0.22709348797798157, 0.1998470574617386, 0.17983953654766083, 0.16844937205314636, 0.1478465050458908, 0.14326165616512299, 0.1276131421327591, 0.11923160403966904, 0.10937827825546265, 0.10407058894634247, 0.09848872572183609, 0.09316552430391312, 0.08783669024705887, 0.084513820707798, 0.08245408535003662, 0.08223183453083038, 0.07666949182748795, 0.08267708122730255, 0.07639580965042114, 0.0722753182053566, 0.07447060197591782, 0.07768198847770691, 0.0683683529496193, 0.07169590890407562, 0.06812078505754471, 0.07264411449432373, 0.0684209018945694, 0.062414608895778656, 0.06936965137720108, 0.06814197450876236, 0.06669005006551743, 0.062464144080877304, 0.06735915690660477, 0.067998968064785, 0.060477785766124725, 0.05540180951356888, 0.058682288974523544, 0.07395125180482864, 0.06082814931869507, 0.06117302551865578, 0.05723994970321655, 0.059349335730075836, 0.05513731390237808, 0.0620582215487957, 0.0665561854839325, 0.057166192680597305, 0.06122106686234474, 0.05685458704829216, 0.05198840796947479, 0.048919253051280975, 0.04885921627283096, 0.08180306851863861, 0.06651034206151962, 0.050375837832689285, 0.047840312123298645, 0.04669295251369476, 0.046186380088329315, 0.04574546962976456, 0.04525516927242279, 0.04470150172710419, 0.04407442733645439, 0.043364956974983215, 0.04256458953022957, 0.041665442287921906, 0.040660519152879715, 0.039544183760881424, 0.03831259161233902, 0.03696422651410103, 0.035500407218933105, 0.03392571210861206, 0.032248180359601974, 0.03047937899827957, 0.028634088113904, 0.026729675009846687, 0.024785485118627548, 0.022822221741080284, 0.020862475037574768, 0.19341513514518738, 0.036004550755023956, 0.02419109083712101, 0.021402470767498016, 0.0208293404430151, 0.020644690841436386, 0.02051607519388199, 0.020398836582899094, 0.020281799137592316, 0.02015870250761509, 0.02002505213022232, 0.019876861944794655, 0.019710389897227287, 0.01952175982296467, 0.019306989386677742, 0.019061820581555367, 0.018781753256917, 0.018462086096405983, 0.018097884953022003, 0.01768418587744236, 0.017216145992279053, 0.01668926142156124, 0.016099704429507256, 0.015444664284586906, 0.014722872525453568, 0.013935046270489693, 0.013084514997899532, 0.012177744880318642, 0.011225037276744843, 0.2351243495941162, 0.07160966843366623, 0.040351998060941696], "moving_avg_accuracy_train": [0.04755648489410298, 0.10311049215289311, 0.16162664148296185, 0.2184919988024582, 0.2708490580065147, 0.3196511333912637, 0.3644005379208158, 0.4079480544960284, 0.44810092562795933, 0.4846939504228138, 0.5180185861287329, 0.5487451087508632, 0.5779771062737097, 0.6069571395382269, 0.6314866549990867, 0.653326089784108, 0.6730257228691893, 0.691429577654068, 0.7068520117249014, 0.7191657370185889, 0.7345180182908901, 0.752519798560823, 0.7694908448156211, 0.7874126623043433, 0.8043048387072607, 0.8196496315472673, 0.8341550924996834, 0.8466358758449993, 0.8585033104319649, 0.8693630380185672, 0.8795344293417566, 0.8874911938469037, 0.8955055754658124, 0.9031044936252113, 0.908878926253277, 0.9145665220173458, 0.9206755832073148, 0.9260040384640105, 0.9307694212605128, 0.9350047152571083, 0.9401138047433022, 0.9447167076761332, 0.9478619756716705, 0.9517272638926172, 0.9541644647712588, 0.9571391955620362, 0.9587420903284609, 0.9596920524611741, 0.9630346392162563, 0.9651896376827351, 0.9670174931108901, 0.9687486295510008, 0.9708088484411388, 0.9722562164982339, 0.974181951581753, 0.975006052070034, 0.9767730249880305, 0.9766195832023596, 0.9777044057226091, 0.9790759852396338, 0.9787548822513847, 0.9802818307821987, 0.9820746112456455, 0.9837532178294143, 0.9843270008822056, 0.983034620100002, 0.9841452205900018, 0.9855516620726683, 0.9869174408058777, 0.988190819493147, 0.989343835758118, 0.990386200694211, 0.9913243291366947, 0.9921663195861204, 0.9929241109906036, 0.9936061232546385, 0.99421993429227, 0.9947723642261382, 0.9952742014642386, 0.9957281801273387, 0.9961367609241286, 0.9965091339388585, 0.9968442696521155, 0.9971482169428563, 0.9974217695045231, 0.9976679668100232, 0.9978895443849733, 0.9980936145000474, 0.9982772776036141, 0.9984402492480146, 0.9985590219422606, 0.9970709734302051, 0.9968360673074227, 0.9970827061123947, 0.9973465337154409, 0.9975909540046111, 0.9978109322648642, 0.9980158881455206, 0.9982026735869209, 0.9983731056329908, 0.9985288196232631, 0.9986689622145082, 0.9987974156954382, 0.9989130238282753, 0.9990170711478287, 0.9991107137354267, 0.999194992064265, 0.9992685174114099, 0.9993346902238402, 0.9993942457550277, 0.9994478457330963, 0.9994984108621676, 0.9995415943295223, 0.999578134301332, 0.9996110202759607, 0.9996406176531266, 0.9996672552925758, 0.9996912291680802, 0.999712805656034, 0.9997345496440021, 0.9950715218725236, 0.9935138047281837, 0.9919397622375544], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04641083866716866, 0.10080428157944277, 0.1579404738092997, 0.21185328119117094, 0.2615203568277014, 0.3067009171539674, 0.34707251171492604, 0.38529609521022556, 0.4205844626752723, 0.45273461839381435, 0.4809046865337251, 0.5065171840418736, 0.5296152009068881, 0.5517656031147685, 0.5707324915984724, 0.5867537689822998, 0.6011251200114042, 0.614645273437598, 0.6248377844033262, 0.6330324227551622, 0.6428562100824322, 0.6550588173780294, 0.666230299392109, 0.6783132064822656, 0.6899549538875029, 0.6997061346565087, 0.7089663605639753, 0.7173474800610417, 0.7253543547959014, 0.7326724643558444, 0.7389463806179256, 0.7441219785783469, 0.749393456831205, 0.7545935654496658, 0.7582115044148648, 0.7618990136119326, 0.7649380396792033, 0.7676243350147468, 0.770112154478257, 0.7728079996949645, 0.7767836709227572, 0.7798693757431321, 0.7816474454636231, 0.7841673535904536, 0.785580778717101, 0.7872577523796529, 0.7880935829398803, 0.7884450574301543, 0.7910339513012201, 0.7916874744692909, 0.7922878523518047, 0.7934975201474977, 0.7951050935280792, 0.7962142307302412, 0.7977628001270967, 0.7983527604664201, 0.7997179209314498, 0.799462308008109, 0.8005770888319217, 0.8014644983128107, 0.801335432470611, 0.8030097358444083, 0.8048176666274374, 0.8061172735057327, 0.8062013763509426, 0.8055822976390411, 0.8065276211507394, 0.808045828068045, 0.8097306266147797, 0.8113150399510427, 0.8127532189849294, 0.8140364025928369, 0.8152156819024539, 0.8162037910936091, 0.8171419174906487, 0.8179496101542345, 0.818602261855302, 0.8192517130511724, 0.8198372486361154, 0.8203031955063141, 0.8206615125332429, 0.8210328259824788, 0.8214524573055412, 0.8217680608313876, 0.8220398969733995, 0.8222723424699602, 0.8225446375904341, 0.8227632301190412, 0.8228999577471973, 0.8229253563625377, 0.8224233127725942, 0.8203304367381811, 0.8190807314962153, 0.8188125479832654, 0.8188051754326798, 0.8189094329270624, 0.8191141574619164, 0.8193217940971254, 0.8195330811313134, 0.8196489677659231, 0.8197400291971622, 0.8197853633915272, 0.8197651290102057, 0.8197580955896068, 0.8197883866048178, 0.8198777131834174, 0.8200445858315667, 0.8201072629788317, 0.8201758794426202, 0.8202376342600298, 0.820292184087039, 0.8204277576587568, 0.820661696171872, 0.8208600338024258, 0.8210263306386743, 0.8211383471888881, 0.821189304450421, 0.8212717870795506, 0.8211740934996076, 0.8208033485415897, 0.8181594606471445, 0.8161776460300958, 0.8134774560223423], "moving_var_accuracy_train": [0.020354573299347412, 0.04609534547200003, 0.07230306851657017, 0.09417578143257914, 0.10942955812579493, 0.11992138536994398, 0.12595182968469507, 0.13042412251504132, 0.13189198780477426, 0.13075423419702836, 0.12767359288171548, 0.12340330632557855, 0.11875356280560204, 0.11443678747715454, 0.10840838288814014, 0.10186019280488887, 0.09516685341758144, 0.08869848491430944, 0.08196929967690136, 0.0751370201846868, 0.06974455102859281, 0.065686672761716, 0.06171015318438687, 0.05842986174483978, 0.05515498618300134, 0.05175865157042569, 0.04847646199036174, 0.04503074536754, 0.04179519486386916, 0.038677078526779145, 0.03574048548714631, 0.03273622785094498, 0.030040677880452005, 0.027556302107145974, 0.025100768546016016, 0.02288183040159349, 0.02092953301903921, 0.019092111635938755, 0.017387280331119675, 0.015809991735146085, 0.014463917720032913, 0.013208206386711208, 0.01197642014491385, 0.010913242207701365, 0.00987537752003689, 0.008967480977531594, 0.008093856324468518, 0.007292592544503966, 0.006663889265990834, 0.006039296504906486, 0.005465436353611961, 0.004945864218619277, 0.004489478313634883, 0.0040593843509056865, 0.0036868220163221877, 0.0033242520892230332, 0.0030199266199371307, 0.0027181458573777265, 0.0024569228307439175, 0.0022281616210132237, 0.002006273423073464, 0.0018266302271079105, 0.001672893760508168, 0.0015309638650249984, 0.0013808305214475334, 0.001257779702078662, 0.001143102632906286, 0.0010465950684131434, 0.0009587237255046115, 0.0008774447924848772, 0.0008016653318019787, 0.0007312775205617457, 0.0006660705332769426, 0.0006058440112015662, 0.000550427840395787, 0.0004995713229108541, 0.00045300506652903166, 0.0004104511693626315, 0.00037167261794826713, 0.00033636022579239055, 0.00030422664762070104, 0.0002750519378175229, 0.0002485575875524732, 0.00022453328439716414, 0.0002027534349933977, 0.00018302360951317738, 0.0001651631181573464, 0.00014902160784840894, 0.0001344230362840738, 0.00012121977046757386, 0.0001092247559969029, 0.00011823087576528836, 0.00010690441616744555, 9.676145085176325e-05, 8.771175080374905e-05, 7.947824722319655e-05, 7.196593641573307e-05, 6.51474049913007e-05, 5.8946663702242655e-05, 5.331342107296627e-05, 4.820030058656849e-05, 4.355703004083972e-05, 3.934982970762338e-05, 3.553513390026384e-05, 3.207905311259373e-05, 2.895006820924295e-05, 2.611898691872462e-05, 2.3555742016907205e-05, 2.1239577385161083e-05, 1.91475413983001e-05, 1.7258643877310742e-05, 1.5555790980081664e-05, 1.4016995188748444e-05, 1.2627312195732266e-05, 1.137431436210456e-05, 1.0244766968509973e-05, 9.226676346177829e-06, 8.309181431920317e-06, 7.482453192220105e-06, 6.738463082112877e-06, 0.0002017590687521152, 0.00020342150619283582, 0.00020537784343431265], "duration": 40777.871924, "accuracy_train": [0.4755648489410299, 0.6030965574820044, 0.6882719854535806, 0.7302802146779255, 0.7420625908430233, 0.7588698118540051, 0.7671451786867847, 0.799875703672942, 0.8094767658153378, 0.8140311735765043, 0.8179403074820044, 0.825283812350037, 0.8410650839793282, 0.8677774389188816, 0.8522522941468254, 0.8498810028492986, 0.8503224206349206, 0.8570642707179772, 0.845653918362403, 0.8299892646617755, 0.8726885497416021, 0.9145358209902179, 0.922230261108804, 0.9487090197028424, 0.956334426333518, 0.9577527671073275, 0.9647042410714286, 0.9589629259528424, 0.9653102217146549, 0.9671005862979882, 0.9710769512504615, 0.9591020743932264, 0.9676350100359912, 0.9714947570598007, 0.9608488199058692, 0.9657548838939645, 0.9756571339170359, 0.973960135774271, 0.973657866429033, 0.9731223612264673, 0.9860956101190477, 0.9861428340716132, 0.9761693876315062, 0.986514857881137, 0.976099272679033, 0.983911772679033, 0.9731681432262828, 0.9682417116555924, 0.9931179200119971, 0.9845846238810447, 0.9834681919642857, 0.9843288575119971, 0.9893508184523809, 0.9852825290120893, 0.9915135673334257, 0.9824229564645626, 0.99267578125, 0.9752386071313216, 0.9874678084048542, 0.9914202008928571, 0.9758649553571429, 0.9940243675595238, 0.9982096354166666, 0.9988606770833334, 0.9894910483573275, 0.9714031930601699, 0.994140625, 0.9982096354166666, 0.9992094494047619, 0.9996512276785714, 0.9997209821428571, 0.9997674851190477, 0.9997674851190477, 0.9997442336309523, 0.9997442336309523, 0.9997442336309523, 0.9997442336309523, 0.9997442336309523, 0.9997907366071429, 0.9998139880952381, 0.9998139880952381, 0.9998604910714286, 0.9998604910714286, 0.9998837425595238, 0.9998837425595238, 0.9998837425595238, 0.9998837425595238, 0.9999302455357143, 0.9999302455357143, 0.9999069940476191, 0.9996279761904762, 0.9836785368217055, 0.9947219122023809, 0.9993024553571429, 0.9997209821428571, 0.9997907366071429, 0.9997907366071429, 0.9998604910714286, 0.9998837425595238, 0.9999069940476191, 0.9999302455357143, 0.9999302455357143, 0.9999534970238095, 0.9999534970238095, 0.9999534970238095, 0.9999534970238095, 0.9999534970238095, 0.9999302455357143, 0.9999302455357143, 0.9999302455357143, 0.9999302455357143, 0.9999534970238095, 0.9999302455357143, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999069940476191, 0.9999302455357143, 0.9531042719292175, 0.9794943504291252, 0.97777337982189], "end": "2016-01-29 23:25:56.180000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0], "moving_var_accuracy_valid": [0.019385693512109628, 0.04407494384755606, 0.06904834962554492, 0.08830283186114316, 0.1016739142955924, 0.10987807014859141, 0.11355905396028212, 0.11535252958125315, 0.11502469652826135, 0.11282491948997374, 0.10868440219204129, 0.10371996223028142, 0.0981496314551217, 0.09275043117134742, 0.086713073782992, 0.08035189836577868, 0.07417553010281647, 0.06840312803054523, 0.062497800745569106, 0.05685238955046863, 0.05203571177248463, 0.048172273218531216, 0.04447826399019623, 0.0413444073849208, 0.03842973919025487, 0.03544253500873783, 0.032670047562579886, 0.030035231282538846, 0.02760869854146257, 0.025329821235098277, 0.023151097338960914, 0.021077068933296073, 0.019219458386699667, 0.01754088271482382, 0.015904599784544587, 0.014436519322796262, 0.013075988505454588, 0.011833335298576995, 0.01070570497986648, 0.00970054271477183, 0.008872742098698136, 0.008071162056974685, 0.00729249963865556, 0.006620399107499, 0.005976339132046845, 0.005404015384826197, 0.004869901360872269, 0.004384023033640863, 0.0040059420735575595, 0.0036091916989826507, 0.0032515166115006902, 0.0029395346159340526, 0.0026688397839062373, 0.0024130274735145907, 0.002193307330755025, 0.0019771090764972945, 0.0017961711367050852, 0.001617142064733786, 0.0014666124848266699, 0.0013270386966249507, 0.0011944847488870602, 0.0011002659000859363, 0.0010196568335233591, 0.0009328919525140384, 0.0008396664168597861, 0.000759149101237574, 0.0006912769199897431, 0.0006428937981845592, 0.0006041513336538162, 0.000566329490869587, 0.0005283117721842299, 0.0004902996365102335, 0.00045378597007002497, 0.00041719461102583124, 0.00038339588015465236, 0.00035092759908847903, 0.00031966842736578805, 0.00029149766633156674, 0.0002654335669895209, 0.00024084416866320044, 0.0002179152716229644, 0.00019736460755891944, 0.00017921296082868305, 0.00016218811501555536, 0.00014663435750693473, 0.00013245719993608323, 0.00011987878163617978, 0.00010832094771462782, 9.765710294187583e-05, 8.789719845463919e-05, 8.137590850500579e-05, 0.00011265948851328907, 0.00011544940838812884, 0.00010455176911887904, 9.409708139751037e-05, 8.478519988397382e-05, 7.66838891121171e-05, 6.94035169514335e-05, 6.286494515363407e-05, 5.669931804700097e-05, 5.110401590063455e-05, 4.601211101317971e-05, 4.141458478354887e-05, 3.7273571526241874e-05, 3.3554472284040304e-05, 3.0270838194434975e-05, 2.74943727012945e-05, 2.478029125426857e-05, 2.2344636100767276e-05, 2.014449540795026e-05, 1.81568270197957e-05, 1.6506566057950988e-05, 1.5348454503423253e-05, 1.4167649394324076e-05, 1.2999776194607676e-05, 1.181272794284332e-05, 1.0654824931085349e-05, 9.65057289494996e-06, 8.7714119255137e-06, 9.131337148024191e-06, 7.112949221876212e-05, 9.936484558401995e-05, 0.00015504759572736754], "accuracy_test": 0.0920639349489796, "start": "2016-01-29 12:06:18.308000", "learning_rate_per_epoch": [0.0037439404986798763, 0.002647365676239133, 0.002161565003916621, 0.0018719702493399382, 0.0016743410378694534, 0.001528457272797823, 0.001415076432749629, 0.0013236828381195664, 0.0012479801662266254, 0.0011839378857985139, 0.0011288404930382967, 0.0010807825019583106, 0.0010383822955191135, 0.0010006101801991463, 0.0009666812838986516, 0.0009359851246699691, 0.0009080389281734824, 0.0008824552060104907, 0.0008589188219048083, 0.0008371705189347267, 0.0008169948123395443, 0.000798210792709142, 0.0007806655485183001, 0.0007642286363989115, 0.0007487880648113787, 0.0007342471508309245, 0.0007205216679722071, 0.0007075382163748145, 0.0006952323019504547, 0.0006835468811914325, 0.0006724315462633967, 0.0006618414190597832, 0.0006517363945022225, 0.0006420805002562702, 0.0006328414310701191, 0.0006239900831133127, 0.0006155000301077962, 0.0006073473487049341, 0.0005995102692395449, 0.0005919689428992569, 0.0005847052671015263, 0.0005777025362476707, 0.0005709455581381917, 0.0005644202465191483, 0.0005581136792898178, 0.0005520139238797128, 0.0005461098626255989, 0.0005403912509791553, 0.000534848659299314, 0.0005294731236062944, 0.0005242565530352294, 0.0005191911477595568, 0.000514269748236984, 0.000509485777001828, 0.0005048328312113881, 0.0005003050900995731, 0.0004958970239385962, 0.0004916034522466362, 0.00048741954378783703, 0.0004833406419493258, 0.0004793624684680253, 0.0004754809197038412, 0.00047169215395115316, 0.00046799256233498454, 0.00046437865239568055, 0.00046084722271189094, 0.0004573951300699264, 0.0004540194640867412, 0.00045071745989844203, 0.0004474864690564573, 0.0004443239886313677, 0.00044122760300524533, 0.0004381951002869755, 0.00043522423948161304, 0.0004323130124248564, 0.00042945941095240414, 0.0004266616015229374, 0.00042391777969896793, 0.0004212261992506683, 0.00041858525946736336, 0.0004159933887422085, 0.0004134490736760199, 0.0004109508590772748, 0.00040849740616977215, 0.0004060873470734805, 0.0004037194885313511, 0.00040139254997484386, 0.000399105396354571, 0.00039685689262114465, 0.0003946459910366684, 0.0003924716147594154, 0.00039033277425915003, 0.0003882285382132977, 0.00038615797529928386, 0.0003841201832983643, 0.00038211431819945574, 0.00038013956509530544, 0.0003781951090786606, 0.0003762801643460989, 0.00037439403240568936, 0.000372536014765501, 0.000370705354725942, 0.0003689014120027423, 0.00036712357541546226, 0.0003653711755760014, 0.0003636436304077506, 0.0003619403869379312, 0.00036026083398610353, 0.00035860444768331945, 0.0003569707041606307, 0.00035535910865291953, 0.00035376910818740726, 0.0003522002953104675, 0.000350652146153152, 0.0003491242532618344, 0.00034761615097522736, 0.0003461274318397045, 0.000344657659297809, 0.0003432064549997449, 0.00034177344059571624, 0.0003403582377359271, 0.0003389604389667511, 0.00033757975324988365], "accuracy_train_first": 0.4755648489410299, "accuracy_train_last": 0.97777337982189, "batch_size_eval": 1024, "accuracy_train_std": [0.017168655747695962, 0.017703688956315744, 0.01870588665292395, 0.017889943243449224, 0.01809797361424354, 0.021108959792546404, 0.022480758413662965, 0.023429931259455628, 0.02356713635196146, 0.023842033802153308, 0.021267372691048572, 0.020833098234506704, 0.0235793862570562, 0.024255109227472996, 0.022414634181272423, 0.023821998068654895, 0.023712348432975806, 0.022206056773176188, 0.01985492688774469, 0.018377550145850706, 0.019204342129872178, 0.019244437895349166, 0.01841099844890845, 0.014523177002933645, 0.01271237950002723, 0.01218660384670346, 0.011723731402987997, 0.013084572695195164, 0.00998167555970342, 0.01073813501634511, 0.009666245098455246, 0.012495758431391417, 0.009158080095474868, 0.009292182920931345, 0.008351426821625487, 0.00944524107303459, 0.00654905492261469, 0.008362677334104292, 0.007762368840246226, 0.007519984968174344, 0.005584811899975853, 0.004890036268689848, 0.008123734704162775, 0.0057913286521990275, 0.007374003707533501, 0.005831184738604519, 0.007306784782365725, 0.0077285592853703474, 0.003776386951126396, 0.004946338818201759, 0.005484641131760136, 0.0060880861179386245, 0.0050059325300587385, 0.005510841890477777, 0.004281161771121269, 0.005058947427093854, 0.003444439377710197, 0.00661959601229519, 0.004911026848775263, 0.003989849667160794, 0.007687351280855384, 0.002962078972154056, 0.001412228854079261, 0.0009510398686857123, 0.0038947215517209327, 0.007163414503027556, 0.0028749221570077625, 0.0015935328953385825, 0.0010705789093397823, 0.0006329360857894439, 0.0006493787222734812, 0.0005136421603974731, 0.0005136421603974731, 0.0005245774819883965, 0.0005245774819883965, 0.0005245774819883965, 0.0005245774819883965, 0.0005245774819883965, 0.00045385094159093966, 0.00043870819996542985, 0.00043870819996542985, 0.0004027275873253528, 0.0004027275873253528, 0.0003813527591810065, 0.0003813527591810065, 0.0003813527591810065, 0.0003813527591810065, 0.0003296467373223081, 0.0003296467373223081, 0.0004673491267262319, 0.00085114421585394, 0.005641347187288437, 0.0028436294267367773, 0.0006834513791247706, 0.0005342785199533136, 0.00045385094159093966, 0.00045385094159093966, 0.0003417256895623853, 0.00031625442961159415, 0.0002866635976083043, 0.00025150329767466447, 0.00025150329767466447, 0.00020796763183591793, 0.00020796763183591793, 0.00020796763183591793, 0.00020796763183591793, 0.00020796763183591793, 0.00025150329767466447, 0.00025150329767466447, 0.00025150329767466447, 0.00025150329767466447, 0.00020796763183591793, 0.0003296467373223081, 0.00035719613782871133, 0.00035719613782871133, 0.00035719613782871133, 0.00035719613782871133, 0.00035719613782871133, 0.00035719613782871133, 0.0003296467373223081, 0.016825976807718027, 0.006808783737718387, 0.006127609630618271], "accuracy_test_std": 0.007890559399160195, "error_valid": [0.5358916133283133, 0.4096547322100903, 0.32783379612198793, 0.30293145237198793, 0.29147596244352414, 0.2866740399096386, 0.2895831372364458, 0.27069165333207834, 0.2618202301393072, 0.2579139801393072, 0.26556470020707834, 0.2629703383847892, 0.2625026473079819, 0.24888077701430722, 0.2585655120481928, 0.269054734563253, 0.2695327207266567, 0.2636733457266567, 0.2834296169051205, 0.29321583207831325, 0.2687297039721386, 0.23511771696159633, 0.23322636248117468, 0.21294062970632532, 0.20526931946536142, 0.21253323842243976, 0.20769160626882532, 0.20722244446536142, 0.20258377259036142, 0.20146454960466864, 0.20458837302334332, 0.20929763977786142, 0.2031632388930723, 0.19860545698418675, 0.20922704489834332, 0.20491340361445776, 0.20771072571536142, 0.20819900696536142, 0.20749747035015065, 0.20292939335466864, 0.1874352880271084, 0.19235928087349397, 0.20234992705195776, 0.1931534732680723, 0.2016983951430723, 0.19764948465737953, 0.2043839420180723, 0.20839167215737953, 0.18566600385918675, 0.2024308170180723, 0.2023087467055723, 0.1956154696912651, 0.19042674604668675, 0.19380353445030118, 0.18830007530120485, 0.19633759647966864, 0.1879956348832832, 0.20283820830195776, 0.1893898837537651, 0.19054881635918675, 0.19982616010918675, 0.18192153379141573, 0.17891095632530118, 0.1821862645896084, 0.19304169804216864, 0.1999894107680723, 0.18496446724397586, 0.17829030967620485, 0.1751061864646084, 0.1744252400225903, 0.1743031697100903, 0.17441494493599397, 0.17417080431099397, 0.17490322618599397, 0.17441494493599397, 0.17478115587349397, 0.1755238728350903, 0.17490322618599397, 0.17489293109939763, 0.17550328266189763, 0.17611363422439763, 0.17562535297439763, 0.17477086078689763, 0.17539150743599397, 0.17551357774849397, 0.17563564806099397, 0.17500470632530118, 0.17526943712349397, 0.17586949359939763, 0.17684605609939763, 0.18209507953689763, 0.1985054475715362, 0.19216661568147586, 0.1836011036332832, 0.1812611775225903, 0.18015224962349397, 0.17904332172439763, 0.17880947618599397, 0.17856533556099397, 0.1793080525225903, 0.17944041792168675, 0.17980662885918675, 0.18041698042168675, 0.1803052051957832, 0.1799389942582832, 0.17931834760918675, 0.1784535603350903, 0.1793286426957832, 0.1792065723832832, 0.1792065723832832, 0.17921686746987953, 0.1783520801957832, 0.1772328572100903, 0.1773549275225903, 0.1774769978350903, 0.17785350385918675, 0.1783520801957832, 0.1779858692582832, 0.17970514871987953, 0.1825333560805723, 0.20563553040286142, 0.20165868552334332, 0.21082425404743976], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.004731146341719073, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.003743940468690413, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 3.525789274869458e-06, "rotation_range": [0, 0], "momentum": 0.718887219539727}, "accuracy_valid_max": 0.825829195689006, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7891757459525602, "accuracy_valid_std": [0.02002338856459055, 0.019594163936998418, 0.02003470967907241, 0.023694064102299624, 0.017516114605854755, 0.014512483203416714, 0.015598186899337129, 0.014092377192910793, 0.014974457740005349, 0.014234319504633755, 0.012368317578326446, 0.008063336253598707, 0.012340834949964795, 0.011852993264953537, 0.012345876312206528, 0.01995380292360676, 0.018465844577963755, 0.016589186936781727, 0.02144483014419431, 0.017675964162298972, 0.019072860911738154, 0.017416604572960633, 0.02163633561962502, 0.01913431884895664, 0.014189953398611245, 0.014412620503844805, 0.015947948383616028, 0.011620792349126241, 0.013763992623379183, 0.01607729652815978, 0.012303191618325663, 0.015833567438667834, 0.014064342705183964, 0.018141819051429156, 0.013695334527227028, 0.01227029920303657, 0.016490809090515538, 0.015253177509689386, 0.015677736379634558, 0.014513909137117592, 0.017860459950542244, 0.014534587276497096, 0.012322604828541745, 0.010979470863056253, 0.012677715306634132, 0.014614775219636191, 0.01481043095624798, 0.01757322774063027, 0.01142654846391572, 0.01667065648574569, 0.01128731562923327, 0.011736346746717176, 0.016299479839007307, 0.01661848833549854, 0.016900874044260397, 0.009599152348281702, 0.01549129331105653, 0.01603218121724886, 0.010386637658237703, 0.013954545234673441, 0.017976994056286548, 0.014443384556096674, 0.010353362454095148, 0.0137679245510751, 0.009944146640892907, 0.011914717468065378, 0.00919126926348666, 0.011293870397957553, 0.012032057024549818, 0.009554629576558523, 0.010124637729177663, 0.01083566156101917, 0.010545197407175596, 0.010507197223116263, 0.010669361873065558, 0.010202561309517435, 0.010481983410868607, 0.010172858727590627, 0.010865419578649959, 0.011917004603113481, 0.0122071754866778, 0.0123562772483911, 0.01134343916440004, 0.01162327391600506, 0.011225044857952468, 0.011018299246260679, 0.011232066481861064, 0.010365958589821481, 0.010500266535130736, 0.010366322499256706, 0.013503201979856638, 0.015403453760365607, 0.011844787924399717, 0.011003359896869347, 0.009870784119909782, 0.00942591272911903, 0.009788134400430033, 0.009364659669405525, 0.0100990333902745, 0.010224149416009527, 0.009627841761592775, 0.010119196969533482, 0.00979994602636638, 0.009251115242477612, 0.009528327473808388, 0.009530580974357682, 0.009755387340975285, 0.01006643541753042, 0.010243344043019053, 0.010886503396060784, 0.011664299641690896, 0.012639621689757958, 0.012268169439551075, 0.011842479170853555, 0.012079937371695378, 0.012152620593333259, 0.012826862751360172, 0.012917943966109407, 0.012728954245153579, 0.012823425458714642, 0.013245777996848148, 0.010286980016012314, 0.011491557436205696], "accuracy_valid": [0.46410838667168675, 0.5903452677899097, 0.6721662038780121, 0.6970685476280121, 0.7085240375564759, 0.7133259600903614, 0.7104168627635542, 0.7293083466679217, 0.7381797698606928, 0.7420860198606928, 0.7344352997929217, 0.7370296616152108, 0.7374973526920181, 0.7511192229856928, 0.7414344879518072, 0.730945265436747, 0.7304672792733433, 0.7363266542733433, 0.7165703830948795, 0.7067841679216867, 0.7312702960278614, 0.7648822830384037, 0.7667736375188253, 0.7870593702936747, 0.7947306805346386, 0.7874667615775602, 0.7923083937311747, 0.7927775555346386, 0.7974162274096386, 0.7985354503953314, 0.7954116269766567, 0.7907023602221386, 0.7968367611069277, 0.8013945430158133, 0.7907729551016567, 0.7950865963855422, 0.7922892742846386, 0.7918009930346386, 0.7925025296498494, 0.7970706066453314, 0.8125647119728916, 0.807640719126506, 0.7976500729480422, 0.8068465267319277, 0.7983016048569277, 0.8023505153426205, 0.7956160579819277, 0.7916083278426205, 0.8143339961408133, 0.7975691829819277, 0.7976912532944277, 0.8043845303087349, 0.8095732539533133, 0.8061964655496988, 0.8116999246987951, 0.8036624035203314, 0.8120043651167168, 0.7971617916980422, 0.8106101162462349, 0.8094511836408133, 0.8001738398908133, 0.8180784662085843, 0.8210890436746988, 0.8178137354103916, 0.8069583019578314, 0.8000105892319277, 0.8150355327560241, 0.8217096903237951, 0.8248938135353916, 0.8255747599774097, 0.8256968302899097, 0.825585055064006, 0.825829195689006, 0.825096773814006, 0.825585055064006, 0.825218844126506, 0.8244761271649097, 0.825096773814006, 0.8251070689006024, 0.8244967173381024, 0.8238863657756024, 0.8243746470256024, 0.8252291392131024, 0.824608492564006, 0.824486422251506, 0.824364351939006, 0.8249952936746988, 0.824730562876506, 0.8241305064006024, 0.8231539439006024, 0.8179049204631024, 0.8014945524284638, 0.8078333843185241, 0.8163988963667168, 0.8187388224774097, 0.819847750376506, 0.8209566782756024, 0.821190523814006, 0.821434664439006, 0.8206919474774097, 0.8205595820783133, 0.8201933711408133, 0.8195830195783133, 0.8196947948042168, 0.8200610057417168, 0.8206816523908133, 0.8215464396649097, 0.8206713573042168, 0.8207934276167168, 0.8207934276167168, 0.8207831325301205, 0.8216479198042168, 0.8227671427899097, 0.8226450724774097, 0.8225230021649097, 0.8221464961408133, 0.8216479198042168, 0.8220141307417168, 0.8202948512801205, 0.8174666439194277, 0.7943644695971386, 0.7983413144766567, 0.7891757459525602], "seed": 853609414, "model": "residualv3", "loss_std": [0.33708450198173523, 0.13346660137176514, 0.10898271203041077, 0.09846381843090057, 0.09321997314691544, 0.08955070376396179, 0.0841972678899765, 0.08223462104797363, 0.07840816676616669, 0.07477519661188126, 0.06888175010681152, 0.062318164855241776, 0.07873345911502838, 0.07023826986551285, 0.05580674111843109, 0.04839721694588661, 0.04335087537765503, 0.04042849689722061, 0.034887488931417465, 0.03361886739730835, 0.033731985837221146, 0.02887936681509018, 0.02881990559399128, 0.026235191151499748, 0.023774482309818268, 0.023315677419304848, 0.022148052230477333, 0.018883001059293747, 0.01959974132478237, 0.021451396867632866, 0.01573827490210533, 0.021730177104473114, 0.017686687409877777, 0.016033092513680458, 0.01687689870595932, 0.019601410254836082, 0.014253499917685986, 0.017292745411396027, 0.015429972670972347, 0.019034648314118385, 0.01482356432825327, 0.011980931274592876, 0.016838030889630318, 0.016034457832574844, 0.01667851023375988, 0.01265956275165081, 0.017781637609004974, 0.01503512542694807, 0.012368405237793922, 0.007852466776967049, 0.011293274350464344, 0.02091674879193306, 0.011230730451643467, 0.01181336771696806, 0.011231236159801483, 0.012113788165152073, 0.006901788990944624, 0.015844546258449554, 0.01761391945183277, 0.009952115826308727, 0.014965714886784554, 0.0105240223929286, 0.007257136516273022, 0.0029902951791882515, 0.0030536875128746033, 0.03749360516667366, 0.018184717744588852, 0.004354884847998619, 0.0018826916348189116, 0.00028852291870862246, 0.00014100156840868294, 0.00014447755529545248, 0.0001576318172737956, 0.0001754440163495019, 0.00019665331637952477, 0.0002208291698480025, 0.00024763072724454105, 0.0002767467522062361, 0.00030782161047682166, 0.0003403885057196021, 0.0003738265950232744, 0.0004073723976034671, 0.00044013408478349447, 0.00047107975115068257, 0.0004991921596229076, 0.0005234989803284407, 0.0005431287572719157, 0.0005573764792643487, 0.0005658365553244948, 0.0005681441980414093, 0.0005631365929730237, 0.23319466412067413, 0.014322937466204166, 0.004038338083773851, 0.0007158754160627723, 0.00016879674512892962, 9.91161068668589e-05, 7.604959682794288e-05, 6.268018478294834e-05, 5.4666001233272254e-05, 5.042695556767285e-05, 4.922811785945669e-05, 5.0582260882947594e-05, 5.415113992057741e-05, 5.965149466646835e-05, 6.68622597004287e-05, 7.570366142317653e-05, 8.611229714006186e-05, 9.806027810554951e-05, 0.00011152635124744847, 0.00012648224947042763, 0.00014284039207268506, 0.0001604272983968258, 0.0001789922680472955, 0.00019818493456114084, 0.0002174878609366715, 0.0002362147206440568, 0.00025356438709422946, 0.0002685689541976899, 0.0002798470086418092, 0.311804860830307, 0.044147539883852005, 0.017774682492017746]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:21 2016", "state": "available"}], "summary": "e063d29238d6ab50a392b83c25ea56f4"}