{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 64, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4481538534164429, 1.05448317527771, 0.8385624885559082, 0.6987218260765076, 0.5859648585319519, 0.4842554032802582, 0.38717615604400635, 0.29509255290031433, 0.21256305277347565, 0.1450389176607132, 0.10226356238126755, 0.08060862869024277, 0.06677184253931046, 0.05606156215071678, 0.04702267050743103, 0.040848229080438614, 0.03368249535560608, 0.03252646327018738, 0.02891307882964611, 0.02547198347747326, 0.024510307237505913, 0.021606333553791046, 0.021516971290111542, 0.01680080033838749, 0.016914967447519302, 0.015552157536149025, 0.015446183271706104, 0.013700101524591446, 0.014818274416029453, 0.012038669548928738, 0.013301456347107887, 0.009788903407752514, 0.011637801304459572, 0.010581445880234241, 0.010115641169250011, 0.00832800567150116, 0.007799726445227861, 0.010330448858439922, 0.005769574083387852, 0.009994229301810265, 0.004772726446390152, 0.009011728689074516, 0.005593086127191782, 0.008479384705424309, 0.004005337134003639, 0.008261991664767265, 0.006096343509852886, 0.006058430764824152, 0.006799297872930765, 0.0063435668125748634, 0.004283152054995298, 0.006337188649922609, 0.004114152397960424, 0.00565783865749836, 0.003812227863818407, 0.006235468201339245, 0.0016529239946976304, 0.009066411294043064, 0.0044684503227472305, 0.003995795734226704, 0.004722400102764368, 0.0039878906682133675, 0.004088742192834616, 0.0028305319137871265, 0.004631428048014641, 0.0014129732735455036, 0.0004101831582374871, 0.00028803327586501837, 0.00025134385214187205, 0.00023220179718919098, 0.00022183691908139735, 0.006547795608639717, 0.0032848408445715904, 0.0031886096112430096, 0.0034682159312069416, 0.003917562309652567, 0.0009292074828408659, 0.0061120158061385155, 0.001913669053465128, 0.001501961494795978, 0.005762655753642321, 0.003109840676188469, 0.0021067969501018524, 0.003471233882009983, 0.002047998597845435, 0.00047422360512427986, 0.00026802843785844743, 0.00023575210070703179, 0.00022496171004604548, 0.0002192660904256627, 0.00021543649199884385, 0.0052528101950883865, 0.0020439426880329847, 0.0026805975940078497, 0.0032613740768283606], "moving_avg_accuracy_train": [0.057079194928940556, 0.1172728960467423, 0.17932099202023344, 0.2401345813794873, 0.2981748496800306, 0.35236167470879753, 0.4026340803679934, 0.4497158246302435, 0.4928755471056189, 0.5329233278797838, 0.5705845980991421, 0.6066443106429562, 0.6396232111239725, 0.6679840417165401, 0.6968495234056743, 0.7227749064056385, 0.7469309258818151, 0.7681577018163819, 0.7877569126586454, 0.8055495180428364, 0.8220700337196343, 0.8373754816096679, 0.8507366163690592, 0.8631545157036833, 0.8741166032679125, 0.8845058208019555, 0.8935699069861103, 0.9019138487983427, 0.9087585480651031, 0.9162926880098848, 0.9230758112066354, 0.9289572996515403, 0.934280794088841, 0.9392395300407912, 0.9419051965630595, 0.9458200411151791, 0.948548164270411, 0.9520845251112732, 0.9544256180966391, 0.9573463678179829, 0.9576990463220373, 0.9602831165767844, 0.960816234269189, 0.9633745429839737, 0.9660351297927654, 0.9682623193040297, 0.9699692068653673, 0.9718377938038766, 0.9730871525164199, 0.974460366280328, 0.9759497719857207, 0.9771574512967002, 0.9785002011432669, 0.9796878578123474, 0.9806707183085674, 0.9814412883658613, 0.9824649725483782, 0.9833769877174052, 0.9841419617492823, 0.9846166688827704, 0.9846137167243291, 0.9852317663674185, 0.9852998379426553, 0.9857656422044068, 0.9862940398875744, 0.9871346822143393, 0.9880213965441236, 0.9888892299540338, 0.9897260835943816, 0.9904861552194858, 0.9912236620558798, 0.9910969397110337, 0.9902808028066524, 0.9903366859926723, 0.9904312668339275, 0.9904559357220094, 0.9908361024914936, 0.9907387994590293, 0.9909256303381541, 0.9885387640270684, 0.98842955960895, 0.9885032284980919, 0.9889717091447296, 0.9889472015458252, 0.989387633026994, 0.9899955738528937, 0.9906194865557365, 0.9912344503620953, 0.991839035012809, 0.9924250138770228, 0.9930035120798059, 0.9925431639576042, 0.9924077603583092, 0.9916908753166181, 0.9913106375969257], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.056002035485692755, 0.11316273884600901, 0.17036320771366714, 0.2247672872152673, 0.2752833107527767, 0.32068772628894476, 0.36095046721426716, 0.3969183793595573, 0.4290565371879088, 0.4582717889661059, 0.484709940924164, 0.5086039929537355, 0.5309540134625788, 0.5500659963407185, 0.5689097296791618, 0.5853410988140317, 0.6007274755666647, 0.6141061999132362, 0.6263729554396085, 0.6372400779585241, 0.6473093389409097, 0.6562404850072856, 0.6639764292117528, 0.6715429535063155, 0.6786225566402473, 0.6848740410929395, 0.6899022325691124, 0.6948436734688277, 0.69883122112571, 0.7035349718952926, 0.7074305216748898, 0.7106629613183948, 0.7141661834941607, 0.7172479002821693, 0.7191872492317385, 0.7214494766334894, 0.7227704139946134, 0.7254352788922153, 0.7271846256264878, 0.7288943445397426, 0.729139146249172, 0.7306534131001584, 0.7311617610785461, 0.7324249383215952, 0.7344783546927489, 0.7361352349614259, 0.7372072701060965, 0.7385099276493273, 0.7396579053757351, 0.7398680666924538, 0.7402626723914312, 0.7411834589926496, 0.7416611044808094, 0.7420299502639031, 0.7421686579860067, 0.742052442836879, 0.7423608292478447, 0.742595578872006, 0.7429605444693687, 0.743243273907974, 0.7425261683733513, 0.7425867221873717, 0.7431631815104266, 0.743869071331899, 0.7438207784212242, 0.7441913243554572, 0.7446713000712669, 0.7451775499116553, 0.7456097902141645, 0.7461494088960613, 0.7466493317583377, 0.7466689277146575, 0.7454729204382972, 0.7452998342020729, 0.7458755960284771, 0.746094635870283, 0.7462185295404083, 0.7460360355848615, 0.7455716157142519, 0.7441414837456128, 0.7439438792810666, 0.7440041459086829, 0.74446621837542, 0.7440917150902123, 0.744784170793164, 0.7453585528008204, 0.7458866741303016, 0.7465450887955847, 0.7471254549630895, 0.7473740822830456, 0.7476721185671658, 0.7469230495944854, 0.7465774478541634, 0.7463081749249217, 0.7461442190194025], "moving_var_accuracy_train": [0.029322310443623947, 0.0589996142875948, 0.08774934878425542, 0.11225904776263347, 0.13135119768596162, 0.14464198597764932, 0.15292362031674916, 0.15758147407005754, 0.15858818146041462, 0.15716378601879336, 0.15421274888773373, 0.1504941998176429, 0.14523325072830962, 0.13794895606258156, 0.13165300475463504, 0.124536833632425, 0.11733476976158333, 0.10965647693461171, 0.10214799083190607, 0.0947823830059333, 0.0877604916493859, 0.08109275310047813, 0.07459015708895785, 0.06851897939502578, 0.06274858772941569, 0.057445151525201125, 0.05244005529786508, 0.04782264205277186, 0.04346202701996619, 0.03962669370033756, 0.03607812117302446, 0.03278163621266997, 0.02975852892861872, 0.027003977595927313, 0.024367531838406058, 0.022068712725370802, 0.01992882535638473, 0.018048495452717313, 0.016292972354740743, 0.01474045212967924, 0.013267526355856317, 0.012000870492003908, 0.010803341373069111, 0.00978191172708349, 0.008867429053879185, 0.008025329506563036, 0.007249017742230171, 0.0065555405223280665, 0.005914034544828731, 0.005339602534718336, 0.004825607245443813, 0.004356172924762942, 0.003936782426640739, 0.0035557989392491674, 0.00320891317811952, 0.002893365864226349, 0.0026134606415535314, 0.002359600522414998, 0.0021289071375985144, 0.001918044545601924, 0.0017262401694788868, 0.001557054020782905, 0.0014013903223588113, 0.0012632040526153224, 0.0011393964843579827, 0.0010318169516161228, 0.0009357116171783128, 0.0008489186689066901, 0.0007703297181542917, 0.0006984961262164581, 0.0006335417605983632, 0.0005703321115126764, 0.0005192936153816469, 0.0004673923602177998, 0.0004207336340158125, 0.00037866574760058407, 0.00034209991379410604, 0.00030797513333583607, 0.00027749177199880325, 0.0003010167718818823, 0.0002710224251381233, 0.00024396902657135763, 0.00022154739096068976, 0.00019939805746625738, 0.00018120407072607161, 0.00016640999208362517, 0.00015327239642218, 0.00014134878112814376, 0.00013050360641423677, 0.00012054358683656015, 0.00011150116968851407, 0.00010225833626219431, 9.21975098482931e-05, 8.760307633046688e-05, 8.014399520871239e-05], "duration": 49371.70864, "accuracy_train": [0.5707919492894057, 0.6590162061069582, 0.7377538557816538, 0.7874568856127722, 0.8205372643849206, 0.8400430999677003, 0.8550857313007567, 0.8734515229904946, 0.8813130493839978, 0.8933533548472684, 0.9095360300733666, 0.9311817235372831, 0.9364333154531194, 0.9232315170496493, 0.9566388586078812, 0.9561033534053157, 0.9643351011674051, 0.9591986852274824, 0.964149810239018, 0.9656829665005537, 0.9707546748108158, 0.9751245126199704, 0.9709868292035806, 0.9749156097153008, 0.9727753913459765, 0.9780087786083426, 0.9751466826435032, 0.9770093251084349, 0.9703608414659468, 0.9840999475129198, 0.9841239199773901, 0.9818906956556847, 0.9821922440245479, 0.9838681536083426, 0.9658961952634736, 0.9810536420842562, 0.9731012726674971, 0.983911772679033, 0.9754954549649317, 0.9836331153100776, 0.9608731528585271, 0.9835397488695091, 0.9656142935008305, 0.9863993214170359, 0.98998041107189, 0.988307024905408, 0.9853311949174051, 0.9886550762504615, 0.9843313809293098, 0.9868192901555003, 0.9893544233342562, 0.988026565095515, 0.9905849497623662, 0.9903767678340717, 0.9895164627745479, 0.9883764188815062, 0.99167813019103, 0.991585124238649, 0.9910267280361758, 0.9888890330841639, 0.9845871472983574, 0.9907942131552234, 0.985912482119786, 0.9899578805601699, 0.9910496190360835, 0.9947004631552234, 0.9960018255121816, 0.9966997306432264, 0.9972577663575121, 0.9973267998454227, 0.9978612235834257, 0.9899564386074198, 0.9829355706672205, 0.9908396346668512, 0.9912824944052234, 0.9906779557147471, 0.9942576034168512, 0.9898630721668512, 0.9926071082502769, 0.9670569672272978, 0.9874467198458842, 0.9891662485003692, 0.9931880349644703, 0.9887266331556847, 0.9933515163575121, 0.9954670412859912, 0.9962347008813216, 0.9967691246193245, 0.9972802968692323, 0.9976988236549464, 0.9982099959048542, 0.9884000308577889, 0.9911891279646549, 0.985238909941399, 0.9878884981196937], "end": "2016-01-30 06:42:26.996000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0], "moving_var_accuracy_valid": [0.028226051806867127, 0.05480956070399505, 0.07877564738171489, 0.09753631744129126, 0.11074950340354199, 0.11822860161481699, 0.12099553621471197, 0.12053919893006257, 0.11778102973445659, 0.11368470518918196, 0.1086070175808801, 0.10288464732431894, 0.0970918933425985, 0.0906701150141474, 0.08479888008790586, 0.07874890110393248, 0.07300467629970492, 0.06731512105600833, 0.061937868570701535, 0.0568069308802015, 0.05203874794276388, 0.04755276147901796, 0.043336088825727835, 0.03951775055225692, 0.03601706252183701, 0.03276708579041357, 0.029717921597061735, 0.026965889980843972, 0.024412405809602744, 0.022170292670363613, 0.020089841176095136, 0.018174895052925747, 0.01646785863814818, 0.01490654557958681, 0.013449740690761885, 0.012150825677040789, 0.010951446988944827, 0.009920215834352581, 0.008955736176887712, 0.008086470808060013, 0.007278363078146468, 0.006571163807195788, 0.005916373185480388, 0.005339096417658561, 0.0048431354450326055, 0.004383529170551923, 0.003955519587659412, 0.0035752398789678933, 0.0032295765668140563, 0.002907016420144055, 0.0026177162010486395, 0.0023635752126286245, 0.0021292709982769966, 0.0019175683233546516, 0.0017259846495087273, 0.0015535077382058356, 0.0013990128839914669, 0.001259607562066715, 0.001134845604845368, 0.001022080467779918, 0.0009245005841320048, 0.000832083526598336, 0.0007518659220987357, 0.0006811638538493873, 0.0006130684583114416, 0.0005529973510846869, 0.0004997710061661215, 0.00045210050565754864, 0.0004085719402038127, 0.00037033544108009986, 0.0003355512027861296, 0.00030199953852105344, 0.00028467348531490983, 0.00025647576638995154, 0.0002338117048776546, 0.00021086234046057437, 0.00018991425318799104, 0.0001712225642634922, 0.0001560414801830967, 0.0001588448291942976, 0.0001433117739945452, 0.0001290132851927288, 0.00011803355535410473, 0.0001074924742143763, 0.00010105868089789114, 9.392204502457757e-05, 8.704004976999685e-05, 8.223763363613581e-05, 7.704529426797997e-05, 6.989710473923904e-05, 6.370682490518439e-05, 6.23860813471587e-05, 5.722243827866538e-05, 5.2152765644600195e-05, 4.717942293073203e-05], "accuracy_test": 0.7181839923469389, "start": "2016-01-29 16:59:35.287000", "learning_rate_per_epoch": [0.00028935031150467694, 0.00020460157247725874, 0.00016705648158676922, 0.00014467515575233847, 0.00012940139276906848, 0.00011812677257694304, 0.00010936414037132636, 0.00010230078623862937, 9.645010868553072e-05, 9.150060941465199e-05, 8.724240615265444e-05, 8.352824079338461e-05, 8.025133865885437e-05, 7.733212987659499e-05, 7.47099329601042e-05, 7.233757787616923e-05, 7.017776079010218e-05, 6.820052658440545e-05, 6.638151535298675e-05, 6.470069638453424e-05, 6.314141501206905e-05, 6.168969412101433e-05, 6.033371391822584e-05, 5.906338628847152e-05, 5.787006375612691e-05, 5.674626663676463e-05, 5.568549386225641e-05, 5.468207018566318e-05, 5.373100430006161e-05, 5.282789788907394e-05, 5.196885103941895e-05, 5.1150393119314685e-05, 5.03694245708175e-05, 4.9623169616097584e-05, 4.890913260169327e-05, 4.822505434276536e-05, 4.7568901209160686e-05, 4.6938821469666436e-05, 4.633313437807374e-05, 4.5750304707325995e-05, 4.518892819760367e-05, 4.4647724280366674e-05, 4.4125510612502694e-05, 4.362120307632722e-05, 4.31338012276683e-05, 4.266237738193013e-05, 4.220608389005065e-05, 4.1764120396692306e-05, 4.133575930609368e-05, 4.092031667823903e-05, 4.0517148590879515e-05, 4.012566932942718e-05, 3.974532228312455e-05, 3.937559085898101e-05, 3.9015991205815226e-05, 3.8666064938297495e-05, 3.832538641290739e-05, 3.799355908995494e-05, 3.767020461964421e-05, 3.73549664800521e-05, 3.7047513615107164e-05, 3.674752952065319e-05, 3.645471588242799e-05, 3.616878893808462e-05, 3.5889490391127765e-05, 3.561656194506213e-05, 3.534976713126525e-05, 3.508888039505109e-05, 3.483368709567003e-05, 3.458397986833006e-05, 3.433956590015441e-05, 3.4100263292202726e-05, 3.3865893783513457e-05, 3.363629002706148e-05, 3.341129558975808e-05, 3.3190757676493376e-05, 3.2974530768115073e-05, 3.27624729834497e-05, 3.255445335526019e-05, 3.235034819226712e-05, 3.215003744116984e-05, 3.195339741068892e-05, 3.176032259943895e-05, 3.157070750603452e-05, 3.138445026706904e-05, 3.120144901913591e-05, 3.1021609174786136e-05, 3.0844847060507163e-05, 3.0671071726828814e-05, 3.0500201319227926e-05, 3.0332155802170746e-05, 3.016685695911292e-05, 3.0004230211488903e-05, 2.984420643770136e-05, 2.9686716516152956e-05], "accuracy_train_first": 0.5707919492894057, "accuracy_train_last": 0.9878884981196937, "batch_size_eval": 1024, "accuracy_train_std": [0.022697890652451348, 0.022581827451722002, 0.02388269479324611, 0.024015136115976783, 0.02781790799380009, 0.029578351870583608, 0.0274726406712974, 0.02584744719936042, 0.023539728783408594, 0.023124259368557443, 0.02056570619864814, 0.01897683863621517, 0.018478543396477577, 0.015929842854295953, 0.01428363665193847, 0.013335612095000135, 0.011074800212055116, 0.012040910130595295, 0.0097955475559583, 0.010641797198255183, 0.008182724544832879, 0.007093811564228205, 0.007071226306928973, 0.0077954254300443195, 0.00838090893437759, 0.0057084563969425585, 0.0065073386878432855, 0.005549938471327397, 0.006517218907015166, 0.005484361772333672, 0.004331384492804838, 0.005042897256860732, 0.005370436858351075, 0.004771556123109515, 0.0057445955937808135, 0.005140957838813553, 0.006010665066380261, 0.005637151353664337, 0.006516294571616346, 0.004785377918581951, 0.007372150476041165, 0.0034828290268869963, 0.006385807151406147, 0.004443409953923719, 0.003322519014132027, 0.003819691826521307, 0.003948884510409681, 0.003502170367355045, 0.004585269317123571, 0.004115420400284413, 0.004073627263942752, 0.004172431034396713, 0.003448041308592757, 0.0032305874549302567, 0.0039260472632609, 0.0039225205699360876, 0.002874281960057272, 0.003033578459858246, 0.003424129986723399, 0.0037643876928503345, 0.004035014110220706, 0.0028598881816533275, 0.003969421878978932, 0.00334842599985008, 0.0032458307209753245, 0.0024741242937380338, 0.002084952890883662, 0.002241821578845023, 0.0020431058804777275, 0.0018823300454714818, 0.0016540059955584962, 0.0031209727594947545, 0.005236240564562164, 0.0035153647124520006, 0.0035615230852710923, 0.0031835270314373235, 0.0024692531516869237, 0.0039303034846159225, 0.002714179602546654, 0.005947410924208404, 0.0036067595837311517, 0.003294521859904457, 0.0029108774990932165, 0.003188753870879908, 0.0029694577432043006, 0.0021391099089834854, 0.002013983754279183, 0.0018002384240122088, 0.0016437793441002263, 0.0014098841065960579, 0.001203877720396776, 0.0033760460179246047, 0.0035246135434004837, 0.003485119596936683, 0.003714925716384393], "accuracy_test_std": 0.008127210754624293, "error_valid": [0.4399796451430723, 0.3723909309111446, 0.3148325724774097, 0.28559599727033136, 0.2700724774096386, 0.27067253388554224, 0.27668486445783136, 0.27937041133283136, 0.2817000423569277, 0.2787909450301205, 0.27734669145331325, 0.2763495387801205, 0.26789580195783136, 0.27792615775602414, 0.26149667027484935, 0.2667765789721386, 0.2607951336596386, 0.2654852809676205, 0.26322624482304224, 0.2649558193712349, 0.2620673122176205, 0.26337920039533136, 0.26640007294804224, 0.2603583278426205, 0.25766101515436746, 0.25886259883283136, 0.26484404414533136, 0.2606833584337349, 0.26528084996234935, 0.2541312711784638, 0.2575095303087349, 0.26024508189006024, 0.2543048169239458, 0.255016648625753, 0.2633586102221386, 0.258190476750753, 0.2653411497552711, 0.25058093702936746, 0.25707125376506024, 0.2557181852409638, 0.2686576383659638, 0.2557181852409638, 0.2642631071159638, 0.2562064664909638, 0.24704089796686746, 0.2489528426204819, 0.25314441359186746, 0.24976615446159633, 0.25001029508659633, 0.25824048145707834, 0.2561858763177711, 0.25052946159638556, 0.254040086125753, 0.254650437688253, 0.25658297251506024, 0.2589934935052711, 0.2548636930534638, 0.25529167451054224, 0.25375476515436746, 0.25421216114457834, 0.263927781438253, 0.2568682934864458, 0.25164868458207834, 0.24977792027484935, 0.25661385777484935, 0.2524737622364458, 0.2510089184864458, 0.25026620152484935, 0.250500047063253, 0.24899402296686746, 0.24885136248117468, 0.2531547086784638, 0.2652911450489458, 0.2562579419239458, 0.24894254753388556, 0.2519340055534638, 0.2526664274284638, 0.25560641001506024, 0.2586081631212349, 0.2687297039721386, 0.25783456089984935, 0.2554534544427711, 0.2513751294239458, 0.2592788144766567, 0.24898372788027112, 0.24947200913027112, 0.24936023390436746, 0.24752917921686746, 0.24765124952936746, 0.25038827183734935, 0.24964555487575302, 0.2598185711596386, 0.2565329678087349, 0.256115281438253, 0.2553313841302711], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.06068831156655973, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.0002893503229715214, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 3.733472013303706e-08, "rotation_range": [0, 0], "momentum": 0.8542997832123659}, "accuracy_valid_max": 0.7529591020331325, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7446686158697289, "accuracy_valid_std": [0.014368137747235755, 0.01554967376743471, 0.00772186736047433, 0.011921698213061526, 0.014267048021908499, 0.015004068198485447, 0.01649663000650087, 0.013715630295901228, 0.014192127556198168, 0.017526800069951463, 0.02093416493607319, 0.017517537690066844, 0.020131490423341728, 0.016432921165756283, 0.014635507635383148, 0.0149755653295988, 0.017550063305753053, 0.020898839646139672, 0.015140317615570834, 0.016769179096421345, 0.022729502552796488, 0.018268690410438316, 0.01682319517693587, 0.022905811385192397, 0.009168948188747611, 0.02113573679486958, 0.018363689684086457, 0.01805594386851962, 0.012447811646773756, 0.011140636959349345, 0.01987369830119073, 0.012594471525747632, 0.017900695431492926, 0.019370696360370795, 0.017460164530923285, 0.014277445256879042, 0.009677178335376525, 0.015466777924523589, 0.012350895914346844, 0.013849579212237676, 0.016294174986929724, 0.01371116869892647, 0.012122593450668424, 0.014592106083120497, 0.014895023519277264, 0.013839263696442483, 0.015174564798031392, 0.011606592270776185, 0.011474672995721682, 0.009740201383240887, 0.013679938519962168, 0.009789147788000496, 0.01710308775167367, 0.015364587551748429, 0.01677857156142832, 0.013712558075916684, 0.013451580774493746, 0.0202518048088526, 0.01649819648743688, 0.012646577296505628, 0.014086181978389473, 0.017962964573183922, 0.014520401307401572, 0.01778430349445387, 0.018938235466296627, 0.020987921158172194, 0.021439708808629315, 0.019867048584521787, 0.01911052777963249, 0.01609134879121741, 0.012705055818035577, 0.014997583410368673, 0.015065826319613573, 0.01707917670342544, 0.014977704011024795, 0.013632306755894798, 0.015703659685394993, 0.016140706106085517, 0.020829807244412798, 0.020243241072642262, 0.017816175050170774, 0.015637820407113853, 0.020800990720801903, 0.014659268365757542, 0.014265740395646515, 0.01330735381964513, 0.014955005814104454, 0.01528309396509135, 0.01408116797570747, 0.018507438184638392, 0.017932843569003046, 0.017402957328102295, 0.021036461191631422, 0.015230986988196187, 0.013198983016884302], "accuracy_valid": [0.5600203548569277, 0.6276090690888554, 0.6851674275225903, 0.7144040027296686, 0.7299275225903614, 0.7293274661144578, 0.7233151355421686, 0.7206295886671686, 0.7182999576430723, 0.7212090549698795, 0.7226533085466867, 0.7236504612198795, 0.7321041980421686, 0.7220738422439759, 0.7385033297251506, 0.7332234210278614, 0.7392048663403614, 0.7345147190323795, 0.7367737551769578, 0.7350441806287651, 0.7379326877823795, 0.7366207996046686, 0.7335999270519578, 0.7396416721573795, 0.7423389848456325, 0.7411374011671686, 0.7351559558546686, 0.7393166415662651, 0.7347191500376506, 0.7458687288215362, 0.7424904696912651, 0.7397549181099398, 0.7456951830760542, 0.744983351374247, 0.7366413897778614, 0.741809523249247, 0.7346588502447289, 0.7494190629706325, 0.7429287462349398, 0.7442818147590362, 0.7313423616340362, 0.7442818147590362, 0.7357368928840362, 0.7437935335090362, 0.7529591020331325, 0.7510471573795181, 0.7468555864081325, 0.7502338455384037, 0.7499897049134037, 0.7417595185429217, 0.7438141236822289, 0.7494705384036144, 0.745959913874247, 0.745349562311747, 0.7434170274849398, 0.7410065064947289, 0.7451363069465362, 0.7447083254894578, 0.7462452348456325, 0.7457878388554217, 0.736072218561747, 0.7431317065135542, 0.7483513154179217, 0.7502220797251506, 0.7433861422251506, 0.7475262377635542, 0.7489910815135542, 0.7497337984751506, 0.749499952936747, 0.7510059770331325, 0.7511486375188253, 0.7468452913215362, 0.7347088549510542, 0.7437420580760542, 0.7510574524661144, 0.7480659944465362, 0.7473335725715362, 0.7443935899849398, 0.7413918368787651, 0.7312702960278614, 0.7421654391001506, 0.7445465455572289, 0.7486248705760542, 0.7407211855233433, 0.7510162721197289, 0.7505279908697289, 0.7506397660956325, 0.7524708207831325, 0.7523487504706325, 0.7496117281626506, 0.750354445124247, 0.7401814288403614, 0.7434670321912651, 0.743884718561747, 0.7446686158697289], "seed": 828010696, "model": "residualv3", "loss_std": [0.41404059529304504, 0.28024277091026306, 0.2662453055381775, 0.25256791710853577, 0.23688429594039917, 0.21719539165496826, 0.19300930202007294, 0.16644950211048126, 0.13599279522895813, 0.103349968791008, 0.0783158540725708, 0.0663742870092392, 0.05893845111131668, 0.05313679203391075, 0.04887937009334564, 0.044292647391557693, 0.03880743309855461, 0.03978549316525459, 0.03819271922111511, 0.034470584243535995, 0.035904210060834885, 0.03517189249396324, 0.039830561727285385, 0.027413371950387955, 0.028296807780861855, 0.027627618983387947, 0.028951840475201607, 0.02472670003771782, 0.03162522614002228, 0.0265719722956419, 0.03163086995482445, 0.021114589646458626, 0.028534119948744774, 0.02355950139462948, 0.0235955361276865, 0.019795842468738556, 0.020239664241671562, 0.02557363174855709, 0.01691884547472, 0.029085254296660423, 0.01660751923918724, 0.024262338876724243, 0.019389938563108444, 0.022723881527781487, 0.011863069608807564, 0.022588089108467102, 0.021994369104504585, 0.017087901011109352, 0.02024831250309944, 0.019093114882707596, 0.014798828400671482, 0.02449370175600052, 0.012373079545795918, 0.030651206150650978, 0.013905576430261135, 0.024051308631896973, 0.004556306172162294, 0.04368762671947479, 0.015010206960141659, 0.015308831818401814, 0.017392734065651894, 0.013526850380003452, 0.015492480248212814, 0.013991366140544415, 0.02081298641860485, 0.0050578247755765915, 0.00034354496165178716, 6.121102342149243e-05, 2.5324756279587746e-05, 1.201910799863981e-05, 5.152720859769033e-06, 0.04100394248962402, 0.018026385456323624, 0.018886327743530273, 0.015485389158129692, 0.019430989399552345, 0.004350121598690748, 0.0399494469165802, 0.008060338906943798, 0.014075745828449726, 0.029459429904818535, 0.013832098804414272, 0.010811276733875275, 0.01957022212445736, 0.008937614969909191, 0.0011277315206825733, 0.0001236417010659352, 2.0440213120309636e-05, 8.109508598863613e-06, 3.6253550206311047e-06, 1.6968677982731606e-06, 0.039932865649461746, 0.011491004377603531, 0.016945336014032364, 0.02751999720931053]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:22 2016", "state": "available"}], "summary": "459ee83d653d17bb26c7e64e4ee27934"}