{"content": {"hp_model": {"f0": 16, "f1": 32, "f2": 32, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.012587482572604445, 0.012922892422514074, 0.013986236245198578, 0.017250728622160906, 0.018947130751796798, 0.019228444715788592, 0.016042534011753123, 0.014021529304952679, 0.016764563240579726, 0.016490392763715427, 0.016778977643898095, 0.017166417740450256, 0.017547955858907286, 0.017296221710669708, 0.016872105373387663, 0.01660535034861028, 0.018650469717885657, 0.01845928871064691, 0.02049934621634946, 0.020798138364160917, 0.016201286068169455, 0.01814275432178639, 0.018245997255098536, 0.016710580791977268, 0.016947410834212855, 0.017943502132677445, 0.018690519712011914, 0.02053697151859052, 0.017996646958447663, 0.016336771061362606, 0.015446611828848449, 0.017545226081415913, 0.01808629202014398, 0.018034575601095545, 0.016712659552369773, 0.018282510193988032, 0.018183882562978728, 0.015875202023482075, 0.017635259497294817, 0.015049947458221843, 0.01651453861033334, 0.015096460015568604, 0.014630209747658213, 0.015801642087017075, 0.01753416973876433, 0.019628318400136586, 0.01519640528891459, 0.015656367573332868, 0.014254434425800492, 0.017068990691580282, 0.01588643697654042, 0.013501252443893169, 0.01594156003477291, 0.01578404349128889, 0.013645589207486163, 0.013103719831882443, 0.016760448213489005, 0.014263212362461478, 0.017200234644003342, 0.020785207221892126, 0.01565111562088887, 0.01471961783699933, 0.015396840900140749, 0.014221999393175573, 0.013721174984743567, 0.01873836320502768, 0.016988992455339833, 0.013898390794681097, 0.015657099235750475, 0.016998220705736082, 0.015123573960385838, 0.017869932894636245, 0.016866735420942542, 0.01726381217699817, 0.0166773201462796, 0.017560897045787977, 0.017701700253435947, 0.017182570214236005, 0.017674186685899086, 0.01564608365655523, 0.016058237955818056, 0.013990569848569608, 0.016350693589558735, 0.014954109620657853, 0.01921539470250181, 0.015593287321814534, 0.015215368845083678, 0.013139490634804995, 0.016004236300644147, 0.014212067506350142, 0.017821607985173155, 0.018539910407036658, 0.016615874548011507, 0.015671009238203505, 0.014040913315447871, 0.015298965541037001, 0.01814393787131996, 0.01618869543656819, 0.014460649916384169, 0.016560248337846483, 0.018702490194403877, 0.016502561264580128, 0.016436236547303276, 0.017532066550230388, 0.014143719955851095, 0.016406828313195978, 0.018531611034459522, 0.014165379207635947, 0.01723406281915393, 0.01634209305842317, 0.01750275430231845, 0.017948002615663684, 0.018613541144210894, 0.015221464638626262, 0.015843078160953036, 0.014811247343229195, 0.013161676405042603, 0.016922096739763387, 0.013893508066676722, 0.013792627021161201, 0.016909146935530944, 0.01296277942549246, 0.015593443792565673, 0.011623189893663628, 0.01777595603345114, 0.016509451699390408, 0.009598390343540805, 0.01328361480535542, 0.015810652763637478, 0.013315108182918301, 0.015553297029763808, 0.01412452734156114, 0.01423865029304068, 0.018305192883479447, 0.016087783986142253, 0.014886359862183259, 0.01576858965960308, 0.013843403075198189, 0.014942941171894583, 0.01640892624266118, 0.0159384834107297, 0.014786385849924442, 0.012388568893373456, 0.014481673485337269, 0.016597452868617985, 0.014643692308987778, 0.015816659650702183, 0.013580772370803908, 0.015099208970758763, 0.014390815863222637, 0.014372182897206745, 0.0142951604805529, 0.013312984469537372, 0.013440864540671007, 0.01840110134520345, 0.013450269614027274, 0.015555478647145108, 0.014913569696737763, 0.015047363655892099, 0.013103052682684996, 0.014615480956964525, 0.017309573726458933, 0.017063730868912524, 0.014589722295999533, 0.015743984808373673, 0.012453627013357923, 0.01367408589485876, 0.013297761945191182, 0.013125296583566998, 0.014981721734139792, 0.014706978301015342, 0.015478759941116397, 0.014858449708250988, 0.01425709130624718, 0.013824176474603916, 0.014108870539941084, 0.014624936341049864, 0.01128821244215858, 0.012551746799813782, 0.012301401731753389, 0.014938280046838393, 0.01495845586002779, 0.013961725198583007, 0.013494591508092579, 0.013208001887405634, 0.01349192242942286, 0.013460843621750054, 0.011206446098483128, 0.01181836701714313, 0.013148033008050442, 0.010859421376168988, 0.01100876686837979, 0.011387324974964409, 0.01330177607469754, 0.011778428909180573, 0.013951704384811905, 0.015953828600731076, 0.01135012541568763, 0.014259598277903955, 0.008910826355273986, 0.01040991257175391, 0.011921074779303554, 0.012629025922568293, 0.014005086078285892, 0.012572792738200006, 0.008961306362351385, 0.008127628859819516, 0.012901558184904975, 0.013024124766465825, 0.011192485733384322, 0.011149873468527256, 0.01488647922834829, 0.01429633877831857, 0.014817486836063615, 0.011651345343383737, 0.013145446591907584, 0.011989389684261028, 0.012747088455216268, 0.010703123691077773, 0.015813544569430012, 0.01590157904374727, 0.011501666875147974, 0.00894701859610903, 0.01386237504217814, 0.013390703720474424, 0.010473312805710032, 0.00893582327225115, 0.011697570615276157, 0.011805208367205442, 0.011977469310647778, 0.01060240960982909, 0.012511538573963091, 0.011932635297446441, 0.016354953309019135, 0.011599208930969107, 0.014174402285642594, 0.013132040489668489, 0.01145480618726995, 0.014525061760286425, 0.01546080242603722, 0.0127039471010719, 0.010048841023619411, 0.013438864355127539, 0.012537611349846213, 0.013400414131786558, 0.012492468144028357], "moving_avg_accuracy_train": [0.0464384127560908, 0.10174186450258396, 0.1591887011466408, 0.21471267779277403, 0.2663208010480112, 0.315708596098941, 0.36302419568755184, 0.40654272884581766, 0.4463696788525242, 0.48358319416563833, 0.5182097421759386, 0.5498710009375345, 0.5791962119479708, 0.6058773645050194, 0.6305063499479744, 0.6532489295561208, 0.67397966857956, 0.6930420898376063, 0.7105237537543624, 0.7266105297032156, 0.7415186724404891, 0.7553103498623686, 0.7676903795563643, 0.7792671370107039, 0.7901231304028875, 0.8000700194724639, 0.8091803297541303, 0.8175518502636288, 0.8251673105399606, 0.8326095234862876, 0.8394260977272675, 0.8453449559489575, 0.8513856048377273, 0.857019934632886, 0.862271976762759, 0.8671896571261195, 0.8715619828840686, 0.8752716447781553, 0.8791658708042158, 0.8829496560359943, 0.8864481407946134, 0.889678157285704, 0.892157056356183, 0.8950115298399353, 0.8975151634180957, 0.8998221644027904, 0.902186567448484, 0.9045378526217788, 0.9067119577538885, 0.9083433838811851, 0.9102648911695155, 0.9124127024170896, 0.9135947455232489, 0.9152305348771164, 0.9168863960027307, 0.9180651371241261, 0.9193817705024296, 0.9207387655059888, 0.9222761010031936, 0.9233390847566948, 0.9246745530978858, 0.9259301332716705, 0.9269204662554115, 0.9281046986419597, 0.9290262404172063, 0.9300534098590129, 0.9310428944256678, 0.9319429113749892, 0.932371241736429, 0.9334196227653516, 0.9344677252901731, 0.9352017181208364, 0.9362016031505301, 0.9371506522416233, 0.9377605116033322, 0.9388719989431374, 0.9396725189466181, 0.9403998542497229, 0.9412173245856403, 0.9422737381795865, 0.9427594806522333, 0.943536228750262, 0.9442072921063174, 0.9448229469684524, 0.9450002901395935, 0.9456087608603149, 0.9465515516601268, 0.9473977021823294, 0.9481522982547019, 0.948652362212685, 0.9491908835760879, 0.9500474324173994, 0.9506299893210083, 0.951219394700923, 0.9515731121845036, 0.951877507026869, 0.952263069527855, 0.9525402492168192, 0.952859717742904, 0.9531286021770853, 0.9532009344023908, 0.9536239981753762, 0.9538141294175009, 0.9545526559425743, 0.9545127736770359, 0.9550045442225383, 0.9553726969027669, 0.9560084846137453, 0.9567924262905675, 0.9567539622294786, 0.9574099858685647, 0.9578282019365625, 0.958114059789464, 0.9584526399677712, 0.9584088421485504, 0.9586969456540257, 0.9591933679387062, 0.9595959701675376, 0.9598398016818378, 0.9604730904839844, 0.9607336253701559, 0.9606567891689654, 0.9612082350271242, 0.9614116035982858, 0.9617133620968921, 0.9621102864884394, 0.9625094792658598, 0.9627943480036334, 0.9630531631628955, 0.9633324916359655, 0.9636537498724704, 0.9636171812078977, 0.9642516231669345, 0.9640926323503334, 0.9644563149094123, 0.9648745263090672, 0.9651787648580239, 0.9654478932056472, 0.9655878382197078, 0.9660555135097249, 0.9663345511445405, 0.9665671919718546, 0.9669344985913911, 0.9671326131644687, 0.9674619428064013, 0.9675561596841683, 0.9678896736991401, 0.968092288209071, 0.9681629259786955, 0.9686266058106894, 0.9690763976451796, 0.9692835726474113, 0.9693048003886686, 0.96959376681298, 0.9697980330234318, 0.9698098476497524, 0.9702318519086329, 0.9706673872154163, 0.9709455087974923, 0.9713052083618646, 0.9716451419138288, 0.9719882484427301, 0.9719065635140164, 0.9720957528448314, 0.9722473499544513, 0.9725789917066529, 0.9722521484491474, 0.9726369329697735, 0.9727901795895089, 0.9729908445163091, 0.9729205071230945, 0.9733314617287069, 0.9734734562904246, 0.973773348456694, 0.9738362410646515, 0.9740510987261357, 0.9739815846107204, 0.974398074659246, 0.9745357144755288, 0.9746757942542126, 0.9747415203324366, 0.9750401280814004, 0.975308983201924, 0.9753646525150834, 0.9756125727898302, 0.9759030222061221, 0.9759969799176805, 0.9760143288355193, 0.9760832770889183, 0.9760850929408422, 0.9762191525432604, 0.9760934485580834, 0.9762546104333105, 0.9763647788888721, 0.976570671051203, 0.9768490159985006, 0.9771903154010961, 0.9771509655931755, 0.9771853773279702, 0.9774673918630764, 0.977567817220881, 0.9777792159274566, 0.9779206826871935, 0.9777827555625771, 0.9777818540373271, 0.9780276526336866, 0.9781766836108587, 0.9784014922938851, 0.9783225131514752, 0.9782399503745337, 0.9784119294050021, 0.9786177556597769, 0.9787542793105306, 0.9787539898069415, 0.9791234639632445, 0.9793140484800799, 0.9795042478333453, 0.979807852586971, 0.9798650743188608, 0.98000936353703, 0.9799554649797926, 0.9800117682188011, 0.9800694165803373, 0.980293325068806, 0.9803739349703324, 0.9804278466424114, 0.9806763299449016, 0.9805165677053025, 0.980774744043161, 0.9809651779710247, 0.9811202924644353, 0.981271449154915, 0.981231067257373, 0.9813340882828815, 0.98131294701181, 0.9813751558809041, 0.981677501490442, 0.98171026640692, 0.9816769037162557, 0.98169101907322, 0.9816295344254956, 0.9818112913234776, 0.9817842824269178, 0.9820203910866808, 0.9822351058828207, 0.982360991981508], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 117826898, "moving_var_accuracy_train": [0.019408735613745516, 0.04499410802806125, 0.07019594858893571, 0.0909225615734453, 0.10580089088945055, 0.1171731905004393, 0.12560476513026317, 0.1300890531714606, 0.13135582137584487, 0.1306838507358948, 0.128406446106292, 0.1245877192529814, 0.11986865933494278, 0.11428874851740102, 0.10831915598120455, 0.10214226472818, 0.09579591011948352, 0.08948670224550807, 0.08328850918064301, 0.07728871750643611, 0.07156012023466678, 0.06611600150618273, 0.0608837875725824, 0.05600160063373362, 0.051462113903140455, 0.04720636793228856, 0.04323271091991385, 0.03954018102869103, 0.036108120042805426, 0.032995786840371175, 0.03011439931577918, 0.02741825532803747, 0.025004834746210288, 0.02279006232175477, 0.02075931160838495, 0.018901032668952086, 0.01718298449485951, 0.015588540367689509, 0.014166171297998976, 0.012878407444321104, 0.011700721260345605, 0.010624546193105495, 0.009617396039209542, 0.008728988605113593, 0.007912503374445464, 0.007169153318891357, 0.00650255160286459, 0.005902053320273536, 0.005354388586375373, 0.004842903688617271, 0.004391843032087504, 0.003994176567275606, 0.003607333943691413, 0.0032706828106143057, 0.0029682914141587616, 0.0026839671484243026, 0.002431172144657639, 0.002204627849149036, 0.002005435668112824, 0.0018150615114434097, 0.0016496066415119797, 0.0014988343115159924, 0.001357777715132562, 0.0012346216007274524, 0.0011188025938464296, 0.0010164180280214166, 0.0009235879425881111, 0.0008385194229108919, 0.0007563186827065831, 0.0006905787394721685, 0.000631407535647785, 0.0005731154913621939, 0.0005248018728794258, 0.0004804279331872262, 0.0004357324958380788, 0.00040327788321319616, 0.00036871758537563036, 0.00033660697662635155, 0.00030896059871465955, 0.0002881086259764609, 0.0002614212751264116, 0.0002407091860838927, 0.00022069120172606624, 0.00020203335973689339, 0.0001821130791663575, 0.0001672339008114981, 0.00015851020116023964, 0.00014910291740022807, 0.00013931736275216456, 0.00012763620213561172, 0.00011748262925162308, 0.0001123374495844289, 0.0001041580575394674, 9.686884010237193e-05, 8.830800061585033e-05, 8.031110653479344e-05, 7.361792186081358e-05, 6.69475868945009e-05, 6.117136945747983e-05, 5.570492206223714e-05, 5.018151741337224e-05, 4.677421227614843e-05, 4.242214005162022e-05, 4.308871890059205e-05, 3.8794162366473085e-05, 3.709129055463922e-05, 3.460198906281101e-05, 3.4779824277410135e-05, 3.68329228235985e-05, 3.3162945897197684e-05, 3.3719954442835835e-05, 3.192210111433544e-05, 2.9465323411491096e-05, 2.7550519904624803e-05, 2.4812732154878824e-05, 2.307849160819552e-05, 2.2988558209922405e-05, 2.2148499380870828e-05, 2.0468733709076782e-05, 2.2031352700487465e-05, 2.043912327265036e-05, 1.84483451617059e-05, 1.9340343455860172e-05, 1.777853809190137e-05, 1.6820208006041195e-05, 1.6556127958884667e-05, 1.6334709024897452e-05, 1.543158990225407e-05, 1.449129849200289e-05, 1.3744388205611196e-05, 1.3298811075750575e-05, 1.1980965373233142e-05, 1.4405518230387172e-05, 1.3192469125220023e-05, 1.3063607246701558e-05, 1.3331353495243363e-05, 1.2831267997760497e-05, 1.2200011805434109e-05, 1.1156272087534496e-05, 1.2009126470813605e-05, 1.1508971838523793e-05, 1.0845170445472015e-05, 1.09748807757234e-05, 1.0230637154742458e-05, 1.0183695556767365e-05, 9.245217381596155e-06, 9.321780027080529e-06, 8.759075781083496e-06, 7.928075453452827e-06, 9.070258787488281e-06, 9.984047158106816e-06, 9.371935776243692e-06, 8.438797751609346e-06, 8.346432325862365e-06, 7.887311255866832e-06, 7.099836398835991e-06, 7.992641109571319e-06, 8.900596029708711e-06, 8.706700956485653e-06, 9.000484850323198e-06, 9.140429743049584e-06, 9.28588558031729e-06, 8.417348870496337e-06, 7.89774740949494e-06, 7.31480782135131e-06, 7.573203305446351e-06, 7.777321609692615e-06, 8.332121594544176e-06, 7.710270173232903e-06, 7.301640871539624e-06, 6.6160029243435895e-06, 7.4743558227748674e-06, 6.9083823405140724e-06, 7.0269619089708684e-06, 6.3598650392949265e-06, 6.139352867651845e-06, 5.568907491064451e-06, 6.573192386645775e-06, 6.086375619218633e-06, 5.654339156861542e-06, 5.127784497403761e-06, 5.417505337334471e-06, 5.526302486087201e-06, 5.001563889327226e-06, 5.054587664068986e-06, 5.308376668481331e-06, 4.856991465684704e-06, 4.374001183667834e-06, 3.979385820121983e-06, 3.581476913973673e-06, 3.385077015581016e-06, 3.1887827410271345e-06, 3.10366281716483e-06, 2.9025303328556414e-06, 2.9938015421539376e-06, 3.3917045751133184e-06, 4.100901657510359e-06, 3.7047471582098207e-06, 3.3449299498130543e-06, 3.7262267369326557e-06, 3.444371335651005e-06, 3.5021389203624535e-06, 3.332040625320064e-06, 3.170051588132448e-06, 2.85305374404919e-06, 3.111500919395292e-06, 3.000242916867706e-06, 3.155069120857345e-06, 2.895701553193856e-06, 2.667480907101161e-06, 2.6669238986786486e-06, 2.781511533202362e-06, 2.6711087448178926e-06, 2.403998624647056e-06, 3.392199131763882e-06, 3.379881341103945e-06, 3.3674753528372335e-06, 3.860310435370086e-06, 3.5037483312373137e-06, 3.3407479044327396e-06, 3.0328186042400434e-06, 2.7580672363217243e-06, 2.5121705149799123e-06, 2.7121685643569e-06, 2.499433313938333e-06, 2.2756481980216692e-06, 2.603778942767117e-06, 2.57311680730576e-06, 2.9157003194452317e-06, 2.9505160154349994e-06, 2.8720089684858705e-06, 2.7904431773282416e-06, 2.5260751384373134e-06, 2.368987609865093e-06, 2.136111428961235e-06, 1.9573297766107056e-06, 2.584312607411052e-06, 2.3355432044363278e-06, 2.112006506147961e-06, 1.9025990452532364e-06, 1.746362397880001e-06, 1.8690462877683998e-06, 1.6887069834318782e-06, 2.021561978024422e-06, 2.234327773354858e-06, 2.153520784603757e-06], "duration": 176103.844874, "accuracy_train": [0.4643841275609081, 0.5994729302210225, 0.6762102309431525, 0.7144284676079734, 0.7307939103451458, 0.760198751557309, 0.7888645919850499, 0.7982095272702103, 0.8048122289128831, 0.8185048319836655, 0.8298486742686415, 0.8348223297918974, 0.8431231110418974, 0.846007737518457, 0.8521672189345699, 0.8579321460294389, 0.8605563197905132, 0.8646038811600221, 0.867858729005168, 0.8713915132428941, 0.8756919570759505, 0.8794354466592839, 0.8791106468023256, 0.88345795409976, 0.8878270709325397, 0.8895920210986527, 0.8911731222891289, 0.892895534849114, 0.8937064530269472, 0.89958944000323, 0.9007752658960871, 0.8986146799441677, 0.9057514448366556, 0.9077289027893135, 0.9095403559316169, 0.911448780396364, 0.910912914705611, 0.9086586018249354, 0.9142139050387597, 0.9170037231220007, 0.9179345036221853, 0.9187483057055187, 0.9144671479904946, 0.9207017911937062, 0.9200478656215393, 0.9205851732650425, 0.9234661948597268, 0.9256994191814323, 0.9262789039428755, 0.9230262190268549, 0.9275584567644887, 0.9317430036452565, 0.9242331334786821, 0.9299526390619232, 0.9317891461332595, 0.928673807216685, 0.9312314709071613, 0.9329517205380213, 0.9361121204780363, 0.9329059385382059, 0.9366937681686047, 0.9372303548357327, 0.9358334631090809, 0.9387627901208934, 0.937320116394426, 0.9392979348352714, 0.9399482555255629, 0.9400430639188816, 0.9362262149893872, 0.9428550520256552, 0.9439006480135659, 0.941807653596807, 0.945200568417774, 0.9456920940614618, 0.9432492458587117, 0.9488753850013842, 0.9468771989779439, 0.946945871977667, 0.9485745576088963, 0.9517814605251015, 0.9471311629060539, 0.9505269616325213, 0.9502468623108158, 0.950363840727667, 0.9465963786798633, 0.951084997346807, 0.9550366688584349, 0.9550130568821521, 0.9549436629060539, 0.953152937834533, 0.9540375758467147, 0.9577563719892026, 0.9558730014534883, 0.956524043120155, 0.9547565695367294, 0.954617060608158, 0.9557331320367294, 0.9550348664174971, 0.955734934477667, 0.9555485620847176, 0.9538519244301403, 0.9574315721322444, 0.9555253105966224, 0.9611993946682356, 0.9541538332871908, 0.9594304791320598, 0.9586860710248246, 0.9617305740125508, 0.9638479013819674, 0.9564077856796788, 0.9633141986203396, 0.9615921465485419, 0.9606867804655776, 0.961499861572536, 0.9580146617755629, 0.9612898772033037, 0.9636611685008305, 0.963219390227021, 0.9620342853105389, 0.9661726897033037, 0.9630784393456996, 0.9599652633582503, 0.9661712477505537, 0.9632419207387413, 0.9644291885843485, 0.9656826060123662, 0.9661022142626431, 0.9653581666435955, 0.9653824995962532, 0.9658464478935955, 0.9665450740010151, 0.9632880632267442, 0.9699616007982651, 0.9626617150009228, 0.9677294579411223, 0.9686384289059615, 0.9679169117986341, 0.9678700483342562, 0.9668473433462532, 0.9702645911198781, 0.9688458898578812, 0.9686609594176817, 0.9702402581672205, 0.9689156443221669, 0.9704259095837948, 0.9684041115840717, 0.9708912998338871, 0.9699158187984496, 0.9687986659053157, 0.9727997242986341, 0.9731245241555924, 0.9711481476674971, 0.9694958500599853, 0.9721944646317828, 0.9716364289174971, 0.9699161792866371, 0.9740298902385567, 0.9745872049764673, 0.9734486030361758, 0.9745425044412146, 0.9747045438815062, 0.9750762072028424, 0.9711713991555924, 0.9737984568221669, 0.97361172394103, 0.9755637674764673, 0.9693105591315985, 0.976099993655408, 0.9741693991671282, 0.9747968288575121, 0.9722874705841639, 0.9770300531792175, 0.9747514073458842, 0.9764723779531194, 0.974402274536268, 0.9759848176794942, 0.9733559575719823, 0.9781464850959765, 0.9757744728220746, 0.9759365122623662, 0.9753330550364526, 0.9777275978220746, 0.9777286792866371, 0.975865676333518, 0.9778438552625508, 0.9785170669527501, 0.9768425993217055, 0.9761704690960686, 0.9767038113695091, 0.976101435608158, 0.9774256889650241, 0.9749621126914912, 0.9777050673103543, 0.9773562949889257, 0.9784237005121816, 0.9793541205241787, 0.9802620100244556, 0.97679681732189, 0.9774950829411223, 0.980005522679033, 0.9784716454411223, 0.9796818042866371, 0.9791938835248246, 0.97654141144103, 0.9777737403100776, 0.9802398400009228, 0.979517962405408, 0.9804247704411223, 0.977611700869786, 0.9774968853820598, 0.9799597406792175, 0.9804701919527501, 0.9799829921673128, 0.97875138427464, 0.9824487313699704, 0.9810293091315985, 0.9812160420127353, 0.9825402953696014, 0.9803800699058692, 0.9813079665005537, 0.9794703779646549, 0.9805184973698781, 0.9805882518341639, 0.9823085014650241, 0.9810994240840717, 0.9809130516911223, 0.9829126796673128, 0.979078707548911, 0.9830983310838871, 0.9826790833217978, 0.9825163229051311, 0.9826318593692323, 0.9808676301794942, 0.9822612775124585, 0.9811226755721669, 0.9819350357027501, 0.9843986119762828, 0.9820051506552234, 0.9813766395002769, 0.9818180572858989, 0.9810761725959765, 0.9834471034053157, 0.9815412023578812, 0.9841453690245479, 0.9841675390480805, 0.9834939668696937], "end": "2016-01-31 11:39:24.090000", "learning_rate_per_epoch": [0.007563164457678795, 0.005347964819520712, 0.004366594832390547, 0.0037815822288393974, 0.0033823498524725437, 0.0030876488890498877, 0.002858607331290841, 0.002673982409760356, 0.002521054819226265, 0.0023916824720799923, 0.002280379878357053, 0.0021832974161952734, 0.002097644377499819, 0.0020213406533002853, 0.0019528006669133902, 0.0018907911144196987, 0.0018343367846682668, 0.00178265490103513, 0.0017351089045405388, 0.0016911749262362719, 0.0016504178056493402, 0.001612471998669207, 0.0015770287718623877, 0.0015438244445249438, 0.0015126328216865659, 0.0014832585584372282, 0.0014555316884070635, 0.0014293036656454206, 0.0014044443378224969, 0.0013808385701850057, 0.0013583843829110265, 0.001336991204880178, 0.0013165778946131468, 0.0012970719253644347, 0.0012784081045538187, 0.0012605274096131325, 0.0012433765223249793, 0.0012269072467461228, 0.0012110755778849125, 0.0011958412360399961, 0.001181167783215642, 0.001167021575383842, 0.001153371762484312, 0.0011401899391785264, 0.001127449912019074, 0.0011151276994496584, 0.001103200949728489, 0.0010916487080976367, 0.001080451998859644, 0.0010695928940549493, 0.0010590548627078533, 0.0010488221887499094, 0.0010388805530965328, 0.0010292163351550698, 0.0010198168456554413, 0.0010106703266501427, 0.0010017656022682786, 0.0009930920787155628, 0.0009846400935202837, 0.0009764003334566951, 0.0009683639509603381, 0.0009605227969586849, 0.000952869129832834, 0.0009453955572098494, 0.0009380950941704214, 0.0009309611632488668, 0.0009239875944331288, 0.0009171683923341334, 0.0009104979690164328, 0.0009039710275828838, 0.0008975824457593262, 0.000891327450517565, 0.000885201443452388, 0.0008792000007815659, 0.0008733189897611737, 0.0008675544522702694, 0.0008619025466032326, 0.0008563597220927477, 0.0008509224862791598, 0.0008455874631181359, 0.0008403515676036477, 0.0008352117729373276, 0.0008301651105284691, 0.0008252089028246701, 0.0008203403558582067, 0.0008155569666996598, 0.0008108563488349319, 0.0008062359993346035, 0.000801693822722882, 0.0007972274906933308, 0.0007928350241854787, 0.0007885143859311938, 0.0007842635968700051, 0.0007800808525644243, 0.000775964290369302, 0.0007719122222624719, 0.0007679229602217674, 0.0007639949908480048, 0.0007601266261190176, 0.0007563164108432829, 0.0007525629480369389, 0.0007488648407161236, 0.000745220691896975, 0.0007416292792186141, 0.0007380892639048398, 0.0007345994818024337, 0.0007311587105505168, 0.0007277658442035317, 0.0007244197768159211, 0.0007211194024421275, 0.0007178637897595763, 0.0007146518328227103, 0.0007114826585166156, 0.0007083552191033959, 0.0007052686996757984, 0.0007022221689112484, 0.0006992148119024932, 0.0006962456973269582, 0.0006933141266927123, 0.0006904192850925028, 0.0006875604158267379, 0.0006847367039881647, 0.000681947567500174, 0.0006791921914555132, 0.0006764699937775731, 0.0006737802177667618, 0.0006711222813464701, 0.000668495602440089, 0.0006658994825556874, 0.0006633333978243172, 0.0006607967079617083, 0.0006582889473065734, 0.0006558095337823033, 0.000653357885312289, 0.0006509335362352431, 0.0006485359626822174, 0.0006461647571995854, 0.0006438192795030773, 0.0006414992385543883, 0.0006392040522769094, 0.0006369333132170141, 0.000634686672128737, 0.0006324635469354689, 0.0006302637048065662, 0.0006280866218730807, 0.0006259319488890469, 0.0006237992784008384, 0.0006216882611624897, 0.0006195985479280353, 0.0006175297894515097, 0.0006154815782792866, 0.0006134536233730614, 0.0006114455754868686, 0.0006094571435824037, 0.0006074879784137011, 0.0006055377889424562, 0.0006036062259227037, 0.0006016930565237999, 0.0005997979314997792, 0.0005979206180199981, 0.0005960608250461519, 0.000594218319747597, 0.0005923927528783679, 0.000590583891607821, 0.0005887915613129735, 0.00058701541274786, 0.0005852552130818367, 0.000583510787691921, 0.0005817818455398083, 0.0005800682120025158, 0.0005783696542493999, 0.000576685881242156, 0.0005750167183578014, 0.0005733619909733534, 0.0005717214662581682, 0.0005700949695892632, 0.0005684822681359947, 0.000566883129067719, 0.0005652974359691143, 0.000563724956009537, 0.0005621655727736652, 0.0005606190534308553, 0.0005590851651504636, 0.0005575638497248292, 0.0005560548743233085, 0.0005545581225305796, 0.0005530733615159988, 0.0005516004748642445, 0.0005501392297446728, 0.0005486896261572838, 0.0005472513730637729, 0.0005458243540488183, 0.0005444084526970983, 0.0005430035525932908, 0.0005416094209067523, 0.000540225999429822, 0.0005388531717471778, 0.0005374907050281763, 0.0005361384828574955, 0.0005347964470274746, 0.0005334644811227918, 0.0005321424105204642, 0.0005308300605975091, 0.0005295274313539267, 0.0005282342899590731, 0.0005269506364129484, 0.0005256762378849089, 0.0005244110943749547, 0.000523155031260103, 0.000521907932125032, 0.0005206696805544198, 0.0005194402765482664, 0.0005182194872759283, 0.0005170072545297444, 0.0005158035201020539, 0.0005146081675775349, 0.0005134210223332047, 0.0005122421425767243, 0.0005110712954774499, 0.0005099084228277206, 0.0005087534664198756, 0.0005076063680462539, 0.0005064669530838728, 0.0005053351633250713, 0.0005042109405621886, 0.0005030942265875638, 0.000501984846778214, 0.0005008828011341393, 0.0004997879732400179, 0.0004987003048881888, 0.0004976196796633303, 0.0004965460393577814, 0.0004954793839715421, 0.0004944195388816297, 0.0004933664458803833, 0.0004923200467601418, 0.0004912803415209055, 0.0004902470973320305, 0.0004892204306088388, 0.00048820016672834754, 0.00048718624748289585, 0.0004861786146648228, 0.0004851772100664675, 0.00048418197548016906, 0.0004831928526982665, 0.0004822097544092685], "accuracy_valid": [0.46011242234563254, 0.5978533273719879, 0.6651890766189759, 0.7017204560429217, 0.7121567323983433, 0.7374767625188253, 0.7582801910768072, 0.7698268660579819, 0.7758186064570783, 0.7883624341114458, 0.7985251553087349, 0.8015357327748494, 0.8059611492846386, 0.8152296686746988, 0.815331148814006, 0.8222994517131024, 0.8219023555158133, 0.8262571771460843, 0.8288412438817772, 0.8278029108621988, 0.8300207666603916, 0.8349138742469879, 0.8333475503576807, 0.8350565347326807, 0.8370096597326807, 0.8382303628576807, 0.8391863351844879, 0.8366228586219879, 0.8374670557228916, 0.8378641519201807, 0.8378435617469879, 0.8374876458960843, 0.8430322853915663, 0.8441412132906627, 0.8439676675451807, 0.8451074807040663, 0.8402746729103916, 0.8416792168674698, 0.8453310311558735, 0.8451986657567772, 0.8455854668674698, 0.8440088478915663, 0.8430925851844879, 0.8439985528049698, 0.8448736351656627, 0.843052875564759, 0.8464502541415663, 0.8477930275790663, 0.8468164650790663, 0.8452398461031627, 0.8495123070406627, 0.8495123070406627, 0.8455854668674698, 0.850621234939759, 0.8501226586031627, 0.8464399590549698, 0.8449648202183735, 0.8490034356174698, 0.8492166909826807, 0.8490652061370482, 0.850499164627259, 0.8494917168674698, 0.8482710137424698, 0.8486372246799698, 0.8444662438817772, 0.8505300498870482, 0.8508550804781627, 0.8512109963290663, 0.8462369987763554, 0.8502447289156627, 0.8506006447665663, 0.849156391189759, 0.8509668557040663, 0.8538053581513554, 0.8495431923004518, 0.8558805534638554, 0.8490034356174698, 0.8469179452183735, 0.8507021249058735, 0.8547613304781627, 0.8486475197665663, 0.8522993340549698, 0.8493490563817772, 0.8531641213290663, 0.8488004753388554, 0.852452289627259, 0.8513227715549698, 0.853184711502259, 0.8511698159826807, 0.8519331231174698, 0.8556055275790663, 0.8569997764495482, 0.8571012565888554, 0.8499491128576807, 0.8521566735692772, 0.8496034920933735, 0.852696430252259, 0.8525434746799698, 0.8532964867281627, 0.8515669121799698, 0.850132953689759, 0.8533170769013554, 0.8525537697665663, 0.856480609939759, 0.8503462090549698, 0.856236469314759, 0.8535612175263554, 0.8580778190888554, 0.853795063064759, 0.8553922722138554, 0.8540186135165663, 0.8541715690888554, 0.8528082054781627, 0.8527670251317772, 0.8510992211031627, 0.8487181146460843, 0.8546186699924698, 0.8507933099585843, 0.854893695877259, 0.8540186135165663, 0.8493799416415663, 0.8504785744540663, 0.8552290215549698, 0.8504270990210843, 0.855870258377259, 0.8539274284638554, 0.8502947336219879, 0.8519434182040663, 0.8546392601656627, 0.8528582101844879, 0.8533979668674698, 0.8582204795745482, 0.8579351586031627, 0.8546598503388554, 0.8549142860504518, 0.854771625564759, 0.856165874435241, 0.854527484939759, 0.855137836502259, 0.8584749152861446, 0.8568262307040663, 0.8588411262236446, 0.8529802804969879, 0.854893695877259, 0.8548128059111446, 0.8574777626129518, 0.856776225997741, 0.8567556358245482, 0.8560232139495482, 0.8588308311370482, 0.856898296310241, 0.8561452842620482, 0.8518316429781627, 0.8579557487763554, 0.8546907355986446, 0.8545480751129518, 0.8601633094879518, 0.8590852668486446, 0.8585969855986446, 0.8563482445406627, 0.8574983527861446, 0.856532085372741, 0.8534906226468373, 0.8576101280120482, 0.8551687217620482, 0.855504047439759, 0.8515669121799698, 0.8566129753388554, 0.8556672980986446, 0.852208149002259, 0.8539274284638554, 0.8587190559111446, 0.8581395896084337, 0.8599603492093373, 0.857752788497741, 0.859583843185241, 0.8541715690888554, 0.8583322548004518, 0.8575998329254518, 0.8569997764495482, 0.8557687782379518, 0.859217632247741, 0.8586984657379518, 0.8576101280120482, 0.8594514777861446, 0.861536968185241, 0.8561349891754518, 0.8562570594879518, 0.8549039909638554, 0.8532964867281627, 0.8588308311370482, 0.8557584831513554, 0.8542936394013554, 0.8557790733245482, 0.8595529579254518, 0.8641313300075302, 0.8599603492093373, 0.8555246376129518, 0.858729350997741, 0.856236469314759, 0.8544157097138554, 0.8595735480986446, 0.8584543251129518, 0.8515875023531627, 0.8589631965361446, 0.8582101844879518, 0.8565923851656627, 0.859705913497741, 0.8573762824736446, 0.8546598503388554, 0.8605501105986446, 0.8593499976468373, 0.8587499411709337, 0.8558202536709337, 0.8583425498870482, 0.860194194747741, 0.8616693335843373, 0.8609472067959337, 0.8590749717620482, 0.8608354315700302, 0.8608251364834337, 0.8562673545745482, 0.857213031814759, 0.8617914038968373, 0.8586175757718373, 0.8599294639495482, 0.8575586525790663, 0.857264507247741, 0.860804546310241, 0.8578336784638554, 0.8590749717620482, 0.859461772872741, 0.8593294074736446, 0.8613443029932228, 0.8602956748870482, 0.8603265601468373, 0.8611810523343373, 0.8594411826995482, 0.8636430487575302, 0.8623105704066265, 0.857264507247741, 0.8607839561370482, 0.860926616622741, 0.8611810523343373, 0.8621679099209337, 0.859461772872741], "accuracy_test": 0.8361527423469388, "start": "2016-01-29 10:44:20.245000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0], "accuracy_train_last": 0.9834939668696937, "batch_size_eval": 1024, "accuracy_train_std": [0.015288250886041138, 0.01748199467965769, 0.017682629296018756, 0.01665580548510896, 0.01738893892773895, 0.01669471571957449, 0.014682447624718544, 0.014004682396288494, 0.015051094598811718, 0.015149782210171506, 0.015170315242379072, 0.0157681734586802, 0.014457921536602579, 0.01390436466984125, 0.013904284434416466, 0.013920255507307048, 0.014691534500999191, 0.015274990543801586, 0.013794710518253553, 0.013094933527088905, 0.013179779849083315, 0.014556497487434407, 0.013280613977088948, 0.012229476998885231, 0.013619747565052015, 0.013881142081385755, 0.014669886498436417, 0.01382287950736972, 0.014325945623932827, 0.012985111187879718, 0.012952504622368154, 0.01225462215937992, 0.012006023345063547, 0.012158861793397702, 0.012470793295906458, 0.011645496580832417, 0.012100967405154796, 0.01251827888667838, 0.012745083866714576, 0.013893523038753965, 0.012933721841469334, 0.012449126987352952, 0.013961912295648377, 0.01207520844151546, 0.012380114091123969, 0.01164845670555385, 0.012078960093741731, 0.012953281209030042, 0.011731922661717143, 0.011681119679498286, 0.012823844818615445, 0.013048310139921296, 0.012650558796146037, 0.01198333972599539, 0.012472178647389249, 0.011624426642948769, 0.012794460910259688, 0.012727421791171747, 0.013124600384754203, 0.012253966152975799, 0.011530061314455883, 0.012831085948313468, 0.01265600740750334, 0.011758164420815263, 0.012068558317726427, 0.011963311607742836, 0.012417209996928896, 0.011608004819239884, 0.012322480996734756, 0.01289940973320361, 0.012839771457159052, 0.012748570932994042, 0.012734947915739637, 0.01211402108578137, 0.012691007107028035, 0.012071978293818179, 0.011677861236843723, 0.01223116430166536, 0.01174203538566723, 0.010865382349335498, 0.011909542549307373, 0.011079519267817013, 0.012436838498950793, 0.011812578812049704, 0.012344012629211244, 0.011108158175156084, 0.011015390604834295, 0.010698678478883197, 0.011760397704950508, 0.01159787227111871, 0.012072193430655045, 0.010287974046331878, 0.012253348520313947, 0.010826562099068723, 0.011432021146998088, 0.011976386006975868, 0.010811003264519906, 0.011671912198861196, 0.011286444583814002, 0.01095955563416197, 0.011883431820461865, 0.011303458647787413, 0.011445943574229359, 0.009583982670344117, 0.011536536669455942, 0.01128942122061765, 0.011454116767653413, 0.010502728992531487, 0.009485051709700473, 0.012601384686705738, 0.00960206069120443, 0.010094166158506614, 0.01049140786649355, 0.009975038399722348, 0.010501729096259599, 0.010771483669093149, 0.010602245339720887, 0.010302883923782433, 0.01054613329281059, 0.00913889034229425, 0.010611173476368332, 0.011412835924636522, 0.009660266772705109, 0.010073263249961953, 0.009327061086113893, 0.010276630812979623, 0.009588740246436805, 0.009838966725235309, 0.00912747243891386, 0.009579820103417744, 0.008807553551857075, 0.010118361452126476, 0.008642215273601955, 0.01015465998311069, 0.009158552087207733, 0.009433179510708498, 0.008910773790768399, 0.00919763295671858, 0.00885599146651303, 0.007953496060674662, 0.009190144012087386, 0.008172023611639831, 0.0094102976937486, 0.008970332257015786, 0.00917053368163259, 0.00900310257559808, 0.008236657682955133, 0.00939115307117928, 0.008181096858578369, 0.007926714982608976, 0.0073345243162863775, 0.007840998465236507, 0.00892356068783662, 0.00786957560008726, 0.007637619654553655, 0.009023427743317776, 0.008725144016524338, 0.009022156290115876, 0.008523000482778782, 0.0075783645083687705, 0.007777857571295649, 0.008447727750909033, 0.00901569871302696, 0.008641252148877742, 0.008044166430243244, 0.008541098420472947, 0.009262132341845137, 0.006706431623908725, 0.0074539925797858664, 0.0075474249011499295, 0.007355650527783225, 0.007318100854539441, 0.007461249133826048, 0.007617727312027047, 0.007316812342384716, 0.007671082467425044, 0.007969930338327732, 0.00677169847581395, 0.00699166585063767, 0.007163443313196424, 0.007510847076637204, 0.0065551381464400765, 0.007197361888288146, 0.008663979743524893, 0.006887022781706074, 0.0072981931402130865, 0.007885144869315939, 0.007400436497986644, 0.006528928383742202, 0.007005479482691727, 0.006839566666287115, 0.006923260054322897, 0.005969180488812421, 0.006839164878213665, 0.00670026124204531, 0.0061556584700120905, 0.006826683394372633, 0.007686150654968436, 0.006852326899577073, 0.007077642348720907, 0.007232440582969082, 0.006092578873808344, 0.006207071781778648, 0.007770566207776536, 0.007712503102856849, 0.006547021479106647, 0.006447041861764809, 0.006171227679042384, 0.007020325338329009, 0.0071565699051104, 0.006664217048461592, 0.006761613866381704, 0.006738790658076701, 0.007049646099421322, 0.006340268919478927, 0.006476863476658491, 0.0063681623634438056, 0.005556050397891887, 0.005952035616424288, 0.00621385606070818, 0.006394159337969757, 0.006492608326431581, 0.006111552902455783, 0.005393127817702542, 0.005986822822980011, 0.005966173112624231, 0.005588169496984656, 0.006539669316121921, 0.005741886282820305, 0.006302478141811876, 0.006243695848215992, 0.0062565493014128636, 0.0069610433129712965, 0.00634137357109364, 0.005742287196080009, 0.006822315296225873, 0.00606392441210748, 0.006385280721279012, 0.007188890805079859, 0.0065800526927253, 0.00596833840019131, 0.0058571164235788654, 0.006572356878898331, 0.005322666916511829, 0.005781430569135471, 0.005646759888120788], "accuracy_test_std": 0.009601846988136957, "error_valid": [0.5398875776543675, 0.40214667262801207, 0.33481092338102414, 0.29827954395707834, 0.2878432676016567, 0.2625232374811747, 0.24171980892319278, 0.2301731339420181, 0.22418139354292166, 0.2116375658885542, 0.2014748446912651, 0.19846426722515065, 0.19403885071536142, 0.18477033132530118, 0.18466885118599397, 0.17770054828689763, 0.17809764448418675, 0.17374282285391573, 0.17115875611822284, 0.17219708913780118, 0.1699792333396084, 0.16508612575301207, 0.1666524496423193, 0.1649434652673193, 0.1629903402673193, 0.1617696371423193, 0.16081366481551207, 0.16337714137801207, 0.1625329442771084, 0.1621358480798193, 0.16215643825301207, 0.16251235410391573, 0.15696771460843373, 0.15585878670933728, 0.1560323324548193, 0.15489251929593373, 0.1597253270896084, 0.15832078313253017, 0.1546689688441265, 0.15480133424322284, 0.15441453313253017, 0.15599115210843373, 0.15690741481551207, 0.15600144719503017, 0.15512636483433728, 0.15694712443524095, 0.15354974585843373, 0.15220697242093373, 0.15318353492093373, 0.15476015389683728, 0.15048769295933728, 0.15048769295933728, 0.15441453313253017, 0.14937876506024095, 0.14987734139683728, 0.15356004094503017, 0.1550351797816265, 0.15099656438253017, 0.1507833090173193, 0.15093479386295183, 0.14950083537274095, 0.15050828313253017, 0.15172898625753017, 0.15136277532003017, 0.15553375611822284, 0.14946995011295183, 0.14914491952183728, 0.14878900367093373, 0.1537630012236446, 0.14975527108433728, 0.14939935523343373, 0.15084360881024095, 0.14903314429593373, 0.1461946418486446, 0.15045680769954817, 0.1441194465361446, 0.15099656438253017, 0.1530820547816265, 0.1492978750941265, 0.14523866952183728, 0.15135248023343373, 0.14770066594503017, 0.15065094361822284, 0.14683587867093373, 0.1511995246611446, 0.14754771037274095, 0.14867722844503017, 0.14681528849774095, 0.1488301840173193, 0.14806687688253017, 0.14439447242093373, 0.14300022355045183, 0.1428987434111446, 0.1500508871423193, 0.14784332643072284, 0.1503965079066265, 0.14730356974774095, 0.14745652532003017, 0.14670351327183728, 0.14843308782003017, 0.14986704631024095, 0.1466829230986446, 0.14744623023343373, 0.14351939006024095, 0.14965379094503017, 0.14376353068524095, 0.1464387824736446, 0.1419221809111446, 0.14620493693524095, 0.1446077277861446, 0.14598138648343373, 0.1458284309111446, 0.14719179452183728, 0.14723297486822284, 0.14890077889683728, 0.15128188535391573, 0.14538133000753017, 0.14920669004141573, 0.14510630412274095, 0.14598138648343373, 0.15062005835843373, 0.14952142554593373, 0.14477097844503017, 0.14957290097891573, 0.14412974162274095, 0.1460725715361446, 0.14970526637801207, 0.14805658179593373, 0.14536073983433728, 0.14714178981551207, 0.14660203313253017, 0.14177952042545183, 0.14206484139683728, 0.1453401496611446, 0.14508571394954817, 0.14522837443524095, 0.14383412556475905, 0.14547251506024095, 0.14486216349774095, 0.1415250847138554, 0.14317376929593373, 0.1411588737763554, 0.14701971950301207, 0.14510630412274095, 0.1451871940888554, 0.14252223738704817, 0.14322377400225905, 0.14324436417545183, 0.14397678605045183, 0.14116916886295183, 0.14310170368975905, 0.14385471573795183, 0.14816835702183728, 0.1420442512236446, 0.1453092644013554, 0.14545192488704817, 0.13983669051204817, 0.1409147331513554, 0.1414030144013554, 0.14365175545933728, 0.1425016472138554, 0.14346791462725905, 0.14650937735316272, 0.14238987198795183, 0.14483127823795183, 0.14449595256024095, 0.14843308782003017, 0.1433870246611446, 0.1443327019013554, 0.14779185099774095, 0.1460725715361446, 0.1412809440888554, 0.14186041039156627, 0.14003965079066272, 0.14224721150225905, 0.14041615681475905, 0.1458284309111446, 0.14166774519954817, 0.14240016707454817, 0.14300022355045183, 0.14423122176204817, 0.14078236775225905, 0.14130153426204817, 0.14238987198795183, 0.1405485222138554, 0.13846303181475905, 0.14386501082454817, 0.14374294051204817, 0.1450960090361446, 0.14670351327183728, 0.14116916886295183, 0.1442415168486446, 0.1457063605986446, 0.14422092667545183, 0.14044704207454817, 0.13586866999246983, 0.14003965079066272, 0.14447536238704817, 0.14127064900225905, 0.14376353068524095, 0.1455842902861446, 0.1404264519013554, 0.14154567488704817, 0.14841249764683728, 0.1410368034638554, 0.14178981551204817, 0.14340761483433728, 0.14029408650225905, 0.1426237175263554, 0.1453401496611446, 0.1394498894013554, 0.14065000235316272, 0.14125005882906627, 0.14417974632906627, 0.14165745011295183, 0.13980580525225905, 0.13833066641566272, 0.13905279320406627, 0.14092502823795183, 0.13916456842996983, 0.13917486351656627, 0.14373264542545183, 0.14278696818524095, 0.13820859610316272, 0.14138242422816272, 0.14007053605045183, 0.14244134742093373, 0.14273549275225905, 0.13919545368975905, 0.1421663215361446, 0.14092502823795183, 0.14053822712725905, 0.1406705925263554, 0.13865569700677716, 0.13970432511295183, 0.13967343985316272, 0.13881894766566272, 0.14055881730045183, 0.13635695124246983, 0.1376894295933735, 0.14273549275225905, 0.13921604386295183, 0.13907338337725905, 0.13881894766566272, 0.13783209007906627, 0.14053822712725905], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.9284792818394055, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0075631642869693665, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "l2_decay": 1.7195759384581236e-07, "optimization": "nesterov_momentum", "nb_data_augmentation": 4, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.008682928750997644}, "accuracy_valid_max": 0.8641313300075302, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop', 'santa_sss'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.859461772872741, "loss_train": [1.6000293493270874, 1.2197061777114868, 1.0151153802871704, 0.9039666652679443, 0.8327715396881104, 0.7792638540267944, 0.7366232872009277, 0.7011498212814331, 0.6680670976638794, 0.6412371397018433, 0.6184040904045105, 0.5983507037162781, 0.5793620347976685, 0.5614955425262451, 0.5464237928390503, 0.5310057401657104, 0.5202279090881348, 0.5070274472236633, 0.49453914165496826, 0.48575109243392944, 0.47306159138679504, 0.46412867307662964, 0.45407113432884216, 0.44461578130722046, 0.4356718957424164, 0.4287201762199402, 0.42152807116508484, 0.41355329751968384, 0.4070815443992615, 0.39753785729408264, 0.39165011048316956, 0.38504791259765625, 0.38021209836006165, 0.37354400753974915, 0.3681422770023346, 0.36198410391807556, 0.35628530383110046, 0.35102590918540955, 0.34678196907043457, 0.340841144323349, 0.33635491132736206, 0.331280916929245, 0.32592082023620605, 0.32015377283096313, 0.31894293427467346, 0.31462129950523376, 0.3097028136253357, 0.30381354689598083, 0.30027639865875244, 0.2974338233470917, 0.29367029666900635, 0.2895115315914154, 0.28439366817474365, 0.28302323818206787, 0.27843761444091797, 0.27478280663490295, 0.27005138993263245, 0.2685703933238983, 0.2643199861049652, 0.2615198493003845, 0.2572941184043884, 0.2549040615558624, 0.25307396054267883, 0.2485276758670807, 0.24629126489162445, 0.24456672370433807, 0.2406480759382248, 0.23998624086380005, 0.23640407621860504, 0.23427629470825195, 0.23290292918682098, 0.22971011698246002, 0.22599278390407562, 0.22358989715576172, 0.2233329862356186, 0.2190786749124527, 0.21553120017051697, 0.21355505287647247, 0.21262522041797638, 0.20859535038471222, 0.2083510309457779, 0.20783329010009766, 0.20492081344127655, 0.20237579941749573, 0.19841602444648743, 0.19882257282733917, 0.19552548229694366, 0.19295404851436615, 0.1917400360107422, 0.18880729377269745, 0.18722788989543915, 0.1888069063425064, 0.18523913621902466, 0.18158869445323944, 0.1807529330253601, 0.17802783846855164, 0.17859214544296265, 0.17710496485233307, 0.17387856543064117, 0.17123468220233917, 0.1715886890888214, 0.16890393197536469, 0.1664850413799286, 0.16598878800868988, 0.16409681737422943, 0.1634434014558792, 0.1626891791820526, 0.15978553891181946, 0.1582976132631302, 0.15787066519260406, 0.15599201619625092, 0.15507817268371582, 0.15272216498851776, 0.1521712988615036, 0.14832673966884613, 0.14939533174037933, 0.14866849780082703, 0.14733721315860748, 0.1458483636379242, 0.14425641298294067, 0.14256291091442108, 0.13932281732559204, 0.1395985335111618, 0.140065997838974, 0.13923996686935425, 0.13544794917106628, 0.13575519621372223, 0.1336907595396042, 0.1339026242494583, 0.13246655464172363, 0.13092806935310364, 0.1302129030227661, 0.12964089214801788, 0.12951622903347015, 0.12718799710273743, 0.12626086175441742, 0.12466485798358917, 0.12418027222156525, 0.1223161518573761, 0.12241093069314957, 0.12165281921625137, 0.11925368756055832, 0.1204490140080452, 0.12169177830219269, 0.11776203662157059, 0.11624497920274734, 0.11486880481243134, 0.1152019277215004, 0.11442054063081741, 0.11317228525876999, 0.11069200187921524, 0.11133397370576859, 0.1114986315369606, 0.10925506055355072, 0.10891856998205185, 0.1089043840765953, 0.10721723735332489, 0.10839974880218506, 0.1053590327501297, 0.10588573664426804, 0.10536778718233109, 0.10420754551887512, 0.1009327620267868, 0.10118263959884644, 0.10048747807741165, 0.10184410214424133, 0.10056719183921814, 0.09846305847167969, 0.09851180016994476, 0.09694916009902954, 0.0969686433672905, 0.0969911739230156, 0.0961160883307457, 0.09505946934223175, 0.09338827431201935, 0.09499310702085495, 0.09331680089235306, 0.09298966825008392, 0.0925140231847763, 0.09302972257137299, 0.08923123776912689, 0.090065598487854, 0.08839736878871918, 0.0893426313996315, 0.08856154978275299, 0.08718924969434738, 0.08767358213663101, 0.0867195576429367, 0.08453893661499023, 0.08637280017137527, 0.08429215848445892, 0.08484943211078644, 0.08566789329051971, 0.08426504582166672, 0.08109554648399353, 0.08313348889350891, 0.08161760121583939, 0.0803980603814125, 0.08135327696800232, 0.07984968274831772, 0.07979311048984528, 0.08074001222848892, 0.07852210849523544, 0.0779227614402771, 0.07838635891675949, 0.07798720896244049, 0.07666191458702087, 0.07704206556081772, 0.07513553649187088, 0.07662568241357803, 0.07595956325531006, 0.07525243610143661, 0.07370222359895706, 0.07314283400774002, 0.07363033294677734, 0.07233503460884094, 0.07236334681510925, 0.07187201082706451, 0.0718008279800415, 0.07196918874979019, 0.07015145570039749, 0.07007014751434326, 0.07138023525476456, 0.07086098194122314, 0.06972530484199524, 0.06906197965145111, 0.06847981363534927, 0.06784018129110336, 0.06831925362348557, 0.0675574317574501, 0.06632347404956818, 0.06652910262346268, 0.06573397666215897, 0.06598521769046783, 0.0645236074924469, 0.06536126881837845, 0.06589589267969131, 0.06400035321712494, 0.06325975805521011, 0.06380157172679901, 0.06270471215248108, 0.06298798322677612, 0.06086643785238266, 0.06254652142524719, 0.06273261457681656, 0.062049560248851776], "accuracy_train_first": 0.4643841275609081, "model": "residualv3", "loss_std": [0.2803526222705841, 0.1497936248779297, 0.1341501921415329, 0.1303185224533081, 0.12874558568000793, 0.12369555234909058, 0.12261354178190231, 0.1193598136305809, 0.11725914478302002, 0.11627837270498276, 0.11531735956668854, 0.11466780304908752, 0.11265189200639725, 0.11120203882455826, 0.10886281728744507, 0.1068854033946991, 0.10613544285297394, 0.10314653068780899, 0.10357365012168884, 0.1030237004160881, 0.1003277599811554, 0.09826067090034485, 0.09910418093204498, 0.09824129939079285, 0.09659995883703232, 0.09540126472711563, 0.09618920087814331, 0.0930178314447403, 0.0932558998465538, 0.0902956873178482, 0.09048745781183243, 0.09106159955263138, 0.08902104943990707, 0.08890367299318314, 0.08656454086303711, 0.0849076360464096, 0.08637421578168869, 0.08417224138975143, 0.08413249999284744, 0.08309724181890488, 0.08220132440328598, 0.08202662318944931, 0.07866720110177994, 0.07911122590303421, 0.07970388978719711, 0.07898840308189392, 0.07934034615755081, 0.07622773945331573, 0.07745128870010376, 0.07747029513120651, 0.07470190525054932, 0.07338409870862961, 0.07438457012176514, 0.0737057700753212, 0.07200293987989426, 0.06990867108106613, 0.07239042967557907, 0.072859987616539, 0.07220052182674408, 0.06847572326660156, 0.06621336936950684, 0.06697722524404526, 0.06671901047229767, 0.06728418171405792, 0.06826416403055191, 0.06417012959718704, 0.06677327305078506, 0.06604306399822235, 0.0651296004652977, 0.06439048796892166, 0.06395174562931061, 0.06335224211215973, 0.06343084573745728, 0.06110473722219467, 0.06329111009836197, 0.060918066650629044, 0.05950894579291344, 0.058426279574632645, 0.061196453869342804, 0.05879576504230499, 0.05778063088655472, 0.058365512639284134, 0.05720481649041176, 0.05990006402134895, 0.05605226755142212, 0.0578157901763916, 0.05577163025736809, 0.05581226199865341, 0.0555139034986496, 0.05533967167139053, 0.054238513112068176, 0.05413210391998291, 0.05359702557325363, 0.05308423936367035, 0.053675565868616104, 0.05371241271495819, 0.05299537628889084, 0.05328378081321716, 0.0504487007856369, 0.05010246858000755, 0.05160531401634216, 0.05126868560910225, 0.04889197275042534, 0.04909944161772728, 0.0498509556055069, 0.05045346915721893, 0.0489298440515995, 0.04798266291618347, 0.046817101538181305, 0.04753996804356575, 0.047879382967948914, 0.04692777246236801, 0.04765365272760391, 0.04642674699425697, 0.04545058310031891, 0.04589853808283806, 0.04689428210258484, 0.045131977647542953, 0.043624840676784515, 0.04450148716568947, 0.042248666286468506, 0.04418226331472397, 0.04364791512489319, 0.04434243589639664, 0.04336383193731308, 0.041945893317461014, 0.041657138615846634, 0.042357753962278366, 0.043651510030031204, 0.04334872588515282, 0.041083402931690216, 0.03986118361353874, 0.04106508195400238, 0.040481530129909515, 0.03849813714623451, 0.03931129351258278, 0.04017265886068344, 0.04006842523813248, 0.04005786404013634, 0.037779927253723145, 0.03845091909170151, 0.03821174427866936, 0.03913504630327225, 0.040676720440387726, 0.03709224611520767, 0.03753229230642319, 0.03682805225253105, 0.03861832246184349, 0.036271434277296066, 0.03782034292817116, 0.034959498792886734, 0.03598133474588394, 0.03608915954828262, 0.03511982783675194, 0.03416454419493675, 0.036268990486860275, 0.03561966493725777, 0.03631420433521271, 0.03468497097492218, 0.0358729287981987, 0.034644242376089096, 0.03456754609942436, 0.03192484751343727, 0.032654449343681335, 0.033170752227306366, 0.03430250659584999, 0.033571891486644745, 0.03353814780712128, 0.033017415553331375, 0.03193321079015732, 0.03239576518535614, 0.03268842026591301, 0.03280059993267059, 0.03363877162337303, 0.031123854219913483, 0.03200514614582062, 0.030313555151224136, 0.032850444316864014, 0.031066348776221275, 0.030797207728028297, 0.030080100521445274, 0.031075110659003258, 0.030869578942656517, 0.03007897175848484, 0.030340518802404404, 0.030272936448454857, 0.030196158215403557, 0.029662711545825005, 0.029485931620001793, 0.030316127464175224, 0.028619850054383278, 0.02884211577475071, 0.03039347566664219, 0.029372820630669594, 0.028054142370820045, 0.02798572927713394, 0.028411343693733215, 0.028029976412653923, 0.02777733840048313, 0.027905212715268135, 0.027920620515942574, 0.028192343190312386, 0.027886170893907547, 0.026456452906131744, 0.02624649927020073, 0.027129072695970535, 0.026341386139392853, 0.027814174070954323, 0.02590220235288143, 0.02567708119750023, 0.025851745158433914, 0.026521110907197, 0.025592338293790817, 0.024558069184422493, 0.02529212087392807, 0.02627469040453434, 0.024311356246471405, 0.025682544335722923, 0.025675442069768906, 0.025839079171419144, 0.024550333619117737, 0.02394498512148857, 0.02540111169219017, 0.025644510984420776, 0.02553100883960724, 0.02446330152451992, 0.02463931031525135, 0.02395709790289402, 0.023952191695570946, 0.02442299947142601, 0.022984564304351807, 0.023561900481581688, 0.023091061040759087, 0.024158276617527008, 0.023380206897854805, 0.023392079398036003, 0.023346900939941406, 0.022269735112786293, 0.023211022838950157, 0.023212043568491936, 0.022600455209612846, 0.0236916895955801, 0.022669225931167603, 0.022964145988225937, 0.023516207933425903, 0.020813103765249252]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:25 2016", "state": "available"}], "summary": "6f52c1c2b860248cb2289a918c69ccaa"}