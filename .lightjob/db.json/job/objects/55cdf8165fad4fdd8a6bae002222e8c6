{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 32, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.026078643733900404, 0.028864429387885505, 0.029988446817648437, 0.031012212136116723, 0.031046126362814577, 0.030403641772061858, 0.03451273700247564, 0.036685935368182127, 0.031045541948640707, 0.03031160167895518, 0.029013645921115296, 0.030929610394875733, 0.02998663170117323, 0.03244635152347486, 0.0296495353033637, 0.02957355786131248, 0.03169562343690767, 0.029881166294185586, 0.03445749343818854, 0.032170618379571886, 0.030717114147543394, 0.030748993692629904, 0.029420397670108584, 0.032752461209153955, 0.026468125520831734, 0.03064437582453325, 0.030653255592854152, 0.030200663153334223, 0.03317298863611811, 0.03443379049343808, 0.02704518661835981, 0.028953550275155712, 0.03052394892070865, 0.021928118102945184, 0.022969907055271774, 0.022178225534361454, 0.025828372444411385, 0.022877303638237048, 0.024165486359550244, 0.0286790312263567, 0.023693882350650394, 0.025556490985201092, 0.025839609500607322, 0.026151593074972466, 0.030912594017627065, 0.029075489462584335, 0.025078489488657388, 0.031740241817531954, 0.02566841672447002, 0.029031150384801876, 0.023668599062093395, 0.025613223373091853, 0.030905550017531595, 0.02626719991325111, 0.024267381340703147, 0.03194820491459826, 0.026933593067936506, 0.025796038641221056, 0.020836913367836458, 0.025095846848784947, 0.02536908915300335, 0.025093677835354232, 0.024446902148040153, 0.023202535560489734, 0.02220357161889176, 0.027006920333733055, 0.020009835780937416, 0.025221330471224223, 0.017173898114772875, 0.020629514783487766, 0.020312214166103775, 0.021033643637869758, 0.019963538718799866, 0.02065412605827882, 0.01811979711293129, 0.019715705240874987, 0.02263011210607586, 0.023390230523373082, 0.024255415913120523, 0.02398612860063055, 0.02272931131958411, 0.01984869478192275, 0.0190005752702706, 0.023180630133942837, 0.023289172190124715, 0.021328314022510224, 0.021324060185330652, 0.021108556452903552, 0.019152749692085656, 0.01952799839163908, 0.026344448436041078, 0.020371973153069284, 0.0203273935268975, 0.023225982734149348, 0.022792285666311928, 0.01960866420805802, 0.019533572246010225, 0.022732504087027806, 0.023755827246819614, 0.01929338283382961, 0.019125257919503067, 0.02241664230895983, 0.022953313439588088, 0.022443336019678135, 0.02396796760722562, 0.02309044346774244, 0.022959636231096925, 0.017378687821854755, 0.0197662548792706, 0.021402195445405208, 0.024821789528868137, 0.023123421980336463, 0.024909349761490757, 0.023791696639366377, 0.019398422443313242, 0.022977804565237046, 0.022877303638237048, 0.02731354232134969, 0.02460447538777166, 0.02095673159971041, 0.020625996489817857, 0.02170440261805971, 0.021306184794931144, 0.02103019295395877, 0.018227618344867746, 0.019501966007424137, 0.020954999996187544, 0.022194581160134806, 0.021446232931156595, 0.02098960492438667, 0.020963656583492876, 0.021429306146411208, 0.019595705920170615, 0.01943953271905006, 0.02184771155489267, 0.02347385581980302, 0.02152055261904265, 0.01718129177954563, 0.02294777956793842, 0.028670172838121788, 0.02078634884096716, 0.017651128503104702, 0.018523829135421426, 0.022843969821648685, 0.019477761925531266, 0.01918020205962022, 0.01631462492310319, 0.02305427001640151, 0.01769732363183582, 0.01793663200616089, 0.02205928458613607, 0.022049412451121124, 0.018076689288115087, 0.018348654314501965, 0.02108963811928803, 0.022565881189316028, 0.0187400110877572, 0.021943833332088547, 0.018758397408601593, 0.019766254879270605, 0.020241525424173776, 0.022284322527020155, 0.01915653856446537, 0.019931704001178784, 0.01689591086432003, 0.02156518975882489, 0.020753153557925615, 0.017858573554299408, 0.01933940786254047, 0.019136638615493577, 0.02092033782706682, 0.017192903971561257, 0.020321144575049688, 0.018918275740979724, 0.017694247708699384, 0.013663744238055773, 0.027993270373753116, 0.020924673738288133, 0.018918275740979724, 0.019173579224823326, 0.015904666830928085, 0.01772805351021785, 0.02103191836668301, 0.016909865114736227, 0.018206703113257776, 0.02473465286883196, 0.021664240234933154, 0.02439489530748226, 0.021706074438021212, 0.022974645887022208, 0.02006054869733994, 0.018931697719071786, 0.022368837801648583, 0.021859334886962064, 0.022359102342982766, 0.01961236500344967, 0.0201786829085707, 0.023360735613353393, 0.01758934627468257, 0.020121055137791753, 0.021633230842118815, 0.02007320690754004, 0.019961720959750455, 0.020206537276507733, 0.02074615830920311, 0.018907723216989858, 0.023041674634724427, 0.018158806409133005, 0.019931704001178784, 0.01972490571981194, 0.018674059079335528, 0.021222567231930098, 0.02651538211884365, 0.022129086126421414, 0.020795075634601118, 0.017456813404442256, 0.02218313348828891, 0.021023289886989947, 0.02426139936456229, 0.018564921502176777, 0.01840591686695983, 0.01920855977368091, 0.020349695547436698, 0.020234353300492454, 0.021265270336062375, 0.01960958947238356, 0.01983680796606152, 0.015678323843697696, 0.02113776057345694, 0.022997536474897457, 0.016813021311023624, 0.022303854476597277, 0.01603531916964777, 0.01932533020954844, 0.020385328030595486, 0.020574913624062528, 0.021697714050067894, 0.015814288923964626, 0.017776090179228037, 0.02103623127934327, 0.019042544463568876, 0.01934128410876002, 0.017617175089916694, 0.019283976474324654, 0.02085432098437948, 0.018676973637386626, 0.01939655172413793, 0.019776349301975166, 0.02371148809375726, 0.02052900712610163, 0.0238807545389874, 0.01898433505112917, 0.018581528291550003, 0.017207671791671673, 0.020531658367912046, 0.01418111227182312, 0.015356784966643961, 0.021058644186297257, 0.01821467365237801, 0.01724137931034483, 0.02143015280318033, 0.018618595789941017, 0.017207671791671673, 0.018901004906962338, 0.01850815090228197, 0.018711912924366934, 0.0196622575658219, 0.020739160701007016, 0.023671665141394044, 0.018665312674561597, 0.018102766753899966, 0.023198625394203608, 0.01698266973326992, 0.02112144560135557, 0.0268208587600294, 0.017541832538900546, 0.021540777122795587, 0.019501966007424137, 0.01810076212881726, 0.019827659412346117, 0.015280983621650625, 0.015477998299809512, 0.017198179648745652, 0.02053342567227236, 0.018137811828677703, 0.018567853191338708, 0.014807010866014327, 0.02040667765560951, 0.018803802119197358], "moving_avg_accuracy_train": [0.027240210843373486, 0.057281626506024086, 0.08774981174698793, 0.11764905873493973, 0.1450784299698795, 0.16909185956325296, 0.19244999288403608, 0.21397588967996983, 0.2408910830914909, 0.2691410184570406, 0.29524837745471, 0.3213028883538173, 0.3462320874702428, 0.3741912394159896, 0.4002745627635472, 0.4241213534751443, 0.4495344252059431, 0.47141315512510784, 0.4927818170222356, 0.5104558190549519, 0.5295556626012639, 0.5491433945339086, 0.5681136559841322, 0.5830008031869238, 0.6016938516332917, 0.6160703060783963, 0.6323011896271833, 0.6473113756343445, 0.6624606974082594, 0.6711722707397226, 0.6833330933645455, 0.6947790573714645, 0.7084995703090169, 0.7200244250251031, 0.7325146406551228, 0.7420356728245503, 0.7523906522288423, 0.761390103572223, 0.7694166617390972, 0.7779724541495248, 0.7844560822285481, 0.7907219762647294, 0.7980508516804252, 0.8044350549159971, 0.811529200026807, 0.8155372363494274, 0.8205375413289425, 0.8264332412623133, 0.8294944540336724, 0.8339650011001847, 0.8383508805082385, 0.8431476636923544, 0.8475683077146852, 0.8523140183588793, 0.854253173751907, 0.8579609512562344, 0.8615968026667555, 0.8651679205928511, 0.8708456880215177, 0.8726730168097274, 0.8756636217552607, 0.8794870374411804, 0.882384530986219, 0.8848793233695249, 0.8878070536831748, 0.8904090666883513, 0.8931250312544559, 0.893799821050697, 0.896922662740808, 0.9000814883341971, 0.9016348982357172, 0.9050613933519045, 0.9066039174203284, 0.9064249827566089, 0.9074452292098637, 0.9106883757165882, 0.913063627000351, 0.9154743200232075, 0.9178580815449832, 0.9187445248965089, 0.9184316311417978, 0.9187265516119554, 0.9184225146736514, 0.9213562421219489, 0.9224835132410792, 0.922507375772393, 0.9231877375927441, 0.9249366407913009, 0.9252752432784359, 0.9246551925951706, 0.9238665370404728, 0.9226037538183532, 0.9231144627738673, 0.9250777717675649, 0.9267623891691216, 0.9289774341377516, 0.931738105633615, 0.931500100793145, 0.9322624589367221, 0.933282730362327, 0.933730342115251, 0.9347685466085451, 0.9346298884838351, 0.9339921067137649, 0.9353994660725089, 0.9347976783508002, 0.9360374135277683, 0.9364895833195697, 0.9366000376382151, 0.9380713403502973, 0.9366328998393639, 0.9355642069939818, 0.9360848759030174, 0.9373229621078963, 0.9374936214693959, 0.938910863238119, 0.9407276082396082, 0.9394518165421535, 0.9405108705807093, 0.9425817714744456, 0.943026625200495, 0.9436952540961081, 0.9438146217587865, 0.9459269472335102, 0.9477103820282315, 0.9488919040663722, 0.950268244533229, 0.9518434532124362, 0.952188098855048, 0.9533265931864106, 0.9548971718195768, 0.9536398529809926, 0.9553932434359055, 0.9560370892730378, 0.9570048223638062, 0.9571486548864617, 0.9582005439158878, 0.959450802024299, 0.9588935230266884, 0.9596462076216099, 0.9590505627630634, 0.9579544296795282, 0.9574926651754307, 0.9574441704952371, 0.9574381758854724, 0.9581669674836721, 0.9580510425726543, 0.9579725949418949, 0.9579137578874645, 0.9571430899300434, 0.9571883818406535, 0.9585704472710459, 0.9581576796523751, 0.9585697919582219, 0.9585241832443274, 0.9591655525704971, 0.9602157706568208, 0.9607421039827051, 0.962001760301302, 0.9625142160482802, 0.9635166536301992, 0.9647388775744082, 0.9656223881603408, 0.9656810077780417, 0.9664208889279483, 0.9658607842219005, 0.9658932110707947, 0.9654964727950406, 0.9662995175336089, 0.9666810492139829, 0.9659655045335485, 0.9654932951946514, 0.9648353436872344, 0.9655468394389929, 0.9657777353143706, 0.9666914903973913, 0.9623980943697004, 0.9628685635471882, 0.9628095874635537, 0.9631424276629815, 0.9643997210412616, 0.9645029530034005, 0.9648311780343858, 0.9654066069176942, 0.9661527496897803, 0.9671090108653805, 0.9676872664053484, 0.9683018228973437, 0.9675324463305008, 0.9673247589263665, 0.9666366166180671, 0.9673444722755374, 0.9671838202287065, 0.9677192973925829, 0.9685942050027222, 0.9683015201952211, 0.9691464434769038, 0.9696456733762013, 0.9703750066409907, 0.9708007966395422, 0.9710663495057086, 0.9712982875973064, 0.9703963391086601, 0.9702411178483965, 0.9710544495876533, 0.9701698254120206, 0.9705125943768426, 0.9701880856921704, 0.968578256791628, 0.9676165154498146, 0.9670992163144718, 0.9672548820324222, 0.9654465625038787, 0.9647344551992739, 0.9655125157034429, 0.9653985758800865, 0.9654631045872586, 0.9652223287670869, 0.9661398549265228, 0.9671021119037501, 0.9681799278218087, 0.9683687121480616, 0.9684021346079543, 0.9682204301833035, 0.96853458821919, 0.9689796986743795, 0.9693544132948934, 0.9695151692545607, 0.9691845107628396, 0.9699576071263147, 0.9712299187028398, 0.9716666971638811, 0.9722433444655653, 0.9710821689045509, 0.9712819339418066, 0.9723747495837705, 0.9718781443543091, 0.9730219375996011, 0.9742513703456651, 0.9749931196062793, 0.9754630282781815, 0.975977719426267, 0.9762409226342428, 0.9759812882021438, 0.976662997484339, 0.9772247662600015, 0.9763867022846039, 0.9769549221163845, 0.9775275021939026, 0.9777180878178858, 0.9777131276806755, 0.9784522629547767, 0.97881392671954, 0.9788335129632487, 0.9787052444982491, 0.9793898781809544, 0.97918950105563, 0.9787714922151273, 0.9792000658851808, 0.9785621564352169, 0.9779033240748278, 0.9781292755528872, 0.9789115098951888, 0.9796108144779592, 0.9793789310723319, 0.9788666780253396, 0.9790104130842514, 0.9790409418059467, 0.9792401985289665, 0.9787888819893228, 0.9793874975554507, 0.979801533944484, 0.9805577322066621, 0.9803794062751525, 0.9803530432078782, 0.9809787893388976, 0.9811654548327187, 0.9808487022711335, 0.981290752224743, 0.9818015489902205, 0.9825483519225239, 0.9824486372121991, 0.9827777569247141, 0.9827586408707969, 0.9829602805487775, 0.9828029008372733, 0.9827177350005339, 0.9826787363498781, 0.9823636112088662], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.006678261781122984, 0.014132815498156027, 0.021074326755239615, 0.02701257881373456, 0.031082654589458372, 0.03316419233803569, 0.03475819463431544, 0.03545265326670661, 0.038427236667452236, 0.04176704263412664, 0.04372468611521269, 0.045461755347416734, 0.04650876452995257, 0.04889331567468553, 0.05012704191889619, 0.05023236257219099, 0.051021544248124426, 0.05022749922919377, 0.04931432670773824, 0.04719422716763652, 0.04575804066231525, 0.04463534977647007, 0.043410652174231616, 0.041064231323346724, 0.040102678732976356, 0.037952552841388223, 0.03652827178421793, 0.034903195761522336, 0.033478393737256626, 0.030813577952716113, 0.029063190619656145, 0.027335962386119683, 0.026296638424933585, 0.024862375068482292, 0.023780186939993585, 0.022218018728135683, 0.02096124724149191, 0.01959403363767963, 0.018214460997967585, 0.017051829152103806, 0.015724983134497335, 0.014505837673701477, 0.013538665640060434, 0.012551621534632174, 0.011749401434848013, 0.01071904048783422, 0.009872163888044268, 0.009197780998578979, 0.008362342111404866, 0.007705980019929494, 0.007108505461574459, 0.006604737075655769, 0.006120142210239716, 0.005710823914881502, 0.005173584436138128, 0.00477995451871868, 0.004420933806161309, 0.004093616374723906, 0.003974388124017772, 0.0036070014861179734, 0.0033267947989684093, 0.003125681886637601, 0.0028886729175657032, 0.002655821527131339, 0.0024673838175233876, 0.0022815796808830172, 0.0021198098845137394, 0.001911926967484366, 0.0018085035327293887, 0.0017174567916214988, 0.0015674288533586139, 0.0015163537870540526, 0.001386132832863654, 0.0012478077081022126, 0.0011323950627204016, 0.0011138175498250735, 0.0010532121627917208, 0.001000193914166588, 0.0009513153936842123, 0.0008632558906549694, 0.0007778114241051076, 0.0007008130844480585, 0.0006315637221419319, 0.0006458681605957867, 0.0005927180061204379, 0.0005334513302920005, 0.0004842722271221232, 0.0004633729659912146, 0.0004180675341907391, 0.00037972094642002487, 0.0003473466500336234, 0.0003269635782248611, 0.0002966146331375555, 0.00030164440966640535, 0.0002970213908064157, 0.0003114770696432522, 0.0003489211266515807, 0.00031453883072320675, 0.0002883156571025904, 0.00026885267542948413, 0.00024377061441873638, 0.0002290943701059288, 0.0002063579677752686, 0.0001893830612738473, 0.0001882706984282614, 0.00017270296474342965, 0.00016926515805019754, 0.00015417875993073798, 0.00013887068534623105, 0.00014446620184682915, 0.00014864158159359365, 0.00014405636301417386, 0.00013209059172828298, 0.00013267724961185952, 0.0001196716462096804, 0.0001257816496678318, 0.00014290854630497619, 0.00014326649177213, 0.000139034201704148, 0.00016372845613883366, 0.00014913666406317076, 0.0001382465790572935, 0.0001245501589016038, 0.0001522524132119463, 0.00016565292889395377, 0.00016165158494406786, 0.00016253524417602822, 0.00016861326120587309, 0.00015282096065602748, 0.00014920438867332926, 0.00015648440499261944, 0.00015506362045008575, 0.0001672266611914904, 0.00015423483223027517, 0.000147239915021963, 0.00013270211367092776, 0.00012939013707587808, 0.0001305194314071223, 0.00012026252719701118, 0.00011333508137219972, 0.00010519470841259602, 0.00010548880720272096, 9.685896459764767e-05, 8.719423374394669e-05, 7.84751337876681e-05, 7.54078551513601e-05, 6.798801690117448e-05, 6.124460148800292e-05, 5.515129752996909e-05, 5.498152968233334e-05, 4.950183892860044e-05, 6.174259872071422e-05, 5.710173281185166e-05, 5.2920088504340055e-05, 4.764680104695402e-05, 4.658431245522068e-05, 5.185250346927294e-05, 4.916049405177229e-05, 5.8525051015426265e-05, 5.5036043947382835e-05, 5.8576369503436274e-05, 6.616321488127262e-05, 6.657221199224117e-05, 5.9945917129231605e-05, 5.887814246019347e-05, 5.581378374980665e-05, 5.0241868879588906e-05, 4.6634293326665564e-05, 4.777479166327794e-05, 4.430741030511156e-05, 4.448470698188252e-05, 4.204307122136824e-05, 4.173486577424157e-05, 4.211741503975078e-05, 3.838548968317415e-05, 4.206147588057348e-05, 0.00020375457334784734, 0.000185371187235757, 0.00016686537211814905, 0.00015117587829153016, 0.00015028537021398138, 0.0001353527447346467, 0.00012278705529986944, 0.0001134884153675925, 0.00010715013515785882, 0.0001046650405657169, 9.720795173467813e-05, 9.08862736978922e-05, 8.712510904256436e-05, 7.88008046588328e-05, 7.518258272119286e-05, 7.217386113538932e-05, 6.518875674320888e-05, 6.125050320618532e-05, 6.20146228220837e-05, 5.65841401087531e-05, 5.735078426524306e-05, 5.385878026989274e-05, 5.326024534306013e-05, 4.9565894914552745e-05, 4.5243970345659496e-05, 4.1203730816099875e-05, 4.440495742003193e-05, 4.018130443476911e-05, 4.211675065403369e-05, 4.494811497765644e-05, 4.151071854909736e-05, 3.830739967203683e-05, 5.780060150602536e-05, 6.034505903240029e-05, 5.6718938687998995e-05, 5.126513116090424e-05, 7.556879370061736e-05, 7.257578564999839e-05, 7.076661041832802e-05, 6.380678992661346e-05, 5.746358652039581e-05, 5.223898482857018e-05, 5.459177462495573e-05, 5.7466043574462616e-05, 6.217462359600353e-05, 5.627791693295191e-05, 5.066017878708419e-05, 4.5891309389815056e-05, 4.219043589444219e-05, 3.975450216086847e-05, 3.704275136622324e-05, 3.357105853671787e-05, 3.119796802637177e-05, 3.3457273108700086e-05, 4.468053652766947e-05, 4.192946169116916e-05, 4.0729214516909006e-05, 4.8791251216691236e-05, 4.4271280726010245e-05, 5.059236689929839e-05, 4.7752680994724146e-05, 5.475177978703172e-05, 6.288014570217838e-05, 6.15438588225561e-05, 5.737680037966036e-05, 5.402328314295205e-05, 4.924443818685519e-05, 4.4926684713151896e-05, 4.461656415071722e-05, 4.299516515142944e-05, 4.5016809678021756e-05, 4.342099270527823e-05, 4.2029524941286966e-05, 3.815347836777997e-05, 3.433835195765228e-05, 3.5821405342671864e-05, 3.3416470917089456e-05, 3.007827641386404e-05, 2.721852396449775e-05, 2.8715181083498384e-05, 2.6205021906327776e-05, 2.515710223234118e-05, 2.429447052507545e-05, 2.5527379669746747e-05, 2.688118241463569e-05, 2.4652550807107102e-05, 2.7694310822881216e-05, 2.932612183594465e-05, 2.6877438876597767e-05, 2.655132364631334e-05, 2.408212918612549e-05, 2.1682304293148106e-05, 1.987140303885057e-05, 1.9717442305568596e-05, 2.0970763439108004e-05, 2.041652227819031e-05, 2.352139235586202e-05, 2.145545436091466e-05, 1.9316164026668173e-05, 2.090857160837322e-05, 1.9131310506787112e-05, 1.8121169123545014e-05, 1.806772566456625e-05, 1.8609173118710167e-05, 2.1767687384109644e-05, 1.968040585679487e-05, 1.8687243337609132e-05, 1.682180781550451e-05, 1.550555407157894e-05, 1.4177914026759524e-05, 1.2825401601811238e-05, 1.1556549494406878e-05, 1.1294629235446145e-05], "duration": 74664.733552, "accuracy_train": [0.2724021084337349, 0.3276543674698795, 0.36196347891566266, 0.38674228162650603, 0.39194277108433734, 0.38521272590361444, 0.4026731927710843, 0.4077089608433735, 0.4831278237951807, 0.5233904367469879, 0.5302146084337349, 0.5557934864457831, 0.5705948795180723, 0.6258236069277109, 0.6350244728915663, 0.6387424698795181, 0.6782520707831325, 0.6683217243975904, 0.6850997740963856, 0.6695218373493976, 0.7014542545180723, 0.7254329819277109, 0.7388460090361446, 0.7169851280120482, 0.7699312876506024, 0.7454583960843374, 0.7783791415662651, 0.7824030496987951, 0.798804593373494, 0.7495764307228916, 0.7927804969879518, 0.7977927334337349, 0.8319841867469879, 0.8237481174698795, 0.8449265813253012, 0.8277249623493976, 0.8455854668674698, 0.8423851656626506, 0.8416556852409639, 0.8549745858433735, 0.842808734939759, 0.8471150225903614, 0.8640107304216867, 0.8618928840361446, 0.8753765060240963, 0.8516095632530121, 0.8655402861445783, 0.8794945406626506, 0.8570453689759037, 0.8741999246987951, 0.8778237951807228, 0.8863187123493976, 0.8873541039156626, 0.8950254141566265, 0.8717055722891566, 0.8913309487951807, 0.8943194653614458, 0.8973079819277109, 0.9219455948795181, 0.8891189759036144, 0.9025790662650602, 0.9138977786144579, 0.9084619728915663, 0.9073324548192772, 0.9141566265060241, 0.9138271837349398, 0.9175687123493976, 0.8998729292168675, 0.9250282379518072, 0.9285109186746988, 0.9156155873493976, 0.9358998493975904, 0.9204866340361446, 0.9048145707831325, 0.9166274472891566, 0.9398766942771084, 0.9344408885542169, 0.9371705572289156, 0.9393119352409639, 0.926722515060241, 0.9156155873493976, 0.9213808358433735, 0.9156861822289156, 0.9477597891566265, 0.932628953313253, 0.9227221385542169, 0.9293109939759037, 0.9406767695783133, 0.9283226656626506, 0.9190747364457831, 0.9167686370481928, 0.9112387048192772, 0.927710843373494, 0.9427475527108434, 0.9419239457831325, 0.9489128388554217, 0.9565841490963856, 0.9293580572289156, 0.9391236822289156, 0.9424651731927711, 0.9377588478915663, 0.9441123870481928, 0.9333819653614458, 0.9282520707831325, 0.9480657003012049, 0.9293815888554217, 0.9471950301204819, 0.9405591114457831, 0.9375941265060241, 0.9513130647590361, 0.9236869352409639, 0.9259459713855421, 0.9407708960843374, 0.9484657379518072, 0.9390295557228916, 0.9516660391566265, 0.9570783132530121, 0.9279696912650602, 0.9500423569277109, 0.9612198795180723, 0.9470303087349398, 0.9497129141566265, 0.9448889307228916, 0.9649378765060241, 0.9637612951807228, 0.9595256024096386, 0.9626553087349398, 0.9660203313253012, 0.9552899096385542, 0.9635730421686747, 0.9690323795180723, 0.9423239834337349, 0.9711737575301205, 0.9618317018072289, 0.9657144201807228, 0.9584431475903614, 0.9676675451807228, 0.970703125, 0.9538780120481928, 0.9664203689759037, 0.9536897590361446, 0.9480892319277109, 0.9533367846385542, 0.957007718373494, 0.9573842243975904, 0.9647260918674698, 0.957007718373494, 0.9572665662650602, 0.9573842243975904, 0.950207078313253, 0.9575960090361446, 0.9710090361445783, 0.9544427710843374, 0.9622788027108434, 0.9581137048192772, 0.9649378765060241, 0.9696677334337349, 0.9654791039156626, 0.9733386671686747, 0.9671263177710844, 0.9725385918674698, 0.9757388930722891, 0.9735739834337349, 0.9662085843373494, 0.9730798192771084, 0.9608198418674698, 0.9661850527108434, 0.961925828313253, 0.9735269201807228, 0.9701148343373494, 0.9595256024096386, 0.9612434111445783, 0.9589137801204819, 0.9719503012048193, 0.9678557981927711, 0.9749152861445783, 0.9237575301204819, 0.9671027861445783, 0.9622788027108434, 0.9661379894578314, 0.9757153614457831, 0.9654320406626506, 0.967785203313253, 0.9705854668674698, 0.9728680346385542, 0.9757153614457831, 0.9728915662650602, 0.9738328313253012, 0.9606080572289156, 0.9654555722891566, 0.9604433358433735, 0.9737151731927711, 0.9657379518072289, 0.9725385918674698, 0.9764683734939759, 0.9656673569277109, 0.9767507530120482, 0.9741387424698795, 0.9769390060240963, 0.974632906626506, 0.9734563253012049, 0.9733857304216867, 0.9622788027108434, 0.9688441265060241, 0.9783744352409639, 0.9622082078313253, 0.973597515060241, 0.9672675075301205, 0.954089796686747, 0.958960843373494, 0.9624435240963856, 0.9686558734939759, 0.9491716867469879, 0.9583254894578314, 0.9725150602409639, 0.9643731174698795, 0.9660438629518072, 0.9630553463855421, 0.9743975903614458, 0.9757624246987951, 0.9778802710843374, 0.9700677710843374, 0.9687029367469879, 0.9665850903614458, 0.9713620105421686, 0.9729856927710844, 0.9727268448795181, 0.9709619728915663, 0.9662085843373494, 0.9769154743975904, 0.9826807228915663, 0.975597703313253, 0.9774331701807228, 0.9606315888554217, 0.9730798192771084, 0.9822100903614458, 0.9674086972891566, 0.9833160768072289, 0.985316265060241, 0.9816688629518072, 0.9796922063253012, 0.9806099397590361, 0.9786097515060241, 0.973644578313253, 0.9827983810240963, 0.9822806852409639, 0.9688441265060241, 0.9820689006024096, 0.9826807228915663, 0.9794333584337349, 0.9776684864457831, 0.9851044804216867, 0.9820689006024096, 0.9790097891566265, 0.977550828313253, 0.9855515813253012, 0.9773861069277109, 0.9750094126506024, 0.9830572289156626, 0.9728209713855421, 0.9719738328313253, 0.9801628388554217, 0.9859516189759037, 0.9859045557228916, 0.9772919804216867, 0.9742564006024096, 0.9803040286144579, 0.9793157003012049, 0.9810335090361446, 0.9747270331325302, 0.9847750376506024, 0.9835278614457831, 0.9873635165662651, 0.9787744728915663, 0.9801157756024096, 0.9866105045180723, 0.9828454442771084, 0.9779979292168675, 0.9852692018072289, 0.9863987198795181, 0.989269578313253, 0.9815512048192772, 0.9857398343373494, 0.9825865963855421, 0.9847750376506024, 0.9813864834337349, 0.9819512424698795, 0.9823277484939759, 0.979527484939759], "end": "2016-01-19 10:42:04.077000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0], "accuracy_valid": [0.27209051724137934, 0.3247575431034483, 0.3615301724137931, 0.38254310344827586, 0.38254310344827586, 0.37351831896551724, 0.3934536637931034, 0.39480064655172414, 0.4676724137931034, 0.5026939655172413, 0.5119881465517241, 0.5344827586206896, 0.5470096982758621, 0.5991379310344828, 0.6085668103448276, 0.6105872844827587, 0.6474946120689655, 0.6290409482758621, 0.6419719827586207, 0.6248653017241379, 0.658270474137931, 0.6795528017241379, 0.6897898706896551, 0.6726831896551724, 0.7221174568965517, 0.6945043103448276, 0.7276400862068966, 0.7310075431034483, 0.7388200431034483, 0.6947737068965517, 0.7337015086206896, 0.736260775862069, 0.7664331896551724, 0.7580818965517241, 0.7742456896551724, 0.7563308189655172, 0.7737068965517241, 0.7730334051724138, 0.7698006465517241, 0.7794989224137931, 0.7733028017241379, 0.7704741379310345, 0.7850215517241379, 0.7823275862068966, 0.7975484913793104, 0.7699353448275862, 0.7860991379310345, 0.7972790948275862, 0.7785560344827587, 0.7957974137931034, 0.7933728448275862, 0.7992995689655172, 0.8037446120689655, 0.8076508620689655, 0.794989224137931, 0.8049568965517241, 0.8120959051724138, 0.8042834051724138, 0.8259698275862069, 0.7970096982758621, 0.8107489224137931, 0.8155980603448276, 0.8122306034482759, 0.8142510775862069, 0.8165409482758621, 0.8176185344827587, 0.8165409482758621, 0.8009159482758621, 0.8255657327586207, 0.8296066810344828, 0.8118265086206896, 0.8296066810344828, 0.8275862068965517, 0.8038793103448276, 0.81640625, 0.8367456896551724, 0.8349946120689655, 0.8309536637931034, 0.8352640086206896, 0.8236799568965517, 0.8127693965517241, 0.8172144396551724, 0.8131734913793104, 0.837823275862069, 0.8257004310344828, 0.8216594827586207, 0.8293372844827587, 0.8296066810344828, 0.8302801724137931, 0.8155980603448276, 0.8147898706896551, 0.8077855603448276, 0.8251616379310345, 0.833917025862069, 0.8389008620689655, 0.8484644396551724, 0.8459051724137931, 0.8313577586206896, 0.8345905172413793, 0.8353987068965517, 0.8341864224137931, 0.8343211206896551, 0.8271821120689655, 0.8251616379310345, 0.8409213362068966, 0.8251616379310345, 0.8440193965517241, 0.83203125, 0.8372844827586207, 0.8411907327586207, 0.8243534482758621, 0.8191002155172413, 0.833917025862069, 0.8387661637931034, 0.8341864224137931, 0.8481950431034483, 0.8433459051724138, 0.8239493534482759, 0.8424030172413793, 0.8480603448275862, 0.8384967672413793, 0.8428071120689655, 0.8390355603448276, 0.8490032327586207, 0.8481950431034483, 0.8461745689655172, 0.8502155172413793, 0.8503502155172413, 0.8430765086206896, 0.8545258620689655, 0.857354525862069, 0.8351293103448276, 0.8582974137931034, 0.8464439655172413, 0.8494073275862069, 0.845770474137931, 0.8542564655172413, 0.8538523706896551, 0.8335129310344828, 0.8527747844827587, 0.8376885775862069, 0.8327047413793104, 0.8405172413793104, 0.8448275862068966, 0.8453663793103449, 0.8498114224137931, 0.8395743534482759, 0.8391702586206896, 0.845770474137931, 0.8364762931034483, 0.8461745689655172, 0.85546875, 0.8421336206896551, 0.8518318965517241, 0.8506196120689655, 0.8526400862068966, 0.8588362068965517, 0.8494073275862069, 0.8601831896551724, 0.8529094827586207, 0.8550646551724138, 0.8604525862068966, 0.8560075431034483, 0.8492726293103449, 0.8541217672413793, 0.8479256465517241, 0.8502155172413793, 0.8469827586206896, 0.8578933189655172, 0.85546875, 0.8465786637931034, 0.8543911637931034, 0.8461745689655172, 0.8542564655172413, 0.8538523706896551, 0.8578933189655172, 0.8115571120689655, 0.8587015086206896, 0.8542564655172413, 0.8558728448275862, 0.8585668103448276, 0.8485991379310345, 0.8480603448275862, 0.8560075431034483, 0.859375, 0.8562769396551724, 0.85546875, 0.8570851293103449, 0.8432112068965517, 0.8494073275862069, 0.8491379310344828, 0.8576239224137931, 0.8516971982758621, 0.8600484913793104, 0.8587015086206896, 0.8531788793103449, 0.8557381465517241, 0.8611260775862069, 0.86328125, 0.8599137931034483, 0.8599137931034483, 0.8565463362068966, 0.8428071120689655, 0.85546875, 0.859375, 0.8481950431034483, 0.8492726293103449, 0.8511584051724138, 0.8375538793103449, 0.8481950431034483, 0.8507543103448276, 0.8515625, 0.8386314655172413, 0.8441540948275862, 0.8591056034482759, 0.8494073275862069, 0.849676724137931, 0.84375, 0.8589709051724138, 0.8655711206896551, 0.8630118534482759, 0.857489224137931, 0.8577586206896551, 0.8561422413793104, 0.8549299568965517, 0.8569504310344828, 0.8596443965517241, 0.8576239224137931, 0.8537176724137931, 0.8615301724137931, 0.869207974137931, 0.8638200431034483, 0.8636853448275862, 0.8465786637931034, 0.8565463362068966, 0.8658405172413793, 0.8562769396551724, 0.8701508620689655, 0.8775592672413793, 0.8648976293103449, 0.8650323275862069, 0.8670528017241379, 0.8669181034482759, 0.8585668103448276, 0.8685344827586207, 0.8709590517241379, 0.8531788793103449, 0.8701508620689655, 0.8685344827586207, 0.8631465517241379, 0.8630118534482759, 0.8709590517241379, 0.8683997844827587, 0.8640894396551724, 0.8611260775862069, 0.8698814655172413, 0.8605872844827587, 0.8617995689655172, 0.8685344827586207, 0.8592403017241379, 0.8569504310344828, 0.8647629310344828, 0.8719019396551724, 0.8751346982758621, 0.8609913793103449, 0.8627424568965517, 0.8640894396551724, 0.8677262931034483, 0.8631465517241379, 0.8626077586206896, 0.8725754310344828, 0.8686691810344828, 0.8743265086206896, 0.8630118534482759, 0.8650323275862069, 0.8735183189655172, 0.8674568965517241, 0.8578933189655172, 0.8714978448275862, 0.8767510775862069, 0.8739224137931034, 0.8642241379310345, 0.8717672413793104, 0.8681303879310345, 0.873114224137931, 0.869073275862069, 0.8714978448275862, 0.8666487068965517, 0.86328125], "accuracy_test": 0.8676883012820513, "start": "2016-01-18 13:57:39.343000", "learning_rate_per_epoch": [0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313, 0.0008176809060387313], "accuracy_train_last": 0.979527484939759, "error_valid": [0.7279094827586207, 0.6752424568965517, 0.6384698275862069, 0.6174568965517242, 0.6174568965517242, 0.6264816810344828, 0.6065463362068966, 0.6051993534482758, 0.5323275862068966, 0.4973060344827587, 0.4880118534482759, 0.4655172413793104, 0.4529903017241379, 0.40086206896551724, 0.3914331896551724, 0.3894127155172413, 0.3525053879310345, 0.3709590517241379, 0.35802801724137934, 0.3751346982758621, 0.34172952586206895, 0.3204471982758621, 0.31021012931034486, 0.3273168103448276, 0.2778825431034483, 0.3054956896551724, 0.2723599137931034, 0.2689924568965517, 0.2611799568965517, 0.3052262931034483, 0.2662984913793104, 0.26373922413793105, 0.23356681034482762, 0.2419181034482759, 0.22575431034482762, 0.24366918103448276, 0.2262931034482759, 0.2269665948275862, 0.2301993534482759, 0.22050107758620685, 0.2266971982758621, 0.22952586206896552, 0.2149784482758621, 0.21767241379310343, 0.2024515086206896, 0.2300646551724138, 0.21390086206896552, 0.2027209051724138, 0.22144396551724133, 0.20420258620689657, 0.2066271551724138, 0.20070043103448276, 0.19625538793103448, 0.19234913793103448, 0.20501077586206895, 0.1950431034482759, 0.1879040948275862, 0.1957165948275862, 0.17403017241379315, 0.2029903017241379, 0.18925107758620685, 0.18440193965517238, 0.1877693965517241, 0.18574892241379315, 0.1834590517241379, 0.18238146551724133, 0.1834590517241379, 0.1990840517241379, 0.17443426724137934, 0.17039331896551724, 0.1881734913793104, 0.17039331896551724, 0.1724137931034483, 0.19612068965517238, 0.18359375, 0.16325431034482762, 0.16500538793103448, 0.16904633620689657, 0.1647359913793104, 0.1763200431034483, 0.1872306034482759, 0.18278556034482762, 0.1868265086206896, 0.16217672413793105, 0.17429956896551724, 0.17834051724137934, 0.17066271551724133, 0.17039331896551724, 0.16971982758620685, 0.18440193965517238, 0.18521012931034486, 0.19221443965517238, 0.17483836206896552, 0.16608297413793105, 0.16109913793103448, 0.15153556034482762, 0.15409482758620685, 0.1686422413793104, 0.16540948275862066, 0.1646012931034483, 0.16581357758620685, 0.16567887931034486, 0.17281788793103448, 0.17483836206896552, 0.15907866379310343, 0.17483836206896552, 0.1559806034482759, 0.16796875, 0.16271551724137934, 0.15880926724137934, 0.1756465517241379, 0.18089978448275867, 0.16608297413793105, 0.16123383620689657, 0.16581357758620685, 0.1518049568965517, 0.1566540948275862, 0.1760506465517241, 0.15759698275862066, 0.1519396551724138, 0.16150323275862066, 0.15719288793103448, 0.16096443965517238, 0.15099676724137934, 0.1518049568965517, 0.15382543103448276, 0.14978448275862066, 0.14964978448275867, 0.1569234913793104, 0.14547413793103448, 0.14264547413793105, 0.16487068965517238, 0.14170258620689657, 0.15355603448275867, 0.15059267241379315, 0.15422952586206895, 0.14574353448275867, 0.14614762931034486, 0.16648706896551724, 0.14722521551724133, 0.16231142241379315, 0.1672952586206896, 0.1594827586206896, 0.15517241379310343, 0.15463362068965514, 0.15018857758620685, 0.1604256465517241, 0.1608297413793104, 0.15422952586206895, 0.1635237068965517, 0.15382543103448276, 0.14453125, 0.15786637931034486, 0.1481681034482759, 0.14938038793103448, 0.14735991379310343, 0.1411637931034483, 0.15059267241379315, 0.13981681034482762, 0.14709051724137934, 0.1449353448275862, 0.13954741379310343, 0.1439924568965517, 0.15072737068965514, 0.14587823275862066, 0.1520743534482759, 0.14978448275862066, 0.1530172413793104, 0.14210668103448276, 0.14453125, 0.15342133620689657, 0.14560883620689657, 0.15382543103448276, 0.14574353448275867, 0.14614762931034486, 0.14210668103448276, 0.18844288793103448, 0.1412984913793104, 0.14574353448275867, 0.1441271551724138, 0.14143318965517238, 0.15140086206896552, 0.1519396551724138, 0.1439924568965517, 0.140625, 0.14372306034482762, 0.14453125, 0.14291487068965514, 0.1567887931034483, 0.15059267241379315, 0.15086206896551724, 0.14237607758620685, 0.1483028017241379, 0.1399515086206896, 0.1412984913793104, 0.14682112068965514, 0.1442618534482759, 0.13887392241379315, 0.13671875, 0.1400862068965517, 0.1400862068965517, 0.14345366379310343, 0.15719288793103448, 0.14453125, 0.140625, 0.1518049568965517, 0.15072737068965514, 0.1488415948275862, 0.16244612068965514, 0.1518049568965517, 0.14924568965517238, 0.1484375, 0.16136853448275867, 0.1558459051724138, 0.1408943965517241, 0.15059267241379315, 0.15032327586206895, 0.15625, 0.1410290948275862, 0.13442887931034486, 0.1369881465517241, 0.14251077586206895, 0.14224137931034486, 0.1438577586206896, 0.1450700431034483, 0.14304956896551724, 0.1403556034482759, 0.14237607758620685, 0.14628232758620685, 0.13846982758620685, 0.13079202586206895, 0.1361799568965517, 0.1363146551724138, 0.15342133620689657, 0.14345366379310343, 0.13415948275862066, 0.14372306034482762, 0.12984913793103448, 0.12244073275862066, 0.13510237068965514, 0.13496767241379315, 0.1329471982758621, 0.1330818965517241, 0.14143318965517238, 0.13146551724137934, 0.1290409482758621, 0.14682112068965514, 0.12984913793103448, 0.13146551724137934, 0.1368534482758621, 0.1369881465517241, 0.1290409482758621, 0.13160021551724133, 0.13591056034482762, 0.13887392241379315, 0.13011853448275867, 0.13941271551724133, 0.13820043103448276, 0.13146551724137934, 0.1407596982758621, 0.14304956896551724, 0.13523706896551724, 0.12809806034482762, 0.1248653017241379, 0.13900862068965514, 0.1372575431034483, 0.13591056034482762, 0.1322737068965517, 0.1368534482758621, 0.1373922413793104, 0.12742456896551724, 0.13133081896551724, 0.1256734913793104, 0.1369881465517241, 0.13496767241379315, 0.12648168103448276, 0.1325431034482759, 0.14210668103448276, 0.1285021551724138, 0.12324892241379315, 0.12607758620689657, 0.13577586206896552, 0.1282327586206896, 0.13186961206896552, 0.12688577586206895, 0.13092672413793105, 0.1285021551724138, 0.1333512931034483, 0.13671875], "accuracy_train_std": [0.029068255426304913, 0.029044929407059165, 0.0314422334094631, 0.02892982603299016, 0.02953686909443287, 0.03143377886648342, 0.03092299267425399, 0.03092302848819549, 0.03362755056052259, 0.03398361211181324, 0.03488898333983794, 0.03390740808743753, 0.03287431388783919, 0.03158299335715075, 0.031983765695690454, 0.03166703009665044, 0.028913283728977484, 0.03063153499938251, 0.029748071316155034, 0.02968997541793646, 0.029043413711324177, 0.0273237752482879, 0.028651318366262283, 0.029465214244958557, 0.026164004834003877, 0.02924837293153996, 0.02542108443895044, 0.025982933206708247, 0.025383372559394515, 0.027293359659098283, 0.025796673679506603, 0.025707836167411947, 0.025935909269288484, 0.025810879901806486, 0.025156838574334674, 0.02632162583119254, 0.02495213607299137, 0.025394670198352606, 0.024793100808769425, 0.024156621536361195, 0.024597833291094766, 0.02539843132758349, 0.024135431573741255, 0.024247180241703904, 0.022717466841391507, 0.024816618877529742, 0.02290689926085998, 0.020592485885609448, 0.022537709352777123, 0.023000115580797034, 0.02232728539596964, 0.022710994366295076, 0.02268943051954643, 0.02196010167498864, 0.02352348315420934, 0.022135694619404258, 0.022818507929500884, 0.022922220067627386, 0.02122058280393859, 0.023132199281218718, 0.024215632979239204, 0.022367290657705388, 0.02248628841335208, 0.0231717588252909, 0.021485238410348356, 0.021260508750638365, 0.021793957887095705, 0.021010843637329128, 0.020745020685620987, 0.020434992358487152, 0.021480650339752883, 0.02034303327203167, 0.021489786850221505, 0.02255529416551592, 0.021208628221510713, 0.018986056499366077, 0.020608009163894898, 0.01887259918581305, 0.017780335666646524, 0.021520415429355264, 0.02162140343449772, 0.02157583254145045, 0.021123708186270355, 0.018010351218912618, 0.01983682617197779, 0.02034766014652874, 0.01958402562705786, 0.018380068273934982, 0.01975059192081483, 0.02141193112714419, 0.019115807838414222, 0.022413574695410006, 0.01902944889503665, 0.018118695345816036, 0.017702102999410246, 0.017688850584052968, 0.015662679592667865, 0.019998227873063903, 0.017533146304060165, 0.016893626563466553, 0.01756444802470264, 0.017292991902354768, 0.019310004534896695, 0.019171633625145564, 0.015720412238422653, 0.018526445214284166, 0.017436220703251504, 0.01792683725789812, 0.018914158702550355, 0.016845900093875644, 0.021760241006883604, 0.0190950558337094, 0.019734001363735522, 0.017101908056942297, 0.01833083497090913, 0.015884179073968177, 0.015483094977437049, 0.020313082830116944, 0.01638208562348635, 0.015241229397747452, 0.017424227978328106, 0.017343447301921944, 0.018357142345667977, 0.01427832703700658, 0.014455392164508571, 0.014934112750953334, 0.013521105500856806, 0.013942960322268584, 0.016154354478284103, 0.014286468867534801, 0.013481055030420469, 0.016983265723053118, 0.013114549343037005, 0.016138098571741085, 0.013628956584414256, 0.016226178412779072, 0.013844758012127707, 0.012825427263918766, 0.016179426449384093, 0.013572200911434656, 0.018973905188563244, 0.01568407179496777, 0.015472809410345473, 0.014656652364918225, 0.01609915844760547, 0.013162679848634918, 0.015592592686468894, 0.01641509324013133, 0.014418436481507181, 0.016183806629381434, 0.014860739154608156, 0.012800253137241414, 0.015168611295040733, 0.014601464315385343, 0.015457180152230254, 0.013229044271579785, 0.014987946686876634, 0.01376937999166226, 0.01267559845232325, 0.013960681576758746, 0.012765620008494466, 0.0134690762787281, 0.01228488389140299, 0.013571446101828833, 0.012412213629373073, 0.015598060707007685, 0.012702741653178152, 0.015516890839604575, 0.011753028633997522, 0.011487965572049914, 0.014660788759365617, 0.015000650560942927, 0.01487593418838815, 0.012561392944972728, 0.013136297338968768, 0.011798805400504098, 0.017760065427845466, 0.012992697288999428, 0.01392477909287069, 0.013836536355752495, 0.010788371809677533, 0.012838804528405384, 0.013287870059751995, 0.01253491554749324, 0.011922920400616946, 0.011656590174838699, 0.01144653395256553, 0.01112705095837544, 0.015258368251677605, 0.012926897211234972, 0.014560221235294409, 0.012046744937538508, 0.013698074901540713, 0.0117455821924085, 0.01095624039294512, 0.012432829698775828, 0.01129380796125931, 0.011557191292290046, 0.011474847267566124, 0.010929319599382115, 0.01153308997768316, 0.010852162630405532, 0.014664282064739983, 0.013054179083246104, 0.010647248406806474, 0.013993939947688678, 0.012075553986665107, 0.012752079125968374, 0.014504971693431984, 0.01396454828806234, 0.01286773372076863, 0.012089028153789812, 0.014533784817046034, 0.014466592516403334, 0.011607557683050596, 0.014277318677837238, 0.013536168022212572, 0.014632206806505997, 0.012047549310989366, 0.011011192087159487, 0.009968748016293553, 0.014243536269917208, 0.012374861541506268, 0.013562221793247758, 0.013259836635396528, 0.011217060106562007, 0.011831728951874334, 0.011444018124454778, 0.01407679127261596, 0.010297741966075457, 0.009109505675963416, 0.0113233101118117, 0.010347201624126723, 0.014470419707971872, 0.012270699709947541, 0.009505728611809986, 0.0120948210932186, 0.009514375253417884, 0.00911752599920388, 0.009622593959580844, 0.010686701060392394, 0.010580129119610785, 0.010508735417352097, 0.0116848684006197, 0.008911529795478955, 0.009858291201488798, 0.013853554377509864, 0.009404293164739874, 0.009543169823064844, 0.011231465625763184, 0.010955355892776446, 0.008495699347396224, 0.009991939827542425, 0.010391924348859194, 0.011260221376138668, 0.008601767117113837, 0.010518426472245998, 0.01115518237498506, 0.00894833222696463, 0.012076860813940295, 0.011835566016535435, 0.009568232499404576, 0.008776413417717463, 0.008508334592057602, 0.011185842258851268, 0.011271526279294163, 0.01010427875133342, 0.009938400749554726, 0.00961876641938254, 0.011708349887420158, 0.008793684131188109, 0.009617154367777622, 0.0070573305563917275, 0.009939487170832541, 0.00943113419566218, 0.00877994596069049, 0.009011998528082606, 0.010149117128899404, 0.007936823789093671, 0.007360849245709945, 0.00744730438435711, 0.008979836403803421, 0.008541688702327282, 0.008528064033538767, 0.009448731908790718, 0.009757796887900658, 0.009131271730115437, 0.008949848198656149, 0.009531557862880962], "accuracy_test_std": 0.01727060254590592, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.9752622672387556, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0008176808785434866, "patience_threshold": 1, "do_flip": true, "batch_size": 256, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 4.740274359858566e-10, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.005941798547368038}, "accuracy_valid_max": 0.8775592672413793, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.86328125, "loss_train": [5.698888778686523, 1.7965844869613647, 1.6698787212371826, 1.5889971256256104, 1.5233371257781982, 1.4651800394058228, 1.413087248802185, 1.362202763557434, 1.311975121498108, 1.2633131742477417, 1.2256404161453247, 1.1828815937042236, 1.147454023361206, 1.1002790927886963, 1.0499889850616455, 1.0112384557724, 0.9731007814407349, 0.930722177028656, 0.9002439975738525, 0.8724096417427063, 0.8502358198165894, 0.8219690322875977, 0.787746250629425, 0.761181652545929, 0.7497078776359558, 0.7202419638633728, 0.7012290954589844, 0.6699599623680115, 0.654827356338501, 0.637819230556488, 0.6368427872657776, 0.6028364896774292, 0.5886274576187134, 0.568235456943512, 0.5481563806533813, 0.5343414545059204, 0.5302402377128601, 0.5140278935432434, 0.49893125891685486, 0.49324363470077515, 0.47563666105270386, 0.4730311334133148, 0.4654252827167511, 0.4461488127708435, 0.4351702332496643, 0.42504799365997314, 0.42448142170906067, 0.4211004674434662, 0.41103559732437134, 0.40053799748420715, 0.399601548910141, 0.38580161333084106, 0.3853073716163635, 0.3920704424381256, 0.37610968947410583, 0.37498053908348083, 0.3782634437084198, 0.3592211604118347, 0.34760811924934387, 0.3499467670917511, 0.33933067321777344, 0.34388288855552673, 0.3248118758201599, 0.3146836459636688, 0.308137446641922, 0.30615583062171936, 0.3010086715221405, 0.3016824424266815, 0.30946993827819824, 0.2903667092323303, 0.2757408320903778, 0.28131890296936035, 0.27472275495529175, 0.27941542863845825, 0.27477025985717773, 0.26640617847442627, 0.26121506094932556, 0.2592378258705139, 0.2523875832557678, 0.2503233253955841, 0.2546994090080261, 0.25725623965263367, 0.24929222464561462, 0.23697131872177124, 0.23840971291065216, 0.23599211871623993, 0.24250556528568268, 0.2346961498260498, 0.23369728028774261, 0.227847620844841, 0.2316882163286209, 0.23830486834049225, 0.22528864443302155, 0.22523456811904907, 0.21812476217746735, 0.21190643310546875, 0.21000739932060242, 0.20779217779636383, 0.20961880683898926, 0.2076883763074875, 0.21169504523277283, 0.206554114818573, 0.20304237306118011, 0.1991695761680603, 0.19481663405895233, 0.19141624867916107, 0.1932212859392166, 0.18533027172088623, 0.18810108304023743, 0.17888499796390533, 0.17879508435726166, 0.20121018588542938, 0.17649275064468384, 0.201205313205719, 0.17371080815792084, 0.17565949261188507, 0.1694209724664688, 0.17211788892745972, 0.19413773715496063, 0.16515861451625824, 0.16124798357486725, 0.17037419974803925, 0.16544082760810852, 0.16749952733516693, 0.16100667417049408, 0.15723320841789246, 0.15624649822711945, 0.16154523193836212, 0.1583302915096283, 0.18409176170825958, 0.1545819491147995, 0.15649601817131042, 0.15839317440986633, 0.15733017027378082, 0.15661975741386414, 0.14704529941082, 0.15366226434707642, 0.15419833362102509, 0.14668092131614685, 0.14647480845451355, 0.15349368751049042, 0.15143485367298126, 0.15815623104572296, 0.145661860704422, 0.14471940696239471, 0.14597582817077637, 0.13686811923980713, 0.15064869821071625, 0.13332444429397583, 0.13498298823833466, 0.13886365294456482, 0.13829560577869415, 0.13777999579906464, 0.13731154799461365, 0.14200188219547272, 0.13250331580638885, 0.14170771837234497, 0.13385970890522003, 0.13436366617679596, 0.129055917263031, 0.1330583095550537, 0.1275017112493515, 0.1282244175672531, 0.1273428350687027, 0.13300356268882751, 0.12730297446250916, 0.13227999210357666, 0.12911872565746307, 0.12632055580615997, 0.12707455456256866, 0.12227203696966171, 0.1227123886346817, 0.12173277139663696, 0.12564422190189362, 0.12347473949193954, 0.1246538758277893, 0.12694060802459717, 0.22006312012672424, 0.15304316580295563, 0.11916593462228775, 0.11857236921787262, 0.1155412420630455, 0.11373894661664963, 0.11664412170648575, 0.11941434442996979, 0.11216986924409866, 0.11949292570352554, 0.11769560724496841, 0.11474577337503433, 0.11581479012966156, 0.116289883852005, 0.12174419313669205, 0.10622221231460571, 0.113144651055336, 0.11353379487991333, 0.1100490614771843, 0.11077476292848587, 0.11188089847564697, 0.1088389977812767, 0.10770326852798462, 0.1107572466135025, 0.11197134852409363, 0.11290722340345383, 0.1125921830534935, 0.10968928784132004, 0.10640271008014679, 0.11169710010290146, 0.10490775853395462, 0.11008147150278091, 0.11753763258457184, 0.113881416618824, 0.11193232983350754, 0.10405253618955612, 0.1104523241519928, 0.10751655697822571, 0.10743884742259979, 0.10441938787698746, 0.10351860523223877, 0.10869739204645157, 0.10379686206579208, 0.10832088440656662, 0.10255425423383713, 0.101723812520504, 0.0970984697341919, 0.10205155611038208, 0.101594939827919, 0.10115227103233337, 0.10260627418756485, 0.10390453785657883, 0.13365983963012695, 0.10353844612836838, 0.097678042948246, 0.09825562685728073, 0.09764908999204636, 0.09795384109020233, 0.09544854611158371, 0.09564092755317688, 0.0981290340423584, 0.09748426079750061, 0.0945122167468071, 0.09863936901092529, 0.0975145548582077, 0.09887455403804779, 0.09830472618341446, 0.10019741207361221, 0.10214152187108994, 0.09690185636281967, 0.09201358258724213, 0.09097584336996078, 0.09110704064369202, 0.09542687237262726, 0.09832192957401276, 0.09598129242658615, 0.09380386024713516, 0.09440740942955017, 0.09323608875274658, 0.09144530445337296, 0.09204269200563431, 0.09163158386945724, 0.09007248282432556, 0.09395098686218262, 0.11333616077899933, 0.08856632560491562, 0.08212070912122726, 0.0879664495587349, 0.09406371414661407, 0.0904235690832138, 0.08810881525278091, 0.09142657369375229, 0.09310244023799896, 0.08726581931114197, 0.0864606723189354, 0.08557755500078201, 0.09160236269235611, 0.08782174438238144, 0.08612935990095139, 0.08584106713533401, 0.09441303461790085, 0.09141954779624939, 0.09250310808420181, 0.09132230281829834, 0.08143483102321625, 0.0873640701174736, 0.0849379226565361, 0.08639007061719894, 0.08532007038593292, 0.08916277438402176, 0.08211611956357956, 0.09050318598747253], "accuracy_train_first": 0.2724021084337349, "model": "residualv2", "loss_std": [26.765954971313477, 0.09365340322256088, 0.08919525146484375, 0.0857551172375679, 0.08912824839353561, 0.08726730942726135, 0.09408675879240036, 0.08822096884250641, 0.09328892827033997, 0.08774944394826889, 0.08653249591588974, 0.08485851436853409, 0.09223100543022156, 0.08869871497154236, 0.08532189577817917, 0.08418537676334381, 0.09014620631933212, 0.08749762177467346, 0.08509941399097443, 0.07992885261774063, 0.0835288017988205, 0.08798516541719437, 0.08543703705072403, 0.07530909031629562, 0.09059032052755356, 0.07630922645330429, 0.08436280488967896, 0.07696251571178436, 0.07683385163545609, 0.069290392100811, 0.0846502035856247, 0.07375344634056091, 0.07221773266792297, 0.06808621436357498, 0.06596728414297104, 0.06430084258317947, 0.06763710826635361, 0.066742442548275, 0.06082235649228096, 0.06504024565219879, 0.06033269315958023, 0.06327829509973526, 0.06226020306348801, 0.05787887051701546, 0.06207356974482536, 0.057907670736312866, 0.06006496027112007, 0.059834178537130356, 0.06379131972789764, 0.062271848320961, 0.057181455194950104, 0.05817103758454323, 0.0543493814766407, 0.08144474029541016, 0.05814718082547188, 0.06172182783484459, 0.060783375054597855, 0.059520334005355835, 0.05671943724155426, 0.05604447051882744, 0.05534902587532997, 0.057465530931949615, 0.04816758260130882, 0.050255388021469116, 0.04964635893702507, 0.05107909068465233, 0.044884905219078064, 0.0501156710088253, 0.06378838419914246, 0.04850909486413002, 0.046412546187639236, 0.047250326722860336, 0.045217789709568024, 0.045260846614837646, 0.04825636371970177, 0.04472710192203522, 0.04084188863635063, 0.04375789687037468, 0.04318562522530556, 0.039602842181921005, 0.0495772585272789, 0.04303118214011192, 0.043340153992176056, 0.040743883699178696, 0.045286618173122406, 0.04395154118537903, 0.041950955986976624, 0.0407291017472744, 0.04396606236696243, 0.04245027154684067, 0.0408584363758564, 0.04638293385505676, 0.043850127607584, 0.041624490171670914, 0.038681063801050186, 0.03970722109079361, 0.040183477103710175, 0.03957164287567139, 0.03891390934586525, 0.041558194905519485, 0.040844593197107315, 0.040430065244436264, 0.03966761752963066, 0.03725702315568924, 0.040830399841070175, 0.03694998845458031, 0.03663542494177818, 0.03468352183699608, 0.03732581064105034, 0.03358638286590576, 0.03407273441553116, 0.05318395048379898, 0.03564860671758652, 0.05913471058011055, 0.036454424262046814, 0.037057626992464066, 0.0368691124022007, 0.033753108233213425, 0.04847658425569534, 0.033446408808231354, 0.032717015594244, 0.036314111202955246, 0.03416875749826431, 0.034087345004081726, 0.03369028866291046, 0.030810926109552383, 0.03233208879828453, 0.0306533370167017, 0.029525022953748703, 0.05759647116065025, 0.031134530901908875, 0.0342475101351738, 0.03394502401351929, 0.03115745261311531, 0.03443169593811035, 0.02942139096558094, 0.03135199844837189, 0.03196101263165474, 0.031109081581234932, 0.0329102985560894, 0.03323045000433922, 0.03188838064670563, 0.0372672863304615, 0.032996032387018204, 0.032791778445243835, 0.03131847456097603, 0.029733266681432724, 0.03286672383546829, 0.027711736038327217, 0.02852029912173748, 0.02927061915397644, 0.029202358797192574, 0.029399288818240166, 0.03317412734031677, 0.033529773354530334, 0.02987867034971714, 0.03438546508550644, 0.030410485342144966, 0.03075052984058857, 0.027656199410557747, 0.03130318596959114, 0.02474871091544628, 0.028719933703541756, 0.029844442382454872, 0.027776453644037247, 0.027956277132034302, 0.028027493506669998, 0.027446206659078598, 0.02877545915544033, 0.03057851456105709, 0.029376162216067314, 0.028010357171297073, 0.027574894949793816, 0.030119353905320168, 0.026380322873592377, 0.027993474155664444, 0.028167512267827988, 0.11679833382368088, 0.05354856699705124, 0.030450772494077682, 0.02704017609357834, 0.027458788827061653, 0.027207912877202034, 0.026802310720086098, 0.026732634752988815, 0.027180619537830353, 0.028497790917754173, 0.02887972816824913, 0.026528507471084595, 0.02618250623345375, 0.027298612520098686, 0.028255242854356766, 0.025240421295166016, 0.025890294462442398, 0.026535717770457268, 0.027292869985103607, 0.026304151862859726, 0.028937557712197304, 0.02465614303946495, 0.027292441576719284, 0.026415906846523285, 0.027682889252901077, 0.027241064235568047, 0.02598334290087223, 0.027968185022473335, 0.026886142790317535, 0.026649460196495056, 0.025221634656190872, 0.027069590985774994, 0.030587883666157722, 0.027792204171419144, 0.03138827905058861, 0.024451857432723045, 0.029149623587727547, 0.02442021854221821, 0.02569708600640297, 0.025082550942897797, 0.0263984352350235, 0.0266359131783247, 0.026152364909648895, 0.023419851437211037, 0.024849362671375275, 0.021532129496335983, 0.023351849988102913, 0.023751022294163704, 0.02494608610868454, 0.022964701056480408, 0.026662888005375862, 0.023273758590221405, 0.046501338481903076, 0.025815743952989578, 0.023704439401626587, 0.02607005089521408, 0.025797003880143166, 0.02320651337504387, 0.02315147966146469, 0.025602802634239197, 0.024160366505384445, 0.025432618334889412, 0.023308470845222473, 0.024377550929784775, 0.023223932832479477, 0.02661692351102829, 0.026890788227319717, 0.026040101423859596, 0.02574135735630989, 0.02262132242321968, 0.02298150211572647, 0.021663106977939606, 0.02491869032382965, 0.024324944242835045, 0.02504586987197399, 0.02442341297864914, 0.025984156876802444, 0.024365274235606194, 0.025161653757095337, 0.025209564715623856, 0.02340364083647728, 0.02330131083726883, 0.021875636652112007, 0.022386251017451286, 0.04016391187906265, 0.02515123039484024, 0.02277963235974312, 0.022368216887116432, 0.024469254538416862, 0.021470654755830765, 0.021660633385181427, 0.024066131561994553, 0.02238144353032112, 0.024002637714147568, 0.02123180218040943, 0.023307127878069878, 0.026084184646606445, 0.024713147431612015, 0.022760432213544846, 0.021969376131892204, 0.024996310472488403, 0.022613678127527237, 0.026818161830306053, 0.025598151609301567, 0.02294083870947361, 0.022343697026371956, 0.02264082245528698, 0.021937359124422073, 0.022961201146245003, 0.024346133694052696, 0.020126596093177795, 0.024128757417201996]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:02 2016", "state": "available"}], "summary": "2830a4d78336e1972f422e682b9c0152"}