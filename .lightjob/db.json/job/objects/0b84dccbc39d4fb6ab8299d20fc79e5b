{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 16, "f3": 16, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.5212829113006592, 1.1286307573318481, 0.917693555355072, 0.8143301606178284, 0.7485666871070862, 0.6979373097419739, 0.6578772068023682, 0.623271644115448, 0.5937431454658508, 0.5678400993347168, 0.544585108757019, 0.5235004425048828, 0.5042622685432434, 0.4864058792591095, 0.46992918848991394, 0.4545835256576538, 0.44011566042900085, 0.4264850318431854, 0.41362911462783813, 0.40136903524398804, 0.3897278904914856, 0.37865135073661804, 0.36807122826576233, 0.35793039202690125, 0.34821242094039917, 0.3389121890068054, 0.33000287413597107, 0.3213847279548645, 0.31312230229377747, 0.3051430583000183, 0.29750075936317444, 0.29005178809165955, 0.28286609053611755, 0.27590593695640564, 0.2692110538482666, 0.26272207498550415, 0.2564387917518616, 0.25033465027809143, 0.24437062442302704, 0.23859618604183197, 0.2329748570919037, 0.22755832970142365, 0.22224494814872742, 0.21705609560012817, 0.21198664605617523, 0.20710374414920807, 0.2023337483406067, 0.19766776263713837, 0.19309371709823608, 0.18867038190364838, 0.18434195220470428, 0.18010267615318298, 0.17597301304340363, 0.17191913723945618, 0.16799500584602356, 0.16417644917964935, 0.16042348742485046, 0.15675830841064453, 0.15316249430179596, 0.1496810019016266, 0.14623866975307465, 0.1428927332162857, 0.1396278738975525, 0.1364242285490036, 0.13327434659004211, 0.13020801544189453, 0.12720441818237305, 0.12427745014429092, 0.12139670550823212, 0.11859944462776184, 0.1158519983291626, 0.11315551400184631, 0.11051540076732635, 0.10794826596975327, 0.10544326156377792, 0.10297932475805283, 0.10057726502418518], "moving_avg_accuracy_train": [0.040093297947812835, 0.08225906231254612, 0.13278753961765177, 0.1831542729205599, 0.2361090906451152, 0.2849240255555483, 0.3322419103234985, 0.37534647875035865, 0.41583526332848814, 0.4532979825832639, 0.48813024899940227, 0.5204418643322509, 0.5501848052984353, 0.5778089266858121, 0.6033586997379765, 0.626953203633688, 0.6487670389493059, 0.6689132404738105, 0.6875284167494268, 0.7047842714915199, 0.7205261653498891, 0.7351262754033554, 0.7485686798455319, 0.760997014974443, 0.7725243495142818, 0.783212773591785, 0.7931950784758235, 0.8024441837869252, 0.8110588419240135, 0.819042187930717, 0.8263410955795981, 0.8331426273445435, 0.839524422599661, 0.845402896960219, 0.8509213524192358, 0.8560366997585229, 0.8608358248638814, 0.8653851550932095, 0.8696608418091101, 0.87365776937723, 0.877445666390919, 0.8810337741127536, 0.8844932607945476, 0.8877509580343527, 0.8908107687347011, 0.8937039991471298, 0.8964241279099732, 0.8990326069667518, 0.901573225469043, 0.9040016161984861, 0.9063545425204518, 0.9085767718578308, 0.9106464966769388, 0.9126277955546029, 0.9145341974314055, 0.9163707947609855, 0.9181283640540361, 0.919849685346353, 0.9215081565034858, 0.923121652234182, 0.9246923809810941, 0.9261920673592674, 0.9276929197722424, 0.9291273923010628, 0.9305137486781917, 0.931882377155703, 0.9332350505235583, 0.9345361258629522, 0.9358303265553114, 0.9371043891724823, 0.9383463766291267, 0.9395501958460589, 0.9407033876055837, 0.9417970637605846, 0.9428650776572283, 0.9438960446284933, 0.9449192460038223], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04069177099021083, 0.08304872811558733, 0.1325709154979292, 0.18098418704113325, 0.23144825068830005, 0.2769890077919098, 0.32118628547657424, 0.3609048592538415, 0.3980299406759724, 0.4320803681068691, 0.4630044554961069, 0.4913742730300806, 0.5170668297255665, 0.5404220643452537, 0.5616360584943128, 0.5807265942111466, 0.5979467564673663, 0.6138030244388526, 0.6281591148319402, 0.6412271100693787, 0.6528265258508444, 0.6635376432676425, 0.673040283073032, 0.6816170729603824, 0.6895834130099767, 0.6967144389435423, 0.703194426948661, 0.7089165528720177, 0.7138701241943792, 0.7183039243220046, 0.7221600670931174, 0.7255217618145285, 0.7285605236037083, 0.7312089304865603, 0.7335314615248772, 0.7355718818257029, 0.7373350179089458, 0.7388974263213646, 0.740255795276201, 0.7413918486081441, 0.742353261450643, 0.7431198472502323, 0.7437365322823627, 0.74421830662378, 0.7446661695796248, 0.7450926307937257, 0.7453909966676664, 0.7455608401955534, 0.745578392518242, 0.7456063966399118, 0.7454230513095049, 0.7452458334808887, 0.7450741304038841, 0.7448697400009204, 0.7445748958483434, 0.7443095361110241, 0.7440340912536868, 0.7437617768195832, 0.74345565867264, 0.7431313242153911, 0.742802802110117, 0.7425193392466204, 0.7421655369108138, 0.7418349077773378, 0.7415383710658692, 0.7411483882043877, 0.7407974036290543, 0.7405435821761639, 0.7402541077123126, 0.740006817234756, 0.7397110136174551, 0.7394702339330439, 0.7392047040920738, 0.7388802780164508, 0.7384143075849112, 0.7380071412277754, 0.737690549140013], "moving_var_accuracy_train": [0.014467252862988838, 0.029022092736849858, 0.049098026632118076, 0.06701949438136275, 0.08555545942539436, 0.09844599431564331, 0.10875223485429605, 0.11459904574225929, 0.11789321625756097, 0.1187349926374642, 0.11778107442688134, 0.115399331352955, 0.11182118105352082, 0.10750689168998952, 0.10263132064814455, 0.09737849411009275, 0.09192323539967556, 0.08638373678250158, 0.08086408619420185, 0.07545755828070363, 0.07014206745286673, 0.06504632962974, 0.06016798080144941, 0.05554135434799322, 0.05118313388753414, 0.04709300218212568, 0.04328051966109421, 0.03972238123648743, 0.03641805412620879, 0.03334985303475265, 0.030494334207079435, 0.027861248295517536, 0.02544166926206994, 0.023208510483132595, 0.021161739590697712, 0.019281066637241915, 0.01756024438950966, 0.01599048760037799, 0.014555972312372949, 0.013244153950998835, 0.012048872029975776, 0.010959855480189603, 0.009971582365084235, 0.009069937450331918, 0.008247205678996426, 0.007497822151071407, 0.006814631840342293, 0.006194406123214938, 0.005633058192261105, 0.0051228261068486, 0.004660369856653132, 0.004238777600038989, 0.003853453687476576, 0.0035034382259126187, 0.0031858037163642427, 0.0028975811524870024, 0.002635624485617171, 0.002398728559977907, 0.002183610443191491, 0.0019886797151291123, 0.0018120164427835879, 0.0016510563316011373, 0.0015062237201308212, 0.0013741207510412033, 0.0012540065319767357, 0.0011454641739641535, 0.0010473852837286836, 0.0009578819287048256, 0.0008771683347232718, 0.0008040606212231973, 0.0007375373546830345, 0.0006768262455782303, 0.0006211122821285299, 0.0005697662017038342, 0.000523055464684266, 0.00048031595427839294, 0.0004417068283408292], "duration": 22961.764422, "accuracy_train": [0.40093297947812845, 0.4617509415951458, 0.5875438353636028, 0.6364548726467332, 0.712702450166113, 0.7242584397494463, 0.7581028732350499, 0.7632875945921004, 0.7802343245316538, 0.7904624558762459, 0.8016206467446475, 0.8112464023278886, 0.8178712739940938, 0.8264260191722037, 0.8333066572074567, 0.8393037386950905, 0.845091556789867, 0.8502290541943521, 0.855065003229974, 0.8600869641703581, 0.8622032100752122, 0.8665272658845515, 0.8695503198251201, 0.8728520311346438, 0.8762703603728312, 0.8794085902893135, 0.8830358224321706, 0.8856861315868402, 0.8885907651578073, 0.8908923019910484, 0.8920312644195275, 0.8943564132290514, 0.896960579895718, 0.8983091662052418, 0.9005874515503876, 0.9020748258121077, 0.9040279508121077, 0.9063291271571613, 0.908142022252215, 0.9096301174903102, 0.9115367395141197, 0.9133267436092655, 0.9156286409306941, 0.9170702331925988, 0.9183490650378369, 0.9197430728589886, 0.9209052867755629, 0.9225089184777593, 0.924438791989664, 0.9258571327634736, 0.9275308794181433, 0.9285768358942414, 0.929274020048911, 0.9304594854535806, 0.9316918143226283, 0.9329001707272055, 0.9339464876914912, 0.9353415769772055, 0.9364343969176817, 0.9376431138104466, 0.9388289397033037, 0.9396892447628276, 0.941200591489018, 0.9420376450604466, 0.9429909560723514, 0.9442000334533037, 0.9454091108342562, 0.9462458039174971, 0.9474781327865448, 0.948570952727021, 0.9495242637389257, 0.9503845687984496, 0.9510821134413067, 0.9516401491555924, 0.952477202727021, 0.9531747473698781, 0.9541280583817828], "end": "2016-02-03 18:09:30.718000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0], "moving_var_accuracy_valid": [0.014902382036877878, 0.029559150185478944, 0.04867525855511707, 0.06490233645324947, 0.08133169828599224, 0.09186417347552285, 0.10025835032058861, 0.10443060121463177, 0.10639198612856723, 0.10618767198975139, 0.10417559741849118, 0.10100165659884068, 0.09684245816491344, 0.09206741520568787, 0.08691097561492585, 0.08149991503903463, 0.07601872942830597, 0.0706796475913276, 0.06546655881456537, 0.06045685542884027, 0.0556220879041981, 0.0510924314406262, 0.04679588976600231, 0.04277835271234789, 0.03907168060518503, 0.035622176322453195, 0.03243787089112621, 0.029488768327758354, 0.02676073231459402, 0.02426158633528019, 0.02196925623539302, 0.01987403953445339, 0.01796974223991046, 0.016235894547073658, 0.014660852446181798, 0.013232237036599807, 0.011936991172572126, 0.010765262135739683, 0.009705342418122884, 0.008746423730867769, 0.007880100189664486, 0.007097379054791226, 0.0063910638531717865, 0.005754046426499041, 0.0051804470148941, 0.004664039135908881, 0.004198436422070585, 0.003778852401279212, 0.003400969933907577, 0.003060879998594294, 0.0027550945383265028, 0.0024798677399228675, 0.002232146303450456, 0.0020093076520368235, 0.0018091592845019208, 0.0016288770981634402, 0.0014666722171719985, 0.0013206723918139892, 0.001189448527511582, 0.0010714504103218545, 0.0009652767102525521, 0.0008694721999821323, 0.0007836515648193191, 0.0007062702489525149, 0.0006364346302485016, 0.000574159946913895, 0.000517852663771603, 0.00046664722536396907, 0.0004207366620145703, 0.00037921336903572466, 0.0003420795301522269, 0.00030839335084483047, 0.0002781885706283577, 0.0002513169840724195, 0.00022813944165280093, 0.00020681755746896924, 0.0001870378766723766], "accuracy_test": 0.5703105070153061, "start": "2016-02-03 11:46:48.954000", "learning_rate_per_epoch": [0.0009278294746764004, 0.0004639147373382002, 0.0003092764818575233, 0.0002319573686691001, 0.00018556589202489704, 0.00015463824092876166, 0.0001325470657320693, 0.00011597868433455005, 0.00010309216304449365, 9.278294601244852e-05, 8.434813207713887e-05, 7.731912046438083e-05, 7.13714980520308e-05, 6.627353286603466e-05, 6.185529491631314e-05, 5.7989342167275026e-05, 5.45782022527419e-05, 5.154608152224682e-05, 4.883312794845551e-05, 4.639147300622426e-05, 4.41823540313635e-05, 4.2174066038569435e-05, 4.034041194245219e-05, 3.8659560232190415e-05, 3.711317913257517e-05, 3.56857490260154e-05, 3.4364053135504946e-05, 3.313676643301733e-05, 3.1994120945455506e-05, 3.092764745815657e-05, 2.9929982702014968e-05, 2.8994671083637513e-05, 2.8116044632042758e-05, 2.728910112637095e-05, 2.6509413146413863e-05, 2.577304076112341e-05, 2.507647150196135e-05, 2.4416563974227756e-05, 2.3790498744347133e-05, 2.319573650311213e-05, 2.2629987142863683e-05, 2.209117701568175e-05, 2.1577428924501874e-05, 2.1087033019284718e-05, 2.061843224510085e-05, 2.0170205971226096e-05, 1.9741051801247522e-05, 1.9329780116095208e-05, 1.8935295884148218e-05, 1.8556589566287585e-05, 1.8192735296906903e-05, 1.78428745130077e-05, 1.7506215954199433e-05, 1.7182026567752473e-05, 1.6869626051629893e-05, 1.6568383216508664e-05, 1.627771052881144e-05, 1.5997060472727753e-05, 1.572592373122461e-05, 1.5463823729078285e-05, 1.5210319361358415e-05, 1.4964991351007484e-05, 1.4727451343787834e-05, 1.4497335541818757e-05, 1.427429924660828e-05, 1.4058022316021379e-05, 1.3848200978827663e-05, 1.3644550563185476e-05, 1.3446803677652497e-05, 1.3254706573206931e-05, 1.3068020962236915e-05, 1.2886520380561706e-05, 1.2709992915915791e-05, 1.2538235750980675e-05, 1.237105971085839e-05, 1.2208281987113878e-05, 1.204973341373261e-05], "accuracy_train_first": 0.40093297947812845, "accuracy_train_last": 0.9541280583817828, "batch_size_eval": 1024, "accuracy_train_std": [0.018406770000168826, 0.016544400207104928, 0.01616380258081884, 0.016868202857315037, 0.018084399518635486, 0.018419899220017123, 0.019224360496460126, 0.01789741598681525, 0.0183068296952574, 0.018157151590452825, 0.01808473275653879, 0.01769389563940913, 0.017749986273435957, 0.017711911170283094, 0.017655990334421785, 0.017302752134423074, 0.017797578856725275, 0.017876997933838974, 0.017945744089330813, 0.01804813565283382, 0.017928544583868233, 0.018403738925838735, 0.017485500996564506, 0.017188694337569557, 0.016461332717416146, 0.016220991459093767, 0.016005442068639717, 0.01586262442485748, 0.016332043010796667, 0.016234876811712377, 0.016262457146140205, 0.015947983253978445, 0.0156689260943063, 0.01562927025420372, 0.015825406879631465, 0.015758997056745723, 0.015787977519473997, 0.015893257071450225, 0.016198106695032737, 0.015675556777899603, 0.015200677466002203, 0.015109497561407587, 0.014599573584078445, 0.014356174861953855, 0.013834382092199074, 0.013955210315918993, 0.014208914892772503, 0.014149825502849227, 0.013842571516071706, 0.013592719854819238, 0.013115882924699411, 0.013416431168181952, 0.013423500691150171, 0.013258163944211403, 0.013213839086775354, 0.012991037374009536, 0.012733922226056711, 0.012336258560831164, 0.012186409842945138, 0.01206320161650953, 0.011907970685277991, 0.011629855613322252, 0.011374178015061921, 0.011384460067742297, 0.011199419764809888, 0.011220540511995454, 0.011063716329796625, 0.011032360201403267, 0.010946420310490545, 0.010873523637366187, 0.010578601290863883, 0.010654798915300218, 0.010442713767131129, 0.010349558004706518, 0.010404936748411274, 0.010018447223645408, 0.009771530923906403], "accuracy_test_std": 0.00936499011869179, "error_valid": [0.5930822900978916, 0.5357386577560241, 0.42172939806099397, 0.3832963690700302, 0.3143751764871988, 0.31314417827560237, 0.2810382153614458, 0.281627976750753, 0.26784432652484935, 0.26146578501506024, 0.258678758000753, 0.2532973691641567, 0.25170016001506024, 0.24938082407756024, 0.24743799416415668, 0.24745858433734935, 0.24707178322665668, 0.24349056381777112, 0.24263607163027112, 0.24116093279367468, 0.2427787321159638, 0.24006229998117468, 0.2414359586784638, 0.2411918180534638, 0.23871952654367468, 0.23910632765436746, 0.23848568100527112, 0.23958431381777112, 0.24154773390436746, 0.24179187452936746, 0.24313464796686746, 0.24422298569277112, 0.24409062029367468, 0.24495540756777112, 0.24556575913027112, 0.24606433546686746, 0.24679675734186746, 0.24704089796686746, 0.24751888413027112, 0.24838367140436746, 0.24899402296686746, 0.2499808805534638, 0.2507133024284638, 0.2514457243034638, 0.2513030638177711, 0.25106921827936746, 0.25192371046686746, 0.2529105680534638, 0.25426363657756024, 0.25414156626506024, 0.2562270566641567, 0.2563491269766567, 0.2564711972891567, 0.256969773625753, 0.25807870152484935, 0.25807870152484935, 0.25844491246234935, 0.25868905308734935, 0.25929940464984935, 0.25978768589984935, 0.26015389683734935, 0.26003182652484935, 0.2610186841114458, 0.2611407544239458, 0.26113045933734935, 0.2623614575489458, 0.2623614575489458, 0.26174081089984935, 0.26235116246234935, 0.262218797063253, 0.262951218938253, 0.2626967832266567, 0.2631850644766567, 0.2640395566641567, 0.2657794262989458, 0.2656573559864458, 0.26515877964984935], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.059338169735870305, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.000927829457070325, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 8.899865260226607e-08, "rotation_range": [0, 0], "momentum": 0.8013569946994216}, "accuracy_valid_max": 0.7615143189947289, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7348412203501506, "accuracy_valid_std": [0.013612017212456626, 0.01689668282532241, 0.015358984797047033, 0.013859735276896623, 0.014233785813648533, 0.013663702240337323, 0.013314578667208237, 0.014670202777126865, 0.016444549765037942, 0.01541874250635636, 0.017099896349025142, 0.018154233075183594, 0.017355778009566846, 0.016503882949760313, 0.01789678990883942, 0.01976301256495781, 0.018787613279275785, 0.015353290536547536, 0.01537484387167833, 0.01590009465277707, 0.016914119521407447, 0.015028843769061327, 0.017404571487031475, 0.017589959615088732, 0.015288354346140152, 0.017027195382905237, 0.015699904969371237, 0.015358715312607076, 0.01611429922218901, 0.01595116902446379, 0.015819044032175662, 0.014627590324456107, 0.01362474030606281, 0.014572427286992574, 0.014513127592270162, 0.01576410975092388, 0.015450419979607423, 0.016139564289480553, 0.015472434123426318, 0.015508786791882997, 0.015065968814550381, 0.01557269160983274, 0.016113449786661266, 0.016343862812258914, 0.015075943987095638, 0.016009274590133814, 0.01591797131553672, 0.015976762396505292, 0.016628813657448702, 0.0168764698931493, 0.016078520592293952, 0.016336401586715604, 0.016085910757171067, 0.01655561656171706, 0.017740437212190697, 0.018263575231282178, 0.01861347170997764, 0.01773757810030233, 0.017048418724809205, 0.0168154459964214, 0.01672210284274733, 0.016584916429056386, 0.01740085021373216, 0.018054168338819218, 0.01689105330306069, 0.017481659562960716, 0.017752328417402558, 0.017534782031581975, 0.017245671039488264, 0.01649823273861415, 0.01671842754946904, 0.015996627482981036, 0.01592188647057088, 0.016003488949032186, 0.017668677570167955, 0.01803326870568779, 0.016942614755075237], "accuracy_valid": [0.4069177099021084, 0.4642613422439759, 0.578270601939006, 0.6167036309299698, 0.6856248235128012, 0.6868558217243976, 0.7189617846385542, 0.718372023249247, 0.7321556734751506, 0.7385342149849398, 0.741321241999247, 0.7467026308358433, 0.7482998399849398, 0.7506191759224398, 0.7525620058358433, 0.7525414156626506, 0.7529282167733433, 0.7565094361822289, 0.7573639283697289, 0.7588390672063253, 0.7572212678840362, 0.7599377000188253, 0.7585640413215362, 0.7588081819465362, 0.7612804734563253, 0.7608936723456325, 0.7615143189947289, 0.7604156861822289, 0.7584522660956325, 0.7582081254706325, 0.7568653520331325, 0.7557770143072289, 0.7559093797063253, 0.7550445924322289, 0.7544342408697289, 0.7539356645331325, 0.7532032426581325, 0.7529591020331325, 0.7524811158697289, 0.7516163285956325, 0.7510059770331325, 0.7500191194465362, 0.7492866975715362, 0.7485542756965362, 0.7486969361822289, 0.7489307817206325, 0.7480762895331325, 0.7470894319465362, 0.7457363634224398, 0.7458584337349398, 0.7437729433358433, 0.7436508730233433, 0.7435288027108433, 0.743030226374247, 0.7419212984751506, 0.7419212984751506, 0.7415550875376506, 0.7413109469126506, 0.7407005953501506, 0.7402123141001506, 0.7398461031626506, 0.7399681734751506, 0.7389813158885542, 0.7388592455760542, 0.7388695406626506, 0.7376385424510542, 0.7376385424510542, 0.7382591891001506, 0.7376488375376506, 0.737781202936747, 0.737048781061747, 0.7373032167733433, 0.7368149355233433, 0.7359604433358433, 0.7342205737010542, 0.7343426440135542, 0.7348412203501506], "seed": 803193642, "model": "residualv3", "loss_std": [0.2547101676464081, 0.11997190117835999, 0.10203082114458084, 0.09283600002527237, 0.08973319083452225, 0.08666782826185226, 0.08514900505542755, 0.08332768827676773, 0.08207805454730988, 0.08079251646995544, 0.07975221425294876, 0.07856398820877075, 0.07758479565382004, 0.07667313516139984, 0.07577268779277802, 0.0750383511185646, 0.07415463030338287, 0.0732295885682106, 0.0724356472492218, 0.07153487950563431, 0.07068127393722534, 0.06983761489391327, 0.06907457858324051, 0.06829196959733963, 0.06744280457496643, 0.0666946992278099, 0.06598307937383652, 0.06525618582963943, 0.06453070789575577, 0.0637907013297081, 0.06304779648780823, 0.06226871907711029, 0.06152864918112755, 0.06072643771767616, 0.05989854037761688, 0.059067994356155396, 0.05828748643398285, 0.057474445551633835, 0.05660910904407501, 0.055797234177589417, 0.05499092862010002, 0.05420927330851555, 0.053382664918899536, 0.05257021635770798, 0.051784079521894455, 0.05100911483168602, 0.05023888126015663, 0.0494874007999897, 0.048673853278160095, 0.04790200665593147, 0.047124218195676804, 0.046374958008527756, 0.045600488781929016, 0.04486110061407089, 0.044116221368312836, 0.043409451842308044, 0.0426836796104908, 0.041983798146247864, 0.04126442223787308, 0.04056986793875694, 0.039875179529190063, 0.03920283913612366, 0.03855380415916443, 0.03788811340928078, 0.037223730236291885, 0.0365787148475647, 0.035958170890808105, 0.035328950732946396, 0.03472209349274635, 0.03412473201751709, 0.033507417887449265, 0.03292063996195793, 0.03233148530125618, 0.031747739762067795, 0.03116372972726822, 0.030597850680351257, 0.030037304386496544]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:34 2016", "state": "available"}], "summary": "f96837a4291a4dd4490be49c02b78bf6"}