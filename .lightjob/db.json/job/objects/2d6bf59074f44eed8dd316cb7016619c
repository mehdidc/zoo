{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 64, "nonlin": "rectify", "nbg1": 2, "nbg3": 2, "nbg2": 2, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.08403874608512744, 0.0846363583390524, 0.07444164695770204, 0.07633996045987924, 0.07568958589170034, 0.08111570983874207, 0.07506672479915764, 0.07737767149150378, 0.07876194530967898, 0.07661281226522666, 0.07629929915406013, 0.07811575389073039, 0.07192916761490503, 0.07453454641496671, 0.07231012504021485, 0.07202691728602702, 0.07020826748953654, 0.0740429948677502, 0.06880056220678495, 0.0702382362926803, 0.07439958861277061, 0.07644081915595155, 0.07065381445732531, 0.07241856675193413, 0.07246731258013583, 0.07180309877314055, 0.07087220337919188, 0.067638230959422, 0.06797949398444707, 0.06855437675706146, 0.06991144442892958, 0.06838298012776166, 0.07146611910809854, 0.06925168946504656, 0.06621252064343469, 0.06889627914299992, 0.06605597386386201, 0.06693210331608823, 0.06908925127227465, 0.06861093726271406, 0.06866874980383696, 0.06918366655157518, 0.06979233618730217, 0.0682340271445973, 0.068640694067497, 0.06843877020409089, 0.06988541880984167, 0.06832662245454085, 0.07064232817689683, 0.07343822735280936, 0.06896717155331007, 0.06992062762869569, 0.0721249053940019, 0.0709632412559463, 0.0683949762268772, 0.07038282115322678, 0.06678098248722639, 0.07163847928035717, 0.07243962011083056, 0.07187224067030568, 0.07362850021154606, 0.07157571496424096, 0.06999137435376378, 0.07075471249438892, 0.07308621610826814, 0.07143466812334877, 0.06990876576843551, 0.07150541338579103, 0.07358815838053598, 0.07086050081037244, 0.07399420243216005, 0.0708081301606262, 0.07171810083819112, 0.07294222200966717, 0.07227756080008275, 0.07040714307339521, 0.07094765742374197, 0.0725857169720722, 0.0735528865920483, 0.07373101194178226, 0.06992062762869569, 0.07121161787562133, 0.07105052285505349, 0.07142268315288751, 0.06983231690252271, 0.07274279934687243, 0.07064927065755487, 0.07006586789565541, 0.07313305374155618, 0.07027567932461763, 0.07026603489219459, 0.07317705865656192, 0.06926443632419839, 0.06993223244762375, 0.06927846803220714, 0.07117892691486812, 0.07044563560660849, 0.07035696990046379, 0.0683699385022735, 0.07044107837826846, 0.07123966252338432, 0.07005148471786203, 0.06854592117932443, 0.07107311068614496, 0.07053102911751727, 0.069746323639489, 0.06931089743589744, 0.0678362280184553, 0.0681525595835858, 0.06674799192108141, 0.06824931598469092, 0.06675480507405317, 0.06806916047645882, 0.06981737471407681, 0.06799693839612111, 0.07244466708284752, 0.06930626559297352, 0.0676656480531031, 0.0666613641687149, 0.06943224436719443, 0.0646461328574678, 0.0680970588286577, 0.06855788876740158, 0.06582987081610323, 0.06745657564474584, 0.06607284641620718, 0.06970949173404355, 0.06943224436719445, 0.07069835346740952, 0.06995059218342121, 0.06951901096122051, 0.06653603607644244, 0.07107913289547517, 0.07048549878605528, 0.06962770137227992, 0.06819167092862792, 0.06665534417191837, 0.06731670082843061, 0.06840996839260094, 0.06715130833029305, 0.06538254777364634, 0.06808605802673813, 0.06824931598469092, 0.06871431594396905, 0.06946241959999946, 0.06891439727835559, 0.06800939595068917, 0.06776783701695147, 0.06682903673715718, 0.06834528303361323, 0.06599668328310368, 0.0659565407502032, 0.06871898768588859, 0.06976217583230421, 0.07012845761379206, 0.06491277615222678, 0.06862198387080405, 0.0694726890293282, 0.06688612297861807, 0.07092590974328462, 0.06676655946791116, 0.0657676646754473, 0.06963436082975824, 0.06519501797053844, 0.06757650182782418, 0.06790704522252439, 0.06682062973810048, 0.0668350410890383, 0.0668914556520524, 0.067638230959422, 0.06632219277740391, 0.07162914283544285, 0.06948501034108692, 0.06797332834735516, 0.06656337128389749, 0.07006472244104026, 0.06763348456492836, 0.06686745527251622, 0.06879589600436915, 0.07091333578787118, 0.0702367127637996, 0.06842521792062636, 0.06986704194771769, 0.06796335719747794, 0.06931089743589744, 0.07055441521990002, 0.07055024421294961, 0.06662215754094813, 0.06874804916908903, 0.06801372277778102, 0.06970450258399742, 0.06674959507846209, 0.069372111614334, 0.06733272771577684, 0.06570417816872753, 0.06878345125034624, 0.07056402023756471, 0.06690012033978313, 0.0655300896196154, 0.06775401891835975, 0.0669261076722558, 0.06801936035161604, 0.07141968659602167, 0.06813724903300447, 0.07148408488660783, 0.06849855065511329, 0.06724632279738613, 0.06721011105791284, 0.0680282746310712, 0.06965075062779959, 0.06656859585430785, 0.06714055102087892, 0.06572588985617911, 0.06602100021204489, 0.06663125874578958, 0.06708434593487657, 0.0695061824924741, 0.06677684286525525, 0.06656337128389749, 0.07095419299589155, 0.067404073917895, 0.06835741620094664, 0.06678218426489706, 0.06814313811340655, 0.06502189766967068, 0.06810897435897435, 0.06606474812886363, 0.06901732141874634, 0.06631573858621735, 0.06653603607644244, 0.06482410862894185, 0.06695980953857182, 0.06693050453024843, 0.06909286515886626, 0.06672915193679894, 0.06826068238951305, 0.06862198387080405, 0.06956402016166072, 0.06687492298027344, 0.06886831609815883, 0.06874350912219471, 0.06648347805129365, 0.06705509535256797, 0.06820853812895221, 0.06895320582312747, 0.06907776302003944, 0.06711451385432843, 0.06730358508191621, 0.06731670082843061, 0.06548721006772917, 0.07047854017306934, 0.06890469172688558, 0.07119345808399245, 0.06617358711561676, 0.06867342464554732, 0.06838754410911435, 0.06437312138252241, 0.06535021579876824, 0.06942646463495511, 0.06656913168449878, 0.06629596871697566, 0.06867173654497366, 0.06930459290695236, 0.0673649024262298, 0.06829320336864753, 0.06847563447268347, 0.06685371784622227, 0.06861093726271406, 0.06720533442734491, 0.066812088211437, 0.06706786081184639, 0.07029509107662314, 0.06821376742145535, 0.06847941096225797, 0.06550354844490422, 0.06631210782761499, 0.06843564299226358, 0.06768251459050095, 0.07131072629576185, 0.06460915388773918, 0.06789601363379631, 0.0666099760418299, 0.06541404583864054, 0.06857037445849794, 0.06850167499510451, 0.06770622604991293, 0.06603761163025454, 0.06638952094534609, 0.06495768229032603], "moving_avg_accuracy_train": [0.05327795557228915, 0.1103301487198795, 0.1687766142695783, 0.22481169757153613, 0.27730228986257527, 0.32579335229198036, 0.3710495780567582, 0.41375919103421493, 0.4531696988886248, 0.4898745663491599, 0.5242078928467739, 0.5554043851886026, 0.5842624782962483, 0.6108983539605994, 0.6357248401006841, 0.6587675669339891, 0.6800237168670962, 0.6999778587346034, 0.7185695871683719, 0.7350974176081613, 0.7510549198232487, 0.7659414270879118, 0.7796310757947833, 0.7919588191189194, 0.8035479522672684, 0.8143782097513849, 0.8244642969087764, 0.8339465193263325, 0.842504051128639, 0.8503046625820402, 0.8581041097274507, 0.8651377311342237, 0.8715150536533314, 0.8775181981373958, 0.8834551960947405, 0.8891161712141822, 0.8942557589120411, 0.8993426077196321, 0.9035207339958617, 0.9080152343914563, 0.9115778864041179, 0.9151631324022602, 0.9187357687102269, 0.9217840668392041, 0.9251934801854041, 0.9278054386427673, 0.930429168121864, 0.9328940638096777, 0.9347265512540112, 0.9372652854358389, 0.9394089564404478, 0.941733591669897, 0.9435033800932687, 0.9458139042827369, 0.9476698256014512, 0.9492766193967277, 0.9508827488727176, 0.9525400500396627, 0.9542975284694313, 0.955773366736946, 0.9568051226837333, 0.9577101714093359, 0.9592636083346673, 0.9601957753626463, 0.9614371165010804, 0.9628367030437435, 0.9642822307815377, 0.9653055325527815, 0.9663700470685876, 0.9671986861870301, 0.968064472688809, 0.9687001376187233, 0.9695828535255256, 0.9703772978416477, 0.971054647123748, 0.9718619271402889, 0.9727861448178262, 0.9736320597035134, 0.9742427806909935, 0.9745029905737013, 0.9749536704319938, 0.9757452009791558, 0.9762081432306379, 0.9764741888473331, 0.9774642887879009, 0.9775176528307976, 0.9782080938730191, 0.9789189109917413, 0.9795704122118444, 0.9802155923762021, 0.9806974216927987, 0.9811381275656875, 0.9819112688753838, 0.9822494153312189, 0.9824172637077355, 0.9828271751381668, 0.9831090284074826, 0.9834968266209512, 0.9838999677540368, 0.9844204566714042, 0.984568866576553, 0.9848247999490182, 0.9850927905866464, 0.9854022238773794, 0.9857371897426535, 0.9856433276960989, 0.985965948992754, 0.9860704083103461, 0.9860608825395525, 0.9863888116048743, 0.9866486503239049, 0.9870260480927192, 0.9871633340967002, 0.9873480737291989, 0.9877614214767609, 0.988079311708603, 0.9883254091522005, 0.9882668704960166, 0.9884589146211137, 0.9887070555385205, 0.9887938989304516, 0.9890814894590931, 0.9892697260553525, 0.9894626706184919, 0.9897916294602572, 0.9898782609419423, 0.989991526715218, 0.9901781797665876, 0.9904379408561939, 0.9907046701139479, 0.9907258823194206, 0.9907261480031412, 0.9909546438955981, 0.9911061674578455, 0.9912543044771212, 0.9912205532462766, 0.9914372592168297, 0.9916064098011708, 0.9916974630981622, 0.9916946972100327, 0.991656910470957, 0.9917852706286806, 0.9918631441682222, 0.9920767732754963, 0.9921372623636092, 0.992250531609176, 0.9924230688097042, 0.9925854117781314, 0.9926444534316436, 0.9928952565824551, 0.9930127339362579, 0.9931419951811863, 0.993121846867887, 0.9931578361268814, 0.9933478883575667, 0.9934365746724124, 0.9935634556087856, 0.9935952877587504, 0.9937486543142006, 0.9937290223165154, 0.9936407586390807, 0.993688392112522, 0.9937783254916313, 0.9937533732135525, 0.9938038642054502, 0.9936257556463509, 0.9935948818889446, 0.9937247574048695, 0.993822820067997, 0.9938004778202335, 0.9938486115141137, 0.9937130914771602, 0.9939064472390828, 0.9941392964910782, 0.9940335370226934, 0.9940654242842795, 0.9941058886329599, 0.9943046747696639, 0.9944835822926975, 0.9945692978586085, 0.9946558545185308, 0.9945902125907742, 0.9947029157292872, 0.9946113892165993, 0.9947055025539756, 0.9947360818166503, 0.9948083132434189, 0.9947791950214867, 0.9945459103084946, 0.9945430323800548, 0.9946722193528927, 0.9947390712127842, 0.9948768922541564, 0.9946856073962107, 0.9948687785843005, 0.9948665581053885, 0.9948833849755725, 0.9949455924117502, 0.9950039322669607, 0.9951246798535177, 0.9952380590067201, 0.9953165686180963, 0.9953048665755637, 0.9953343385023447, 0.9953137999834354, 0.995302374804369, 0.9954544603661007, 0.9955113298415388, 0.9955060364658186, 0.9955200977288753, 0.9955562844921324, 0.9955653209525578, 0.995606398044049, 0.9954998245047044, 0.9956392245843545, 0.9955764316439912, 0.9957670000759776, 0.995757318140669, 0.9959297979229876, 0.9959485462933395, 0.9960383678688248, 0.9959497795759182, 0.9959241728532662, 0.995974074845048, 0.9960495777521094, 0.9959575153082237, 0.9960017298918592, 0.9960038724147214, 0.9960740424021649, 0.9960948384631532, 0.9961276738939463, 0.9961313409925034, 0.9961346413812049, 0.9961658496828435, 0.9962551193832339, 0.9963095773244286, 0.9961373921823472, 0.9961094963376065, 0.9962797025773398, 0.9962258098798468, 0.9961726001268018, 0.9962635479454469, 0.9962277428496975, 0.9962684663056917, 0.9963168832293393, 0.9964216406895379, 0.9963559073434757, 0.996395580163345, 0.9965254122072513, 0.9965810788178515, 0.9965770560264279, 0.9965781418394477, 0.9966450076253826, 0.9967310716218805, 0.996740287501861, 0.9966426894745666, 0.9967760485391581, 0.9968090046792183, 0.9967916019522604, 0.9969077166064318, 0.9968945616626561, 0.996835658960246, 0.9968626540581973, 0.9968445927186427, 0.9968942260672604, 0.9969365429183658, 0.9970169850120714, 0.9968658324445991, 0.9968686317302597, 0.9968946827138603, 0.9970193145930767, 0.9971173643084679, 0.9970950104077416, 0.9971243083127506, 0.9970824347103912, 0.9970588674441713, 0.9971294302479469, 0.9971929367713449, 0.9971394939978249, 0.9971949346582833, 0.9972518907406478, 0.9972278500099565, 0.9972179791655874, 0.9972702776345708, 0.9972561640277402, 0.9972105175044843, 0.9971694356335539, 0.9972548264075479, 0.9973057933149859], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.025546864949665352, 0.05228675314124842, 0.07780198184439271, 0.09828115870586962, 0.11325040334685955, 0.12308781123196579, 0.1292121638430221, 0.13270794682487713, 0.1334158453064719, 0.13219948643348375, 0.12958853356566133, 0.12538867041899915, 0.12034490921738521, 0.11469564714730762, 0.1087732721591512, 0.10267465028246495, 0.09647360044402702, 0.09040975039864177, 0.08447964665417258, 0.07849020460017317, 0.07293296103265655, 0.0676341378162587, 0.06255738237009076, 0.05766940343227373, 0.05311123515321781, 0.048855761932446395, 0.04488574812652026, 0.04120638619165227, 0.03774482972741443, 0.034517992606095386, 0.03161367572745231, 0.028897554625551415, 0.026373831345610745, 0.02406078790431865, 0.02197194061659643, 0.020063166308663217, 0.018294587933132735, 0.01669801341694108, 0.015185322727868052, 0.013848595259335243, 0.012577968137671614, 0.011435857223709218, 0.010407145073039319, 0.009450059659083528, 0.0086096705874624, 0.00781010447156308, 0.0070910496318221045, 0.006436626065406113, 0.0058231855509682596, 0.005298873537085261, 0.004810344111760742, 0.004377945061134635, 0.003968339914592677, 0.0036195526214044737, 0.0032885973547353495, 0.0029829736959666683, 0.002707893193412793, 0.0024618236984931324, 0.0022434399025237383, 0.002038698799598112, 0.00184440960264188, 0.0016673406611391257, 0.001522325091554063, 0.0013779130007111188, 0.0012539900510377283, 0.001146220628347587, 0.0010504045194794235, 0.0009547883861667577, 0.0008695082679393408, 0.0007887372262429244, 0.0007166097800185952, 0.0006485854311448421, 0.0005907395743794553, 0.0005373458928842787, 0.00048774052204550694, 0.0004448317790669121, 0.00040803620599947407, 0.0003736727333439723, 0.0003396622811305118, 0.00030630543566499035, 0.00027750290311052647, 0.00025539129826328993, 0.00023178100819082597, 0.0002092399298032082, 0.00019713861785370046, 0.0001774503855579989, 0.0001639957264972535, 0.00015214350263394468, 0.0001407492369287112, 0.00013042063023616603, 0.00011946800262553742, 0.0001092691973605718, 0.00010372200498734499, 9.437889171895512e-05, 8.519456024455314e-05, 7.818735064728168e-05, 7.108358697136986e-05, 6.532871536355786e-05, 6.025854878587198e-05, 5.6670872325205476e-05, 5.120201459220124e-05, 4.667133015325376e-05, 4.265056797463621e-05, 3.9247251829896934e-05, 3.6332345824996735e-05, 3.277840199654766e-05, 3.0437322306392116e-05, 2.7491795817039104e-05, 2.4743432898118113e-05, 2.3236926855252144e-05, 2.152087960889428e-05, 2.065065333115914e-05, 1.8755215020045117e-05, 1.7186852104382244e-05, 1.7005874137675534e-05, 1.6214774519412877e-05, 1.5138372633178787e-05, 1.3655376338271267e-05, 1.2621767218303064e-05, 1.1913755730495703e-05, 1.0790256129945005e-05, 1.0455605326429651e-05, 9.728941939328481e-06, 9.0910961854013e-06, 9.155911843041086e-06, 8.30786578130761e-06, 7.59254142173843e-06, 7.1468415338354105e-06, 7.0394397935129705e-06, 6.9757962866401905e-06, 6.2822662769253065e-06, 5.65404028452333e-06, 5.558529611898384e-06, 5.2093111599538825e-06, 4.885881232277464e-06, 4.407545419301478e-06, 4.389444176431435e-06, 4.208007040434801e-06, 3.861822662428287e-06, 3.4757092474197614e-06, 3.140988861527457e-06, 2.9751769461920985e-06, 2.7322378450194845e-06, 2.8697506197903924e-06, 2.615705925838065e-06, 2.4696046311756984e-06, 2.4905659381530612e-06, 2.4787064989174393e-06, 2.2622091006707405e-06, 2.6021081747166443e-06, 2.4661057151532825e-06, 2.369871368601973e-06, 2.1365378225010555e-06, 1.9345410811176716e-06, 2.0661656265022218e-06, 1.9303364258202666e-06, 1.8821917313727541e-06, 1.7030921301779215e-06, 1.7444746201362497e-06, 1.5734958961206012e-06, 1.4862605972971745e-06, 1.3580550676962254e-06, 1.2950416750286631e-06, 1.1711410531576858e-06, 1.0769710102073046e-06, 1.2547778386062097e-06, 1.1378787548129663e-06, 1.1758997260622896e-06, 1.1448563265529914e-06, 1.0348632782138485e-06, 9.522286227714912e-07, 1.0222968842373484e-06, 1.256545251831386e-06, 1.618859694041276e-06, 1.557639311014734e-06, 1.4110265569763938e-06, 1.284660172905984e-06, 1.5118375089267383e-06, 1.6487248742162617e-06, 1.5499768109495776e-06, 1.4624076282467423e-06, 1.3549466295386018e-06, 1.3337699434607586e-06, 1.2757868718377127e-06, 1.2279240671027306e-06, 1.1135474821440264e-06, 1.049149145047023e-06, 9.518650681787877e-07, 1.346474377202914e-06, 1.2119014817315656e-06, 1.2409147991175676e-06, 1.1570458597443252e-06, 1.21229302877411e-06, 1.420372797810677e-06, 1.580300675345575e-06, 1.4223149825504042e-06, 1.282631776337079e-06, 1.1891964847455787e-06, 1.100908684624881e-06, 1.1220376330963312e-06, 1.1255273612148259e-06, 1.0684484567992917e-06, 9.62836051314257e-07, 8.743697963964822e-07, 7.907292935876705e-07, 7.128311766792032e-07, 8.497182217967112e-07, 7.938536347465017e-07, 7.147204497104822e-07, 6.450278768081808e-07, 5.923104256425571e-07, 5.338143016314655e-07, 4.956188184767073e-07, 5.48278210225086e-07, 6.683418290605171e-07, 6.369942263895277e-07, 9.001417491784283e-07, 8.109712331024654e-07, 9.976175875703788e-07, 9.01019341330988e-07, 8.83528646001887e-07, 8.658067521626112e-07, 7.851274151511661e-07, 7.290265526901867e-07, 7.074300981937554e-07, 7.129665305421486e-07, 6.592642421424477e-07, 5.933791315661413e-07, 5.783556626499359e-07, 5.244123817586154e-07, 4.816746332210821e-07, 4.3362819840542674e-07, 3.9036341165511105e-07, 3.60092693310064e-07, 3.958051386491001e-07, 3.829156310166615e-07, 6.114535762973752e-07, 5.573118220518356e-07, 7.623121162440902e-07, 7.12220710207348e-07, 6.664801395585144e-07, 6.742756770494209e-07, 6.183861532791655e-07, 5.714731367641831e-07, 5.354236095473303e-07, 5.806483777979556e-07, 5.614713950789877e-07, 5.194896492985246e-07, 6.192479209930531e-07, 5.852120727151442e-07, 5.26836511101178e-07, 4.741634709002871e-07, 4.669864237682912e-07, 4.869508848301551e-07, 4.39020188341496e-07, 4.808465438934304e-07, 5.928236504826393e-07, 5.433162499433167e-07, 4.91710319099149e-07, 5.6388280340965e-07, 5.090519959803652e-07, 4.89372551543342e-07, 4.469939142096143e-07, 4.0523043066723375e-07, 3.8687861125552737e-07, 3.643071931171733e-07, 3.8611484776310523e-07, 5.53127250867737e-07, 4.978850497828485e-07, 4.5420442852356133e-07, 5.485819335242726e-07, 5.802474603663638e-07, 5.267199862288609e-07, 4.817732927472095e-07, 4.493765506434657e-07, 4.094376399128082e-07, 4.133058594116487e-07, 4.0827298009748746e-07, 3.9315085246135647e-07, 3.8149876870386474e-07, 3.7254484969821576e-07, 3.404919753179336e-07, 3.0731967990317914e-07, 3.012038806349571e-07, 2.728762376513721e-07, 2.643410596544404e-07, 2.5309643476124163e-07, 2.9341104983477794e-07, 2.874485757354209e-07], "duration": 19405.691037, "accuracy_train": [0.5327795557228916, 0.6237998870481928, 0.6947948042168675, 0.7291274472891566, 0.7497176204819277, 0.7622129141566265, 0.778355609939759, 0.7981457078313253, 0.8078642695783133, 0.8202183734939759, 0.8332078313253012, 0.8361728162650602, 0.8439853162650602, 0.850621234939759, 0.8591632153614458, 0.8661521084337349, 0.8713290662650602, 0.8795651355421686, 0.8858951430722891, 0.8838478915662651, 0.8946724397590361, 0.8999199924698795, 0.9028379141566265, 0.9029085090361446, 0.9078501506024096, 0.9118505271084337, 0.9152390813253012, 0.9192865210843374, 0.9195218373493976, 0.9205101656626506, 0.9282991340361446, 0.9284403237951807, 0.9289109563253012, 0.9315464984939759, 0.9368881777108434, 0.9400649472891566, 0.9405120481927711, 0.9451242469879518, 0.9411238704819277, 0.9484657379518072, 0.9436417545180723, 0.9474303463855421, 0.9508894954819277, 0.94921875, 0.9558782003012049, 0.9513130647590361, 0.9540427334337349, 0.955078125, 0.9512189382530121, 0.9601138930722891, 0.9587019954819277, 0.9626553087349398, 0.9594314759036144, 0.9666086219879518, 0.9643731174698795, 0.9637377635542169, 0.9653379141566265, 0.9674557605421686, 0.9701148343373494, 0.9690559111445783, 0.9660909262048193, 0.965855609939759, 0.9732445406626506, 0.9685852786144579, 0.9726091867469879, 0.9754329819277109, 0.9772919804216867, 0.9745152484939759, 0.9759506777108434, 0.9746564382530121, 0.9758565512048193, 0.9744211219879518, 0.977527296686747, 0.977527296686747, 0.9771507906626506, 0.9791274472891566, 0.9811041039156626, 0.9812452936746988, 0.9797392695783133, 0.9768448795180723, 0.9790097891566265, 0.9828689759036144, 0.9803746234939759, 0.9788685993975904, 0.9863751882530121, 0.9779979292168675, 0.9844220632530121, 0.985316265060241, 0.9854339231927711, 0.9860222138554217, 0.9850338855421686, 0.9851044804216867, 0.9888695406626506, 0.9852927334337349, 0.9839278990963856, 0.9865163780120482, 0.9856457078313253, 0.9869870105421686, 0.9875282379518072, 0.9891048569277109, 0.9859045557228916, 0.9871282003012049, 0.9875047063253012, 0.9881871234939759, 0.9887518825301205, 0.9847985692771084, 0.9888695406626506, 0.9870105421686747, 0.9859751506024096, 0.9893401731927711, 0.9889871987951807, 0.9904226280120482, 0.9883989081325302, 0.9890107304216867, 0.9914815512048193, 0.9909403237951807, 0.9905402861445783, 0.9877400225903614, 0.9901873117469879, 0.9909403237951807, 0.9895754894578314, 0.9916698042168675, 0.9909638554216867, 0.991199171686747, 0.9927522590361446, 0.9906579442771084, 0.9910109186746988, 0.9918580572289156, 0.9927757906626506, 0.9931052334337349, 0.9909167921686747, 0.9907285391566265, 0.9930111069277109, 0.9924698795180723, 0.9925875376506024, 0.9909167921686747, 0.9933876129518072, 0.993128765060241, 0.9925169427710844, 0.9916698042168675, 0.9913168298192772, 0.9929405120481928, 0.9925640060240963, 0.9939994352409639, 0.9926816641566265, 0.9932699548192772, 0.9939759036144579, 0.9940464984939759, 0.993175828313253, 0.995152484939759, 0.9940700301204819, 0.9943053463855421, 0.9929405120481928, 0.9934817394578314, 0.9950583584337349, 0.9942347515060241, 0.9947053840361446, 0.9938817771084337, 0.995128953313253, 0.9935523343373494, 0.9928463855421686, 0.994117093373494, 0.9945877259036144, 0.9935288027108434, 0.9942582831325302, 0.9920227786144579, 0.9933170180722891, 0.9948936370481928, 0.9947053840361446, 0.9935993975903614, 0.9942818147590361, 0.9924934111445783, 0.9956466490963856, 0.9962349397590361, 0.9930817018072289, 0.9943524096385542, 0.9944700677710844, 0.99609375, 0.99609375, 0.9953407379518072, 0.9954348644578314, 0.9939994352409639, 0.9957172439759037, 0.9937876506024096, 0.9955525225903614, 0.9950112951807228, 0.9954583960843374, 0.9945171310240963, 0.9924463478915663, 0.9945171310240963, 0.9958349021084337, 0.9953407379518072, 0.996117281626506, 0.9929640436746988, 0.9965173192771084, 0.9948465737951807, 0.9950348268072289, 0.9955054593373494, 0.9955289909638554, 0.9962114081325302, 0.9962584713855421, 0.9960231551204819, 0.9951995481927711, 0.9955995858433735, 0.995128953313253, 0.9951995481927711, 0.9968232304216867, 0.9960231551204819, 0.9954583960843374, 0.9956466490963856, 0.9958819653614458, 0.9956466490963856, 0.9959760918674698, 0.9945406626506024, 0.9968938253012049, 0.9950112951807228, 0.9974821159638554, 0.9956701807228916, 0.9974821159638554, 0.996117281626506, 0.9968467620481928, 0.995152484939759, 0.9956937123493976, 0.9964231927710844, 0.9967291039156626, 0.995128953313253, 0.9963996611445783, 0.9960231551204819, 0.9967055722891566, 0.9962820030120482, 0.9964231927710844, 0.9961643448795181, 0.9961643448795181, 0.9964467243975904, 0.997058546686747, 0.9967996987951807, 0.9945877259036144, 0.9958584337349398, 0.9978115587349398, 0.9957407756024096, 0.9956937123493976, 0.997082078313253, 0.9959054969879518, 0.9966349774096386, 0.9967526355421686, 0.9973644578313253, 0.9957643072289156, 0.9967526355421686, 0.9976939006024096, 0.997082078313253, 0.9965408509036144, 0.9965879141566265, 0.9972467996987951, 0.9975056475903614, 0.9968232304216867, 0.9957643072289156, 0.9979762801204819, 0.997105609939759, 0.9966349774096386, 0.9979527484939759, 0.9967761671686747, 0.9963055346385542, 0.997105609939759, 0.9966820406626506, 0.9973409262048193, 0.9973173945783133, 0.9977409638554217, 0.9955054593373494, 0.9968938253012049, 0.9971291415662651, 0.9981410015060241, 0.9979998117469879, 0.9968938253012049, 0.9973879894578314, 0.9967055722891566, 0.9968467620481928, 0.9977644954819277, 0.9977644954819277, 0.9966585090361446, 0.9976939006024096, 0.9977644954819277, 0.9970114834337349, 0.9971291415662651, 0.9977409638554217, 0.9971291415662651, 0.9967996987951807, 0.9967996987951807, 0.998023343373494, 0.9977644954819277], "end": "2016-01-17 20:28:27.156000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0], "accuracy_valid": [0.5339209401709402, 0.6180555555555556, 0.6762820512820513, 0.703659188034188, 0.7156784188034188, 0.7267628205128205, 0.7409188034188035, 0.7512019230769231, 0.7569444444444444, 0.766159188034188, 0.7725694444444444, 0.7748397435897436, 0.7801816239316239, 0.7831196581196581, 0.7853899572649573, 0.7893963675213675, 0.7888621794871795, 0.7915331196581197, 0.7958066239316239, 0.7926014957264957, 0.796073717948718, 0.8011485042735043, 0.7980769230769231, 0.8008814102564102, 0.797676282051282, 0.8004807692307693, 0.8014155982905983, 0.7979433760683761, 0.8023504273504274, 0.8011485042735043, 0.8075587606837606, 0.8072916666666666, 0.8070245726495726, 0.8006143162393162, 0.8072916666666666, 0.8108974358974359, 0.8092948717948718, 0.8099626068376068, 0.8078258547008547, 0.812767094017094, 0.8056891025641025, 0.8083600427350427, 0.8106303418803419, 0.8082264957264957, 0.8129006410256411, 0.8091613247863247, 0.8107638888888888, 0.8112980769230769, 0.8078258547008547, 0.8098290598290598, 0.8114316239316239, 0.8099626068376068, 0.8110309829059829, 0.8112980769230769, 0.8083600427350427, 0.8126335470085471, 0.8149038461538461, 0.8135683760683761, 0.8141025641025641, 0.8171741452991453, 0.8126335470085471, 0.8111645299145299, 0.8175747863247863, 0.8138354700854701, 0.8154380341880342, 0.8155715811965812, 0.8170405982905983, 0.8143696581196581, 0.8138354700854701, 0.8143696581196581, 0.811965811965812, 0.8141025641025641, 0.8173076923076923, 0.8166399572649573, 0.8171741452991453, 0.8179754273504274, 0.8203792735042735, 0.8173076923076923, 0.8158386752136753, 0.8149038461538461, 0.8150373931623932, 0.8153044871794872, 0.8202457264957265, 0.8158386752136753, 0.8177083333333334, 0.8154380341880342, 0.8229166666666666, 0.8230502136752137, 0.8207799145299145, 0.8213141025641025, 0.8218482905982906, 0.8201121794871795, 0.8207799145299145, 0.8221153846153846, 0.8209134615384616, 0.8229166666666666, 0.8201121794871795, 0.8238514957264957, 0.8198450854700855, 0.8225160256410257, 0.8198450854700855, 0.8221153846153846, 0.8221153846153846, 0.8239850427350427, 0.8229166666666666, 0.8202457264957265, 0.8257211538461539, 0.8241185897435898, 0.8225160256410257, 0.8235844017094017, 0.8238514957264957, 0.8263888888888888, 0.8215811965811965, 0.8229166666666666, 0.8265224358974359, 0.8235844017094017, 0.8233173076923077, 0.8257211538461539, 0.8254540598290598, 0.8243856837606838, 0.8245192307692307, 0.8243856837606838, 0.8250534188034188, 0.8287927350427351, 0.827323717948718, 0.8267895299145299, 0.8274572649572649, 0.8243856837606838, 0.8299946581196581, 0.8285256410256411, 0.8249198717948718, 0.8254540598290598, 0.8223824786324786, 0.8285256410256411, 0.8262553418803419, 0.8250534188034188, 0.8223824786324786, 0.8247863247863247, 0.8245192307692307, 0.828125, 0.8230502136752137, 0.8254540598290598, 0.8238514957264957, 0.8245192307692307, 0.8293269230769231, 0.8295940170940171, 0.8290598290598291, 0.828659188034188, 0.8269230769230769, 0.8303952991452992, 0.8299946581196581, 0.8287927350427351, 0.8261217948717948, 0.8269230769230769, 0.827590811965812, 0.8299946581196581, 0.827323717948718, 0.8279914529914529, 0.8295940170940171, 0.8245192307692307, 0.8293269230769231, 0.828659188034188, 0.8265224358974359, 0.8277243589743589, 0.8270566239316239, 0.8255876068376068, 0.8265224358974359, 0.827323717948718, 0.8293269230769231, 0.8270566239316239, 0.8266559829059829, 0.8259882478632479, 0.8319978632478633, 0.8305288461538461, 0.8262553418803419, 0.8271901709401709, 0.8267895299145299, 0.8317307692307693, 0.8294604700854701, 0.8306623931623932, 0.8267895299145299, 0.8297275641025641, 0.8299946581196581, 0.8254540598290598, 0.8305288461538461, 0.8307959401709402, 0.8330662393162394, 0.8301282051282052, 0.8282585470085471, 0.828659188034188, 0.8340010683760684, 0.8315972222222222, 0.8318643162393162, 0.828926282051282, 0.8310630341880342, 0.8262553418803419, 0.8305288461538461, 0.827590811965812, 0.8306623931623932, 0.8295940170940171, 0.8327991452991453, 0.8309294871794872, 0.8270566239316239, 0.8277243589743589, 0.828659188034188, 0.8271901709401709, 0.8326655982905983, 0.8322649572649573, 0.8319978632478633, 0.827590811965812, 0.8314636752136753, 0.8293269230769231, 0.8305288461538461, 0.827590811965812, 0.8314636752136753, 0.828926282051282, 0.8315972222222222, 0.827857905982906, 0.8299946581196581, 0.828926282051282, 0.8330662393162394, 0.8299946581196581, 0.8345352564102564, 0.8321314102564102, 0.8344017094017094, 0.8301282051282052, 0.8348023504273504, 0.8317307692307693, 0.8298611111111112, 0.8307959401709402, 0.8319978632478633, 0.827323717948718, 0.8302617521367521, 0.8297275641025641, 0.8306623931623932, 0.8279914529914529, 0.828926282051282, 0.8301282051282052, 0.8360042735042735, 0.8285256410256411, 0.827323717948718, 0.8305288461538461, 0.8302617521367521, 0.8307959401709402, 0.8327991452991453, 0.8317307692307693, 0.8336004273504274, 0.8302617521367521, 0.8314636752136753, 0.8315972222222222, 0.8291933760683761, 0.8299946581196581, 0.8282585470085471, 0.8303952991452992, 0.8313301282051282, 0.8330662393162394, 0.8350694444444444, 0.8336004273504274, 0.8306623931623932, 0.8325320512820513, 0.8318643162393162, 0.8295940170940171, 0.8319978632478633, 0.8349358974358975, 0.8326655982905983, 0.8301282051282052, 0.8350694444444444, 0.8295940170940171, 0.8311965811965812, 0.8315972222222222, 0.8348023504273504, 0.8313301282051282, 0.8337339743589743, 0.8299946581196581, 0.8323985042735043, 0.8299946581196581, 0.8340010683760684, 0.8299946581196581, 0.828125, 0.8311965811965812, 0.8338675213675214, 0.8318643162393162, 0.8336004273504274, 0.8330662393162394, 0.8322649572649573, 0.827590811965812, 0.8306623931623932, 0.8323985042735043, 0.8344017094017094], "accuracy_test": 0.8206129807692307, "start": "2016-01-17 15:05:01.465000", "learning_rate_per_epoch": [0.0010000000474974513, 0.0007071067811921239, 0.0005773502634838223, 0.0005000000237487257, 0.00044721359154209495, 0.0004082482773810625, 0.000377964461222291, 0.00035355339059606194, 0.00033333332976326346, 0.0003162277571391314, 0.0003015113470610231, 0.00028867513174191117, 0.00027735010371543467, 0.0002672612317837775, 0.00025819888105615973, 0.0002500000118743628, 0.00024253562150988728, 0.00023570226039737463, 0.00022941573115531355, 0.00022360679577104747, 0.00021821788686793298, 0.00021320072119124234, 0.00020851440785918385, 0.00020412413869053125, 0.00019999999494757503, 0.0001961161324288696, 0.00019245008297730237, 0.0001889822306111455, 0.00018569533131085336, 0.00018257419287692755, 0.00017960529658012092, 0.00017677669529803097, 0.00017407764971721917, 0.00017149858467746526, 0.00016903085634112358, 0.00016666666488163173, 0.0001643989817239344, 0.00016222141857724637, 0.00016012815467547625, 0.0001581138785695657, 0.00015617375902365893, 0.00015430334315169603, 0.00015249857096932828, 0.00015075567353051156, 0.00014907120203133672, 0.00014744195505045354, 0.00014586499310098588, 0.00014433756587095559, 0.0001428571413271129, 0.00014142136205919087, 0.00014002800162415951, 0.00013867505185771734, 0.00013736056280322373, 0.00013608275912702084, 0.0001348399673588574, 0.00013363061589188874, 0.0001324532349826768, 0.00013130642764735967, 0.00013018891331739724, 0.00012909944052807987, 0.00012803687423001975, 0.00012700012302957475, 0.00012598815374076366, 0.0001250000059371814, 0.00012403473374433815, 0.00012309149315115064, 0.00012216944014653563, 0.00012126781075494364, 0.0001203858555527404, 0.00011952286149607971, 0.0001186781664728187, 0.00011785113019868731, 0.00011704114876920357, 0.00011624764010775834, 0.00011547005124157295, 0.00011470786557765678, 0.00011396057379897684, 0.00011322770296828821, 0.00011250878742430359, 0.00011180339788552374, 0.00011111111234640703, 0.00011043152335332707, 0.00010976425983244553, 0.00010910894343396649, 0.00010846523218788207, 0.00010783276957226917, 0.00010721124999690801, 0.00010660036059562117, 0.00010599978850223124, 0.00010540925723034889, 0.00010482848301762715, 0.00010425720392959192, 0.00010369517258368433, 0.00010314212704543024, 0.00010259783448418602, 0.00010206206934526563, 0.00010153461334994063, 0.00010101525549544021, 0.00010050378477899358, 9.999999747378752e-05, 9.95037189568393e-05, 9.901475277729332e-05, 9.853292431216687e-05, 9.80580662144348e-05, 9.759000386111438e-05, 9.712858445709571e-05, 9.667364793131128e-05, 9.622504148865119e-05, 9.578262688592076e-05, 9.534625860396773e-05, 9.49157983995974e-05, 9.449111530557275e-05, 9.407208563061431e-05, 9.365857840748504e-05, 9.32504772208631e-05, 9.284766565542668e-05, 9.245003457181156e-05, 9.205746027873829e-05, 9.16698481887579e-05, 9.128709643846378e-05, 9.09090886125341e-05, 9.053574467543513e-05, 9.016696276376024e-05, 8.980264829006046e-05, 8.944272121880203e-05, 8.908707968657836e-05, 8.87356509338133e-05, 8.838834764901549e-05, 8.804508979665115e-05, 8.770580461714417e-05, 8.737040479900315e-05, 8.703882485860959e-05, 8.671099931234494e-05, 8.638684084871784e-05, 8.606629853602499e-05, 8.574929233873263e-05, 8.543576404917985e-05, 8.512565545970574e-05, 8.481889381073415e-05, 8.451542817056179e-05, 8.421519305557013e-05, 8.391813753405586e-05, 8.362420339835808e-05, 8.333333244081587e-05, 8.304548100568354e-05, 8.276059088530019e-05, 8.247861114796251e-05, 8.21994908619672e-05, 8.19231936475262e-05, 8.164966129697859e-05, 8.137884287862107e-05, 8.111070928862318e-05, 8.084520959528163e-05, 8.058229286689311e-05, 8.032192999962717e-05, 8.006407733773813e-05, 7.980869122548029e-05, 7.955572800710797e-05, 7.930515857879072e-05, 7.905693928478286e-05, 7.881104102125391e-05, 7.856742013245821e-05, 7.832604751456529e-05, 7.808687951182947e-05, 7.78498942963779e-05, 7.761505548842251e-05, 7.738232670817524e-05, 7.715167157584801e-05, 7.69230755395256e-05, 7.669650221941993e-05, 7.647190795978531e-05, 7.624928548466414e-05, 7.602859113831073e-05, 7.580980309285223e-05, 7.55928922444582e-05, 7.537783676525578e-05, 7.51646002754569e-05, 7.495316822314635e-05, 7.474351150449365e-05, 7.453560101566836e-05, 7.432941492879763e-05, 7.412493141600862e-05, 7.392212864942849e-05, 7.372097752522677e-05, 7.352146349148825e-05, 7.332355744438246e-05, 7.312724483199418e-05, 7.293249655049294e-05, 7.273929804796353e-05, 7.25476274965331e-05, 7.23574630683288e-05, 7.216878293547779e-05, 7.198157254606485e-05, 7.179581734817475e-05, 7.161148823797703e-05, 7.142857066355646e-05, 7.124705007299781e-05, 7.106690463842824e-05, 7.088811980793253e-05, 7.071068102959543e-05, 7.053455919958651e-05, 7.035975431790575e-05, 7.018623728072271e-05, 7.001400081207976e-05, 6.984303036006168e-05, 6.967330409679562e-05, 6.950480747036636e-05, 6.933752592885867e-05, 6.917144492035732e-05, 6.900655716890469e-05, 6.884284084662795e-05, 6.868028140161186e-05, 6.851887155789882e-05, 6.835858948761597e-05, 6.819943519076332e-05, 6.804137956351042e-05, 6.788442260585725e-05, 6.77285497658886e-05, 6.757373921573162e-05, 6.74199836794287e-05, 6.726727588102221e-05, 6.711560854455456e-05, 6.696495256619528e-05, 6.681530794594437e-05, 6.666666740784422e-05, 6.651900912402198e-05, 6.637233309447765e-05, 6.62266174913384e-05, 6.608186231460422e-05, 6.593804573640227e-05, 6.579516775673255e-05, 6.565321382367983e-05, 6.55121766612865e-05, 6.537204171763733e-05, 6.523280899273232e-05, 6.509445665869862e-05, 6.495697743957862e-05, 6.482037133537233e-05, 6.468462379416451e-05, 6.454972026403993e-05, 6.44156607449986e-05, 6.42824379610829e-05, 6.415003008442e-05, 6.401843711500987e-05, 6.388765905285254e-05, 6.375767407007515e-05, 6.36284748907201e-05, 6.350006151478738e-05, 6.337242666631937e-05, 6.324555579340085e-05, 6.311944162007421e-05, 6.299407687038183e-05, 6.286946154432371e-05, 6.274558108998463e-05, 6.262242823140696e-05, 6.25000029685907e-05, 6.237828347366303e-05, 6.225727702258155e-05, 6.213697633938864e-05, 6.201736687216908e-05, 6.189844862092286e-05, 6.178020703373477e-05, 6.166264211060479e-05, 6.154574657557532e-05, 6.142951315268874e-05, 6.131393456598744e-05, 6.11990035395138e-05, 6.108472007326782e-05, 6.0971076891291887e-05, 6.085806307964958e-05, 6.07456750003621e-05, 6.063390537747182e-05, 6.0522754210978746e-05, 6.041221058694646e-05, 6.030226722941734e-05, 6.01929277763702e-05, 6.0084177675889805e-05, 5.9976013289997354e-05, 5.9868434618692845e-05, 5.9761430748039857e-05, 5.965499804005958e-05, 5.954913285677321e-05, 5.944383156020194e-05, 5.933908323640935e-05, 5.923488788539544e-05, 5.913123823120259e-05, 5.90281342738308e-05, 5.892556509934366e-05, 5.8823530707741156e-05], "accuracy_train_last": 0.9977644954819277, "error_valid": [0.46607905982905984, 0.3819444444444444, 0.3237179487179487, 0.29634081196581197, 0.28432158119658124, 0.2732371794871795, 0.25908119658119655, 0.24879807692307687, 0.24305555555555558, 0.23384081196581197, 0.22743055555555558, 0.2251602564102564, 0.21981837606837606, 0.2168803418803419, 0.2146100427350427, 0.21060363247863245, 0.21113782051282048, 0.20846688034188032, 0.20419337606837606, 0.20739850427350426, 0.20392628205128205, 0.19885149572649574, 0.20192307692307687, 0.19911858974358976, 0.20232371794871795, 0.19951923076923073, 0.19858440170940173, 0.20205662393162394, 0.1976495726495726, 0.19885149572649574, 0.19244123931623935, 0.19270833333333337, 0.1929754273504274, 0.19938568376068377, 0.19270833333333337, 0.1891025641025641, 0.1907051282051282, 0.1900373931623932, 0.19217414529914534, 0.18723290598290598, 0.19431089743589747, 0.1916399572649573, 0.1893696581196581, 0.19177350427350426, 0.18709935897435892, 0.19083867521367526, 0.18923611111111116, 0.18870192307692313, 0.19217414529914534, 0.19017094017094016, 0.18856837606837606, 0.1900373931623932, 0.18896901709401714, 0.18870192307692313, 0.1916399572649573, 0.18736645299145294, 0.18509615384615385, 0.18643162393162394, 0.1858974358974359, 0.18282585470085466, 0.18736645299145294, 0.18883547008547008, 0.1824252136752137, 0.18616452991452992, 0.18456196581196582, 0.18442841880341876, 0.18295940170940173, 0.1856303418803419, 0.18616452991452992, 0.1856303418803419, 0.18803418803418803, 0.1858974358974359, 0.1826923076923077, 0.1833600427350427, 0.18282585470085466, 0.1820245726495726, 0.17962072649572647, 0.1826923076923077, 0.18416132478632474, 0.18509615384615385, 0.1849626068376068, 0.18469551282051277, 0.17975427350427353, 0.18416132478632474, 0.18229166666666663, 0.18456196581196582, 0.17708333333333337, 0.1769497863247863, 0.1792200854700855, 0.17868589743589747, 0.17815170940170943, 0.17988782051282048, 0.1792200854700855, 0.17788461538461542, 0.17908653846153844, 0.17708333333333337, 0.17988782051282048, 0.17614850427350426, 0.1801549145299145, 0.17748397435897434, 0.1801549145299145, 0.17788461538461542, 0.17788461538461542, 0.1760149572649573, 0.17708333333333337, 0.17975427350427353, 0.17427884615384615, 0.17588141025641024, 0.17748397435897434, 0.17641559829059827, 0.17614850427350426, 0.17361111111111116, 0.17841880341880345, 0.17708333333333337, 0.1734775641025641, 0.17641559829059827, 0.1766826923076923, 0.17427884615384615, 0.17454594017094016, 0.17561431623931623, 0.17548076923076927, 0.17561431623931623, 0.17494658119658124, 0.1712072649572649, 0.17267628205128205, 0.17321047008547008, 0.1725427350427351, 0.17561431623931623, 0.1700053418803419, 0.17147435897435892, 0.1750801282051282, 0.17454594017094016, 0.1776175213675214, 0.17147435897435892, 0.1737446581196581, 0.17494658119658124, 0.1776175213675214, 0.17521367521367526, 0.17548076923076927, 0.171875, 0.1769497863247863, 0.17454594017094016, 0.17614850427350426, 0.17548076923076927, 0.17067307692307687, 0.17040598290598286, 0.1709401709401709, 0.17134081196581197, 0.17307692307692313, 0.1696047008547008, 0.1700053418803419, 0.1712072649572649, 0.17387820512820518, 0.17307692307692313, 0.17240918803418803, 0.1700053418803419, 0.17267628205128205, 0.17200854700854706, 0.17040598290598286, 0.17548076923076927, 0.17067307692307687, 0.17134081196581197, 0.1734775641025641, 0.17227564102564108, 0.17294337606837606, 0.1744123931623932, 0.1734775641025641, 0.17267628205128205, 0.17067307692307687, 0.17294337606837606, 0.17334401709401714, 0.17401175213675213, 0.1680021367521367, 0.16947115384615385, 0.1737446581196581, 0.1728098290598291, 0.17321047008547008, 0.16826923076923073, 0.17053952991452992, 0.1693376068376068, 0.17321047008547008, 0.1702724358974359, 0.1700053418803419, 0.17454594017094016, 0.16947115384615385, 0.16920405982905984, 0.16693376068376065, 0.16987179487179482, 0.17174145299145294, 0.17134081196581197, 0.16599893162393164, 0.1684027777777778, 0.16813568376068377, 0.17107371794871795, 0.16893696581196582, 0.1737446581196581, 0.16947115384615385, 0.17240918803418803, 0.1693376068376068, 0.17040598290598286, 0.16720085470085466, 0.16907051282051277, 0.17294337606837606, 0.17227564102564108, 0.17134081196581197, 0.1728098290598291, 0.16733440170940173, 0.1677350427350427, 0.1680021367521367, 0.17240918803418803, 0.16853632478632474, 0.17067307692307687, 0.16947115384615385, 0.17240918803418803, 0.16853632478632474, 0.17107371794871795, 0.1684027777777778, 0.17214209401709402, 0.1700053418803419, 0.17107371794871795, 0.16693376068376065, 0.1700053418803419, 0.1654647435897436, 0.16786858974358976, 0.16559829059829057, 0.16987179487179482, 0.1651976495726496, 0.16826923076923073, 0.17013888888888884, 0.16920405982905984, 0.1680021367521367, 0.17267628205128205, 0.16973824786324787, 0.1702724358974359, 0.1693376068376068, 0.17200854700854706, 0.17107371794871795, 0.16987179487179482, 0.16399572649572647, 0.17147435897435892, 0.17267628205128205, 0.16947115384615385, 0.16973824786324787, 0.16920405982905984, 0.16720085470085466, 0.16826923076923073, 0.1663995726495726, 0.16973824786324787, 0.16853632478632474, 0.1684027777777778, 0.17080662393162394, 0.1700053418803419, 0.17174145299145294, 0.1696047008547008, 0.1686698717948718, 0.16693376068376065, 0.16493055555555558, 0.1663995726495726, 0.1693376068376068, 0.16746794871794868, 0.16813568376068377, 0.17040598290598286, 0.1680021367521367, 0.16506410256410253, 0.16733440170940173, 0.16987179487179482, 0.16493055555555558, 0.17040598290598286, 0.16880341880341876, 0.1684027777777778, 0.1651976495726496, 0.1686698717948718, 0.16626602564102566, 0.1700053418803419, 0.16760149572649574, 0.1700053418803419, 0.16599893162393164, 0.1700053418803419, 0.171875, 0.16880341880341876, 0.1661324786324786, 0.16813568376068377, 0.1663995726495726, 0.16693376068376065, 0.1677350427350427, 0.17240918803418803, 0.1693376068376068, 0.16760149572649574, 0.16559829059829057], "accuracy_train_std": [0.08903416888190946, 0.0868569101495396, 0.0799469201456499, 0.07901671756281921, 0.07359759872552361, 0.0741365564297649, 0.07197972988339012, 0.06992869340654928, 0.06973900338721788, 0.06599657668243301, 0.06469045712962788, 0.06405678729255278, 0.062098227993478985, 0.061621957213515384, 0.060173783127549244, 0.05800591278476933, 0.05759965384247302, 0.056256141671240135, 0.0571890324942653, 0.056176887887754184, 0.05367447945673242, 0.05292106897959181, 0.05201466301260559, 0.05236444155477352, 0.05103957170910041, 0.0494800893206549, 0.0501353990630999, 0.04883340373737907, 0.047764448877737786, 0.047941148486404114, 0.04671690493499035, 0.046270137330191655, 0.04643904933919527, 0.04531802109046379, 0.0426487344212402, 0.04345632684048551, 0.041726397964238014, 0.04077525041149005, 0.04192400812551832, 0.04031755365331529, 0.04139056578682628, 0.03981670808216695, 0.03853373356829479, 0.03891396836393156, 0.03656041646724052, 0.03826881359535211, 0.038243048893726796, 0.03713042364373575, 0.039157071963968, 0.03472297815174439, 0.03541627054456926, 0.03374463957959086, 0.03514752299910067, 0.03204885723131186, 0.03336618685016218, 0.03339799407188131, 0.03219084362118886, 0.032071310655984425, 0.03038460620527547, 0.03047409230857026, 0.0320559749420998, 0.03233261751934213, 0.028998440676812252, 0.03137872469487234, 0.03007176147224234, 0.027564927602455064, 0.02572280185867123, 0.028976510840861086, 0.027487800475711317, 0.028846271011080126, 0.028015525533838147, 0.028041001405271174, 0.027524469849723943, 0.026957581136281605, 0.02593991212720315, 0.025038701099412395, 0.02381799351036278, 0.02438593025067659, 0.02524669375633417, 0.025994598679872954, 0.025566221490099905, 0.02289655071169881, 0.02497524941702446, 0.025622429647680977, 0.020733152453433892, 0.026020137906257384, 0.02206373287532256, 0.021262592276750578, 0.02129162320184635, 0.02101061961998531, 0.021342238247113118, 0.02185072130887194, 0.01887604641677292, 0.02136711855996144, 0.02179093414409645, 0.019996607981900474, 0.020966718832362882, 0.01971808488571164, 0.019563770284343446, 0.018503206864939906, 0.020914294863128784, 0.019773386458753817, 0.018995474613371713, 0.019521608158633016, 0.018668812588757557, 0.022126286758607203, 0.018561770257040512, 0.020230411792705523, 0.020767856936969385, 0.01840153633131034, 0.018730228679870394, 0.016722213567664682, 0.019591983410144252, 0.019036009582813464, 0.01602743900965533, 0.01652582084615262, 0.0172001220289185, 0.01975310102807641, 0.01697958097118509, 0.01683442429177541, 0.018215713371039104, 0.01617162131499637, 0.016955839170417753, 0.016598789672473278, 0.015014579215657752, 0.016985189302402882, 0.01636333201238681, 0.015993683306655546, 0.01485363909129243, 0.014612192701573516, 0.016974052343586968, 0.016784566660668323, 0.014767947108580105, 0.015071414341612684, 0.01520235957450746, 0.017060477902921808, 0.01454123146262349, 0.014946566000988714, 0.01519195683744993, 0.016126084747979542, 0.0163712317781801, 0.014508006344125307, 0.014773664126507522, 0.01366778369200834, 0.01495573252160158, 0.014763690710712317, 0.013630480104834905, 0.01431850649251529, 0.014819993442616577, 0.012428174572017576, 0.013778847400703145, 0.013556095999049238, 0.015104005030477784, 0.014070397573019772, 0.012151345499814522, 0.012942801027298018, 0.012973397799147527, 0.013749881954751337, 0.012270045353859624, 0.014284220635348044, 0.01471387276330507, 0.013031592953085046, 0.012607945953000703, 0.013934677392511322, 0.013206254048675167, 0.015869303917073183, 0.014175651809018053, 0.01229421081354572, 0.012570360530173363, 0.013888046197984208, 0.013627371942493508, 0.015009839389534946, 0.011796247348091198, 0.011464129290440564, 0.014575862524694444, 0.013135285622337605, 0.013101326834704354, 0.011090063870888733, 0.011221896897300588, 0.01202012434898515, 0.012237803301667462, 0.013828249745409167, 0.011538754112580624, 0.013814487807949798, 0.011571986878156432, 0.012312596112165057, 0.012513848168997883, 0.0131770174825658, 0.015516587504719653, 0.01356203805968079, 0.011676596043845145, 0.012202277219230237, 0.010998486885480387, 0.014392259036363238, 0.010128554398297268, 0.012393797391769358, 0.012646076489267882, 0.012052213618346724, 0.01215207459877264, 0.010897125037661992, 0.010640433234854021, 0.010897531550106943, 0.012086737688827403, 0.011716174468694291, 0.01268262983699192, 0.012025743274404884, 0.009598105942416224, 0.011098124790047, 0.01166217058715746, 0.011920272849670916, 0.011309658102408686, 0.011858422245559276, 0.010947619790571362, 0.012876423456721115, 0.009659324236426693, 0.012549220280471935, 0.008927360718217836, 0.011521176617868086, 0.008927360718217836, 0.010658943685326026, 0.01016381045570624, 0.01236886399536828, 0.011433925061756332, 0.010593309957724718, 0.009869126003224135, 0.012329831290102825, 0.010410211779681891, 0.010897531550106941, 0.010045992831056658, 0.011021948593929291, 0.010731247326088551, 0.010675969850629031, 0.011014988222175844, 0.010908907748321676, 0.009823686087958432, 0.009780101813147996, 0.01345441195308009, 0.012087104192388561, 0.008246920293806264, 0.011322380927406938, 0.011433925061756332, 0.009565309492149955, 0.011543360171987701, 0.010418293789360013, 0.010134129298477242, 0.009257953167121085, 0.011619573100511933, 0.009688973975529907, 0.008693208365321241, 0.009793228561128018, 0.010528056010360524, 0.010473424433734028, 0.009420853682680879, 0.008725760644643806, 0.010047288072987888, 0.011101741565408937, 0.007785661869154711, 0.009610789882111354, 0.010276156488111905, 0.007732100027439834, 0.009884599695370434, 0.010447803669737986, 0.009378438152923677, 0.01043337760989969, 0.00921139200072062, 0.009402173197312406, 0.00836085014729008, 0.011991043592850277, 0.009582891945952098, 0.009346411318478118, 0.007490564344077742, 0.007744408080400053, 0.009959189290847228, 0.009382924399141738, 0.010045992831056658, 0.009720014559647761, 0.00814449276481132, 0.008234287404061777, 0.010461071837142025, 0.008608202194782874, 0.008411001270119001, 0.009658378299109094, 0.009424761598618946, 0.00836085014729008, 0.009579539889997608, 0.0102929819815215, 0.009855004725121507, 0.007797743357693691, 0.008234287404061777], "accuracy_test_std": 0.07505947065083957, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "rotation_range": [0, 0], "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.001, "patience_threshold": 1, "do_flip": true, "nb_data_augmentation": 1, "optimization": "adam", "batch_size": 32, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0, "valid_ratio": 0.15, "momentum": 0.9, "learning_rate_decay": 0.05}, "accuracy_valid_max": 0.8360042735042735, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256, 512],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8344017094017094, "loss_train": [1.6126577854156494, 1.2571439743041992, 1.0324985980987549, 0.9114992022514343, 0.8296631574630737, 0.7706141471862793, 0.721636950969696, 0.6812572479248047, 0.6461728811264038, 0.6210880279541016, 0.5912209749221802, 0.5701727867126465, 0.5499764084815979, 0.5304026007652283, 0.510892927646637, 0.4960562288761139, 0.4828525185585022, 0.4682720899581909, 0.45646148920059204, 0.44464391469955444, 0.43449893593788147, 0.42228588461875916, 0.41242289543151855, 0.4045051038265228, 0.3957337737083435, 0.38585516810417175, 0.3770763576030731, 0.37051886320114136, 0.36177852749824524, 0.35815465450286865, 0.3486885726451874, 0.34459033608436584, 0.33840125799179077, 0.33053863048553467, 0.3249552249908447, 0.31858107447624207, 0.3149486482143402, 0.30963245034217834, 0.3075641989707947, 0.3004675805568695, 0.2942318916320801, 0.2916291356086731, 0.28553256392478943, 0.28131067752838135, 0.27845972776412964, 0.27522748708724976, 0.2688840627670288, 0.2669588327407837, 0.2650364637374878, 0.2624067962169647, 0.25736600160598755, 0.2570807933807373, 0.24992993474006653, 0.2486265003681183, 0.24505004286766052, 0.24457067251205444, 0.23827362060546875, 0.2394123524427414, 0.23493556678295135, 0.233737513422966, 0.23145173490047455, 0.2265496402978897, 0.2243162840604782, 0.2282109260559082, 0.2229369729757309, 0.21901452541351318, 0.21754297614097595, 0.21566377580165863, 0.2164507806301117, 0.21225526928901672, 0.21177782118320465, 0.20994755625724792, 0.20848530530929565, 0.20425382256507874, 0.20470984280109406, 0.2024298757314682, 0.20039504766464233, 0.19877062737941742, 0.19676218926906586, 0.19190141558647156, 0.19606301188468933, 0.1929558962583542, 0.18974030017852783, 0.18835246562957764, 0.19015055894851685, 0.184671550989151, 0.18479034304618835, 0.18580646812915802, 0.18380974233150482, 0.18110139667987823, 0.18254373967647552, 0.17755447328090668, 0.177669957280159, 0.17519046366214752, 0.17459635436534882, 0.17210398614406586, 0.17153386771678925, 0.17362304031848907, 0.170912966132164, 0.16946730017662048, 0.16783584654331207, 0.16700416803359985, 0.16535331308841705, 0.16647250950336456, 0.16459544003009796, 0.1620483100414276, 0.16177615523338318, 0.1590793877840042, 0.159759059548378, 0.15788452327251434, 0.1542131006717682, 0.15911346673965454, 0.1565834879875183, 0.1559271365404129, 0.153368279337883, 0.15414954721927643, 0.15108339488506317, 0.1527990698814392, 0.15089744329452515, 0.15054121613502502, 0.1479942947626114, 0.15094731748104095, 0.14793933928012848, 0.1478888988494873, 0.1462836116552353, 0.14528711140155792, 0.1438450813293457, 0.14231619238853455, 0.14144371449947357, 0.1426386684179306, 0.14274995028972626, 0.13820762932300568, 0.13852031528949738, 0.13599643111228943, 0.13613903522491455, 0.1366981565952301, 0.1367325484752655, 0.13636402785778046, 0.13504286110401154, 0.13531138002872467, 0.1308763474225998, 0.136090487241745, 0.13113458454608917, 0.13089996576309204, 0.12987802922725677, 0.1288713663816452, 0.13219667971134186, 0.1277417540550232, 0.12826406955718994, 0.12775252759456635, 0.1291552633047104, 0.1271214485168457, 0.12339790910482407, 0.12421469390392303, 0.12636031210422516, 0.1239781528711319, 0.12193135172128677, 0.12263200432062149, 0.11975781619548798, 0.12169679999351501, 0.12413441389799118, 0.11944831162691116, 0.12022605538368225, 0.11864873766899109, 0.11930480599403381, 0.11573177576065063, 0.11973763257265091, 0.11878600716590881, 0.11571993678808212, 0.11657324433326721, 0.11382494121789932, 0.11485296487808228, 0.11580409109592438, 0.11325650662183762, 0.11385811865329742, 0.11453159898519516, 0.11291690170764923, 0.11196888983249664, 0.11051589250564575, 0.11246027052402496, 0.11254134029150009, 0.11126277595758438, 0.11141965538263321, 0.10933934152126312, 0.10618408769369125, 0.10849699378013611, 0.10848516970872879, 0.10908211022615433, 0.10730010271072388, 0.10762885957956314, 0.10647114366292953, 0.10589070618152618, 0.1058141365647316, 0.1039542630314827, 0.10534470528364182, 0.10482467710971832, 0.10305365920066833, 0.10405520349740982, 0.10223326832056046, 0.1038622260093689, 0.10353567451238632, 0.1034247875213623, 0.10130761563777924, 0.10164299607276917, 0.10180512815713882, 0.10185930877923965, 0.10183380544185638, 0.09914766252040863, 0.09993632137775421, 0.10010486841201782, 0.09865792095661163, 0.09787588566541672, 0.09814462065696716, 0.09765981137752533, 0.09780692309141159, 0.09678345918655396, 0.09518734365701675, 0.09762072563171387, 0.09826123714447021, 0.09616650640964508, 0.09289703518152237, 0.09406059235334396, 0.0939573422074318, 0.09333769977092743, 0.09193088859319687, 0.09424399584531784, 0.09406090527772903, 0.09457561373710632, 0.09224579483270645, 0.09338989853858948, 0.09078673273324966, 0.09177879244089127, 0.09249738603830338, 0.09248961508274078, 0.09089656174182892, 0.09226665645837784, 0.09066641330718994, 0.0881572887301445, 0.09099533408880234, 0.08903493732213974, 0.08985210955142975, 0.09005580097436905, 0.0871000811457634, 0.08961780369281769, 0.08371040225028992, 0.08736948668956757, 0.08756943047046661, 0.08357636630535126, 0.08713334053754807, 0.08607934415340424, 0.08530687540769577, 0.08502210676670074, 0.08633089065551758, 0.08385768532752991, 0.08768133074045181, 0.08677481859922409, 0.08372998982667923, 0.08383552730083466, 0.08258917182683945, 0.08280627429485321, 0.0829479992389679, 0.08306475728750229, 0.08449380099773407, 0.08049280941486359, 0.08262602239847183, 0.08210095018148422, 0.08408143371343613, 0.08143014460802078, 0.08131000399589539, 0.08103633671998978, 0.07942313700914383, 0.08146490901708603, 0.07930684834718704, 0.08018719404935837, 0.07942324876785278, 0.08013266324996948, 0.079487144947052, 0.07841392606496811, 0.076532743871212, 0.07877754420042038, 0.07556793838739395, 0.07596266269683838, 0.07696563005447388, 0.07786296308040619, 0.07661014050245285, 0.07630361616611481, 0.07599721848964691, 0.07817275822162628, 0.07953016459941864], "accuracy_train_first": 0.5327795557228916, "model": "residual", "loss_std": [0.2598153054714203, 0.19978676736354828, 0.1865181177854538, 0.1808602660894394, 0.17683690786361694, 0.1745614856481552, 0.1708761304616928, 0.16736182570457458, 0.16397878527641296, 0.160536527633667, 0.15913785994052887, 0.1557258814573288, 0.15209342539310455, 0.15108142793178558, 0.1486235111951828, 0.14744839072227478, 0.14629551768302917, 0.14224711060523987, 0.14209188520908356, 0.14184625446796417, 0.13898009061813354, 0.13559037446975708, 0.13284757733345032, 0.13366913795471191, 0.13011068105697632, 0.1279131919145584, 0.12642313539981842, 0.12716464698314667, 0.1255013793706894, 0.1232067197561264, 0.12293482571840286, 0.12086648494005203, 0.1160755529999733, 0.1162368431687355, 0.11602337658405304, 0.11471091210842133, 0.11228309571743011, 0.1118074432015419, 0.11135035753250122, 0.1106053963303566, 0.1101822629570961, 0.10832385718822479, 0.10717424005270004, 0.10543964803218842, 0.10736817866563797, 0.105109803378582, 0.10419416427612305, 0.101924367249012, 0.10177284479141235, 0.10217257589101791, 0.10100985318422318, 0.09888926148414612, 0.09925612807273865, 0.09699564427137375, 0.09714905917644501, 0.09744704514741898, 0.09603974223136902, 0.09984694421291351, 0.09352993220090866, 0.095351442694664, 0.0950523391366005, 0.09262870252132416, 0.0919928252696991, 0.09393525868654251, 0.09062115848064423, 0.09096118062734604, 0.09041356295347214, 0.08888079971075058, 0.08928079158067703, 0.08874408900737762, 0.08648337423801422, 0.09065194427967072, 0.08482690900564194, 0.08654435724020004, 0.08923041075468063, 0.08721502870321274, 0.08635126799345016, 0.08636672794818878, 0.0849534347653389, 0.08355399966239929, 0.08437146246433258, 0.08379994332790375, 0.08328629285097122, 0.08320188522338867, 0.08318261057138443, 0.08205139636993408, 0.08178967237472534, 0.08205846697092056, 0.08013174682855606, 0.08150632679462433, 0.08150313049554825, 0.07665472477674484, 0.08225211501121521, 0.07784213870763779, 0.07972823828458786, 0.07865344732999802, 0.07971319556236267, 0.0791696235537529, 0.07535453140735626, 0.0781622901558876, 0.07632999122142792, 0.0758945643901825, 0.07684925198554993, 0.07750684022903442, 0.07783833146095276, 0.07340890914201736, 0.07686381042003632, 0.07572413235902786, 0.07604531943798065, 0.07508061081171036, 0.07310494035482407, 0.07708358764648438, 0.07395213097333908, 0.07541662454605103, 0.07461005449295044, 0.07507830113172531, 0.07356204092502594, 0.07362408936023712, 0.0718458741903305, 0.0722963809967041, 0.07555089890956879, 0.07377367466688156, 0.07367696613073349, 0.07189223915338516, 0.07216598093509674, 0.06849648058414459, 0.07096179574728012, 0.07007576525211334, 0.06963001936674118, 0.07018303871154785, 0.07256826013326645, 0.06796016544103622, 0.06972134113311768, 0.06750642508268356, 0.06956908851861954, 0.06761886179447174, 0.06935128569602966, 0.06823728233575821, 0.06956008821725845, 0.06845121085643768, 0.06733083724975586, 0.06780289113521576, 0.06663927435874939, 0.06564787775278091, 0.06651311367750168, 0.06557813286781311, 0.0670945793390274, 0.06756246834993362, 0.065726637840271, 0.067313052713871, 0.06698913127183914, 0.0663285180926323, 0.06335875391960144, 0.06675548851490021, 0.06428870558738708, 0.0663219541311264, 0.06260044127702713, 0.06346450001001358, 0.062257058918476105, 0.06383970379829407, 0.06574844568967819, 0.06303846836090088, 0.06476376950740814, 0.064530149102211, 0.06424474716186523, 0.06111164018511772, 0.06257078051567078, 0.0637066587805748, 0.0630820021033287, 0.06478229910135269, 0.06231500953435898, 0.06241285428404808, 0.06390064209699631, 0.060238856822252274, 0.062682144343853, 0.06298769265413284, 0.06042398139834404, 0.05998356640338898, 0.06149415299296379, 0.06396694481372833, 0.060820452868938446, 0.06030232459306717, 0.06061897426843643, 0.06018928810954094, 0.05879592150449753, 0.06202007830142975, 0.06092224642634392, 0.0607265941798687, 0.05761292576789856, 0.06012493371963501, 0.06062695384025574, 0.05935582518577576, 0.05894346907734871, 0.05821329727768898, 0.05838388204574585, 0.06050616502761841, 0.05797276645898819, 0.058021046221256256, 0.05837777629494667, 0.056981410831213, 0.05942177399992943, 0.058763038367033005, 0.05718366801738739, 0.05909295007586479, 0.05742795392870903, 0.05616649240255356, 0.05894865468144417, 0.05574778839945793, 0.05607302486896515, 0.05798637494444847, 0.055682726204395294, 0.05693075433373451, 0.056106578558683395, 0.05629323050379753, 0.05774091184139252, 0.05469938740134239, 0.05612393468618393, 0.05716117098927498, 0.05759293958544731, 0.05770154297351837, 0.05281532183289528, 0.05768270790576935, 0.05425362288951874, 0.05547097325325012, 0.05571274086833, 0.05680185928940773, 0.056885384023189545, 0.05438747629523277, 0.0536675900220871, 0.05649898946285248, 0.05501393601298332, 0.05391031503677368, 0.05583330988883972, 0.05622675642371178, 0.056315839290618896, 0.054164040833711624, 0.054595280438661575, 0.05301279202103615, 0.05441759154200554, 0.054372936487197876, 0.05270889401435852, 0.05281127244234085, 0.05120020732283592, 0.0548512265086174, 0.05140933766961098, 0.05308730900287628, 0.054062798619270325, 0.049954842776060104, 0.05446894094347954, 0.053060807287693024, 0.055949389934539795, 0.05253458023071289, 0.05109171196818352, 0.05180716514587402, 0.054758865386247635, 0.05147199332714081, 0.0508405864238739, 0.05140592157840729, 0.05051695555448532, 0.050971999764442444, 0.0515575036406517, 0.05346331372857094, 0.0529235303401947, 0.04773349314928055, 0.052694689482450485, 0.05171649903059006, 0.05131809413433075, 0.05225318670272827, 0.05166468024253845, 0.05090833827853203, 0.04993133991956711, 0.05146487057209015, 0.05140771344304085, 0.05250048637390137, 0.050650447607040405, 0.05088415369391441, 0.05209990218281746, 0.04889947548508644, 0.05085060000419617, 0.04946375638246536, 0.04906266927719116, 0.04798257350921631, 0.04974145069718361, 0.04874711111187935, 0.05039181187748909, 0.049911268055438995, 0.04906259477138519, 0.048695869743824005, 0.052388064563274384]}, "state": "available", "life": [{"dt": "Sun May 15 22:04:58 2016", "state": "available"}], "summary": "b1352a1e3a365decdc4d0bf1a74fa0af"}