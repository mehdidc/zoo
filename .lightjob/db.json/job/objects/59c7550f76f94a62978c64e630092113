{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 32, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4502533674240112, 1.056708812713623, 0.8858185410499573, 0.7664673924446106, 0.6802890300750732, 0.6151654720306396, 0.5616163015365601, 0.5152179002761841, 0.4736515283584595, 0.4361371695995331, 0.40432092547416687, 0.36990493535995483, 0.3410593569278717, 0.31212782859802246, 0.29305219650268555, 0.269214004278183, 0.2409461885690689, 0.2241908758878708, 0.204146146774292, 0.19178831577301025, 0.18410064280033112, 0.16376353800296783, 0.15706168115139008, 0.14229531586170197, 0.134967640042305, 0.13028977811336517, 0.12515684962272644, 0.10999476164579391, 0.1124630719423294, 0.10663608461618423, 0.10239478200674057, 0.09333331882953644, 0.09379520267248154, 0.09178785234689713, 0.0860118418931961, 0.08575405925512314, 0.0743805468082428, 0.07758019864559174, 0.08075159788131714, 0.07193154096603394, 0.07078688591718674, 0.06810226291418076, 0.06942502409219742, 0.063753642141819, 0.056568462401628494, 0.06088143214583397, 0.06374804675579071, 0.05048934742808342, 0.06284546107053757, 0.05768923833966255, 0.051106229424476624, 0.06127498298883438, 0.04596326872706413, 0.055106014013290405, 0.05573634058237076, 0.050498079508543015, 0.04382322356104851, 0.05087888240814209, 0.052787333726882935, 0.044926274567842484, 0.04673882946372032, 0.04773526266217232, 0.047142066061496735, 0.05282137915492058, 0.031504563987255096, 0.055381108075380325, 0.036986276507377625, 0.04313214123249054, 0.04348494112491608, 0.04168542101979256, 0.03670497611165047, 0.04009635001420975, 0.04398247227072716, 0.03404678404331207, 0.04004329815506935, 0.03771290183067322, 0.035478029400110245, 0.03770818933844566, 0.03292257711291313, 0.04084457829594612, 0.035853009670972824, 0.0336114838719368, 0.041065629571676254, 0.038503795862197876, 0.02869057096540928, 0.04161669686436653, 0.02847723662853241, 0.03843162953853607, 0.03671449050307274, 0.030887873843312263, 0.033977165818214417, 0.03225964680314064, 0.0337958037853241, 0.03415956720709801, 0.03656718507409096, 0.02763722836971283, 0.03469263017177582, 0.022611606866121292, 0.044285185635089874, 0.02559053897857666, 0.027193468064069748, 0.034897852689027786, 0.03482759743928909, 0.027369271963834763, 0.03087932989001274, 0.025191539898514748, 0.03746940940618515, 0.028740232810378075, 0.03276311978697777, 0.026173297315835953, 0.030638236552476883, 0.02909904718399048, 0.030568040907382965, 0.029779305681586266, 0.023455921560525894, 0.029080383479595184, 0.030091390013694763, 0.029569324105978012, 0.02852645516395569, 0.026185080409049988, 0.03660789877176285, 0.025192631408572197, 0.022517437115311623, 0.028749875724315643, 0.03286708891391754, 0.02262023836374283, 0.032186999917030334, 0.023136025294661522, 0.02848152257502079, 0.03475143760442734, 0.023642705753445625, 0.02515687793493271, 0.028224898502230644, 0.031284015625715256, 0.027303962036967278, 0.02647516317665577, 0.024655301123857498, 0.02713601291179657, 0.027359576895833015, 0.027326615527272224, 0.02675822004675865, 0.024045957252383232, 0.028683511540293694, 0.028284350410103798, 0.027614926919341087, 0.026088714599609375, 0.023370297625660896, 0.02686351351439953, 0.032522208988666534, 0.01879969798028469, 0.02349710464477539, 0.0322268046438694, 0.020049937069416046, 0.029016833752393723, 0.03036865033209324, 0.022868763655424118, 0.02307230792939663, 0.02983112819492817, 0.031018216162919998, 0.01958244852721691, 0.026044854894280434, 0.02432418242096901, 0.024851690977811813, 0.02377358078956604, 0.024870343506336212, 0.0298518817871809, 0.02548920549452305, 0.021998267620801926, 0.028759751468896866, 0.02371286414563656, 0.025239305570721626, 0.028705012053251266, 0.019824642688035965, 0.02728675864636898, 0.023168982937932014, 0.02400306425988674, 0.03252696990966797, 0.024456631392240524, 0.013843098655343056, 0.03340527042746544, 0.02740384079515934, 0.017786821350455284, 0.022151438519358635, 0.03952699899673462, 0.017640715464949608, 0.022968465462327003, 0.03095461055636406, 0.020700983703136444, 0.024081138893961906, 0.029492540284991264, 0.022858191281557083, 0.021543830633163452, 0.033682893961668015, 0.020851245149970055, 0.0216989628970623, 0.02800273522734642, 0.024913685396313667, 0.023578105494379997, 0.02052021399140358, 0.03007950447499752, 0.023280292749404907, 0.015352142974734306, 0.04116128385066986, 0.02143578790128231, 0.017301585525274277, 0.036364492028951645, 0.02044598013162613, 0.019414275884628296, 0.027359699830412865, 0.029775938019156456, 0.02266128733754158, 0.02168990671634674, 0.027322955429553986, 0.02587699517607689, 0.022305559366941452, 0.019704723730683327, 0.035575635731220245, 0.023206979036331177, 0.020442841574549675, 0.023240279406309128, 0.03118039481341839, 0.025127625092864037, 0.021180570125579834, 0.025465548038482666, 0.024035988375544548, 0.023813482373952866, 0.025123149156570435, 0.02503775618970394, 0.024120474234223366, 0.019148139283061028, 0.03275449946522713, 0.021287715062499046, 0.025831684470176697, 0.027087202295660973, 0.01977144181728363], "moving_avg_accuracy_train": [0.054165657299741585, 0.11475435253437613, 0.17522803365229325, 0.23202985566773943, 0.2836997259172261, 0.33195101290006973, 0.3784436098785659, 0.4214328129364826, 0.4606926490004848, 0.4972096777627656, 0.5287077440511808, 0.5592203207154149, 0.5877883024001027, 0.6139856583104246, 0.6386814589141828, 0.6602707328790306, 0.6821185492817422, 0.7010864726965913, 0.7209149418675006, 0.7382631264713558, 0.7542809964100453, 0.7681372231752331, 0.7827090768601555, 0.7963026537337099, 0.8071280850830688, 0.8171178356083075, 0.8249137008858396, 0.8343520637187672, 0.8423560920160489, 0.8507802764133273, 0.8579157940435431, 0.8656813714832733, 0.8717008401742778, 0.8785157764307058, 0.8831706767603649, 0.8885248784641734, 0.892536869409515, 0.8988587126745897, 0.9040367307286055, 0.9096291874545637, 0.9142114277853347, 0.9172219861938168, 0.9220400742923199, 0.9246535264595719, 0.928995816595776, 0.9323039893255026, 0.934151610851378, 0.937718442660297, 0.9404077940038096, 0.9423261943630263, 0.9443921182660556, 0.9469837995561444, 0.9489396746589002, 0.949807285352617, 0.9506576010506979, 0.9529458936980275, 0.9544612001615581, 0.9548949885525636, 0.956378181996126, 0.9580083860429605, 0.9598732061803588, 0.960326226930217, 0.9612431171455562, 0.9627728384286474, 0.9638101158572389, 0.9638904440763323, 0.9656180651818036, 0.9654710594434313, 0.9668964237371833, 0.9675958194944635, 0.9688390428640924, 0.969688190586035, 0.9704686274798124, 0.970408407923507, 0.970531065827631, 0.9713760607698771, 0.9715205720274686, 0.9716969909402163, 0.970800510890353, 0.9718138738263269, 0.9731025745758463, 0.9730976138432985, 0.9735138929720731, 0.9737582998058182, 0.9745085440800352, 0.9756161695077644, 0.9762084925486822, 0.9748512733521842, 0.975799103865803, 0.9764172752494793, 0.9774665249935882, 0.9783155186620958, 0.9786984327542657, 0.9771992124312662, 0.9781493781667294, 0.9783859656476755, 0.9795150030114794, 0.980026615396055, 0.979345382427878, 0.9804342816850903, 0.979824033426142, 0.9800164243168703, 0.9806429440875643, 0.9801420379217018, 0.9808629531771507, 0.9800726539892344, 0.9803331527272157, 0.9805025695223697, 0.9808108656570652, 0.9798422326604802, 0.9798676820134797, 0.9804998835657308, 0.981289682002024, 0.9818819901030399, 0.9826313783308773, 0.9826104640466083, 0.9832613200967278, 0.9835076548644637, 0.9838153145637408, 0.9834552617145558, 0.9836542284371571, 0.9844680641124982, 0.9838147996274665, 0.9841010454456816, 0.9839239720011503, 0.9841783381938924, 0.9840400024019119, 0.9844153350855395, 0.9845508465543757, 0.9845658500310903, 0.9852699223565619, 0.9854990476054479, 0.985507586631817, 0.9855524741365017, 0.9858741798478515, 0.9854453882011985, 0.9856940971489359, 0.986515498445947, 0.9866037539954091, 0.9867878877839912, 0.9868721558877441, 0.9866805690192079, 0.9869592197065727, 0.9867940560300277, 0.9873823366984812, 0.9865260006096132, 0.9872874630486518, 0.9874543071080816, 0.987216166910378, 0.9880504467967212, 0.9870970727635053, 0.9875759246014497, 0.9881161732496473, 0.9870423303282909, 0.9871988464764327, 0.9878791455335698, 0.9867568897219071, 0.9869767911140114, 0.9872327950383245, 0.9874469225285397, 0.9872234716816474, 0.9880337696027683, 0.9881771362805959, 0.9886130498846791, 0.9889240279688395, 0.988801693549355, 0.9893937154146576, 0.9882408022065252, 0.9883239380942153, 0.9880850455479443, 0.9868609637217859, 0.9877470760174736, 0.9884422344871548, 0.9885191419908204, 0.9886069959834142, 0.9890953268160436, 0.9881722152653917, 0.9889667299364808, 0.989702683430928, 0.9885166203699965, 0.9888373135032626, 0.9896513128076982, 0.988244991569841, 0.9887742091902656, 0.9896921751760009, 0.9888978239893809, 0.9890756569178237, 0.9894915450201074, 0.9892031769014484, 0.989380737522027, 0.9898590514186338, 0.9899245576601223, 0.9899184091107952, 0.9904382869497157, 0.9906016185595152, 0.990546365110725, 0.9907291518877662, 0.9910866473382938, 0.990699186808045, 0.9902831151129825, 0.9910013984302649, 0.9915549195610757, 0.9913368706478345, 0.9916846753985272, 0.9920116505670078, 0.9918943768793547, 0.992314350240238, 0.9921135084067365, 0.9909213110244423, 0.9912199909339028, 0.9915422812750363, 0.9917695635641993, 0.9918253441494553, 0.9917871910214238, 0.9922992271276148, 0.9920811161708056, 0.9920057600965915, 0.9923750315571704, 0.9924028174264626, 0.9925068437195307, 0.9922447917130722, 0.9926785877644025, 0.9926783431617809, 0.9925317467908779, 0.9919579236367992, 0.9919832064219288, 0.9920803656904502, 0.9921260284511856, 0.9923670156358289, 0.9923258125841508, 0.992509655023364, 0.992737892236513, 0.9926666490688325, 0.9928140827107681, 0.9930188526016053], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.053087349397590355, 0.11285988681287648, 0.17142429581607677, 0.22547812588243593, 0.2746485338325959, 0.3208032564094267, 0.3650515852300804, 0.4053470373527802, 0.44191606102714076, 0.47514865367254416, 0.5029480825918108, 0.5297855338394069, 0.5541589665247433, 0.5759220984867268, 0.5951538838376024, 0.61219496547455, 0.6289408950848511, 0.6428972738557335, 0.6572962759976451, 0.669978734241254, 0.6813104388950654, 0.6904457847834202, 0.7004621767493553, 0.7101087536903836, 0.7175149646353512, 0.7244074876089397, 0.729812153710621, 0.7355623189400861, 0.7407680587610623, 0.745795021474941, 0.7503122284294801, 0.7547398075914267, 0.7576665880804014, 0.7618225984647559, 0.764217145847196, 0.7668268401009554, 0.768326220285137, 0.7716512895687467, 0.7735888996931973, 0.7761943004806547, 0.7788455135519416, 0.780724939982892, 0.7832912119861088, 0.7850790429712329, 0.7872771168838234, 0.7889837401916759, 0.7901331942033819, 0.7914269919234804, 0.7930482175711173, 0.793514433088102, 0.7947235131226653, 0.7962857003552031, 0.7971932396005563, 0.7966457788746875, 0.7961551232387247, 0.7978519697250932, 0.7988551116550688, 0.7988068204632065, 0.799073534642413, 0.7995709545686085, 0.8011438854671693, 0.8008820124513258, 0.8020846974072474, 0.8030003334647154, 0.8035314371664367, 0.8034661440710279, 0.8040767079865908, 0.8032629989725703, 0.8044137792710964, 0.8040109637969235, 0.8049220791548065, 0.8055111788918108, 0.8055876494815455, 0.8044438588839181, 0.8045374942210535, 0.8046797126547462, 0.8049227200696181, 0.804898462699328, 0.8038735954862475, 0.8042186872271558, 0.8052708101742444, 0.8052136557381453, 0.8056016698706561, 0.8055602575899158, 0.806161870196888, 0.8068802499599552, 0.8079256528159928, 0.8072256256556285, 0.8079048420810294, 0.8085029003239806, 0.8089892360916578, 0.8095785702008655, 0.8100713202967429, 0.808514754202686, 0.8086703147387427, 0.8086801599120823, 0.8093004016392475, 0.8090161869647807, 0.8078622209885586, 0.8086027896464798, 0.8080100652752054, 0.8074358742126697, 0.8078152160082702, 0.8076633419036782, 0.8088745761903434, 0.8076187309583572, 0.8080958274125968, 0.8084113799781895, 0.8085661004141055, 0.8073716938742009, 0.806977233212308, 0.8078918969392699, 0.8088514306546049, 0.8090424476983311, 0.809329373862233, 0.8095896664270639, 0.810595031721481, 0.8103238674518178, 0.8103045466422535, 0.8101611166391727, 0.8103179388984483, 0.8109411831298383, 0.8100229931395201, 0.8101274450492126, 0.8096415442472281, 0.8105297994610595, 0.8106313693549385, 0.8108550005858604, 0.8108538967057382, 0.8110288021217608, 0.8117855381087564, 0.8120727398984079, 0.8119783941841696, 0.8122139543798339, 0.8128826191828143, 0.8125566831304968, 0.8129998805930495, 0.8133315461011391, 0.8137938840079679, 0.8142405792385717, 0.8146761375138862, 0.8143864581563229, 0.8147360982970159, 0.8142889380155071, 0.814374775012149, 0.8133360409220787, 0.8138070478520847, 0.8141169727732015, 0.8138262927680953, 0.81462566297359, 0.8132384272955835, 0.8135737407218987, 0.814778990190748, 0.8141148736453178, 0.8137470433308613, 0.8141119439017661, 0.812806524172734, 0.813178997932042, 0.8132597886038228, 0.812811715899314, 0.8122232859791868, 0.8132989971967801, 0.8138622462440449, 0.8142115084889928, 0.8143365619887382, 0.8149120948900149, 0.8157371622270677, 0.8144807111587284, 0.8145076612213195, 0.8140028958992628, 0.8125476305469118, 0.8137719537591634, 0.8142583455443917, 0.8149281788175127, 0.8146224138348578, 0.8150400846784052, 0.8144038343525075, 0.8151536864688381, 0.8162019708716531, 0.8151950962148342, 0.8157396337977936, 0.8164931247666588, 0.8147135353227489, 0.8151872472083957, 0.8166898656727971, 0.8155203672926409, 0.8153833460942503, 0.8156872731094488, 0.815436934588037, 0.8153173751653779, 0.816044997353283, 0.81576491638678, 0.8155688782025448, 0.8162825276093234, 0.8164152052889031, 0.8156830644663381, 0.8161218881025356, 0.8162553341755652, 0.8158525923148611, 0.8158248620272756, 0.8164121682756021, 0.8164586397010539, 0.8160161536959334, 0.8164226979178311, 0.8169636041896774, 0.8167422649491735, 0.8169204480928104, 0.8165865016927913, 0.8153663045543857, 0.8158631301889321, 0.8165585319196623, 0.8168028869825906, 0.8171622314262743, 0.8176718354203186, 0.8188751079212084, 0.8187046999152321, 0.8191372702098535, 0.8198023447231302, 0.819264481297504, 0.8191151416014885, 0.8186633530625745, 0.8191519746934406, 0.81885931228622, 0.8189621270572215, 0.8191695241030054, 0.8193379444336687, 0.8192921512139464, 0.8194931659965428, 0.8196262806845391, 0.8190786681469587, 0.8187240651688592, 0.8184537506135697, 0.8182573836941556, 0.8186707090013213, 0.8189154839219723], "moving_var_accuracy_train": [0.026405265876417446, 0.05680364920089455, 0.08403687925236883, 0.1046712141856018, 0.1182320721914307, 0.12736254523179424, 0.13408034487285866, 0.137304954601566, 0.13744647169136032, 0.13570326502885147, 0.1310620921451509, 0.12633503894285267, 0.12104670124639728, 0.11511874423198629, 0.10909581291593291, 0.10238110237730294, 0.09643893587367199, 0.090033081354349, 0.08456828692586942, 0.07882009381472746, 0.07324723384960966, 0.06765046564616345, 0.06279646935988015, 0.05817989041384723, 0.053416611047559626, 0.04897310598281223, 0.04462277502335988, 0.04096224175771781, 0.03744259780279919, 0.03433703996735342, 0.031361576477278164, 0.02876815656630237, 0.026217446939569986, 0.024013692451225564, 0.02180733607981456, 0.019884609754798697, 0.018041013421428356, 0.016596603399699057, 0.015178249898438568, 0.013941905058680147, 0.012736686890852634, 0.011544589359145306, 0.010599056179555215, 0.009600621751674318, 0.008810258929149668, 0.00802772909752206, 0.007255679535495756, 0.0066446121843242315, 0.006045244461731485, 0.005473842355002521, 0.0049648704936602365, 0.004528834751478779, 0.004110380303089122, 0.0037061170076228764, 0.0033420126379382136, 0.003054937923302798, 0.0027701095140782762, 0.0024947921139839894, 0.0022651116677048287, 0.0020625185880431838, 0.0018875647165424814, 0.0017006552950864517, 0.0015381559545806717, 0.0014054007839580818, 0.0012745442057370627, 0.0011471478587684008, 0.001059295145048188, 0.0009535601267273985, 0.0008764890843837898, 0.0007932425657731247, 0.0007278287483169365, 0.000661535340168365, 0.0006008635418580496, 0.0005408098252268992, 0.00048686424735720616, 0.00044460397069327935, 0.0004003315251560875, 0.0003605784853354548, 0.00033175372512013506, 0.00030782049256817287, 0.0002919851899076624, 0.0002627868923967028, 0.00023806779797451276, 0.0002147986304804931, 0.0001983845656714024, 0.0001895876158976334, 0.00017378647357109024, 0.00017298622174006457, 0.00016377304370897977, 0.00015083496207444767, 0.00014565979109661654, 0.000137580924229448, 0.00012514244062434394, 0.00013285715075396124, 0.00012769677000220127, 0.00011543085572724495, 0.00011536029847430729, 0.00010617999371533655, 9.97386995561832e-05, 0.00010043614393178027, 9.374415597654711e-05, 8.47028686724097e-05, 7.9765325012802e-05, 7.404695539451224e-05, 7.131972910491113e-05, 6.980891145220965e-05, 6.34387566393975e-05, 5.735319942978012e-05, 5.2473298046815686e-05, 5.567021718079437e-05, 5.010902448882782e-05, 4.869523126396388e-05, 4.943974226730944e-05, 4.76532280193385e-05, 4.794214966159613e-05, 4.3151871361014864e-05, 4.264920660670817e-05, 3.893041330619667e-05, 3.588926239061077e-05, 3.346707863940633e-05, 3.0476660585789897e-05, 3.338995108533258e-05, 3.38917463634324e-05, 3.1240001743099106e-05, 2.8398196611612622e-05, 2.6140696390542387e-05, 2.3698857873574267e-05, 2.259684369680844e-05, 2.050242955080298e-05, 1.8454212534544387e-05, 2.1070251836545236e-05, 1.9435712069984712e-05, 1.7492797097728247e-05, 1.5761651380646765e-05, 1.5116937325017987e-05, 1.5260004078670652e-05, 1.4290708936964872e-05, 1.8933938859853285e-05, 1.7110646351965745e-05, 1.5704728985647276e-05, 1.4198166106873645e-05, 1.3108699249946268e-05, 1.249664517507215e-05, 1.1492492018013814e-05, 1.3457910120097176e-05, 1.8711922581967898e-05, 2.2059155738371835e-05, 2.0103772626037656e-05, 1.8603792147295053e-05, 2.3007619291376286e-05, 2.888715578713115e-05, 2.8062131952742657e-05, 2.7882736174382354e-05, 3.547271013466902e-05, 3.2145914862864276e-05, 3.309658464085239e-05, 4.112204913806204e-05, 3.744505382450022e-05, 3.429039052542381e-05, 3.1274006711474034e-05, 2.8595978569118847e-05, 3.164562520096369e-05, 2.866604871966934e-05, 2.7509629879726225e-05, 2.5629033211206048e-05, 2.3200821281801015e-05, 2.4035148154588173e-05, 3.359451312850515e-05, 3.029726599805274e-05, 2.7781166236221634e-05, 3.8488436466780925e-05, 4.170634782522452e-05, 4.1884920724427744e-05, 3.7749661529065455e-05, 3.4044160292291045e-05, 3.278594728193085e-05, 3.71765669682617e-05, 3.9140192334617994e-05, 4.010082101505689e-05, 4.8751449174106677e-05, 4.4801901028212416e-05, 4.628506473398659e-05, 5.945621307702443e-05, 5.6031233377232266e-05, 5.8012063998212647e-05, 5.788980186755309e-05, 5.238544263474488e-05, 4.8703564593860655e-05, 4.4581613681204675e-05, 4.040720227890678e-05, 3.8425539704200905e-05, 3.4621605342846256e-05, 3.1159785050491083e-05, 3.047626325204762e-05, 2.7668731859680325e-05, 2.4929335166141197e-05, 2.273710070227706e-05, 2.1613617606380464e-05, 2.0803386808247966e-05, 2.0281089026313e-05, 2.2896358438657694e-05, 2.3364193375077702e-05, 2.145568199466094e-05, 2.0398827096634783e-05, 1.9321159234197656e-05, 1.751282137111984e-05, 1.7348937848672278e-05, 1.597708104256308e-05, 2.7171384323448284e-05, 2.5257133085941677e-05, 2.366625935323925e-05, 2.1764548568620024e-05, 1.9616096974981495e-05, 1.7667588228090662e-05, 1.8260458171670388e-05, 1.686256385982494e-05, 1.5227414315131226e-05, 1.4931925588001068e-05, 1.3445681519991863e-05, 1.219850659483795e-05, 1.1596697222154122e-05, 1.2130638627286395e-05, 1.0917575303031738e-05, 1.0019232236386158e-05, 1.1980766122157476e-05, 1.0788442482956916e-05, 9.79455754579776e-06, 8.833867580679742e-06, 8.473154231072732e-06, 7.641118031173767e-06, 7.18118861015912e-06, 6.931899778337482e-06, 6.2843901009740434e-06, 5.8515811998459175e-06, 5.643799453602587e-06], "duration": 51912.230917, "accuracy_train": [0.541656572997416, 0.6600526096460871, 0.7194911637135475, 0.7432462538067552, 0.7487285581626061, 0.7662125957456626, 0.7968769826850315, 0.8083356404577334, 0.8140311735765043, 0.8258629366232927, 0.8121903406469176, 0.8338335106935216, 0.8449001375622923, 0.8497618615033223, 0.8609436643480066, 0.8545741985626615, 0.8787488969061462, 0.8717977834302326, 0.8993711644056847, 0.8943967879060539, 0.8984418258582503, 0.8928432640619232, 0.9138557600244556, 0.9186448455956996, 0.9045569672272978, 0.9070255903354559, 0.8950764883836286, 0.9192973292151162, 0.9143923466915835, 0.9265979359888336, 0.9221354527154854, 0.9355715684408453, 0.9258760583933187, 0.9398502027385567, 0.9250647797272978, 0.9367126937984496, 0.9286447879175894, 0.9557553020602622, 0.9506388932147471, 0.9599612979881875, 0.9554515907622739, 0.944317011870155, 0.9654028671788483, 0.9481745959648394, 0.9680764278216132, 0.9620775438930418, 0.9507802045842562, 0.9698199289405685, 0.9646119560954227, 0.9595917975959765, 0.9629854333933187, 0.9703089311669435, 0.9665425505837025, 0.9576157815960686, 0.9583104423334257, 0.9735405275239941, 0.9680989583333334, 0.9587990840716132, 0.9697269229881875, 0.9726802224644703, 0.9766565874169435, 0.9644034136789406, 0.9694951290836102, 0.9765403299764673, 0.9731456127145626, 0.9646133980481728, 0.9811666551310447, 0.9641480077980805, 0.9797247023809523, 0.9738903813099853, 0.980028053190753, 0.977330520083518, 0.9774925595238095, 0.9698664319167589, 0.9716349869647471, 0.9789810152500923, 0.9728211733457919, 0.9732847611549464, 0.9627321904415835, 0.9809341402500923, 0.9847008813215209, 0.9730529672503692, 0.9772604051310447, 0.9759579613095238, 0.9812607425479882, 0.9855847983573275, 0.9815393999169435, 0.9626363005837025, 0.9843295784883721, 0.9819808177025655, 0.9869097726905685, 0.9859564616786637, 0.9821446595837948, 0.963706229524271, 0.9867008697858989, 0.9805152529761905, 0.9896763392857143, 0.9846311268572352, 0.9732142857142857, 0.990234375, 0.9743317990956073, 0.9817479423334257, 0.9862816220238095, 0.9756338824289406, 0.9873511904761905, 0.9729599612979882, 0.9826776413690477, 0.982027320678756, 0.9835855308693245, 0.9711245356912146, 0.9800967261904762, 0.9861896975359912, 0.9883978679286637, 0.9872127630121816, 0.9893758723814139, 0.9824222354881875, 0.9891190245478036, 0.9857246677740864, 0.9865842518572352, 0.98021478607189, 0.9854449289405685, 0.9917925851905685, 0.9779354192621816, 0.9866772578096161, 0.9823303110003692, 0.9864676339285714, 0.9827949802740864, 0.9877933292381875, 0.9857704497739018, 0.9847008813215209, 0.9916065732858066, 0.9875611748454227, 0.98558443786914, 0.9859564616786637, 0.98876953125, 0.9815862633813216, 0.9879324776785714, 0.9939081101190477, 0.9873980539405685, 0.9884450918812293, 0.9876305688215209, 0.9849562872023809, 0.9894670758928571, 0.9853075829411223, 0.9926768627145626, 0.9788189758098007, 0.994140625, 0.9889559036429494, 0.9850729051310447, 0.9955589657738095, 0.9785167064645626, 0.9918855911429494, 0.9929784110834257, 0.9773777440360835, 0.9886074918097084, 0.9940018370478036, 0.9766565874169435, 0.9889559036429494, 0.9895368303571429, 0.9893740699404762, 0.9852124140596161, 0.9953264508928571, 0.9894674363810447, 0.9925362723214286, 0.9917228307262828, 0.9877006837739941, 0.9947219122023809, 0.9778645833333334, 0.9890721610834257, 0.9859350126315062, 0.9758442272863603, 0.9957220866786637, 0.9946986607142857, 0.9892113095238095, 0.9893976819167589, 0.9934903043097084, 0.9798642113095238, 0.9961173619762828, 0.9963262648809523, 0.9778420528216132, 0.9917235517026578, 0.9969773065476191, 0.9755881004291252, 0.9935371677740864, 0.9979538690476191, 0.9817486633098007, 0.9906761532738095, 0.9932345379406607, 0.986607863833518, 0.9909787831072352, 0.9941638764880952, 0.990514113833518, 0.9898630721668512, 0.9951171875, 0.9920716030477114, 0.9900490840716132, 0.992374232881137, 0.9943041063930418, 0.9872120420358066, 0.9865384698574198, 0.9974659482858066, 0.9965366097383721, 0.9893744304286637, 0.9948149181547619, 0.9949544270833334, 0.9908389136904762, 0.9960941104881875, 0.9903059319052234, 0.9801915345837948, 0.9939081101190477, 0.9944428943452381, 0.9938151041666666, 0.9923273694167589, 0.99144381286914, 0.9969075520833334, 0.9901181175595238, 0.9913275554286637, 0.9956984747023809, 0.9926528902500923, 0.9934430803571429, 0.9898863236549464, 0.996582752226375, 0.9926761417381875, 0.9912123794527501, 0.9867935152500923, 0.9922107514880952, 0.9929547991071429, 0.9925369932978036, 0.9945359002976191, 0.9919549851190477, 0.9941642369762828, 0.9947920271548542, 0.9920254605597084, 0.9941409854881875, 0.99486178161914], "end": "2016-02-02 21:23:44.312000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0], "moving_var_accuracy_valid": [0.02536439999455654, 0.05498276605665692, 0.08035259946803838, 0.09861368842482007, 0.11051188074420451, 0.11863301841508198, 0.12439094800436003, 0.12656536435987914, 0.1259444693563547, 0.12328966934613711, 0.11791597664565964, 0.11260661808629753, 0.10669253426546742, 0.10028598605407305, 0.09358614155870508, 0.08684111357304858, 0.08068083764236213, 0.07436577845369294, 0.06879518197246862, 0.06336326649912973, 0.05818260762246764, 0.05311543776071982, 0.04870684695678509, 0.04467367028121919, 0.0406999708981495, 0.037057535664807545, 0.03361467583936276, 0.030550787856921825, 0.027739606614982933, 0.025193079140625182, 0.022857417654593884, 0.02074810700425223, 0.0187503907001028, 0.017030803430926278, 0.015379327802334405, 0.013902689558983904, 0.012532653871515961, 0.011378893256031614, 0.010274792927377815, 0.009308406654009584, 0.00844082636535289, 0.0076285339222017965, 0.006924952297932067, 0.006261224124821187, 0.00567858547266597, 0.005136939993433525, 0.004635137194815414, 0.004186688688198662, 0.0037916751727837972, 0.003414463867679913, 0.0030861743516817377, 0.002799520777059098, 0.002526981346689894, 0.0022769806312382245, 0.00205144925469232, 0.001872217921207798, 0.001694052772672095, 0.001524668483757789, 0.001372841863462518, 0.0012377845163630528, 0.001136273069231574, 0.001023262959596259, 0.0009339547235654354, 0.0008481047557165122, 0.0007658329204226988, 0.0006892879970752014, 0.0006237142920225685, 0.0005673019640557959, 0.0005224904253094989, 0.0004717017255346472, 0.0004320027337395141, 0.0003919258068668093, 0.0003527858559399776, 0.00032928158272696825, 0.0002964323326415154, 0.0002669711341233023, 0.00024080549414411595, 0.00021673024050982489, 0.00020451039169886665, 0.00018513114731576866, 0.00017658069684630626, 0.00015895202682776795, 0.00014441181884824393, 0.00012998607175638456, 0.00012024490414055799, 0.00011286503908236287, 0.000111414339356831, 0.00010468324764837785, 9.836693745635084e-05, 9.174930666837358e-05, 8.47030783118361e-05, 7.935860271113328e-05, 7.360796635290376e-05, 8.805325176411912e-05, 7.946571831111144e-05, 7.152001882694308e-05, 6.783031514530129e-05, 6.177428546141222e-05, 6.758159418377392e-05, 6.57594121992541e-05, 6.234537060205337e-05, 5.907809192850987e-05, 5.4465384516663553e-05, 4.9226437757808036e-05, 5.750759045677011e-05, 6.595115663141422e-05, 6.140463020810462e-05, 5.61603279821636e-05, 5.075974090355754e-05, 5.852322965630204e-05, 5.4071299614701286e-05, 5.619365725401091e-05, 5.8860636086392226e-05, 5.330296007669829e-05, 4.8713603680811184e-05, 4.445201328648643e-05, 4.9103646334803326e-05, 4.4855052251600606e-05, 4.037290666958053e-05, 3.6520765494676215e-05, 3.3090027934247034e-05, 3.3276925488471786e-05, 3.753688866450877e-05, 3.388139161100372e-05, 3.2618148754226126e-05, 3.645730980289172e-05, 3.2904426812685837e-05, 3.006408247840971e-05, 2.7057685197530657e-05, 2.4627243818763817e-05, 2.7318363623015302e-05, 2.5328891072524837e-05, 2.2876111989428706e-05, 2.1087898242518753e-05, 2.300312198697106e-05, 2.1658918580077256e-05, 2.126084263938819e-05, 2.0124776458756543e-05, 2.0036105873698916e-05, 1.982832494772675e-05, 1.955289155370861e-05, 1.8352829570122445e-05, 1.7617780664964663e-05, 1.765557345469961e-05, 1.595632801916242e-05, 2.4071411806114166e-05, 2.366089837852575e-05, 2.215928965123666e-05, 2.0703814474430355e-05, 2.4384367555881045e-05, 3.9265736237302525e-05, 3.6351078458377055e-05, 4.5789607151992844e-05, 4.518010351002105e-05, 4.18797854211173e-05, 3.889017871882568e-05, 5.033824686745759e-05, 4.655305249306862e-05, 4.195649143758281e-05, 3.956776463055689e-05, 3.872723610560906e-05, 4.526890410795405e-05, 4.359725910036054e-05, 4.0335390232039065e-05, 3.6442596609022074e-05, 3.577948003218857e-05, 3.832815702501124e-05, 4.8703364906688956e-05, 4.3839565168883e-05, 4.1748700925153206e-05, 5.66340060444168e-05, 6.446131139249749e-05, 6.014437297188532e-05, 5.816802519871759e-05, 5.3192652700407334e-05, 4.944342783231265e-05, 4.8142415343926354e-05, 4.838867757682265e-05, 5.343991152180679e-05, 5.7220089540524346e-05, 5.416677119976878e-05, 5.385983184124496e-05, 7.697629595699897e-05, 7.129829291672638e-05, 8.448922387109385e-05, 8.834983963467665e-05, 7.968382895048455e-05, 7.25467907305431e-05, 6.585613603521234e-05, 5.9399172531610355e-05, 5.82241617134339e-05, 5.310775367226576e-05, 4.814285703214339e-05, 4.791223061108886e-05, 4.327943784990787e-05, 4.3775765721512584e-05, 4.1131284802531815e-05, 3.7178427011941765e-05, 3.492039336801822e-05, 3.143527475086257e-05, 3.139610493968828e-05, 2.8275930786171184e-05, 2.7210482490101182e-05, 2.59769380803162e-05, 2.601246062658965e-05, 2.385213409841219e-05, 2.1752663782657845e-05, 2.058107918716284e-05, 3.192290077760649e-05, 3.095213210012739e-05, 3.2209170994038735e-05, 2.9525638465643323e-05, 2.7735230481936174e-05, 2.729897351045519e-05, 3.759985856198842e-05, 3.410122270229682e-05, 3.23751539701665e-05, 3.311855554704198e-05, 3.2410373573975665e-05, 2.9370057319832005e-05, 2.8270067542894497e-05, 2.759182067195672e-05, 2.5603500166162277e-05, 2.313828804377085e-05, 2.1211581050792673e-05, 1.9345711615740088e-05, 1.7430013624918882e-05, 1.605067474782724e-05, 1.4605082954487748e-05, 1.5843490080876408e-05, 1.5390830521482028e-05, 1.4509377098546287e-05, 1.3405479092053687e-05, 1.3602471468741412e-05, 1.2781457177884615e-05], "accuracy_test": 0.11716757015306123, "start": "2016-02-02 06:58:32.081000", "learning_rate_per_epoch": [0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537, 0.0025234436616301537], "accuracy_train_first": 0.541656572997416, "accuracy_train_last": 0.99486178161914, "batch_size_eval": 1024, "accuracy_train_std": [0.01688630458366988, 0.014294376654316439, 0.017715749232553334, 0.01982411179410576, 0.02087500421225022, 0.020493220241943284, 0.02117124959219201, 0.022567716651381377, 0.02399960716822046, 0.024522162078174523, 0.026538063525919052, 0.027774118853151467, 0.02730967468009205, 0.02406598142023468, 0.024887971925870694, 0.023710269159017645, 0.02521099092114546, 0.024046635338924368, 0.02353016746968592, 0.023757914295597305, 0.022905296327658472, 0.019648796560560844, 0.020729820378122796, 0.019336329644288323, 0.02344117648282156, 0.017740327020550627, 0.01872951715308185, 0.018109841690538853, 0.019417601505966588, 0.018498631200468584, 0.019531145699836557, 0.018639039878709025, 0.017274422228148324, 0.014257338046698462, 0.01744832637005664, 0.015176462859257804, 0.016492651881573585, 0.012793538298885942, 0.014995195952104322, 0.014385040075948704, 0.01348674755835552, 0.012157449444133635, 0.011686760117296788, 0.014470988822677054, 0.010647449427337401, 0.012878213368258064, 0.012969203068232332, 0.011120767785364694, 0.011095321869279442, 0.011354848554928226, 0.011811342906406059, 0.010535578382624942, 0.010754208232680808, 0.010480298833182761, 0.011970113626379312, 0.008836795102464864, 0.010547362982905593, 0.011216656485305109, 0.009950924593211098, 0.010202807263955102, 0.007926883537242765, 0.01072308050052029, 0.010496255697087528, 0.008212993936910232, 0.008098633448703695, 0.009461091652631554, 0.007059977390542984, 0.009181664955282547, 0.008507630211423431, 0.0076787045344241505, 0.007357086596053817, 0.008039202796834066, 0.0073850474446076324, 0.008508189125893812, 0.008312212765014832, 0.007652581398365938, 0.007414019667557243, 0.008636726885275578, 0.008356178993995097, 0.006580410689245304, 0.005831712784279516, 0.006297472938546718, 0.006887612412627797, 0.0073881214677204475, 0.005955216425266988, 0.005856055667783612, 0.006426439894877403, 0.009853441902662281, 0.006479257541157729, 0.006476559281848828, 0.004713568286078939, 0.005646815914219229, 0.00575351952832152, 0.009210470187733629, 0.004911796025959536, 0.006523026690885036, 0.004789580799696329, 0.005030651756978501, 0.00793404010975469, 0.0048828125, 0.006415869422958089, 0.006204739053982209, 0.005621861711450195, 0.00677255093734592, 0.004444380692697309, 0.007285241922244623, 0.007354567344006946, 0.005222149581182277, 0.005099996539430814, 0.005962455311289919, 0.006592278700397824, 0.004736226114708133, 0.005388422783088216, 0.004440231285005329, 0.0045320116473368905, 0.005635157619925417, 0.004218120127261739, 0.005058027795074952, 0.0048699683519503436, 0.0054782829119988516, 0.005176306421656442, 0.0033705316514039763, 0.005928077396388343, 0.004760379356537924, 0.0050133112975907675, 0.00524412559408831, 0.004436922777442777, 0.004666005619847715, 0.0053587684964388795, 0.0049606824149833134, 0.00327487936353397, 0.0045771662607613835, 0.004278060876840802, 0.005216223203853562, 0.004384185076140666, 0.004971509401723508, 0.0045696716906235, 0.003415041288641584, 0.005011233051307509, 0.004531587937795477, 0.004366447542242717, 0.004892380524245992, 0.004211344544677338, 0.0038540022427124786, 0.0028136173297799096, 0.006271973776702522, 0.0030137373039471078, 0.003984706355625431, 0.005903740657805792, 0.002122518302581184, 0.005958308961235997, 0.003990136033742954, 0.0028296945943647542, 0.006168447810411848, 0.004175439565620618, 0.0025361843291833207, 0.00616028605351049, 0.003950367877102794, 0.00386114746180191, 0.003895786656890352, 0.005385976535992286, 0.002260661727740855, 0.004360410507013287, 0.0034283922996351276, 0.0028617702549113954, 0.003948608415178659, 0.002729550409682731, 0.0059503824421231356, 0.0039374030977960715, 0.004374008825421485, 0.0054465773046992235, 0.0028028519445854948, 0.0030670819285418807, 0.0042189759475638276, 0.0038753712673393697, 0.002537182218766057, 0.006606041985520745, 0.0021682038828333386, 0.0024279720018985512, 0.0063541565924567275, 0.002647584283299006, 0.0025287529993159455, 0.0065551852887128685, 0.002786543866341237, 0.0014734913986007125, 0.0045659831182359775, 0.0036738086989692954, 0.0032632258142782887, 0.004617943493791361, 0.003963504900637529, 0.002708074775941809, 0.0033045692803787903, 0.0036611060706176657, 0.002737362844635684, 0.0030682256000362823, 0.0038443200284684533, 0.0031990838466602013, 0.002324429601206238, 0.004673633521288626, 0.004951612103981072, 0.0016653301188356145, 0.0020560820788146643, 0.003994425360078903, 0.002790662935388722, 0.0024844299352984613, 0.004115447710163242, 0.002334733605216023, 0.0031202753091329016, 0.0053407217130648586, 0.0028336305313582818, 0.002886651411442771, 0.002880182769196805, 0.0036518634838755056, 0.003805638334022737, 0.001819716778564282, 0.003907426237483816, 0.0032759004245195844, 0.0021633882257127224, 0.002916667598433812, 0.0031914732025248305, 0.0038122229409140733, 0.002317199149018901, 0.0030237818415492328, 0.003462939518878324, 0.0052693750036954335, 0.0037124552379127714, 0.0029492750633786616, 0.0033146647977346836, 0.002420947798897934, 0.0029590658984250434, 0.002632063127307296, 0.0022924069970972935, 0.0033697729719459157, 0.0026791949437052864, 0.002721641846628172], "accuracy_test_std": 0.007422850021377278, "error_valid": [0.46912650602409633, 0.34918727644954817, 0.3014960231551205, 0.28803740352033136, 0.2828177946159638, 0.26380424039909633, 0.2367134553840362, 0.23199389354292166, 0.22896272590361444, 0.22575801251882532, 0.24685705713478923, 0.22867740493222888, 0.22648013930722888, 0.22820971385542166, 0.2317600480045181, 0.23443529979292166, 0.22034573842243976, 0.23149531720632532, 0.21311270472515065, 0.2158791415662651, 0.21670421922063254, 0.22733610222138556, 0.20939029555722888, 0.20307205384036142, 0.21582913685993976, 0.2135598056287651, 0.22154585137424698, 0.21268619399472888, 0.21238028285015065, 0.20896231410015065, 0.20903290897966864, 0.2054119799510542, 0.21599238751882532, 0.2007733080760542, 0.21423192771084332, 0.20968591161521077, 0.21817935805722888, 0.1984230868787651, 0.20897260918674698, 0.20035709243222888, 0.19729356880647586, 0.2023602221385542, 0.19361233998493976, 0.19883047816265065, 0.19294021790286142, 0.19565665003765065, 0.1995217196912651, 0.19692882859563254, 0.19236075160015065, 0.2022896272590362, 0.1943947665662651, 0.18965461455195776, 0.1946389071912651, 0.20828136765813254, 0.20826077748493976, 0.1868764118975903, 0.19211661097515065, 0.2016278002635542, 0.19852603774472888, 0.19595226609563254, 0.1846997364457832, 0.2014748446912651, 0.18709113798945776, 0.1887589420180723, 0.1916886295180723, 0.19712149378765065, 0.19042821677334332, 0.20406038215361444, 0.18522919804216864, 0.19961437547063254, 0.18687788262424698, 0.18918692347515065, 0.19372411521084332, 0.20585025649472888, 0.19461978774472888, 0.1940403214420181, 0.1928902131965362, 0.1953198536332832, 0.20535020943147586, 0.19267548710466864, 0.18526008330195776, 0.19530073418674698, 0.19090620293674698, 0.19481245293674698, 0.18842361634036142, 0.18665433217243976, 0.18266572147966864, 0.19907461878765065, 0.18598221009036142, 0.18611457548945776, 0.18663374199924698, 0.1851174228162651, 0.18549392884036142, 0.20549434064382532, 0.18992964043674698, 0.19123123352786142, 0.1851174228162651, 0.19354174510542166, 0.20252347279743976, 0.18473209243222888, 0.1973244540662651, 0.19773184535015065, 0.18877070783132532, 0.19370352503765065, 0.18022431522966864, 0.2036838761295181, 0.18761030449924698, 0.18874864693147586, 0.19004141566265065, 0.20337796498493976, 0.19657291274472888, 0.1838761295180723, 0.18251276590737953, 0.18923839890813254, 0.18808829066265065, 0.18806770048945776, 0.1803566806287651, 0.19211661097515065, 0.18986934064382532, 0.1911297533885542, 0.1882706607680723, 0.18344961878765065, 0.19824071677334332, 0.1889324877635542, 0.19473156297063254, 0.18147590361445776, 0.18845450160015065, 0.18713231833584332, 0.18915603821536142, 0.1873970491340362, 0.1814038380082832, 0.18534244399472888, 0.18887071724397586, 0.18566600385918675, 0.18109939759036142, 0.19037674134036142, 0.18301134224397586, 0.1836834643260542, 0.1820450748305723, 0.18173916368599397, 0.1814038380082832, 0.18822065606174698, 0.18211714043674698, 0.1897355045180723, 0.1848526920180723, 0.1960125658885542, 0.18195388977786142, 0.18309370293674698, 0.18878982727786142, 0.17818000517695776, 0.19924669380647586, 0.1834084384412651, 0.1743737645896084, 0.1918621752635542, 0.18956342949924698, 0.1826039509600903, 0.1989422533885542, 0.18346873823418675, 0.18601309535015065, 0.1912209384412651, 0.19307258330195776, 0.17701960184487953, 0.1810685123305723, 0.18264513130647586, 0.1845379565135542, 0.17990810899849397, 0.17683723173945776, 0.19682734845632532, 0.18524978821536142, 0.19053999199924698, 0.20054975762424698, 0.1752091373305723, 0.1813641283885542, 0.17904332172439763, 0.1881294710090362, 0.18120087772966864, 0.1913224185805723, 0.17809764448418675, 0.17436346950301207, 0.1938667756965362, 0.1793595279555723, 0.1767254565135542, 0.20130276967243976, 0.1805493458207832, 0.1697865681475903, 0.1950051181287651, 0.1858498446912651, 0.1815773837537651, 0.18681611210466864, 0.1857586596385542, 0.1774064029555723, 0.18675581231174698, 0.1861954654555723, 0.17729462772966864, 0.18239069559487953, 0.19090620293674698, 0.17992869917168675, 0.18254365116716864, 0.18777208443147586, 0.18442471056099397, 0.17830207548945776, 0.18312311746987953, 0.18796622035015065, 0.1799184040850903, 0.17816823936370485, 0.18524978821536142, 0.18147590361445776, 0.18641901590737953, 0.1956154696912651, 0.17966543910015065, 0.1771828525037651, 0.1809979174510542, 0.1796036685805723, 0.1777417286332832, 0.1702954395707832, 0.1828289721385542, 0.1769695971385542, 0.17421198465737953, 0.18557628953313254, 0.18222891566265065, 0.18540274378765065, 0.1764504306287651, 0.1837746493787651, 0.1801125400037651, 0.17896390248493976, 0.17914627259036142, 0.1811199877635542, 0.1786977009600903, 0.17917568712349397, 0.1858498446912651, 0.1844673616340362, 0.1839790803840362, 0.1835099185805723, 0.17760936323418675, 0.17888154179216864], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.04071680265150693, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.0025234437322686214, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.8036443804070056e-08, "rotation_range": [0, 0], "momentum": 0.9405357943556433}, "accuracy_valid_max": 0.8302134318524097, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8211184582078314, "accuracy_valid_std": [0.01488145390569015, 0.012429978135875375, 0.010237085414320092, 0.012449901818821628, 0.00668355867106858, 0.010329224391867124, 0.012489188736944944, 0.009198106409458113, 0.014267883675521486, 0.010086153661677644, 0.012147093123305575, 0.013917876369286448, 0.01295739799008644, 0.015500229864640948, 0.011855149811040099, 0.012183814128400403, 0.014670212803331752, 0.016000764966170762, 0.010616194321560038, 0.017672686256092987, 0.014500710226871567, 0.02098298189212627, 0.010293264414903058, 0.011397129173395725, 0.010007676223078063, 0.014867047208683384, 0.013684858487233949, 0.01196146094769518, 0.008182573162467613, 0.0072620245427551956, 0.013113875652244403, 0.006080378705378522, 0.011716562809848109, 0.012523329887030055, 0.011959821847894616, 0.0194432733434456, 0.01525020632306483, 0.014452078185802124, 0.009080079140715215, 0.011636070694994232, 0.009062911106550092, 0.008680589050453779, 0.016064892080309368, 0.013830151701220797, 0.011578081765480475, 0.014440831601552072, 0.008005481190709485, 0.014052988222145202, 0.01416118937181974, 0.010822321091671118, 0.014373921386847273, 0.011863813553688091, 0.013212615057620818, 0.010327230621758922, 0.013683944313238558, 0.009383191809060179, 0.017852857560916834, 0.011483468016683094, 0.01630320864692018, 0.012290333815929151, 0.009973263686703338, 0.00956632025548417, 0.009797542098712536, 0.009655480789585943, 0.008142565468241119, 0.013393878189194162, 0.012786173004183103, 0.015326452015047624, 0.01160568511445293, 0.013590154710830252, 0.012114572411061853, 0.010441519476352898, 0.010308276028449716, 0.010350913503547844, 0.01671694601351672, 0.01707596765811851, 0.01389945527804768, 0.013310460657239774, 0.009396925395168123, 0.010354783751916069, 0.011938214954587122, 0.012143014717084984, 0.012714342715901288, 0.011277222049055556, 0.011578663233415365, 0.016749340229166243, 0.00889751156593761, 0.006867302012846138, 0.010953476092768177, 0.012911965237413435, 0.011749674103550767, 0.01196201220694942, 0.012487118912109308, 0.013962526996059276, 0.011667079438724807, 0.014092609881606339, 0.01131677363720811, 0.017569629352887875, 0.011799819428964709, 0.02244557147082334, 0.012573955682147243, 0.013470870864198597, 0.019089962205687178, 0.014996743776978926, 0.010090294387387384, 0.015335165786102938, 0.010382613452198, 0.0121016729242748, 0.014465252760129556, 0.0131631991244856, 0.015421294872775586, 0.008984827916924058, 0.011581731686157526, 0.0158524432503199, 0.01444577879057394, 0.01237162780148002, 0.009807633642833562, 0.009775721612818302, 0.017154195539866923, 0.011262306570893487, 0.009804421191294151, 0.013128421214333887, 0.013591484603859493, 0.010848827519236633, 0.0147446425227008, 0.014034241876239884, 0.01377956879455951, 0.018384341818587675, 0.010350946625339435, 0.01757565958799769, 0.010074538037061197, 0.02009806772198157, 0.00814737542115278, 0.011141306393887232, 0.01163768151198633, 0.009949186574886491, 0.01068421686304405, 0.013261758702675566, 0.007264879823861144, 0.011773609841356301, 0.007253999444745813, 0.01709342248100848, 0.012325215884407114, 0.00846734620887151, 0.011893241149056237, 0.005763558411338399, 0.00996351293216081, 0.013267034453505766, 0.014430436519307147, 0.01488651875047076, 0.01414370527430687, 0.015600224694765567, 0.010181729111870411, 0.018576855231282174, 0.012499743751909464, 0.01379230419190191, 0.012305502349529002, 0.01105479231922312, 0.012694824434952413, 0.011079786986120154, 0.008120331254899969, 0.0073847603403681015, 0.014182719076197921, 0.006383959228378667, 0.010857693904012401, 0.01038509616750432, 0.013214754901152833, 0.015605049115440474, 0.01175583712926714, 0.01349132241518148, 0.014376690541789819, 0.01358055575914428, 0.01284795021900677, 0.009158965339262054, 0.017544313020048864, 0.01055909132635309, 0.00980087730706189, 0.008882784668740283, 0.013801461940954798, 0.018683770098399666, 0.014001250336868838, 0.01740326432500605, 0.013016037517617636, 0.009831887230668013, 0.010729828219228469, 0.011992448279868879, 0.005557627535798027, 0.01173243768682375, 0.008039685398434717, 0.012319267210691072, 0.010321772906315363, 0.01279230267866146, 0.013558381291786659, 0.012393418926882121, 0.008842338906462993, 0.012477742032108738, 0.010717795358921367, 0.012094523142233414, 0.014122109965359139, 0.008922806265483313, 0.014789960421087487, 0.0126678774526182, 0.013551977319190304, 0.011863570697997119, 0.011451174745018458, 0.011886931821886429, 0.011452354221240886, 0.0072264137436387245, 0.008282538682054294, 0.014039876119114551, 0.014656695384587031, 0.015289060823433452, 0.011374460286197104, 0.011147176590437135, 0.01459609094110984, 0.013747962600664607, 0.0160254490600469, 0.012670293587280885, 0.019175110120855657, 0.013524467114537957, 0.01255626007482769, 0.014561726272574717, 0.006735131503681942, 0.013359371713972631, 0.01944900586174478, 0.01440380642421002, 0.01269096193393622, 0.012605213627368883, 0.009062347949295748, 0.009219991392767952, 0.015364236159182944, 0.01617740465411775, 0.014112925554469816, 0.014306180183203357, 0.016794484703366412], "accuracy_valid": [0.5308734939759037, 0.6508127235504518, 0.6985039768448795, 0.7119625964796686, 0.7171822053840362, 0.7361957596009037, 0.7632865446159638, 0.7680061064570783, 0.7710372740963856, 0.7742419874811747, 0.7531429428652108, 0.7713225950677711, 0.7735198606927711, 0.7717902861445783, 0.7682399519954819, 0.7655647002070783, 0.7796542615775602, 0.7685046827936747, 0.7868872952748494, 0.7841208584337349, 0.7832957807793675, 0.7726638977786144, 0.7906097044427711, 0.7969279461596386, 0.7841708631400602, 0.7864401943712349, 0.778454148625753, 0.7873138060052711, 0.7876197171498494, 0.7910376858998494, 0.7909670910203314, 0.7945880200489458, 0.7840076124811747, 0.7992266919239458, 0.7857680722891567, 0.7903140883847892, 0.7818206419427711, 0.8015769131212349, 0.791027390813253, 0.7996429075677711, 0.8027064311935241, 0.7976397778614458, 0.8063876600150602, 0.8011695218373494, 0.8070597820971386, 0.8043433499623494, 0.8004782803087349, 0.8030711714043675, 0.8076392483998494, 0.7977103727409638, 0.8056052334337349, 0.8103453854480422, 0.8053610928087349, 0.7917186323418675, 0.7917392225150602, 0.8131235881024097, 0.8078833890248494, 0.7983721997364458, 0.8014739622552711, 0.8040477339043675, 0.8153002635542168, 0.7985251553087349, 0.8129088620105422, 0.8112410579819277, 0.8083113704819277, 0.8028785062123494, 0.8095717832266567, 0.7959396178463856, 0.8147708019578314, 0.8003856245293675, 0.813122117375753, 0.8108130765248494, 0.8062758847891567, 0.7941497435052711, 0.8053802122552711, 0.8059596785579819, 0.8071097868034638, 0.8046801463667168, 0.7946497905685241, 0.8073245128953314, 0.8147399166980422, 0.804699265813253, 0.809093797063253, 0.805187547063253, 0.8115763836596386, 0.8133456678275602, 0.8173342785203314, 0.8009253812123494, 0.8140177899096386, 0.8138854245105422, 0.813366258000753, 0.8148825771837349, 0.8145060711596386, 0.7945056593561747, 0.810070359563253, 0.8087687664721386, 0.8148825771837349, 0.8064582548945783, 0.7974765272025602, 0.8152679075677711, 0.8026755459337349, 0.8022681546498494, 0.8112292921686747, 0.8062964749623494, 0.8197756847703314, 0.7963161238704819, 0.812389695500753, 0.8112513530685241, 0.8099585843373494, 0.7966220350150602, 0.8034270872552711, 0.8161238704819277, 0.8174872340926205, 0.8107616010918675, 0.8119117093373494, 0.8119322995105422, 0.8196433193712349, 0.8078833890248494, 0.8101306593561747, 0.8088702466114458, 0.8117293392319277, 0.8165503812123494, 0.8017592832266567, 0.8110675122364458, 0.8052684370293675, 0.8185240963855422, 0.8115454983998494, 0.8128676816641567, 0.8108439617846386, 0.8126029508659638, 0.8185961619917168, 0.8146575560052711, 0.8111292827560241, 0.8143339961408133, 0.8189006024096386, 0.8096232586596386, 0.8169886577560241, 0.8163165356739458, 0.8179549251694277, 0.818260836314006, 0.8185961619917168, 0.811779343938253, 0.817882859563253, 0.8102644954819277, 0.8151473079819277, 0.8039874341114458, 0.8180461102221386, 0.816906297063253, 0.8112101727221386, 0.8218199948230422, 0.8007533061935241, 0.8165915615587349, 0.8256262354103916, 0.8081378247364458, 0.810436570500753, 0.8173960490399097, 0.8010577466114458, 0.8165312617658133, 0.8139869046498494, 0.8087790615587349, 0.8069274166980422, 0.8229803981551205, 0.8189314876694277, 0.8173548686935241, 0.8154620434864458, 0.820091891001506, 0.8231627682605422, 0.8031726515436747, 0.8147502117846386, 0.809460008000753, 0.799450242375753, 0.8247908626694277, 0.8186358716114458, 0.8209566782756024, 0.8118705289909638, 0.8187991222703314, 0.8086775814194277, 0.8219023555158133, 0.8256365304969879, 0.8061332243034638, 0.8206404720444277, 0.8232745434864458, 0.7986972303275602, 0.8194506541792168, 0.8302134318524097, 0.8049948818712349, 0.8141501553087349, 0.8184226162462349, 0.8131838878953314, 0.8142413403614458, 0.8225935970444277, 0.813244187688253, 0.8138045345444277, 0.8227053722703314, 0.8176093044051205, 0.809093797063253, 0.8200713008283133, 0.8174563488328314, 0.8122279155685241, 0.815575289439006, 0.8216979245105422, 0.8168768825301205, 0.8120337796498494, 0.8200815959149097, 0.8218317606362951, 0.8147502117846386, 0.8185240963855422, 0.8135809840926205, 0.8043845303087349, 0.8203345608998494, 0.8228171474962349, 0.8190020825489458, 0.8203963314194277, 0.8222582713667168, 0.8297045604292168, 0.8171710278614458, 0.8230304028614458, 0.8257880153426205, 0.8144237104668675, 0.8177710843373494, 0.8145972562123494, 0.8235495693712349, 0.8162253506212349, 0.8198874599962349, 0.8210360975150602, 0.8208537274096386, 0.8188800122364458, 0.8213022990399097, 0.820824312876506, 0.8141501553087349, 0.8155326383659638, 0.8160209196159638, 0.8164900814194277, 0.8223906367658133, 0.8211184582078314], "seed": 228773146, "model": "residualv3", "loss_std": [0.2891979217529297, 0.13929195702075958, 0.13480353355407715, 0.12902531027793884, 0.12680965662002563, 0.12426149845123291, 0.12018444389104843, 0.11454606056213379, 0.11072510480880737, 0.1037381961941719, 0.10089149326086044, 0.09777944535017014, 0.09269566833972931, 0.08747705817222595, 0.08971305936574936, 0.08329640328884125, 0.0806797444820404, 0.0758584663271904, 0.07412464171648026, 0.06909477710723877, 0.07221121340990067, 0.06641528755426407, 0.06472345441579819, 0.06364463269710541, 0.06200886145234108, 0.060844212770462036, 0.060271456837654114, 0.054880980402231216, 0.0602220818400383, 0.054004255682229996, 0.05539078637957573, 0.050942085683345795, 0.05101301521062851, 0.05312909185886383, 0.05237247794866562, 0.051538266241550446, 0.04679841175675392, 0.047078270465135574, 0.05028275400400162, 0.046635787934064865, 0.043684445321559906, 0.042603518813848495, 0.044240906834602356, 0.04560961201786995, 0.03989414870738983, 0.04476098716259003, 0.04344617575407028, 0.03460374101996422, 0.04705405235290527, 0.04349620267748833, 0.03999554365873337, 0.046704716980457306, 0.03548348322510719, 0.042799901217222214, 0.04033363610506058, 0.03940074145793915, 0.036501165479421616, 0.04085714370012283, 0.037863388657569885, 0.03607717528939247, 0.03820937126874924, 0.039226286113262177, 0.06792233139276505, 0.0593467578291893, 0.028789451345801353, 0.04708528146147728, 0.03223298490047455, 0.03874943032860756, 0.035907384008169174, 0.036347657442092896, 0.03296289220452309, 0.03439246118068695, 0.03796849399805069, 0.02898300252854824, 0.036271464079618454, 0.03376467153429985, 0.031937409192323685, 0.03335590660572052, 0.028879331424832344, 0.035232216119766235, 0.0335051491856575, 0.030379004776477814, 0.036601487547159195, 0.03420449048280716, 0.02534683793783188, 0.038602374494075775, 0.025989100337028503, 0.03403082862496376, 0.03510033339262009, 0.028621895238757133, 0.03178270533680916, 0.029603751376271248, 0.03177158907055855, 0.031701911240816116, 0.033942557871341705, 0.030469298362731934, 0.0315571203827858, 0.02143748849630356, 0.04158951714634895, 0.023745939135551453, 0.026413124054670334, 0.032636597752571106, 0.03279796242713928, 0.026417940855026245, 0.028597306460142136, 0.025318536907434464, 0.03520519658923149, 0.027453575283288956, 0.02938029170036316, 0.024523193016648293, 0.027849113568663597, 0.028077581897377968, 0.02987363561987877, 0.027409644797444344, 0.024194937199354172, 0.025698162615299225, 0.02773171104490757, 0.02796531654894352, 0.027804424986243248, 0.026190228760242462, 0.03586537763476372, 0.022706974297761917, 0.020423175767064095, 0.0253935344517231, 0.029699763283133507, 0.02273697406053543, 0.03265780210494995, 0.022007452324032784, 0.025172587484121323, 0.033436063677072525, 0.02463015355169773, 0.02326592616736889, 0.025942618027329445, 0.02985507622361183, 0.0252189040184021, 0.0244620218873024, 0.02265477553009987, 0.02440512739121914, 0.024966586381196976, 0.02520807646214962, 0.02556360699236393, 0.02405582182109356, 0.028929894790053368, 0.029215091839432716, 0.024890601634979248, 0.02372448332607746, 0.02246910333633423, 0.02742019109427929, 0.0314505361020565, 0.01606459729373455, 0.021951774135231972, 0.030470503494143486, 0.017347443848848343, 0.03205616772174835, 0.03195049613714218, 0.021581972017884254, 0.020187776535749435, 0.027073347941040993, 0.029925327748060226, 0.01650969311594963, 0.02465224452316761, 0.022500989958643913, 0.022912973538041115, 0.02131710574030876, 0.025879861786961555, 0.030298583209514618, 0.02342645637691021, 0.02241736836731434, 0.027430986985564232, 0.024277186021208763, 0.023255765438079834, 0.024830365553498268, 0.016307514160871506, 0.024953167885541916, 0.019129637628793716, 0.020025573670864105, 0.03318404406309128, 0.023948708549141884, 0.0061960783787071705, 0.039026498794555664, 0.024435417726635933, 0.013691009022295475, 0.02089766226708889, 0.03882833197712898, 0.013124683871865273, 0.022113323211669922, 0.029433313757181168, 0.01672535575926304, 0.020990019664168358, 0.03069354221224785, 0.02162087708711624, 0.01964312233030796, 0.031172651797533035, 0.016306469216942787, 0.01856493018567562, 0.023499783128499985, 0.02119356207549572, 0.01958025060594082, 0.016877129673957825, 0.02633592300117016, 0.019449537619948387, 0.0076494766399264336, 0.04096977040171623, 0.01832316815853119, 0.01206819899380207, 0.03412964195013046, 0.01588241197168827, 0.015462699346244335, 0.024282976984977722, 0.028248487040400505, 0.01804310828447342, 0.016962481662631035, 0.024802152067422867, 0.021504973992705345, 0.018452752381563187, 0.014409995637834072, 0.03155946731567383, 0.01858591102063656, 0.01593869924545288, 0.01798669807612896, 0.027515007182955742, 0.022606495767831802, 0.015578618273139, 0.02278544381260872, 0.020627453923225403, 0.018918553367257118, 0.020566551014780998, 0.02039799839258194, 0.020315375179052353, 0.012263049371540546, 0.028544269502162933, 0.0157190952450037, 0.02365637570619583, 0.023833613842725754, 0.015459627844393253]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:32 2016", "state": "available"}], "summary": "89c4cbaef6c302f867a2583403d47795"}