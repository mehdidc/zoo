{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 16, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.041851948672928754, 0.039100800560357266, 0.04643086887310888, 0.04063514576501036, 0.039801688092924496, 0.04023241558165324, 0.04028627049050564, 0.04100782768376103, 0.040671742351772365, 0.041910216451199585, 0.045812465832743364, 0.042505150257661155, 0.04508289114952473, 0.03992707743759973, 0.038575479137217136, 0.04012674976610234, 0.041686885855459384, 0.04337619123950597, 0.03669631978973212, 0.03749647755206382, 0.03574152187060912, 0.03321453004531441, 0.03965440374770386, 0.0361513711146902, 0.04122493491629705, 0.03810818718154212, 0.03556034482758621, 0.03408505204537416, 0.03430656934531991, 0.037641601290992845, 0.0354706880635158, 0.04090571744849635, 0.039935256143247826, 0.037094887829437526, 0.03657076794342083, 0.038823959531677096, 0.040045958253994596, 0.03935610711230408, 0.03338262456843479, 0.03753734276058099, 0.03436575144474178, 0.036031725849928906, 0.03659854032649117, 0.03714840719421869, 0.03684434911112441, 0.03674400095030054, 0.03658540066580151, 0.03647339806993054, 0.03652484766909093, 0.03650820283635505, 0.03661415303455174, 0.03670126371966897, 0.03659854032649117, 0.03638050569258999, 0.03721769668739886, 0.037169890988719055, 0.03685739645681699, 0.03637751325946196, 0.03608129102390763, 0.03610014312805329, 0.03592481552498029, 0.03637950824223016, 0.03667084799512691, 0.03635655933113903, 0.03670620698371181, 0.03696160941836212, 0.037389873409568154, 0.03750034835599197, 0.03702144804599745, 0.037750378362146404, 0.03775398284774753, 0.03775398284774753, 0.03749067059682903, 0.03701556656880998, 0.03737725464846878, 0.037398849550858905, 0.038040519720630925, 0.03786722873559082, 0.03786243705314214, 0.03801642585038958, 0.03796102360734598, 0.03847304398620651, 0.038628121398566646, 0.03846431852275994, 0.038573597727742645, 0.038390899076259546, 0.03852770995900574, 0.03884264825882651, 0.03900858348016895, 0.0381317472611727, 0.038044096716816835, 0.038044096716816835, 0.03734617491778633, 0.037749417107859166, 0.03821278746038223, 0.0383745908345959, 0.037898838645560415, 0.03850509896929665], "moving_avg_accuracy_train": [0.049002259036144566, 0.10067676957831323, 0.15396564382530117, 0.20540360504518068, 0.2552157483057228, 0.30159035193900596, 0.3464030787932981, 0.3899936632332454, 0.4311736079038968, 0.4696921657882059, 0.5049965749623974, 0.537928299243266, 0.5673927170599032, 0.5928282382755996, 0.617030918966112, 0.6389003986056454, 0.6619479528715869, 0.6855521974940668, 0.706539522925383, 0.7263293771087483, 0.7462863302111264, 0.763358092521339, 0.7784450054077593, 0.7937410357404773, 0.8083404826182368, 0.8214564531817143, 0.8339032400924586, 0.845037106595261, 0.8548481549718794, 0.8653747287819203, 0.8756981369278247, 0.8861540197711868, 0.8947054099627427, 0.9019663260447817, 0.9057432438921107, 0.9120392131775984, 0.9192633792092362, 0.9261557536377101, 0.9331542595992403, 0.9396929375549788, 0.9456389299440593, 0.9510091483954365, 0.9558494044896277, 0.9602126944623518, 0.964142008600454, 0.9676830976500471, 0.9708724309573316, 0.9737545967471406, 0.9763485459579687, 0.9786854534103646, 0.9807910232801715, 0.982690742488299, 0.9844051961009148, 0.9859505575149197, 0.987341382787524, 0.9885931255328679, 0.9897220471663282, 0.9907380766364423, 0.9916548563221956, 0.9924823112020243, 0.9932270205938701, 0.9938996122091819, 0.9945049446629625, 0.9950497438713649, 0.9955400631589272, 0.9959813505177332, 0.9963785091406586, 0.9967359519012915, 0.9970576503858611, 0.9973471790219738, 0.9976077547944752, 0.9978422729897264, 0.9980533393654525, 0.998243299103606, 0.9984166160305947, 0.9985726012648847, 0.9987129879757456, 0.9988393360155204, 0.9989530492513178, 0.9990553911635354, 0.9991474988845312, 0.9992303958334275, 0.9993050030874342, 0.9993721496160402, 0.9994325814917855, 0.9994869701799564, 0.9995359199993101, 0.9995799748367284, 0.999619624190405, 0.9996576617713645, 0.9996895424315774, 0.999718235025769, 0.9997440583605415, 0.9997672993618367, 0.9997882162630024, 0.9998046883114009, 0.9998195131549595, 0.9998328555141623], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234423, "moving_var_accuracy_train": [0.02161099251580871, 0.04348218862218216, 0.0646913068265656, 0.0820349508340295, 0.09616270229650553, 0.10590186682615205, 0.11338530453659343, 0.11914802554927967, 0.12249531358205287, 0.12359889593722943, 0.12245661810775509, 0.11997144247397999, 0.11578766548204233, 0.11003159058946538, 0.10430035930398092, 0.09817479063091851, 0.09313801938660031, 0.0888386607257211, 0.08391900511198874, 0.07905184955817962, 0.07473118439653637, 0.0698810715722703, 0.06494149887902519, 0.060553065886577544, 0.05641605394014849, 0.05232270670053172, 0.048484738570091813, 0.044751931562802647, 0.04114304843875752, 0.03802602240048593, 0.03518257496215965, 0.032648246840250715, 0.03004155862409981, 0.02751189088284354, 0.02488908777038844, 0.02275693205654384, 0.020950936024563473, 0.019283385849467663, 0.01779585903576306, 0.016401061916866515, 0.015079149154598884, 0.013830787455078606, 0.012658561421086949, 0.011564049973452917, 0.010546600562470632, 0.009604794311137907, 0.008735861502528702, 0.00793703726903534, 0.007203890694707008, 0.006532651853205879, 0.005919287488175039, 0.00535983913698509, 0.004850309383994886, 0.004386771722694455, 0.003965504104875246, 0.0035830554334924138, 0.0032362200666336224, 0.0029218889029275245, 0.0026372643775646625, 0.002379700074011566, 0.002146721395315139, 0.0019361206711125145, 0.0017458064504176636, 0.0015738970609731817, 0.001418671071909664, 0.0012785565755160761, 0.001152120532710345, 0.0010380583673834706, 0.0009351839398798932, 0.0008424199873720674, 0.0007587890862337931, 0.0006834051666655491, 0.0006154655911336538, 0.0005542437943393627, 0.000499089763720054, 0.00044939976988789694, 0.00040463716875638436, 0.00036431712632514047, 0.00032800178999258596, 0.0002952958757962946, 0.0002658426427070686, 0.00023932022557358854, 0.0002154382991973834, 0.00019393504718437956, 0.00017457441057039657, 0.00015714359267796543, 0.0001414507981735018, 0.00012732318581445124, 0.00011460501587422884, 0.00010315753600489321, 9.285092979286441e-05, 8.3573246198231e-05, 7.522192317997684e-05, 6.770459215925002e-05, 6.093807059411441e-05, 5.484670549010897e-05, 4.9364012924976936e-05, 4.4429213799421124e-05], "duration": 31053.280563, "accuracy_train": [0.4900225903614458, 0.5657473644578314, 0.6335655120481928, 0.6683452560240963, 0.7035250376506024, 0.7189617846385542, 0.7497176204819277, 0.7823089231927711, 0.801793109939759, 0.8163591867469879, 0.8227362575301205, 0.8343138177710844, 0.8325724774096386, 0.8217479292168675, 0.8348550451807228, 0.8357257153614458, 0.8693759412650602, 0.8979903990963856, 0.8954254518072289, 0.9044380647590361, 0.9258989081325302, 0.917003953313253, 0.9142272213855421, 0.9314053087349398, 0.9397355045180723, 0.9395001882530121, 0.9459243222891566, 0.9452419051204819, 0.9431475903614458, 0.9601138930722891, 0.9686088102409639, 0.9802569653614458, 0.971667921686747, 0.9673145707831325, 0.9397355045180723, 0.9687029367469879, 0.9842808734939759, 0.9881871234939759, 0.9961408132530121, 0.9985410391566265, 0.9991528614457831, 0.9993411144578314, 0.9994117093373494, 0.9994823042168675, 0.9995058358433735, 0.9995528990963856, 0.9995764307228916, 0.9996940888554217, 0.9996940888554217, 0.9997176204819277, 0.9997411521084337, 0.9997882153614458, 0.9998352786144579, 0.9998588102409639, 0.9998588102409639, 0.9998588102409639, 0.9998823418674698, 0.9998823418674698, 0.9999058734939759, 0.9999294051204819, 0.9999294051204819, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 1.0, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.999976468373494, 0.9999529367469879, 0.9999529367469879, 0.9999529367469879], "end": "2016-01-20 21:37:03.998000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0], "accuracy_valid": [0.48060344827586204, 0.5542834051724138, 0.611260775862069, 0.6457435344827587, 0.6668911637931034, 0.6728178879310345, 0.6888469827586207, 0.7008351293103449, 0.7033943965517241, 0.701104525862069, 0.6928879310344828, 0.6957165948275862, 0.6846713362068966, 0.6729525862068966, 0.6751077586206896, 0.6736260775862069, 0.6866918103448276, 0.6950431034482759, 0.6904633620689655, 0.6920797413793104, 0.7033943965517241, 0.6910021551724138, 0.6810344827586207, 0.6877693965517241, 0.6951778017241379, 0.6930226293103449, 0.7001616379310345, 0.6976023706896551, 0.6928879310344828, 0.6994881465517241, 0.7019127155172413, 0.7063577586206896, 0.7015086206896551, 0.7019127155172413, 0.6889816810344828, 0.7152478448275862, 0.7112068965517241, 0.7140355603448276, 0.7264278017241379, 0.7264278017241379, 0.7252155172413793, 0.7260237068965517, 0.7261584051724138, 0.7257543103448276, 0.7265625, 0.7264278017241379, 0.7268318965517241, 0.7275053879310345, 0.7271012931034483, 0.7272359913793104, 0.7268318965517241, 0.7265625, 0.7261584051724138, 0.7260237068965517, 0.7252155172413793, 0.7254849137931034, 0.7250808189655172, 0.7249461206896551, 0.724542025862069, 0.7241379310344828, 0.7241379310344828, 0.7235991379310345, 0.7234644396551724, 0.7233297413793104, 0.7230603448275862, 0.7231950431034483, 0.7227909482758621, 0.7230603448275862, 0.7229256465517241, 0.7231950431034483, 0.7227909482758621, 0.7225215517241379, 0.7217133620689655, 0.7210398706896551, 0.7209051724137931, 0.720770474137931, 0.720770474137931, 0.720635775862069, 0.7200969827586207, 0.7195581896551724, 0.7195581896551724, 0.7194234913793104, 0.7190193965517241, 0.7190193965517241, 0.7190193965517241, 0.7194234913793104, 0.7194234913793104, 0.7192887931034483, 0.71875, 0.7182112068965517, 0.7179418103448276, 0.7179418103448276, 0.7179418103448276, 0.7178071120689655, 0.7175377155172413, 0.7179418103448276, 0.7176724137931034, 0.7172683189655172], "accuracy_test": 0.6852964743589743, "start": "2016-01-20 12:59:30.717000", "learning_rate_per_epoch": [0.00020286714425310493, 0.00019739166600629687, 0.00019206397701054811, 0.00018688007548917085, 0.00018183609063271433, 0.0001769282534951344, 0.00017215288244187832, 0.00016750639770179987, 0.00016298532136715949, 0.0001585862773936242, 0.00015430596249643713, 0.00015014117525424808, 0.00014608878700528294, 0.00014214578550308943, 0.00013830920215696096, 0.00013457617023959756, 0.00013094389578327537, 0.00012740965757984668, 0.00012397080718073994, 0.00012062477617291734, 0.00011736905435100198, 0.00011420121154515073, 0.00011111886851722375, 0.00010811971878865734, 0.00010520151408854872, 0.00010236207890557125, 9.959928138414398e-05, 9.691104787634686e-05, 9.429537021787837e-05, 9.175029117614031e-05, 8.927390445023775e-05, 8.68643619469367e-05, 8.451985195279121e-05, 8.223862096201628e-05, 8.001895912457258e-05, 7.785920752212405e-05, 7.575775089208037e-05, 7.371301035163924e-05, 7.17234579497017e-05, 6.978760939091444e-05, 6.790400948375463e-05, 6.607124669244513e-05, 6.428795313695446e-05, 6.255279004108161e-05, 6.086446228437126e-05, 5.922170021221973e-05, 5.762327782576904e-05, 5.6067998229991645e-05, 5.4554697271669284e-05, 5.308223990141414e-05, 5.164952381164767e-05, 5.025547943660058e-05, 4.8899059038376436e-05, 4.757925125886686e-05, 4.629506656783633e-05, 4.504554090090096e-05, 4.382973929750733e-05, 4.264675226295367e-05, 4.149569576838985e-05, 4.0375707612838596e-05, 3.9285947423195466e-05, 3.822560029220767e-05, 3.719387314049527e-05, 3.6189994716551155e-05, 3.521320832078345e-05, 3.426278635743074e-05, 3.3338015782646835e-05, 3.2438205380458385e-05, 3.156268212478608e-05, 3.071079117944464e-05, 2.9881892260164022e-05, 2.9075365091557615e-05, 2.8290607588132843e-05, 2.752703039732296e-05, 2.678406235645525e-05, 2.6061148673761636e-05, 2.5357745471410453e-05, 2.467332706146408e-05, 2.4007382307900116e-05, 2.335941098863259e-05, 2.2728929252480157e-05, 2.2115464162197895e-05, 2.1518557332456112e-05, 2.0937761291861534e-05, 2.0372641301946715e-05, 1.9822773538180627e-05, 1.928774690895807e-05, 1.8767161236610264e-05, 1.826062725740485e-05, 1.7767764802556485e-05, 1.7288204617216252e-05, 1.682158836047165e-05, 1.6367564967367798e-05, 1.5925796105875634e-05, 1.5495950719923712e-05, 1.5077707757882308e-05, 1.467075344407931e-05, 1.4274783097789623e-05], "accuracy_train_last": 0.9999529367469879, "error_valid": [0.5193965517241379, 0.4457165948275862, 0.38873922413793105, 0.3542564655172413, 0.3331088362068966, 0.3271821120689655, 0.31115301724137934, 0.29916487068965514, 0.2966056034482759, 0.29889547413793105, 0.30711206896551724, 0.3042834051724138, 0.3153286637931034, 0.3270474137931034, 0.3248922413793104, 0.32637392241379315, 0.3133081896551724, 0.3049568965517241, 0.3095366379310345, 0.3079202586206896, 0.2966056034482759, 0.3089978448275862, 0.31896551724137934, 0.3122306034482759, 0.3048221982758621, 0.30697737068965514, 0.2998383620689655, 0.30239762931034486, 0.30711206896551724, 0.3005118534482759, 0.2980872844827587, 0.2936422413793104, 0.29849137931034486, 0.2980872844827587, 0.31101831896551724, 0.2847521551724138, 0.2887931034482759, 0.2859644396551724, 0.2735721982758621, 0.2735721982758621, 0.27478448275862066, 0.2739762931034483, 0.2738415948275862, 0.2742456896551724, 0.2734375, 0.2735721982758621, 0.2731681034482759, 0.2724946120689655, 0.2728987068965517, 0.2727640086206896, 0.2731681034482759, 0.2734375, 0.2738415948275862, 0.2739762931034483, 0.27478448275862066, 0.2745150862068966, 0.27491918103448276, 0.27505387931034486, 0.27545797413793105, 0.27586206896551724, 0.27586206896551724, 0.2764008620689655, 0.2765355603448276, 0.2766702586206896, 0.2769396551724138, 0.2768049568965517, 0.2772090517241379, 0.2769396551724138, 0.2770743534482759, 0.2768049568965517, 0.2772090517241379, 0.2774784482758621, 0.2782866379310345, 0.27896012931034486, 0.27909482758620685, 0.27922952586206895, 0.27922952586206895, 0.27936422413793105, 0.27990301724137934, 0.2804418103448276, 0.2804418103448276, 0.2805765086206896, 0.2809806034482759, 0.2809806034482759, 0.2809806034482759, 0.2805765086206896, 0.2805765086206896, 0.2807112068965517, 0.28125, 0.2817887931034483, 0.2820581896551724, 0.2820581896551724, 0.2820581896551724, 0.2821928879310345, 0.2824622844827587, 0.2820581896551724, 0.2823275862068966, 0.28273168103448276], "accuracy_train_std": [0.045308495438244, 0.04460129140984491, 0.044353863861241474, 0.043780893084705244, 0.04275241938455377, 0.041906880295614936, 0.04066635448604017, 0.03954172484212513, 0.0403529110991066, 0.040506508259157095, 0.04030188652499518, 0.039550462295945, 0.040521071380784444, 0.041178994975674024, 0.041035513380412864, 0.04044239150035054, 0.037327205263519986, 0.034010446293026096, 0.033909588188388705, 0.03671189406208943, 0.03287531609509258, 0.03288373679797161, 0.03253220768930376, 0.02808650204122008, 0.027958137277236134, 0.02791016572458947, 0.02508912840627973, 0.02576517535352273, 0.025251792679699427, 0.02155511117157222, 0.019778608548494857, 0.01441801402230712, 0.018390474227972218, 0.019778146596151906, 0.02466737473252899, 0.019375261653823715, 0.014489215659734569, 0.01095624039294512, 0.005956430612483486, 0.00349442672832202, 0.002646445014967912, 0.002334261439690746, 0.002148864016719665, 0.0020357237155386077, 0.001996031293368623, 0.0019133108099918617, 0.0018701352114368905, 0.0016321859124491564, 0.0016321859124491564, 0.001579250916374484, 0.0015241156734479742, 0.0014061992816574418, 0.0011223870498599227, 0.0010407259218512793, 0.0010407259218512793, 0.0010407259218512793, 0.0009515044530852656, 0.0009515044530852656, 0.0008523517637554043, 0.0007392826653052055, 0.0007392826653052055, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.0, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.00042812042071395547, 0.0006045384308483212, 0.0006045384308483212, 0.0006045384308483212], "accuracy_test_std": 0.03827118023746554, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.8147626937360073, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0002084945209239048, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.6089236523716883e-09, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.026990472190952033}, "accuracy_valid_max": 0.7275053879310345, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234423\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7172683189655172, "loss_train": [1.563251256942749, 1.1845682859420776, 1.0132333040237427, 0.8951472640037537, 0.805282473564148, 0.7297320365905762, 0.6600402593612671, 0.5941724181175232, 0.5314897894859314, 0.4708927273750305, 0.4133065342903137, 0.3601558804512024, 0.31056374311447144, 0.2716948986053467, 0.24131663143634796, 0.21033741533756256, 0.18583156168460846, 0.15893389284610748, 0.12928640842437744, 0.10506609082221985, 0.08885371685028076, 0.07328996807336807, 0.05927377566695213, 0.051005952060222626, 0.04315941035747528, 0.038947943598032, 0.032862357795238495, 0.030313720926642418, 0.02578061819076538, 0.021413348615169525, 0.01770084910094738, 0.01566264219582081, 0.013904763385653496, 0.012915966100990772, 0.016990894451737404, 0.029993174597620964, 0.015828290954232216, 0.007404209114611149, 0.004562552087008953, 0.002465401077643037, 0.0013995543122291565, 0.001033006003126502, 0.0008645019261166453, 0.0007529063732363284, 0.0006664050160907209, 0.000594964949414134, 0.0005342872464098036, 0.00048147980123758316, 0.0004351277893874794, 0.0003941211325582117, 0.0003574034490156919, 0.0003245520929340273, 0.0002950944472104311, 0.00026883865939453244, 0.00024528586072847247, 0.00022418009757529944, 0.00020529728499241173, 0.0001884364610305056, 0.0001734313991619274, 0.00016002162010408938, 0.00014811023720540106, 0.00013757131819147617, 0.00012824335135519505, 0.00011999232810921967, 0.00011274003918515518, 0.00010635248327162117, 0.00010073285375256091, 9.580526239005849e-05, 9.14948177523911e-05, 8.772098226472735e-05, 8.442947728326544e-05, 8.155419345712289e-05, 7.905399252194911e-05, 7.687566539971158e-05, 7.497719343518838e-05, 7.332344102906063e-05, 7.188519521150738e-05, 7.063472730806097e-05, 6.954836135264486e-05, 6.860002031316981e-05, 6.777576345484704e-05, 6.705770647386089e-05, 6.643187953159213e-05, 6.588544783880934e-05, 6.540668982779607e-05, 6.498827133327723e-05, 6.461919838329777e-05, 6.429374479921535e-05, 6.40044454485178e-05, 6.374574877554551e-05, 6.351376214297488e-05, 6.33035451755859e-05, 6.311034667305648e-05, 6.293261685641482e-05, 6.276580825215206e-05, 6.260755617404357e-05, 6.245566328288987e-05, 6.23083979007788e-05], "accuracy_train_first": 0.4900225903614458, "model": "residualv3", "loss_std": [0.3034549951553345, 0.12179787456989288, 0.11533670872449875, 0.10649990290403366, 0.1014557033777237, 0.09725461155176163, 0.09387101233005524, 0.08949495851993561, 0.08462786674499512, 0.07947897911071777, 0.07329483330249786, 0.06657139211893082, 0.061574339866638184, 0.05656658485531807, 0.05211129039525986, 0.04570456221699715, 0.039867378771305084, 0.038414690643548965, 0.03493340313434601, 0.03008122742176056, 0.026619965210556984, 0.022296015173196793, 0.020094772800803185, 0.01775563880801201, 0.01467879954725504, 0.01427592895925045, 0.013475772924721241, 0.01401287131011486, 0.010661984793841839, 0.010155913420021534, 0.00819479487836361, 0.008649305440485477, 0.008184844627976418, 0.006822987459599972, 0.011387684382498264, 0.01711427979171276, 0.009736527688801289, 0.005437442567199469, 0.0024809157475829124, 0.001146038412116468, 0.00041124355630017817, 0.00022789246577303857, 0.00017157726688310504, 0.00014130197814665735, 0.0001196738812723197, 0.0001027608523145318, 8.900061948224902e-05, 7.743258902337402e-05, 6.773567292839289e-05, 5.9341156884329394e-05, 5.202765896683559e-05, 4.561900277622044e-05, 3.997871317551471e-05, 3.509920497890562e-05, 3.0793544283369556e-05, 2.701748235267587e-05, 2.3711738322163e-05, 2.077827048196923e-05, 1.8204913430963643e-05, 1.5938754586386494e-05, 1.3907245374866761e-05, 1.2138377314840909e-05, 1.0588997611193918e-05, 9.240878171112854e-06, 8.053995770751499e-06, 7.01988028595224e-06, 6.1047358030918986e-06, 5.307008450472495e-06, 4.6115656004985794e-06, 4.003351023129653e-06, 3.4773906918417197e-06, 3.0162739221850643e-06, 2.6179832275374793e-06, 2.2721771983924555e-06, 1.97012332137092e-06, 1.7088468666770495e-06, 1.4816548628004966e-06, 1.2846949175582267e-06, 1.1142552693854668e-06, 9.66841753324843e-07, 8.386559215978195e-07, 7.276822771018487e-07, 6.319550607258861e-07, 5.488843726197956e-07, 4.772779789163906e-07, 4.15328173630769e-07, 3.61887799726901e-07, 3.152814826989925e-07, 2.751136491951911e-07, 2.405600127985963e-07, 2.1093771351843316e-07, 1.8553376435193059e-07, 1.6290330506762984e-07, 1.4380299262484186e-07, 1.2760014556079113e-07, 1.1401441923908351e-07, 1.0137189576653327e-07, 9.178040727420012e-08]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:04 2016", "state": "available"}], "summary": "30487fae2cb4578ccbd315afefd48036"}