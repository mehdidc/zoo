{"content": {"hp_model": {"f0": 16, "f1": 32, "f2": 32, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.778558611869812, 1.4269137382507324, 1.2750650644302368, 1.1741477251052856, 1.0915954113006592, 1.0258307456970215, 0.970432460308075, 0.9224478006362915, 0.8811419010162354, 0.8398907780647278, 0.8077414631843567, 0.7785207033157349, 0.7529512047767639, 0.7270616888999939, 0.705385148525238, 0.6852343082427979, 0.6677234172821045, 0.6521985530853271, 0.6361575126647949, 0.6217473745346069, 0.607635498046875, 0.5952244997024536, 0.5836336016654968, 0.570148229598999, 0.5611554980278015, 0.5494995713233948, 0.5396333336830139, 0.5293029546737671, 0.5203171968460083, 0.5126861929893494, 0.5047723650932312, 0.49453043937683105, 0.4883560240268707, 0.48040688037872314, 0.4707624614238739, 0.4665195345878601, 0.45800670981407166, 0.45245325565338135, 0.4463454484939575, 0.4367237687110901, 0.4324575364589691, 0.4248135983943939, 0.41908004879951477, 0.41670286655426025, 0.4124498665332794, 0.40675944089889526, 0.39938199520111084, 0.39647427201271057, 0.39177727699279785, 0.3859335482120514, 0.38369396328926086, 0.37827953696250916, 0.3739047944545746, 0.3684169352054596, 0.3633468747138977, 0.36145222187042236, 0.35656672716140747, 0.35295355319976807, 0.35086914896965027, 0.3474135398864746, 0.34265026450157166, 0.3404616415500641, 0.3362305164337158, 0.3324195146560669, 0.3299889862537384, 0.3274023234844208, 0.32517537474632263, 0.31862881779670715, 0.3183728754520416, 0.3138343393802643, 0.3139304518699646, 0.30855461955070496, 0.30867984890937805, 0.3052881956100464, 0.30135104060173035, 0.29777273535728455, 0.29638317227363586, 0.2907307744026184, 0.2898913621902466, 0.28836360573768616, 0.28726983070373535, 0.2840501368045807, 0.28144174814224243, 0.28028959035873413, 0.27850770950317383, 0.2748171389102936, 0.27229130268096924, 0.27222898602485657, 0.27093780040740967, 0.2663213610649109, 0.2356511801481247, 0.21921077370643616, 0.21340519189834595, 0.21097314357757568, 0.20832864940166473, 0.20895732939243317, 0.20624038577079773, 0.20357109606266022, 0.20304864645004272, 0.20241792500019073, 0.20106980204582214, 0.1997741013765335, 0.1980043202638626, 0.19844087958335876, 0.1985781341791153, 0.19642123579978943, 0.19644029438495636, 0.19612929224967957, 0.19439205527305603, 0.1931207925081253, 0.19316384196281433, 0.19199559092521667, 0.1922498345375061, 0.18982647359371185, 0.1893720030784607, 0.1878654807806015, 0.18830974400043488, 0.1872653365135193, 0.18797092139720917, 0.18759261071681976, 0.18746724724769592, 0.18722490966320038, 0.18782001733779907, 0.1889549195766449, 0.18807849287986755, 0.1876329481601715, 0.18644627928733826, 0.1882486641407013, 0.1888314038515091, 0.18776005506515503, 0.18698430061340332, 0.18804048001766205, 0.18813210725784302, 0.18788142502307892, 0.18767386674880981, 0.18682189285755157, 0.1880243718624115, 0.1870441734790802, 0.18798013031482697, 0.1870693564414978, 0.1881960779428482, 0.18962495028972626, 0.18738946318626404, 0.18641851842403412, 0.18894246220588684, 0.1883838176727295, 0.18669237196445465, 0.18796446919441223, 0.18836602568626404, 0.1873767077922821, 0.18834194540977478, 0.18779577314853668, 0.1884777545928955, 0.18906767666339874, 0.18837493658065796, 0.18722902238368988, 0.18897755444049835, 0.18525943160057068, 0.1883016973733902, 0.18681925535202026, 0.18833470344543457, 0.18761326372623444, 0.18673259019851685, 0.1883353739976883, 0.18789009749889374, 0.18866033852100372, 0.1878851354122162, 0.18817317485809326, 0.1893559694290161, 0.1872887909412384, 0.1885489970445633, 0.18878471851348877, 0.1874421089887619, 0.18746770918369293, 0.18691328167915344, 0.18784025311470032, 0.1880340874195099, 0.18755707144737244, 0.18738755583763123, 0.18824328482151031, 0.18749196827411652, 0.18734252452850342, 0.1876416653394699, 0.1873462200164795, 0.1869240403175354, 0.1896684467792511, 0.18728281557559967, 0.18687184154987335, 0.1873043328523636, 0.18676233291625977, 0.18792030215263367, 0.18733268976211548, 0.1882164031267166, 0.18693014979362488, 0.1889665424823761, 0.18791483342647552, 0.18835848569869995, 0.1870058923959732, 0.1881531924009323, 0.1879783719778061, 0.1865464746952057, 0.1882551610469818, 0.1874508112668991, 0.18796589970588684, 0.18852165341377258, 0.18690216541290283, 0.1874728798866272, 0.18729306757450104, 0.1875459998846054, 0.18768328428268433, 0.18723097443580627], "moving_avg_accuracy_train": [0.043325615281238454, 0.09013641413748152, 0.13987980584827192, 0.18784772241760678, 0.23349934852394502, 0.2763289166015985, 0.3190276668641961, 0.35936487644323417, 0.3977558440118584, 0.43261209302475523, 0.4653799152779737, 0.49820903987351517, 0.5279602616417469, 0.5559865703163043, 0.5814009103257869, 0.605385021172361, 0.6273286136068507, 0.6466918720955104, 0.6665644647459168, 0.6840128864480047, 0.6986467533322279, 0.7118290755649889, 0.7247299656506088, 0.7377262670275929, 0.7492207584669063, 0.7595565722646878, 0.7693933726159691, 0.7756291323977923, 0.7840027278154973, 0.7932524902175947, 0.8017260498544732, 0.8084850451193488, 0.8157397274671869, 0.8229174778540046, 0.8293077347866735, 0.8329831849202709, 0.837839242610645, 0.8413611594117806, 0.8445353906351466, 0.8491566261944171, 0.8527997354061401, 0.8575153675145202, 0.8599458203406337, 0.8637560015090897, 0.8661344135917078, 0.8702532895659626, 0.8731839666309611, 0.8761565055644874, 0.8790245977117578, 0.8822080220883303, 0.884708091712969, 0.8864421515835234, 0.8887908146205383, 0.8917856264597488, 0.89341621920437, 0.8934262448591452, 0.8953950800043216, 0.8971902831230755, 0.8986082922323257, 0.9008540514354035, 0.9029983955074409, 0.9033915260044543, 0.9049542045398061, 0.9038615128372097, 0.905444658053581, 0.9070181180280309, 0.9090107968121602, 0.9111624248298184, 0.9130221961838152, 0.913696176414317, 0.915630382543188, 0.9159505381853715, 0.9168572038954889, 0.9176639745369938, 0.9179204962012807, 0.9182162896217118, 0.9191544356572334, 0.9197500122154026, 0.9196561320832866, 0.9214872020952422, 0.9222050695333739, 0.923804497288416, 0.9236211365453624, 0.9232562572254515, 0.9233649577649033, 0.9247367895539353, 0.9258018104474252, 0.9272927162313094, 0.9279835258189573, 0.9286818762120984, 0.9331887758290299, 0.9374496706771439, 0.9413588808023512, 0.9449515386281239, 0.9482197718546433, 0.9512866676965877, 0.9539958288269843, 0.9565153459062183, 0.9588271251537287, 0.9608961728300779, 0.9627676163340302, 0.9644263748995012, 0.9659842896774544, 0.9674654319883174, 0.9687822200752461, 0.9700324695689673, 0.9711110829906697, 0.9721353855904584, 0.9730688476254972, 0.9739555024820412, 0.9747418661088832, 0.9754425818777936, 0.9760291203400696, 0.9767662683489752, 0.9773924991760378, 0.9780212110870607, 0.9786033278486482, 0.9791132820412197, 0.9795745659633436, 0.9799711203027789, 0.980307092868985, 0.98066062145238, 0.9809601959869593, 0.98123213821689, 0.9814489844381136, 0.9816487963348337, 0.9818565288275962, 0.9820551138151301, 0.9821943127741486, 0.9823172666884558, 0.9824279252113322, 0.982536818477159, 0.9826045954818794, 0.9826586193396991, 0.9827281311022039, 0.9828046786301341, 0.9828828720005094, 0.9829578963314662, 0.982988215848375, 0.9830620063897834, 0.9830958657937175, 0.9831100632155917, 0.9831205157464687, 0.9831322481730678, 0.9831916354820068, 0.9832311331671948, 0.9832527301910068, 0.9832837932564853, 0.9833303512058921, 0.9833652779139297, 0.9834129879928303, 0.983425700129317, 0.9834441164985835, 0.9834444151892567, 0.983467935498958, 0.9834891037776889, 0.9834965294844993, 0.9835380898527715, 0.9835336415056449, 0.9835482391837072, 0.9835613770939633, 0.983547624576289, 0.9835305970127631, 0.9835385236936851, 0.9835433325577053, 0.9835476605353235, 0.9835120281854179, 0.9835218117490744, 0.9835259666587461, 0.9835413318214983, 0.9835481850215467, 0.9835427271575427, 0.9834913121037485, 0.9834868912339052, 0.983503838790332, 0.9834935149542113, 0.9834586468647979, 0.9834877194533734, 0.9835092344854724, 0.9834983710798377, 0.9835048700564332, 0.9835246700282262, 0.9835238888123636, 0.9835138851228493, 0.9835002315046675, 0.9834925935459228, 0.9834996702759097, 0.9834897632912313, 0.9834994481954968, 0.9834988640140978, 0.9834680752674961, 0.9834706283788971, 0.9834985028160627, 0.9835166143630831, 0.9835305896065921, 0.9835198797888363, 0.9835498045314366, 0.9835651110557293, 0.9835626108859261, 0.9835231583521508, 0.9835341540479434, 0.983562651364633, 0.983576673205606, 0.983568366523196, 0.9835818168483128, 0.9835985724385369, 0.9836252782137862, 0.9835911846912725, 0.983595377753153, 0.9836200778481312, 0.9836027804038496], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.043110969267695774, 0.08980614351939004, 0.13881848732821908, 0.18647581287062306, 0.23118434157038303, 0.27254403476650735, 0.31344016310461564, 0.35198934262434983, 0.3887517400166588, 0.4218989328259869, 0.4534548038506171, 0.48533923922233246, 0.5137962379751746, 0.5401623137729132, 0.5643088800706972, 0.5869716126396817, 0.6078269386686351, 0.6260391796191662, 0.6438716556708038, 0.6595740867716452, 0.6727123576878542, 0.6847331435211019, 0.696289420189323, 0.7074773491700141, 0.7176828216137056, 0.7268789243356182, 0.7350598195526588, 0.7398753266787182, 0.7468807109912681, 0.7546596662004997, 0.7612078891512328, 0.7663109213016216, 0.7720419926692004, 0.7772508440423406, 0.7820536740300492, 0.7847740113992582, 0.7881185758560943, 0.7907858574835873, 0.7931396418406503, 0.7964584548591456, 0.7989132776714237, 0.8021440378655013, 0.8038666105002614, 0.8066274809826148, 0.8081458499306636, 0.8111166506209556, 0.8129805891450799, 0.8144719398220629, 0.8162933181760765, 0.8182652370644177, 0.8197815573903554, 0.8207454726697686, 0.8222457030289213, 0.823436189437249, 0.824022434480723, 0.8233475889053917, 0.8237809140698223, 0.8242665039504906, 0.8248541372527307, 0.8262029373358161, 0.8269600497110446, 0.8266282672550005, 0.8269420736243799, 0.825032234202454, 0.825935978496817, 0.8266587515996955, 0.8276683988418344, 0.8288578430785094, 0.8298948103237459, 0.8296703248203623, 0.830810178868823, 0.830764770215751, 0.8314655898809229, 0.8313403740780715, 0.8312328273988036, 0.8312570761913027, 0.8314172954829405, 0.8315736998766645, 0.830680837136739, 0.8318315622521314, 0.8320491966895689, 0.8325787755616512, 0.8319170541142963, 0.8315321128689058, 0.8313545051682352, 0.8320145883487008, 0.832650431848168, 0.8337699483866193, 0.8340796534726562, 0.8339667335414298, 0.837111293479832, 0.8400411126917133, 0.8426148558088372, 0.844893574011839, 0.8471072298354291, 0.8490109823319314, 0.8508983465422624, 0.8525206436180812, 0.8538942322589086, 0.8553654841553822, 0.8565706290756874, 0.8575067161116428, 0.8586086306262315, 0.8595341709898132, 0.8602695010670367, 0.8609679192302878, 0.8614967803098945, 0.8620348199464503, 0.8624213993693504, 0.8629311007821895, 0.8631823125224947, 0.8633798709916307, 0.8637428380999225, 0.8640430354175658, 0.8643773366856736, 0.8647758640769707, 0.8649971728594091, 0.8653225391107423, 0.8655400675321229, 0.865822321838775, 0.865954280402262, 0.8662561485781503, 0.8664545877489497, 0.8665334677353499, 0.8666543173567697, 0.8668017621271168, 0.86685916121561, 0.8669219979178442, 0.8669429593647645, 0.8670838949794928, 0.8669788034389984, 0.867178219311213, 0.8672610668548657, 0.8673091565643339, 0.8673402302716053, 0.8673814331480593, 0.8674429297993678, 0.8675369568966147, 0.8675442210619985, 0.8675782613993227, 0.867583454131755, 0.8675870980822843, 0.8676158212089203, 0.8675796073579831, 0.8676823217445492, 0.867761528152549, 0.8677239801471586, 0.8677644586384669, 0.8678130963118942, 0.8679056983429789, 0.8678150532074762, 0.8678830454865027, 0.867979830122717, 0.8678828013179001, 0.8677954753935649, 0.8678633664366633, 0.867975355517771, 0.8679906964720181, 0.8678925810322712, 0.8678653122927489, 0.8680137278819982, 0.8679997880286628, 0.867999449191911, 0.867972671159015, 0.8679129793443183, 0.8680332436745701, 0.8680905944294776, 0.8679224835463943, 0.8678179528593001, 0.8678490340793942, 0.8678017059726595, 0.867808968310258, 0.8678032973828467, 0.8678104005794265, 0.8678676805986676, 0.8678683454736653, 0.867744814531344, 0.8678055646294144, 0.8678246481325873, 0.8678275572368738, 0.8678444414793008, 0.8679084654224852, 0.8678419576415318, 0.8678207807497431, 0.867775248467314, 0.867833984680447, 0.8679611189684264, 0.8680378892251982, 0.8680571248226332, 0.8681741521276439, 0.8681187262785843, 0.8680942865855904, 0.8680967049243958, 0.8680266687504803, 0.867937163114137, 0.8678566080414282, 0.8678583801721498, 0.8679464538172089, 0.8679260048304428, 0.8678465655861033, 0.8679225841498573, 0.8679432022408957, 0.867923078411761, 0.8678317247780397, 0.8678349557264405, 0.8677524143612513, 0.8677890199224906, 0.867785343833856, 0.8677942423853349, 0.8678378426667562, 0.8678913489686046], "moving_var_accuracy_train": [0.01689398045548095, 0.03492584041596968, 0.0537029015444109, 0.06904090056999383, 0.08089344920837059, 0.08931345140299872, 0.09679075572858796, 0.10175549444533837, 0.1048447425185009, 0.10529489112389247, 0.10442897358846989, 0.10368583902500919, 0.10128347189283081, 0.09822439050484183, 0.09421494955741591, 0.08997059275958112, 0.08530722472400193, 0.08015092426528961, 0.07569011128660157, 0.07086112693698644, 0.06570236478315426, 0.06069609087987394, 0.05612437847689778, 0.0520320752745406, 0.04801797774812259, 0.04417764139507202, 0.04063074102592353, 0.03691762922384061, 0.03385692020343126, 0.031241251123545418, 0.02876333692746849, 0.026298159387637153, 0.02414201719258574, 0.02219149637886632, 0.020339865193969398, 0.018427459077733504, 0.016796944836590333, 0.015228885434518388, 0.013796678585801076, 0.012609213090069363, 0.01146774198361929, 0.010521102460891628, 0.009522156123262134, 0.008700597835764032, 0.007881449648500325, 0.007245990937271936, 0.006598691656078512, 0.006018346379872626, 0.005490545314972468, 0.005032698500327423, 0.004585681783447052, 0.0041541762778143495, 0.0037884046125858774, 0.003490284232897767, 0.0031651853038972945, 0.002848667678131348, 0.002598687716778145, 0.002367823733238584, 0.0021491381084199745, 0.0019796152071618577, 0.001823037589939207, 0.0016421247952344243, 0.001499889993554628, 0.0013606467706114712, 0.0012471392325353982, 0.001144707295902623, 0.0010659734849428342, 0.0010010416645858927, 0.0009320662435296259, 0.0008429478633366291, 0.0007923234571436258, 0.0007140136081462613, 0.0006500106317207582, 0.000590867478360632, 0.0005323729608028058, 0.00047992310845065866, 0.0004398518594612786, 0.00039905907644491713, 0.0003592324901132807, 0.00035348459760009977, 0.00032277414076865835, 0.00031352024898418344, 0.00028247081454460315, 0.0002554219653530307, 0.00022998611108322178, 0.00022392480209148846, 0.00021174074741446832, 0.0002105718731807982, 0.00019380964684019547, 0.00017881792160058006, 0.00034374542685440177, 0.00047276790832912103, 0.0005630284317234231, 0.0006228903008288491, 0.0006567334065522975, 0.0006757127168450852, 0.0006741974314346431, 0.0006639093851041462, 0.0006456173561967063, 0.000619584245160089, 0.0005891465277404493, 0.0005549951947731184, 0.0005213395613940905, 0.0004889496481599361, 0.00045566006113683863, 0.0004241621691921069, 0.000392216614494185, 0.00036243771538817146, 0.00033403610618708144, 0.00030770790708007154, 0.00028250242615464566, 0.0002586712068383796, 0.00023590033246410365, 0.00021720078390099424, 0.00019901019094976667, 0.00018266667985835007, 0.00016744975118960394, 0.00015304525557733486, 0.00013965577573089128, 0.0001271054962549269, 0.00011541084471662194, 0.00010499460237845502, 9.530284625652508e-05, 8.643813481865062e-05, 7.821752188971584e-05, 7.075509284738264e-05, 6.406795865958819e-05, 5.801608676909372e-05, 5.238886524391102e-05, 4.728603770491105e-05, 4.2667641712586786e-05, 3.8507597231410196e-05, 3.469818100958904e-05, 3.125463010355376e-05, 2.8172654059337104e-05, 2.5408124369693456e-05, 2.292233976125995e-05, 2.068076363725362e-05, 1.8620960731478474e-05, 1.6807870054342663e-05, 1.5137401182021405e-05, 1.3625475164910103e-05, 1.2263910947034735e-05, 1.1038758700836363e-05, 9.966624502919954e-06, 8.984002656844875e-06, 8.08980027409825e-06, 7.289504473020725e-06, 6.580062809595388e-06, 5.933035403044941e-06, 5.360218127398669e-06, 4.8256507003852955e-06, 4.346138094259418e-06, 3.911525087778541e-06, 3.525351423716619e-06, 3.176849145564861e-06, 2.8596605011030666e-06, 2.5892398288909852e-06, 2.3304939361313096e-06, 2.099362372361478e-06, 1.890979577298403e-06, 1.7035838052499949e-06, 1.5358348660016522e-06, 1.3828168698354282e-06, 1.2447433094103684e-06, 1.1204375609817027e-06, 1.019820784121653e-06, 9.187001687698642e-07, 8.269855213623014e-07, 7.464117632636838e-07, 6.721932840954464e-07, 6.052420502012825e-07, 5.685094149910274e-07, 5.118343703034655e-07, 4.6323591029266275e-07, 4.1787155359361545e-07, 3.8702645116830405e-07, 3.55930744709842e-07, 3.2450373969484e-07, 2.9311548796321623e-07, 2.6418406943798424e-07, 2.412940124412218e-07, 2.1717010388111364e-07, 1.9635375772809166e-07, 1.7839617356040515e-07, 1.6108160192843625e-07, 1.454241627013614e-07, 1.317650815399958e-07, 1.1943274972169806e-07, 1.0749254616069142e-07, 1.0527481380037312e-07, 9.480599782076938e-08, 9.231825626441855e-08, 8.603868385727247e-08, 7.919258235175947e-08, 7.230562588386856e-08, 7.313447527273895e-08, 6.792963491876287e-08, 6.119292906829324e-08, 6.908215795310533e-08, 6.326209009148179e-08, 6.424475460890297e-08, 5.9589787366469e-08, 5.425181738376513e-08, 5.0454836857098436e-08, 4.7936101405208593e-08, 4.9561277149689206e-08, 5.506646393126422e-08, 4.971805344954186e-08, 5.023710033196137e-08, 4.7906204506824564e-08], "duration": 173355.003316, "accuracy_train": [0.4332561528123846, 0.5114336038436692, 0.5875703312453857, 0.6195589715416205, 0.6443639834809893, 0.6617950293004798, 0.7033164192275747, 0.7223997626545773, 0.7432745521294758, 0.7463183341408269, 0.7602903155569398, 0.7936711612333887, 0.7957212575558323, 0.8082233483873201, 0.8101299704111297, 0.8212420187915282, 0.8248209455172573, 0.8209611984934477, 0.8454177985995754, 0.8410486817667959, 0.8303515552902363, 0.8304699756598376, 0.8408379764211886, 0.8546929794204503, 0.8526711814207272, 0.8525788964447213, 0.857924575777501, 0.8317509704342008, 0.8593650865748431, 0.876500351836471, 0.8779880865863787, 0.86931600250323, 0.8810318685977298, 0.8875172313353636, 0.8868200471806941, 0.8660622361226468, 0.8815437618240125, 0.8730584106220007, 0.8731034716454411, 0.8907477462278516, 0.8855877183116464, 0.8999560564899409, 0.8818198957756552, 0.8980476320251938, 0.8875401223352714, 0.9073231733342562, 0.8995600602159468, 0.9029093559662238, 0.9048374270371908, 0.9108588414774824, 0.9072087183347176, 0.9020486904185124, 0.9099287819536729, 0.9187389330126431, 0.9080915539059615, 0.8935164757521227, 0.9131145963109081, 0.9133471111918604, 0.9113703742155776, 0.9210658842631044, 0.9222974921557769, 0.9069297004775747, 0.9190183113579733, 0.8940272875138427, 0.9196929650009228, 0.9211792577980805, 0.9269449058693245, 0.9305270769887413, 0.929760138369786, 0.9197619984888336, 0.9330382377030271, 0.9188319389650241, 0.9250171952865448, 0.9249249103105389, 0.9202291911798633, 0.9208784304055924, 0.9275977499769288, 0.9251102012389257, 0.9188112108942414, 0.9379668322028424, 0.9286658764765596, 0.9381993470837948, 0.9219708898578812, 0.9199723433462532, 0.9243432626199704, 0.9370832756552234, 0.9353869984888336, 0.940710868286268, 0.9342008121077889, 0.9349670297503692, 0.9737508723814139, 0.9757977243101699, 0.9765417719292175, 0.9772854590600776, 0.9776338708933187, 0.9788887302740864, 0.9783782790005537, 0.9791909996193245, 0.9796331383813216, 0.9795176019172205, 0.9796106078696014, 0.9793552019887413, 0.980005522679033, 0.9807957127860835, 0.9806333128576044, 0.9812847150124585, 0.9808186037859912, 0.9813541089885567, 0.9814700059408453, 0.9819353961909376, 0.9818191387504615, 0.9817490237979882, 0.9813079665005537, 0.9834006004291252, 0.9830285766196014, 0.983679618286268, 0.9838423787029347, 0.9837028697743633, 0.9837261212624585, 0.9835401093576966, 0.9833308459648394, 0.9838423787029347, 0.9836563667981728, 0.983679618286268, 0.9834006004291252, 0.9834471034053157, 0.9837261212624585, 0.9838423787029347, 0.9834471034053157, 0.9834238519172205, 0.9834238519172205, 0.9835168578696014, 0.9832145885243633, 0.9831448340600776, 0.9833537369647471, 0.9834936063815062, 0.9835866123338871, 0.9836331153100776, 0.9832610915005537, 0.9837261212624585, 0.9834006004291252, 0.9832378400124585, 0.9832145885243633, 0.9832378400124585, 0.9837261212624585, 0.9835866123338871, 0.9834471034053157, 0.9835633608457919, 0.9837493727505537, 0.983679618286268, 0.9838423787029347, 0.9835401093576966, 0.9836098638219823, 0.9834471034053157, 0.983679618286268, 0.983679618286268, 0.9835633608457919, 0.9839121331672205, 0.9834936063815062, 0.983679618286268, 0.983679618286268, 0.9834238519172205, 0.98337734894103, 0.9836098638219823, 0.9835866123338871, 0.9835866123338871, 0.983191337036268, 0.9836098638219823, 0.9835633608457919, 0.983679618286268, 0.9836098638219823, 0.9834936063815062, 0.9830285766196014, 0.9834471034053157, 0.9836563667981728, 0.9834006004291252, 0.9831448340600776, 0.9837493727505537, 0.9837028697743633, 0.9834006004291252, 0.9835633608457919, 0.9837028697743633, 0.9835168578696014, 0.9834238519172205, 0.98337734894103, 0.9834238519172205, 0.9835633608457919, 0.9834006004291252, 0.9835866123338871, 0.9834936063815062, 0.9831909765480805, 0.9834936063815062, 0.9837493727505537, 0.983679618286268, 0.9836563667981728, 0.983423491429033, 0.9838191272148394, 0.9837028697743633, 0.9835401093576966, 0.9831680855481728, 0.9836331153100776, 0.9838191272148394, 0.9837028697743633, 0.9834936063815062, 0.9837028697743633, 0.9837493727505537, 0.98386563019103, 0.983284342988649, 0.9836331153100776, 0.9838423787029347, 0.9834471034053157], "end": "2016-02-05 21:41:04.659000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0], "moving_var_accuracy_valid": [0.01672700104080189, 0.03467825462228653, 0.05283031777077166, 0.06798827209438654, 0.07917911773142323, 0.08665682394977872, 0.09304358137222407, 0.09711357640980393, 0.09956548352709396, 0.09949756269463352, 0.09850976339027805, 0.09780834202200811, 0.09531571482198058, 0.09204067291653137, 0.08808411560063772, 0.08389809906801375, 0.0794227907751779, 0.07446568318162192, 0.06988108968264978, 0.06511207779667481, 0.060154397481016655, 0.055439451361354274, 0.0510974339991111, 0.04711421839309289, 0.04334016156397409, 0.039767260155024395, 0.036392877558491736, 0.03296229178257273, 0.030107741288614133, 0.027641576457077807, 0.025263331825682606, 0.022971367077265457, 0.020969836980721447, 0.019117042476296482, 0.017412942811684342, 0.01573825064913674, 0.014265100586876455, 0.012902620049712063, 0.011662220751936845, 0.01059512935540876, 0.009589851815225018, 0.008724806936587238, 0.007879031551266734, 0.0071597300485230315, 0.006464506042032316, 0.005897486348502043, 0.0053390061150472715, 0.004825122645118182, 0.004372467152582588, 0.003970216614244098, 0.0035938879987973556, 0.0032428613929105974, 0.0029388314737942476, 0.002657703647410541, 0.0023950264319284663, 0.0021596225376905183, 0.0019453502202046267, 0.0017529373759740316, 0.001580751454457743, 0.0014390496639891481, 0.0013003036699287525, 0.001171264019319126, 0.0010550238873243815, 0.000982348878149825, 0.0008914647740811862, 0.0008070199052972696, 0.0007354924027495705, 0.0006746761608040475, 0.0006168862543328813, 0.0005556511725706577, 0.0005117794605797233, 0.0004606200720337154, 0.0004189783986581685, 0.00037722166976790494, 0.0003396035993851086, 0.00030564853148203676, 0.00027531471032654934, 0.00024800340030328006, 0.00023037789512407716, 0.0002192576202324225, 0.00019775814094440873, 0.00018050641088577122, 0.00016639664726219902, 0.000151090600397604, 0.0001362654408158814, 0.00012656028498049602, 0.00011754292908477951, 0.00011706849169509474, 0.00010622489768843915, 9.571716611740894e-05, 0.00017513976436150453, 0.00023488035345413058, 0.000271009700805199, 0.0002906417405629057, 0.00030568001545444855, 0.00030773047602045145, 0.00030901672138035, 0.00030180167946221146, 0.00028860222330388135, 0.00027922324025938784, 0.0002643722847438849, 0.0002458213867194496, 0.00023216718842465674, 0.00021666009426376097, 0.00019986047773961049, 0.0001842645213424814, 0.00016835531558193872, 0.00015412516387829005, 0.00014005764034234945, 0.00012839003608036565, 0.00011611899851853333, 0.0001048583628052265, 9.555823262001889e-05, 8.681347522369904e-05, 7.9137943742056e-05, 7.265356610237705e-05, 6.582900768679893e-05, 6.01988756956785e-05, 5.4604855653085624e-05, 4.9861377530390355e-05, 4.5031957339649195e-05, 4.1348881166211244e-05, 3.756839599015823e-05, 3.386755486143289e-05, 3.061224105426545e-05, 2.774667659156336e-05, 2.5001660830645606e-05, 2.253703080791005e-05, 2.0287282167432016e-05, 1.8437319578178587e-05, 1.6692985707312223e-05, 1.5381587347401083e-05, 1.39052020520647e-05, 1.2535495428268894e-05, 1.1290636062994316e-05, 1.0176851549947584e-05, 9.1932029380523e-06, 8.353452499397262e-06, 7.518582162346033e-06, 6.777152647197768e-06, 6.099680062709001e-06, 5.489831561817243e-06, 4.9482735676692645e-06, 4.465249197899665e-06, 4.113676484978652e-06, 3.758771732095008e-06, 3.395583233264713e-06, 3.0707714842655594e-06, 2.78498494532689e-06, 2.583662676243261e-06, 2.399245273931675e-06, 2.2009272966034283e-06, 2.0651399592070955e-06, 1.9433572639641136e-06, 1.8176538911166664e-06, 1.677371245601803e-06, 1.622508109627879e-06, 1.4623754025599645e-06, 1.402777617954688e-06, 1.2691921135554354e-06, 1.3405175863895854e-06, 1.208214703349728e-06, 1.0873942663078547e-06, 9.851084070890393e-07, 9.186655810561842e-07, 9.569706051290098e-07, 8.908755264121977e-07, 1.056139394870397e-06, 1.0488654362829217e-06, 9.526732728374629e-07, 8.775654927374484e-07, 7.902836173902565e-07, 7.11544690410573e-07, 6.408443199843764e-07, 6.062888934242633e-07, 5.456639826107002e-07, 6.284366277468365e-07, 5.988081347122422e-07, 5.422049420812129e-07, 4.880606138628368e-07, 4.418202512575823e-07, 4.345298138397103e-07, 4.3088639680177176e-07, 3.918339038340757e-07, 3.713092121395227e-07, 3.6522777552448256e-07, 4.7417314259227543e-07, 4.797988792563501e-07, 4.351490652088463e-07, 5.148926697507317e-07, 4.910516254714314e-07, 4.473221502670457e-07, 4.0264257050354136e-07, 4.065239043636685e-07, 4.3797284436212897e-07, 4.525776375781247e-07, 4.0734813784596364e-07, 4.36426026647359e-07, 3.9654687352045423e-07, 4.136875280394296e-07, 4.2432817355266214e-07, 3.857213072999907e-07, 3.507938930613952e-07, 3.908238813019947e-07, 3.5183544441991563e-07, 3.779695926836492e-07, 3.522323374381048e-07, 3.1713072634313894e-07, 2.861303116746227e-07, 2.746261413673315e-07, 2.7292984626809913e-07], "accuracy_test": 0.8602479272959183, "start": "2016-02-03 21:31:49.655000", "learning_rate_per_epoch": [0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 0.0001899522467283532, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-05, 1.899522430903744e-06, 1.8995224593254534e-07, 1.8995224948525902e-08, 1.899522539261511e-09, 1.89952248375036e-10, 1.899522553139299e-11, 1.8995226398754728e-12, 1.8995226127704185e-13, 1.8995225450077827e-14, 1.8995226297110774e-15, 1.8995226032412978e-16, 1.8995226694157468e-17, 1.8995226694157468e-18, 1.899522695265141e-19, 1.899522695265141e-20, 1.8995227356548193e-21, 1.8995227861419172e-22, 1.8995227861419172e-23, 1.8995228255849625e-24, 1.8995228255849625e-25, 1.8995228255849625e-26, 1.8995227485477647e-27, 1.8995227966960133e-28, 1.8995227365107026e-29, 1.8995226988948833e-30, 1.8995226988948833e-31, 1.899522757669601e-32, 1.8995228311379978e-33, 1.8995228770557459e-34, 1.8995228196585608e-35, 1.899522891405042e-36, 1.8995228465634913e-37, 1.8995228465634913e-38, 1.899523126823184e-39, 1.8995161203308625e-40, 1.8994600683922895e-41, 1.900160717624452e-42, 1.9057659114817512e-43, 1.961817850054744e-44, 1.401298464324817e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_train_first": 0.4332561528123846, "accuracy_train_last": 0.9834471034053157, "batch_size_eval": 1024, "accuracy_train_std": [0.014830205255058397, 0.01809302639168476, 0.01599239852993491, 0.01613277526543918, 0.014819398117256556, 0.014989211101376196, 0.015420805586989744, 0.0147443222558632, 0.014118945201089951, 0.015111684586748565, 0.015040878869720364, 0.015593124322341412, 0.013473690987221966, 0.015844489372469205, 0.014417436843441057, 0.014560753657859485, 0.016230128696807972, 0.017259778152798937, 0.015945217378123194, 0.014639950427127155, 0.01666828150235572, 0.015669341734767327, 0.017175211342142643, 0.01787771651033148, 0.015924864322135496, 0.015836891153356156, 0.01684198971954244, 0.015624279486274466, 0.017966295041396473, 0.01644655618637995, 0.01621301295403238, 0.016357263806999308, 0.016963349282661307, 0.018311494770499398, 0.01693173147346012, 0.01650261334722603, 0.017341343380047416, 0.017437881360532384, 0.016773211732944115, 0.017814752184287096, 0.0188826407535004, 0.01607429049569894, 0.01868840188533143, 0.017790483850754324, 0.018903593801417193, 0.017892356082880142, 0.017218263843852492, 0.01557243919398623, 0.016705823946543852, 0.01709488544866656, 0.016852203942668897, 0.016844925566765884, 0.01646804854634207, 0.016610969682677584, 0.015534568498733869, 0.0159820403588154, 0.01508860905053595, 0.015647865558302915, 0.016298517672521627, 0.015121317190180353, 0.01646694512629765, 0.017522106551050343, 0.016664989243082268, 0.017848537959923482, 0.016692229022853004, 0.017230791504289744, 0.0163707802570734, 0.015583934374767468, 0.015442775249234385, 0.015888900520684705, 0.014764346553566697, 0.016995627747630564, 0.014509428274660502, 0.014912025960801838, 0.013874921927641243, 0.016086543272828286, 0.015151023588268248, 0.014695928359827928, 0.016208411337639114, 0.013921036487282375, 0.01566996793015162, 0.013470123539439664, 0.01565946603929757, 0.013817568167738421, 0.015587404874988178, 0.01437676690867838, 0.012882002150979998, 0.014162676005082524, 0.014872650711174013, 0.015253940210533891, 0.007673243622823776, 0.0074911592414058144, 0.007101754454518051, 0.00670890472550356, 0.007169315645003187, 0.006724349329446254, 0.00661485877699303, 0.00659313575614353, 0.006330178002807448, 0.0066107662646282105, 0.005832312642690893, 0.00611481421197993, 0.0064533860536008045, 0.005891806552250911, 0.006003625961128021, 0.00616008036512608, 0.006621507448876889, 0.005926870958373746, 0.005302681989942226, 0.005540327347290464, 0.005148216064802977, 0.005646850080200799, 0.005553951154258718, 0.004810048136004061, 0.004441849858414444, 0.004657801330433911, 0.004867114082451189, 0.0046343433274410265, 0.004640103450583965, 0.004500608168287549, 0.004544995843444253, 0.0045587677589113825, 0.004762775366658768, 0.004686959740589626, 0.0046075171663124215, 0.004728866387722978, 0.0046596364968595205, 0.0046475583490729975, 0.004771885882657953, 0.004731448649411373, 0.004707392166432136, 0.004730034759986742, 0.004844179167267036, 0.004467824778368801, 0.004627346278783735, 0.004761657275158651, 0.004867394353835355, 0.004827893887382554, 0.004669124651096852, 0.004600788577041236, 0.0045379986293805205, 0.004621944751132627, 0.004628442932964975, 0.004953916397209714, 0.004679088002336493, 0.004720563827815691, 0.004856781856894386, 0.004456717856999873, 0.004699196145490642, 0.004657801330433911, 0.004758602636259556, 0.00456074891182235, 0.0045704849982294024, 0.004646520767980485, 0.004830112161274139, 0.004667541039901409, 0.0046706633096809756, 0.004825080525192473, 0.004728159109766636, 0.004478866260237682, 0.004978272943144109, 0.004600049307289475, 0.004831198795713768, 0.0045952582552529165, 0.004706111310245847, 0.004787432060101332, 0.004760488740806286, 0.0048873914572414605, 0.00453750405618306, 0.004763843050824005, 0.004510474073399367, 0.004640910841518183, 0.0044520620267543935, 0.004771885882657953, 0.004719672830724334, 0.004661411602445099, 0.004508299319221642, 0.004399734157041014, 0.004594979170258454, 0.004651659059092547, 0.004814300326421318, 0.004731321097782035, 0.0044326566604601944, 0.004629571471055442, 0.004459718493309781, 0.004678361105394769, 0.004656055902192543, 0.004810048136004061, 0.004758889298352087, 0.0046701747092627146, 0.004712900734658586, 0.004732959077570314, 0.004516875147091369, 0.004677260467895278, 0.0048337589031251585, 0.004746190478486181, 0.00475355481837317, 0.004530282966900735, 0.004698084332139758, 0.004851560197924792, 0.004626144264397008, 0.004543514247339857, 0.004779072081186632, 0.004679888667522883, 0.004707263962949958, 0.004860708646392881, 0.0046281386830721045, 0.0046036393241936984, 0.00475682283121157, 0.00459350137895832, 0.004833349220988322], "accuracy_test_std": 0.007153920094956912, "error_valid": [0.5688903073230421, 0.4899372882153614, 0.4200704183923193, 0.38460825724774095, 0.36643890013177716, 0.3552187264683735, 0.3184946818524097, 0.30106804169804224, 0.28038668345256024, 0.27977633189006024, 0.2625423569277108, 0.22770084243222888, 0.23009077324924698, 0.22254300404743976, 0.21837202324924698, 0.20906379423945776, 0.2044751270707832, 0.2100506518260542, 0.19563605986445776, 0.1991040333207832, 0.2090432040662651, 0.20707978397966864, 0.19970408979668675, 0.1918312900037651, 0.1904679263930723, 0.19035615116716864, 0.19131212349397586, 0.21678510918674698, 0.1900708301957832, 0.17532973691641573, 0.17985810429216864, 0.18776178934487953, 0.1763783650225903, 0.17586949359939763, 0.1747208560805723, 0.19074295227786142, 0.18178034403237953, 0.18520860786897586, 0.1856762989457832, 0.17367222797439763, 0.1789933170180723, 0.16877912038780118, 0.18063023578689763, 0.16852468467620485, 0.17818882953689763, 0.16214614316641573, 0.17024396413780118, 0.1721059040850903, 0.16731427663780118, 0.16398749294051207, 0.16657155967620485, 0.17057928981551207, 0.16425222373870485, 0.16584943288780118, 0.17070136012801207, 0.1827260212725903, 0.17231915945030118, 0.17136318712349397, 0.1698571630271084, 0.16165786191641573, 0.16622593891189763, 0.17635777484939763, 0.17023366905120485, 0.19215632059487953, 0.16593032285391573, 0.16683629047439763, 0.16324477597891573, 0.16043715879141573, 0.1607724844691265, 0.1723500447100903, 0.15893113469503017, 0.16964390766189763, 0.16222703313253017, 0.1697865681475903, 0.1697350927146084, 0.16852468467620485, 0.1671407308923193, 0.1670186605798193, 0.1773549275225903, 0.15781191170933728, 0.16599209337349397, 0.1626550145896084, 0.17403843891189763, 0.1719323583396084, 0.17024396413780118, 0.1620446630271084, 0.1616269766566265, 0.1561544027673193, 0.16313300075301207, 0.1670495458396084, 0.13458766707454817, 0.1335905144013554, 0.13422145613704817, 0.1345979621611446, 0.13296986775225905, 0.13385524519954817, 0.13211537556475905, 0.13287868269954817, 0.1337434699736446, 0.1313932487763554, 0.13258306664156627, 0.13406850056475905, 0.13147413874246983, 0.13213596573795183, 0.13311252823795183, 0.13274631730045183, 0.1337434699736446, 0.13312282332454817, 0.13409938582454817, 0.13248158650225905, 0.13455678181475905, 0.1348421027861446, 0.13299045792545183, 0.1332551887236446, 0.1326139519013554, 0.1316373894013554, 0.1330110480986446, 0.13174916462725905, 0.13250217667545183, 0.1316373894013554, 0.1328580925263554, 0.1310270378388554, 0.1317594597138554, 0.13275661238704817, 0.13225803605045183, 0.13187123493975905, 0.13262424698795183, 0.13251247176204817, 0.13286838761295183, 0.13164768448795183, 0.13396702042545183, 0.1310270378388554, 0.13199330525225905, 0.13225803605045183, 0.13238010636295183, 0.1322477409638554, 0.1320036003388554, 0.13161679922816272, 0.13239040144954817, 0.13211537556475905, 0.1323698112763554, 0.13238010636295183, 0.1321256706513554, 0.13274631730045183, 0.1313932487763554, 0.13152561417545183, 0.1326139519013554, 0.13187123493975905, 0.13174916462725905, 0.13126088337725905, 0.13300075301204817, 0.13150502400225905, 0.1311491081513554, 0.13299045792545183, 0.13299045792545183, 0.13152561417545183, 0.13101674275225905, 0.13187123493975905, 0.13299045792545183, 0.13238010636295183, 0.13065053181475905, 0.1321256706513554, 0.1320036003388554, 0.13226833113704817, 0.13262424698795183, 0.13088437735316272, 0.1313932487763554, 0.1335905144013554, 0.13312282332454817, 0.13187123493975905, 0.13262424698795183, 0.1321256706513554, 0.1322477409638554, 0.1321256706513554, 0.13161679922816272, 0.1321256706513554, 0.13336696394954817, 0.13164768448795183, 0.1320036003388554, 0.13214626082454817, 0.1320036003388554, 0.1315153190888554, 0.13275661238704817, 0.1323698112763554, 0.13263454207454817, 0.1316373894013554, 0.13089467243975905, 0.1312711784638554, 0.13176975480045183, 0.13077260212725905, 0.13238010636295183, 0.1321256706513554, 0.1318815300263554, 0.13260365681475905, 0.13286838761295183, 0.13286838761295183, 0.1321256706513554, 0.13126088337725905, 0.13225803605045183, 0.13286838761295183, 0.1313932487763554, 0.13187123493975905, 0.13225803605045183, 0.13299045792545183, 0.13213596573795183, 0.13299045792545183, 0.1318815300263554, 0.1322477409638554, 0.1321256706513554, 0.13176975480045183, 0.13162709431475905], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.03116058439051238, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.00018995224650230632, "optimization": "rmsprop", "nb_data_augmentation": 3, "learning_rate_decay_method": "discrete", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.2374882111182177e-05, "rotation_range": [0, 0], "momentum": 0.5716738475375452}, "accuracy_valid_max": 0.869349468185241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.868372905685241, "accuracy_valid_std": [0.016146844197327814, 0.020332331081435007, 0.012401705685036379, 0.011005476463228614, 0.010399889019327346, 0.009859642253945805, 0.011359106656206416, 0.011248158910911243, 0.009829284149952988, 0.009823428467108899, 0.013425516020226992, 0.010795240657478132, 0.01218585204417809, 0.008214380988005388, 0.013936786378540905, 0.015152307113537409, 0.013754205183651336, 0.012321984826632, 0.011098882539714458, 0.014503696032115512, 0.016895904473299424, 0.013435325479837248, 0.01799064577748416, 0.016324857534281596, 0.013307161771956967, 0.015952317613911488, 0.013639963998639492, 0.017527748844258405, 0.01627785912345407, 0.01468308551649707, 0.012710568086292565, 0.0122084441290008, 0.010324797365651733, 0.00916676352960054, 0.009816983875825377, 0.01083367074712189, 0.009157294429946358, 0.009395769447085416, 0.010854024902787428, 0.008326906252300785, 0.009005584899766201, 0.011415069650139007, 0.009585234505778658, 0.008970724217631912, 0.012252514146618328, 0.008874487855756856, 0.008076236550417677, 0.010534400076022073, 0.005491626179863679, 0.0071507182272535575, 0.007637199601252633, 0.007756820277080378, 0.008518992047830813, 0.0074284490379569745, 0.00953247417932199, 0.0110196290893608, 0.009733915240683807, 0.007306617396364911, 0.008969291357643915, 0.008293302164531665, 0.006974419499094725, 0.008215381686785468, 0.008994348602580313, 0.008350809786311104, 0.008918309394147837, 0.010402593844477765, 0.010385909688253796, 0.0106037550968666, 0.009044905206540024, 0.009907827687704185, 0.010223542956839807, 0.0071093385557070045, 0.012855821508150128, 0.007810774363537644, 0.0058143490831949335, 0.00893076912989598, 0.010503657440374936, 0.011803221649237559, 0.00772391307406888, 0.012025901196778892, 0.008636639899399265, 0.008015133608725114, 0.01250837440826269, 0.013282579786020626, 0.010535746960031, 0.008303411672403479, 0.0084876378232003, 0.006237474859173352, 0.007893957601800698, 0.008861162036567045, 0.010897914924292403, 0.01074968098119357, 0.009076325480890008, 0.0076633609275346334, 0.01194854678025325, 0.009013931781283622, 0.009794597421838604, 0.010373344347116887, 0.009833201326038194, 0.009079482504516807, 0.012080751799898384, 0.010594675077124192, 0.012836171644592876, 0.00682907657246404, 0.008818161100866518, 0.011091705131963727, 0.008394391259479597, 0.010852020615037086, 0.009684793773435684, 0.010691642535797682, 0.01160275899385007, 0.010890014969499175, 0.010345268921643079, 0.009610191982632408, 0.01032399065742571, 0.00999990553869423, 0.009923346531244284, 0.010621356061404784, 0.010073546058824106, 0.010465890021726295, 0.010302683563296803, 0.00999896294203739, 0.010172942183826762, 0.010390628351401672, 0.010133889281429422, 0.010849288874249425, 0.010094296381477831, 0.009734744073065264, 0.009698418535927837, 0.009313709565402119, 0.00966051626768873, 0.009951160012773927, 0.011273911665931509, 0.010192536723690424, 0.009991793920187175, 0.00991555491504532, 0.010939787661496395, 0.011597402438065113, 0.00956339067002301, 0.010522171380479615, 0.010374021593941015, 0.010239274188370102, 0.010256646409598166, 0.009753509572433282, 0.010750683003648837, 0.009766606505673122, 0.010653587277934069, 0.010203784105326968, 0.0103714992090298, 0.010883497202096463, 0.009810725324343348, 0.011259570442010161, 0.0099782662610357, 0.009566994377520694, 0.010310641751307697, 0.010219907467414562, 0.010768674539862483, 0.010947732015756799, 0.009825180485906882, 0.009786870281083878, 0.010639722121335876, 0.010666858226262276, 0.010585346453819013, 0.009323612220003118, 0.00933342742687913, 0.011011109483893625, 0.010204562374157402, 0.0102035067207583, 0.010171589683186013, 0.010469041856228259, 0.009358937156056915, 0.010186671885209298, 0.01001127254179467, 0.010520571414655141, 0.011881728137155908, 0.01024501717872749, 0.009290984224574665, 0.008773256187157586, 0.010437917321911419, 0.009916919432359872, 0.010574078729056125, 0.010097588518407814, 0.009957091448319355, 0.010176797540819406, 0.009707087289226504, 0.009987977383019346, 0.01068642740593966, 0.010332082435059838, 0.009880500506786575, 0.010165894044849523, 0.00984758461726888, 0.010383708390630013, 0.010880886179105254, 0.011443216314821739, 0.010580203945607373, 0.010880166228803126, 0.010733702804428142, 0.011014151546862803, 0.009589936178551962, 0.01025987306528702, 0.010616786806549578, 0.010783160835409205, 0.009713447467285518, 0.009776527873649169, 0.009724115447278033, 0.010459864953818943, 0.009965951922145657, 0.010812718365110658, 0.010429528956671359, 0.010107138233324974, 0.0104897714455032], "accuracy_valid": [0.43110969267695787, 0.5100627117846386, 0.5799295816076807, 0.615391742752259, 0.6335610998682228, 0.6447812735316265, 0.6815053181475903, 0.6989319583019578, 0.7196133165474398, 0.7202236681099398, 0.7374576430722892, 0.7722991575677711, 0.769909226750753, 0.7774569959525602, 0.781627976750753, 0.7909362057605422, 0.7955248729292168, 0.7899493481739458, 0.8043639401355422, 0.8008959666792168, 0.7909567959337349, 0.7929202160203314, 0.8002959102033133, 0.8081687099962349, 0.8095320736069277, 0.8096438488328314, 0.8086878765060241, 0.783214890813253, 0.8099291698042168, 0.8246702630835843, 0.8201418957078314, 0.8122382106551205, 0.8236216349774097, 0.8241305064006024, 0.8252791439194277, 0.8092570477221386, 0.8182196559676205, 0.8147913921310241, 0.8143237010542168, 0.8263277720256024, 0.8210066829819277, 0.8312208796121988, 0.8193697642131024, 0.8314753153237951, 0.8218111704631024, 0.8378538568335843, 0.8297560358621988, 0.8278940959149097, 0.8326857233621988, 0.8360125070594879, 0.8334284403237951, 0.8294207101844879, 0.8357477762612951, 0.8341505671121988, 0.8292986398719879, 0.8172739787274097, 0.8276808405496988, 0.828636812876506, 0.8301428369728916, 0.8383421380835843, 0.8337740610881024, 0.8236422251506024, 0.8297663309487951, 0.8078436794051205, 0.8340696771460843, 0.8331637095256024, 0.8367552240210843, 0.8395628412085843, 0.8392275155308735, 0.8276499552899097, 0.8410688653049698, 0.8303560923381024, 0.8377729668674698, 0.8302134318524097, 0.8302649072853916, 0.8314753153237951, 0.8328592691076807, 0.8329813394201807, 0.8226450724774097, 0.8421880882906627, 0.834007906626506, 0.8373449854103916, 0.8259615610881024, 0.8280676416603916, 0.8297560358621988, 0.8379553369728916, 0.8383730233433735, 0.8438455972326807, 0.8368669992469879, 0.8329504541603916, 0.8654123329254518, 0.8664094855986446, 0.8657785438629518, 0.8654020378388554, 0.867030132247741, 0.8661447548004518, 0.867884624435241, 0.8671213173004518, 0.8662565300263554, 0.8686067512236446, 0.8674169333584337, 0.865931499435241, 0.8685258612575302, 0.8678640342620482, 0.8668874717620482, 0.8672536826995482, 0.8662565300263554, 0.8668771766754518, 0.8659006141754518, 0.867518413497741, 0.865443218185241, 0.8651578972138554, 0.8670095420745482, 0.8667448112763554, 0.8673860480986446, 0.8683626105986446, 0.8669889519013554, 0.868250835372741, 0.8674978233245482, 0.8683626105986446, 0.8671419074736446, 0.8689729621611446, 0.8682405402861446, 0.8672433876129518, 0.8677419639495482, 0.868128765060241, 0.8673757530120482, 0.8674875282379518, 0.8671316123870482, 0.8683523155120482, 0.8660329795745482, 0.8689729621611446, 0.868006694747741, 0.8677419639495482, 0.8676198936370482, 0.8677522590361446, 0.8679963996611446, 0.8683832007718373, 0.8676095985504518, 0.867884624435241, 0.8676301887236446, 0.8676198936370482, 0.8678743293486446, 0.8672536826995482, 0.8686067512236446, 0.8684743858245482, 0.8673860480986446, 0.868128765060241, 0.868250835372741, 0.868739116622741, 0.8669992469879518, 0.868494975997741, 0.8688508918486446, 0.8670095420745482, 0.8670095420745482, 0.8684743858245482, 0.868983257247741, 0.868128765060241, 0.8670095420745482, 0.8676198936370482, 0.869349468185241, 0.8678743293486446, 0.8679963996611446, 0.8677316688629518, 0.8673757530120482, 0.8691156226468373, 0.8686067512236446, 0.8664094855986446, 0.8668771766754518, 0.868128765060241, 0.8673757530120482, 0.8678743293486446, 0.8677522590361446, 0.8678743293486446, 0.8683832007718373, 0.8678743293486446, 0.8666330360504518, 0.8683523155120482, 0.8679963996611446, 0.8678537391754518, 0.8679963996611446, 0.8684846809111446, 0.8672433876129518, 0.8676301887236446, 0.8673654579254518, 0.8683626105986446, 0.869105327560241, 0.8687288215361446, 0.8682302451995482, 0.869227397872741, 0.8676198936370482, 0.8678743293486446, 0.8681184699736446, 0.867396343185241, 0.8671316123870482, 0.8671316123870482, 0.8678743293486446, 0.868739116622741, 0.8677419639495482, 0.8671316123870482, 0.8686067512236446, 0.868128765060241, 0.8677419639495482, 0.8670095420745482, 0.8678640342620482, 0.8670095420745482, 0.8681184699736446, 0.8677522590361446, 0.8678743293486446, 0.8682302451995482, 0.868372905685241], "seed": 218807926, "model": "residualv3", "loss_std": [0.30671897530555725, 0.17513565719127655, 0.1736801415681839, 0.1733049601316452, 0.1727408617734909, 0.1739911437034607, 0.1732567548751831, 0.17343559861183167, 0.17100250720977783, 0.16995015740394592, 0.16785717010498047, 0.1659591645002365, 0.1656850427389145, 0.16083204746246338, 0.16051074862480164, 0.15907888114452362, 0.15711943805217743, 0.1556842178106308, 0.1550878882408142, 0.15125906467437744, 0.15118207037448883, 0.15013638138771057, 0.14837931096553802, 0.14498122036457062, 0.14633792638778687, 0.14529962837696075, 0.1432749330997467, 0.14064231514930725, 0.13901591300964355, 0.13986684381961823, 0.1398272067308426, 0.13559916615486145, 0.13599197566509247, 0.1338190883398056, 0.13257034122943878, 0.13187138736248016, 0.12937414646148682, 0.1288284808397293, 0.12918636202812195, 0.12517493963241577, 0.1263773888349533, 0.12397139519453049, 0.12267936766147614, 0.12347491830587387, 0.123135507106781, 0.1225525438785553, 0.12067902088165283, 0.11744458973407745, 0.11849885433912277, 0.11711437255144119, 0.11672418564558029, 0.11478230357170105, 0.11568944901227951, 0.11153809726238251, 0.11099264770746231, 0.11162986606359482, 0.108531154692173, 0.10725775361061096, 0.1095280572772026, 0.10802772641181946, 0.10912076383829117, 0.10462227463722229, 0.10442836582660675, 0.10458334535360336, 0.10450386255979538, 0.10250837355852127, 0.10157977044582367, 0.10219284147024155, 0.10120079666376114, 0.09897882491350174, 0.10077362507581711, 0.09800243377685547, 0.09893020987510681, 0.09609927982091904, 0.09635777026414871, 0.09289165586233139, 0.09211947023868561, 0.09096143394708633, 0.09232725203037262, 0.09044931828975677, 0.09087511152029037, 0.08911105245351791, 0.09083164483308792, 0.08997628837823868, 0.08814612776041031, 0.0866551622748375, 0.08982054144144058, 0.08490662276744843, 0.08641830831766129, 0.08622746914625168, 0.0787288025021553, 0.0699365884065628, 0.06700029224157333, 0.06581944227218628, 0.06588641554117203, 0.0664551630616188, 0.06531798094511032, 0.061802905052900314, 0.06274963915348053, 0.06332258135080338, 0.06250298023223877, 0.06213824078440666, 0.06050528585910797, 0.06179230287671089, 0.06228019297122955, 0.06008491665124893, 0.060762934386730194, 0.06163971498608589, 0.05841441452503204, 0.058893635869026184, 0.05919657275080681, 0.05988762900233269, 0.0586630180478096, 0.06072021275758743, 0.0591258630156517, 0.057882193475961685, 0.058685947209596634, 0.058176811784505844, 0.057499710470438004, 0.0575055293738842, 0.058718908578157425, 0.05714359134435654, 0.05782188102602959, 0.058218710124492645, 0.0571354441344738, 0.05676259845495224, 0.05684183910489082, 0.058266691863536835, 0.05791553854942322, 0.059679675847291946, 0.05677398294210434, 0.05836150422692299, 0.05724972113966942, 0.05834178626537323, 0.0581340454518795, 0.057327646762132645, 0.0587662011384964, 0.05864318832755089, 0.056794073432683945, 0.05825069174170494, 0.05736324191093445, 0.05742116644978523, 0.0577087327837944, 0.05816219747066498, 0.05762682482600212, 0.05858924984931946, 0.057041265070438385, 0.05715613812208176, 0.0580165833234787, 0.056759707629680634, 0.0574289932847023, 0.058793261647224426, 0.057128287851810455, 0.059155598282814026, 0.05696532502770424, 0.058191437274217606, 0.0578279010951519, 0.05406073108315468, 0.05968423932790756, 0.05749282240867615, 0.05893339589238167, 0.0574219711124897, 0.0600019246339798, 0.05908956378698349, 0.057297028601169586, 0.05956152081489563, 0.05715196207165718, 0.05892765149474144, 0.05980096384882927, 0.05688431113958359, 0.05762548744678497, 0.05843191221356392, 0.05701671168208122, 0.058171603828668594, 0.057434406131505966, 0.05733364075422287, 0.0585145503282547, 0.05869102478027344, 0.05726764723658562, 0.05794363096356392, 0.057159315794706345, 0.05762076750397682, 0.05734363943338394, 0.05739424377679825, 0.05777221918106079, 0.058882780373096466, 0.05653057619929314, 0.05784175917506218, 0.057833462953567505, 0.05939574912190437, 0.05720730870962143, 0.05804188549518585, 0.058368660509586334, 0.05765524506568909, 0.058671507984399796, 0.05841512605547905, 0.05912861227989197, 0.05755803361535072, 0.05860205367207527, 0.05903208255767822, 0.05649423971772194, 0.05754491686820984, 0.058069005608558655, 0.05917693302035332, 0.05889277532696724, 0.0574815571308136, 0.057225968688726425, 0.05802088603377342, 0.05828915163874626, 0.05696495622396469, 0.05806238204240799]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:41 2016", "state": "available"}], "summary": "8c8f1a9faf56dfd1ac3e6e544ae9e0c2"}