{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 16, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.6670578718185425, 1.2520276308059692, 1.0325342416763306, 0.8842054009437561, 0.785277247428894, 0.7100792527198792, 0.6502411365509033, 0.6025866270065308, 0.5631250143051147, 0.5274369120597839, 0.49801796674728394, 0.46973931789398193, 0.44501906633377075, 0.4256504476070404, 0.4064789116382599, 0.38741981983184814, 0.3730880916118622, 0.35572758316993713, 0.342833012342453, 0.3303905129432678, 0.315647691488266, 0.30210793018341064, 0.29123935103416443, 0.28224000334739685, 0.269829660654068, 0.2608238160610199, 0.25364553928375244, 0.2445024996995926, 0.2346140444278717, 0.22668015956878662, 0.2218509465456009, 0.21353460848331451, 0.2050570547580719, 0.1993499994277954, 0.1938645839691162, 0.1867050975561142, 0.1811874806880951, 0.1802557408809662, 0.17000342905521393, 0.16655036807060242, 0.16636528074741364, 0.1559440642595291, 0.15147647261619568, 0.14917340874671936, 0.14388127624988556, 0.1396959275007248, 0.13715633749961853, 0.13545826077461243, 0.13054752349853516, 0.1265249103307724, 0.12500351667404175, 0.12115781754255295, 0.11999054998159409, 0.11718624085187912, 0.1119762659072876, 0.10650118440389633, 0.10918537527322769, 0.1047448143362999, 0.10478483140468597, 0.10459070652723312, 0.10207964479923248, 0.09682026505470276, 0.09281618893146515, 0.09466356784105301, 0.09091532975435257, 0.09032846242189407, 0.08927084505558014, 0.08913014084100723, 0.08546953648328781, 0.08285464346408844, 0.08112090826034546, 0.07972287386655807, 0.08005428314208984, 0.07812433689832687, 0.07663579285144806, 0.07477608323097229, 0.07247558981180191, 0.07151255756616592, 0.0690557211637497, 0.07408832758665085, 0.0679817944765091, 0.06663070619106293, 0.06706952303647995, 0.06631270051002502, 0.06732872128486633, 0.06240638345479965, 0.06147807836532593, 0.06309594213962555, 0.06152665615081787, 0.061340756714344025, 0.060289449989795685, 0.0589870922267437, 0.056841082870960236, 0.055850204080343246, 0.055330973118543625, 0.05430665612220764, 0.05635327845811844, 0.0530884712934494, 0.05391790717840195, 0.05032562091946602, 0.05372973531484604, 0.051489125937223434, 0.04993542656302452, 0.05225808918476105, 0.047318194061517715, 0.05016790330410004, 0.04704601317644119, 0.0486142598092556, 0.04360329732298851, 0.05016468092799187, 0.04736023396253586, 0.044564004987478256, 0.04510421305894852, 0.04593989998102188, 0.04504723846912384, 0.04528419300913811, 0.04502563923597336, 0.042575106024742126, 0.046324990689754486, 0.04112865403294563, 0.041017670184373856, 0.04320808872580528, 0.041938625276088715, 0.038517434149980545, 0.04006972163915634, 0.03922161087393761, 0.03846452012658119, 0.03872434422373772, 0.03924456611275673, 0.03886895999312401, 0.03624550998210907, 0.037681326270103455, 0.03863757848739624, 0.03519797325134277, 0.034106869250535965, 0.036923546344041824, 0.03787713497877121, 0.03479136526584625, 0.03632308170199394, 0.03724517300724983, 0.033611539751291275, 0.0350014753639698, 0.03575161099433899, 0.034560441970825195, 0.03302598372101784, 0.03499931842088699, 0.03398805111646652, 0.03372545912861824, 0.03137809783220291, 0.03257299214601517, 0.032382648438215256, 0.032586511224508286, 0.034474555402994156, 0.03772397339344025, 0.031560268253088, 0.029223918914794922, 0.031613789498806, 0.030696433037519455, 0.03255916386842728, 0.03262250870466232, 0.03322545811533928, 0.028652094304561615, 0.030811337754130363, 0.031752023845911026, 0.02939344197511673, 0.029900463297963142, 0.03190745785832405, 0.02864377573132515, 0.030216693878173828, 0.027610067278146744, 0.03014586679637432, 0.026694320142269135, 0.029126450419425964, 0.02885977365076542, 0.029005948454141617, 0.029956573620438576, 0.02730284444987774, 0.02934836968779564, 0.025984106585383415, 0.026341229677200317, 0.028225162997841835, 0.02986680530011654, 0.025570953264832497, 0.02604716084897518, 0.028139036148786545, 0.027179833501577377, 0.02370583452284336, 0.02499411441385746, 0.025365907698869705, 0.02610623650252819, 0.02948840707540512, 0.027770427986979485, 0.024479076266288757, 0.023972038179636, 0.028497589752078056, 0.025048689916729927, 0.02478501759469509, 0.024245258420705795, 0.024613259360194206, 0.02438204735517502, 0.02545422501862049, 0.024509530514478683, 0.027039382606744766, 0.026200121268630028, 0.02681523934006691, 0.021674584597349167, 0.023739438503980637, 0.024066148325800896, 0.0254680123180151, 0.025503622367978096, 0.0241361353546381, 0.023917313665151596, 0.023258643224835396, 0.023057179525494576, 0.02398449182510376, 0.026951435953378677, 0.021505694836378098, 0.023508837446570396, 0.02403612993657589, 0.021698392927646637, 0.024606842547655106, 0.02306881546974182, 0.022470729425549507, 0.0231011975556612, 0.024276170879602432, 0.023637738078832626, 0.022591589018702507, 0.0218674149364233, 0.02169722132384777, 0.02102081850171089, 0.02223193272948265, 0.02221550978720188, 0.022218573838472366, 0.02307806722819805, 0.020595412701368332, 0.021794280037283897, 0.021870151162147522, 0.022988582029938698, 0.023028919473290443], "moving_avg_accuracy_train": [0.025829321099806197, 0.05560067245466499, 0.08959686587964884, 0.12621438576778213, 0.16886869181540407, 0.2154477687567411, 0.26527518295710983, 0.30762318664829436, 0.3487560733463756, 0.391113095527934, 0.4271070485258973, 0.45978534647646374, 0.4960607534066598, 0.5281666076294859, 0.5591823039978588, 0.5898027597484052, 0.6109103599790373, 0.6356347807052477, 0.6600000672849629, 0.6755176869868837, 0.6991516035906593, 0.7165214300521453, 0.7340718006589647, 0.7531082474503035, 0.764691784525825, 0.7759539133187666, 0.7909486692679438, 0.799447601367543, 0.8115393507534446, 0.8207692490806473, 0.8278231907573463, 0.8390676364875825, 0.8470185261472406, 0.8562040736051909, 0.8654498097708807, 0.8694582899129787, 0.8731732754231112, 0.880333863653456, 0.8863482765798232, 0.8799727257248586, 0.8879413560166678, 0.8935322383817323, 0.8990544226161874, 0.9037106735820051, 0.9086754658583561, 0.9133809080368247, 0.9140727478463758, 0.9181758630522789, 0.92210332652326, 0.9245105267186176, 0.9286161089039449, 0.9316064685861787, 0.9351511579621031, 0.9378344599111401, 0.939996026493854, 0.9427226503694779, 0.9451232415813766, 0.9472395597958857, 0.9453198810807397, 0.9462866572191589, 0.9476194243080127, 0.9497627809093727, 0.9502014175125107, 0.9522400346148495, 0.9542235634819451, 0.9561203466051884, 0.9486005579879512, 0.95068761785107, 0.9523404322933532, 0.9531514190854742, 0.9550926736793262, 0.9574582563483075, 0.9592478090242003, 0.9612513565813133, 0.9629917343160391, 0.9643023439570635, 0.9650168628720807, 0.9661180563087098, 0.9651980383243413, 0.9669204940895446, 0.9678360107508651, 0.9690389029043684, 0.9702725684175031, 0.9689257618687576, 0.9700847109795009, 0.9709510899184648, 0.9718540998992558, 0.9731015396117112, 0.9738894139243496, 0.9748008248009715, 0.9758233464875411, 0.9762717189435766, 0.9766054636409041, 0.9772731713315848, 0.9779229363781975, 0.9783031478737295, 0.978926645176842, 0.9794319531293959, 0.9803261834116944, 0.9804683232550488, 0.9807985370604964, 0.9814654641949321, 0.9822493853718767, 0.982234190397812, 0.9825622396985163, 0.9828458222762838, 0.9832219543343697, 0.9831351151497791, 0.9836171765514679, 0.9840766084498924, 0.9845575264739508, 0.984802015642032, 0.9849825283635429, 0.9845033208391119, 0.984962638158809, 0.9852131191345949, 0.9853804232925639, 0.9857100334930695, 0.9859834311854292, 0.9838838465455685, 0.984449144926726, 0.982402863318651, 0.9829628362498903, 0.983431934655863, 0.9841448028712475, 0.984630527197218, 0.9853421187477528, 0.9859127966789483, 0.9861705683503391, 0.9864909545581716, 0.9867420997642684, 0.9858683350628508, 0.9863979450089466, 0.9870699425092516, 0.9873771212119071, 0.987660521441907, 0.9878830295655734, 0.9882344575983111, 0.9880810627682511, 0.9883429330164353, 0.9884507691040959, 0.9887593380270197, 0.9889650425421932, 0.9891524657058403, 0.9895001469626371, 0.9894015087544685, 0.9897987265171262, 0.9902143872725749, 0.9904372751822222, 0.9906006719199524, 0.9903896921160616, 0.9867383486427352, 0.9847375863202207, 0.985245448558446, 0.985832732906182, 0.9865473007239063, 0.98713922243723, 0.9877603076339831, 0.9881263690575081, 0.9869817881398986, 0.987618616766385, 0.9881382841076036, 0.9885130508599569, 0.9890874700668275, 0.9896068085506394, 0.9897417169063082, 0.990195630706172, 0.9905366517129357, 0.9908645330071275, 0.988358254442249, 0.9890644107313666, 0.989297700647525, 0.9892310409613716, 0.9893383858604817, 0.9898651487994428, 0.9902206168064033, 0.990617267923382, 0.990958013935815, 0.9912809253398526, 0.9916087479844388, 0.9919061495621946, 0.9921388977012132, 0.9921066636965957, 0.9920891706900313, 0.9921966959198469, 0.9922539771457378, 0.9924822415585635, 0.9927945642777071, 0.9931663355285077, 0.9932707399220855, 0.9933996171572671, 0.9934620921974928, 0.9933416084241722, 0.9936540249627074, 0.9938793962759604, 0.9939543472733644, 0.994107869725799, 0.9941507088317998, 0.9943031602700484, 0.9944171150763769, 0.9942801840746915, 0.9942174721398599, 0.9932565485116066, 0.9935635201485412, 0.993909549086068, 0.9941535458143659, 0.9941941064115007, 0.9942422366929697, 0.9944483504117773, 0.9944059521265519, 0.9945654313186587, 0.9946857111034595, 0.9948427910347802, 0.9948074877122638, 0.994845433137466, 0.9949260869963384, 0.9949079946657522, 0.994933564246796, 0.9950937606494974, 0.9949333789666998, 0.9949610964640867, 0.9950557606272018, 0.9952502403680531, 0.9952857992550666, 0.9953177662045598, 0.9951837760424371, 0.9953747908858217, 0.995497840071049, 0.9954412096722867, 0.9955181615467431, 0.9956152839706494, 0.9955376446355076, 0.9956281324040996, 0.9956119151458326, 0.9957252388467348, 0.9959178749322994, 0.9959029103557362, 0.9959522212546864, 0.9959850474173314], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.025227962631777106, 0.05458007812499999, 0.08859607963102407, 0.12430507812499997, 0.1659731913591867, 0.2114755404273343, 0.2597989365916792, 0.30117302919004135, 0.3409093595541698, 0.3821521314771414, 0.41623210493522544, 0.4472722039296547, 0.4816234556281802, 0.5117420070909646, 0.5404407650132688, 0.5681902690842311, 0.5875565007883833, 0.6106310523755841, 0.6324816331320016, 0.6463658763982442, 0.6675248636360553, 0.6826625845860793, 0.6977779973435858, 0.7144764247835494, 0.7235973946451795, 0.7335226055289297, 0.7459120912580398, 0.7526678030189075, 0.7624803537128751, 0.7700106445369942, 0.7756494167738068, 0.7845799687899502, 0.790663164023154, 0.7976965687710644, 0.8053827900942592, 0.8085943051831013, 0.8112506761519899, 0.816508150423086, 0.82151563851519, 0.8157200846410807, 0.821927367169066, 0.8257600799062256, 0.8295279336908289, 0.8330003332810834, 0.8366942229104298, 0.8404378806739802, 0.8405426007014617, 0.843455790508951, 0.84646019733908, 0.8485385163664672, 0.8519898875743235, 0.8540421989392556, 0.8570540946797427, 0.8594046198879732, 0.8607489905893114, 0.862940634263814, 0.8646975050430049, 0.8660894062235689, 0.8641132839841186, 0.8649511966907519, 0.8655466267204719, 0.8668658227645392, 0.8670622706556305, 0.8684130077749318, 0.8695686655347127, 0.8709362883449463, 0.8649576468033734, 0.8663835394554908, 0.8678011201861465, 0.8681624450086463, 0.8694275787551461, 0.8711908167380652, 0.8724735846501019, 0.874180480703164, 0.8750126503003928, 0.8764076931581547, 0.8768890412180923, 0.8775897796508765, 0.8767514824557436, 0.8785921121657416, 0.8792129931931434, 0.8803018360048531, 0.8813215041551208, 0.8802229863167924, 0.8814712955070259, 0.8822651839344859, 0.8828555541893808, 0.8840226825524458, 0.8846539409820656, 0.8852882562682717, 0.8860890146022878, 0.886554378955312, 0.8870535085484855, 0.8873216787309111, 0.8880218986119615, 0.8881963183140184, 0.8884855143723002, 0.8886613711146635, 0.8892661547957423, 0.8887006497736228, 0.888867200007104, 0.8895217015331255, 0.8905257919690448, 0.8905454195680741, 0.8909007632475618, 0.8910161415538297, 0.891320442072769, 0.8913938524965161, 0.8917172990427983, 0.8922088609777504, 0.8925647879917977, 0.8927386379294402, 0.8927668555088606, 0.8921463081827485, 0.8926051172176364, 0.8929468621788547, 0.8931435398540414, 0.894035764134827, 0.8943310711456666, 0.8922550094000758, 0.8933062403877791, 0.8906449499333385, 0.8907695845051402, 0.8914382785866292, 0.8920868723676499, 0.8924051406090475, 0.8935959318474651, 0.8940359668630198, 0.8941949172399708, 0.8948456674210942, 0.8952308825408071, 0.8941065553465908, 0.8947345210939347, 0.895476765756002, 0.8960877217575856, 0.8964830087873993, 0.8965182957757527, 0.8966822723917015, 0.896309067036944, 0.8963913098061412, 0.8966494632758283, 0.8971513855947063, 0.8971148344316965, 0.8972894579162377, 0.897562512312867, 0.8972558563376043, 0.897659488747895, 0.8977256711325181, 0.8977862647873386, 0.8980392001026559, 0.8977479695219837, 0.8945377904161708, 0.8921348514536199, 0.8922966898681224, 0.8924464624758132, 0.8930207109477348, 0.8943086365585335, 0.8949703698529814, 0.8953309076982555, 0.8941264243267734, 0.894901976077078, 0.8952215546836021, 0.8956078611881335, 0.8958781768200732, 0.8969943371595267, 0.8969745203486945, 0.8975904213352859, 0.8981569392544682, 0.8984684043557534, 0.8957731487752232, 0.8962131296431828, 0.8963161436743464, 0.8960466163268666, 0.8959689101723425, 0.8963150432044306, 0.8962552044525115, 0.8967233104662211, 0.8973602144064213, 0.8974877977756437, 0.898108258632492, 0.8985181300113362, 0.8988249495873862, 0.8986107469385121, 0.8984942952680042, 0.8987995273564146, 0.8987527353888454, 0.8991388982204428, 0.8995007108174496, 0.9003766880696655, 0.9001885050966598, 0.900448445532024, 0.9004432517694843, 0.9003907787668581, 0.9010658269255639, 0.9013559874558992, 0.9011288506832009, 0.9013760877440224, 0.9013513719477828, 0.9013667783335768, 0.9014406497283818, 0.9012518158361159, 0.9015030814475344, 0.9003690924857629, 0.9010636638471263, 0.9010865155064649, 0.90167978295996, 0.9017986846056055, 0.9017581822030268, 0.9021377986118657, 0.9023207619735708, 0.9024386598914246, 0.9022965093578543, 0.9025277253271894, 0.9026208088750427, 0.9029528427277493, 0.9031285733740256, 0.9034902795249513, 0.9035990299515978, 0.9040041401341489, 0.903337171621487, 0.9031173769461606, 0.9031148742383668, 0.9034839802821506, 0.9033959891157578, 0.9035141685833237, 0.9032054910416328, 0.9032399165233129, 0.9034134128698521, 0.9031301064567373, 0.9034101810426147, 0.9036093020102659, 0.9034528910581099, 0.9033913933679616, 0.9032139751343281, 0.9031031268490579, 0.9035822414043629, 0.9038303390353875, 0.9041634901845595, 0.9042680137188144], "moving_var_accuracy_train": [0.006004384456292044, 0.013380946264112917, 0.02244452214420186, 0.03226765479460222, 0.04541539773477977, 0.06040035163966476, 0.07670525732875423, 0.08517491234553602, 0.09188465042403711, 0.0988432413344347, 0.10061899907276758, 0.10016793957800477, 0.1019942919517661, 0.10107193563498572, 0.09962250286242308, 0.09809876336952128, 0.09229866412003472, 0.08857047053025117, 0.08505642818823088, 0.07871795406032878, 0.0758732167806039, 0.07100129294426273, 0.06667330322576687, 0.06326744966114539, 0.05814830967565069, 0.05347499861262488, 0.05015108310514087, 0.04578606141612915, 0.042523348903419314, 0.03903773322125186, 0.03558178273773112, 0.03316154250198006, 0.03041433806920258, 0.02813227280120265, 0.02608839825629229, 0.023624169648109407, 0.02138596273936292, 0.01970883267966761, 0.01806350787734053, 0.016622985927944634, 0.015532178953698007, 0.014260282748908108, 0.013108705142490672, 0.011992960685751699, 0.01101550707830236, 0.010113227045326323, 0.00910621212169241, 0.008347110899059398, 0.007651224532996472, 0.006938253594721595, 0.006396130480973724, 0.005836997692138517, 0.005366381327870787, 0.00489454417923106, 0.004447141092131506, 0.0040693372827504525, 0.0037142690979752122, 0.003383151413243257, 0.0030780027692433915, 0.002778614397235403, 0.0025167393705300485, 0.0023064112311623874, 0.0020775017266726607, 0.0019071551912149295, 0.0017518491529928547, 0.0016090443136431542, 0.001957064869910208, 0.0018005607527693636, 0.001645090837718006, 0.0014865010501391568, 0.0013717671697086042, 0.0012849542850118096, 0.0011852813455287834, 0.0011028810362984267, 0.0010198531646043482, 0.0009333271268242275, 0.0008445892496610606, 0.0007710439675588305, 0.0007015574686270019, 0.000658103406532043, 0.0005998366026932385, 0.0005528754882205547, 0.0005112853147831778, 0.00047648177422255397, 0.0004409220641719325, 0.00040358536994766124, 0.000370565676181569, 0.00034751406108930884, 0.0003183493683730169, 0.00029399045960993724, 0.00027400136904448806, 0.0002484105728740209, 0.0002245719852935666, 0.0002061272888059577, 0.00018931431146755788, 0.00017168392735281455, 0.0001580142746004297, 0.00014451087228261459, 0.00013725661523437006, 0.0001237127873265523, 0.00011232287900967016, 0.00010509371733252367, 0.00010011513730423103, 9.010570155893938e-05, 8.206367849627814e-05, 7.458108235236921e-05, 6.83962520432118e-05, 6.162449623471374e-05, 5.755349536622547e-05, 5.369784485321362e-05, 5.0409599680670164e-05, 4.590661429238407e-05, 4.160921644679176e-05, 3.951505346535475e-05, 3.7462299720383334e-05, 3.428073622142026e-05, 3.110457873074194e-05, 2.8971906816163288e-05, 2.6747432818235506e-05, 6.374699047586487e-05, 6.024835176593138e-05, 9.190893236525049e-05, 8.554016628221281e-05, 7.896662948436564e-05, 7.564359636847898e-05, 7.020258981918639e-05, 6.773959365039979e-05, 6.389669399574268e-05, 5.8105040707313266e-05, 5.32183625361053e-05, 4.846419151340358e-05, 5.048895514305387e-05, 4.79644398837816e-05, 4.7232221659149515e-05, 4.335822829152059e-05, 3.9745246675643785e-05, 3.621631079395746e-05, 3.370619467430606e-05, 3.0547344971877606e-05, 2.810979471664593e-05, 2.5403472841198942e-05, 2.3720058578827935e-05, 2.1728881849010535e-05, 1.9872140644552698e-05, 1.8972866887048477e-05, 1.716314566333981e-05, 1.686686865574234e-05, 1.6735146562749734e-05, 1.5508743088877135e-05, 1.4198155225097152e-05, 1.3178952001435515e-05, 0.00013185183924311825, 0.00015469410415955195, 0.00014154601022073324, 0.0001304955353445219, 0.00012204144630521602, 0.0001129906435070306, 0.00010516330055096108, 9.585297918800272e-05, 9.805827056180289e-05, 9.190239980123475e-05, 8.514264713087455e-05, 7.789243348581236e-05, 7.307280696422861e-05, 6.819293841471807e-05, 6.153744695310962e-05, 5.723804189716002e-05, 5.256089565093151e-05, 4.827236137356665e-05, 9.997801543913461e-05, 9.446812423716506e-05, 8.551112947827875e-05, 7.70000081542735e-05, 6.940371368513089e-05, 6.496065506138381e-05, 5.96018070909976e-05, 5.505761535930202e-05, 5.059682442827233e-05, 4.6475587959162603e-05, 4.279523833997759e-05, 3.931174379204474e-05, 3.5868114678790006e-05, 3.2290654490394095e-05, 2.9064343088862626e-05, 2.626196385539848e-05, 2.366529771941472e-05, 2.176770972693691e-05, 2.0468848082282804e-05, 1.966588804035195e-05, 1.7797401732901888e-05, 1.6167145635344265e-05, 1.4585559247670632e-05, 1.3257650379605949e-05, 1.2810322183597993e-05, 1.1986420024774939e-05, 1.0838336890404074e-05, 9.966625491977751e-06, 8.986479643806472e-06, 8.2970046486424e-06, 7.584175464746451e-06, 6.994508811274668e-06, 6.330453011080163e-06, 1.4007775683990453e-05, 1.3455082388532014e-05, 1.3187198380132367e-05, 1.2404288172900163e-05, 1.1178665813969561e-05, 1.0081647948521147e-05, 9.45582893939494e-06, 8.526424576765892e-06, 7.902684633524386e-06, 7.242621209857472e-06, 6.740426032285201e-06, 6.0776003502829605e-06, 5.48279901289864e-06, 4.993064516167926e-06, 4.496704056385505e-06, 4.052917882019766e-06, 3.8785920807638675e-06, 3.722233430280537e-06, 3.356924424205001e-06, 3.1018837157891194e-06, 3.132096670624323e-06, 2.8302669135726036e-06, 2.556437194954537e-06, 2.4623737473699493e-06, 2.5445164061720133e-06, 2.4263346834208548e-06, 2.212564233654599e-06, 2.044602129130397e-06, 1.925036803246367e-06, 1.786783920172952e-06, 1.6817978545386558e-06, 1.5159850642761084e-06, 1.479966908523944e-06, 1.6659481708264556e-06, 1.5013688007092752e-06, 1.3731160034358331e-06, 1.245502415678252e-06], "duration": 274744.515999, "accuracy_train": [0.258293210998062, 0.32354283464839423, 0.3955626067045035, 0.45577206476098187, 0.5527574462440015, 0.6346594612287745, 0.7137219107604282, 0.6887552198689553, 0.7189520536291066, 0.77232629516196, 0.7510526255075674, 0.7538900280315615, 0.8225394157784238, 0.8171192956349206, 0.8383235713132153, 0.8653868615033223, 0.800878762054725, 0.8581545672411407, 0.8792876465023993, 0.8151762643041713, 0.91185685302464, 0.8728498682055187, 0.8920251361203396, 0.9244362685723514, 0.8689436182055187, 0.8773130724552418, 0.9259014728105389, 0.875937990263935, 0.9203650952265596, 0.9038383340254706, 0.8913086658476375, 0.9402676480597084, 0.9185765330841639, 0.9388740007267442, 0.9486614352620893, 0.9055346111918604, 0.9066081450143041, 0.9447791577265596, 0.9404779929171282, 0.8225927680301772, 0.9596590286429494, 0.9438501796673128, 0.9487540807262828, 0.9456169322743633, 0.953358596345515, 0.9557298876430418, 0.9202993061323367, 0.955103899905408, 0.9574504977620893, 0.9461753284768365, 0.96556634857189, 0.9585197057262828, 0.9670533623454227, 0.9619841774524732, 0.9594501257382798, 0.9672622652500923, 0.9667285624884644, 0.9662864237264673, 0.928042772644426, 0.9549876424649317, 0.9596143281076966, 0.9690529903216132, 0.954149146940753, 0.9705875885358989, 0.9720753232858066, 0.973191394714378, 0.8809224604328165, 0.96947115661914, 0.9672157622739018, 0.9604503002145626, 0.9725639650239941, 0.97874850036914, 0.9753537831072352, 0.9792832845953304, 0.9786551339285714, 0.9760978307262828, 0.9714475331072352, 0.9760287972383721, 0.9569178764650241, 0.982422595976375, 0.9760756607027501, 0.9798649322858989, 0.9813755580357143, 0.956804502930048, 0.9805152529761905, 0.97874850036914, 0.979981189726375, 0.9843284970238095, 0.9809802827380952, 0.9830035226905685, 0.9850260416666666, 0.9803070710478959, 0.9796091659168512, 0.9832825405477114, 0.9837708217977114, 0.981725051333518, 0.9845381209048542, 0.9839797247023809, 0.9883742559523809, 0.9817475818452381, 0.9837704613095238, 0.9874678084048542, 0.989304675964378, 0.9820974356312293, 0.9855146834048542, 0.9853980654761905, 0.9866071428571429, 0.9823535624884644, 0.9879557291666666, 0.9882114955357143, 0.9888857886904762, 0.9870024181547619, 0.9866071428571429, 0.9801904531192323, 0.9890964940360835, 0.9874674479166666, 0.9868861607142857, 0.9886765252976191, 0.9884440104166666, 0.9649875847868217, 0.9895368303571429, 0.9639863288459765, 0.9880025926310447, 0.9876538203096161, 0.9905606168097084, 0.9890020461309523, 0.9917464427025655, 0.9910488980597084, 0.9884905133928571, 0.9893744304286637, 0.98900240661914, 0.9780044527500923, 0.9911644345238095, 0.9931179200119971, 0.9901417295358066, 0.9902111235119048, 0.9898856026785714, 0.9913973098929494, 0.9867005092977114, 0.9906997652500923, 0.9894212938930418, 0.9915364583333334, 0.990816383178756, 0.9908392741786637, 0.9926292782738095, 0.9885137648809523, 0.9933736863810447, 0.9939553340716132, 0.9924432663690477, 0.9920712425595238, 0.9884908738810447, 0.9538762573827981, 0.9667307254175894, 0.9898162087024732, 0.9911182920358066, 0.9929784110834257, 0.9924665178571429, 0.9933500744047619, 0.9914209218692323, 0.9766805598814139, 0.9933500744047619, 0.9928152901785714, 0.991885951631137, 0.9942572429286637, 0.9942808549049464, 0.9909558921073275, 0.9942808549049464, 0.9936058407738095, 0.9938154646548542, 0.9658017473583426, 0.9954198173334257, 0.9913973098929494, 0.9886311037859912, 0.9903044899524732, 0.9946060152500923, 0.9934198288690477, 0.9941871279761905, 0.9940247280477114, 0.9941871279761905, 0.9945591517857143, 0.9945827637619971, 0.9942336309523809, 0.9918165576550388, 0.9919317336309523, 0.9931644229881875, 0.992769508178756, 0.9945366212739941, 0.99560546875, 0.9965122767857143, 0.9942103794642857, 0.9945595122739018, 0.9940243675595238, 0.9922572544642857, 0.9964657738095238, 0.9959077380952381, 0.99462890625, 0.9954895717977114, 0.9945362607858066, 0.9956752232142857, 0.9954427083333334, 0.9930478050595238, 0.993653064726375, 0.9846082358573275, 0.9963262648809523, 0.9970238095238095, 0.9963495163690477, 0.9945591517857143, 0.9946754092261905, 0.9963033738810447, 0.9940243675595238, 0.9960007440476191, 0.9957682291666666, 0.9962565104166666, 0.9944897578096161, 0.9951869419642857, 0.9956519717261905, 0.9947451636904762, 0.9951636904761905, 0.9965355282738095, 0.9934899438215209, 0.9952105539405685, 0.9959077380952381, 0.9970005580357143, 0.9956058292381875, 0.99560546875, 0.9939778645833334, 0.9970939244762828, 0.9966052827380952, 0.9949315360834257, 0.9962107284168512, 0.9964893857858066, 0.9948388906192323, 0.9964425223214286, 0.9954659598214286, 0.9967451521548542, 0.9976515997023809, 0.9957682291666666, 0.9963960193452381, 0.996280482881137], "end": "2016-02-07 01:58:38.968000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0], "moving_var_accuracy_valid": [0.005728050886953081, 0.01290916595360523, 0.02203204458436521, 0.03130503328691365, 0.043800614902695365, 0.0580547273489018, 0.07326561016571762, 0.0813453889941865, 0.08742163365203222, 0.09398816640984126, 0.09504235108699055, 0.09420950568854722, 0.09540863155899156, 0.09403191268303993, 0.09204128977128306, 0.08976747557981393, 0.08416618639560272, 0.08054148213459598, 0.07678436483567089, 0.07084087825178963, 0.06778611509497935, 0.06306985894552858, 0.05881915437644384, 0.055446776249509055, 0.050650827445509014, 0.04647233300074032, 0.043206593910352684, 0.03929669129188076, 0.036233597522787854, 0.03312058528957138, 0.030094688531662084, 0.027803012512313263, 0.025355758639289395, 0.023265401816491827, 0.02147056361890485, 0.019416331719507112, 0.01753820530807559, 0.01603315409866918, 0.014655513121735339, 0.013492257811931143, 0.012489805238178112, 0.011373031896690576, 0.010363499206300867, 0.009435667315900374, 0.008614903969654478, 0.00787954833374435, 0.007091692196927317, 0.006458903050924725, 0.005894250889440584, 0.005343700490312922, 0.004916538110211405, 0.004462792136637929, 0.004098156566538215, 0.003738065628675139, 0.0033805250590511747, 0.0030857022711099423, 0.0028049113984119213, 0.002541856758638828, 0.0023228166147221943, 0.002096853832585413, 0.001890359281609503, 0.0017169858572726974, 0.0015456345975106555, 0.0014074915546487183, 0.0012787623029035231, 0.0011677196019728108, 0.001372645033919126, 0.001253679059225477, 0.0011463969694542673, 0.0010329322731550314, 0.0009440441164083228, 0.0008776207784271686, 0.0008046681422298143, 0.0007504227752304634, 0.0006816130538543844, 0.000630967049643879, 0.0005699556082727419, 0.0005173793566060947, 0.00047196610063179336, 0.0004552607501325572, 0.00041320411437098845, 0.0003825539109513977, 0.0003536560280862912, 0.00032915109824779235, 0.0003102604709328038, 0.0002849067533568186, 0.00025955291136191744, 0.00024585731776856145, 0.0002248579708364008, 0.00020599337669359314, 0.00019116496420970152, 0.00017399754361832238, 0.00015883996241352515, 0.000143603203392852, 0.00013365565398993184, 0.00012056388868312911, 0.00010926020905594827, 9.861251849486533e-05, 9.204313635347217e-05, 8.571698608850545e-05, 7.739493830210834e-05, 7.351079469997817e-05, 7.523349366152335e-05, 6.77136114791639e-05, 6.207867250621471e-05, 5.599061463760851e-05, 5.1224942426288304e-05, 4.615094999649217e-05, 4.247741401155939e-05, 4.040437083344811e-05, 3.750409010406055e-05, 3.4025695301019255e-05, 3.063029185701247e-05, 3.103297352681354e-05, 2.9824227748584224e-05, 2.789291154038863e-05, 2.5451759357601813e-05, 3.0071160926852475e-05, 2.784890091002633e-05, 6.385430216257162e-05, 6.741465125188257e-05, 0.00012441538807276222, 0.0001121136532538797, 0.00010492665390005748, 9.822005354506162e-05, 8.930970025189669e-05, 9.31405841881346e-05, 8.556920310354915e-05, 7.723966979419013e-05, 7.332698499886044e-05, 6.732980269507297e-05, 7.197382718245321e-05, 6.832551328274299e-05, 6.64513061997763e-05, 6.316558070263704e-05, 5.825528915582398e-05, 5.2440966784165086e-05, 4.743886508095084e-05, 4.3948518704232805e-05, 3.961454169157649e-05, 3.625287644762217e-05, 3.4894922930550874e-05, 3.1417454525152095e-05, 2.855014932481665e-05, 2.6366162724002033e-05, 2.457588743608013e-05, 2.3584570796206416e-05, 2.1265534688895438e-05, 1.9172025539046418e-05, 1.783060944875396e-05, 1.6810885763946653e-05, 0.00010787704621012694, 0.00014905638250881678, 0.00013438646930961315, 0.0001211497088847823, 0.00011200258976384376, 0.00011573110219802269, 0.00010809901055504769, 9.845899734041724e-05, 0.00010167011933596924, 9.691643205897694e-05, 8.814396322481039e-05, 8.06726613413185e-05, 7.326303007502512e-05, 7.71490521978436e-05, 6.943768133198327e-05, 6.590791942634317e-05, 6.220561045850013e-05, 5.6858143996517e-05, 0.00011655195339627561, 0.00010663900653418249, 9.607061289631351e-05, 8.711735652603775e-05, 7.845996509149216e-05, 7.169224126546505e-05, 6.455524322499952e-05, 6.0071828063140194e-05, 5.77154649182087e-05, 5.2090416071306915e-05, 5.0346119538104345e-05, 4.6823458509054524e-05, 4.298835692837722e-05, 3.910246620860186e-05, 3.5314268511818257e-05, 3.262134131079494e-05, 2.9378912573776395e-05, 2.7783116908964583e-05, 2.618298041624423e-05, 3.0470707692216885e-05, 2.7742352404958618e-05, 2.5576238433898422e-05, 2.3018857367032454e-05, 2.0741752374370637e-05, 2.276878728608189e-05, 2.1249646757753225e-05, 1.9589002103584297e-05, 1.818023737141866e-05, 1.6367711469530606e-05, 1.4733076533086649e-05, 1.330888172651187e-05, 1.2298917703675272e-05, 1.1637235600641483e-05, 2.2046890729354064e-05, 2.418406604065546e-05, 2.177035922160065e-05, 2.276101974182945e-05, 2.061215617968154e-05, 1.856570456324515e-05, 1.8006111667658254e-05, 1.650678082642997e-05, 1.4981202015095239e-05, 1.3664942781334268e-05, 1.277959592348077e-05, 1.157961725306139e-05, 1.1413873841843744e-05, 1.0550417798025457e-05, 1.0672858074780669e-05, 9.712012164964646e-06, 1.021783928852716e-05, 1.3199678331615899e-05, 1.23144977921709e-05, 1.1083104384870519e-05, 1.1200947390403064e-05, 1.0150534659631207e-05, 9.261178672655288e-06, 9.192597228088193e-06, 8.28400352937953e-06, 7.726512016803606e-06, 7.676223528530608e-06, 7.614577138567524e-06, 7.209961862535846e-06, 6.70914514987169e-06, 6.0722683279267526e-06, 5.748336561764789e-06, 5.284088986714319e-06, 6.821636901989293e-06, 6.693445122470299e-06, 7.0230078039754575e-06, 6.419033546496108e-06], "accuracy_test": 0.541733099489796, "start": "2016-02-03 21:39:34.452000", "learning_rate_per_epoch": [0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757, 0.0032380707561969757], "accuracy_train_first": 0.258293210998062, "accuracy_train_last": 0.996280482881137, "batch_size_eval": 1024, "accuracy_train_std": [0.014018568030875448, 0.01492665248346342, 0.016680361347527786, 0.017397874546043125, 0.018198715307383626, 0.018746149510455633, 0.017332854180773197, 0.016706930085538016, 0.01815926594411046, 0.01867659996615882, 0.0209268964669723, 0.019141666045394405, 0.019170680876166597, 0.02194864393025202, 0.019382335636433254, 0.016962122324563844, 0.01466190650544223, 0.01960057902214858, 0.017594782463386943, 0.014268268783367831, 0.016794863468336974, 0.016667719945294816, 0.018744729325379187, 0.015788158877413458, 0.019095748023575092, 0.01574879204169081, 0.016255202772919416, 0.019532802539227484, 0.018296842404679606, 0.017625483033783675, 0.01909681832314381, 0.014931980719046412, 0.016264530166148063, 0.015481592703078367, 0.013629707201985818, 0.016419484735769808, 0.015066415812265352, 0.013580582082684922, 0.014486181466231303, 0.01711179940838934, 0.012480834914708873, 0.01394317977667498, 0.014779640578141948, 0.014122111487284315, 0.013844757863320895, 0.01289926881901946, 0.015002212374016829, 0.012616305151351977, 0.011959203694706613, 0.014242373214319332, 0.010293183049915547, 0.012789517391576785, 0.010139741674987511, 0.010618807295248063, 0.011411288753622819, 0.0108802322841927, 0.010029479505283934, 0.011361761337021891, 0.01302196631303596, 0.011034762154514072, 0.011427503219307952, 0.010687825753714329, 0.012260130417842434, 0.008637953501881917, 0.00931208732182123, 0.009682958118509362, 0.014144612558568775, 0.009194401602221782, 0.008541785547877871, 0.01225642111636433, 0.0082632399396212, 0.007933963324577721, 0.008151504607955091, 0.007285624155624429, 0.0076437653637292, 0.007975269946822506, 0.008546036378166772, 0.008387361722730174, 0.00946020138097472, 0.006017802461911733, 0.007937279923074653, 0.006573361668707608, 0.00704980364439693, 0.008934791780129132, 0.007150730456229967, 0.008008028075973552, 0.0073009678604044805, 0.006389380316425853, 0.007453253537815913, 0.006304758877093934, 0.005620707601530459, 0.006577189562667386, 0.007372042190220979, 0.007161786706935796, 0.006527295654227475, 0.006381521814088675, 0.006099119526492057, 0.006681597397242887, 0.004589445606947667, 0.005841864084077899, 0.007003138237540245, 0.00538306440763946, 0.004378179808276222, 0.006569122522872851, 0.005508283076817825, 0.00631790468226689, 0.0047949958164621425, 0.005989757662759749, 0.0054358776771586525, 0.005226001484916396, 0.004745810422411259, 0.005359404959247238, 0.005350065855011033, 0.006487559276213617, 0.003685610518912713, 0.005015481263663548, 0.004635392780646247, 0.005007066382740675, 0.004449304542196532, 0.007099236456199022, 0.004486754052839392, 0.007735975943597408, 0.0042750758635094485, 0.005136572658876163, 0.004407908121815789, 0.0045559272169340735, 0.0035489294253779396, 0.0036976809268007872, 0.005248299192515815, 0.004316804912862773, 0.004571568486855543, 0.00665263792724464, 0.0036036056112461632, 0.0030957314075963516, 0.004137363839027662, 0.004167727899671584, 0.004932878685334025, 0.0032761402892951207, 0.004952683855566633, 0.00481422655099633, 0.003629827471820718, 0.003620668091484697, 0.0031336172012501875, 0.003239360593004684, 0.003176616227241115, 0.004711511174377233, 0.0029498471563764355, 0.002731604063715261, 0.0032463107832812273, 0.003722925577836679, 0.004407108057710547, 0.00866443139157731, 0.007608078817070242, 0.004033646455237731, 0.004382473769637305, 0.0034051143078569408, 0.003567720941000118, 0.003162544296115942, 0.00379829299119706, 0.006753331934202659, 0.0030899119401748914, 0.0030721014897315533, 0.00233075313094453, 0.003516288044599056, 0.0030259894881161323, 0.003212304357970143, 0.0025980223362840247, 0.0026888413314944456, 0.003427812988325295, 0.006783676571247813, 0.0023004305696238173, 0.004050892251207653, 0.003301967983549108, 0.004317729057264989, 0.002165835741035351, 0.0033631169719934182, 0.0031460904530474045, 0.003580304439176421, 0.0027944380929266397, 0.002820243526796188, 0.002541721615476071, 0.0024466046201573484, 0.003679131315665014, 0.003088599411149933, 0.0033429237414628944, 0.0033162448763386495, 0.0024214160945066, 0.0027723926236389237, 0.002143176826972268, 0.0025695787467067332, 0.0022166682757089004, 0.003007721764624065, 0.004034317450033832, 0.002032344994736994, 0.0023367456336311596, 0.0032265995445310888, 0.0021202782888663035, 0.0030594657588615915, 0.002738547593812399, 0.0024637801672153284, 0.0030969899847473584, 0.002908904369313344, 0.004496303671739642, 0.0022533559225419862, 0.002098309927953586, 0.0023154793359999176, 0.002915258187994323, 0.002620412792760852, 0.002126378198579754, 0.002931255633091932, 0.002052989216391752, 0.00200664518325813, 0.002284451309833691, 0.002538329295287772, 0.00251600011117068, 0.0025052332006315447, 0.0025920977509992153, 0.002274846504582405, 0.0021010135219507956, 0.0027351981067697613, 0.002342729388177299, 0.0023560998029935644, 0.0019692514248734797, 0.002394820387494271, 0.002144311683724804, 0.00295988794999233, 0.001629974287579953, 0.0019904143005052733, 0.0021340971337447823, 0.0019084259032265674, 0.0022359044154003724, 0.0026301316485443185, 0.0018678052230742027, 0.0025821717098915217, 0.0019378056184044172, 0.0016787832037002137, 0.002388913604732389, 0.0018515252094139188, 0.0016675618577810638], "accuracy_test_std": 0.009264948352291063, "error_valid": [0.7477203736822289, 0.681250882435994, 0.605259906814759, 0.5543139354292168, 0.45901378953313254, 0.3790033179593373, 0.3052904979292168, 0.3264601374246988, 0.3014636671686747, 0.24666292121611444, 0.2770481339420181, 0.2733669051204819, 0.2092152790850903, 0.21719102974397586, 0.20127041368599397, 0.1820641942771084, 0.23814741387424698, 0.1816979833396084, 0.17086314006024095, 0.2286759342055723, 0.1420442512236446, 0.18109792686370485, 0.1661832878388554, 0.13523772825677716, 0.19431387660015065, 0.1771504965173193, 0.14258253717996983, 0.1865307911332832, 0.14920669004141573, 0.16221673804593373, 0.17360163309487953, 0.13504506306475905, 0.15458807887801207, 0.13900278849774095, 0.12544121799698793, 0.1625020590173193, 0.16484198512801207, 0.13617458113704817, 0.1334169686558735, 0.23643990022590367, 0.12220709007906627, 0.13974550545933728, 0.13656138224774095, 0.1357480704066265, 0.13006077042545183, 0.12586919945406627, 0.15851491905120485, 0.1303255012236446, 0.12650014118975905, 0.13275661238704817, 0.11694777155496983, 0.1274869987763554, 0.11583884365587349, 0.11944065323795183, 0.1271516730986446, 0.11733457266566272, 0.11949065794427716, 0.12138348315135539, 0.15367181617093373, 0.12750758894954817, 0.12909450301204817, 0.12126141283885539, 0.13116969832454817, 0.11943035815135539, 0.12003041462725905, 0.11675510636295183, 0.1888501270707832, 0.12078342667545183, 0.11944065323795183, 0.1285856315888554, 0.11918621752635539, 0.11294004141566272, 0.11598150414156627, 0.11045745481927716, 0.11749782332454817, 0.11103692112198793, 0.11877882624246983, 0.11610357445406627, 0.13079319230045183, 0.10484222044427716, 0.11519907756024095, 0.10989857868975905, 0.10950148249246983, 0.12966367422816272, 0.10729392178087349, 0.11058982021837349, 0.11183111351656627, 0.10547316217996983, 0.10966473315135539, 0.10900290615587349, 0.10670416039156627, 0.10925734186746983, 0.10845432511295183, 0.11026478962725905, 0.10567612245858427, 0.11023390436746983, 0.10891172110316272, 0.10975591820406627, 0.10529079207454817, 0.11638889542545183, 0.10963384789156627, 0.10458778473268071, 0.10043739410768071, 0.10927793204066272, 0.10590114363704817, 0.10794545368975905, 0.10594085325677716, 0.10794545368975905, 0.10537168204066272, 0.10336708160768071, 0.10423186888177716, 0.10569671263177716, 0.10697918627635539, 0.11343861775225905, 0.10326560146837349, 0.10397743317018071, 0.10508636106927716, 0.09793421733810237, 0.10301116575677716, 0.12642954631024095, 0.0972326807228916, 0.1333066641566265, 0.10810870434864461, 0.10254347467996983, 0.10207578360316272, 0.10473044521837349, 0.09568694700677716, 0.10200371799698793, 0.10437452936746983, 0.09929758094879515, 0.10130218138177716, 0.11601238940135539, 0.09961378717996983, 0.0978430322853916, 0.09841367422816272, 0.09995940794427716, 0.10316412132906627, 0.10184193806475905, 0.10704978115587349, 0.10286850527108427, 0.10102715549698793, 0.0983313135353916, 0.1032141260353916, 0.1011389307228916, 0.09997999811746983, 0.10550404743975905, 0.09870781955948793, 0.10167868740587349, 0.10166839231927716, 0.09968438205948793, 0.10487310570406627, 0.1343538215361446, 0.12949159920933728, 0.10624676440135539, 0.10620558405496983, 0.10181105280496983, 0.09410003294427716, 0.09907403049698793, 0.10142425169427716, 0.11671392601656627, 0.09811805817018071, 0.10190223785768071, 0.10091538027108427, 0.10168898249246983, 0.0929602197853916, 0.10320383094879515, 0.0968664697853916, 0.0967443994728916, 0.09872840973268071, 0.12848415144954817, 0.09982704254518071, 0.10275673004518071, 0.10637912980045183, 0.10473044521837349, 0.10056975950677716, 0.10428334431475905, 0.0990637354103916, 0.09690765013177716, 0.10136395190135539, 0.09630759365587349, 0.09779302757906627, 0.09841367422816272, 0.10331707690135539, 0.10255376976656627, 0.0984533838478916, 0.10166839231927716, 0.09738563629518071, 0.09724297580948793, 0.0917395166603916, 0.1015051416603916, 0.09721209054969882, 0.09960349209337349, 0.10008147825677716, 0.09285873964608427, 0.09603256777108427, 0.10091538027108427, 0.09639877870858427, 0.09887107021837349, 0.09849456419427716, 0.09789450771837349, 0.10044768919427716, 0.09623552804969882, 0.10983680817018071, 0.09268519390060237, 0.09870781955948793, 0.09298080995858427, 0.09713120058358427, 0.09860633942018071, 0.09444565370858427, 0.09603256777108427, 0.0965002588478916, 0.09898284544427716, 0.09539133094879515, 0.09654143919427716, 0.0940588525978916, 0.09528985080948793, 0.09325436511671681, 0.09542221620858427, 0.0923498682228916, 0.10266554499246983, 0.09886077513177716, 0.09690765013177716, 0.09319406532379515, 0.09739593138177716, 0.09542221620858427, 0.09957260683358427, 0.09645025414156627, 0.09502512001129515, 0.09941965126129515, 0.09406914768448793, 0.09459860928087349, 0.09795480751129515, 0.09716208584337349, 0.09838278896837349, 0.09789450771837349, 0.0921057275978916, 0.0939367822853916, 0.0928381494728916, 0.0947912744728916], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.054550426896069516, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.003238070656413369, "optimization": "rmsprop", "nb_data_augmentation": 3, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.904173759043622e-08, "rotation_range": [0, 0], "momentum": 0.9813141325879224}, "accuracy_valid_max": 0.9082604833396084, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.9052087255271084, "accuracy_valid_std": [0.013996084899416415, 0.010158235555247285, 0.011170107281274056, 0.013019933995746934, 0.0137882091640031, 0.016787559026616498, 0.015286191206344802, 0.01880743994832587, 0.019691843429768284, 0.018859903121631546, 0.022321743589449893, 0.019529863392214533, 0.016228117023783288, 0.018340003631030447, 0.022033666311652277, 0.01678047735664831, 0.013872072129491575, 0.012707413903451635, 0.01860802423738941, 0.02100126635985419, 0.009235226470425194, 0.0120530713750469, 0.023984987464322486, 0.01705805807589784, 0.015203389028094264, 0.01278906683708473, 0.019035051384739484, 0.012720079337464111, 0.011971057205149975, 0.012268890890847171, 0.008502841036044399, 0.01342115847167272, 0.0129139981231133, 0.00858066538660889, 0.014481430393811773, 0.012939677376274534, 0.013482589808904205, 0.008969516598525929, 0.014861070940767503, 0.010557758995986133, 0.013102902377527896, 0.014179512069522315, 0.011426141841921037, 0.012279421595513536, 0.010532252096763402, 0.011499533291648075, 0.00861041716137257, 0.012517990300781583, 0.012042738070370478, 0.012437652473069768, 0.00981960552651683, 0.010303310871459314, 0.008781607139430433, 0.0064326967937512695, 0.012302206333811848, 0.011132553293455421, 0.014229422914420715, 0.009383949621200104, 0.012740269897005102, 0.006538509819426369, 0.011512174885536033, 0.012478221513500065, 0.012217107327907237, 0.013355104986471956, 0.010693724517902885, 0.011389285578218578, 0.015521158924513877, 0.011911626383515596, 0.01278475265855143, 0.00913199703499578, 0.009940266113153164, 0.011639517712669325, 0.010777464066980593, 0.008741761710518804, 0.010284350471618459, 0.015492129178714282, 0.011935995310863317, 0.010321767876859787, 0.01281609259204974, 0.011422650222333292, 0.010617526856984773, 0.012828006709028106, 0.010612649009754347, 0.011581043631481453, 0.007619829982202913, 0.011209261865747736, 0.009740520830183811, 0.011811048118721289, 0.012136771342925524, 0.012373023895582667, 0.01213188432001706, 0.014455157534458836, 0.011240645589012437, 0.014223443575177668, 0.013501447498271408, 0.011361018343792733, 0.013175859091387401, 0.014110733675139282, 0.012356503680878506, 0.00993117483274448, 0.012458036500736873, 0.011215274219912212, 0.009966774045901815, 0.014480692804503729, 0.01308601338991016, 0.014200370294878617, 0.013106250447627085, 0.013643801115161034, 0.010315625606448265, 0.00998649684139687, 0.01058556826535475, 0.009137364087789117, 0.013390869128966042, 0.00976067455069922, 0.008438124208004608, 0.010160433331933236, 0.0122196524198337, 0.017131669484237534, 0.008171586936586876, 0.010302121829748585, 0.01445301815521657, 0.010715022837401727, 0.015077543014614475, 0.012622022514050212, 0.014895208163790651, 0.010238954774831319, 0.013461693329126466, 0.01107378535577242, 0.01345732860883458, 0.01323229961574572, 0.012473574569746683, 0.01413823717442737, 0.009890870111066988, 0.013752320013380047, 0.013906132273551865, 0.010013900784404983, 0.011667295145678725, 0.012604286017053738, 0.010449867064320119, 0.00980092950206937, 0.01109115137611437, 0.011487465376207333, 0.009415571265202836, 0.008775849498586646, 0.009433434760940485, 0.013866727232035752, 0.008575954180971596, 0.010588520133366369, 0.013375067349705012, 0.015555141509348815, 0.013980047683579121, 0.010772395601899827, 0.007699533157363171, 0.010732565375215681, 0.012273567659058836, 0.010719909287945358, 0.00928764477539572, 0.009718949897119515, 0.011328715215277523, 0.013517047609654262, 0.010671992725222392, 0.013900786078835969, 0.013113737841968284, 0.008424607288977681, 0.011408488674460433, 0.011795942222245344, 0.010193078288922727, 0.008220140611560131, 0.012828592728602449, 0.010051636655468741, 0.010594969475569616, 0.013745575934893362, 0.01157926391283742, 0.012739508328209437, 0.011695764242259803, 0.012540540807517576, 0.010161537204002865, 0.009315756672016538, 0.010907385532559584, 0.010409518497634931, 0.00977923291954074, 0.012799086334614945, 0.011495407943152854, 0.008258894317030852, 0.012209320053130988, 0.006718601322683801, 0.010509766174824534, 0.01127707848148038, 0.008917872207075322, 0.014404423239207981, 0.010666209002917485, 0.010638614901449598, 0.01313536787662419, 0.007394036104263606, 0.011480207025692397, 0.011526902151715125, 0.012474743988904873, 0.011874631724497783, 0.009993657217792403, 0.00938437339303469, 0.010417266854622537, 0.008207470192400947, 0.014254950121317337, 0.009005850063840104, 0.009734795511676825, 0.008716335575245532, 0.009228261073366103, 0.007960687317982, 0.010963104589103665, 0.00571078142170641, 0.011084034239554692, 0.00871366261732309, 0.006925672907790943, 0.010848565929804937, 0.008811006914385943, 0.008891935888543926, 0.013133562939485819, 0.007894666575288454, 0.009763154575527348, 0.011426724605497535, 0.008614541947536428, 0.01177958287106811, 0.009202289092155298, 0.009923791189344116, 0.011507424672394606, 0.010807940920554055, 0.011632922396595996, 0.010766122463726912, 0.011771054398910621, 0.00911069367121149, 0.01228396044161752, 0.011302649755478096, 0.009450372690067673, 0.0077573987425564915, 0.01002318462830944, 0.009426233533503001, 0.010129614339478007, 0.0098933612260814, 0.010107213671856], "accuracy_valid": [0.2522796263177711, 0.31874911756400603, 0.39474009318524095, 0.44568606457078314, 0.5409862104668675, 0.6209966820406627, 0.6947095020707832, 0.6735398625753012, 0.6985363328313253, 0.7533370787838856, 0.7229518660579819, 0.7266330948795181, 0.7907847209149097, 0.7828089702560241, 0.798729586314006, 0.8179358057228916, 0.761852586125753, 0.8183020166603916, 0.829136859939759, 0.7713240657944277, 0.8579557487763554, 0.8189020731362951, 0.8338167121611446, 0.8647622717432228, 0.8056861233998494, 0.8228495034826807, 0.8574174628200302, 0.8134692088667168, 0.8507933099585843, 0.8377832619540663, 0.8263983669051205, 0.864954936935241, 0.8454119211219879, 0.860997211502259, 0.8745587820030121, 0.8374979409826807, 0.8351580148719879, 0.8638254188629518, 0.8665830313441265, 0.7635600997740963, 0.8777929099209337, 0.8602544945406627, 0.863438617752259, 0.8642519295933735, 0.8699392295745482, 0.8741308005459337, 0.8414850809487951, 0.8696744987763554, 0.873499858810241, 0.8672433876129518, 0.8830522284450302, 0.8725130012236446, 0.8841611563441265, 0.8805593467620482, 0.8728483269013554, 0.8826654273343373, 0.8805093420557228, 0.8786165168486446, 0.8463281838290663, 0.8724924110504518, 0.8709054969879518, 0.8787385871611446, 0.8688303016754518, 0.8805696418486446, 0.879969585372741, 0.8832448936370482, 0.8111498729292168, 0.8792165733245482, 0.8805593467620482, 0.8714143684111446, 0.8808137824736446, 0.8870599585843373, 0.8840184958584337, 0.8895425451807228, 0.8825021766754518, 0.8889630788780121, 0.8812211737575302, 0.8838964255459337, 0.8692068076995482, 0.8951577795557228, 0.884800922439759, 0.890101421310241, 0.8904985175075302, 0.8703363257718373, 0.8927060782191265, 0.8894101797816265, 0.8881688864834337, 0.8945268378200302, 0.8903352668486446, 0.8909970938441265, 0.8932958396084337, 0.8907426581325302, 0.8915456748870482, 0.889735210372741, 0.8943238775414157, 0.8897660956325302, 0.8910882788968373, 0.8902440817959337, 0.8947092079254518, 0.8836111045745482, 0.8903661521084337, 0.8954122152673193, 0.8995626058923193, 0.8907220679593373, 0.8940988563629518, 0.892054546310241, 0.8940591467432228, 0.892054546310241, 0.8946283179593373, 0.8966329183923193, 0.8957681311182228, 0.8943032873682228, 0.8930208137236446, 0.886561382247741, 0.8967343985316265, 0.8960225668298193, 0.8949136389307228, 0.9020657826618976, 0.8969888342432228, 0.873570453689759, 0.9027673192771084, 0.8666933358433735, 0.8918912956513554, 0.8974565253200302, 0.8979242163968373, 0.8952695547816265, 0.9043130529932228, 0.8979962820030121, 0.8956254706325302, 0.9007024190512049, 0.8986978186182228, 0.8839876105986446, 0.9003862128200302, 0.9021569677146084, 0.9015863257718373, 0.9000405920557228, 0.8968358786709337, 0.898158061935241, 0.8929502188441265, 0.8971314947289157, 0.8989728445030121, 0.9016686864646084, 0.8967858739646084, 0.8988610692771084, 0.9000200018825302, 0.894495952560241, 0.9012921804405121, 0.8983213125941265, 0.8983316076807228, 0.9003156179405121, 0.8951268942959337, 0.8656461784638554, 0.8705084007906627, 0.8937532355986446, 0.8937944159450302, 0.8981889471950302, 0.9058999670557228, 0.9009259695030121, 0.8985757483057228, 0.8832860739834337, 0.9018819418298193, 0.8980977621423193, 0.8990846197289157, 0.8983110175075302, 0.9070397802146084, 0.8967961690512049, 0.9031335302146084, 0.9032556005271084, 0.9012715902673193, 0.8715158485504518, 0.9001729574548193, 0.8972432699548193, 0.8936208701995482, 0.8952695547816265, 0.8994302404932228, 0.895716655685241, 0.9009362645896084, 0.9030923498682228, 0.8986360480986446, 0.9036924063441265, 0.9022069724209337, 0.9015863257718373, 0.8966829230986446, 0.8974462302334337, 0.9015466161521084, 0.8983316076807228, 0.9026143637048193, 0.9027570241905121, 0.9082604833396084, 0.8984948583396084, 0.9027879094503012, 0.9003965079066265, 0.8999185217432228, 0.9071412603539157, 0.9039674322289157, 0.8990846197289157, 0.9036012212914157, 0.9011289297816265, 0.9015054358057228, 0.9021054922816265, 0.8995523108057228, 0.9037644719503012, 0.8901631918298193, 0.9073148060993976, 0.9012921804405121, 0.9070191900414157, 0.9028687994164157, 0.9013936605798193, 0.9055543462914157, 0.9039674322289157, 0.9034997411521084, 0.9010171545557228, 0.9046086690512049, 0.9034585608057228, 0.9059411474021084, 0.9047101491905121, 0.9067456348832832, 0.9045777837914157, 0.9076501317771084, 0.8973344550075302, 0.9011392248682228, 0.9030923498682228, 0.9068059346762049, 0.9026040686182228, 0.9045777837914157, 0.9004273931664157, 0.9035497458584337, 0.9049748799887049, 0.9005803487387049, 0.9059308523155121, 0.9054013907191265, 0.9020451924887049, 0.9028379141566265, 0.9016172110316265, 0.9021054922816265, 0.9078942724021084, 0.9060632177146084, 0.9071618505271084, 0.9052087255271084], "seed": 844229759, "model": "residualv3", "loss_std": [0.3511127233505249, 0.15067213773727417, 0.1429969221353531, 0.13825024664402008, 0.13343583047389984, 0.1289125680923462, 0.12301312386989594, 0.12053589522838593, 0.11735173314809799, 0.11446058005094528, 0.11241760849952698, 0.10917220264673233, 0.10660486668348312, 0.10438543558120728, 0.10258559137582779, 0.09995850175619125, 0.09949729591608047, 0.09768962115049362, 0.09577469527721405, 0.09250085800886154, 0.08973415195941925, 0.08886735886335373, 0.08492168039083481, 0.08246567100286484, 0.07968290150165558, 0.07932921499013901, 0.0793609470129013, 0.0736524909734726, 0.07080517709255219, 0.07195379585027695, 0.0682506412267685, 0.07042912393808365, 0.06546532362699509, 0.06526454538106918, 0.06432750076055527, 0.06103898957371712, 0.06128730624914169, 0.06217367202043533, 0.05908086895942688, 0.056716207414865494, 0.05797654017806053, 0.05431826412677765, 0.05186695605516434, 0.0523284375667572, 0.051020748913288116, 0.052372608333826065, 0.0495387502014637, 0.05113326013088226, 0.04879652336239815, 0.047286875545978546, 0.04785411059856415, 0.04645451158285141, 0.04765792563557625, 0.04557191953063011, 0.04139164835214615, 0.04240564629435539, 0.04240601137280464, 0.04242464527487755, 0.04338103160262108, 0.04399629309773445, 0.04233609512448311, 0.03951522335410118, 0.038924526423215866, 0.03689245507121086, 0.03751402348279953, 0.03960506618022919, 0.036859914660453796, 0.042537711560726166, 0.035010021179914474, 0.035943228751420975, 0.03613810986280441, 0.034404169768095016, 0.03462184965610504, 0.03421153128147125, 0.03475870192050934, 0.0323651060461998, 0.03346901759505272, 0.03199189528822899, 0.030256597325205803, 0.03332216665148735, 0.03186130151152611, 0.030364708974957466, 0.03135748207569122, 0.03235877305269241, 0.03255677595734596, 0.02949003502726555, 0.028131864964962006, 0.03123381920158863, 0.029825570061802864, 0.030198959633708, 0.029410846531391144, 0.027704890817403793, 0.026622727513313293, 0.027101241052150726, 0.027675973251461983, 0.028647085651755333, 0.027783460915088654, 0.02723565883934498, 0.025137262418866158, 0.024040628224611282, 0.02702096477150917, 0.026305465027689934, 0.025374293327331543, 0.0267565306276083, 0.024891380220651627, 0.02518135868012905, 0.023323627188801765, 0.026007799431681633, 0.022254889830946922, 0.02622283436357975, 0.025249382480978966, 0.023256292566657066, 0.024783780798316002, 0.023602744564414024, 0.024285299703478813, 0.023925259709358215, 0.02402772568166256, 0.022791704162955284, 0.024657780304551125, 0.023026298731565475, 0.02459072321653366, 0.022847717627882957, 0.023519976064562798, 0.02076665498316288, 0.021692711859941483, 0.02123219147324562, 0.02166609838604927, 0.0231234859675169, 0.020888861268758774, 0.021890005096793175, 0.020298991352319717, 0.020682448521256447, 0.02261454053223133, 0.019663458690047264, 0.019709400832653046, 0.021725311875343323, 0.022623741999268532, 0.019603347405791283, 0.02139885723590851, 0.02189868688583374, 0.019414229318499565, 0.020313063636422157, 0.020673004910349846, 0.019930273294448853, 0.019673580303788185, 0.021667780354619026, 0.01971394568681717, 0.01971512846648693, 0.018211370334029198, 0.019462378695607185, 0.019387073814868927, 0.019135134294629097, 0.02359476499259472, 0.02342885360121727, 0.017987586557865143, 0.017562029883265495, 0.019298816099762917, 0.018719568848609924, 0.01984546333551407, 0.02004554495215416, 0.02223818190395832, 0.016294734552502632, 0.019292959943413734, 0.019010286778211594, 0.01670941896736622, 0.017783379182219505, 0.0195729099214077, 0.01731102168560028, 0.01756112277507782, 0.02022506482899189, 0.02033633179962635, 0.017403360456228256, 0.01827877201139927, 0.018101688474416733, 0.018422894179821014, 0.018671853467822075, 0.016254084184765816, 0.018885768949985504, 0.0166704710572958, 0.01752367988228798, 0.017806774005293846, 0.018904967233538628, 0.01501031406223774, 0.016580283641815186, 0.01782137341797352, 0.01615530252456665, 0.013921408914029598, 0.016988171264529228, 0.01523508969694376, 0.016256051138043404, 0.01820077747106552, 0.017268914729356766, 0.014877920970320702, 0.014332152903079987, 0.017631500959396362, 0.016245700418949127, 0.014506537467241287, 0.015676477923989296, 0.01605062745511532, 0.015204938128590584, 0.01608729362487793, 0.01553539652377367, 0.018498748540878296, 0.017545627430081367, 0.018918994814157486, 0.012604552321135998, 0.014667565934360027, 0.014962776564061642, 0.016364185139536858, 0.016566473990678787, 0.015956038609147072, 0.015373529866337776, 0.014399997889995575, 0.014448306523263454, 0.014770781621336937, 0.017970843240618706, 0.0143465930595994, 0.015238090418279171, 0.015655381605029106, 0.013912207446992397, 0.016028348356485367, 0.0146095622330904, 0.015104454942047596, 0.016659844666719437, 0.015570237301290035, 0.015559593215584755, 0.014085200615227222, 0.01433012168854475, 0.01310129277408123, 0.012135060504078865, 0.015257398597896099, 0.014559481292963028, 0.01401595026254654, 0.014546125195920467, 0.014384482987225056, 0.015081970021128654, 0.014895172789692879, 0.014527535997331142, 0.01499866135418415]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:43 2016", "state": "available"}], "summary": "9d3b2a0080ae8acfbafd01188303887a"}