{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 64, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.7053438425064087, 1.381476640701294, 1.2210042476654053, 1.1073222160339355, 1.0160458087921143, 0.9381171464920044, 0.8684808015823364, 0.8042934536933899, 0.7428772449493408, 0.6824365854263306, 0.6224679350852966, 0.5622161626815796, 0.5040568113327026, 0.4486629366874695, 0.39868786931037903, 0.3582633137702942, 0.3269006907939911, 0.3018684387207031, 0.2893809378147125, 0.27303531765937805, 0.25905078649520874, 0.24787621200084686, 0.24301986396312714, 0.23610679805278778, 0.23376061022281647, 0.22892995178699493, 0.22653160989284515, 0.22217848896980286, 0.21844585239887238, 0.21641334891319275, 0.21473447978496552, 0.21216079592704773, 0.20972596108913422, 0.20981311798095703, 0.2070019245147705, 0.2064061462879181, 0.20508043467998505, 0.2028956562280655, 0.20385585725307465, 0.20180736482143402, 0.19919876754283905, 0.19954688847064972, 0.19919636845588684, 0.19973789155483246, 0.19719192385673523, 0.19540776312351227, 0.1982671320438385, 0.19620457291603088, 0.19440580904483795, 0.1922769695520401, 0.19220981001853943, 0.193129763007164, 0.19282788038253784, 0.19045063853263855, 0.18923373520374298, 0.191769540309906, 0.18989242613315582, 0.1902616322040558, 0.18798941373825073, 0.18733297288417816, 0.18783283233642578, 0.1860460788011551, 0.18701967597007751, 0.1848270148038864, 0.18571491539478302, 0.18489417433738708, 0.18530093133449554, 0.18405474722385406, 0.18444140255451202, 0.18447847664356232, 0.1826602667570114, 0.18189029395580292, 0.18168072402477264, 0.18183623254299164, 0.18141254782676697, 0.18012523651123047, 0.180692657828331, 0.1796165555715561, 0.1792677938938141, 0.17616377770900726, 0.1797151267528534, 0.17853766679763794, 0.1787857711315155, 0.17911219596862793, 0.178031325340271, 0.1792243868112564, 0.17784936726093292, 0.1776859611272812, 0.17639830708503723, 0.1756383776664734, 0.17626403272151947, 0.17439872026443481, 0.17637398838996887, 0.1752273440361023, 0.1741684228181839, 0.1746859848499298, 0.17416398227214813, 0.17361190915107727, 0.17308728396892548, 0.17395582795143127, 0.17374642193317413, 0.17305004596710205, 0.17239397764205933, 0.1728258579969406, 0.17106719315052032, 0.16924597322940826, 0.17026755213737488, 0.16981752216815948, 0.17068476974964142, 0.17029419541358948, 0.1703711599111557, 0.17111143469810486, 0.16950920224189758, 0.16900669038295746, 0.16729164123535156, 0.16745556890964508, 0.1673506498336792, 0.16654393076896667, 0.16788619756698608, 0.16746197640895844, 0.16688945889472961, 0.16655953228473663, 0.1656988263130188, 0.16703706979751587, 0.16767460107803345, 0.16327112913131714, 0.16266760230064392, 0.1653127372264862, 0.16379088163375854, 0.16436491906642914, 0.1633957326412201, 0.16468705236911774, 0.16262242197990417, 0.1615052968263626, 0.16294080018997192, 0.16244296729564667, 0.1619018167257309, 0.16273975372314453, 0.16198982298374176, 0.16047829389572144, 0.16101378202438354, 0.16159117221832275, 0.16107071936130524, 0.16021043062210083, 0.15964475274085999, 0.15886561572551727, 0.16037990152835846, 0.15871168673038483, 0.15970450639724731, 0.15961870551109314, 0.15859454870224, 0.15835276246070862, 0.15957073867321014, 0.15715602040290833, 0.15757068991661072, 0.15743501484394073, 0.15722456574440002, 0.1567501276731491, 0.15658995509147644, 0.15565869212150574, 0.15746700763702393, 0.15516245365142822, 0.15705819427967072, 0.152900829911232, 0.15466786921024323, 0.15441814064979553, 0.1556181162595749, 0.15457940101623535, 0.15319523215293884, 0.15306876599788666, 0.15262147784233093, 0.15129739046096802, 0.1530681550502777, 0.15166085958480835, 0.15372811257839203, 0.1528521478176117, 0.151310533285141, 0.1507897526025772, 0.15078270435333252, 0.1513398289680481, 0.15087537467479706, 0.15095427632331848, 0.1499539464712143, 0.1499401330947876, 0.14939291775226593, 0.1483658254146576, 0.14928439259529114, 0.14869539439678192, 0.1497393101453781, 0.14797431230545044, 0.14934596419334412, 0.14754325151443481, 0.14682228863239288, 0.1481933295726776, 0.14619523286819458, 0.1471700519323349, 0.1458645612001419, 0.14607815444469452, 0.14605946838855743, 0.14461955428123474, 0.14516489207744598, 0.14520765841007233, 0.14300647377967834, 0.14243721961975098, 0.1432507038116455, 0.14445509016513824, 0.14341148734092712, 0.14341624081134796, 0.14203786849975586, 0.14421574771404266, 0.14273636043071747, 0.14211726188659668, 0.14068034291267395, 0.141202911734581, 0.142067551612854, 0.14100217819213867, 0.1408008188009262, 0.14026300609111786, 0.14092332124710083, 0.14112283289432526, 0.14019222557544708, 0.13882045447826385, 0.1397298276424408, 0.13867661356925964, 0.13911907374858856, 0.13852576911449432, 0.13889440894126892, 0.13789516687393188, 0.13639923930168152, 0.13612982630729675, 0.13660383224487305, 0.1373651623725891, 0.1365640014410019, 0.13780851662158966, 0.13568955659866333, 0.1362973302602768, 0.13470080494880676, 0.13445140421390533], "moving_avg_accuracy_train": [0.04411283136074196, 0.09332265206833701, 0.14238644513946563, 0.19086537327109862, 0.2383854813274328, 0.28603330890413026, 0.3314713317766371, 0.37536888759860426, 0.4158645516430535, 0.45370995628056615, 0.48893096156382365, 0.5223239264827919, 0.5517107097873551, 0.580287894045792, 0.6075184182140255, 0.628634290926353, 0.651369791327996, 0.6541095656097405, 0.666440770593617, 0.6834291599655952, 0.6974217820481239, 0.7182399683112887, 0.7322219834137608, 0.7501925539677334, 0.7616582900057607, 0.7702876460365615, 0.7851723383127504, 0.7949468446877321, 0.8020519130682576, 0.8167988597447744, 0.8258236777085584, 0.8367172307687287, 0.8369791800282808, 0.8466550926017723, 0.8523460917395278, 0.8631424895965366, 0.8701671218834223, 0.8791302995010509, 0.8873740869593529, 0.8887514432827975, 0.892661866882028, 0.8908970860977565, 0.8935073893119935, 0.89904426097857, 0.9034250156439098, 0.9047689715476804, 0.9074500626669526, 0.913547792707474, 0.9189449607939155, 0.9252718340216946, 0.9263371172815775, 0.9303205663772939, 0.932603911669474, 0.9366138678977831, 0.9355525418142155, 0.9387307058971444, 0.942244204094344, 0.9454879129242507, 0.9456870791057551, 0.9481982005833303, 0.9496770680596041, 0.9448593279445352, 0.9485598511762906, 0.9459177357695788, 0.948631222868839, 0.9460865659404822, 0.9486786104238611, 0.9523762046636364, 0.9530466106830608, 0.9528851823863034, 0.9551832678298436, 0.9582466363218685, 0.9584997710873837, 0.9589159654787376, 0.9584022975368993, 0.9600092706832648, 0.9626504927589952, 0.9651019973890572, 0.965924960112084, 0.9668144721354364, 0.9684682183742737, 0.9693313412523779, 0.9705567613676347, 0.9720083757439757, 0.9706810839602297, 0.9706743119083373, 0.9711911232020458, 0.9724258415735172, 0.9712935357995635, 0.9725947067731785, 0.9728172080816025, 0.9736568391329846, 0.9754773531363528, 0.9726147602299711, 0.9741279668331737, 0.9745135426177873, 0.9757950183036368, 0.9754161454530627, 0.9758471453411266, 0.9774603626141845, 0.9779007823789749, 0.9788760501232203, 0.9758716577527865, 0.9741670499728475, 0.9757807939708101, 0.9733413691452961, 0.9743354862855376, 0.9747048522760776, 0.9742933421949723, 0.9747600006445873, 0.9755145983848998, 0.9762055423393223, 0.9774386897422949, 0.9777186245240639, 0.9780634275847621, 0.9793572882858188, 0.9801474860560742, 0.9794218302314744, 0.9806774708690413, 0.978583142825142, 0.9776376798023176, 0.9789114083613992, 0.9794974032014775, 0.9804618544361009, 0.9808276644532236, 0.9809245588317753, 0.9807976337890832, 0.9811577676566219, 0.9812099178243299, 0.9820309833335635, 0.9774718654242566, 0.9760209691699907, 0.9769773881375431, 0.9783009058702542, 0.9789502761082565, 0.9784140596939056, 0.978029085122171, 0.9793403670111629, 0.9784443791172633, 0.9796791822769655, 0.9808673071290492, 0.9813623077399724, 0.9821518942647939, 0.9833112398085526, 0.9844617157896298, 0.9851087722237714, 0.9848727427311837, 0.9839887447189088, 0.9843320368387031, 0.9840295577072506, 0.9843386136913245, 0.983542653473447, 0.982982146345233, 0.9838306741952519, 0.9842781650709925, 0.9845530236746353, 0.9854072242083807, 0.9860713369435042, 0.9840443058873506, 0.9842611702010242, 0.9823293416060787, 0.9835244208383279, 0.9843721996616565, 0.9846004163764617, 0.9843036874233855, 0.9845108896251222, 0.9854785495090478, 0.9846336638272459, 0.9846590949136058, 0.9854630886960547, 0.986561032058592, 0.986923968396845, 0.9868783709988365, 0.9873628169715811, 0.98757349520544, 0.987412008145675, 0.9881243973608693, 0.9881610089640681, 0.9880406077319747, 0.9878858157445376, 0.9879811987903312, 0.9879647009351076, 0.9882800960939961, 0.9879107291167947, 0.9875875633837328, 0.9883986545155976, 0.9882104190474266, 0.9886174998355596, 0.988493230097251, 0.9878700348387718, 0.984940373201517, 0.985293134169479, 0.9860640230585018, 0.986411447983641, 0.9864334147174383, 0.9866857357076269, 0.9870662483714064, 0.9872785014354747, 0.9874346519609933, 0.9872613644423118, 0.9874633343968902, 0.9882798729810107, 0.9875037354198974, 0.9879860627707648, 0.98858760414965, 0.9881571512859031, 0.988367234854941, 0.9887702598063701, 0.9892329276126471, 0.9882010132716944, 0.9888670901064389, 0.989296787345795, 0.989711524793386, 0.9897801940021702, 0.9885911743770086, 0.9890229946988592, 0.9893557573194587, 0.9897807656648937, 0.9897610945293751, 0.9903687834395328, 0.9903414638003599, 0.9903680293989139, 0.9899593886614034, 0.9896963878893477, 0.9853307636410644, 0.9863977616817199, 0.9870349363314235, 0.987785032728043, 0.986130716914864, 0.9867503821650535, 0.9870362187236035, 0.9871956711810235, 0.9874484243379303, 0.9882734293743755, 0.989118240454795, 0.9892461299509822, 0.9897472051999315, 0.9903562830430336], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04273137471762047, 0.0912517354574548, 0.13838803357963098, 0.18397850003529737, 0.2287282109786803, 0.2729205254229809, 0.31423890092096896, 0.35339797746102564, 0.38862482128118814, 0.42029338913424397, 0.44835461756833467, 0.47331057735705845, 0.4943386004760213, 0.5133513295191571, 0.5305339688281601, 0.5432852947427838, 0.5561255870399662, 0.5557011636898852, 0.5624647081360323, 0.5701876403250646, 0.5782033795399226, 0.5887868325309605, 0.5953200409853192, 0.6048418890140463, 0.6099384312402772, 0.6147551938203158, 0.6226865009631337, 0.6272264916800734, 0.630326802320048, 0.6376042689253926, 0.6410848764831545, 0.6462621745558481, 0.6459481864865585, 0.6498080459252521, 0.6525016989287359, 0.6583246888626695, 0.661496214470002, 0.666041334881059, 0.6707250873116277, 0.6704347463138987, 0.6720340557092408, 0.6702903404621119, 0.6720385148590483, 0.6752536439830833, 0.6777861968005129, 0.6775293732895128, 0.6786970402527301, 0.6822820025489933, 0.6857780528117898, 0.6892032007497374, 0.689973557444342, 0.6919903853877842, 0.6936427210959938, 0.6960515276290902, 0.6948166332434402, 0.6962991489006474, 0.6984758452210494, 0.6995925867531614, 0.6999222964513392, 0.7014528277719433, 0.701334871096029, 0.6983029935496792, 0.7008987754729492, 0.6983255465514073, 0.6997095475720949, 0.6969949228224155, 0.699012621569918, 0.701015626873393, 0.7010491945512646, 0.7012961905705357, 0.7024106297777895, 0.7055194114912756, 0.7052370251237745, 0.7048831621257043, 0.7033032431740526, 0.7042190361382739, 0.7062223313666904, 0.7082754676765575, 0.7084732821193687, 0.7094702157203083, 0.7108883873429311, 0.7115807162479453, 0.7123055865470965, 0.7133516833423116, 0.7127031678695261, 0.7122862843468807, 0.7116953335759728, 0.7134260437707098, 0.7119917837083979, 0.7133266379523924, 0.7136408644527104, 0.7149287629001351, 0.7169942803412963, 0.7139193993233564, 0.7161896864241533, 0.7172299092350511, 0.7187551357908382, 0.7184095897381098, 0.7186468851882446, 0.7201655739284563, 0.7213484058899028, 0.7219948270667258, 0.7201116682493605, 0.7178308878137316, 0.7192115968015602, 0.7153950822644765, 0.7153742169691282, 0.7156475245173208, 0.7146726511130285, 0.71537320767906, 0.7159304664009883, 0.7169842571102871, 0.7175807238597253, 0.7181104844462678, 0.7180592781044273, 0.71893077875784, 0.7200610442555498, 0.7190680940092117, 0.7208804287630344, 0.7185196837500593, 0.717895448573472, 0.7194313343448898, 0.7189052166295273, 0.7202180552828397, 0.7213315154266189, 0.721107778887722, 0.7213326325878052, 0.7206418286193108, 0.7214096475928466, 0.723036655113306, 0.7185895231580748, 0.7163490349330053, 0.7173030221588312, 0.7195339457053729, 0.72032210328092, 0.7196092524219545, 0.7191599106229066, 0.7202041687605407, 0.7184297750396071, 0.7203131482510079, 0.7219614150335879, 0.7222962176190846, 0.7232362765330045, 0.7248779926767672, 0.7257218010898134, 0.7264607855610279, 0.726549052590392, 0.725486179522618, 0.7243585482514556, 0.7237129795708883, 0.7234789121766759, 0.7220047502511769, 0.7219903339139357, 0.7236101599446054, 0.7237759700043618, 0.72432303061876, 0.7260187337221702, 0.7270209936801489, 0.7249240689168027, 0.7251488001087067, 0.7233663125583029, 0.7244192356134666, 0.7256966032795296, 0.7251960788702513, 0.7245430878412833, 0.7245322149099411, 0.725920207886191, 0.7254440921239274, 0.7252545810195918, 0.7266599046382651, 0.72836723754605, 0.729017724352439, 0.7288289719661408, 0.7290925179641803, 0.7294120700551869, 0.7286457442149544, 0.7300965465347994, 0.7306198420413345, 0.7305648761448064, 0.7300402150551751, 0.731238618483769, 0.731382240633886, 0.7317179905915818, 0.7308766755779809, 0.7302965675551979, 0.7313278518294221, 0.7314797581468564, 0.7330102814850322, 0.7335606158177037, 0.7321332357589002, 0.7293246267443806, 0.7301021897194153, 0.7302870949944618, 0.7307242705194885, 0.7307534294991662, 0.7305965671121262, 0.7309569087536997, 0.7318652417864623, 0.7315971981706926, 0.7315065613261383, 0.7314798462703317, 0.7326114997268828, 0.7315109648709113, 0.7321512252174045, 0.7324090472080887, 0.7317193826039967, 0.7319767082743199, 0.731774878231903, 0.7329452702091644, 0.7310859959179167, 0.7318939119981883, 0.7324877886353424, 0.7328737342164617, 0.7333462440779481, 0.7320786965715087, 0.7323071503330325, 0.7327202782496539, 0.7336068477044325, 0.7337282259516851, 0.7343613392093027, 0.733961785201776, 0.7339582495185714, 0.7331910249055696, 0.7319623838702085, 0.7269787419628564, 0.7287528768968419, 0.7298164599244016, 0.7305498400520668, 0.7294785427467848, 0.7297340487883714, 0.7293627711685705, 0.7305567063069845, 0.7307604306781686, 0.7317026775670535, 0.7330033894319596, 0.7327080097790498, 0.7335693330010695, 0.7345530729407969], "moving_var_accuracy_train": [0.01751347701595134, 0.03755658740101906, 0.055466230775655934, 0.07107146595321866, 0.0842877653850679, 0.09629182810156933, 0.10524417059447452, 0.11206271219931155, 0.11561553023698852, 0.11694444908288325, 0.11641467709306422, 0.11480902033847284, 0.11110036560152974, 0.10734022818264263, 0.1032797183826692, 0.09696466726803127, 0.09192032734784614, 0.0827958518810957, 0.07588479424017555, 0.0708937631772435, 0.06556652811421938, 0.06291044721638782, 0.05837887321168086, 0.05544745854483059, 0.051085880616390994, 0.04664748462430876, 0.043976722739289396, 0.04043891923923151, 0.03684936528553585, 0.035121680683502535, 0.032342538668667216, 0.03017631028627322, 0.027159296814377117, 0.025285976690108083, 0.02304886626177069, 0.021793039495775046, 0.020057844675091148, 0.01877510718462846, 0.017509236751084543, 0.015775387069951685, 0.014335471077485278, 0.012929954030685554, 0.011698281773449297, 0.010804366126773613, 0.009896648617037316, 0.008923239712575106, 0.008095609987626156, 0.007620689793687239, 0.007120785624498249, 0.006768970985611903, 0.006102287342864794, 0.005634869408861787, 0.005118305459485501, 0.004751192654113549, 0.004286211106203142, 0.003948496538024994, 0.003664748910458015, 0.003392968842171146, 0.0030540289624647267, 0.002805377645894505, 0.0025445233224164797, 0.0024989665685219323, 0.002372314761368593, 0.0021979102496331856, 0.0020443863348105352, 0.0018982252112767885, 0.0017688709415834432, 0.0017150336758832677, 0.0015475753063728663, 0.001393052307590526, 0.0013012778471837758, 0.0012556081011267746, 0.0011306239858997092, 0.0010191205472522883, 0.0009195831853173113, 0.0008508661310238369, 0.000828564004401382, 0.0007997964785221869, 0.0007259122394613923, 0.0006604421002724483, 0.0006190117798474206, 0.0005638154317870406, 0.0005209487787382218, 0.0004878185595427986, 0.00045489203490131625, 0.0004094032441573661, 0.0003708667649613718, 0.0003475008535768734, 0.0003242898155107477, 0.0003070982470828788, 0.000276833983864845, 0.0002554954082003643, 0.0002597743085084654, 0.00030754682098661914, 0.0002974002869037407, 0.0002689982763844902, 0.0002568780681468533, 0.00023248216306428712, 0.00021090579488945897, 0.00021323744513134408, 0.00019365942674117267, 0.0001828538086237444, 0.0002458057894010615, 0.00024737639961181407, 0.00024607628686927467, 0.000275025799496354, 0.0002564176395434166, 0.00023200375670378331, 0.000210327445955067, 0.00019125463233693395, 0.00017725392885040172, 0.0001638251678987391, 0.00016112852376598636, 0.00014572094272778446, 0.0001322188508110069, 0.00013406364535355995, 0.0001262769934632524, 0.00011838848149890582, 0.00012073933404539867, 0.00014814129024002756, 0.0001413722641637769, 0.0001418364977273811, 0.00013074335752802789, 0.00012604051743092426, 0.00011464081840547735, 0.00010326123325028402, 9.308009962341719e-05, 8.493935728401096e-05, 7.646989831553768e-05, 7.489024561806232e-05, 0.00025447122605492183, 0.0002479700029152126, 0.0002314056377971379, 0.0002240303667166326, 0.00020542246539899742, 0.00018746797124627205, 0.000170055022909585, 0.00016852466235020835, 0.00015889734486931927, 0.00015673025997128308, 0.00015376199995140755, 0.00014059103039959457, 0.00013214294928125259, 0.00013102539316162581, 0.00012983520869278296, 0.00012061982608417974, 0.00010905923276810194, 0.00010518638186264532, 9.572838899199618e-05, 8.697899271747456e-05, 7.914073385735327e-05, 7.692863448760837e-05, 7.206328520585624e-05, 7.133695229559104e-05, 6.600548982087162e-05, 6.008486610675231e-05, 6.064330646273555e-05, 5.8548387341041466e-05, 8.967324273044102e-05, 8.112918963230293e-05, 0.0001066039261513159, 0.00010879746287836595, 0.00010438627699008805, 9.441639511132752e-05, 8.57671882445381e-05, 7.757686419172532e-05, 7.824646863118253e-05, 7.684630810588709e-05, 6.916749795667941e-05, 6.806840218096053e-05, 7.211087860892375e-05, 6.608529581865203e-05, 5.9495478341133236e-05, 5.565812161159631e-05, 5.049177731443372e-05, 4.567730221723458e-05, 4.567705754083892e-05, 4.112141547215409e-05, 3.713974203514517e-05, 3.3641412866003e-05, 3.035915290822641e-05, 2.7325687230446578e-05, 2.548838546365554e-05, 2.4167434591911914e-05, 2.269061595194959e-05, 2.634237377446235e-05, 2.4027029720314286e-05, 2.3115759660885257e-05, 2.0943170405530408e-05, 2.234420433669654e-05, 9.7356039682249e-05, 8.874039841868154e-05, 8.521478568978474e-05, 7.777964382827754e-05, 7.000602228199326e-05, 6.357841299260188e-05, 5.852368067901142e-05, 5.307677487996769e-05, 4.798854427154855e-05, 4.3459946921570694e-05, 3.948107899238502e-05, 4.1533588427364184e-05, 4.28017352085654e-05, 4.0615318748261695e-05, 3.981045514803472e-05, 3.749701664440188e-05, 3.4144530933779265e-05, 3.2191939843671364e-05, 3.089929934999063e-05, 3.739299427856766e-05, 3.764661999876086e-05, 3.5543715456477146e-05, 3.3537408264738505e-05, 3.022610658038026e-05, 3.9927404943518176e-05, 3.7612883562435075e-05, 3.4848173861205756e-05, 3.2989045318290426e-05, 2.969362336861468e-05, 3.0047833335511333e-05, 2.7049767266121048e-05, 2.4351142118747683e-05, 2.3418913178050557e-05, 2.1699546515163084e-05, 0.00019105766755843324, 0.00018219826417145333, 0.00016763236156233226, 0.00015593292684409392, 0.0001649704814472906, 0.0001519292985031932, 0.00013747169149670737, 0.00012395334812263217, 0.00011213297073530651, 0.00010704537345321323, 0.00010276418796228943, 9.263497067517554e-05, 8.563116125364533e-05, 8.040682749890176e-05], "duration": 54627.954139, "accuracy_train": [0.4411283136074197, 0.5362110384366925, 0.5839605827796235, 0.6271757264557954, 0.6660664538344407, 0.7148637570944075, 0.7404135376291989, 0.7704468899963085, 0.7803255280430971, 0.7943185980181802, 0.8059200091131414, 0.8228606107535069, 0.8161917595284238, 0.8374825523717239, 0.8525931357281286, 0.8186771453373015, 0.8559892949427832, 0.6787675341454411, 0.7774216154485051, 0.8363246643133997, 0.8233553807908823, 0.9056036446797711, 0.8580601193360096, 0.9119276889534883, 0.8648499143480066, 0.8479518503137689, 0.9191345687984496, 0.8829174020625692, 0.8659975284929864, 0.9495213798334257, 0.9070470393826136, 0.9347592083102622, 0.8393367233642488, 0.9337383057631967, 0.9035650839793282, 0.9603100703096161, 0.9333888124653931, 0.9597988980597084, 0.9615681740840717, 0.9011476501937985, 0.9278556792751015, 0.8750140590393135, 0.9170001182401256, 0.9488761059777593, 0.9428518076319674, 0.9168645746816169, 0.9315798827404023, 0.9684273630721669, 0.96751947357189, 0.9822136930717055, 0.9359246666205242, 0.9661716082387413, 0.9531540192990956, 0.9727034739525655, 0.9260006070621077, 0.9673341826435032, 0.97386568786914, 0.974681292393411, 0.9474795747392949, 0.9707982938815062, 0.9629868753460686, 0.9014996669089147, 0.9818645602620893, 0.9221386971091732, 0.9730526067621816, 0.9231846535852714, 0.972007010774271, 0.9856545528216132, 0.9590802648578812, 0.9514323277154854, 0.9758660368217055, 0.9858169527500923, 0.960777983977021, 0.9626617150009228, 0.9537792860603543, 0.9744720290005537, 0.9864214914405685, 0.9871655390596161, 0.9733316246193245, 0.9748200803456073, 0.9833519345238095, 0.9770994471553157, 0.9815855424049464, 0.9850729051310447, 0.9587354579065154, 0.9706133634413067, 0.9758424248454227, 0.9835383069167589, 0.9611027838339794, 0.9843052455357143, 0.9748197198574198, 0.9812135185954227, 0.9918619791666666, 0.946851424072536, 0.9877468262619971, 0.9779837246793098, 0.9873282994762828, 0.9720062897978959, 0.9797261443337025, 0.9919793180717055, 0.9818645602620893, 0.9876534598214286, 0.9488321264188816, 0.958825579953396, 0.9903044899524732, 0.9513865457156699, 0.9832825405477114, 0.9780291461909376, 0.9705897514650241, 0.9789599266911223, 0.9823059780477114, 0.9824240379291252, 0.9885370163690477, 0.9802380375599853, 0.9811666551310447, 0.9910020345953304, 0.9872592659883721, 0.9728909278100776, 0.9919782366071429, 0.959734190430048, 0.9691285125968992, 0.9903749653931341, 0.9847713567621816, 0.9891419155477114, 0.9841199546073275, 0.9817966082387413, 0.9796553084048542, 0.9843989724644703, 0.9816792693337025, 0.9894205729166666, 0.9364398042404946, 0.9629629028815985, 0.985585158845515, 0.9902125654646549, 0.9847946082502769, 0.9735881119647471, 0.9745643139765596, 0.9911419040120893, 0.9703804880721669, 0.9907924107142857, 0.9915604307978036, 0.9858173132382798, 0.9892581729881875, 0.9937453497023809, 0.9948159996193245, 0.9909322801310447, 0.9827484772978959, 0.9760327626084349, 0.9874216659168512, 0.9813072455241787, 0.9871201175479882, 0.9763790115125508, 0.9779375821913067, 0.9914674248454227, 0.9883055829526578, 0.9870267511074198, 0.9930950290120893, 0.9920483515596161, 0.9658010263819674, 0.9862129490240864, 0.9649428842515688, 0.9942801339285714, 0.9920022090716132, 0.9866543668097084, 0.9816331268456996, 0.986375709440753, 0.994187488464378, 0.97702969269103, 0.9848879746908453, 0.9926990327380952, 0.9964425223214286, 0.9901903954411223, 0.9864679944167589, 0.9917228307262828, 0.9894695993101699, 0.9859586246077889, 0.9945359002976191, 0.9884905133928571, 0.9869569966431341, 0.9864926878576044, 0.9888396462024732, 0.9878162202380952, 0.9911186525239941, 0.9845864263219823, 0.9846790717861758, 0.9956984747023809, 0.9865162998338871, 0.992281226928756, 0.9873748024524732, 0.9822612775124585, 0.9585734184662238, 0.988467982881137, 0.9930020230597084, 0.989538272309893, 0.9866311153216132, 0.9889566246193245, 0.9904908623454227, 0.9891887790120893, 0.9888400066906607, 0.9857017767741787, 0.9892810639880952, 0.9956287202380952, 0.9805184973698781, 0.9923270089285714, 0.9940014765596161, 0.9842830755121816, 0.9902579869762828, 0.9923974843692323, 0.99339693786914, 0.9789137842031194, 0.99486178161914, 0.9931640625, 0.9934441618217055, 0.9903982168812293, 0.9778899977505537, 0.992909377595515, 0.9923506209048542, 0.9936058407738095, 0.9895840543097084, 0.9958379836309523, 0.9900955870478036, 0.9906071197858989, 0.9862816220238095, 0.9873293809408453, 0.9460401454065154, 0.9960007440476191, 0.992769508178756, 0.9945359002976191, 0.9712418745962532, 0.9923273694167589, 0.9896087477505537, 0.9886307432978036, 0.9897232027500923, 0.9956984747023809, 0.9967215401785714, 0.9903971354166666, 0.9942568824404762, 0.9958379836309523], "end": "2016-01-30 06:53:50.493000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0], "moving_var_accuracy_valid": [0.01643373346731925, 0.03597838877750023, 0.05237702530571425, 0.06584573845995004, 0.07728399427960195, 0.08713224075513724, 0.09378389006375817, 0.09820640053661255, 0.09955413521272238, 0.09862480540022259, 0.0958492177312723, 0.09186949531893264, 0.08666214559366409, 0.08124928582530698, 0.07578154508538593, 0.06966675739007594, 0.0641839396075621, 0.057767166863426735, 0.05240215997835912, 0.047698737114890734, 0.043507132079847174, 0.04016450416678403, 0.03653219906447857, 0.03369496946697029, 0.03055924520424705, 0.02771213149959448, 0.025507069046578446, 0.023141865783309686, 0.020914186539557775, 0.01929942156732915, 0.01747851107133658, 0.015971899702204573, 0.014375597028553023, 0.013072123959675967, 0.011830213462236968, 0.010952357021949504, 0.009947648491856243, 0.009138806718629685, 0.008422363878244448, 0.007580886171474664, 0.006845817669205462, 0.006188600788052543, 0.005597245732746224, 0.00513055465702956, 0.004675223605284241, 0.004208294869598039, 0.0037997363978711394, 0.0035354303500746793, 0.003291888622027203, 0.0030682845053959184, 0.002766797099788626, 0.002526725744390811, 0.0022986250895853486, 0.0021209837208518044, 0.0019226100260600128, 0.0017501296975187916, 0.0016177587896081822, 0.001467206915493257, 0.0013214646003095838, 0.0012104008753887746, 0.0010894860118464318, 0.001063267943766334, 0.00101758390352828, 0.0009754190769193895, 0.0008951162986548291, 0.0008719273565734922, 0.0008213745950371987, 0.0007753454077452221, 0.0006978210080716791, 0.0006285879705663334, 0.0005769069462296775, 0.0006061969652856608, 0.0005462949473020487, 0.000492792423764473, 0.0004659784764321212, 0.0004269287195687634, 0.0004203545735616572, 0.00041625743456754385, 0.0003749838660948515, 0.00034643036892750866, 0.00032988822879567075, 0.00030121327973056607, 0.00027582088431283403, 0.0002580876624261833, 0.00023606404704954337, 0.00021402176918766804, 0.00019576259759163158, 0.0002031445578359693, 0.00020134401938946017, 0.00019724614012490643, 0.00017841017075393464, 0.00017549729537645273, 0.000196344826536477, 0.0002618043833532113, 0.00028201177669829317, 0.0002635491704952754, 0.0002581310978640502, 0.00023339260674865074, 0.00021056012824967777, 0.00021026185483152176, 0.00020182749238954482, 0.00018540548619119712, 0.00019878152175486515, 0.00022572100413930307, 0.00022030611950701016, 0.0003293675564622525, 0.000296434719060977, 0.00026746352029797073, 0.0002492705716577421, 0.0002287605300118563, 0.00020867931255915746, 0.00019780565503428097, 0.0001812270427795207, 0.0001656301550130537, 0.00014909073831675064, 0.00014101728498516435, 0.00013841305734447036, 0.00013344530333534967, 0.0001496617883410407, 0.00018485366265351866, 0.00016987532238936702, 0.00017411829607602504, 0.00015919766512218658, 0.00015878980657664635, 0.00015406896734504672, 0.00013911259296007982, 0.00012565636634204186, 0.0001173856208138259, 0.00011095297251753715, 0.00012368205651046386, 0.00028930669450456375, 0.0003055541124341842, 0.00028318952583411815, 0.0002996637520853289, 0.0002752881081518257, 0.00025233270446079365, 0.0002289166064860584, 0.00021583922135958664, 0.00022259155691562485, 0.00023225625310485938, 0.00023348167827338094, 0.00021114234538733987, 0.00019798150770336756, 0.00020244044400325367, 0.00018860451334427566, 0.00017465894444811274, 0.0001572631696195563, 0.0001517041450813972, 0.00014797770112658754, 0.00013693076130589274, 0.00012373077308060356, 0.0001309160762158592, 0.00011782633907128835, 0.00012965823249087532, 0.00011693984602503533, 0.00010793933926496292, 0.0001230240864726996, 0.00011976240303573788, 0.00014736000390037546, 0.0001330785404878695, 0.00014836604324518362, 0.0001435072615615224, 0.00014384154879409875, 0.000131712116073239, 0.00012237848002112802, 0.00011014169600473896, 0.00011646624692333557, 0.00010685979820268539, 9.649704851041501e-05, 0.00010462175391818399, 0.00012039444944841375, 0.00011216320227114753, 0.0001012675292140319, 9.176588473037262e-05, 8.350831810713598e-05, 8.044278393709555e-05, 9.134195188479266e-05, 8.467230038075211e-05, 7.623226159070707e-05, 7.108645876239373e-05, 7.690334988514559e-05, 6.939866079466931e-05, 6.347334702203652e-05, 6.349631088882619e-05, 6.0175407662818635e-05, 6.372979218489576e-05, 5.756449272989424e-05, 7.289055865521204e-05, 6.832731368914347e-05, 7.983130681065826e-05, 0.00014284273749755577, 0.0001339999013691054, 0.00012090762087885478, 0.00011053696074811072, 9.949091688816222e-05, 8.976327747555732e-05, 8.195556461586872e-05, 8.118562823995056e-05, 7.371369183554965e-05, 6.641625799031136e-05, 5.978105543914098e-05, 6.532870580674471e-05, 6.969642794894232e-05, 6.641618495567246e-05, 6.0372816070028716e-05, 5.861626985826234e-05, 5.335059137790174e-05, 4.838215053430974e-05, 5.5872291904821796e-05, 8.139717072519369e-05, 7.913200918752692e-05, 7.439301341019092e-05, 6.829429799344204e-05, 6.347425831691454e-05, 7.158692261494954e-05, 6.489795044384407e-05, 5.994422747888748e-05, 6.102385331431629e-05, 5.505406209303951e-05, 5.31561474564765e-05, 4.927732335520428e-05, 4.4349703529185374e-05, 4.5212435637427526e-05, 5.427722121764557e-05, 0.00027237967904233284, 0.0002734697040139871, 0.0002563036133212077, 0.00023551386969397585, 0.0002222915839713182, 0.00020064997560977158, 0.00018182560168748032, 0.00017647237155138975, 0.0001591986669709799, 0.00015126926307040218, 0.00015136899896292926, 0.0001370173413208145, 0.00012999250642384687, 0.00012570295420259568], "accuracy_test": 0.4514090401785714, "start": "2016-01-29 15:43:22.539000", "learning_rate_per_epoch": [0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524, 0.00017512562044430524], "accuracy_train_first": 0.4411283136074197, "accuracy_train_last": 0.9958379836309523, "batch_size_eval": 1024, "accuracy_train_std": [0.016650471339707918, 0.016768222346025024, 0.020930227977158503, 0.022391482919646884, 0.021567176011609745, 0.023715801462350423, 0.02146555103995751, 0.02418185837420549, 0.02389879391410444, 0.02513902895771063, 0.025246773850041013, 0.029329662850272876, 0.02761108459009261, 0.030504316208289348, 0.03030003526045632, 0.027369617786504773, 0.027987295755422695, 0.021203953555527188, 0.025580055956231938, 0.02519906936484823, 0.022467004045169804, 0.02181676198071379, 0.023703572637300437, 0.02045189893242885, 0.020958622655459495, 0.019680620251760716, 0.01866363834751686, 0.01904686323792995, 0.017006676885344622, 0.015924769580724734, 0.017634605622526934, 0.01588377882038538, 0.015123571784764886, 0.013128355789702907, 0.014779855569276572, 0.010492872219177609, 0.014002983493042829, 0.010699976231755242, 0.012125801062294415, 0.015869094854542028, 0.014654921730617087, 0.015315911134198426, 0.014072961346404787, 0.012204135913692966, 0.01208031544597702, 0.012550494004058034, 0.011379095069653039, 0.0077092201827375475, 0.008993028739611454, 0.005516476662068185, 0.012620548124315184, 0.008195668644276604, 0.010577061354238458, 0.008924163063635403, 0.00940367378020965, 0.00926526773408765, 0.00800257508135131, 0.006953485394777568, 0.011592425379664869, 0.007472243359694058, 0.008570881421009964, 0.013571912346409603, 0.005767962347095959, 0.012413719031537618, 0.006657785026381795, 0.012256051852904792, 0.007093868472060718, 0.0048726645485320285, 0.009480180095291202, 0.009906131536313357, 0.007007043584280165, 0.005554737191866984, 0.009788893394365297, 0.00868941754431759, 0.00941948208987942, 0.008069534929955843, 0.0044241120154574045, 0.004360786775153576, 0.00695605658989849, 0.007811455303266143, 0.005706049721048352, 0.006739837714780281, 0.005553102675458978, 0.004940561641842599, 0.0065764323749669855, 0.007196798165490052, 0.007362724410746555, 0.00558071359094886, 0.008271943169014508, 0.005558662021794752, 0.00591897176327492, 0.005647370967157731, 0.003466889661386868, 0.010177379901430646, 0.005825820134972782, 0.005083407483155655, 0.004753965868855556, 0.007476018640013388, 0.0058072256013332975, 0.0034005839783352405, 0.0061785111805034406, 0.004797532001595027, 0.006835160468632175, 0.009372602221047854, 0.004162427824486097, 0.008325127987877646, 0.00568405916866541, 0.0057507206456784464, 0.006898631940012337, 0.005585697058392509, 0.005129786392904385, 0.005009346188588107, 0.0038184154148943822, 0.005846208031405673, 0.006710402082607335, 0.0038159655707808763, 0.00514670644221117, 0.006224954362789075, 0.0033528129846270693, 0.007065048700418632, 0.008150384402357044, 0.004308442298973908, 0.004786564750080879, 0.004011463670910597, 0.005907387180492235, 0.003831899450155275, 0.005238222113790175, 0.004350963760519331, 0.003797062669392719, 0.003402432447976379, 0.00840926553786076, 0.007933618390187878, 0.004985062721803577, 0.003531448712210493, 0.005103766997289487, 0.005975553463215287, 0.006603020339131719, 0.0036387092171981977, 0.006272817298698455, 0.0037890652394968706, 0.003597384129311539, 0.004173590316581548, 0.004650049448445041, 0.0037463768535040487, 0.0027078143392741255, 0.003914372533203312, 0.005238228982602111, 0.005538540867984945, 0.004183986969408769, 0.005337227238510375, 0.0035503428365322113, 0.0050400185467425985, 0.005456904751072988, 0.0028923001204399596, 0.0038874122221745047, 0.004417082311823288, 0.00288665510292948, 0.0037318464444648196, 0.0061568942146763075, 0.005218123473087028, 0.006272431801868732, 0.0033665713909483384, 0.0038261914457147373, 0.004726703148094283, 0.004951726931427299, 0.004567195912091251, 0.002898627638134384, 0.005956666461735021, 0.005166180501941661, 0.0035864619577118378, 0.002042031412988902, 0.004184263523980482, 0.004529414452244436, 0.0031560795992259284, 0.003197919141843747, 0.0035786114299175345, 0.0027378565524302364, 0.0043856645953175635, 0.004144106199188299, 0.003617845445836054, 0.004358416176262185, 0.00420434228136001, 0.0036599726218075543, 0.004812043410277289, 0.004372164010847446, 0.0019186352535227168, 0.003076453438975464, 0.002661072622395915, 0.004018355136084108, 0.004646898219985029, 0.00600231060959886, 0.004200249909673497, 0.0028750432106015187, 0.0038267101895443486, 0.004494355655266882, 0.00359593362274676, 0.003741393846782906, 0.003626595504866254, 0.004285305918174807, 0.005021447394420568, 0.003432804849583129, 0.002523616731996863, 0.005119958776949138, 0.003186387186221335, 0.0022816576632720166, 0.004016759716309458, 0.0030779382921872155, 0.002996006336387287, 0.002801993543933159, 0.00598498566771796, 0.0030519965553928966, 0.0032458944134328774, 0.002347235062278296, 0.003528107085806184, 0.005721402617191531, 0.003118302737947677, 0.0030955587956637822, 0.0028126613102616893, 0.003533109618507793, 0.002522009503260224, 0.003869821619208738, 0.003495981285557279, 0.004840555527952093, 0.003401644247266191, 0.007561979116852662, 0.001939235441033579, 0.00267158562496719, 0.003189863508076777, 0.007069406551745522, 0.003107675791857378, 0.0036583059761425953, 0.004310059955248366, 0.0035234337664023785, 0.002315479335999918, 0.0021818024902707407, 0.003793699572920248, 0.002374954844190181, 0.002627829653300804], "accuracy_test_std": 0.01742209596965946, "error_valid": [0.5726862528237951, 0.4720650178840362, 0.4373852833207832, 0.40570730186370485, 0.3685243905308735, 0.32934864457831325, 0.3138957195971386, 0.2941703336784638, 0.29433358433734935, 0.294689500188253, 0.29909432652484935, 0.3020857845444277, 0.31640919145331325, 0.3155341090926205, 0.31482227739081325, 0.34195277202560237, 0.3283117822853916, 0.4481186464608433, 0.3766633918486446, 0.3603059699736446, 0.3496549675263554, 0.3159620905496988, 0.34588108292545183, 0.3094614787274097, 0.3441926887236446, 0.3418939429593373, 0.30593173475150603, 0.3319135918674698, 0.3417704019201807, 0.29689853162650603, 0.32758965549698793, 0.3071421427899097, 0.35687770613704817, 0.31545321912650603, 0.3232554240399097, 0.2892684017319277, 0.30996005506400603, 0.2930525814194277, 0.287121140813253, 0.3321783226656627, 0.3135721597326807, 0.34540309676204817, 0.31222791556852414, 0.29581019390060237, 0.2994208278426205, 0.32478203830948793, 0.31079395707831325, 0.2854533367846386, 0.28275749482304224, 0.2799704678087349, 0.3030932323042168, 0.2898581631212349, 0.2914862575301205, 0.28226921357304224, 0.3162974162274097, 0.29035821018448793, 0.28193388789533136, 0.29035673945783136, 0.29711031626506024, 0.2847723903426205, 0.2997267389871988, 0.3289839043674698, 0.2757391872176205, 0.3248335137424698, 0.2878344432417168, 0.3274366999246988, 0.28282808970256024, 0.28095732539533136, 0.2986486963478916, 0.29648084525602414, 0.2875594173569277, 0.26650155308734935, 0.2973044521837349, 0.2983016048569277, 0.31091602739081325, 0.2875388271837349, 0.27574801157756024, 0.2732463055346386, 0.28974638789533136, 0.2815573818712349, 0.2763480680534638, 0.2821883236069277, 0.28117058076054224, 0.277233445500753, 0.29313347138554224, 0.2914656673569277, 0.2936232233621988, 0.2709975644766567, 0.3009165568524097, 0.2746596738516567, 0.2835310970444277, 0.27348015107304224, 0.264416062688253, 0.31375452983810237, 0.2633777296686747, 0.27340808546686746, 0.26751782520707834, 0.2847003247364458, 0.27921745576054224, 0.2661662274096386, 0.26800610645707834, 0.27218738234186746, 0.2968367611069277, 0.3026961361069277, 0.2683620223079819, 0.31895354856927716, 0.28481357068900603, 0.2818927075489458, 0.29410120952560237, 0.2783217832266567, 0.2790542051016567, 0.27353162650602414, 0.27705107539533136, 0.27712167027484935, 0.2824015789721386, 0.2732257153614458, 0.26976656626506024, 0.28986845820783136, 0.26280855845256024, 0.3027270213667168, 0.28772266801581325, 0.26674569371234935, 0.2858298428087349, 0.26796639683734935, 0.26864734327936746, 0.28090584996234935, 0.2766436841114458, 0.2855754070971386, 0.27167998164533136, 0.26232027720256024, 0.32143466443900603, 0.3038153590926205, 0.2741110928087349, 0.260387742375753, 0.2725844785391567, 0.2868064053087349, 0.28488416556852414, 0.270397508000753, 0.29753976844879515, 0.26273649284638556, 0.2632041839231928, 0.2746905591114458, 0.2683031932417168, 0.26034656202936746, 0.2666839231927711, 0.26688835419804224, 0.27265654414533136, 0.28407967808734935, 0.28579013318900603, 0.2820971385542168, 0.2786276943712349, 0.29126270707831325, 0.2781394131212349, 0.26181140577936746, 0.27473173945783136, 0.2707534238516567, 0.2587199383471386, 0.26395866669804224, 0.29394825395331325, 0.2728286191641567, 0.29267607539533136, 0.26610445689006024, 0.26280708772590367, 0.279308640813253, 0.2813338314194277, 0.2755656414721386, 0.26158785532756024, 0.2788409497364458, 0.2764510189194277, 0.2606921827936747, 0.25626676628388556, 0.26512789439006024, 0.27286979951054224, 0.2685355680534638, 0.267711961125753, 0.2782511883471386, 0.25684623258659633, 0.26467049839984935, 0.2699298169239458, 0.27468173475150603, 0.25797575065888556, 0.26732516001506024, 0.2652602597891567, 0.2766951595444277, 0.27492440464984935, 0.25939058970256024, 0.2671530849962349, 0.25321500847138556, 0.261486375188253, 0.28071318477033136, 0.29595285438629515, 0.2628997435052711, 0.2680487575301205, 0.2653411497552711, 0.2689841396837349, 0.2708151943712349, 0.2658000164721386, 0.2599597609186747, 0.2708151943712349, 0.26930917027484935, 0.2687605892319277, 0.2572036191641567, 0.27839384883283136, 0.2620864316641567, 0.265270554875753, 0.27448759883283136, 0.2657073606927711, 0.27004159214984935, 0.2565212019954819, 0.28564747270331325, 0.26083484327936746, 0.2621673216302711, 0.2636527555534638, 0.2624011671686747, 0.2793292309864458, 0.265636765813253, 0.263561570500753, 0.25841402720256024, 0.26517936982304224, 0.2599406414721386, 0.2696342008659638, 0.2660735716302711, 0.2737139966114458, 0.27909538544804224, 0.31787403520331325, 0.2552799086972892, 0.26061129282756024, 0.2628497387989458, 0.280163133000753, 0.26796639683734935, 0.2739787274096386, 0.2586978774472892, 0.2674060499811747, 0.2598171004329819, 0.25529020378388556, 0.2699504070971386, 0.258678758000753, 0.2565932676016567], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.014798034394882743, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.00017512561721335393, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 3.704645927816043e-05, "rotation_range": [0, 0], "momentum": 0.8964876297778029}, "accuracy_valid_max": 0.7467849915286144, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7434067323983433, "accuracy_valid_std": [0.011172404450909367, 0.01880723638016131, 0.014135088019269864, 0.01625135832497071, 0.017561726661203463, 0.01879455077170656, 0.01570276820070542, 0.01419372922962705, 0.01253012433993304, 0.008899585138562309, 0.010270796730076519, 0.011169572323786948, 0.010405602607881833, 0.006334875560900963, 0.01379445509435421, 0.01385711100857125, 0.011512007191376435, 0.0126033637446164, 0.00893163943504733, 0.014190356658061438, 0.011025909641476187, 0.01157282088557095, 0.017539367349325014, 0.011751167097832568, 0.0176622100502909, 0.01870993203967353, 0.014144588357375294, 0.014053837912191402, 0.009306666710889564, 0.014763423472994575, 0.014047772519319417, 0.012816905387003481, 0.011725931250972463, 0.011549913741060878, 0.007876659332632697, 0.011829913809067434, 0.010512731817278112, 0.010763041649111512, 0.006462985424037684, 0.017988305685713444, 0.016438922779378324, 0.014177627993368141, 0.006300281094971004, 0.015833280075164793, 0.011631291858909548, 0.010748096870818806, 0.01197069446673106, 0.01006219157848402, 0.009868465725238217, 0.0134493162549089, 0.012390588494802996, 0.007536790806156345, 0.0162995448647613, 0.012933866818762168, 0.012959540918138359, 0.024291402269088058, 0.012931457695035961, 0.01208926719605931, 0.01561570773752905, 0.01473983467804358, 0.018014801982391138, 0.014206609275368544, 0.017434639622458236, 0.015019554596071039, 0.016513790383059394, 0.011922933462733121, 0.013766697176723037, 0.012666968262951505, 0.01680333596095025, 0.010300107693374926, 0.014662115074237286, 0.013048837248078244, 0.013015119576531438, 0.012993486717795131, 0.009558570035680872, 0.011152368081992044, 0.013032523675547749, 0.014681646253292097, 0.01308888084055507, 0.01119489066688247, 0.009927662360527488, 0.012825714306800736, 0.0121725523142549, 0.011836266230679416, 0.00971905672471059, 0.009134050884418122, 0.019549243881728965, 0.0071627183107821025, 0.013594401843583773, 0.010851402701974485, 0.013392859685764274, 0.015903196249149185, 0.01236410466098945, 0.014341696182207668, 0.009321491075055493, 0.006871793994615153, 0.011001105290184636, 0.008094487777983227, 0.011114949544230096, 0.015258143701083315, 0.011057816105260626, 0.005787942313623542, 0.014190913093081249, 0.007509646675551562, 0.011051202455996447, 0.016661695019481018, 0.01936888059557759, 0.007941342034186425, 0.01664435100230951, 0.00590187324449587, 0.00942822179526047, 0.018224756695588967, 0.01421388698352193, 0.010283165022071689, 0.012925225743549425, 0.013171637443752538, 0.008397277898884021, 0.012912249686459782, 0.014151151754704138, 0.007918252320377623, 0.015400534319484798, 0.014119080998898982, 0.010825917720333393, 0.01151766451047306, 0.012326798676860672, 0.008624870298980698, 0.009389111603837279, 0.015221512385625333, 0.01871594014282978, 0.013968553217673573, 0.011259929291271847, 0.010272318839091564, 0.014646739568753455, 0.015446774756498003, 0.009142793997080657, 0.009971659920738389, 0.01287320103075898, 0.013472359600165103, 0.016363053886372613, 0.009688568550022257, 0.007352604290770216, 0.011443720240400208, 0.019577606104877302, 0.01007536332287172, 0.010088912154604932, 0.013827042039737171, 0.014156833053481442, 0.0061165907329359835, 0.017869460758734634, 0.015050966785347815, 0.013803839492555509, 0.014782228483989376, 0.011915131288787491, 0.010342317898212688, 0.016389367150865905, 0.011037098644895344, 0.017855508810710463, 0.015814169932650588, 0.01602201789514621, 0.009004808097024466, 0.010251068084645364, 0.008122764074525628, 0.014614222342356206, 0.01005394594378692, 0.012507264858785037, 0.011121056454502514, 0.011635450082464872, 0.01024697765571574, 0.0138241013699108, 0.010318428301196355, 0.009541931169401283, 0.011353614667373968, 0.010573789067679619, 0.006274579631690166, 0.011108264274017185, 0.011289226444794059, 0.004358187454177125, 0.010908191432121126, 0.014166556390388699, 0.022705448137682306, 0.010204897277516735, 0.009699207583463834, 0.011649321244358175, 0.015572528818931893, 0.011546348835298757, 0.010115529965871726, 0.016095109421883958, 0.007854373815717172, 0.012671598909024086, 0.011242514601974618, 0.01708153978433685, 0.008541070664990649, 0.02038451424602023, 0.0073207553739773525, 0.015606000791938988, 0.01546666884073518, 0.01903094601247738, 0.009850826579311118, 0.016909993688138232, 0.01460741404311552, 0.019878512980695488, 0.014379816419508994, 0.015046897112699176, 0.0118927737311338, 0.012111845313734541, 0.015456537266654446, 0.006207065905110723, 0.012227332280644924, 0.011331354379465431, 0.01613475034947643, 0.007999421542173209, 0.011759167276414283, 0.010734950532850165, 0.009593630134653513, 0.008115929180387659, 0.013141183571052262, 0.011758960520715471, 0.015518630927709097, 0.015623155322459415, 0.019320656987239376, 0.0062672362015739735, 0.013122700411582405, 0.012615677570410424, 0.01003687393776715, 0.0077682567989697335, 0.007483341078401789, 0.01159365297165299, 0.015325981688904276, 0.01557396054268677, 0.01137183959033844, 0.012285005029059808, 0.006127825282172801, 0.00351498594120957, 0.011892292380598548, 0.011126195492734255, 0.015173976580518694, 0.014430685940888323, 0.014328492615108376], "accuracy_valid": [0.42731374717620485, 0.5279349821159638, 0.5626147166792168, 0.5942926981362951, 0.6314756094691265, 0.6706513554216867, 0.6861042804028614, 0.7058296663215362, 0.7056664156626506, 0.705310499811747, 0.7009056734751506, 0.6979142154555723, 0.6835908085466867, 0.6844658909073795, 0.6851777226091867, 0.6580472279743976, 0.6716882177146084, 0.5518813535391567, 0.6233366081513554, 0.6396940300263554, 0.6503450324736446, 0.6840379094503012, 0.6541189170745482, 0.6905385212725903, 0.6558073112763554, 0.6581060570406627, 0.694068265248494, 0.6680864081325302, 0.6582295980798193, 0.703101468373494, 0.6724103445030121, 0.6928578572100903, 0.6431222938629518, 0.684546780873494, 0.6767445759600903, 0.7107315982680723, 0.690039944935994, 0.7069474185805723, 0.712878859186747, 0.6678216773343373, 0.6864278402673193, 0.6545969032379518, 0.6877720844314759, 0.7041898060993976, 0.7005791721573795, 0.6752179616905121, 0.6892060429216867, 0.7145466632153614, 0.7172425051769578, 0.7200295321912651, 0.6969067676957832, 0.7101418368787651, 0.7085137424698795, 0.7177307864269578, 0.6837025837725903, 0.7096417898155121, 0.7180661121046686, 0.7096432605421686, 0.7028896837349398, 0.7152276096573795, 0.7002732610128012, 0.6710160956325302, 0.7242608127823795, 0.6751664862575302, 0.7121655567582832, 0.6725633000753012, 0.7171719102974398, 0.7190426746046686, 0.7013513036521084, 0.7035191547439759, 0.7124405826430723, 0.7334984469126506, 0.7026955478162651, 0.7016983951430723, 0.6890839726091867, 0.7124611728162651, 0.7242519884224398, 0.7267536944653614, 0.7102536121046686, 0.7184426181287651, 0.7236519319465362, 0.7178116763930723, 0.7188294192394578, 0.722766554499247, 0.7068665286144578, 0.7085343326430723, 0.7063767766378012, 0.7290024355233433, 0.6990834431475903, 0.7253403261483433, 0.7164689029555723, 0.7265198489269578, 0.735583937311747, 0.6862454701618976, 0.7366222703313253, 0.7265919145331325, 0.7324821747929217, 0.7152996752635542, 0.7207825442394578, 0.7338337725903614, 0.7319938935429217, 0.7278126176581325, 0.7031632388930723, 0.6973038638930723, 0.7316379776920181, 0.6810464514307228, 0.715186429310994, 0.7181072924510542, 0.7058987904743976, 0.7216782167733433, 0.7209457948983433, 0.7264683734939759, 0.7229489246046686, 0.7228783297251506, 0.7175984210278614, 0.7267742846385542, 0.7302334337349398, 0.7101315417921686, 0.7371914415474398, 0.6972729786332832, 0.7122773319841867, 0.7332543062876506, 0.7141701571912651, 0.7320336031626506, 0.7313526567206325, 0.7190941500376506, 0.7233563158885542, 0.7144245929028614, 0.7283200183546686, 0.7376797227974398, 0.678565335560994, 0.6961846409073795, 0.7258889071912651, 0.739612257624247, 0.7274155214608433, 0.7131935946912651, 0.7151158344314759, 0.729602491999247, 0.7024602315512049, 0.7372635071536144, 0.7367958160768072, 0.7253094408885542, 0.7316968067582832, 0.7396534379706325, 0.7333160768072289, 0.7331116458019578, 0.7273434558546686, 0.7159203219126506, 0.714209866810994, 0.7179028614457832, 0.7213723056287651, 0.7087372929216867, 0.7218605868787651, 0.7381885942206325, 0.7252682605421686, 0.7292465761483433, 0.7412800616528614, 0.7360413333019578, 0.7060517460466867, 0.7271713808358433, 0.7073239246046686, 0.7338955431099398, 0.7371929122740963, 0.720691359186747, 0.7186661685805723, 0.7244343585278614, 0.7384121446724398, 0.7211590502635542, 0.7235489810805723, 0.7393078172063253, 0.7437332337161144, 0.7348721056099398, 0.7271302004894578, 0.7314644319465362, 0.732288038874247, 0.7217488116528614, 0.7431537674134037, 0.7353295016001506, 0.7300701830760542, 0.725318265248494, 0.7420242493411144, 0.7326748399849398, 0.7347397402108433, 0.7233048404555723, 0.7250755953501506, 0.7406094102974398, 0.7328469150037651, 0.7467849915286144, 0.738513624811747, 0.7192868152296686, 0.7040471456137049, 0.7371002564947289, 0.7319512424698795, 0.7346588502447289, 0.7310158603162651, 0.7291848056287651, 0.7341999835278614, 0.7400402390813253, 0.7291848056287651, 0.7306908297251506, 0.7312394107680723, 0.7427963808358433, 0.7216061511671686, 0.7379135683358433, 0.734729445124247, 0.7255124011671686, 0.7342926393072289, 0.7299584078501506, 0.7434787980045181, 0.7143525272966867, 0.7391651567206325, 0.7378326783697289, 0.7363472444465362, 0.7375988328313253, 0.7206707690135542, 0.734363234186747, 0.736438429499247, 0.7415859727974398, 0.7348206301769578, 0.7400593585278614, 0.7303657991340362, 0.7339264283697289, 0.7262860033885542, 0.7209046145519578, 0.6821259647966867, 0.7447200913027108, 0.7393887071724398, 0.7371502612010542, 0.719836866999247, 0.7320336031626506, 0.7260212725903614, 0.7413021225527108, 0.7325939500188253, 0.7401828995670181, 0.7447097962161144, 0.7300495929028614, 0.741321241999247, 0.7434067323983433], "seed": 150408482, "model": "residualv3", "loss_std": [0.21813516318798065, 0.11402326822280884, 0.10074023902416229, 0.09606899321079254, 0.0936184674501419, 0.09264951944351196, 0.0907568708062172, 0.08857031166553497, 0.08576924353837967, 0.08307957649230957, 0.07898671925067902, 0.07440990954637527, 0.06924430280923843, 0.06380552798509598, 0.057198282331228256, 0.051976319402456284, 0.046647049486637115, 0.0396578311920166, 0.06001143530011177, 0.04587901011109352, 0.03597208485007286, 0.03356437012553215, 0.031944096088409424, 0.028327709063887596, 0.029987115412950516, 0.027760792523622513, 0.029849402606487274, 0.027323493734002113, 0.028058243915438652, 0.028202718123793602, 0.02493749000132084, 0.024126283824443817, 0.027071328833699226, 0.02472248673439026, 0.02478974312543869, 0.023835470899939537, 0.0233567226678133, 0.02391480840742588, 0.023320147767663002, 0.022539887577295303, 0.021393414586782455, 0.02404025010764599, 0.021380364894866943, 0.02298770658671856, 0.023518042638897896, 0.0207747183740139, 0.034102801233530045, 0.02662436105310917, 0.019516978412866592, 0.021179594099521637, 0.02082710526883602, 0.0215314794331789, 0.018674373626708984, 0.020123811438679695, 0.019161265343427658, 0.023326998576521873, 0.02071361429989338, 0.019698025658726692, 0.017862895503640175, 0.020254086703062057, 0.018448837101459503, 0.020079968497157097, 0.019288405776023865, 0.017489079385995865, 0.021297667175531387, 0.019189603626728058, 0.0187623780220747, 0.0179853904992342, 0.01991049014031887, 0.02317889593541622, 0.01964343711733818, 0.01754900813102722, 0.017633015289902687, 0.017393948510289192, 0.018962247297167778, 0.017496390268206596, 0.018737688660621643, 0.017731832340359688, 0.015684818848967552, 0.01612481102347374, 0.01934927888214588, 0.01799876056611538, 0.019382594153285027, 0.019337596371769905, 0.019570359960198402, 0.019549980759620667, 0.019375009462237358, 0.01664016768336296, 0.01923401653766632, 0.016795197501778603, 0.01677224226295948, 0.014985037967562675, 0.017759686335921288, 0.017277201637625694, 0.01715398207306862, 0.01624559424817562, 0.015338202007114887, 0.017261918634176254, 0.01570953242480755, 0.015779569745063782, 0.016254348680377007, 0.016638752073049545, 0.016796883195638657, 0.018041767179965973, 0.014724320732057095, 0.01387446653097868, 0.014765564352273941, 0.01550251990556717, 0.015441902913153172, 0.014775712043046951, 0.017090290784835815, 0.017209675163030624, 0.016348982229828835, 0.015693960711359978, 0.013961275108158588, 0.013884488493204117, 0.013462385162711143, 0.014980992302298546, 0.014775265008211136, 0.01493957918137312, 0.013373126275837421, 0.014499695971608162, 0.01387141365557909, 0.017342519015073776, 0.017878098413348198, 0.01268243882805109, 0.012273473665118217, 0.01586383767426014, 0.013398908078670502, 0.014065575785934925, 0.013991856016218662, 0.014846580103039742, 0.012526181526482105, 0.014429132454097271, 0.014375387690961361, 0.013287783600389957, 0.014938358217477798, 0.014420614577829838, 0.014841309748589993, 0.011609594337642193, 0.01462580543011427, 0.013776740990579128, 0.013486883603036404, 0.014145948924124241, 0.014504324644804, 0.011969579383730888, 0.014392438344657421, 0.012459221296012402, 0.014123346656560898, 0.013681621290743351, 0.014427541755139828, 0.012800950556993484, 0.0387004055082798, 0.013582400977611542, 0.013051253743469715, 0.011288576759397984, 0.012582527473568916, 0.012148892506957054, 0.011607246473431587, 0.01273379847407341, 0.015454867854714394, 0.013641969300806522, 0.01385312806814909, 0.011183472350239754, 0.014674996957182884, 0.012357586994767189, 0.013708734884858131, 0.012329486198723316, 0.011387520469725132, 0.013718700036406517, 0.011059878394007683, 0.01058974489569664, 0.014743075706064701, 0.011301876977086067, 0.013773049227893353, 0.013108148239552975, 0.01176279317587614, 0.011549527756869793, 0.011968517675995827, 0.012279481627047062, 0.012788781896233559, 0.013105493038892746, 0.014667542651295662, 0.01324450969696045, 0.011307359673082829, 0.012323022820055485, 0.011517297476530075, 0.011845597997307777, 0.014845105819404125, 0.014232061803340912, 0.02994985692203045, 0.010491590015590191, 0.010250466875731945, 0.01365708652883768, 0.011273489333689213, 0.011916307732462883, 0.009995898231863976, 0.012954900972545147, 0.010800354182720184, 0.0102873919531703, 0.011252466589212418, 0.01140497624874115, 0.011109025217592716, 0.009813284501433372, 0.01153563242405653, 0.013637981377542019, 0.01162448339164257, 0.012532525695860386, 0.010530713014304638, 0.012548171915113926, 0.012234451249241829, 0.009625173173844814, 0.009068646468222141, 0.011147254146635532, 0.011562206782400608, 0.01112277153879404, 0.01053580641746521, 0.010722159408032894, 0.011483908630907536, 0.012786057777702808, 0.009917999617755413, 0.010214933194220066, 0.011195946484804153, 0.010916310362517834, 0.011238043196499348, 0.011999200098216534, 0.011643098667263985, 0.01081580575555563, 0.009674111381173134, 0.00918157771229744, 0.010184314101934433, 0.011091834865510464, 0.009404562413692474, 0.012676475569605827, 0.009601500816643238, 0.012256287969648838, 0.010490970686078072, 0.009738924913108349]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:23 2016", "state": "available"}], "summary": "71dc22432d18f4cc9b118ee851e3be72"}