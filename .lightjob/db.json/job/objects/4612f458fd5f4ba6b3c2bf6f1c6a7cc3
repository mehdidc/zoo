{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 64, "f3": 32, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.6629194021224976, 1.210864543914795, 1.018079400062561, 0.8850648403167725, 0.7783643007278442, 0.694693922996521, 0.6298412084579468, 0.5749708414077759, 0.5256064534187317, 0.4807891547679901, 0.43740251660346985, 0.39618682861328125, 0.3557847738265991, 0.31665360927581787, 0.28102028369903564, 0.24941281974315643, 0.22058752179145813, 0.19542372226715088, 0.1663704812526703, 0.14633363485336304, 0.12890625, 0.11056773364543915, 0.09413646906614304, 0.08341878652572632, 0.07130727916955948, 0.060591474175453186, 0.053793713450431824, 0.04492154344916344, 0.041249923408031464, 0.03368581831455231, 0.028091832995414734, 0.025509396567940712, 0.021438483148813248, 0.01707332953810692, 0.013211585581302643, 0.011536133475601673, 0.009516429156064987, 0.008557090535759926, 0.008261548355221748, 0.008152159862220287, 0.008102377876639366, 0.008069445379078388, 0.008044655434787273, 0.00802515633404255, 0.008009176701307297, 0.00799577496945858, 0.007984315045177937, 0.007974371314048767, 0.007965654134750366, 0.007957933470606804, 0.007951072417199612, 0.007944942452013493, 0.00793942529708147, 0.007934466935694218, 0.007929942570626736, 0.007925812155008316, 0.007922039367258549, 0.00791858695447445, 0.007915417663753033, 0.007912497967481613, 0.007909801788628101, 0.00790731143206358, 0.007905000820755959, 0.007902870886027813, 0.007900894619524479, 0.007899060845375061, 0.00789735373109579, 0.007895770482718945, 0.00789429061114788, 0.007892908528447151, 0.007891626097261906, 0.007890426553785801, 0.007889306172728539, 0.007888260297477245, 0.007887281477451324, 0.007886367850005627, 0.007885510101914406, 0.007884709164500237, 0.007883958518505096, 0.007883257232606411, 0.007882598787546158, 0.007881982252001762, 0.007881403900682926, 0.007880862802267075, 0.007880354300141335, 0.007879876531660557, 0.007879429496824741, 0.00787900947034359, 0.007878615520894527], "moving_avg_accuracy_train": [0.03504494927210225, 0.08358274609807585, 0.13738837032663112, 0.19115718285330724, 0.24572813400319246, 0.295632576682146, 0.3424551257288169, 0.38629939346001424, 0.4272819545465987, 0.46650252939463355, 0.5033122853375991, 0.538154448017156, 0.5697515603167692, 0.5994142066625839, 0.6273939984190369, 0.6526385900177016, 0.6755214468243479, 0.6968529819764923, 0.7179463238443653, 0.736993146592127, 0.7546397722591417, 0.7723212563427514, 0.7889623996441997, 0.804018483675027, 0.8181014544289714, 0.8313807028468163, 0.8443108419740487, 0.8563316167421292, 0.8676293307369825, 0.8781576353490077, 0.8879167776545924, 0.8970626928950856, 0.905749745778196, 0.9138750490646713, 0.9217040050582135, 0.9289291019107346, 0.9356944308934799, 0.9418971592696173, 0.9475075165938552, 0.9525661387809075, 0.9571188987492545, 0.9612187078695764, 0.9649271372683422, 0.9682716991736601, 0.9712864551860653, 0.9740020607460393, 0.9764484308988256, 0.9786501640363332, 0.98063172386009, 0.9824174528502807, 0.9840315843878809, 0.985484302771721, 0.9867917493171772, 0.9879684512080877, 0.9890274829099073, 0.9899806114415448, 0.9908407522688282, 0.9916172041621927, 0.9923183360150302, 0.9929470295337745, 0.9935128537006443, 0.9940244205996367, 0.9944848308087298, 0.9948991999969137, 0.9952721322662791, 0.9956077713087079, 0.995909846446894, 0.9961817140712613, 0.9964287200820016, 0.9966510254916678, 0.9968511003603675, 0.9970311677421971, 0.9971932283858438, 0.9973390829651259, 0.9974703520864797, 0.9975884942956982, 0.9976948222839948, 0.9977928426222712, 0.9978810609267199, 0.9979604574007238, 0.9980319142273273, 0.9980962253712704, 0.9981541054008193, 0.9982061974274132, 0.9982530802513478, 0.9982952747928889, 0.9983355750290854, 0.9983741703904718, 0.9984089062157196], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.035006235881024084, 0.08365522637424697, 0.13728686229292164, 0.19079215102597885, 0.24395914733151347, 0.29173311329301577, 0.33592494221220814, 0.3770018286385777, 0.41519584758194883, 0.45143622846757925, 0.4848124957281255, 0.5158816744309154, 0.5433647725186973, 0.5682907552630625, 0.590746494778172, 0.6110329910552494, 0.6288035859632788, 0.6449202212016647, 0.6605045592095102, 0.6743442694218423, 0.6864449751980315, 0.6986264671831228, 0.709315225302913, 0.718206656697697, 0.7267948824530026, 0.7348509340232144, 0.7430148487628357, 0.7501650005111757, 0.7565879300534316, 0.7625994707265523, 0.7682957665944091, 0.7732850670057514, 0.7781590028880075, 0.7822656658992821, 0.7864377368281792, 0.7903767356415962, 0.7942718675179486, 0.7980195678143466, 0.8014311781921739, 0.8044772134697186, 0.8071687875858491, 0.8095657607192069, 0.8117596576329791, 0.813734164855374, 0.8155356354180293, 0.8171325448619192, 0.8185453492989201, 0.8198046662609708, 0.8209502585580666, 0.8220057056879527, 0.8229556081048502, 0.823834934342558, 0.8246507420189949, 0.8253605548652881, 0.8259749723644522, 0.8265279481136998, 0.8270378333192725, 0.827496730004288, 0.827909737020802, 0.8282814433356644, 0.8285783284166311, 0.8288455249895011, 0.8290737948738341, 0.8292792377697339, 0.8294641363760437, 0.8296305451217224, 0.8297803129928333, 0.8299151040768331, 0.830036416052433, 0.8301211827679728, 0.8301852657807086, 0.8302429404921708, 0.8303070547637369, 0.8303647576081463, 0.8304166901681148, 0.8304634294720865, 0.830505494845661, 0.830531146650628, 0.8305420262438483, 0.8305640249089966, 0.8305838237076301, 0.8306016426264001, 0.8306176796532933, 0.8306321129774971, 0.8306451029692804, 0.8306567939618854, 0.83066731585523, 0.8306767855592401, 0.8306853082928491], "moving_var_accuracy_train": [0.011053336225357983, 0.031151262089297627, 0.05409154266798832, 0.07470215520594907, 0.09403383806998258, 0.10704453485485696, 0.11607124126242244, 0.12176499545214439, 0.12470462872587054, 0.12607844727597622, 0.12566522574160482, 0.12402448986914266, 0.12060743843329776, 0.11646554788409988, 0.11186481181630015, 0.10641393527952052, 0.10048516797226974, 0.09453196070256731, 0.0890831262727053, 0.08343984675649664, 0.07789849265773266, 0.07292235730654986, 0.06812247042930894, 0.06335039438346805, 0.05880032553242931, 0.05450733892607189, 0.050561301514110965, 0.04680566259692416, 0.04327384141081725, 0.039944064051767855, 0.03680682537345693, 0.033878972726387804, 0.03117025944389465, 0.02864741848098005, 0.02633430960042141, 0.024170696861134076, 0.02216555426122363, 0.02029526338887453, 0.018549022033737754, 0.016924426756246017, 0.015418532690585865, 0.01402795533493495, 0.012748931838892134, 0.011574713504049452, 0.010499040937973502, 0.009515507466192416, 0.008617819261893166, 0.007799665994983042, 0.007055038609500883, 0.006378234200788463, 0.0057638595662956975, 0.005206467125990853, 0.004701205161614795, 0.004243546291513968, 0.0038292855956717, 0.003454533122084924, 0.003115738390061268, 0.002809590448939525, 0.002533055676921144, 0.0022833074090936292, 0.002057858081074592, 0.0018544275791964352, 0.0016708926193225266, 0.0015053486738073193, 0.0013560655127243942, 0.0012214728435531784, 0.0011001468036998517, 0.0009907973313764795, 0.0008922667059629079, 0.0008034848126231188, 0.0007234966009385733, 0.0006514387592027068, 0.0005865312561524087, 0.0005280695925618456, 0.00047541771754564996, 0.00042800156402547597, 0.0003853031583927851, 0.00034685931443394896, 0.00031224342521371247, 0.0002810758168930995, 0.0002530141899064038, 0.0002277499942248809, 0.000205005145682778, 0.0001845290533276122, 0.0001660959299874717, 0.0001495023604027473, 0.00013456674134381004, 0.00012112347362671396, 0.00010902198546204336], "duration": 22928.041836, "accuracy_train": [0.35044949272102255, 0.5204229175318383, 0.6216389883836286, 0.6750764955933923, 0.7368666943521595, 0.744772560792728, 0.7638580671488556, 0.78089780304079, 0.7961250043258582, 0.8194877030269472, 0.8346000888242894, 0.8517339121331673, 0.854125571013289, 0.8663780237749169, 0.8792121242271133, 0.8798399144056847, 0.8814671580841639, 0.8888367983457919, 0.9077864006552234, 0.9084145513219823, 0.9134594032622739, 0.9314546130952381, 0.9387326893572352, 0.9395232399524732, 0.9448481912144703, 0.9508939386074198, 0.96068209411914, 0.9645185896548542, 0.9693087566906607, 0.9729123768572352, 0.9757490584048542, 0.9793759300595238, 0.9839332217261905, 0.9870027786429494, 0.9921646090000923, 0.9939549735834257, 0.9965823917381875, 0.9977217146548542, 0.9980007325119971, 0.998093738464378, 0.998093738464378, 0.9981169899524732, 0.9983030018572352, 0.9983727563215209, 0.9984192592977114, 0.9984425107858066, 0.9984657622739018, 0.9984657622739018, 0.9984657622739018, 0.9984890137619971, 0.9985587682262828, 0.9985587682262828, 0.9985587682262828, 0.9985587682262828, 0.9985587682262828, 0.9985587682262828, 0.998582019714378, 0.9986052712024732, 0.9986285226905685, 0.9986052712024732, 0.9986052712024732, 0.9986285226905685, 0.9986285226905685, 0.9986285226905685, 0.9986285226905685, 0.9986285226905685, 0.9986285226905685, 0.9986285226905685, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986517741786637, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986750256667589, 0.9986982771548542, 0.9987215286429494, 0.9987215286429494], "end": "2016-02-04 03:55:00.771000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0], "moving_var_accuracy_valid": [0.011028928955021085, 0.0312265545436062, 0.053991070431065075, 0.07435730668962895, 0.09236214148604067, 0.10366709375065361, 0.11087664406459678, 0.11497477504450086, 0.11660634528747013, 0.11676599761934323, 0.11511517480363564, 0.1122913021106651, 0.1078600580241224, 0.10266579376366168, 0.09693755652182953, 0.09094767825044546, 0.08469505681586839, 0.07856326451694623, 0.07289278238553663, 0.06732734235583494, 0.06191245184278855, 0.057056705381355315, 0.052379280794510194, 0.04785287068529253, 0.04373140221138013, 0.03994236169235932, 0.03654797105800565, 0.033353295982423675, 0.030389252599324363, 0.02767557493077319, 0.025200047517223333, 0.02290408083285258, 0.02082747000842642, 0.018896505137377312, 0.017163510206161317, 0.015586800590414092, 0.014164669002380274, 0.012874609419746837, 0.01169190024610305, 0.010606215199701164, 0.009610794820734663, 0.008701424660479552, 0.007874600847445925, 0.007122228871642937, 0.006439213650171668, 0.005818243363102362, 0.005254383174187009, 0.004743217769666487, 0.0042807074281003225, 0.0038626624030861536, 0.0034845169941921878, 0.00314302422646386, 0.0028347116833018758, 0.002555775023462555, 0.002303595100885809, 0.002075987630410531, 0.0018707287136752362, 0.0016855511178153766, 0.0015185311791950469, 0.0013679215515361206, 0.001231922663144214, 0.0011093729429067739, 0.0009989046128769372, 0.0008993940126405245, 0.0008097622988280096, 0.0007290352957809541, 0.0006563336399398126, 0.0005908637936727639, 0.0005319098636643028, 0.0004787835458624433, 0.0004309421509688907, 0.0003878778732230819, 0.00034912708165913976, 0.0003142443400575022, 0.00028284417896881593, 0.00025457942213475614, 0.00022913740538216617, 0.00020622958697983217, 0.00018560769357178671, 0.0001670512796860228, 0.0001503496796492665, 0.0001353175693091351, 0.00012178812705430572, 0.0001096111892365033, 9.865158897183178e-05, 8.878766018842144e-05, 7.99098905617353e-05, 7.191970858320813e-05, 6.472839145778087e-05], "accuracy_test": 0.8140027104591837, "start": "2016-02-03 21:32:52.729000", "learning_rate_per_epoch": [0.006212911102920771, 0.005848029628396034, 0.005504577420651913, 0.005181295797228813, 0.004877000581473112, 0.0045905765146017075, 0.004320973996073008, 0.0040672048926353455, 0.003828339744359255, 0.0036035028751939535, 0.0033918707631528378, 0.003192667616531253, 0.003005163511261344, 0.002828671596944332, 0.0026625448372215033, 0.002506174612790346, 0.0023589879274368286, 0.0022204455453902483, 0.002090039663016796, 0.0019672925118356943, 0.0018517542630434036, 0.0017430015141144395, 0.0016406357754021883, 0.0015442819567397237, 0.0014535869704559445, 0.001368218450807035, 0.001287863589823246, 0.0012122278567403555, 0.0011410341830924153, 0.0010740216821432114, 0.0010109448339790106, 0.0009515724377706647, 0.0008956869714893401, 0.0008430836605839431, 0.0007935697212815285, 0.0007469637203030288, 0.0007030948763713241, 0.0006618024199269712, 0.0006229350110515952, 0.0005863502738066018, 0.0005519141559489071, 0.0005195004632696509, 0.0004889903939329088, 0.0004602721892297268, 0.00043324060970917344, 0.00040779655682854354, 0.00038384684012271464, 0.0003613036824390292, 0.0003400844580028206, 0.0003201114304829389, 0.0003013114328496158, 0.00028361554723232985, 0.0002669589302968234, 0.00025128055131062865, 0.00023652294476050884, 0.00022263205028139055, 0.00020955696527380496, 0.00019724977028090507, 0.00018566536891739815, 0.00017476131324656308, 0.00016449765826109797, 0.00015483677270822227, 0.0001457432663301006, 0.00013718382979277521, 0.00012912707461509854, 0.00012154349678894505, 0.00011440529488027096, 0.00010768631909741089, 0.00010136194759979844, 9.540899918647483e-05, 8.980566781247035e-05, 8.453142072539777e-05, 7.95669257058762e-05, 7.48939928598702e-05, 7.049550185911357e-05, 6.635532918153331e-05, 6.245831173146144e-05, 5.8790159528143704e-05, 5.533743751584552e-05, 5.2087492804275826e-05, 4.9028414650820196e-05, 4.614899808075279e-05, 4.343868567957543e-05, 4.088754940312356e-05, 3.848623964586295e-05, 3.6225959775038064e-05, 3.409842247492634e-05, 3.2095835194922984e-05, 3.0210860131774098e-05], "accuracy_train_first": 0.35044949272102255, "accuracy_train_last": 0.9987215286429494, "batch_size_eval": 1024, "accuracy_train_std": [0.015738884915639323, 0.019090937619123175, 0.020106762433869788, 0.023278211276460008, 0.02407297433030437, 0.024246554280496872, 0.024532925509622154, 0.024788645587427237, 0.02427858577655374, 0.026062560938066644, 0.02618370159086951, 0.02695957727716294, 0.027975650059757724, 0.02862885932291121, 0.027922707824144938, 0.02756123358891475, 0.02630199165094004, 0.025374875064581658, 0.02317708069539593, 0.021639334704724667, 0.02142505877676832, 0.019805136582539837, 0.018285962932462454, 0.016317825040661288, 0.015415591444074407, 0.016662106440779666, 0.012112548879014279, 0.01201003447508649, 0.011017660192793625, 0.009868456643497343, 0.008625479351589785, 0.00816551080839052, 0.006729488408254434, 0.005283346904125961, 0.0043128128989054736, 0.003523000780503605, 0.0022071729471957397, 0.0016870463190168288, 0.0016082353378397006, 0.001490989384701942, 0.0014756816332149236, 0.0014037654997377568, 0.0011875727465174655, 0.001140882012095462, 0.0011265612881939478, 0.0010877330243213954, 0.00106841832988313, 0.00106841832988313, 0.0011101098382602869, 0.0010906957343988662, 0.0009818978945801585, 0.0009818978945801585, 0.0009818978945801585, 0.0010047569547243552, 0.0010047569547243552, 0.0010047569547243552, 0.0010039411731757142, 0.0010025856357092958, 0.0010006881488588294, 0.0010249834240692016, 0.0010249834240692016, 0.0010006881488588294, 0.0010006881488588294, 0.0010006881488588294, 0.0010006881488588294, 0.0010006881488588294, 0.0010006881488588294, 0.0010006881488588294, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009982456221817966, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.0009952540428184392, 0.000991708441978028, 0.0010103328448205836, 0.0010103328448205836], "accuracy_test_std": 0.00699552503802808, "error_valid": [0.649937641189759, 0.478503859186747, 0.38002841443900603, 0.32766025037650603, 0.2775378859186747, 0.2783011930534638, 0.26634859751506024, 0.25330619352409633, 0.24105798192771077, 0.22240034356174698, 0.21480109892695776, 0.20449571724397586, 0.2092873446912651, 0.20737540003765065, 0.20715184958584332, 0.2063885424510542, 0.21126105986445776, 0.21003006165286142, 0.19923639871987953, 0.20109833866716864, 0.2046486728162651, 0.1917401049510542, 0.19448595161897586, 0.20177046074924698, 0.19591108574924698, 0.19264460184487953, 0.1835099185805723, 0.1854836337537651, 0.1856057040662651, 0.18329666321536142, 0.18043757059487953, 0.18181122929216864, 0.17797557417168675, 0.18077436699924698, 0.17601362481174698, 0.17417227503765065, 0.17067194559487953, 0.1682511295180723, 0.16786432840737953, 0.16810846903237953, 0.16860704536897586, 0.1688614810805723, 0.1684952701430723, 0.1684952701430723, 0.1682511295180723, 0.1684952701430723, 0.1687394107680723, 0.1688614810805723, 0.1687394107680723, 0.1684952701430723, 0.1684952701430723, 0.1682511295180723, 0.1680069888930723, 0.1682511295180723, 0.1684952701430723, 0.1684952701430723, 0.1683731998305723, 0.1683731998305723, 0.1683731998305723, 0.1683731998305723, 0.16874970585466864, 0.16874970585466864, 0.16887177616716864, 0.16887177616716864, 0.16887177616716864, 0.16887177616716864, 0.16887177616716864, 0.16887177616716864, 0.16887177616716864, 0.16911591679216864, 0.16923798710466864, 0.16923798710466864, 0.16911591679216864, 0.16911591679216864, 0.16911591679216864, 0.16911591679216864, 0.16911591679216864, 0.16923798710466864, 0.16936005741716864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864, 0.16923798710466864], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.058729583608763174, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.00660055930259933, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.732768061686767e-07, "rotation_range": [0, 0], "momentum": 0.959193197763357}, "accuracy_valid_max": 0.8321356715926205, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8307620128953314, "accuracy_valid_std": [0.01663993320418446, 0.013617174020167306, 0.02195752948247626, 0.010609449825606859, 0.011052682163364882, 0.009712962002336768, 0.011975393043367656, 0.010437221424461981, 0.01174348260940244, 0.006816493597413073, 0.009050943018001642, 0.01073945833517962, 0.01030012071345267, 0.00482976154323254, 0.006447434180075332, 0.006124625510596598, 0.010833535078168139, 0.01107381729209876, 0.008003879858011511, 0.005480465894201201, 0.00948728455827036, 0.007648373528534714, 0.008507878499015612, 0.010207740545817629, 0.01066936025119756, 0.00783416484001883, 0.006184021896181519, 0.009523595385682959, 0.008140116910000699, 0.008786133848449463, 0.004003579461340899, 0.006691955621306393, 0.0028369215474192276, 0.013214893949526548, 0.013551966864703226, 0.013764805703033465, 0.006303837784665031, 0.009463165043287423, 0.007747809105261712, 0.00810814246859354, 0.008529796201795866, 0.009815520734439068, 0.00978730345924786, 0.009578005698404994, 0.009760816489153688, 0.009701668874461455, 0.00974668032136158, 0.00985188829745384, 0.009783303788808859, 0.00978730345924786, 0.00978730345924786, 0.010025903813381061, 0.010124444275478274, 0.010120577844569026, 0.010134369629994281, 0.010134369629994281, 0.010239416463613765, 0.010239416463613765, 0.010239416463613765, 0.010239416463613765, 0.011042723369880969, 0.011042723369880969, 0.011017193260690894, 0.011017193260690894, 0.011017193260690894, 0.011017193260690894, 0.011017193260690894, 0.011017193260690894, 0.011017193260690894, 0.011048534058799723, 0.011040577111690996, 0.011040577111690996, 0.011123804875228998, 0.011123804875228998, 0.011123804875228998, 0.011123804875228998, 0.011123804875228998, 0.011126620852352597, 0.010944470298499261, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998, 0.011040577111690998], "accuracy_valid": [0.35006235881024095, 0.521496140813253, 0.619971585560994, 0.672339749623494, 0.7224621140813253, 0.7216988069465362, 0.7336514024849398, 0.7466938064759037, 0.7589420180722892, 0.777599656438253, 0.7851989010730422, 0.7955042827560241, 0.7907126553087349, 0.7926245999623494, 0.7928481504141567, 0.7936114575489458, 0.7887389401355422, 0.7899699383471386, 0.8007636012801205, 0.7989016613328314, 0.7953513271837349, 0.8082598950489458, 0.8055140483810241, 0.798229539250753, 0.804088914250753, 0.8073553981551205, 0.8164900814194277, 0.8145163662462349, 0.8143942959337349, 0.8167033367846386, 0.8195624294051205, 0.8181887707078314, 0.8220244258283133, 0.819225633000753, 0.823986375188253, 0.8258277249623494, 0.8293280544051205, 0.8317488704819277, 0.8321356715926205, 0.8318915309676205, 0.8313929546310241, 0.8311385189194277, 0.8315047298569277, 0.8315047298569277, 0.8317488704819277, 0.8315047298569277, 0.8312605892319277, 0.8311385189194277, 0.8312605892319277, 0.8315047298569277, 0.8315047298569277, 0.8317488704819277, 0.8319930111069277, 0.8317488704819277, 0.8315047298569277, 0.8315047298569277, 0.8316268001694277, 0.8316268001694277, 0.8316268001694277, 0.8316268001694277, 0.8312502941453314, 0.8312502941453314, 0.8311282238328314, 0.8311282238328314, 0.8311282238328314, 0.8311282238328314, 0.8311282238328314, 0.8311282238328314, 0.8311282238328314, 0.8308840832078314, 0.8307620128953314, 0.8307620128953314, 0.8308840832078314, 0.8308840832078314, 0.8308840832078314, 0.8308840832078314, 0.8308840832078314, 0.8307620128953314, 0.8306399425828314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314, 0.8307620128953314], "seed": 301699994, "model": "residualv3", "loss_std": [0.28686779737472534, 0.15993572771549225, 0.1483444720506668, 0.14527671039104462, 0.1393604874610901, 0.13247773051261902, 0.12879514694213867, 0.12626659870147705, 0.12373921275138855, 0.12029764801263809, 0.11696551740169525, 0.11372273415327072, 0.10905815660953522, 0.10032759606838226, 0.09497782588005066, 0.09043728560209274, 0.08233467489480972, 0.07517678290605545, 0.06872302293777466, 0.06241222843527794, 0.05480329692363739, 0.05569847300648689, 0.04594998061656952, 0.04463217779994011, 0.04076961427927017, 0.03420419991016388, 0.032247304916381836, 0.027502024546265602, 0.027377916499972343, 0.02339772693812847, 0.018912222236394882, 0.0175491776317358, 0.015637632459402084, 0.011224557645618916, 0.006447216961532831, 0.00514904735609889, 0.002181399380788207, 0.0006874418468214571, 0.00033786697895266116, 0.0001929495920194313, 0.00015478924615308642, 0.0001333485561190173, 0.00011861085658892989, 0.00010781979653984308, 9.937081631505862e-05, 9.259676153305918e-05, 8.704434731043875e-05, 8.243285992648453e-05, 7.849931716918945e-05, 7.511116564273834e-05, 7.22210606909357e-05, 6.968768866499886e-05, 6.745509745087475e-05, 6.550024409079924e-05, 6.374438089551404e-05, 6.217788177309558e-05, 6.0769245465053245e-05, 5.950462946202606e-05, 5.835535193909891e-05, 5.7318109611514956e-05, 5.637292269966565e-05, 5.5509306548628956e-05, 5.4720137995900586e-05, 5.4001084208721295e-05, 5.333706576493569e-05, 5.273408169159666e-05, 5.217726720729843e-05, 5.166664777789265e-05, 5.119156412547454e-05, 5.0749906222335994e-05, 5.0346101488685235e-05, 4.996984716854058e-05, 4.962250022799708e-05, 4.929976421408355e-05, 4.8999809223460034e-05, 4.872167846770026e-05, 4.846194133278914e-05, 4.8221532779280096e-05, 4.79955633636564e-05, 4.778555012308061e-05, 4.758859358844347e-05, 4.740609438158572e-05, 4.723546953755431e-05, 4.7075522161321715e-05, 4.692651782534085e-05, 4.6787390601821244e-05, 4.665695450967178e-05, 4.653505311580375e-05, 4.642072963179089e-05]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:34 2016", "state": "available"}], "summary": "6f7318e8d1bafced082707ca0ebfc39e"}