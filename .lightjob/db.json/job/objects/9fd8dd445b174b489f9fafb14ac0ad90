{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 64, "f3": 32, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [2.069667339324951, 1.7450428009033203, 1.6273558139801025, 1.5505244731903076, 1.487690806388855, 1.4354945421218872, 1.392625093460083, 1.3562004566192627, 1.3237366676330566, 1.2937864065170288, 1.265487551689148, 1.2382889986038208, 1.2118808031082153, 1.1861963272094727, 1.1612787246704102, 1.1369584798812866, 1.1133638620376587, 1.090201497077942, 1.0676648616790771, 1.0457241535186768, 1.0245763063430786, 1.0041080713272095, 0.9844378232955933, 0.9652126431465149, 0.946564257144928, 0.9283956289291382, 0.9105545878410339, 0.8928935527801514, 0.8756001591682434, 0.8586159348487854, 0.8417785167694092, 0.8250017762184143, 0.8082717061042786, 0.7915130853652954, 0.7747311592102051, 0.757781982421875, 0.7407965064048767, 0.7236850261688232, 0.7063553333282471, 0.688819169998169, 0.6709147095680237, 0.6529017686843872, 0.6346490979194641, 0.615946888923645, 0.5971090793609619, 0.577920138835907, 0.5585767030715942, 0.5389876365661621, 0.5193012356758118, 0.49945083260536194, 0.4795096516609192, 0.4595065414905548, 0.4396006464958191, 0.4196414649486542, 0.3998529314994812, 0.38014423847198486, 0.3608604669570923, 0.3419182300567627, 0.32338523864746094, 0.3052772879600525, 0.2877127528190613, 0.2709193527698517, 0.25484541058540344, 0.23934903740882874, 0.22443825006484985, 0.21037596464157104, 0.1970754861831665, 0.18452881276607513, 0.17275923490524292, 0.16153670847415924, 0.1509924829006195, 0.14110851287841797, 0.13193143904209137, 0.12338874489068985, 0.1155068650841713, 0.10838207602500916, 0.10192835330963135, 0.09618779271841049, 0.09107887744903564, 0.0865134745836258, 0.08247914165258408, 0.07893132418394089, 0.07581833004951477, 0.07306361943483353, 0.07061321288347244, 0.06844578683376312, 0.06648866087198257, 0.0647137388586998, 0.06312534958124161, 0.06169362738728523, 0.06039505451917648, 0.05922425538301468, 0.05816754326224327, 0.05721278861165047], "moving_avg_accuracy_train": [0.036523058987403094, 0.07438979984253874, 0.11190778838334023, 0.1484194380818279, 0.18369059744248045, 0.2172272585015731, 0.24887960330710052, 0.27871254220696445, 0.30668247635720747, 0.33285036448998984, 0.3573036215475892, 0.380076238467212, 0.40158528647818736, 0.42191498140225864, 0.4410975164327138, 0.4592430654077517, 0.47645729159353617, 0.49282871302019216, 0.5082906196862885, 0.5229641539535862, 0.5369212857619928, 0.550194055729998, 0.5627299923035468, 0.5747142057208481, 0.5861229213844591, 0.5971184649614525, 0.6075932720390429, 0.6175529853886177, 0.6271211218984363, 0.6362717350858075, 0.6449605828258425, 0.6532872119394376, 0.6612625560428822, 0.6689772948668886, 0.6764181056049137, 0.6836820634322038, 0.6907380615636511, 0.6975510563485928, 0.7040639679133459, 0.7103719447954149, 0.716579149771392, 0.7226887206342769, 0.7284917847096458, 0.7342816984429078, 0.7399947808480632, 0.7456664726483622, 0.7512243271888508, 0.756712208181206, 0.7620490096672106, 0.7672705856926914, 0.7724232639382063, 0.7774141330270361, 0.7823799571735758, 0.7872932662792618, 0.7920174417219797, 0.7966295255882646, 0.8010989104060069, 0.8055095844955281, 0.8099744839213444, 0.8142484434807142, 0.8185530253508045, 0.8227804995552959, 0.8267991400298143, 0.8306693216283002, 0.8342524304169283, 0.8376213515040652, 0.8408114545527173, 0.8438406574155519, 0.8468296818075792, 0.84978254557588, 0.8526400497161509, 0.8554233919840615, 0.8583585525549429, 0.861599977315137, 0.8650774762671319, 0.8685141449667846, 0.8720975729511877, 0.8755133203395316, 0.8786410074604787, 0.8817651706609978, 0.8847281243117215, 0.8874994503426203, 0.8900913000204291, 0.8925565342614187, 0.8948822019235474, 0.8971938668075585, 0.899351059065064, 0.9014529673646761, 0.9034980725581181, 0.9055269682369685, 0.9075599486408004, 0.9095663062649539, 0.9115138261552543, 0.9134572562589056], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.036207525414156616, 0.07395713714231926, 0.11072631541792166, 0.14618482798381022, 0.18059904826336592, 0.21283225925969498, 0.2430221131530026, 0.271222490316618, 0.29760895386967, 0.3221359620500976, 0.34472296472498243, 0.36598311954201734, 0.38581614818457766, 0.40446139001145126, 0.42213630946286634, 0.4386327629951189, 0.45422728860637507, 0.4689347778839153, 0.4830524835010207, 0.4962365517924849, 0.5084725422269412, 0.5198165824790212, 0.5304656718308931, 0.5404537137874875, 0.5500410960796724, 0.5590471286027293, 0.5676195135869595, 0.5756143922828569, 0.5829440604529146, 0.5897269558006955, 0.5958406801189693, 0.6014651023179158, 0.6066888622291966, 0.6114034826892588, 0.6156445820859956, 0.6193242056733297, 0.6225117375721112, 0.6254934680882435, 0.628310273387853, 0.6308331911262514, 0.6330438114432196, 0.6351086709333104, 0.637101321818142, 0.6389313287082405, 0.6404928856905792, 0.6418372518184339, 0.6430461518248436, 0.6439998844868623, 0.6447738241725887, 0.6453249150234021, 0.6455258690218149, 0.645597893847796, 0.645577266972429, 0.6454345734547795, 0.6451729014538046, 0.6448265038630175, 0.6441973632188092, 0.6434327356130427, 0.6427333932452626, 0.6420408909406911, 0.6415427977050557, 0.6408869942617339, 0.6400760150915846, 0.6392139155120196, 0.6382437428990706, 0.6371599794901877, 0.6362243020419219, 0.6351471702187538, 0.6339814095692429, 0.6329088404308426, 0.6317227721351228, 0.6306319261151346, 0.6295525084471452, 0.6287163393983644, 0.6277887707823231, 0.6270017576442264, 0.6264053681185086, 0.6257231626790221, 0.6252455141445536, 0.6247657728298723, 0.6241753142404093, 0.6236327239873021, 0.6230955646345055, 0.6227728716405581, 0.6224458268522552, 0.6222257582389424, 0.621853709523482, 0.6215788713271578, 0.6213925521067162, 0.621199421237159, 0.6210988456420576, 0.620984943052626, 0.6210167080658875, 0.6210086754840729], "moving_var_accuracy_train": [0.012005404540175936, 0.02370987465306834, 0.034007282365090916, 0.0426044592019275, 0.04954050542553569, 0.054708823597914284, 0.05825477962331485, 0.06043933985161052, 0.06143626081376984, 0.06145546005636118, 0.06069157007725037, 0.05928974180183634, 0.0575245199386987, 0.05549173640618111, 0.053254289617314765, 0.050892209184032804, 0.048469954514207644, 0.04603517001854942, 0.04358328803645414, 0.04116277270385076, 0.038799709188320805, 0.03650523607310096, 0.03426905981777519, 0.03213474617708049, 0.03009270069721055, 0.028171548434471536, 0.02634188784083903, 0.024600462066806425, 0.02296435898656049, 0.02142152658324847, 0.019958838600369223, 0.018586949511890636, 0.017300709582816706, 0.016106293380638712, 0.014993955022526822, 0.013969445270123981, 0.013020584729790485, 0.012136278338268214, 0.011304412657894048, 0.010532086543207083, 0.009825642431410535, 0.00917901989342698, 0.008564197878049816, 0.008009485999592387, 0.007502291194746025, 0.0070415748661696205, 0.0066154251033917295, 0.00622493413312884, 0.0058587737707251385, 0.0055182800993615125, 0.005205402927341586, 0.0049090416029639585, 0.00464007212775677, 0.004393330372293244, 0.0041548578375861355, 0.003930813912134327, 0.003717511126762489, 0.0035208464274019977, 0.0033481797266056938, 0.003177762326781282, 0.0030267509197899416, 0.002884919671157705, 0.0027417729454128716, 0.0026024004013189142, 0.0024577083785073165, 0.0023140842042787915, 0.002174266601000091, 0.002039424570757929, 0.0019158905150273439, 0.0018027761034318998, 0.001695986462293702, 0.0015961107636873694, 0.001514036195510344, 0.0014571940862433078, 0.0014203116682691126, 0.0013845767272027498, 0.0013616876595571054, 0.0013305248655901896, 0.0012855142195700201, 0.0012448063589443191, 0.0011993375720769236, 0.0011485260465950629, 0.001094132604706777, 0.0010394157630026267, 0.0009841527573744052, 0.0009338316324606942, 0.0008823297751372, 0.0008338589641232841, 0.0007881151649811448, 0.0007463514075639517, 0.0007089133507088317, 0.0006742512538819433, 0.0006409616320017926, 0.0006108577539116192], "duration": 28823.31794, "accuracy_train": [0.365230589874031, 0.4151904675387597, 0.4495696852505537, 0.47702428536821706, 0.5011310316883536, 0.5190572080334072, 0.5337507065568475, 0.5472089923057402, 0.5584118837093947, 0.5683613576850314, 0.5773829350659837, 0.5850297907438169, 0.5951667185769657, 0.6048822357189, 0.6137403317068106, 0.6225530061830934, 0.6313853272655962, 0.640171505860096, 0.6474477796811554, 0.6550259623592654, 0.6625354720376523, 0.6696489854420451, 0.6755534214654854, 0.6825721264765596, 0.6888013623569582, 0.6960783571543927, 0.7018665357373569, 0.7071904055347914, 0.7132343504868033, 0.7186272537721484, 0.7231602124861573, 0.728226873961794, 0.7330406529738833, 0.7384099442829457, 0.7433854022471392, 0.7490576838778147, 0.7542420447466777, 0.7588680094130675, 0.7626801719961241, 0.7671437367340348, 0.7724439945551864, 0.77767485840024, 0.7807193613879659, 0.7863909220422666, 0.7914125224944629, 0.7967116988510521, 0.8012450180532484, 0.806103137112403, 0.8100802230412514, 0.8142647699220191, 0.8187973681478405, 0.8223319548265043, 0.8270723744924326, 0.8315130482304356, 0.8345350207064415, 0.8381382803848283, 0.8413233737656883, 0.8452056513012183, 0.8501585787536915, 0.8527140795150425, 0.8572942621816169, 0.860827767395718, 0.8629669043004798, 0.8655009560146733, 0.866500409514581, 0.8679416412882982, 0.8695223819905868, 0.8711034831810631, 0.873730901335825, 0.8763583194905868, 0.8783575869785898, 0.8804734723952565, 0.8847749976928755, 0.8907728001568845, 0.8963749668350868, 0.8994441632636582, 0.9043484248108158, 0.9062550468346253, 0.9067901915490033, 0.9098826394656699, 0.9113947071682356, 0.9124413846207088, 0.9134179471207088, 0.9147436424303249, 0.9158132108827058, 0.9179988507636582, 0.9187657893826136, 0.920370142061185, 0.9219040192990956, 0.9237870293466224, 0.9258567722752861, 0.9276235248823367, 0.9290415051679586, 0.9309481271917681], "end": "2016-02-01 01:37:38.240000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0], "moving_var_accuracy_valid": [0.01179886406955118, 0.023444276333239377, 0.03326760093948273, 0.041256595866001944, 0.0477899832964498, 0.05236180398700965, 0.05532846909120204, 0.056952973631613286, 0.05752388539798086, 0.057185664030727626, 0.056058651836172146, 0.05452073429815356, 0.052608802094567766, 0.05047672727015435, 0.04824067954166502, 0.045865808399774416, 0.0434679306211581, 0.04106792972668293, 0.0387549232610359, 0.036443807845358236, 0.03414690221803138, 0.03189039723939554, 0.029721985451673365, 0.027647635745646243, 0.025710133264030138, 0.023869097533884345, 0.02214355983935659, 0.02050446662367996, 0.018937536280660375, 0.017457851676284858, 0.01604846513401505, 0.014728325746261558, 0.013501082180131732, 0.0123510227768605, 0.011277802816011458, 0.010271879202110507, 0.009336134518351202, 0.008482537518353591, 0.0077056932953813995, 0.006992409991075789, 0.006337150571640344, 0.005741808316900668, 0.005203363403149984, 0.004713167389795256, 0.004263796792697544, 0.003853682995999298, 0.003481467649428843, 0.0031415073384013694, 0.0028327474482955136, 0.0025522060135986144, 0.002297348854824056, 0.0020676606575216693, 0.001860898420981389, 0.001674991831843063, 0.0015081088987836048, 0.0013583779305233724, 0.0012261024990227896, 0.001108754147500012, 0.0010022804504763623, 0.0009063684404052568, 0.0008179644682072026, 0.0007400387247929375, 0.0006719540372433881, 0.000611447574684826, 0.000558773931306589, 0.0005134674263138327, 0.0004700001142671874, 0.00043344201952080145, 0.00040232879859625437, 0.0003724495597464656, 0.00034786542579082414, 0.00032378838856565837, 0.0003018958322268009, 0.0002779988571073715, 0.00025794242323381653, 0.00023772268802626728, 0.00021715154342111392, 0.00019962502743398587, 0.00018171585779290628, 0.00016561563757472466, 0.00015219184593008944, 0.00013962229898198292, 0.0001282569306164552, 0.00011636841446989511, 0.00010569419766490973, 9.556064964950783e-05, 8.725036690463944e-05, 7.920515452160365e-05, 7.159707273659729e-05, 6.477306125792069e-05, 5.8386794185098707e-05, 5.266487896550199e-05, 4.740747221355931e-05, 4.2667305693538865e-05], "accuracy_test": 0.368668287627551, "start": "2016-01-31 17:37:14.922000", "learning_rate_per_epoch": [0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409, 0.000353834853740409], "accuracy_train_first": 0.365230589874031, "accuracy_train_last": 0.9309481271917681, "batch_size_eval": 1024, "accuracy_train_std": [0.016530241176721604, 0.014698529015229951, 0.016399983855786584, 0.014774159118485293, 0.013721595341997786, 0.012581223394602001, 0.012368643265073486, 0.0139426205179339, 0.015239964508683479, 0.016198678631655722, 0.01645322974208536, 0.017414099934474594, 0.016637693772419932, 0.015941409637150145, 0.01521546431155073, 0.014682852367238965, 0.015523157159365612, 0.016373510846372674, 0.01583124801551768, 0.0164840700650253, 0.01588683118360352, 0.016324397227589608, 0.015894364338774, 0.017261034268426033, 0.01717645192956759, 0.017015766490910713, 0.017850124322338616, 0.017947598610084502, 0.01783281659051455, 0.018308584873803577, 0.018260698739506066, 0.01874878614623106, 0.017245303413111097, 0.017339148177712413, 0.017316371646002002, 0.01789528308745435, 0.017994585220679767, 0.01832233887224525, 0.017523754373267336, 0.0179858843677146, 0.017988657831275894, 0.017673707950751016, 0.017772531739948715, 0.018339153066697318, 0.018568640187645185, 0.019307901270962012, 0.019059072832664933, 0.019148810600260798, 0.01791460199422395, 0.0178201674112291, 0.01803014592117678, 0.017089062519471947, 0.01800139716185162, 0.018620525925001668, 0.018211296530745907, 0.01784892984133704, 0.017233225798913007, 0.0169669734796604, 0.01686608398581635, 0.017878749060919324, 0.017071834308784097, 0.017881715391471386, 0.01728691380683259, 0.016692027418012793, 0.016561542634173743, 0.017001992306954688, 0.01729471274618103, 0.017175310697906985, 0.01680425240324601, 0.01723957391275419, 0.016932639214602148, 0.01680752276495671, 0.016126569931126225, 0.015749650201835653, 0.015391187408390393, 0.014643275879729932, 0.0157309564851249, 0.01569573178119227, 0.015460575562515722, 0.014743918053871315, 0.014127723622497628, 0.01344187892004568, 0.01268350661911857, 0.012614670140522269, 0.012365105100841945, 0.012094578431634117, 0.012528678227480298, 0.012583844427244658, 0.012294458499696516, 0.01244632029305442, 0.011750329284411125, 0.0115459753588621, 0.011579155143591672, 0.011053844555260648], "accuracy_test_std": 0.012829943414289034, "error_valid": [0.6379247458584337, 0.5862963573042168, 0.5583510801016567, 0.5346885589231928, 0.5096729692206325, 0.4970688417733433, 0.4852692018072289, 0.4749741152108433, 0.4649128741528614, 0.4571209643260542, 0.4519940112010542, 0.44267548710466864, 0.4356865940323795, 0.42773143354668675, 0.41878941547439763, 0.4128991552146084, 0.4054219808923193, 0.39869781861822284, 0.3898881659450302, 0.3851068335843373, 0.38140354386295183, 0.37808705525225905, 0.37369252400225905, 0.3696539086031627, 0.3636724632906627, 0.35989857868975905, 0.3552290215549698, 0.35243169945406627, 0.35108892601656627, 0.34922698606927716, 0.34913580101656627, 0.34791509789156627, 0.34629729856927716, 0.3461649331701807, 0.3461855233433735, 0.3475591820406627, 0.3488004753388554, 0.34767095726656627, 0.3463384789156627, 0.3464605492281627, 0.34706060570406627, 0.3463075936558735, 0.3449648202183735, 0.3445986092808735, 0.3454531014683735, 0.3460634530308735, 0.3460737481174698, 0.3474165215549698, 0.3482607186558735, 0.34971526731927716, 0.3526655449924698, 0.3537538827183735, 0.3546083749058735, 0.35584966820406627, 0.3571821465549698, 0.35829107445406627, 0.36146490257906627, 0.3634489128388554, 0.36356068806475905, 0.36419162980045183, 0.3629400414156627, 0.3650152367281627, 0.36722279743975905, 0.36854498070406627, 0.3704878106174698, 0.37259389118975905, 0.3721967949924698, 0.37454701618975905, 0.3765104362763554, 0.37674428181475905, 0.3789518425263554, 0.37918568806475905, 0.38016225056475905, 0.3788091820406627, 0.38055934676204817, 0.3800813605986446, 0.37896213761295183, 0.3804166862763554, 0.3790533226656627, 0.37955189900225905, 0.38113881306475905, 0.3812505882906627, 0.3817388695406627, 0.3801313653049698, 0.3804975762424698, 0.3797548592808735, 0.3814947289156627, 0.38089467243975905, 0.38028432087725905, 0.3805387565888554, 0.3798063347138554, 0.38004018025225905, 0.37869740681475905, 0.37906361775225905], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.01664450292293499, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.00035383485270617555, "optimization": "nesterov_momentum", "nb_data_augmentation": 0, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.1352417743159938e-05, "rotation_range": [0, 0], "momentum": 0.6747168349608005}, "accuracy_valid_max": 0.6554013907191265, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.620936382247741, "accuracy_valid_std": [0.0065083694358589175, 0.007842741980095123, 0.01159064879284099, 0.014286182710002157, 0.019914072920702543, 0.019490984508025472, 0.01491674402695713, 0.015153048554342392, 0.014878673877360492, 0.012761167557376633, 0.0120065561917221, 0.01000344886406174, 0.010508141677387249, 0.008583204617589863, 0.008349987094407383, 0.008556556616129933, 0.007585612744812249, 0.006051379311805819, 0.0058936036074816655, 0.006456175768563561, 0.0088188532917319, 0.010932018678587795, 0.00981504119969044, 0.008198064024132375, 0.009239796882586176, 0.008558238155775501, 0.008327565379321009, 0.008060978476715535, 0.008319020215825246, 0.008235871777160819, 0.008659422238796947, 0.009074848275847895, 0.009469387534478539, 0.010611122719281302, 0.010387237510478611, 0.011377722023112798, 0.012512474615931924, 0.009943366588582851, 0.010683426462724924, 0.01048959854169908, 0.010727816858005912, 0.01102139270705793, 0.010822155999350283, 0.01180896237331414, 0.010140004475057298, 0.009180137599750058, 0.00963529235729565, 0.00992493587431606, 0.008507634807176296, 0.007721395066458971, 0.007383394102747353, 0.007543379244716661, 0.009243827557421475, 0.00879748892865801, 0.008123622957857943, 0.0076087373741017175, 0.00929568487243947, 0.009680615117882152, 0.010629187683221545, 0.01094781568994836, 0.011515960647480703, 0.010837366199182116, 0.011840559356571528, 0.012937659225655667, 0.01288628506198545, 0.013367195014433158, 0.015555628545621052, 0.013818168765907775, 0.013342085861159042, 0.01354016586841237, 0.013126500220912243, 0.014420793084661064, 0.013344961989113483, 0.01429763180579784, 0.01271931485916702, 0.011999251220703071, 0.011923911266632569, 0.013453361052978919, 0.01356998481392938, 0.012717111295867303, 0.012850854715051832, 0.015194863112954793, 0.016448590884368605, 0.016001523799872845, 0.01653767795365378, 0.016265243652544607, 0.014610513357400039, 0.013273603929183081, 0.012891980743096982, 0.013715664360350297, 0.014200594511931536, 0.012823114411683654, 0.013232232594335976, 0.012448472209998137], "accuracy_valid": [0.36207525414156627, 0.41370364269578314, 0.4416489198983434, 0.4653114410768072, 0.49032703077936746, 0.5029311582266567, 0.5147307981927711, 0.5250258847891567, 0.5350871258471386, 0.5428790356739458, 0.5480059887989458, 0.5573245128953314, 0.5643134059676205, 0.5722685664533133, 0.5812105845256024, 0.5871008447853916, 0.5945780191076807, 0.6013021813817772, 0.6101118340549698, 0.6148931664156627, 0.6185964561370482, 0.621912944747741, 0.626307475997741, 0.6303460913968373, 0.6363275367093373, 0.640101421310241, 0.6447709784450302, 0.6475683005459337, 0.6489110739834337, 0.6507730139307228, 0.6508641989834337, 0.6520849021084337, 0.6537027014307228, 0.6538350668298193, 0.6538144766566265, 0.6524408179593373, 0.6511995246611446, 0.6523290427334337, 0.6536615210843373, 0.6535394507718373, 0.6529393942959337, 0.6536924063441265, 0.6550351797816265, 0.6554013907191265, 0.6545468985316265, 0.6539365469691265, 0.6539262518825302, 0.6525834784450302, 0.6517392813441265, 0.6502847326807228, 0.6473344550075302, 0.6462461172816265, 0.6453916250941265, 0.6441503317959337, 0.6428178534450302, 0.6417089255459337, 0.6385350974209337, 0.6365510871611446, 0.636439311935241, 0.6358083701995482, 0.6370599585843373, 0.6349847632718373, 0.632777202560241, 0.6314550192959337, 0.6295121893825302, 0.627406108810241, 0.6278032050075302, 0.625452983810241, 0.6234895637236446, 0.623255718185241, 0.6210481574736446, 0.620814311935241, 0.619837749435241, 0.6211908179593373, 0.6194406532379518, 0.6199186394013554, 0.6210378623870482, 0.6195833137236446, 0.6209466773343373, 0.620448100997741, 0.618861186935241, 0.6187494117093373, 0.6182611304593373, 0.6198686346950302, 0.6195024237575302, 0.6202451407191265, 0.6185052710843373, 0.619105327560241, 0.619715679122741, 0.6194612434111446, 0.6201936652861446, 0.619959819747741, 0.621302593185241, 0.620936382247741], "seed": 297034954, "model": "residualv3", "loss_std": [0.3828901946544647, 0.14834357798099518, 0.15581367909908295, 0.16301186382770538, 0.1689024418592453, 0.17341004312038422, 0.17661333084106445, 0.17845647037029266, 0.1793866753578186, 0.1800483763217926, 0.18047556281089783, 0.18069157004356384, 0.18079112470149994, 0.18089547753334045, 0.1807805746793747, 0.18069443106651306, 0.18046416342258453, 0.1801106482744217, 0.17979450523853302, 0.1794213503599167, 0.17914579808712006, 0.17874571681022644, 0.17838124930858612, 0.1778857260942459, 0.1773400753736496, 0.17669808864593506, 0.17606058716773987, 0.17534714937210083, 0.1745547503232956, 0.1736074835062027, 0.17255432903766632, 0.17145660519599915, 0.17007796466350555, 0.16864389181137085, 0.16708622872829437, 0.16550730168819427, 0.16381490230560303, 0.16203606128692627, 0.1601095348596573, 0.15801621973514557, 0.15576539933681488, 0.1533188819885254, 0.150676891207695, 0.14810585975646973, 0.14527550339698792, 0.14232607185840607, 0.13934268057346344, 0.13611151278018951, 0.13278622925281525, 0.12933357059955597, 0.12583550810813904, 0.12236189097166061, 0.11881518363952637, 0.1151733323931694, 0.11141268908977509, 0.10773094743490219, 0.10394267737865448, 0.10008832812309265, 0.0961068868637085, 0.09216833114624023, 0.08807209879159927, 0.0841088816523552, 0.08016028255224228, 0.07629937678575516, 0.07230314612388611, 0.06833048909902573, 0.06431606411933899, 0.060378484427928925, 0.05641636997461319, 0.052578262984752655, 0.04877171665430069, 0.04483022540807724, 0.04100040718913078, 0.03729987516999245, 0.033767469227313995, 0.030524255707859993, 0.027571531012654305, 0.02483373135328293, 0.022337177768349648, 0.02011951431632042, 0.018165510147809982, 0.016518613323569298, 0.015014730393886566, 0.01363656111061573, 0.012412108480930328, 0.011308325454592705, 0.010246914811432362, 0.009236276149749756, 0.008287177421152592, 0.0074668163433671, 0.006701820529997349, 0.006073744036257267, 0.005537287797778845, 0.005092971958220005]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:27 2016", "state": "available"}], "summary": "57f2a2de40a5a97d5ae6cb706ccded16"}