{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 32, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.387164831161499, 1.0048182010650635, 0.7741042375564575, 0.654379665851593, 0.5722940564155579, 0.5094078183174133, 0.4577333629131317, 0.41337814927101135, 0.3748684525489807, 0.34096047282218933, 0.31049877405166626, 0.2830178737640381, 0.2580167055130005, 0.2352607101202011, 0.2144182324409485, 0.19510768353939056, 0.17735031247138977, 0.16104935109615326, 0.1458929032087326, 0.13194367289543152, 0.119075246155262, 0.10722202062606812, 0.09634736180305481, 0.08638453483581543, 0.07736065983772278, 0.06913735717535019, 0.06173357367515564, 0.05507630482316017, 0.04909886047244072, 0.04375697672367096, 0.03901088237762451, 0.034791845828294754, 0.031048428267240524, 0.027737928554415703, 0.024841170758008957, 0.022292427718639374, 0.020061086863279343, 0.018104929476976395, 0.016387630254030228, 0.014882801100611687, 0.013562812469899654, 0.012410611845552921, 0.0114002525806427, 0.010515959933400154, 0.0097401337698102, 0.009060678072273731, 0.008466961793601513, 0.007947194389998913, 0.007492766249924898, 0.007094630040228367, 0.006745956838130951, 0.006440851371735334, 0.0061736274510622025, 0.005939544644206762, 0.005734619218856096, 0.005555029027163982, 0.005397914443165064, 0.005260396283119917, 0.005139495711773634, 0.005033419001847506, 0.00494018942117691, 0.004858258180320263], "moving_avg_accuracy_train": [0.06422580114894794, 0.13001614266103725, 0.19526975475267622, 0.2567456826492709, 0.3141431118061323, 0.36724686036273757, 0.41643521520294036, 0.4618532859733901, 0.5036617901441389, 0.5420682966513659, 0.577503613967357, 0.6101510368660256, 0.6401847951903126, 0.6677476728083707, 0.6930122809312803, 0.7162340231454613, 0.7374940252525191, 0.7569697879750523, 0.7748373740538852, 0.7912089172236628, 0.8061897358014535, 0.8198747604678935, 0.8324005821093655, 0.8438482437962234, 0.8543116106310713, 0.8638983405967109, 0.872696097380063, 0.8807791640505562, 0.8882259490170861, 0.8950908159036295, 0.9013969350907675, 0.9071933140484681, 0.9125146868068273, 0.9173945670441033, 0.9218864406564611, 0.9260151574135356, 0.9298890765651314, 0.9334825606468058, 0.9368120274215032, 0.9399062037687308, 0.9427606087990651, 0.9453993277906517, 0.9478299784545083, 0.9500780179210269, 0.9521872839468459, 0.9541600281319879, 0.955993590570035, 0.9576996003357059, 0.9592908126962384, 0.9607530947064226, 0.9621249520870169, 0.9633968261105041, 0.9645973163030713, 0.9657103095597152, 0.9667538561692659, 0.9677511768380997, 0.9686906181186217, 0.9695593667591866, 0.9703784429166474, 0.971141188095267, 0.9718578856905483, 0.9725470553048637], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.06091661568147589, 0.12334169686558731, 0.18405734363234183, 0.23988756677099016, 0.2911795718126411, 0.3376750547198559, 0.3795077527964396, 0.41733116802884385, 0.4514556319394384, 0.4821076438113831, 0.5097321050985429, 0.5346307413507368, 0.5570018633753018, 0.5770371874387505, 0.5948360159934447, 0.6107461279200792, 0.6249553653728003, 0.6377691226514088, 0.649153990318497, 0.6593525726025358, 0.6684102558543304, 0.6765377567184456, 0.6838789805759686, 0.69039857381167, 0.6961807585050512, 0.7012005897516848, 0.7056828462885645, 0.709641575966937, 0.7131444270298818, 0.7162349283216225, 0.7188078304442795, 0.7211356493859209, 0.7231584737545577, 0.7249169510214212, 0.726549438195258, 0.7278955768305515, 0.7290704805085656, 0.730128923327438, 0.7310072501682634, 0.7317478866913467, 0.7324521101645314, 0.7330492901966476, 0.733598959256802, 0.7340814543796911, 0.734440398785472, 0.7348234543982651, 0.7352048255435291, 0.7355846806680166, 0.7358533080925553, 0.7360096235558902, 0.7362235496603915, 0.7363794620606927, 0.7365075761897139, 0.7366350859370829, 0.736798672834715, 0.7369459010425838, 0.7370539923671658, 0.7371268604967895, 0.7370937560547913, 0.7370761690882429, 0.7370603408183493, 0.7369718236792854], "moving_var_accuracy_train": [0.03712458179901783, 0.07236744494561215, 0.10345300547010577, 0.12712131231982096, 0.14405936495219118, 0.15503350145384048, 0.16130559957542775, 0.16374024999047124, 0.16309778418038381, 0.16006354344115242, 0.15535814451660201, 0.14941501806226237, 0.1425917560077713, 0.13516999041028657, 0.12739769518169566, 0.11951116946668296, 0.11162794172634358, 0.10387889555632897, 0.0963642616912566, 0.08914008235396996, 0.08224589844591905, 0.07570682770241681, 0.06954821080232083, 0.06377283034495952, 0.058380885720148934, 0.05336994567104088, 0.048729555823707964, 0.0444446239425339, 0.040499253005320125, 0.03687346528111777, 0.0335440230058275, 0.030492002786436222, 0.027697655580093267, 0.025142209102255345, 0.02280958054897438, 0.02068203921261827, 0.018748900537694357, 0.016990228634532145, 0.015390973912113257, 0.013938041866311621, 0.012617566332375244, 0.011418475240386762, 0.010329800280195443, 0.009342303385163123, 0.008448114075155883, 0.007638328144220396, 0.0069047528907263105, 0.006240471825538761, 0.005639212253971685, 0.005094535446670293, 0.004602019836057484, 0.004156376824236333, 0.0037537097321347487, 0.0033894875448252843, 0.0030603396960795014, 0.0027632575631199, 0.0024948747560838472, 0.0022521797982798133, 0.0020329997902173193, 0.001834935833063153, 0.0016560651487445765, 0.00149473322668578], "duration": 29024.033725, "accuracy_train": [0.6422580114894795, 0.7221292162698413, 0.7825522635774271, 0.8100290337186231, 0.8307199742178849, 0.8451805973721853, 0.8591304087647655, 0.8706159229074382, 0.8799383276808784, 0.8877268552164084, 0.8964214698112772, 0.9039778429540422, 0.9104886201088963, 0.9158135713708934, 0.9203937540374677, 0.9252297030730897, 0.9288340442160392, 0.9322516524778516, 0.9356456487633813, 0.9385528057516611, 0.9410171030015688, 0.9430399824658545, 0.9451329768826136, 0.9468771989779439, 0.9484819121447029, 0.9501789102874677, 0.9518759084302326, 0.9535267640849945, 0.9552470137158545, 0.9568746178825213, 0.9581520077750092, 0.959360724667774, 0.9604070416320598, 0.9613134891795865, 0.9623133031676817, 0.9631736082272055, 0.9647543489294942, 0.9658239173818751, 0.9667772283937799, 0.9677537908937799, 0.9684502540720746, 0.9691477987149317, 0.9697058344292175, 0.9703103731196937, 0.9711706781792175, 0.9719147257982651, 0.9724956525124585, 0.9730536882267442, 0.97361172394103, 0.9739136327980805, 0.9744716685123662, 0.97484369232189, 0.9754017280361758, 0.9757272488695091, 0.9761457756552234, 0.9767270628576044, 0.9771455896433187, 0.977378104524271, 0.9777501283337948, 0.9780058947028424, 0.9783081640480805, 0.9787495818337025], "end": "2016-01-31 23:48:59.513000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0], "moving_var_accuracy_valid": [0.03339750659476172, 0.06512977278287169, 0.09179430336533229, 0.11066799737020044, 0.12327902566391515, 0.13040759247449957, 0.13311660488234908, 0.1326804410527, 0.12989270828209923, 0.12535934994006986, 0.11969141269871503, 0.1133017502138151, 0.10647577909817534, 0.09944092908130447, 0.09234802085444861, 0.08539140372266607, 0.07866938521128974, 0.0722801780705166, 0.06621869716963891, 0.06053292717811382, 0.055218009093311, 0.05029071461664564, 0.045746685264517445, 0.04155456260169672, 0.0377000092799824, 0.03415679670368626, 0.03092193264627924, 0.02797078324764916, 0.025284134613006812, 0.02284168193581439, 0.020617092170227908, 0.018604151622430697, 0.016780562826024786, 0.015130336724104989, 0.013641288181049165, 0.012293468165973117, 0.011076544937249307, 0.009978973154331779, 0.008988018961252432, 0.008094153947261113, 0.00728920192883666, 0.006563491351869818, 0.005909861441364057, 0.005320970511120157, 0.0047900330297861145, 0.004312350311229935, 0.0038824242756609, 0.003495480457335205, 0.003146581857840613, 0.0028321435827732503, 0.0025493411038996095, 0.002294625771598758, 0.002065310913509376, 0.0018589261507795055, 0.0016732743817592468, 0.0015061420288900527, 0.0013556329796110965, 0.0012201174695288207, 0.0010981155857126587, 0.0009883068108539241, 0.0008894783845756823, 0.0008006010636732865], "accuracy_test": 0.563932955994898, "start": "2016-01-31 15:45:15.479000", "learning_rate_per_epoch": [0.00028145217220298946, 0.00014072608610149473, 9.381739073432982e-05, 7.036304305074736e-05, 5.629043516819365e-05, 4.690869536716491e-05, 4.020745473098941e-05, 3.518152152537368e-05, 3.1272466003429145e-05, 2.8145217584096827e-05, 2.5586561605450697e-05, 2.3454347683582455e-05, 2.1650166672770865e-05, 2.0103727365494706e-05, 1.8763477783068083e-05, 1.759076076268684e-05, 1.6556010450585745e-05, 1.5636233001714572e-05, 1.481327217334183e-05, 1.4072608792048413e-05, 1.3402484910329804e-05, 1.2793280802725349e-05, 1.223705112352036e-05, 1.1727173841791227e-05, 1.1258087397436611e-05, 1.0825083336385433e-05, 1.042415442498168e-05, 1.0051863682747353e-05, 9.705247975944076e-06, 9.381738891534042e-06, 9.079102710529696e-06, 8.79538038134342e-06, 8.528853868483566e-06, 8.278005225292873e-06, 8.041491128096823e-06, 7.818116500857286e-06, 7.606815415783785e-06, 7.406636086670915e-06, 7.216722679004306e-06, 7.036304396024207e-06, 6.864687293273164e-06, 6.701242455164902e-06, 6.545399628521409e-06, 6.396640401362674e-06, 6.254492745938478e-06, 6.11852556176018e-06, 5.98834412812721e-06, 5.863586920895614e-06, 5.743921974499244e-06, 5.629043698718306e-06, 5.5186701501952484e-06, 5.412541668192716e-06, 5.310418600856792e-06, 5.21207721249084e-06, 5.11731241203961e-06, 5.0259318413736764e-06, 4.937757694278844e-06, 4.852623987972038e-06, 4.7703761083539575e-06, 4.690869445767021e-06, 4.613970304490067e-06, 4.539551355264848e-06], "accuracy_train_first": 0.6422580114894795, "accuracy_train_last": 0.9787495818337025, "batch_size_eval": 1024, "accuracy_train_std": [0.020129391094998162, 0.02450699001586296, 0.022661614038733863, 0.024471406618485462, 0.024255116605032413, 0.023513012089394467, 0.02271397345306739, 0.021287787675663618, 0.021261592902828065, 0.020309935825391354, 0.019855803311148296, 0.019137943806884713, 0.01708488422667834, 0.016336725583527178, 0.01565128319811924, 0.015584989826058764, 0.014392796186867774, 0.013540547656645594, 0.013142192837474375, 0.0127113027091325, 0.012071988945525825, 0.012038200055158741, 0.011227760453149254, 0.010903596376098239, 0.010571333112421826, 0.01011818690565731, 0.010151042496485864, 0.009452123348329497, 0.009136321060918745, 0.008410514614785381, 0.00862473703705019, 0.008254139680110744, 0.008065050181124522, 0.008175984856066017, 0.008111668407005857, 0.007674622333598026, 0.007429081426569899, 0.007208873848474579, 0.006969732793603898, 0.0067507682742076296, 0.007240753730120803, 0.006829207310188159, 0.006696132944115808, 0.0064632041169503255, 0.006220023058866562, 0.006092735419749448, 0.006047876106541312, 0.0058768436406108245, 0.005920632029056237, 0.005980519749807715, 0.005935707475402006, 0.0057932556862480685, 0.005667984167992372, 0.005576334666269934, 0.005643275546624563, 0.005682281412251288, 0.00577782090352759, 0.005745657849427557, 0.005526448897927055, 0.005438154586344413, 0.005372089207113426, 0.005343182230893921], "accuracy_test_std": 0.016109216379626982, "error_valid": [0.39083384318524095, 0.3148325724774097, 0.26950183546686746, 0.2576404249811747, 0.2471923828125, 0.24386559911521077, 0.24399796451430722, 0.2422580948795181, 0.24142419286521077, 0.24202424934111444, 0.2416477433170181, 0.2412815323795181, 0.24165803840361444, 0.24264489599021077, 0.24497452701430722, 0.24606286474021077, 0.24716149755271077, 0.24690706184111444, 0.24838220067771077, 0.24886018684111444, 0.2500705948795181, 0.2503147355045181, 0.2500500047063253, 0.2509250870670181, 0.2517795792545181, 0.25362092902861444, 0.2539768448795181, 0.2547298569277108, 0.25532991340361444, 0.2559505600527108, 0.2580360504518072, 0.2579139801393072, 0.2586361069277108, 0.2592567535768072, 0.2587581772402108, 0.2599891754518072, 0.2603553863893072, 0.2603450913027108, 0.2610878082643072, 0.26158638460090367, 0.2612098785768072, 0.2615760895143072, 0.2614540192018072, 0.2615760895143072, 0.2623291015625, 0.26172904508659633, 0.26136283414909633, 0.26099662321159633, 0.26172904508659633, 0.26258353727409633, 0.26185111539909633, 0.26221732633659633, 0.26233939664909633, 0.26221732633659633, 0.26172904508659633, 0.26172904508659633, 0.26197318571159633, 0.26221732633659633, 0.2632041839231928, 0.2630821136106928, 0.2630821136106928, 0.2638248305722892], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.06914626406912329, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.00028145217833981635, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 9.375725590799718e-07, "rotation_range": [0, 0], "momentum": 0.8523991641651598}, "accuracy_valid_max": 0.7587184676204819, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7361751694277108, "accuracy_valid_std": [0.01659561677065192, 0.012139409896783854, 0.01427834642783117, 0.012636250549417609, 0.013005501940000807, 0.012886127864127319, 0.01140352465370164, 0.01166286943466434, 0.013878197478687543, 0.01401456094770625, 0.01286154278880892, 0.01372494345698111, 0.014262748908087467, 0.014272583088116133, 0.015305865175708986, 0.014229801342188837, 0.01447665556266762, 0.014570767928244072, 0.014945167380954196, 0.01406856799470434, 0.015088548827772191, 0.014389796146038383, 0.016304948527358924, 0.016200527178434634, 0.015251512014597823, 0.015090284771393408, 0.015093973597735464, 0.014327340513473993, 0.014142916195350248, 0.013525411018515057, 0.01348015391242922, 0.013722635935340673, 0.014517547520892446, 0.013034703455391669, 0.013098159079312844, 0.012520424476077121, 0.012990063209741018, 0.013237113480607538, 0.013548204880495308, 0.012860396852529354, 0.01410080042427815, 0.01395207608218605, 0.013886056217605941, 0.013641017489742172, 0.012534071264626504, 0.012508428361401185, 0.013568713072120039, 0.013229244320470785, 0.01380415288541202, 0.013970372359854377, 0.013747272511651136, 0.013559825326068215, 0.013417777423917348, 0.013365016054357982, 0.013630343550395116, 0.013665282273637966, 0.01410932578789496, 0.014026527230393321, 0.013441021365937274, 0.012560374098823273, 0.012503299005773684, 0.012354276199583993], "accuracy_valid": [0.609166156814759, 0.6851674275225903, 0.7304981645331325, 0.7423595750188253, 0.7528076171875, 0.7561344008847892, 0.7560020354856928, 0.7577419051204819, 0.7585758071347892, 0.7579757506588856, 0.7583522566829819, 0.7587184676204819, 0.7583419615963856, 0.7573551040097892, 0.7550254729856928, 0.7539371352597892, 0.7528385024472892, 0.7530929381588856, 0.7516177993222892, 0.7511398131588856, 0.7499294051204819, 0.7496852644954819, 0.7499499952936747, 0.7490749129329819, 0.7482204207454819, 0.7463790709713856, 0.7460231551204819, 0.7452701430722892, 0.7446700865963856, 0.7440494399472892, 0.7419639495481928, 0.7420860198606928, 0.7413638930722892, 0.7407432464231928, 0.7412418227597892, 0.7400108245481928, 0.7396446136106928, 0.7396549086972892, 0.7389121917356928, 0.7384136153990963, 0.7387901214231928, 0.7384239104856928, 0.7385459807981928, 0.7384239104856928, 0.7376708984375, 0.7382709549134037, 0.7386371658509037, 0.7390033767884037, 0.7382709549134037, 0.7374164627259037, 0.7381488846009037, 0.7377826736634037, 0.7376606033509037, 0.7377826736634037, 0.7382709549134037, 0.7382709549134037, 0.7380268142884037, 0.7377826736634037, 0.7367958160768072, 0.7369178863893072, 0.7369178863893072, 0.7361751694277108], "seed": 124708323, "model": "residualv3", "loss_std": [0.3601257801055908, 0.28099340200424194, 0.25920671224594116, 0.2458055168390274, 0.2332315742969513, 0.2215137928724289, 0.21057073771953583, 0.19990985095500946, 0.18953904509544373, 0.17961956560611725, 0.1696861982345581, 0.16005544364452362, 0.15068648755550385, 0.14150060713291168, 0.13254734873771667, 0.12371452152729034, 0.1151253804564476, 0.10673020780086517, 0.098448246717453, 0.09040158987045288, 0.08263082802295685, 0.07512683421373367, 0.06786736100912094, 0.06092686951160431, 0.05440935492515564, 0.0481988787651062, 0.04233371838927269, 0.03688611835241318, 0.03182072192430496, 0.027181247249245644, 0.02294461987912655, 0.019140463322401047, 0.015815995633602142, 0.013033850118517876, 0.010834232904016972, 0.009107675403356552, 0.007725372910499573, 0.006601771339774132, 0.005669980775564909, 0.004891437012702227, 0.004229011945426464, 0.0036679431796073914, 0.0031877225264906883, 0.002773868851363659, 0.002416514791548252, 0.002106199972331524, 0.0018377003725618124, 0.0016042067436501384, 0.0014028174336999655, 0.0012256577610969543, 0.0010713536757975817, 0.0009369219187647104, 0.0008200540905818343, 0.0007183336419984698, 0.0006293157930485904, 0.0005516772507689893, 0.00048382996465079486, 0.00042470559128560126, 0.00037268418236635625, 0.0003272295871283859, 0.00028736991225741804, 0.00025255620130337775]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:27 2016", "state": "available"}], "summary": "ac6886beb9898003aadaa2cc72fd7b28"}