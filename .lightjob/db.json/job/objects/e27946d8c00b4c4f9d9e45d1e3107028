{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 32, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.5201640129089355, 1.1127568483352661, 0.8969408869743347, 0.7850939631462097, 0.7107503414154053, 0.6568360924720764, 0.6137598752975464, 0.5788949728012085, 0.547264575958252, 0.5233955979347229, 0.4998757243156433, 0.4788854718208313, 0.45842957496643066, 0.44235533475875854, 0.4246402084827423, 0.41110190749168396, 0.3974669873714447, 0.3863827586174011, 0.37383466958999634, 0.36283963918685913, 0.3512760102748871, 0.34251320362091064, 0.3323904573917389, 0.3233228027820587, 0.31533753871917725, 0.3070845901966095, 0.2989863455295563, 0.2897351384162903, 0.28333714604377747, 0.27461960911750793, 0.26795315742492676, 0.2624855935573578, 0.25622108578681946, 0.24906355142593384, 0.24491864442825317, 0.2382649928331375, 0.2326497584581375, 0.22474417090415955, 0.221281498670578, 0.2178671658039093, 0.2117840051651001, 0.2076779454946518, 0.20328868925571442, 0.1982092708349228, 0.19313965737819672, 0.18959514796733856, 0.18691232800483704, 0.18088169395923615, 0.17742414772510529, 0.17340846359729767, 0.1701459437608719, 0.16679692268371582, 0.1649225354194641, 0.15918929874897003, 0.15591062605381012, 0.1544392704963684, 0.1526378095149994, 0.14901378750801086, 0.14388996362686157, 0.1425987035036087, 0.13897351920604706, 0.13840533792972565, 0.13383068144321442, 0.13240507245063782, 0.12867172062397003, 0.12745694816112518, 0.1262776255607605, 0.12070147693157196, 0.11806055158376694, 0.11675971746444702, 0.11601731181144714, 0.11374381184577942, 0.11153723299503326, 0.11170005798339844, 0.11062944680452347, 0.10647691041231155, 0.10357856750488281, 0.10113247483968735, 0.1011531725525856, 0.09866958856582642, 0.09648099541664124, 0.09673013538122177, 0.0926910936832428, 0.09383980929851532, 0.09122774004936218, 0.08868499845266342, 0.08960289508104324, 0.08702732622623444, 0.0854635164141655, 0.08359642326831818, 0.08455575257539749, 0.08362651616334915, 0.08159775286912918, 0.08122046291828156, 0.08005549013614655, 0.0773773342370987, 0.0753106102347374, 0.07634622603654861, 0.07411445677280426, 0.074869804084301, 0.07175213098526001, 0.07099147140979767, 0.06965474039316177, 0.06829880177974701, 0.06761376559734344, 0.06706807017326355, 0.06610623747110367, 0.06502193212509155, 0.06279084831476212, 0.06345219910144806, 0.06385041028261185, 0.061827968806028366, 0.0615580789744854, 0.05877511948347092, 0.05983394384384155, 0.05815788358449936, 0.0579083114862442, 0.05615808069705963, 0.05594203248620033, 0.054770030081272125, 0.05429405719041824, 0.05489293485879898, 0.05438653379678726, 0.052464935928583145, 0.05016372725367546, 0.05234196409583092, 0.05071486160159111, 0.049709297716617584, 0.048649296164512634, 0.048338983207941055, 0.04940754547715187, 0.04924875125288963, 0.04798905923962593, 0.04687149450182915, 0.04596124589443207, 0.045191943645477295, 0.045936889946460724, 0.04429185390472412, 0.04512123763561249, 0.04408958926796913, 0.043532948940992355, 0.04224323108792305, 0.04182646423578262, 0.04203033819794655, 0.041739847511053085, 0.041087109595537186, 0.04086603596806526, 0.04086214676499367, 0.04020770266652107, 0.03861387446522713, 0.03991306200623512, 0.039360206574201584, 0.03757014870643616, 0.038400646299123764, 0.036788493394851685, 0.037272918969392776, 0.03734397143125534, 0.03727540373802185, 0.03631815314292908, 0.03564441576600075, 0.03575689345598221, 0.035613760352134705, 0.03373044729232788, 0.03424207121133804, 0.03320148587226868, 0.03323759511113167, 0.033867739140987396, 0.03285748139023781, 0.03254849836230278, 0.033276550471782684, 0.0317789725959301, 0.03142821416258812, 0.032018519937992096, 0.030376022681593895, 0.03072345443069935, 0.030536016449332237, 0.030561069026589394, 0.0290992371737957, 0.030252687633037567, 0.02831965498626232, 0.029208652675151825, 0.028566429391503334, 0.02947182022035122, 0.027547253295779228, 0.02807733416557312, 0.027454955503344536, 0.027764542028307915, 0.027546927332878113, 0.02582591027021408, 0.027121592313051224, 0.027330908924341202, 0.026265084743499756, 0.026585906744003296, 0.02703251503407955, 0.025882836431264877, 0.02527586556971073, 0.02641839161515236, 0.025463547557592392, 0.025448644533753395, 0.024679766967892647, 0.024742618203163147, 0.02474791184067726, 0.02369292452931404, 0.023243675008416176, 0.023866858333349228, 0.023242997005581856, 0.02421862632036209, 0.022975586354732513, 0.022509800270199776, 0.022206775844097137, 0.022617407143115997, 0.022455403581261635, 0.022837987169623375, 0.022471074014902115, 0.021807895973324776, 0.02211943455040455, 0.02171444334089756, 0.022054452449083328, 0.02143137902021408, 0.021728243678808212, 0.021160515025258064, 0.0204879529774189, 0.02065238356590271], "moving_avg_accuracy_train": [0.0514548582272056, 0.11212597187615354, 0.17342699753714466, 0.23149451531642207, 0.28671690807118627, 0.33739580500400856, 0.3853177938673028, 0.4299215118965932, 0.4711109948431465, 0.5092416892057311, 0.5442171870498774, 0.5766645419190868, 0.6059556972002309, 0.6331268166413373, 0.6584034942310795, 0.6814527006000074, 0.7026385843617582, 0.7215990310485522, 0.7392770560594685, 0.7549221755561886, 0.7699139890948388, 0.7838577001486716, 0.7962838072102164, 0.8083065380905698, 0.8190410014257543, 0.828788012884554, 0.837751057497492, 0.8461734733193559, 0.8533257120316248, 0.8605323511286191, 0.8674668637432397, 0.8735242743892646, 0.8791968331075917, 0.884736938781467, 0.8894022354498781, 0.8934869620133251, 0.8974375113823138, 0.9015953635513452, 0.9053697302450755, 0.9086181030873546, 0.9118391855953873, 0.9150427903954832, 0.9180653994488659, 0.9206788988981285, 0.9231936646238564, 0.9253106135972866, 0.9276226966174029, 0.9296571044081359, 0.9320716837709859, 0.9338331817606279, 0.935213988953705, 0.937123997086989, 0.9389382634104975, 0.9404409668659593, 0.9414002695829717, 0.942665964869968, 0.9437214573687593, 0.9450550501712429, 0.9463575902410972, 0.947299722620642, 0.948214998980071, 0.9493713521297753, 0.9502328893109008, 0.9512964830798384, 0.9523537349195105, 0.9527636100490526, 0.9533673737442212, 0.9539991167246349, 0.9548234878248736, 0.955453706525775, 0.9560417936470531, 0.9565316526728977, 0.957339863259244, 0.9582555537917083, 0.9587262526518786, 0.9593127501891547, 0.9599196169834083, 0.9605190952767618, 0.9612308309479598, 0.962099149488915, 0.9628271217043368, 0.9634684179029969, 0.9639990454567817, 0.9645162098825875, 0.9647608047777266, 0.9652529465452474, 0.965744702261016, 0.9662220514908946, 0.9667958971216131, 0.9673495245213934, 0.9679965987050052, 0.9683836529702559, 0.9687740707804654, 0.9691044123239121, 0.9694877862677851, 0.9699721875505672, 0.9701755977753, 0.9703681117680727, 0.970557614354416, 0.9711861488999637, 0.9713217135100134, 0.9714529141078401, 0.9716965887304171, 0.9719648682110114, 0.9723179268864034, 0.9722566083406663, 0.9726757520066458, 0.9730295856226572, 0.9731970453997234, 0.9733965152264454, 0.9736319137395613, 0.9738158706156512, 0.9740069363433995, 0.974381255542439, 0.9745740556930216, 0.9749381298844706, 0.9752333166710789, 0.9754339527099972, 0.9758258973937778, 0.9760252598853894, 0.9764580552504403, 0.9766081168004239, 0.9768060233109038, 0.9768098611560778, 0.9771386918547927, 0.9773742216634072, 0.9775746808935688, 0.9778503171554486, 0.9778147576851971, 0.977996667852447, 0.9780697061994006, 0.9782122066711918, 0.9783800206743846, 0.9784310358296298, 0.9785954239121799, 0.9786921838638467, 0.9788258428941748, 0.9788484437226515, 0.9789664767670991, 0.9793702895059023, 0.9795827665422999, 0.9797925249678965, 0.9799533697164003, 0.9802026535400261, 0.9804433931694123, 0.9806297958525172, 0.9806278584530351, 0.9807724549732263, 0.981023571677131, 0.9812055070297205, 0.9812064163327471, 0.9813489966852144, 0.9815890342917483, 0.9817933702959437, 0.9819633939044999, 0.9821674963283725, 0.9821024696848764, 0.9821089417259403, 0.982303283860563, 0.9824594463959722, 0.9825210457647728, 0.9825578840062174, 0.9826468059461271, 0.9826454554837126, 0.9828185541306164, 0.9828627718187913, 0.9830514133107771, 0.9831374852964214, 0.9830754051061111, 0.9831219115800884, 0.9831962473923639, 0.9833467828829171, 0.9835683674280049, 0.9835467962352229, 0.9836159180605747, 0.9837175110378783, 0.9837554662948325, 0.9836270098046995, 0.9837810441278472, 0.9838661605472422, 0.9838125569913644, 0.9838155391625214, 0.9839669965915535, 0.9840335898622155, 0.9841747958676882, 0.9842646428428425, 0.9840271760264893, 0.9840064792917804, 0.9840853642852676, 0.9842470776317962, 0.9842879518984247, 0.984429334386, 0.9845124368462557, 0.9845895181604766, 0.9848705159337607, 0.9850024701428026, 0.9851096031868926, 0.9851827714384783, 0.9853765060494293, 0.985336953508809, 0.9854013015722416, 0.9855173795983876, 0.9856496074123584, 0.9856338980092547, 0.9857662078726426, 0.9857877025973292, 0.9858233599400326, 0.985825188565123, 0.9859545733169534, 0.9860688025912474, 0.9860669411928646, 0.9860652298855014, 0.9858801110993783, 0.9859227315359059, 0.9859751489680942, 0.9859455947463494, 0.9859141654050663, 0.9858999380372249, 0.986049785676378, 0.9859568921147387, 0.9859918704985491, 0.9860024607535114, 0.9860142089853308], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05047504471009036, 0.10961872882153613, 0.1686405014589608, 0.2248821553793298, 0.27780486086925826, 0.32646980494046496, 0.372061805762307, 0.4145544497813323, 0.45318742488979546, 0.4889367535133912, 0.5211477703683774, 0.5510146798432114, 0.5780393237282426, 0.6025048990737919, 0.625433414249244, 0.6455013774176932, 0.664247167527957, 0.6812536854796041, 0.6968647274173365, 0.7105118331300456, 0.7232377994311224, 0.7346239568938837, 0.7448216409767091, 0.7548225752883002, 0.7637288484447112, 0.7716580155580715, 0.7790038445086649, 0.7857595159218798, 0.7910308676052942, 0.7972491934483039, 0.8027602374882626, 0.8074027943117256, 0.8118272950951614, 0.816186734260344, 0.8195323810056199, 0.8223502095936874, 0.8251812830902675, 0.8280710461121895, 0.8306830103545096, 0.8331324639312575, 0.8351497486469419, 0.8374231420992658, 0.8393471258938573, 0.8412394617325589, 0.8426831278051614, 0.8440902315344344, 0.8454706062066687, 0.8465816075212428, 0.8482845160462269, 0.8499555290971011, 0.8510067511779784, 0.8520107976810389, 0.8529520901362031, 0.8539680927660316, 0.8541916948222598, 0.8552231618705308, 0.8558868984884476, 0.8570631394566209, 0.8577098057914558, 0.8584107872793283, 0.8588310625611847, 0.8592113693321746, 0.8597785195318637, 0.860227919555334, 0.8612814112500264, 0.8616374392232918, 0.8618490306266403, 0.8622622779781329, 0.862400207983407, 0.862825402734765, 0.8631643974292855, 0.8631682878350768, 0.8633498941984065, 0.8637229184739724, 0.8639711320859125, 0.8643196831751375, 0.86470662134294, 0.8646408561401219, 0.8647637434176759, 0.8653595346914956, 0.8655864530220448, 0.865918926883997, 0.8666637835367117, 0.867025890216926, 0.8671300006492997, 0.867354888856207, 0.8675237556746527, 0.8677947175977747, 0.8680884409622442, 0.8684016201152669, 0.8686946588755775, 0.8691089961694957, 0.869567348952772, 0.8703166628620881, 0.8702117073251262, 0.8704133046178395, 0.8703973706639622, 0.8705559875602918, 0.8705593178799403, 0.8706986515286933, 0.870775223687571, 0.8710048890541301, 0.8712146764100123, 0.8711928769730772, 0.8712729727471551, 0.8711090073154366, 0.8714761927567093, 0.8717242989610835, 0.8716525667777011, 0.8719695143073858, 0.872157110834102, 0.8720034173523483, 0.8723452854721586, 0.8725553105299879, 0.872327235002215, 0.8727008450392676, 0.8730970997202053, 0.87351270507198, 0.8740495593294657, 0.8739416431179047, 0.874286030669819, 0.874327424779042, 0.8744013005710926, 0.8741005483377784, 0.874430074876365, 0.8745007451466352, 0.874553170867288, 0.8750795167606044, 0.8752592298059295, 0.8751859494269932, 0.8751454406571102, 0.8753094428075137, 0.8752596732255574, 0.8756238896850047, 0.8756463616445916, 0.8755587821442891, 0.8759632413733842, 0.8758348553949313, 0.875767106630664, 0.8760642546837121, 0.876454787752615, 0.8768205335631968, 0.8770224869369223, 0.8771442393256849, 0.8774756020553904, 0.8776538172169448, 0.877877305035913, 0.8780488824671862, 0.8783264019764916, 0.878388946031478, 0.8781746219761465, 0.878082475102327, 0.878272215638028, 0.8782526700907916, 0.8782768477353269, 0.8781316801398815, 0.8779044025626404, 0.8782176955989215, 0.8783033173229148, 0.87826742506728, 0.8782229150059586, 0.8783446358829983, 0.8783432918824243, 0.8785568083737753, 0.8786726425025122, 0.8788246918347158, 0.8786044438014702, 0.8789128859047569, 0.8785729256745974, 0.8787624492780713, 0.8790550908336979, 0.8795423128309003, 0.8800164042134729, 0.8799984857894901, 0.8799447086054959, 0.8797976233812415, 0.8797262818356625, 0.8794057267883915, 0.8793145987631668, 0.8793811269327838, 0.8795874866604392, 0.87950156720185, 0.8795626350675083, 0.8799746885788298, 0.8798988770534016, 0.8797299019045374, 0.8793957483104692, 0.879872289113835, 0.879710090793566, 0.8797482472827335, 0.8797428785032553, 0.8798743829627943, 0.8800945112610179, 0.8797727248563016, 0.8797038731632166, 0.8798881062817594, 0.8796978531648787, 0.879700612323165, 0.8796857409910744, 0.8797761900941508, 0.8795797740214827, 0.8796299326791989, 0.8794969704730259, 0.879520847409157, 0.8795026270319461, 0.8796235945621852, 0.8796561346259214, 0.8797698403933745, 0.8799718908514015, 0.8800449024910355, 0.8802703338816157, 0.8802036379369782, 0.8801080200017141, 0.8802141878339974, 0.8805803525878717, 0.8803941170278797, 0.8804360835724562, 0.8802601568793672, 0.880278898345045, 0.8802326714905857, 0.8801198841513916, 0.8800560261485266, 0.8800178204651499], "moving_var_accuracy_train": [0.02382842191663646, 0.054574436007604823, 0.08293733413064978, 0.10499013030700509, 0.12193673123035749, 0.13285821345627039, 0.14024104526016662, 0.14412236569247797, 0.14497929067186985, 0.14356691027783844, 0.14021978829506757, 0.13567328700763645, 0.12982770430620968, 0.1234893614607346, 0.11689061918444313, 0.10998295049413565, 0.10302423048161985, 0.09595729428052266, 0.08917417796704964, 0.08245968804694456, 0.07623650950084902, 0.07036270225233915, 0.06471610525745, 0.059545409252097635, 0.05462792665473764, 0.050020172080665615, 0.045741180391200724, 0.04180549614656811, 0.038085337199286806, 0.03474422430302708, 0.03170258905954536, 0.028862560167202, 0.026265905452197626, 0.023915549844877218, 0.021719879797428083, 0.019698056737568442, 0.017868712626662946, 0.01623743097593233, 0.014741900473787766, 0.013362677761511097, 0.012119788338071976, 0.011000177257701551, 0.009982385021337714, 0.009045619933545603, 0.008197974360088707, 0.0074185101806848, 0.006724770713643511, 0.006089542977810114, 0.005533060421524618, 0.005007680255879768, 0.004524071886831873, 0.004104497877771584, 0.0037236721506279814, 0.003371627994640697, 0.0030427475505024337, 0.002752890656487912, 0.0024876281705741633, 0.002254871581382272, 0.0020446539189462294, 0.0018481770478368865, 0.0016708989203803638, 0.0015158434018038053, 0.0013709392784535793, 0.0012440264359561276, 0.0011296838254329256, 0.0010182274214859876, 0.0009196854547338213, 0.0008313088020001561, 0.0007542942111983179, 0.0006824393705771783, 0.0006173080516793796, 0.0005577369032982556, 0.0005078420521353695, 0.00046460424928303543, 0.0004201378411074221, 0.00038121987124775875, 0.0003464124698766917, 0.00031500559090684097, 0.00028806414080705713, 0.00026604352052345104, 0.0002442086603889426, 0.00022348914167979116, 0.00020367431791933326, 0.00018571401751727107, 0.00016768105573009736, 0.00015309278183113414, 0.0001399599168039417, 0.00012801468570893757, 0.00011817690640909726, 0.00010911774544827577, 0.00010197431589532088, 9.312518334402756e-05, 8.518449960838421e-05, 7.76481794654861e-05, 7.120614174650487e-05, 6.619732899670397e-05, 5.994997757276648e-05, 5.428853455220944e-05, 4.9182882169065876e-05, 4.782009502668097e-05, 4.320348539549441e-05, 3.903805922777558e-05, 3.566864920019049e-05, 3.27495491975431e-05, 3.0596448132215015e-05, 2.7570642995455263e-05, 2.639471141048647e-05, 2.4882024319814568e-05, 2.2646206880248494e-05, 2.0739680098176217e-05, 1.9164424228153167e-05, 1.7552542995685048e-05, 1.612584370699638e-05, 1.5774293101223104e-05, 1.4531410873682886e-05, 1.4271219938228116e-05, 1.3628315095298583e-05, 1.2627776966784243e-05, 1.2747584986401024e-05, 1.1830535115314896e-05, 1.233328805586971e-05, 1.1302625469334228e-05, 1.0524865804413972e-05, 9.472511785472786e-06, 9.498427262681181e-06, 9.047853153126875e-06, 8.504722964427382e-06, 8.338028807751976e-06, 7.515606210297811e-06, 7.0618673698082005e-06, 6.4036920339587214e-06, 5.946080290709329e-06, 5.604926118646602e-06, 5.067856421364162e-06, 4.804281754388342e-06, 4.408115973168627e-06, 4.128087003346113e-06, 3.7198754800419473e-06, 3.4732741282720306e-06, 4.593529267622503e-06, 4.540494759826911e-06, 4.4824326578227805e-06, 4.2670286901318064e-06, 4.399607643611866e-06, 4.481247001663266e-06, 4.345835943915344e-06, 3.911286131174587e-06, 3.7083309009195817e-06, 3.905034201647585e-06, 3.812435034179991e-06, 3.4311989722499373e-06, 3.2710414872121597e-06, 3.4624998114458275e-06, 3.4920286537962214e-06, 3.4029980356149934e-06, 3.437618426929698e-06, 3.131912763516115e-06, 2.819098473004294e-06, 2.8771084133110947e-06, 2.8088782091688195e-06, 2.5621407283817695e-06, 2.3181401598380806e-06, 2.157490146430239e-06, 1.9417575455258116e-06, 2.0172500650124037e-06, 1.833121894039026e-06, 1.9700802171226666e-06, 1.8397476758252373e-06, 1.690458458503354e-06, 1.5408782817492333e-06, 1.43652277045409e-06, 1.4968188986535267e-06, 1.7890344043839596e-06, 1.6143188111679208e-06, 1.49588737071086e-06, 1.4391888309763743e-06, 1.3082353616528346e-06, 1.3259214542029755e-06, 1.4068684631505907e-06, 1.331384860491256e-06, 1.224106445266809e-06, 1.1017758408434165e-06, 1.1980524320401903e-06, 1.118159162113248e-06, 1.1857954697362045e-06, 1.1398682332621575e-06, 1.533395809756563e-06, 1.383911422229339e-06, 1.301525859783611e-06, 1.4067341318146046e-06, 1.2810970696848524e-06, 1.332888432853458e-06, 1.2617537596730168e-06, 1.1890521447238648e-06, 1.7807846675676412e-06, 1.7594134203654789e-06, 1.6867694805528283e-06, 1.5662748698585896e-06, 1.7474452781957228e-06, 1.5867803816018295e-06, 1.4653684028492667e-06, 1.4400985359501104e-06, 1.4534464354424757e-06, 1.3103228600110933e-06, 1.3368436735576028e-06, 1.2073175149060397e-06, 1.0980287782134526e-06, 9.882559952196023e-07, 1.040094121753244e-06, 1.053519653529441e-06, 9.481988714119511e-07, 8.534053414267793e-07, 1.0764854920651107e-06, 9.851854573468708e-07, 9.113951963871192e-07, 8.281167449548837e-07, 7.54195301900826e-07, 6.805975336720034e-07, 8.146266149426454e-07, 8.108268775946411e-07, 7.407555758410455e-07, 6.676893997584542e-07, 6.021626483405523e-07], "duration": 295667.465111, "accuracy_train": [0.5145485822720561, 0.6581659947166851, 0.725136228486065, 0.7541021753299189, 0.7837184428640642, 0.7935058773994095, 0.8166156936369509, 0.8313549741602067, 0.8418163413621264, 0.8524179384689923, 0.8589966676471945, 0.8686907357419711, 0.8695760947305279, 0.8776668916112956, 0.8858935925387597, 0.8888955579203581, 0.8933115382175157, 0.8922430512296974, 0.898379281157715, 0.8957282510266703, 0.9048403109426911, 0.9093510996331673, 0.9081187707641197, 0.9165111160137505, 0.9156511714424143, 0.9165111160137505, 0.918418459013935, 0.9219752157161315, 0.9176958604420451, 0.9253921030015688, 0.9298774772748246, 0.9280409702034883, 0.930249861572536, 0.9345978898463455, 0.9313899054655776, 0.9302495010843485, 0.9329924557032114, 0.9390160330726283, 0.939339030488649, 0.9378534586678663, 0.9408289281676817, 0.9438752335963455, 0.9452688809293098, 0.9442003939414912, 0.945826556155408, 0.944363154358158, 0.9484314437984496, 0.9479667745247323, 0.9538028980366371, 0.9496866636674051, 0.947641253691399, 0.9543140702865448, 0.9552666603220746, 0.9539652979651162, 0.9500339940360835, 0.9540572224529347, 0.9532208898578812, 0.9570573853935955, 0.958080450869786, 0.9557789140365448, 0.9564524862149317, 0.9597785304771133, 0.95798672394103, 0.9608688270002769, 0.9618690014765596, 0.9564524862149317, 0.9588012470007383, 0.9596848035483574, 0.962242827727021, 0.9611256748338871, 0.9613345777385567, 0.9609403839055003, 0.9646137585363603, 0.9664967685838871, 0.962962542393411, 0.96459122802464, 0.9653814181316908, 0.9659143999169435, 0.9676364519887413, 0.9699140163575121, 0.9693788716431341, 0.9692400836909376, 0.9687746934408453, 0.9691706897148394, 0.9669621588339794, 0.9696822224529347, 0.9701705037029347, 0.9705181945598007, 0.9719605077980805, 0.9723321711194168, 0.9738202663575121, 0.9718671413575121, 0.9722878310723514, 0.9720774862149317, 0.9729381517626431, 0.9743317990956073, 0.9720062897978959, 0.9721007377030271, 0.9722631376315062, 0.976842959809893, 0.9725417950004615, 0.9726337194882798, 0.9738896603336102, 0.9743793835363603, 0.9754954549649317, 0.971704741429033, 0.9764480450004615, 0.9762140881667589, 0.9747041833933187, 0.9751917436669435, 0.9757505003576044, 0.9754714825004615, 0.9757265278931341, 0.9777501283337948, 0.9763092570482651, 0.9782147976075121, 0.9778899977505537, 0.9772396770602622, 0.9793533995478036, 0.977819522309893, 0.9803532135358989, 0.9779586707502769, 0.9785871819052234, 0.9768444017626431, 0.9800981681432264, 0.9794939899409376, 0.9793788139650241, 0.9803310435123662, 0.9774947224529347, 0.9796338593576966, 0.9787270513219823, 0.9794947109173128, 0.9798903467031194, 0.9788901722268365, 0.9800749166551311, 0.9795630234288483, 0.9800287741671282, 0.9790518511789406, 0.9800287741671282, 0.9830046041551311, 0.9814950598698781, 0.9816803507982651, 0.9814009724529347, 0.9824462079526578, 0.9826100498338871, 0.9823074200004615, 0.9806104218576966, 0.9820738236549464, 0.9832836220122739, 0.9828429252030271, 0.9812146000599853, 0.9826322198574198, 0.9837493727505537, 0.9836323943337025, 0.9834936063815062, 0.9840044181432264, 0.981517229893411, 0.982167190095515, 0.9840523630721669, 0.9838649092146549, 0.9830754400839794, 0.9828894281792175, 0.9834471034053157, 0.9826333013219823, 0.9843764419527501, 0.9832607310123662, 0.984749186738649, 0.9839121331672205, 0.9825166833933187, 0.9835404698458842, 0.9838652697028424, 0.9847016022978959, 0.9855626283337948, 0.9833526555001846, 0.9842380144887413, 0.9846318478336102, 0.9840970636074198, 0.9824709013935032, 0.9851673530361758, 0.9846322083217978, 0.9833301249884644, 0.9838423787029347, 0.9853301134528424, 0.9846329292981728, 0.9854456499169435, 0.9850732656192323, 0.9818899746793098, 0.9838202086794019, 0.9847953292266519, 0.9857024977505537, 0.9846558202980805, 0.9857017767741787, 0.9852603589885567, 0.9852832499884644, 0.9873994958933187, 0.9861900580241787, 0.9860738005837025, 0.9858412857027501, 0.9871201175479882, 0.9849809806432264, 0.9859804341431341, 0.9865620818337025, 0.9868396577380952, 0.9854925133813216, 0.9869569966431341, 0.9859811551195091, 0.9861442760243633, 0.9858416461909376, 0.9871190360834257, 0.987096866059893, 0.9860501886074198, 0.9860498281192323, 0.984214042024271, 0.9863063154646549, 0.9864469058577889, 0.985679606750646, 0.985631301333518, 0.9857718917266519, 0.987398414428756, 0.9851208500599853, 0.9863066759528424, 0.9860977730481728, 0.9861199430717055], "end": "2016-02-04 19:55:08.241000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0], "moving_var_accuracy_valid": [0.02292957124637059, 0.05211839245420388, 0.07825868001615818, 0.09890092473582937, 0.11421814706960977, 0.12411082339573187, 0.13040741590660831, 0.13361729747749596, 0.13368812862132656, 0.1318214462325345, 0.12797724807077088, 0.12320781379789512, 0.11746001481212044, 0.11110109272380711, 0.10472243472478485, 0.09787469956387843, 0.09124987142921318, 0.08472787916184911, 0.07844843291909893, 0.07227978107619376, 0.06650935493323966, 0.06102522067581684, 0.05585863345411317, 0.0511729382926447, 0.046769539777209684, 0.04265843101949306, 0.03887823874428615, 0.03540116673604749, 0.032111134399574866, 0.029248029146225967, 0.026596570689296654, 0.024130893625098727, 0.021893990127232477, 0.019875633503023585, 0.0179888103220188, 0.0162613907113825, 0.01470738643453159, 0.013311804363984246, 0.012042025142414257, 0.010891821033594616, 0.009839263868852364, 0.008901852342068748, 0.00804498253063853, 0.007272712691912589, 0.006564198968283983, 0.005925598539599991, 0.005350187593761705, 0.004826277749674403, 0.004369749051707136, 0.003957904708082153, 0.003572059848043852, 0.003223926847662241, 0.002909508446271358, 0.0026278479537385877, 0.0023655131392806743, 0.002138537143797627, 0.001928648346099537, 0.001748235396826467, 0.0015771754532812995, 0.001423880283370229, 0.0012830819368460607, 0.001156075442322002, 0.0010433628322308692, 0.0009408441924376379, 0.000856748375950949, 0.0007722143416155815, 0.0006953958457517625, 0.0006273932215382271, 0.0005648251215615985, 0.0005099697245946809, 0.00046000700876143013, 0.0004140064441026021, 0.00037290262753315835, 0.0003368646887712962, 0.0003037327098685378, 0.0002744528296378836, 0.0002483550369854166, 0.00022355845884399029, 0.00020133852450645315, 0.00018439937723344578, 0.00016642286686875446, 0.00015077543000181139, 0.00014069118989947125, 0.000127802162140227, 0.00011511949676536558, 0.0001040627194392832, 9.391309151670221e-05, 8.518256563907015e-05, 7.744076980868074e-05, 7.057942346480397e-05, 6.429432655372326e-05, 5.940997243653371e-05, 5.535976065831484e-05, 5.4877026604735596e-05, 4.948846492691254e-05, 4.490539165008522e-05, 4.0417137503052174e-05, 3.660185763095833e-05, 3.2941771687123146e-05, 2.982231930948412e-05, 2.6892857038172367e-05, 2.467828695972598e-05, 2.2606554875945687e-05, 2.0350176327407248e-05, 1.837289669189264e-05, 1.677756898789117e-05, 1.6313238423645086e-05, 1.5235924779121581e-05, 1.375864185640474e-05, 1.3286879299923419e-05, 1.2274923481455055e-05, 1.1260026310311352e-05, 1.118588798136422e-05, 1.0464293907473691e-05, 9.886030534046237e-06, 1.015368761871959e-05, 1.0551478806332979e-05, 1.105088120151326e-05, 1.2539705525386929e-05, 1.1390548151307406e-05, 1.1318918409398693e-05, 1.0202447818964048e-05, 9.231321730927602e-06, 9.122256710425434e-06, 9.187320696078807e-06, 8.313537210371392e-06, 7.506919595007891e-06, 9.249587630206304e-06, 8.615299875125865e-06, 7.802100013046743e-06, 7.036658655679012e-06, 6.5750631381436854e-06, 5.939849925922153e-06, 6.539747597320711e-06, 5.890317738297708e-06, 5.370317484327112e-06, 6.305571147896883e-06, 5.8233606682769316e-06, 5.2823336569868615e-06, 5.548772980160442e-06, 6.366540383304755e-06, 6.93381632659804e-06, 6.607501180370254e-06, 6.0801638598577955e-06, 6.460358801613598e-06, 6.1001687157227535e-06, 5.9396730911948235e-06, 5.610655116376011e-06, 5.742743307144809e-06, 5.20367480575758e-06, 5.096720531425592e-06, 4.663467895475331e-06, 4.521134343920822e-06, 4.07245916527972e-06, 3.6704742752092284e-06, 3.4930895245947367e-06, 3.608676446184805e-06, 4.131181540806675e-06, 3.784043103302418e-06, 3.4172330791031943e-06, 3.0933400812223636e-06, 2.917349820265904e-06, 2.625631095277198e-06, 2.7733716144588256e-06, 2.616792361435147e-06, 2.5631841201036708e-06, 2.7434484734306043e-06, 3.325332405806903e-06, 4.032955788036603e-06, 3.952932975696834e-06, 4.328391398843129e-06, 6.032019729980717e-06, 7.4516815082491924e-06, 6.7094029866865305e-06, 6.064490557682987e-06, 5.652748070660405e-06, 5.13327980872472e-06, 5.5447516728308545e-06, 5.0650153583799246e-06, 4.598347798715291e-06, 4.521772053625661e-06, 4.136034228541289e-06, 3.755994363631784e-06, 4.908487792999654e-06, 4.469365500189392e-06, 4.2794023585737364e-06, 4.8563897425746145e-06, 6.414571003769247e-06, 6.009888559275201e-06, 5.422002962337984e-06, 4.880062080241953e-06, 4.547696678125389e-06, 4.529035219422162e-06, 5.008050109821844e-06, 4.549910099605673e-06, 4.400395667357154e-06, 4.286122336967034e-06, 3.857578619860366e-06, 3.4738111665376683e-06, 3.2000594121096376e-06, 3.2272669333198966e-06, 2.9271832584829195e-06, 2.7935754670679103e-06, 2.5193488930722138e-06, 2.2704018430763557e-06, 2.1750599491180857e-06, 1.9670836559379406e-06, 1.8867363043129133e-06, 2.0654821621819586e-06, 1.9069102416620925e-06, 2.173593024226096e-06, 1.9962688630832503e-06, 1.8789270826724335e-06, 1.7924788519110223e-06, 2.8199206095387362e-06, 2.850081702834627e-06, 2.5809242503243795e-06, 2.601383637362995e-06, 2.344406456448444e-06, 2.129198109462427e-06, 2.030767153458573e-06, 1.8643910388819559e-06, 1.6910890031743258e-06], "accuracy_test": 0.8699976084183673, "start": "2016-02-01 09:47:20.776000", "learning_rate_per_epoch": [0.0034586351830512285, 0.002445624442771077, 0.0019968438427895308, 0.0017293175915256143, 0.0015467486809939146, 0.0014119818806648254, 0.001307241152971983, 0.0012228122213855386, 0.0011528783943504095, 0.0010937164770439267, 0.0010428177192807198, 0.0009984219213947654, 0.0009592528222128749, 0.0009243591339327395, 0.0008930157637223601, 0.0008646587957628071, 0.0008388422429561615, 0.0008152081281878054, 0.0007934652967378497, 0.0007733743404969573, 0.0007547360728494823, 0.000737383496016264, 0.0007211752817966044, 0.0007059909403324127, 0.0006917270366102457, 0.0006782941636629403, 0.0006656146142631769, 0.0006536205764859915, 0.0006422524456866086, 0.0006314574857242405, 0.0006211891886778176, 0.0006114061106927693, 0.0006020711152814329, 0.0005931510240770876, 0.0005846160347573459, 0.0005764391971752048, 0.0005685961223207414, 0.0005610646912828088, 0.0005538248806260526, 0.0005468582385219634, 0.0005401480593718588, 0.0005336789763532579, 0.0005274369032122195, 0.0005214088596403599, 0.0005155829130671918, 0.0005099479458294809, 0.0005044937715865672, 0.0004992109606973827, 0.0004940907238051295, 0.0004891248536296189, 0.000484305783174932, 0.00047962641110643744, 0.0004750800726469606, 0.00047066062688827515, 0.0004663622530642897, 0.00046217956696636975, 0.0004581074172165245, 0.000454141030786559, 0.0004502759547904134, 0.00044650788186118007, 0.00044283285387791693, 0.0004392470873426646, 0.0004357470606919378, 0.00043232939788140357, 0.00042899089748971164, 0.000425728561822325, 0.00042253953870385885, 0.00041942112147808075, 0.0004163707490079105, 0.0004133859765715897, 0.00041046447586268187, 0.0004076040640939027, 0.0004048026166856289, 0.00040205815457738936, 0.0003993687860202044, 0.00039673264836892486, 0.00039414805360138416, 0.00039161331369541585, 0.00038912685704417527, 0.00038668717024847865, 0.00038429279811680317, 0.0003819423436652869, 0.00037963452632538974, 0.00037736803642474115, 0.00037514165160246193, 0.00037295420770533383, 0.0003708045987877995, 0.000368691748008132, 0.00036661457852460444, 0.00036457215901464224, 0.0003625634708441794, 0.0003605876408983022, 0.0003586437669582665, 0.0003567309759091586, 0.00035484848194755614, 0.00035299547016620636, 0.0003511711838655174, 0.0003493748954497278, 0.0003476059064269066, 0.00034586351830512285, 0.00034414706169627607, 0.0003424558963160962, 0.00034078944008797407, 0.00033914708183147013, 0.00033752823946997523, 0.00033593233092688024, 0.00033435889054089785, 0.00033280730713158846, 0.0003312771732453257, 0.0003297679068055004, 0.00032827912946231663, 0.00032681028824299574, 0.00032536103390157223, 0.00032393087167292833, 0.00032251939410343766, 0.0003211262228433043, 0.0003197509213350713, 0.0003183931694366038, 0.00031705255969427526, 0.00031572874286212027, 0.00031442136969417334, 0.00031313012004829943, 0.0003118546155747026, 0.0003105945943389088, 0.0003093497361987829, 0.00030811972101219, 0.00030690422863699496, 0.00030570305534638464, 0.00030451585189439356, 0.0003033423563465476, 0.00030218236497603357, 0.00030103555764071643, 0.00029990170150995255, 0.00029878056375309825, 0.0002976719115395099, 0.0002965755120385438, 0.0002954911324195564, 0.00029441856895573437, 0.00029335758881643414, 0.00029230801737867296, 0.00029126962181180716, 0.00029024219838902354, 0.00028922560159116983, 0.0002882195985876024, 0.00028722401475533843, 0.00028623867547139525, 0.0002852634061127901, 0.0002842980611603707, 0.00028334243688732386, 0.00028239638777449727, 0.0002814597391989082, 0.0002805323456414044, 0.000279614090686664, 0.0002787047706078738, 0.000277804268989712, 0.0002769124403130263, 0.00027602913905866444, 0.00027515424881130457, 0.00027428759494796395, 0.0002734291192609817, 0.000272578647127375, 0.00027173603302799165, 0.0002709012187551707, 0.0002700740296859294, 0.0002692543785087764, 0.0002684421488083899, 0.000267637224169448, 0.00026683948817662895, 0.0002660488535184413, 0.0002652652037795633, 0.00026448845164850354, 0.00026371845160610974, 0.000262955145444721, 0.0002621984458528459, 0.0002614482364151627, 0.00026070442982017994, 0.0002599669387564063, 0.0002592356759123504, 0.00025851052487269044, 0.0002577914565335959, 0.0002570783253759146, 0.00025637110229581594, 0.0002556696708779782, 0.00025497397291474044, 0.0002542839210946113, 0.00025359942810609937, 0.00025292043574154377, 0.0002522468857932836, 0.00025157869094982743, 0.00025091576389968395, 0.00025025804643519223, 0.00024960548034869134, 0.0002489580074325204, 0.000248315540375188, 0.0002476779918652028, 0.00024704536190256476, 0.00024641756317578256, 0.0002457945083733648, 0.0002451761392876506, 0.00024456242681480944, 0.00024395331274718046, 0.0002433487243251875, 0.00024274860334116966, 0.000242152891587466, 0.00024156155996024609, 0.00024097452114801854, 0.00024039176059886813, 0.00023981320555321872, 0.0002392387978034094, 0.00023866849369369447, 0.0002381022641202435, 0.0002375400363234803, 0.00023698178119957447, 0.00023642742598894984, 0.00023587695613969117, 0.00023533031344413757, 0.00023478745424654335, 0.0002342483348911628, 0.00023371289717033505, 0.00023318112653214484, 0.0002326529793208465, 0.0002321283973287791, 0.00023160733690019697], "accuracy_train_first": 0.5145485822720561, "accuracy_train_last": 0.9861199430717055, "batch_size_eval": 1024, "accuracy_train_std": [0.016941451076438276, 0.01851423613688886, 0.019115945882171182, 0.018500351468033308, 0.018048549683414246, 0.01812294732635297, 0.017367589756058843, 0.01703060636422231, 0.016060069257725053, 0.015496198996685983, 0.015588696756947216, 0.014790840055739864, 0.014510193740418224, 0.012519061195919522, 0.014705245636450759, 0.013750828000350351, 0.014823342205326728, 0.01295947736244593, 0.013383832952880577, 0.014319492019810035, 0.014339295656227978, 0.01431075691999159, 0.013369634380791773, 0.01338724610898523, 0.013508896745446622, 0.013535682764416032, 0.01250746054927699, 0.012761727501877318, 0.014215088728579468, 0.013046854601302789, 0.013568089911537068, 0.01267517456436004, 0.013158999449698783, 0.011955653066322817, 0.011278900577802814, 0.012977606934374952, 0.013025526394090109, 0.010879903054778083, 0.012361593733545045, 0.010829403179094843, 0.010861284828029531, 0.010035073485330363, 0.010855578481172896, 0.010856942061849643, 0.011372107473051403, 0.010881777081622942, 0.010182474096969788, 0.009741082494028554, 0.009070633024137941, 0.01005805569581075, 0.010876995805009481, 0.009312306429319973, 0.010787950497255224, 0.00838081107549048, 0.00990780874117497, 0.010153693911065064, 0.009312824277238079, 0.009205390219116153, 0.008949684396129804, 0.008965811563650833, 0.009975847609705327, 0.008385924210903638, 0.009445021589053531, 0.00902859219780884, 0.008611275620111833, 0.009658982655750029, 0.00863133005115749, 0.009384851119477157, 0.008023449144989009, 0.009246893684791221, 0.008358318461129992, 0.008379014249193384, 0.008532732614934358, 0.007092110963009011, 0.008605813918761671, 0.007451361723490825, 0.007542242910036669, 0.007821664393454848, 0.007143430631245382, 0.007213021584297932, 0.007838619743606287, 0.007618020930094599, 0.008209259073066048, 0.0073943126569769955, 0.008072864735895567, 0.006363656274957095, 0.006802412893754837, 0.007833874596533659, 0.006888019626355441, 0.007242160378716765, 0.007164860025108486, 0.007371439068771064, 0.006228540858785224, 0.006556694428012492, 0.00752754770650983, 0.006472247635514633, 0.007557579466889512, 0.00634221665302902, 0.007152754149911971, 0.006184634386149922, 0.007155991802846484, 0.00803101191994552, 0.007443458756878526, 0.006695461659339057, 0.005928793456651087, 0.007549282766166946, 0.006147949546003728, 0.007633648961152611, 0.0062277457051765515, 0.006307152161427412, 0.0068394889748657805, 0.006279782979479478, 0.006995018545361408, 0.0062331555325484496, 0.006347402151769435, 0.006210702731370833, 0.006060593817801615, 0.005887990530537443, 0.006361425725272255, 0.006351054011732191, 0.005780182633328825, 0.006274492057365217, 0.006021144265021784, 0.0054508254227461864, 0.005873781230971775, 0.005645654475828298, 0.005765007740349896, 0.0065452956701783594, 0.005963028982667387, 0.006387415447763212, 0.00574372093231007, 0.005741013095827465, 0.005632694308509762, 0.005764772174386374, 0.006109161037019014, 0.005702610040752168, 0.005989743473782656, 0.005928866634681557, 0.005357402633490602, 0.005187851990876323, 0.005119339915578688, 0.005899278453029741, 0.005668759746442799, 0.005254830105398994, 0.005604995354442128, 0.005214874654258623, 0.00529898047545877, 0.00511566741048621, 0.004849073261669635, 0.004642213085250077, 0.0045682163463450845, 0.004526052230269981, 0.0047948624242531036, 0.004752515499274869, 0.004300625331153391, 0.004866387959686874, 0.0052157754638938085, 0.005660817991645312, 0.004422681411327383, 0.0048863853221234295, 0.004021020044692618, 0.0049595269824438465, 0.005089636156194771, 0.004812921225647491, 0.005009054437988853, 0.00553711417914021, 0.004247623303664648, 0.004676921758093169, 0.0044823972006889186, 0.0050649047690260645, 0.0045593510340662296, 0.004470690788090724, 0.0038589351792639435, 0.004389916908100403, 0.004136675493905276, 0.004390724181699494, 0.004097824922404903, 0.005031168250741679, 0.0037134049525451157, 0.004598005596071796, 0.004520391490941914, 0.0044783651566965505, 0.003665629328463798, 0.0038382963346062712, 0.004531766888650539, 0.004307832181749727, 0.0046859781049180885, 0.004614823194022174, 0.004040980561732786, 0.004299577132661316, 0.00423390736647655, 0.0039018021661804563, 0.004732658896994974, 0.004345602659255171, 0.00372801638638631, 0.003763880747257837, 0.0038207351411565687, 0.0040694101995853845, 0.003972889206224662, 0.00453270494681548, 0.004409805161220306, 0.00350921678753452, 0.005079904747101821, 0.004859498633717356, 0.004066673494706297, 0.004033018598950978, 0.004497673947835092, 0.00443747499996277, 0.004301373437495679, 0.0037391053722857863, 0.0045189589109236395, 0.0036886293004801674, 0.004641535260947561, 0.003991714923058778, 0.003686105101994615, 0.004386746820135075, 0.004007355112446999, 0.003856525055265888, 0.003958714075837491, 0.003993733622451556, 0.004287579948410639, 0.004020950980316909, 0.004840398141434447], "accuracy_test_std": 0.007632824358068624, "error_valid": [0.49524955289909633, 0.35808811417545183, 0.3001635448042168, 0.26894295933734935, 0.24589078972138556, 0.23554569841867468, 0.21761018684111444, 0.20301175404743976, 0.1991157991340362, 0.18931928887424698, 0.18895307793674698, 0.1801831348832832, 0.17873888130647586, 0.1773049228162651, 0.16820994917168675, 0.1738869540662651, 0.16704072147966864, 0.1656876529555723, 0.1626358951430723, 0.1666642154555723, 0.16222850385918675, 0.1629006259412651, 0.16339920227786142, 0.15516901590737953, 0.1561146931475903, 0.15697948042168675, 0.15488369493599397, 0.15343944135918675, 0.16152696724397586, 0.1467858739646084, 0.1476403661521084, 0.1508141942771084, 0.14835219785391573, 0.14457831325301207, 0.15035679828689763, 0.15228933311370485, 0.14933905544051207, 0.14592108669051207, 0.1458093114646084, 0.14482245387801207, 0.14669468891189763, 0.1421163168298193, 0.1433370199548193, 0.1417295157191265, 0.14432387754141573, 0.1432458349021084, 0.14210602174322284, 0.1434193806475903, 0.13638930722891573, 0.13500535344503017, 0.1395322500941265, 0.13895278379141573, 0.1385762777673193, 0.13688788356551207, 0.14379588667168675, 0.13549363469503017, 0.13813947195030118, 0.1323506918298193, 0.13647019719503017, 0.1352803793298193, 0.1373864599021084, 0.13736586972891573, 0.13511712867093373, 0.13572748023343373, 0.12923716349774095, 0.1351583090173193, 0.13624664674322284, 0.13401849585843373, 0.1363584219691265, 0.13334784450301207, 0.13378465032003017, 0.13679669851280118, 0.1350156485316265, 0.13291986304593373, 0.1337949454066265, 0.13254335702183728, 0.13181093514683728, 0.13595103068524095, 0.13413027108433728, 0.1292783438441265, 0.13237128200301207, 0.13108880835843373, 0.1266325065888554, 0.1297151496611446, 0.13193300545933728, 0.1306211172816265, 0.13095644295933728, 0.1297666250941265, 0.12926804875753017, 0.12877976750753017, 0.1286679922816265, 0.12716196818524095, 0.12630747599774095, 0.12293951195406627, 0.13073289250753017, 0.12777231974774095, 0.12974603492093373, 0.12801646037274095, 0.12941070924322284, 0.12804734563253017, 0.12853562688253017, 0.12692812264683728, 0.12689723738704817, 0.12900331795933728, 0.1280061652861446, 0.13036668157003017, 0.12521913827183728, 0.12604274519954817, 0.12899302287274095, 0.12517795792545183, 0.12615452042545183, 0.12937982398343373, 0.12457790144954817, 0.12555446394954817, 0.12972544474774095, 0.12393666462725905, 0.12333660815135539, 0.12274684676204817, 0.12111875235316272, 0.1270296027861446, 0.12261448136295183, 0.12530002823795183, 0.12493381730045183, 0.12860622176204817, 0.12260418627635539, 0.12486322242093373, 0.12497499764683728, 0.12018337019954817, 0.12312335278614461, 0.12547357398343373, 0.12521913827183728, 0.12321453783885539, 0.12518825301204817, 0.12109816217996983, 0.12415139071912651, 0.12522943335843373, 0.12039662556475905, 0.1253206184111446, 0.12484263224774095, 0.12126141283885539, 0.12003041462725905, 0.11988775414156627, 0.12115993269954817, 0.12175998917545183, 0.11954213337725905, 0.12074224632906627, 0.12011130459337349, 0.12040692065135539, 0.11917592243975905, 0.12104815747364461, 0.12375429452183728, 0.12274684676204817, 0.12002011954066272, 0.12192323983433728, 0.12150555346385539, 0.12317482821912651, 0.12414109563253017, 0.11896266707454817, 0.12092608716114461, 0.12205560523343373, 0.12217767554593373, 0.12055987622364461, 0.12166880412274095, 0.11952154320406627, 0.12028485033885539, 0.11980686417545183, 0.12337778849774095, 0.11831113516566272, 0.12448671639683728, 0.11953183829066272, 0.11831113516566272, 0.11607268919427716, 0.11571677334337349, 0.12016278002635539, 0.12053928605045183, 0.12152614363704817, 0.12091579207454817, 0.12347926863704817, 0.12150555346385539, 0.12002011954066272, 0.11855527579066272, 0.12127170792545183, 0.11988775414156627, 0.11631682981927716, 0.12078342667545183, 0.12179087443524095, 0.12361163403614461, 0.11583884365587349, 0.12174969408885539, 0.11990834431475905, 0.12030544051204817, 0.11894207690135539, 0.11792433405496983, 0.12312335278614461, 0.12091579207454817, 0.11845379565135539, 0.12201442488704817, 0.12027455525225905, 0.12044810099774095, 0.11940976797816272, 0.12218797063253017, 0.11991863940135539, 0.12169968938253017, 0.12026426016566272, 0.12066135636295183, 0.11928769766566272, 0.12005100480045183, 0.11920680769954817, 0.11820965502635539, 0.11929799275225905, 0.11770078360316272, 0.12039662556475905, 0.12075254141566272, 0.11883030167545183, 0.11612416462725905, 0.12128200301204817, 0.11918621752635539, 0.12132318335843373, 0.11955242846385539, 0.12018337019954817, 0.12089520190135539, 0.12051869587725905, 0.12032603068524095], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.02146479959779255, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.0034586351317399617, "optimization": "nesterov_momentum", "nb_data_augmentation": 4, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.4138381457465574e-08, "rotation_range": [0, 0], "momentum": 0.9547570998858328}, "accuracy_valid_max": 0.8842832266566265, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.879673969314759, "accuracy_valid_std": [0.008259097551981745, 0.013057012772477762, 0.014564840061308959, 0.014884342044097047, 0.010910455425574702, 0.015970374196617128, 0.012838740422935679, 0.010658195145696638, 0.012007718223043367, 0.012112023186624715, 0.011706896977504825, 0.010642198310837967, 0.009210986102062127, 0.010265726003802426, 0.009076192499384007, 0.009676152885891012, 0.011631003978371654, 0.0097242283351659, 0.012767013087642448, 0.010487284635119479, 0.010416027068744211, 0.014614835382907683, 0.015239806653234916, 0.01403039861179506, 0.01043105040245028, 0.012130995672345749, 0.01124748583581338, 0.010740393542917103, 0.013955163462026755, 0.009491232466056383, 0.009519780415003879, 0.008924825004276936, 0.00863886510160077, 0.008675639903865547, 0.010251214943771167, 0.008979375714543656, 0.006555519372414433, 0.010732183249337435, 0.008887623333265031, 0.011903903837065173, 0.013857894821488515, 0.009172203744004025, 0.010058390677913193, 0.009857684615686363, 0.010513091469164003, 0.011967656609181998, 0.011034903464490474, 0.014882242269612985, 0.0116801388823391, 0.010084002008857475, 0.01104514965158522, 0.010766933311663542, 0.01325652205214877, 0.014771336509968916, 0.01713103924809577, 0.010236740048104364, 0.015415743176106934, 0.012429924277263296, 0.01028363450672347, 0.012414084068401174, 0.015282092739535753, 0.01447578444402509, 0.010546277106579858, 0.013546130246088561, 0.011636326013019038, 0.012112393211015001, 0.011539686024605608, 0.011525755170580678, 0.014699959283974069, 0.016501632784287703, 0.012512881459880526, 0.013825314886610693, 0.012345126069356418, 0.01324436243592397, 0.01245386322585093, 0.011316150422833435, 0.010587926883786007, 0.012758316647636572, 0.009323781575244208, 0.010192004467752898, 0.012737598730474907, 0.011958631015442265, 0.010107824435711647, 0.01142465275876025, 0.012164595956303577, 0.014331181649217638, 0.01311521401077216, 0.012218426632080755, 0.013133601560491343, 0.009850264001263837, 0.009917449548663236, 0.01012667448364494, 0.00954409896278252, 0.011880527292276087, 0.012060012750002331, 0.00950572303681182, 0.01041933671176513, 0.010125974178554969, 0.01232810554049137, 0.012049140663087021, 0.009498979787611342, 0.011007195677203863, 0.011081851479526101, 0.012099602685313496, 0.009389716094054985, 0.012784998233729023, 0.011000604291114812, 0.009469743755256735, 0.010281232168622187, 0.01061443378591234, 0.008857945150538437, 0.009653429877433466, 0.007563504219665145, 0.010867956995030731, 0.010726311795025102, 0.011570165291909597, 0.009500768415142078, 0.008006858523729553, 0.007942410768621561, 0.009460879023564704, 0.008305384463367423, 0.008454623101011687, 0.008932621650613742, 0.011332364140082013, 0.0067327468094396554, 0.010926399521422749, 0.009811480979324747, 0.010790702035670554, 0.010573637278676778, 0.012404456680942318, 0.011612130397028112, 0.007394380121006697, 0.007767210329932509, 0.010048760411281549, 0.010443336502019092, 0.009717897582595066, 0.00813903214609943, 0.008304673958381909, 0.008416652815060169, 0.010597821981119115, 0.008918891832283267, 0.01038906153151264, 0.009824522648563639, 0.010261561528533525, 0.00682349825722975, 0.010028020370353668, 0.011312159450725738, 0.009749958830179995, 0.008206296279470919, 0.011131308840023798, 0.010986429224687193, 0.008988831067281773, 0.008203307235606114, 0.011622353172932448, 0.007492929559879368, 0.013278132649324223, 0.011078626906223332, 0.008254832104685769, 0.007994856577755189, 0.011646896392713936, 0.01140333497069098, 0.008618030406499387, 0.008730339352170196, 0.012562545838528052, 0.008463645882252058, 0.007366000372328008, 0.008872635264740603, 0.0072029507302169195, 0.010422979840737588, 0.009365012251750748, 0.010990244245797453, 0.012838027828229619, 0.010375339367027411, 0.011729538392060356, 0.008900002565744886, 0.011065509277756748, 0.008798890274943953, 0.010443847354084825, 0.009232066942982196, 0.008724433335667449, 0.009213645545995552, 0.007848847908181546, 0.010593589284533543, 0.011963559973139654, 0.00781427826386002, 0.007300312025230405, 0.010342086268300039, 0.010071510265082139, 0.008263236590327922, 0.007516857899953312, 0.008690190162469457, 0.01015199892410915, 0.008955644688043957, 0.008733695495887778, 0.009823133736167305, 0.008045011800568148, 0.009261944295962015, 0.008796796532036407, 0.011496130475202603, 0.008592821276745901, 0.012493892112688781, 0.007483687204117204, 0.011327721169267588, 0.008886200076380735, 0.007163541626864519, 0.009987782581750853, 0.009134382767957895, 0.00888247589412056, 0.00779429058010343, 0.008356026268916772, 0.007771214859458576, 0.007206852955981976, 0.009463073613101513, 0.008243602124555254, 0.006919125895984064, 0.005485491039599735, 0.007586993885309965, 0.009142964335826084, 0.008403999282572771, 0.00820518269922753, 0.008562773063701016, 0.007842930487884392, 0.009481962158715896], "accuracy_valid": [0.5047504471009037, 0.6419118858245482, 0.6998364551957832, 0.7310570406626506, 0.7541092102786144, 0.7644543015813253, 0.7823898131588856, 0.7969882459525602, 0.8008842008659638, 0.810680711125753, 0.811046922063253, 0.8198168651167168, 0.8212611186935241, 0.8226950771837349, 0.8317900508283133, 0.8261130459337349, 0.8329592785203314, 0.8343123470444277, 0.8373641048569277, 0.8333357845444277, 0.8377714961408133, 0.8370993740587349, 0.8366007977221386, 0.8448309840926205, 0.8438853068524097, 0.8430205195783133, 0.845116305064006, 0.8465605586408133, 0.8384730327560241, 0.8532141260353916, 0.8523596338478916, 0.8491858057228916, 0.8516478021460843, 0.8554216867469879, 0.8496432017131024, 0.8477106668862951, 0.8506609445594879, 0.8540789133094879, 0.8541906885353916, 0.8551775461219879, 0.8533053110881024, 0.8578836831701807, 0.8566629800451807, 0.8582704842808735, 0.8556761224585843, 0.8567541650978916, 0.8578939782567772, 0.8565806193524097, 0.8636106927710843, 0.8649946465549698, 0.8604677499058735, 0.8610472162085843, 0.8614237222326807, 0.8631121164344879, 0.8562041133283133, 0.8645063653049698, 0.8618605280496988, 0.8676493081701807, 0.8635298028049698, 0.8647196206701807, 0.8626135400978916, 0.8626341302710843, 0.8648828713290663, 0.8642725197665663, 0.870762836502259, 0.8648416909826807, 0.8637533532567772, 0.8659815041415663, 0.8636415780308735, 0.8666521554969879, 0.8662153496799698, 0.8632033014871988, 0.8649843514683735, 0.8670801369540663, 0.8662050545933735, 0.8674566429781627, 0.8681890648531627, 0.864048969314759, 0.8658697289156627, 0.8707216561558735, 0.8676287179969879, 0.8689111916415663, 0.8733674934111446, 0.8702848503388554, 0.8680669945406627, 0.8693788827183735, 0.8690435570406627, 0.8702333749058735, 0.8707319512424698, 0.8712202324924698, 0.8713320077183735, 0.872838031814759, 0.873692524002259, 0.8770604880459337, 0.8692671074924698, 0.872227680252259, 0.8702539650790663, 0.871983539627259, 0.8705892907567772, 0.8719526543674698, 0.8714643731174698, 0.8730718773531627, 0.8731027626129518, 0.8709966820406627, 0.8719938347138554, 0.8696333184299698, 0.8747808617281627, 0.8739572548004518, 0.871006977127259, 0.8748220420745482, 0.8738454795745482, 0.8706201760165663, 0.8754220985504518, 0.8744455360504518, 0.870274555252259, 0.876063335372741, 0.8766633918486446, 0.8772531532379518, 0.8788812476468373, 0.8729703972138554, 0.8773855186370482, 0.8746999717620482, 0.8750661826995482, 0.8713937782379518, 0.8773958137236446, 0.8751367775790663, 0.8750250023531627, 0.8798166298004518, 0.8768766472138554, 0.8745264260165663, 0.8747808617281627, 0.8767854621611446, 0.8748117469879518, 0.8789018378200302, 0.8758486092808735, 0.8747705666415663, 0.879603374435241, 0.8746793815888554, 0.875157367752259, 0.8787385871611446, 0.879969585372741, 0.8801122458584337, 0.8788400673004518, 0.8782400108245482, 0.880457866622741, 0.8792577536709337, 0.8798886954066265, 0.8795930793486446, 0.880824077560241, 0.8789518425263554, 0.8762457054781627, 0.8772531532379518, 0.8799798804593373, 0.8780767601656627, 0.8784944465361446, 0.8768251717808735, 0.8758589043674698, 0.8810373329254518, 0.8790739128388554, 0.8779443947665663, 0.8778223244540663, 0.8794401237763554, 0.878331195877259, 0.8804784567959337, 0.8797151496611446, 0.8801931358245482, 0.876622211502259, 0.8816888648343373, 0.8755132836031627, 0.8804681617093373, 0.8816888648343373, 0.8839273108057228, 0.8842832266566265, 0.8798372199736446, 0.8794607139495482, 0.8784738563629518, 0.8790842079254518, 0.8765207313629518, 0.8784944465361446, 0.8799798804593373, 0.8814447242093373, 0.8787282920745482, 0.8801122458584337, 0.8836831701807228, 0.8792165733245482, 0.878209125564759, 0.8763883659638554, 0.8841611563441265, 0.8782503059111446, 0.880091655685241, 0.8796945594879518, 0.8810579230986446, 0.8820756659450302, 0.8768766472138554, 0.8790842079254518, 0.8815462043486446, 0.8779855751129518, 0.879725444747741, 0.879551899002259, 0.8805902320218373, 0.8778120293674698, 0.8800813605986446, 0.8783003106174698, 0.8797357398343373, 0.8793386436370482, 0.8807123023343373, 0.8799489951995482, 0.8807931923004518, 0.8817903449736446, 0.880702007247741, 0.8822992163968373, 0.879603374435241, 0.8792474585843373, 0.8811696983245482, 0.883875835372741, 0.8787179969879518, 0.8808137824736446, 0.8786768166415663, 0.8804475715361446, 0.8798166298004518, 0.8791047980986446, 0.879481304122741, 0.879673969314759], "seed": 882147187, "model": "residualv3", "loss_std": [0.3210684359073639, 0.26633957028388977, 0.25582799315452576, 0.24766656756401062, 0.2415119856595993, 0.23584119975566864, 0.2304569035768509, 0.22622837126255035, 0.22072432935237885, 0.2162804752588272, 0.21154874563217163, 0.2081676423549652, 0.20496679842472076, 0.20016324520111084, 0.19462533295154572, 0.19243517518043518, 0.18836738169193268, 0.18639333546161652, 0.1848057061433792, 0.17973972856998444, 0.17771218717098236, 0.1719997674226761, 0.17138977348804474, 0.1662728190422058, 0.1671755611896515, 0.16155467927455902, 0.15854842960834503, 0.15450166165828705, 0.15339158475399017, 0.15008878707885742, 0.14751069247722626, 0.14574970304965973, 0.14192728698253632, 0.13936029374599457, 0.1370471566915512, 0.13303744792938232, 0.13425548374652863, 0.12903939187526703, 0.12985168397426605, 0.126155287027359, 0.12282349169254303, 0.12384526431560516, 0.12052871286869049, 0.11834152042865753, 0.11549938470125198, 0.11410010606050491, 0.11283347755670547, 0.11115513741970062, 0.1080995723605156, 0.10589150339365005, 0.10364512354135513, 0.10195454210042953, 0.10155271738767624, 0.09935474395751953, 0.09662425518035889, 0.09685684740543365, 0.09635147452354431, 0.09291909635066986, 0.09130042046308517, 0.09010198712348938, 0.08800956606864929, 0.08750416338443756, 0.0852382555603981, 0.08542045205831528, 0.08387324959039688, 0.08413960039615631, 0.08272629231214523, 0.07818722724914551, 0.07870201766490936, 0.07637914270162582, 0.0757148414850235, 0.07559794187545776, 0.07543238252401352, 0.07419189065694809, 0.07346067577600479, 0.07260604202747345, 0.0697532594203949, 0.06881073862314224, 0.06769762188196182, 0.06697701662778854, 0.06428108364343643, 0.06612807512283325, 0.06383482366800308, 0.0648319199681282, 0.06249045953154564, 0.059655170887708664, 0.0625772699713707, 0.06039033457636833, 0.060075659304857254, 0.05881638824939728, 0.059526924043893814, 0.05983686447143555, 0.058549024164676666, 0.059314802289009094, 0.05720385164022446, 0.05574991554021835, 0.05310986936092377, 0.054895542562007904, 0.05463400110602379, 0.055292122066020966, 0.05245381221175194, 0.05185874179005623, 0.0514238178730011, 0.050485704094171524, 0.05001910775899887, 0.049325183033943176, 0.04782680794596672, 0.048516251146793365, 0.04711082577705383, 0.046949028968811035, 0.048341140151023865, 0.04636646807193756, 0.045951224863529205, 0.04490482062101364, 0.04670008271932602, 0.0454995334148407, 0.04433469474315643, 0.04335427284240723, 0.04271860048174858, 0.0416591614484787, 0.043230097740888596, 0.04323273524641991, 0.04276806488633156, 0.04146869480609894, 0.03943488001823425, 0.04067764803767204, 0.03873992711305618, 0.03905068710446358, 0.03844057396054268, 0.03887337073683739, 0.040039487183094025, 0.04039876535534859, 0.038610611110925674, 0.03824930265545845, 0.03716540336608887, 0.036980632692575455, 0.03770758956670761, 0.03758323937654495, 0.03705206513404846, 0.0364944189786911, 0.036052118986845016, 0.03452211618423462, 0.03484330698847771, 0.03612588718533516, 0.0356038399040699, 0.03461630269885063, 0.03497539833188057, 0.03496062010526657, 0.033706750720739365, 0.032908231019973755, 0.03498402237892151, 0.03375893086194992, 0.03207892179489136, 0.03361409157514572, 0.03232729062438011, 0.03282274678349495, 0.03290557488799095, 0.03348540887236595, 0.03142157942056656, 0.03161308914422989, 0.03235190734267235, 0.03243274986743927, 0.030123960226774216, 0.03166285902261734, 0.028891783207654953, 0.030435483902692795, 0.031010903418064117, 0.02895504981279373, 0.0295995082706213, 0.03173922374844551, 0.029546819627285004, 0.028304744511842728, 0.02888297103345394, 0.028069430962204933, 0.02830394171178341, 0.02854512259364128, 0.02933104895055294, 0.027039429172873497, 0.029284005984663963, 0.026609882712364197, 0.02799336612224579, 0.026348043233156204, 0.027141662314534187, 0.025918681174516678, 0.027005434036254883, 0.026481930166482925, 0.026818720623850822, 0.026286832988262177, 0.025824064388871193, 0.025768235325813293, 0.026029976084828377, 0.025869224220514297, 0.026636434718966484, 0.02740015648305416, 0.025037430226802826, 0.025000039488077164, 0.026352906599640846, 0.024948155507445335, 0.025022145360708237, 0.024382123723626137, 0.024679940193891525, 0.025318307802081108, 0.022872792556881905, 0.023661892861127853, 0.024078669026494026, 0.023744715377688408, 0.024592537432909012, 0.023166479542851448, 0.023042060434818268, 0.02313689887523651, 0.023926222696900368, 0.022970102727413177, 0.023554598912596703, 0.023133806884288788, 0.02329343743622303, 0.023324979469180107, 0.022577103227376938, 0.023941563442349434, 0.022255951538681984, 0.02320845052599907, 0.022597400471568108, 0.02214760333299637, 0.021530823782086372]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:38 2016", "state": "available"}], "summary": "a7e877199101fa5d93c236fc26d8999d"}