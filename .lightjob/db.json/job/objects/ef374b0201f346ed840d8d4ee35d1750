{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 16, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.010790656833250855, 0.008462548402182277, 0.01145103043051444, 0.01087870292191316, 0.008656342280201335, 0.01430587423487122, 0.007664348057647792, 0.005133947595198055, 0.0058731969652805124, 0.005287314286446469, 0.01060696782632884, 0.007499266228765097, 0.00965096838684796, 0.007852392253262107, 0.009343986430964103, 0.0055901821074501555, 0.011608674222301989, 0.007999980843291687, 0.011650536172989874, 0.014170861485567447, 0.007853847247300112, 0.009416594540800948, 0.009323322685013794, 0.016109682091593677, 0.013693400577105967, 0.010826181755076504, 0.0175180606748715, 0.014419665083338615, 0.009167746979667388, 0.00850906151925267, 0.006731556234153066, 0.011524106466746016, 0.007979305591733278, 0.013312817524675865, 0.010613559114961415, 0.01078399597600801, 0.013710446467003833, 0.008818398541700804, 0.014092517251705319, 0.007219681811222259, 0.013536975851040403, 0.010678560386129746, 0.012059844871520729, 0.010478122264994182, 0.012900100911546466, 0.012757812342829442, 0.01663798296911671, 0.012253567769614683, 0.009720002876588574, 0.010042564025917166, 0.008463110578185443, 0.01600928593949471, 0.005184433084974893, 0.007190492574437847, 0.012701484150107542, 0.013161407782734868, 0.00798726881970285, 0.011257674287047444, 0.010342516165114274, 0.009634068242086603, 0.010768531624319816, 0.010133379239667886, 0.010737153954788067, 0.013715148337962649, 0.012004993068249446, 0.008960371226128404, 0.014510174287248807, 0.010647035498715297, 0.006104447427545626, 0.010212348048646984, 0.013365287705399947, 0.0107348594568063, 0.012153583922445841, 0.004857353723692969, 0.00870520461788822, 0.009158342311964928, 0.015866190173912657, 0.009598901771112141, 0.007265976610959667, 0.006120982709916164, 0.010047978255061955, 0.015039036585065198, 0.006586221867884639, 0.009755860052388824, 0.009119497720354974, 0.010888215669220677, 0.00746754055542375, 0.016798106013678475, 0.012153972525148713, 0.01098444693014215, 0.012070941615217767, 0.01388119525159879, 0.011915526306698539, 0.017754763205914015, 0.010873799707407395, 0.012184309792247182, 0.012889851167286165], "moving_avg_accuracy_train": [0.009619266795865632, 0.018711770227713177, 0.027711042402062565, 0.03803018349569721, 0.04664104451812823, 0.05278457419676022, 0.059136853586100435, 0.06373082211268788, 0.06701013556171809, 0.07071922778720002, 0.07475717243534417, 0.07896556227698878, 0.08277632857374542, 0.0864962653050106, 0.09218073057498943, 0.09524596806797037, 0.09932340167484074, 0.10183302290916546, 0.10407268429257523, 0.1081479566994196, 0.11018638538002212, 0.11428730635429381, 0.11615608373612173, 0.120225298377229, 0.12272526949119493, 0.12520242314954128, 0.12701394748625752, 0.12951785436530805, 0.1307860481934967, 0.1304931663115778, 0.13180315762961714, 0.13271980453738264, 0.13257501945670638, 0.13355649450323767, 0.13348916062138935, 0.13636900820012343, 0.13915629166744037, 0.14120185378438035, 0.1425595892254329, 0.14544396042355223, 0.14223733244021325, 0.1409601899873049, 0.14086747882818312, 0.13881306961969114, 0.14048652153438315, 0.14121363130877798, 0.1448041523198806, 0.14564641366942632, 0.14577375677553647, 0.1443264063033169, 0.14261249188076483, 0.1425108401859977, 0.14295392159398523, 0.14258600858394996, 0.14255726436661253, 0.1456205440207597, 0.1427096841323419, 0.1447116211385429, 0.14490679476319912, 0.14659104001694565, 0.1443876320170045, 0.1447221974478714, 0.14438836046655787, 0.1458551644738888, 0.1471962504685911, 0.14801274705909817, 0.14980063405953756, 0.14775535545655538, 0.14853650739936422, 0.1508022604408047, 0.14974716979608746, 0.14821615681818598, 0.14519018326676605, 0.1430267713965771, 0.14194443977763735, 0.14087737141702938, 0.14017012667335155, 0.1401376764598739, 0.13940768223119918, 0.13927809966814755, 0.1405956235422335, 0.14163938070743615, 0.1407632895705242, 0.13785953496055559, 0.13638722709595996, 0.13798893558791436, 0.13425352039406385, 0.13501290989904655, 0.1366655509700961, 0.1362658083211762, 0.1395977634167533, 0.13872401469712486, 0.13844362206946664, 0.1371271436238249, 0.1361208447976181, 0.1359203087732365, 0.13740423636190582], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 908733046, "moving_var_accuracy_train": [0.0008327726432103876, 0.001493557946812783, 0.0020730842491436773, 0.0028241378804223626, 0.003209046440308722, 0.0032278284084879386, 0.0032682086486012737, 0.0031313287051506307, 0.0029149809049084817, 0.0027472991006518084, 0.002619314163419912, 0.002516777652611239, 0.002395797345266582, 0.0022807589743014667, 0.0023435013855216784, 0.002193712374964895, 0.0021239703208343285, 0.0019682570774088573, 0.0018165761176790044, 0.0017843891126209871, 0.0016433469247320149, 0.0016303702077938064, 0.00149876414713991, 0.0014979143025845357, 0.001404371572462058, 0.0013191610274393812, 0.0012167795084980797, 0.00115152750457888, 0.0010508495943936942, 0.0009465366531251319, 0.0008673276830926647, 0.0007881570887650426, 0.0007095300443648162, 0.0006472466793310068, 0.000582562816062709, 0.000598948233147103, 0.0006089739519769973, 0.0005857354761476373, 0.000543752938283885, 0.0005642540193323588, 0.0006003707846109165, 0.0005550135417550121, 0.0004995895458107422, 0.00048761596599309834, 0.00046405834119086586, 0.00042241070468796387, 0.0004961962043996931, 0.0004529612215881709, 0.0004078110458294179, 0.0003858833517513842, 0.0003737325404067336, 0.00033645228396950156, 0.0003045739457794894, 0.0002753347910481195, 0.0002478087480135806, 0.00030748101336783025, 0.00035299085964104397, 0.00035376153966811376, 0.00031872822039515547, 0.0003123855370285495, 0.00032484204465353645, 0.0002933652464359633, 0.00026503174596319973, 0.00025789219733017826, 0.0002482895824038403, 0.00022946062430424338, 0.00023528342121088044, 0.0002494035601641431, 0.00022995498936751498, 0.00025316222203393407, 0.00023786494624766915, 0.0002351744582694269, 0.0002940656558475205, 0.0003067822485434394, 0.00028664699928930576, 0.00026823001333627013, 0.0002459087681497825, 0.00022132736848199693, 0.00020399065579888298, 0.00018374271498481794, 0.00018099126591541407, 0.0001726970005030793, 0.0001623351215743523, 0.00022198772693114344, 0.0002192981682713798, 0.00022045758228303114, 0.00032399176408877037, 0.000296782639462394, 0.0002916853781036335, 0.00026395498796155973, 0.00033747681199588353, 0.0003106000622217664, 0.0002802476362303955, 0.0002678209120879099, 0.00025015255682774517, 0.00022549923341864362, 0.0002227676798725052], "duration": 64643.706291, "accuracy_train": [0.09619266795865633, 0.10054430111434108, 0.10870449197120709, 0.13090245333840902, 0.12413879372000738, 0.10807634130444813, 0.11630736809016241, 0.1050765388519749, 0.09652395660299003, 0.10410105781653746, 0.11109867426864158, 0.11684107085179034, 0.11707322524455518, 0.1199756958863972, 0.1433409180047988, 0.12283310550479881, 0.13602030413667404, 0.12441961401808786, 0.12422963674326319, 0.14482540836101881, 0.12853224350544482, 0.151195595122739, 0.1329750801725729, 0.15684823014719454, 0.14522500951688816, 0.14749680607465857, 0.14331766651670358, 0.15205301627676265, 0.14219979264719454, 0.12785722937430788, 0.1435930794919712, 0.14096962670727206, 0.13127195373062014, 0.14238976992201918, 0.13288315568475453, 0.16228763640873017, 0.16424184287329271, 0.15961191283684015, 0.15477920819490587, 0.17140330120662606, 0.11337768059016241, 0.12946590791112958, 0.1400330783960871, 0.12032338674326319, 0.1555475887666113, 0.1477576192783315, 0.17711884141980436, 0.15322676581533776, 0.14691984473052788, 0.1313002520533407, 0.12718726207779624, 0.1415959749330934, 0.14694165426587302, 0.13927479149363234, 0.14229856641057587, 0.17319006090808417, 0.11651194513658177, 0.16272905419435216, 0.14666335738510522, 0.16174924730066445, 0.12455696001753415, 0.14773328632567367, 0.14138382763473606, 0.1590564005398671, 0.15926602442091178, 0.15536121637366188, 0.16589161706349206, 0.12934784802971575, 0.15556687488464377, 0.1711940378137689, 0.14025135399363234, 0.1344370400170727, 0.11795642130398672, 0.12355606456487633, 0.13220345520717977, 0.1312737561715578, 0.133804923980251, 0.13984562453857513, 0.1328377341731266, 0.13811185660068293, 0.15245333840900702, 0.1510331951942599, 0.1328784693383167, 0.11172574347083795, 0.12313645631459949, 0.1524043120155039, 0.10063478364940938, 0.14184741544389073, 0.15153932060954226, 0.13266812448089702, 0.1695853592769472, 0.1308602762204688, 0.13592008842054262, 0.1252788376130491, 0.1270641553617571, 0.13411548455380215, 0.15075958465992986], "end": "2016-01-24 04:39:17.024000", "learning_rate_per_epoch": [0.007598725147545338, 0.0053731100633740425, 0.004387125838547945, 0.003799362573772669, 0.0033982531167566776, 0.0031021665781736374, 0.0028720481786876917, 0.0026865550316870213, 0.002532908460125327, 0.0024029279593378305, 0.0022911017294973135, 0.0021935629192739725, 0.0021075070835649967, 0.0020308448001742363, 0.0019619823433458805, 0.0018996812868863344, 0.001842961530201137, 0.0017910366877913475, 0.0017432670574635267, 0.0016991265583783388, 0.0016581777017563581, 0.001620053662918508, 0.0015844437293708324, 0.0015510832890868187, 0.0015197449829429388, 0.0014902326511219144, 0.0014623752795159817, 0.0014360240893438458, 0.001411047880537808, 0.0013873310526832938, 0.0013647712767124176, 0.0013432775158435106, 0.001322768279351294, 0.0013031705748289824, 0.0012844189768657088, 0.0012664542300626636, 0.0012492226669564843, 0.001232675975188613, 0.0012167698005214334, 0.0012014639796689153, 0.0011867214925587177, 0.0011725086951628327, 0.0011587947374209762, 0.0011455508647486567, 0.0011327510001137853, 0.0011203709291294217, 0.0011083879508078098, 0.0010967814596369863, 0.0010855321306735277, 0.0010746220359578729, 0.0010640342952683568, 0.0010537535417824984, 0.0010437651071697474, 0.0010340554872527719, 0.001024611876346171, 0.0010154224000871181, 0.0010064757661893964, 0.0009977614972740412, 0.0009892696980386972, 0.0009809911716729403, 0.0009729170706123114, 0.0009650390711612999, 0.0009573493734933436, 0.0009498406434431672, 0.0009425058378838003, 0.0009353383793495595, 0.0009283320396207273, 0.0009214807651005685, 0.0009147790260612965, 0.0009082213509827852, 0.0009018027340061963, 0.0008955183438956738, 0.0008893635240383446, 0.0008833338506519794, 0.0008774251909926534, 0.0008716335287317634, 0.00086595508037135, 0.0008603861788287759, 0.000854923389852047, 0.0008495632791891694, 0.0008443027618341148, 0.0008391388109885156, 0.0008340684580616653, 0.0008290888508781791, 0.0008241974283009768, 0.0008193915709853172, 0.0008146688342094421, 0.000810026831459254, 0.0008054632344283164, 0.0008009759476408362, 0.0007965628174133599, 0.0007922218646854162, 0.0007879511103965342, 0.0007837486336939037, 0.0007796127465553582, 0.0007755416445434093, 0.0007715336396358907], "accuracy_valid": [0.09789450771837349, 0.10257435993975904, 0.10990887377635541, 0.12452642601656627, 0.11269590079066265, 0.11373423381024096, 0.10824989410768072, 0.10535109186746988, 0.09210572759789157, 0.1061849938817771, 0.10956178228539157, 0.1168051110692771, 0.11584913874246988, 0.11865675592996988, 0.14654173333960843, 0.12643984139683734, 0.1303652108433735, 0.12398814006024096, 0.12304246282003012, 0.15075389448418675, 0.13005047533885541, 0.15462925922439757, 0.13516860410391568, 0.1566544498305723, 0.14262371752635541, 0.1464181923004518, 0.1423178063817771, 0.14931699454066266, 0.14558429028614459, 0.12833119587725905, 0.14489304875753012, 0.13477003717996988, 0.12844297110316266, 0.13680699359939757, 0.13102850856551204, 0.1626756047628012, 0.16583031344126506, 0.16077395519578314, 0.15636765813253012, 0.16913503623870482, 0.11431222938629518, 0.12863710702183734, 0.1358804358057229, 0.12068194653614459, 0.15675592996987953, 0.1475388860128012, 0.18469091208584337, 0.15501458960843373, 0.14645937264683734, 0.1279561605798193, 0.12418080525225904, 0.13574659967996988, 0.1499082266566265, 0.13302134318524095, 0.14213543627635541, 0.16208437264683734, 0.11453725056475904, 0.15856492375753012, 0.13687611775225905, 0.15134218514683734, 0.13062994164156627, 0.1456460608057229, 0.1365304969879518, 0.1583413733057229, 0.16137254094503012, 0.15281732398343373, 0.16145343091114459, 0.13394790097891568, 0.15934882106551204, 0.17706960655120482, 0.13260365681475905, 0.13517889919051204, 0.11730515813253012, 0.1200510048004518, 0.12960337443524095, 0.12800616528614459, 0.12786203407379518, 0.13481121752635541, 0.1339670204254518, 0.1416074454066265, 0.1510171545557229, 0.14200307087725905, 0.1254220985504518, 0.1113119470067771, 0.1279355704066265, 0.1440988563629518, 0.09939023672816265, 0.13746587914156627, 0.14792421639683734, 0.1359304405120482, 0.17166762754141568, 0.13260512754141568, 0.13327577889683734, 0.12419257106551204, 0.1256044686558735, 0.13359051440135541, 0.15343797063253012], "accuracy_test": 0.1715255591054313, "start": "2016-01-23 10:41:53.317000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0], "accuracy_train_last": 0.15075958465992986, "batch_size_eval": 1024, "accuracy_train_std": [0.009752763962946038, 0.01006237451089328, 0.012570932817796742, 0.00999328945428117, 0.00890449773196594, 0.010670996039424448, 0.009423251558946208, 0.010353660821845375, 0.008807098543969421, 0.009373620837176664, 0.009861540753604904, 0.00840437939944439, 0.008742332647568414, 0.010587183343749938, 0.00953825176545074, 0.010414370241259338, 0.010551373806044933, 0.011072951389108797, 0.009883956483031631, 0.009527735264667169, 0.009042031979005596, 0.010360348696835239, 0.008373560093845637, 0.008991707136002712, 0.009909313390279572, 0.013071790075536964, 0.010925824266469802, 0.012710724715403061, 0.013346250752172646, 0.008184380051211866, 0.009958928140453772, 0.011516760731917345, 0.009585810725214037, 0.010603319231518072, 0.00989012653572181, 0.011035566031225155, 0.010982981151549992, 0.011562848933016966, 0.010896738939038772, 0.012216415117541572, 0.010369566915104017, 0.010548507621314878, 0.012843300119087504, 0.009412015966441934, 0.010429456085183477, 0.009912557633597215, 0.009994206148150954, 0.01095859745137132, 0.0111239855065858, 0.012774228538167131, 0.009556512630367577, 0.009055425192858386, 0.009517044232862818, 0.008630942665680045, 0.010722359293795345, 0.011665420819022177, 0.009399860930411159, 0.011115468913153686, 0.008223695482914956, 0.012117986467946236, 0.00929824513805274, 0.01109242096981683, 0.009628860502848585, 0.010498456092696703, 0.011926755150432882, 0.01041442530236608, 0.010599369363720869, 0.00924787567402529, 0.011820688514317291, 0.012824302570560286, 0.010267552548715829, 0.011963642687395313, 0.012375444473735366, 0.0075276624927276955, 0.010340580587389708, 0.009733493870052195, 0.010247536519794029, 0.011574028334924094, 0.01108110974744194, 0.008628329095044117, 0.012496466882159857, 0.01169416131189993, 0.01229054605069431, 0.007827379762348546, 0.011499177441923357, 0.012627890815178714, 0.010306721269892403, 0.010920501504464919, 0.012709042648124193, 0.011145911629458223, 0.011086550265650474, 0.012020192869023028, 0.01083584935174204, 0.010311387141608182, 0.012524578894843805, 0.009597018824781882, 0.009518824050082348], "accuracy_test_std": 0.06485698620681639, "error_valid": [0.9021054922816265, 0.897425640060241, 0.8900911262236446, 0.8754735739834337, 0.8873040992093374, 0.886265766189759, 0.8917501058923193, 0.8946489081325302, 0.9078942724021084, 0.8938150061182228, 0.8904382177146084, 0.8831948889307228, 0.8841508612575302, 0.8813432440700302, 0.8534582666603916, 0.8735601586031627, 0.8696347891566265, 0.876011859939759, 0.8769575371799698, 0.8492461055158133, 0.8699495246611446, 0.8453707407756024, 0.8648313958960843, 0.8433455501694277, 0.8573762824736446, 0.8535818076995482, 0.8576821936182228, 0.8506830054593373, 0.8544157097138554, 0.871668804122741, 0.8551069512424698, 0.8652299628200302, 0.8715570288968373, 0.8631930064006024, 0.8689714914344879, 0.8373243952371988, 0.8341696865587349, 0.8392260448042168, 0.8436323418674698, 0.8308649637612951, 0.8856877706137049, 0.8713628929781627, 0.8641195641942772, 0.8793180534638554, 0.8432440700301205, 0.8524611139871988, 0.8153090879141567, 0.8449854103915663, 0.8535406273531627, 0.8720438394201807, 0.875819194747741, 0.8642534003200302, 0.8500917733433735, 0.866978656814759, 0.8578645637236446, 0.8379156273531627, 0.885462749435241, 0.8414350762424698, 0.863123882247741, 0.8486578148531627, 0.8693700583584337, 0.8543539391942772, 0.8634695030120482, 0.8416586266942772, 0.8386274590549698, 0.8471826760165663, 0.8385465690888554, 0.8660520990210843, 0.8406511789344879, 0.8229303934487951, 0.867396343185241, 0.8648211008094879, 0.8826948418674698, 0.8799489951995482, 0.870396625564759, 0.8719938347138554, 0.8721379659262049, 0.8651887824736446, 0.8660329795745482, 0.8583925545933735, 0.8489828454442772, 0.857996929122741, 0.8745779014495482, 0.8886880529932228, 0.8720644295933735, 0.8559011436370482, 0.9006097632718374, 0.8625341208584337, 0.8520757836031627, 0.8640695594879518, 0.8283323724585843, 0.8673948724585843, 0.8667242211031627, 0.8758074289344879, 0.8743955313441265, 0.8664094855986446, 0.8465620293674698], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.5648312398829487, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.007598725086514719, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 4.17353856695562e-08, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.09556036319455541}, "accuracy_valid_max": 0.18469091208584337, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.15343797063253012, "loss_train": [1.549401411853222e+18, 587067469856768.0, 237176616910848.0, 120782214660096.0, 80944505552896.0, 57336341200896.0, 41138778013696.0, 7.253847919223112e+17, 1800728255397888.0, 510972963848192.0, 263162007912448.0, 151681518010368.0, 90513172594688.0, 56152578588672.0, 35334029049856.0, 20474559987712.0, 13523179536384.0, 8502842490880.0, 3810041528320.0, 56586810687488.0, 774308757504.0, 339898957824.0, 173875347456.0, 102611582976.0, 70379610112.0, 239266068168704.0, 618446061568.0, 300472336384.0, 172484247552.0, 125533896704.0, 80053493760.0, 108059574272.0, 22068858880.0, 21106742263808.0, 100447870976.0, 40593584128.0, 21209550848.0, 12739726336.0, 13592609792.0, 3266895360.0, 34827596201984.0, 135988756480.0, 59542200320.0, 39030194176.0, 316154314752.0, 20776464384.0, 15022048256.0, 5170738688.0, 1789352320.0, 1060642112.0, 1049990660096.0, 5398546432.0, 2555112960.0, 1497587584.0, 864641280.0, 539504704.0, 379594208.0, 188920240.0, 99672960.0, 71793008.0, 83074293760.0, 367261984.0, 187413184.0, 108936920.0, 154459760.0, 32059454.0, 23334970.0, 14938645.0, 8750219.0, 6008008.0, 47058771968.0, 402232352.0, 209886752.0, 123265968.0, 79980520.0, 45702248.0, 32930700.0, 15347826.0, 206538407936.0, 1729756928.0, 644385856.0, 315697568.0, 222443680.0, 118178448.0, 101332520.0, 72760016.0, 210744352.0, 22336070.0, 4227317.0, 2506322.0, 1515712.75, 1165880.5, 3016129.0, 355692.84375, 2795539712.0, 18402256.0, 7647427.5], "accuracy_train_first": 0.09619266795865633, "model": "residualv2", "loss_std": [Infinity, 368473163169792.0, 103999462178816.0, 82790477463552.0, 101465372753920.0, 40522223714304.0, 38577073291264.0, Infinity, 1078462932582400.0, 178607959834624.0, 92239657172992.0, 41592446517248.0, 25092671143936.0, 15798799171584.0, 11076298080256.0, 6674531745792.0, 7501506936832.0, 5672046428160.0, 1775389769728.0, 279723099815936.0, 467889455104.0, 199459110912.0, 72389558272.0, 38566944768.0, 32601317376.0, 3337696126697472.0, 308752973824.0, 126611169280.0, 87538098176.0, 101736554496.0, 62416101376.0, 375522852864.0, 34950656000.0, 262694879887360.0, 210924765184.0, 30977435648.0, 10404148224.0, 9978669056.0, 35243069440.0, 2037563136.0, 315492560535552.0, 54547767296.0, 19374157824.0, 20805945344.0, 1089196982272.0, 10350398464.0, 14176978944.0, 4562204160.0, 569357824.0, 320556992.0, 9502037377024.0, 2208800000.0, 912886336.0, 476734496.0, 328497824.0, 416538560.0, 523648288.0, 207265344.0, 46000144.0, 48942456.0, 916962803712.0, 150439200.0, 77156576.0, 51884460.0, 293052864.0, 11960116.0, 17306300.0, 9742864.0, 6471166.5, 5509009.0, 443639496704.0, 139873120.0, 61703028.0, 40173328.0, 30408230.0, 27117390.0, 39380652.0, 9832601.0, 2711172153344.0, 776151680.0, 222487408.0, 98190832.0, 166097440.0, 49898028.0, 146323392.0, 184663808.0, 1177274880.0, 43569316.0, 1735690.625, 993693.625, 535457.25, 738847.4375, 10120744.0, 145318.265625, 18783535104.0, 8787133.0, 2290342.25]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:09 2016", "state": "available"}], "summary": "886b016571e3cdeae0f6c4b2be3545a6"}