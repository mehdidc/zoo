{"content": {"hp_model": {"f0": 64, "f1": 64, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4461039304733276, 1.0225838422775269, 0.8055369257926941, 0.6914827227592468, 0.618328869342804, 0.560018002986908, 0.5183981657028198, 0.4833148121833801, 0.44961851835250854, 0.42238110303878784, 0.3982895314693451, 0.37665945291519165, 0.3538055419921875, 0.33605340123176575, 0.31908056139945984, 0.30415308475494385, 0.289146363735199, 0.2751658260822296, 0.26068687438964844, 0.2502793073654175, 0.23830904066562653, 0.22812075912952423, 0.21715494990348816, 0.20922346413135529, 0.1991913765668869, 0.18978583812713623, 0.18088068068027496, 0.17549264430999756, 0.16607438027858734, 0.15886521339416504, 0.1535138487815857, 0.14716127514839172, 0.14266230165958405, 0.13630779087543488, 0.13076834380626678, 0.12712311744689941, 0.12216046452522278, 0.11713442206382751, 0.11390096694231033, 0.10839275270700455, 0.10491591691970825, 0.10027777403593063, 0.09970975667238235, 0.09438499808311462, 0.09182120114564896, 0.09036723524332047, 0.08605951070785522, 0.08367756754159927, 0.08077078312635422, 0.07699564099311829, 0.07405291497707367, 0.0729592815041542, 0.06969911605119705, 0.06758634001016617, 0.06839345395565033, 0.06488528847694397, 0.06005562096834183, 0.06147078424692154, 0.05903249979019165, 0.05543598532676697, 0.0542224682867527, 0.052819665521383286, 0.050962697714567184, 0.050770413130521774, 0.04983023181557655, 0.0465303510427475, 0.047016024589538574, 0.04507894068956375, 0.04425245150923729, 0.0413961187005043, 0.03966015949845314, 0.039568010717630386, 0.03975047916173935, 0.03899875655770302, 0.03859928995370865, 0.0380641408264637, 0.034899692982435226, 0.03518763557076454, 0.032666079699993134, 0.031033242121338844, 0.031464431434869766, 0.031064845621585846, 0.029916072264313698, 0.030279800295829773, 0.029128190129995346, 0.029823875054717064, 0.02884015068411827, 0.027269689366221428, 0.027037207037210464, 0.02604936808347702, 0.025327403098344803, 0.024913443252444267, 0.024981364607810974, 0.025199323892593384, 0.022980157285928726, 0.023772625252604485, 0.022543219849467278, 0.02272794395685196, 0.021157821640372276, 0.02136053517460823, 0.020594904199242592, 0.020177913829684258, 0.01947680301964283, 0.019631609320640564, 0.02002521976828575, 0.018794747069478035, 0.018915271386504173, 0.018342169001698494, 0.017909590154886246, 0.017703574150800705, 0.01742609404027462, 0.01661800406873226, 0.017256539314985275, 0.016522444784641266, 0.0167531780898571, 0.01548830233514309, 0.015345360152423382, 0.015060435980558395, 0.014656124636530876, 0.015016179531812668, 0.014187734574079514, 0.014437727630138397, 0.014156193472445011, 0.013740353286266327, 0.013539350591599941, 0.013217750936746597, 0.013930415734648705, 0.01340731792151928, 0.012726381421089172, 0.012657425366342068, 0.012904166243970394, 0.012903102673590183, 0.012737753801047802, 0.012125826440751553, 0.011597122065722942, 0.012226059101521969, 0.011779298074543476, 0.010546393692493439, 0.011244889348745346, 0.011512616649270058, 0.010880962014198303, 0.011104305274784565, 0.010855435393750668, 0.010736011900007725, 0.009529231116175652, 0.010047269985079765, 0.010253752581775188, 0.009495104663074017, 0.009316506795585155, 0.009402050636708736, 0.00988626480102539, 0.009940368123352528, 0.00939246080815792, 0.009233678691089153, 0.009339183568954468, 0.009192573837935925, 0.008548066020011902, 0.008674746379256248, 0.008913257159292698, 0.008731533773243427, 0.008763299323618412, 0.008750231005251408, 0.00835098884999752, 0.008591040037572384, 0.007922776974737644, 0.008063769899308681, 0.007642399985343218, 0.007577093783766031, 0.007696793880313635, 0.00793407205492258, 0.007582706864923239, 0.007916908711194992, 0.0076980143785476685, 0.007117059081792831, 0.007509121671319008, 0.007044580299407244, 0.006799865048378706, 0.007155203726142645, 0.00783685315400362, 0.007307283580303192, 0.006930917501449585, 0.006695868447422981, 0.0069365776143968105, 0.006818418391048908, 0.00670283567160368, 0.006350725889205933, 0.006513859145343304, 0.006460173986852169, 0.006091983988881111, 0.0064641572535037994, 0.006253319792449474, 0.006276002153754234, 0.006263448856770992, 0.006526798475533724, 0.005739831365644932, 0.005728146061301231, 0.005958959925919771, 0.006071827840059996, 0.005736819468438625, 0.005865574348717928, 0.006202836986631155, 0.006123935338109732, 0.005633615888655186, 0.00539808114990592, 0.0051064700819551945, 0.005479448474943638, 0.005653023719787598, 0.005954761989414692, 0.005854420829564333, 0.005571955349296331, 0.005413917824625969, 0.0051798028871417046, 0.005535540636628866, 0.005182306282222271, 0.004996206611394882, 0.005271036643534899, 0.005151725839823484, 0.004936067387461662], "moving_avg_accuracy_train": [0.058231333200673675, 0.12261127369128366, 0.18760366612881824, 0.24882146114153625, 0.30749773718500534, 0.3617503390836606, 0.41197451844587407, 0.45783655003613344, 0.5001353718459198, 0.539297095366385, 0.57470050431212, 0.6075586279073015, 0.637700492454842, 0.6648026299595424, 0.6898780032684977, 0.7134477620905497, 0.7344211628494718, 0.7537086667253312, 0.7717765185028719, 0.788488700020525, 0.8039807062066415, 0.8180560092074705, 0.8304168983141782, 0.841548637907825, 0.8521576831932698, 0.8621266758846939, 0.8715405115319665, 0.879606098621664, 0.886925616920258, 0.894133926023498, 0.900874845436652, 0.9066766780418424, 0.9119400358698102, 0.9173468089185803, 0.9216501465529312, 0.9258928490845613, 0.9297787106785046, 0.933550389721396, 0.9369495151087986, 0.9400807715217375, 0.9423851165041153, 0.9447588990870462, 0.9478811304581035, 0.9502820206480351, 0.9526775537022792, 0.9540035634725552, 0.9561966781074426, 0.9580124072086122, 0.9594094342699124, 0.9612550933715296, 0.9631276309093767, 0.9645548231755819, 0.9655742652996996, 0.9668986642530722, 0.9680604324254025, 0.9694733612435857, 0.9703473967335221, 0.971322401776855, 0.9720464104456072, 0.972937544623684, 0.973618621597039, 0.9745873386409158, 0.9751057974101761, 0.9755700851537007, 0.9763203683049972, 0.97725375070784, 0.9775334340073034, 0.9780432404946776, 0.9789391943095048, 0.979506098464287, 0.9802906076654774, 0.9808571570179773, 0.9812275425066558, 0.9818375821547998, 0.9823331394155103, 0.9827605397596735, 0.9833149359325157, 0.9837256089309493, 0.9842020993771401, 0.9845101051382541, 0.9851546117375238, 0.9855393551768667, 0.9859298020996563, 0.9861138296646998, 0.9864747309244203, 0.9869320755403116, 0.9871646852850993, 0.9874228621804081, 0.9876692083278619, 0.987888558662942, 0.9879604159287999, 0.9882110993728339, 0.9886691933045981, 0.9889048386312996, 0.989065694053884, 0.9892360405711147, 0.9894219045199556, 0.9895589551393885, 0.9897985581373545, 0.9900072253890952, 0.9902368785942334, 0.9904738294622002, 0.9907335521707421, 0.9909510265667631, 0.9912514212684294, 0.9915032113582716, 0.9916623570748346, 0.9917450983018751, 0.991840491745497, 0.9920333387388137, 0.992313821829218, 0.9922849496534483, 0.9923101179690651, 0.99233970885073, 0.9925407268049427, 0.9927821328816004, 0.9929505341767737, 0.9930974450448107, 0.9932157139331868, 0.9934105476363059, 0.9935672607298182, 0.9935548787413693, 0.9937018090219942, 0.9938178062817088, 0.993952394701157, 0.9941340141965268, 0.9942068269876068, 0.9942932848388645, 0.9944501519645204, 0.994516891566887, 0.9945839326554456, 0.9946861223137199, 0.9947617809156812, 0.9947880209788751, 0.9948488394167019, 0.9947291898500317, 0.9947424129781238, 0.9947566389422162, 0.9948019943932327, 0.9947870107277189, 0.9948642422811467, 0.9949384009768508, 0.9950539358791658, 0.9951161006614966, 0.9952324667858231, 0.9953139448096218, 0.9954244774119929, 0.9954844652731838, 0.9955826321756366, 0.9956802829830821, 0.995693799996697, 0.9957151938065512, 0.9957763009139913, 0.9957661931440207, 0.9957780585391516, 0.9956631433102364, 0.9957062039792128, 0.9957891724574912, 0.9957894032772183, 0.9958616906280678, 0.995884896565261, 0.9958965173623155, 0.9959557681558459, 0.9959858784307466, 0.996024603422205, 0.9961013085930889, 0.9961610426516463, 0.9962263929995768, 0.9962131286996192, 0.9962988470796573, 0.9962272922443383, 0.9962604770449136, 0.9963414605904223, 0.9963841188468563, 0.9964620388074088, 0.9964717129028584, 0.9964780944399536, 0.9965163899066726, 0.9965462415779194, 0.9964498751951367, 0.9964909925863373, 0.9964838204110369, 0.9964309706235323, 0.9964763757183404, 0.9964846521715155, 0.996526978211516, 0.996567396796326, 0.996608423820274, 0.9966755750763511, 0.996715048818716, 0.9967761518237491, 0.9967660403616122, 0.9968034430218795, 0.9968301660185103, 0.9968821185011923, 0.9969288396867874, 0.9969197354800134, 0.9969766458605835, 0.9970092640126205, 0.9970339700518346, 0.9970678312311749, 0.9970866805485337, 0.9970990306853562, 0.9971310360989635, 0.9971784421616862, 0.9971955309812318, 0.9972481132997753, 0.9972163823269407, 0.9971552723680561, 0.9971467763812506, 0.9971344796955065, 0.9971489893152415, 0.9971666982706221, 0.9972198387114171, 0.9972188369831324, 0.9972156102788667, 0.9972754852628848, 0.9972852309699388], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.058022519766566256, 0.12218567629894575, 0.1855001000094126, 0.24454106915945026, 0.30061895348974016, 0.35165969132977215, 0.3986076270348973, 0.44136228695941965, 0.4804019748203301, 0.5163485055009477, 0.5483352016846631, 0.5780031640086667, 0.6049861213276795, 0.6287529400589928, 0.6510678698388616, 0.6714147137849452, 0.6896821632460591, 0.7059935908879441, 0.7209639030623274, 0.7350841566755224, 0.7477466453283769, 0.759283192438988, 0.769571517114517, 0.7786824659301738, 0.787043070287834, 0.7948535234717765, 0.8021982551325054, 0.8081950735386826, 0.8136888368455824, 0.8190116417905422, 0.8242111753242138, 0.8286567628934491, 0.8324126215721012, 0.8364642811016381, 0.8395430741887634, 0.8426954944619052, 0.8454360459663924, 0.8485221594608676, 0.8506709259601875, 0.8531470727278735, 0.8548811465168331, 0.856727722188945, 0.859087500092415, 0.8610261357194686, 0.862990634346317, 0.8643883541383419, 0.8661244351872337, 0.8674580630634652, 0.8685464058535042, 0.869710049341949, 0.8707482099762782, 0.8715950463111053, 0.8725392749725399, 0.873047283892831, 0.874154553103322, 0.874879452179285, 0.8754453826202421, 0.8762660728503112, 0.8762518290818463, 0.8766805218325472, 0.8770897298620184, 0.8777561333818407, 0.878159554541021, 0.8785836687405334, 0.8792074531277752, 0.8799927036734314, 0.8802192369111335, 0.880543128120246, 0.8810971549166552, 0.8815926905074445, 0.8824425340790645, 0.8826295447901339, 0.8825659208363464, 0.8828057460625762, 0.8832413153286831, 0.8835081688297003, 0.8835693495465043, 0.8837800150718991, 0.8841761040673447, 0.8844969925781554, 0.884956690675385, 0.8850408291191416, 0.8853830493887034, 0.8854499955322879, 0.8857086480874927, 0.8861611619496772, 0.886248982595824, 0.8860818215350367, 0.8862040493024668, 0.8864340655883345, 0.8867418250215944, 0.8868284964821609, 0.8872035875813092, 0.8873560050844735, 0.8873141934032099, 0.887519674006413, 0.8875103235579553, 0.8872933591144339, 0.8875619583027645, 0.887557497929943, 0.8878586593756534, 0.8876159798556333, 0.8873874202736846, 0.8876232287922499, 0.8875607247195009, 0.8880711420348248, 0.8883372641359357, 0.888633691148547, 0.888619713741147, 0.888756706975466, 0.8893316610426032, 0.889237738631867, 0.8891989480612253, 0.8893044909433558, 0.8896314131310232, 0.8899337320965354, 0.8902068486741559, 0.8901607143526741, 0.8903531860744097, 0.8905609727004025, 0.8905292836099555, 0.8907347560396226, 0.890770108325344, 0.890799866365174, 0.8907513473962019, 0.890969175523675, 0.891067564588401, 0.8910675770019254, 0.891303639802486, 0.8914794752292404, 0.8914749176724309, 0.8917048084823715, 0.8916309484925682, 0.8916987518454951, 0.8914545990818793, 0.8914291445859654, 0.8913452003833929, 0.8913581883458066, 0.8914309126682289, 0.8916896180410898, 0.8919590739704146, 0.8921904067842166, 0.8921554952002979, 0.8922573226098616, 0.8923967658948091, 0.8922272370839427, 0.8921967314666629, 0.8920126440221804, 0.892106401504375, 0.8922141677921905, 0.8919153849079263, 0.8918916504457481, 0.8918713189384475, 0.8921470188405365, 0.8921255645562569, 0.892290390677815, 0.8919616304598076, 0.8921041698799412, 0.8922233368527904, 0.8923051435571951, 0.8922556697699997, 0.8923332136740239, 0.8925271325174648, 0.8924676668654925, 0.892695939006127, 0.8929268275038575, 0.8930878580441345, 0.8935766414227029, 0.8937794653263663, 0.8939539178430519, 0.8939481156671804, 0.8940548160074653, 0.8940653970949718, 0.8942346409886373, 0.8942862157169572, 0.8944323482397645, 0.8946015181127007, 0.8946327301945028, 0.8945478692608959, 0.89469019147449, 0.8947318027393151, 0.8945648218723866, 0.8947817795383106, 0.8947695219063921, 0.894595680596777, 0.8942795025032138, 0.8942177573074858, 0.8944317708274901, 0.8943659763219249, 0.8941968979856662, 0.8941332652277622, 0.8940892322855581, 0.894219471566415, 0.8942837407595475, 0.8943914406670265, 0.8944639565212575, 0.8944214165261348, 0.8943709234992744, 0.8943244502664403, 0.8942470327717992, 0.8942882498165319, 0.8942765170317913, 0.8944724475481152, 0.8945643653027163, 0.8946094406794477, 0.8947232507060059, 0.8948246502212487, 0.8948670816599672, 0.8944494917639253, 0.8944572263695357, 0.8943431467107448, 0.8943584272956944, 0.8944230669644684, 0.8945422778226149, 0.8944410185550371, 0.894584907333946, 0.8948354480388044, 0.8948890067270173], "moving_var_accuracy_train": [0.03051799349695093, 0.06476918478542619, 0.0963083659796741, 0.12040609521767917, 0.13935163402887574, 0.15190657394095392, 0.15941813028032864, 0.16240625072656933, 0.162268338592377, 0.15984427003497953, 0.15514045531629217, 0.14934331636042897, 0.14258577271000655, 0.13493792815491906, 0.12710310445867837, 0.11939259579117784, 0.11141228806660926, 0.10361912951179995, 0.09619524197131658, 0.08908939087389577, 0.08234047208754226, 0.07588945226987436, 0.06967563125846186, 0.06382330877004254, 0.05845394446985587, 0.05350297736040532, 0.04895026233870953, 0.044640719360752014, 0.04065882555778789, 0.03706058048315977, 0.03376348238565554, 0.030690085501297846, 0.02787040337179514, 0.025346461787823793, 0.0229784840421984, 0.020842640360925667, 0.018894275607778652, 0.01713287811222407, 0.015523576781595234, 0.014059462003947849, 0.01270130585573335, 0.011481888863919256, 0.01042143493613706, 0.009431169905860343, 0.008539700122800094, 0.00770155482771789, 0.006974687111161915, 0.0063068902495652356, 0.005693766386098755, 0.005155047865163318, 0.004671100650122802, 0.004222322484992965, 0.003809443596693499, 0.003444285530313399, 0.003112004324858216, 0.0028187712029796694, 0.0025437695250207174, 0.002297948286029367, 0.0020728711543982867, 0.0018727311200684871, 0.0016896328006543496, 0.0015291152349887905, 0.0013786229069487168, 0.00124270068423293, 0.001123496939073713, 0.0010189880695557717, 0.0009177932673321827, 0.0008283530644900832, 0.0007527423571858053, 0.0006803605443536094, 0.0006178635820990192, 0.0005589660274084796, 0.0005043040933596438, 0.00045722301937444767, 0.00041371091042478897, 0.000373983858870028, 0.0003393516690311836, 0.00030693437293284685, 0.00027828432394736194, 0.0002513096994925403, 0.0002299172283518075, 0.000208257753143683, 0.00018880401702495687, 0.00017022841062472408, 0.00015437781703566225, 0.00014082251221125895, 0.0001272272266304644, 0.0001151044017508597, 0.00010414013939506186, 9.415915658105379e-05, 8.478971212285755e-05, 7.687632061258656e-05, 7.107733900420077e-05, 6.446936358374702e-05, 5.8255297428145356e-05, 5.269092910872431e-05, 4.773274486516052e-05, 4.312851622922722e-05, 3.933235097601277e-05, 3.5790994075952774e-05, 3.268656002002928e-05, 2.992321544249853e-05, 2.753799686623968e-05, 2.5209853195938083e-05, 2.350100066744669e-05, 2.1721484844786634e-05, 1.9777282592211195e-05, 1.7861169328859355e-05, 1.6156951577748028e-05, 1.4875966085454721e-05, 1.4096406352934171e-05, 1.2694268140443848e-05, 1.1430542323398338e-05, 1.0295368673557873e-05, 9.629505767444868e-06, 9.191047235326298e-06, 8.527173477738056e-06, 7.868701358290494e-06, 7.20771899208085e-06, 6.828588639712763e-06, 6.366760718845163e-06, 5.7314644697021554e-06, 5.35261458901276e-06, 4.938451408463097e-06, 4.607632651462779e-06, 4.443740156201629e-06, 4.0470814634853016e-06, 3.7096479575337915e-06, 3.5601488177840844e-06, 3.2442215067222846e-06, 2.9602499240461763e-06, 2.7582094679653104e-06, 2.5339065376254905e-06, 2.2867127521106633e-06, 2.0913314183168073e-06, 2.011042445724398e-06, 1.8115118612008096e-06, 1.632182077569949e-06, 1.4874779222451215e-06, 1.3407507221106593e-06, 1.260358065503458e-06, 1.1838178682898873e-06, 1.1855709043371505e-06, 1.1017939553634902e-06, 1.1134842338441337e-06, 1.0618838257189087e-06, 1.065652548829489e-06, 9.914741853588593e-07, 9.790574334574911e-07, 9.669728118646957e-07, 8.719199175918437e-07, 7.888471817333232e-07, 7.435691707772729e-07, 6.701317568235449e-07, 6.043856695557185e-07, 6.627966911297547e-07, 6.132050129310002e-07, 6.138384271284372e-07, 5.524550639153112e-07, 5.442387073594616e-07, 4.946614763126557e-07, 4.4641071499903924e-07, 4.333655523049257e-07, 3.9818865496586763e-07, 3.7186641414034666e-07, 3.8763292188937485e-07, 3.8098304946617873e-07, 3.813207562914241e-07, 3.4477215554258884e-07, 3.764237060755007e-07, 3.848621855857071e-07, 3.5628704593020173e-07, 3.7968335312552764e-07, 3.580925593908407e-07, 3.769269857242309e-07, 3.400765802567189e-07, 3.064354383723131e-07, 2.8899077947606625e-07, 2.6811180201446807e-07, 3.248789393886386e-07, 3.0760680418207713e-07, 2.773090846507256e-07, 2.747160765391552e-07, 2.6579907259602647e-07, 2.398356624308748e-07, 2.3197553914693304e-07, 2.2348094321463666e-07, 2.1628179913948554e-07, 2.3523723996009244e-07, 2.2573710299069215e-07, 2.367655877083762e-07, 2.1400920393643652e-07, 2.0519891449846734e-07, 1.9110608998899019e-07, 1.9628702510151438e-07, 1.9630414524203366e-07, 1.7741970994667942e-07, 1.888268617016985e-07, 1.7951967011223547e-07, 1.670611984638679e-07, 1.6067429381435887e-07, 1.4780453531692082e-07, 1.3439681470104433e-07, 1.3017625173247312e-07, 1.3738463960504265e-07, 1.262744254257203e-07, 1.3853108489382405e-07, 1.3373966813775193e-07, 1.539755449978112e-07, 1.392276266242411e-07, 1.2666574028442095e-07, 1.1589392783968334e-07, 1.071269989617689e-07, 1.2182945709650523e-07, 1.0965554252285952e-07, 9.87836928543336e-08, 1.211704469694054e-07, 1.099082115263222e-07], "duration": 279337.65182, "accuracy_train": [0.5823133320067369, 0.7020307381067736, 0.7725351980666297, 0.7997816162559985, 0.8355842215762275, 0.8500237561715578, 0.8639921327057956, 0.8705948343484681, 0.8808247681339978, 0.8917526070505721, 0.8933311848237356, 0.903281740263935, 0.9089772733827058, 0.9087218675018457, 0.9155563630490956, 0.925575591489018, 0.9231817696797711, 0.9272962016080657, 0.9343871845007383, 0.9388983336794019, 0.9434087618816908, 0.9447337362149317, 0.9416649002745479, 0.941734294250646, 0.9476390907622739, 0.9518476101075121, 0.9562650323574198, 0.9521963824289406, 0.9528012816076044, 0.9590087079526578, 0.9615431201550388, 0.9588931714885567, 0.9593102563215209, 0.9660077663575121, 0.9603801852620893, 0.9640771718692323, 0.9647514650239941, 0.9674955011074198, 0.9675416435954227, 0.9682620792381875, 0.963124221345515, 0.9661229423334257, 0.9759812127976191, 0.9718900323574198, 0.9742373511904762, 0.9659376514050388, 0.9759347098214286, 0.97435396911914, 0.9719826778216132, 0.9778660252860835, 0.97998046875, 0.9773995535714286, 0.9747492444167589, 0.9788182548334257, 0.978516345976375, 0.9821897206072352, 0.9782137161429494, 0.9800974471668512, 0.978562488464378, 0.980957752226375, 0.9797483143572352, 0.9833057920358066, 0.979771926333518, 0.9797486748454227, 0.9830729166666666, 0.9856541923334257, 0.9800505837024732, 0.9826314988810447, 0.9870027786429494, 0.9846082358573275, 0.9873511904761905, 0.9859561011904762, 0.9845610119047619, 0.9873279389880952, 0.9867931547619048, 0.9866071428571429, 0.9883045014880952, 0.9874216659168512, 0.9884905133928571, 0.9872821569882798, 0.9909551711309523, 0.9890020461309523, 0.9894438244047619, 0.9877700777500923, 0.9897228422619048, 0.9910481770833334, 0.9892581729881875, 0.9897464542381875, 0.9898863236549464, 0.9898627116786637, 0.9886071313215209, 0.99046725036914, 0.9927920386904762, 0.9910256465716132, 0.9905133928571429, 0.9907691592261905, 0.9910946800595238, 0.9907924107142857, 0.9919549851190477, 0.9918852306547619, 0.9923037574404762, 0.9926063872739018, 0.9930710565476191, 0.9929082961309523, 0.9939549735834257, 0.9937693221668512, 0.9930946685239018, 0.9924897693452381, 0.9926990327380952, 0.9937689616786637, 0.9948381696428571, 0.9920251000715209, 0.9925366328096161, 0.9926060267857143, 0.9943498883928571, 0.9949547875715209, 0.9944661458333334, 0.9944196428571429, 0.9942801339285714, 0.995164050964378, 0.9949776785714286, 0.9934434408453304, 0.9950241815476191, 0.99486178161914, 0.9951636904761905, 0.9957685896548542, 0.9948621421073275, 0.9950714055001846, 0.9958619560954227, 0.9951175479881875, 0.9951873024524732, 0.9956058292381875, 0.9954427083333334, 0.9950241815476191, 0.9953962053571429, 0.99365234375, 0.9948614211309523, 0.9948846726190477, 0.9952101934523809, 0.9946521577380952, 0.9955593262619971, 0.9956058292381875, 0.99609375, 0.9956755837024732, 0.9962797619047619, 0.9960472470238095, 0.9964192708333334, 0.9960243560239018, 0.9964661342977114, 0.9965591402500923, 0.9958154531192323, 0.9959077380952381, 0.9963262648809523, 0.9956752232142857, 0.9958848470953304, 0.99462890625, 0.99609375, 0.9965358887619971, 0.9957914806547619, 0.9965122767857143, 0.99609375, 0.9960011045358066, 0.9964890252976191, 0.9962568709048542, 0.9963731283453304, 0.9967916551310447, 0.9966986491786637, 0.9968145461309523, 0.99609375, 0.9970703125, 0.9955832987264673, 0.9965591402500923, 0.9970703125, 0.9967680431547619, 0.9971633184523809, 0.9965587797619048, 0.9965355282738095, 0.9968610491071429, 0.99681490661914, 0.9955825777500923, 0.9968610491071429, 0.9964192708333334, 0.9959553225359912, 0.9968850215716132, 0.9965591402500923, 0.9969079125715209, 0.9969311640596161, 0.9969776670358066, 0.9972799363810447, 0.9970703125, 0.9973260788690477, 0.9966750372023809, 0.9971400669642857, 0.9970706729881875, 0.9973496908453304, 0.9973493303571429, 0.9968377976190477, 0.9974888392857143, 0.9973028273809523, 0.9972563244047619, 0.9973725818452381, 0.9972563244047619, 0.9972101819167589, 0.9974190848214286, 0.9976050967261905, 0.9973493303571429, 0.9977213541666666, 0.9969308035714286, 0.9966052827380952, 0.9970703125, 0.9970238095238095, 0.9972795758928571, 0.9973260788690477, 0.9976981026785714, 0.9972098214285714, 0.9971865699404762, 0.9978143601190477, 0.9973729423334257], "end": "2016-02-03 21:14:50.154000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0], "moving_var_accuracy_valid": [0.030299515200554156, 0.06432175958628646, 0.09396802987575456, 0.1159437512317604, 0.13265193810723672, 0.1428331565698069, 0.14838681891557937, 0.1499997855313754, 0.14871668203273375, 0.1454743914412136, 0.1401352908918361, 0.13404345369877896, 0.1271918282000181, 0.11955640043348026, 0.11208236520985651, 0.10460007521596741, 0.09714336508269983, 0.0898235926198779, 0.08285822557727653, 0.07636683707845739, 0.07017320094056465, 0.06435370811962632, 0.05887098392932556, 0.05373097003128666, 0.048986970375185956, 0.04463730194811438, 0.04065907750181598, 0.03691682623060437, 0.03349677652499408, 0.030402089144833475, 0.027605196571060118, 0.025022546153475756, 0.022647249807854236, 0.020530268331558393, 0.018562552200262532, 0.016795736762442916, 0.015183758689137348, 0.013751099688730652, 0.012417544497074981, 0.011230971772703583, 0.010134937702583236, 0.009152132507740432, 0.008287036222749733, 0.007492157373325097, 0.006777674929686587, 0.006117490022271093, 0.005532866816718872, 0.0049955872048573395, 0.004506688894629274, 0.004068206600680146, 0.0036710859381361683, 0.0033104315303244002, 0.0029874124871776325, 0.002690993896027728, 0.0024329289123654675, 0.0021943653291619084, 0.001977811291621734, 0.0017860919545431395, 0.0016074845850532864, 0.0014483901238184895, 0.0013050581723390937, 0.0011785491979662678, 0.001062159015854711, 0.000957561969957292, 0.000865307735617463, 0.0007843265278307972, 0.0007063557308177714, 0.0006366643073740578, 0.0005757603878569062, 0.0005203943487668657, 0.0004748550207561939, 0.0004276842757350669, 0.00038495228022902015, 0.0003469746974583438, 0.00031398471298270104, 0.00028322713880347733, 0.0002549381126441075, 0.00022984372105200538, 0.000208271327377623, 0.00018837091956719356, 0.00017143572867584324, 0.0001543558693077191, 0.0001399743147930374, 0.00012601721938900118, 0.00011401760774892751, 0.00010445876613325659, 9.408230171293762e-05, 8.492555692383541e-05, 7.65674578756303e-05, 6.938687951394699e-05, 6.330063438139653e-05, 5.7038178421947395e-05, 5.260060057369567e-05, 4.7549620373763545e-05, 4.281039228659801e-05, 3.890935356257262e-05, 3.501920508429258e-05, 3.194094670363642e-05, 2.9396161749020032e-05, 2.6456724628449403e-05, 2.4627336113046524e-05, 2.2694642646676827e-05, 2.0895333724514958e-05, 1.930625126891499e-05, 1.74107869740155e-05, 1.8014440798657074e-05, 1.6850385473088436e-05, 1.595616769003024e-05, 1.4362309232285814e-05, 1.3094982625299922e-05, 1.4760633976627593e-05, 1.3363963352111369e-05, 1.2041109392236477e-05, 1.0937252152728509e-05, 1.0805429988559016e-05, 1.0547457801878081e-05, 1.0164046006430778e-05, 9.166796786355028e-06, 8.58352538073035e-06, 8.1137503801304e-06, 7.311413128197509e-06, 6.9602420895574675e-06, 6.275465937553315e-06, 5.6558892122087315e-06, 5.111487104139007e-06, 5.027380231791377e-06, 4.611765881130913e-06, 4.150589294404683e-06, 4.237061177240299e-06, 4.0916179352334485e-06, 3.682643083626757e-06, 3.7900268357205385e-06, 3.4601218349923503e-06, 3.1554853035062964e-06, 3.37643192098667e-06, 3.0446201111480493e-06, 2.8035777623429596e-06, 2.524738170617607e-06, 2.3198637972019673e-06, 2.6902336470053302e-06, 3.074668762939145e-06, 3.248835723318805e-06, 2.9349215192122977e-06, 2.734748759336925e-06, 2.636273750855965e-06, 2.631306535194504e-06, 2.376551215845653e-06, 2.4438897792061787e-06, 2.2786149904928144e-06, 2.1552756465493596e-06, 2.743188989257738e-06, 2.4739400125859473e-06, 2.2302663430294272e-06, 2.691333632833329e-06, 2.426342846375527e-06, 2.428217414868747e-06, 3.158145201880363e-06, 3.0251880583208044e-06, 2.8504761592512144e-06, 2.6256595752960907e-06, 2.3851225183416e-06, 2.200727779969162e-06, 2.319095662545656e-06, 2.119011570171606e-06, 2.376083944863067e-06, 2.6182610358357354e-06, 2.5898124463689767e-06, 4.481013922215487e-06, 4.403150353069428e-06, 4.23673844296412e-06, 3.813367585871298e-06, 3.534495490836553e-06, 3.1820535764682772e-06, 3.1216396787088963e-06, 2.833415284249548e-06, 2.7422661838228224e-06, 2.7256055786237935e-06, 2.461812767215269e-06, 2.2804438929674702e-06, 2.234700016011743e-06, 2.0268134906536657e-06, 2.0750756308700152e-06, 2.2912037270116787e-06, 2.0634356001727354e-06, 2.12907924851375e-06, 2.815888605305919e-06, 2.568611967534732e-06, 2.7239668514834934e-06, 2.4905304189983737e-06, 2.498764731226822e-06, 2.285330409010318e-06, 2.0742474681014955e-06, 2.019483153794295e-06, 1.854709601088102e-06, 1.773632071618114e-06, 1.6435958064900743e-06, 1.49552308650645e-06, 1.368916689709591e-06, 1.2514628730690723e-06, 1.1802578020505742e-06, 1.0775216248340193e-06, 9.710083864905274e-07, 1.2194064528839772e-06, 1.173505670093806e-06, 1.0744412093717125e-06, 1.0835715877412487e-06, 1.0677511841903665e-06, 9.771799086968291e-07, 2.4488938093137345e-06, 2.20454284549791e-06, 2.101216077896794e-06, 1.8931959365947374e-06, 1.741480923948096e-06, 1.6952338898535916e-06, 1.6179914543016883e-06, 1.6425281351346764e-06, 2.043211124739772e-06, 1.864706810013605e-06], "accuracy_test": 0.8832788584183673, "start": "2016-01-31 15:39:12.502000", "learning_rate_per_epoch": [0.008218872360885143, 0.005811620038002729, 0.004745168145745993, 0.004109436180442572, 0.0036755914334207773, 0.0033553405664861202, 0.003106441581621766, 0.0029058100190013647, 0.0027396241202950478, 0.0025990356225520372, 0.0024780831299722195, 0.0023725840728729963, 0.0022795049007982016, 0.0021965859923511744, 0.002122103702276945, 0.002054718090221286, 0.001993369311094284, 0.0019372067181393504, 0.0018855385715141892, 0.0018377957167103887, 0.0017935049254447222, 0.0017522694543004036, 0.0017137533286586404, 0.0016776702832430601, 0.0016437744488939643, 0.0016118534840643406, 0.0015817226376384497, 0.001553220790810883, 0.0015262062661349773, 0.0015005539171397686, 0.0014761530328541994, 0.0014529050095006824, 0.001430721953511238, 0.001409524935297668, 0.0013892429415136576, 0.0013698120601475239, 0.001351174316368997, 0.0013332770904526114, 0.0013160728849470615, 0.0012995178112760186, 0.0012835721718147397, 0.001268199528567493, 0.0012533662375062704, 0.0012390415649861097, 0.0012251971056684852, 0.0012118065496906638, 0.0011988456826657057, 0.0011862920364364982, 0.0011741245398297906, 0.0011623241007328033, 0.0011508723255246878, 0.0011397524503991008, 0.0011289488757029176, 0.0011184468166902661, 0.0011082325363531709, 0.0010982929961755872, 0.0010886162053793669, 0.001079190755262971, 0.001070006052032113, 0.0010610518511384726, 0.0010523187229409814, 0.0010437978198751807, 0.0010354805272072554, 0.001027359045110643, 0.001019425573758781, 0.0010116732446476817, 0.0010040950728580356, 0.000996684655547142, 0.000989435939118266, 0.0009823431028053164, 0.0009754006750881672, 0.0009686033590696752, 0.0009619462070986629, 0.0009554245043545961, 0.000949033594224602, 0.0009427692857570946, 0.0009366273880004883, 0.0009306040010415018, 0.0009246953413821757, 0.0009188978583551943, 0.000913208001293242, 0.0009076225687749684, 0.0009021384175866842, 0.0008967524627223611, 0.0008914618520066142, 0.0008862637914717197, 0.0008811556035652757, 0.0008761347271502018, 0.0008711987175047398, 0.0008663451881147921, 0.0008615719270892441, 0.0008568766643293202, 0.0008522573625668883, 0.0008477119263261557, 0.000843238492961973, 0.0008388351416215301, 0.0008345000096596777, 0.0008302314672619104, 0.0008260277099907398, 0.0008218872244469821, 0.0008178083226084709, 0.0008137896074913442, 0.0008098295656964183, 0.0008059267420321703, 0.0008020797977223992, 0.000798287452198565, 0.0007945483666844666, 0.0007908613188192248, 0.0007872252026572824, 0.0007836387376300991, 0.0007801008177921176, 0.0007766103954054415, 0.0007731664809398353, 0.0007697679102420807, 0.000766413810197264, 0.0007631031330674887, 0.0007598350057378411, 0.0007566084968857467, 0.0007534227916039526, 0.0007502769585698843, 0.0007471701828762889, 0.0007441017078235745, 0.0007410707767121494, 0.0007380765164270997, 0.0007351182866841555, 0.0007321953307837248, 0.0007293069502338767, 0.0007264525047503412, 0.0007236313540488482, 0.0007208427996374667, 0.0007180862012319267, 0.000715360976755619, 0.0007126666023395956, 0.0007100024376995862, 0.0007073679007589817, 0.000704762467648834, 0.0007021856145001948, 0.0006996368756517768, 0.00069711561081931, 0.0006946214707568288, 0.0006921538733877242, 0.0006897124112583697, 0.000687296618707478, 0.0006849060300737619, 0.0006825401796959341, 0.0006801987183280289, 0.0006778811803087592, 0.0006755871581844985, 0.0006733162445016205, 0.0006710680900141597, 0.0006688423454761505, 0.0006666385452263057, 0.0006644564564339817, 0.000662295613437891, 0.0006601557251997292, 0.0006580364424735308, 0.0006559374160133302, 0.000653858354780823, 0.0006517989677377045, 0.0006497589056380093, 0.0006477378774434328, 0.0006457355921156704, 0.0006437517586164176, 0.0006417860859073699, 0.0006398383411578834, 0.0006379081751219928, 0.0006359954131767154, 0.0006340997642837465, 0.0006322209374047816, 0.000630358699709177, 0.00062851287657395, 0.0006266831187531352, 0.0006248693098314106, 0.0006230711005628109, 0.0006212883163243532, 0.0006195207824930549, 0.0006177682662382722, 0.0006160305347293615, 0.0006143073551356792, 0.0006125985528342426, 0.0006109039532020688, 0.0006092233234085143, 0.0006075564888305962, 0.0006059032748453319, 0.0006042635068297386, 0.0006026369519531727, 0.0006010234355926514, 0.0005994228413328528, 0.0005978349945507944, 0.0005962596624158323, 0.0005946967285126448, 0.0005931460182182491, 0.0005916073569096625, 0.0005900806281715631, 0.0005885656573809683, 0.0005870622699148953, 0.0005855704075656831, 0.0005840898375026882, 0.0005826203851029277, 0.0005811620503664017, 0.0005797145422548056, 0.0005782778025604784, 0.0005768517148680985, 0.0005754361627623439, 0.000574030913412571, 0.0005726359668187797, 0.0005712510901503265, 0.0005698762251995504, 0.0005685112555511296, 0.0005671560647897422, 0.0005658104782924056, 0.0005644744378514588, 0.00056314782705158, 0.0005618305294774473, 0.0005605224287137389, 0.0005592234083451331, 0.0005579334101639688, 0.0005566522595472634], "accuracy_train_first": 0.5823133320067369, "accuracy_train_last": 0.9973729423334257, "batch_size_eval": 1024, "accuracy_train_std": [0.017863627164240385, 0.01856283840540697, 0.01975883635510353, 0.01941590458593426, 0.018884826372892235, 0.016868179195589587, 0.017377922533734252, 0.01752548420745209, 0.01719515500016721, 0.017359674308619268, 0.018101053379894476, 0.017131691824350592, 0.017220341394545237, 0.015310655768846184, 0.015265972607677914, 0.015263713438686537, 0.014780071810195488, 0.015167299332656694, 0.015080126558686752, 0.013981226649768771, 0.013743374513449437, 0.013955732066617283, 0.013554267882116494, 0.013542765178692783, 0.013403142806082017, 0.012361929804328558, 0.012443014325775761, 0.012432340233401198, 0.012118149587662295, 0.01093733902862813, 0.011226942137027305, 0.01151014981036937, 0.011274926099333256, 0.009443877959215996, 0.01072373390490772, 0.010456306517770311, 0.010096706344444503, 0.009392412450491487, 0.009811361927099116, 0.00983218339859002, 0.010059491889191637, 0.010208954583625661, 0.007996517705876602, 0.00925368657741791, 0.008705873827259347, 0.009813282931560722, 0.008613758468488875, 0.008238137315237941, 0.008928127868116734, 0.007241058475014995, 0.00753208261774261, 0.007533051547438377, 0.007665627371827948, 0.008367649877210332, 0.007206420664094005, 0.0059633225803729754, 0.007497494866229926, 0.006604352043640357, 0.00746550190939906, 0.006309916316713806, 0.007493093290240636, 0.0059288864023760175, 0.006420761689021075, 0.0068643747232836365, 0.006127109037202605, 0.005448471001387519, 0.00682406457489482, 0.005850767841824238, 0.0047635335939243675, 0.005875530738120016, 0.005318850959238362, 0.005486957083305037, 0.005918131796850087, 0.005295472176955867, 0.005967801419267082, 0.004962545227661495, 0.0045230569428595215, 0.004477597399342536, 0.005031839061669954, 0.004820888837618072, 0.003540721460356985, 0.004398712068632623, 0.004496623792274395, 0.004487339336380633, 0.004516777366662231, 0.0038235090902213544, 0.004077685983192272, 0.003438711904075615, 0.003423073745144677, 0.00391253699978929, 0.00447931327769765, 0.003969276125829865, 0.002983085275291969, 0.0038500391409682045, 0.003661943289175973, 0.004033245241795891, 0.0036738086989692954, 0.0043367609494175076, 0.0035004109498807316, 0.0038328299136833883, 0.0035287915657975883, 0.0033507375478948566, 0.003448125913674968, 0.0036667382935727418, 0.003275858846172492, 0.002867224422011315, 0.0030842741381449635, 0.003989578654413085, 0.0036492245753001204, 0.0030364089086994785, 0.002629783392038447, 0.0029064398123978975, 0.003145777571990037, 0.003728657233147525, 0.0028633336707273704, 0.002363103298292101, 0.0029579694742911554, 0.002789015754719838, 0.002941841639496784, 0.002494295711646213, 0.0025711562401002763, 0.0027486120355262105, 0.0024925768756059144, 0.0026711151164263837, 0.002429307642598396, 0.002311980079330572, 0.0028037405862988258, 0.002475903362406986, 0.0018432813626326557, 0.002584151268470672, 0.0024800547535973588, 0.0024695078841433784, 0.0027179388385793262, 0.002801394248852127, 0.0028771778828604946, 0.0031840958284342132, 0.002891142800471711, 0.0027932770494198673, 0.0025732580603156476, 0.002722708550651869, 0.0022273332986889587, 0.002134109898417113, 0.0022753217676199904, 0.0023555458944808467, 0.0021335695213828983, 0.0020765544607297347, 0.001853713860490583, 0.002037619524544925, 0.0019294698437872413, 0.002057985829228063, 0.002621215609026837, 0.002227293529543908, 0.0020749917705843663, 0.0022966068126610392, 0.0021371006185966343, 0.0028371579725308934, 0.0023634311308729653, 0.0021756020388681665, 0.0022400006239074294, 0.00203447199165061, 0.001964716348054093, 0.0022334429315254522, 0.0024396340648467703, 0.0021090262824173234, 0.0018493694011577804, 0.001885763670790139, 0.0018204309039824174, 0.0017056198786359101, 0.0023344308776062374, 0.0020216764433858034, 0.0021750174812212096, 0.0020357994861801825, 0.001857792443772152, 0.0018392206334230932, 0.0021816785910974516, 0.0021964965920051233, 0.0021648871091897973, 0.0018398084316590727, 0.0017711855611002407, 0.0018854213883120654, 0.0018149570077089408, 0.0020403097998958615, 0.0018879339077972738, 0.0015977564019176718, 0.0019445243753790796, 0.0016770963650219297, 0.00190115550728596, 0.0020084543643019374, 0.0017514457339442874, 0.0019179306759022768, 0.0018339219714202937, 0.0018462618611519083, 0.0017232788284679856, 0.0015516448462425136, 0.0017739742747095745, 0.0020136379366267644, 0.0022432565281235743, 0.001719981585649826, 0.0019156742860905861, 0.0017212384229279897, 0.0017891563061021797, 0.00189695666428303, 0.0019482924185923853, 0.0017289166150503445, 0.0020683371657836762, 0.0015845168375558797, 0.0014082034904879764, 0.0016169399786750101, 0.001760369534109719, 0.0017443265749173226, 0.0021305266348503175, 0.0017770283486128623, 0.0016652026850626747, 0.0014267019118901086, 0.001900942469863253, 0.0017339125918435787, 0.0015632195232488477, 0.0015587012861541176], "accuracy_test_std": 0.008032822158005814, "error_valid": [0.4197748023343373, 0.3003459149096386, 0.24467008659638556, 0.22409020849021077, 0.19468008753765065, 0.18897366810993976, 0.17886095161897586, 0.17384577371987953, 0.16824083443147586, 0.16013271837349397, 0.16378453266189763, 0.15498517507530118, 0.15216726280120485, 0.15734569135918675, 0.1480977621423193, 0.14546369070030118, 0.14591079160391573, 0.1472035603350903, 0.14430328736822284, 0.13783356080572284, 0.13829095679593373, 0.13688788356551207, 0.13783356080572284, 0.13931899472891573, 0.13771149049322284, 0.13485239787274095, 0.13169915992093373, 0.13783356080572284, 0.1368672933923193, 0.1330831137048193, 0.12899302287274095, 0.13133294898343373, 0.13378465032003017, 0.12707078313253017, 0.1327477880271084, 0.1289327230798193, 0.12989899049322284, 0.12370281908885539, 0.12999017554593373, 0.12456760636295183, 0.12951218938253017, 0.12665309676204817, 0.11967449877635539, 0.12152614363704817, 0.11932887801204817, 0.12303216773343373, 0.11825083537274095, 0.12053928605045183, 0.12165850903614461, 0.11981715926204817, 0.11990834431475905, 0.12078342667545183, 0.11896266707454817, 0.12238063582454817, 0.11588002400225905, 0.11859645613704817, 0.11946124341114461, 0.11634771507906627, 0.12387636483433728, 0.11946124341114461, 0.11922739787274095, 0.11624623493975905, 0.11820965502635539, 0.11759930346385539, 0.11517848738704817, 0.11294004141566272, 0.11774196394954817, 0.11654185099774095, 0.11391660391566272, 0.11394748917545183, 0.10990887377635539, 0.11568735881024095, 0.11800669474774095, 0.11503582690135539, 0.11283856127635539, 0.11409014966114461, 0.11588002400225905, 0.11432399519954817, 0.11225909497364461, 0.11261501082454817, 0.11090602644954817, 0.11420192488704817, 0.11153696818524095, 0.11394748917545183, 0.11196347891566272, 0.10976621329066272, 0.11296063158885539, 0.11542262801204817, 0.11269590079066272, 0.11149578783885539, 0.11048834007906627, 0.11239146037274095, 0.10942059252635539, 0.11127223738704817, 0.11306211172816272, 0.11063100056475905, 0.11257383047816272, 0.11465932087725905, 0.11002064900225905, 0.11248264542545183, 0.10943088761295183, 0.11456813582454817, 0.11466961596385539, 0.11025449454066272, 0.11300181193524095, 0.10733510212725905, 0.10926763695406627, 0.10869846573795183, 0.11150608292545183, 0.11001035391566272, 0.10549375235316272, 0.11160756306475905, 0.11115016707454817, 0.10974562311746983, 0.10742628717996983, 0.10734539721385539, 0.10733510212725905, 0.11025449454066272, 0.10791456842996983, 0.10756894766566272, 0.10975591820406627, 0.10741599209337349, 0.10891172110316272, 0.10893231127635539, 0.10968532332454817, 0.10707037132906627, 0.10804693382906627, 0.10893231127635539, 0.10657179499246983, 0.10693800592996983, 0.10856610033885539, 0.10622617422816272, 0.10903379141566272, 0.10769101797816272, 0.11074277579066272, 0.10879994587725905, 0.10941029743975905, 0.10852491999246983, 0.10791456842996983, 0.10598203360316272, 0.10561582266566272, 0.10572759789156627, 0.10815870905496983, 0.10682623070406627, 0.10634824454066272, 0.10929852221385539, 0.10807781908885539, 0.10964414297816272, 0.10704978115587349, 0.10681593561746983, 0.11077366105045183, 0.10832195971385539, 0.10831166462725905, 0.10537168204066272, 0.10806752400225905, 0.10622617422816272, 0.11099721150225905, 0.10661297533885539, 0.10670416039156627, 0.10695859610316272, 0.10818959431475905, 0.10696889118975905, 0.10572759789156627, 0.10806752400225905, 0.10524961172816272, 0.10499517601656627, 0.10546286709337349, 0.10202430817018071, 0.10439511954066272, 0.10447600950677716, 0.10610410391566272, 0.10498488092996983, 0.10583937311746983, 0.10424216396837349, 0.10524961172816272, 0.10425245905496983, 0.10387595303087349, 0.10508636106927716, 0.10621587914156627, 0.10402890860316272, 0.10489369587725905, 0.10693800592996983, 0.10326560146837349, 0.10534079678087349, 0.10696889118975905, 0.10856610033885539, 0.10633794945406627, 0.10364210749246983, 0.10622617422816272, 0.10732480704066272, 0.10643942959337349, 0.10630706419427716, 0.10460837490587349, 0.10513783650225905, 0.10463926016566272, 0.10488340079066272, 0.10596144342996983, 0.10608351374246983, 0.10609380882906627, 0.10644972467996983, 0.10534079678087349, 0.10582907803087349, 0.10376417780496983, 0.10460837490587349, 0.10498488092996983, 0.10425245905496983, 0.10426275414156627, 0.10475103539156627, 0.10930881730045183, 0.10547316217996983, 0.10668357021837349, 0.10550404743975905, 0.10499517601656627, 0.10438482445406627, 0.10647031485316272, 0.10412009365587349, 0.10290968561746983, 0.10462896507906627], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.055032802013036744, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.00821887218153534, "optimization": "nesterov_momentum", "nb_data_augmentation": 3, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 7.192260644997154e-08, "rotation_range": [0, 0], "momentum": 0.9378403164254363}, "accuracy_valid_max": 0.8979756918298193, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8953710349209337, "accuracy_valid_std": [0.02319001274078812, 0.013613323042765104, 0.01591941708189877, 0.014390637523147475, 0.011414606243933872, 0.016363342323051224, 0.008517158256665155, 0.00949898343101142, 0.009544182364484852, 0.009426522202221411, 0.007426511837102671, 0.00836858924323794, 0.008076075986335265, 0.010917588141451856, 0.006577732691032457, 0.009308986883027023, 0.008012483730792382, 0.013216934575964831, 0.008627370194152958, 0.007320212434418567, 0.006037705163671011, 0.009840595791314941, 0.006343033158933406, 0.009370764871557748, 0.007013816167979299, 0.009162120328878167, 0.005622350640377779, 0.006113349875977159, 0.006913398881961471, 0.010513591936798768, 0.003288333988920498, 0.01019681296867408, 0.00873070107561788, 0.008746920738099977, 0.011547408447908903, 0.012321646111959142, 0.010442750746700126, 0.00482496531288719, 0.005489084283487148, 0.008220036934268858, 0.007233994779325185, 0.006323708701999614, 0.008558830439079568, 0.007760041651345235, 0.010116894237082395, 0.007644036962477282, 0.01281840932678769, 0.006536972010627434, 0.005543024972114585, 0.008983876449122175, 0.009042981923727158, 0.006139863519092427, 0.005046318204133703, 0.00523422319076041, 0.007833402068177205, 0.00787632827911505, 0.008910700128243057, 0.011868613491553954, 0.007857724629632504, 0.008748688691812737, 0.01084668227972041, 0.007817468767242, 0.006601880637498421, 0.009186683773612142, 0.007268632299440309, 0.009792899900064515, 0.00973796174042179, 0.011504872524846489, 0.006422943337552103, 0.00954738280749509, 0.011293795607945294, 0.010961629562567606, 0.008803977498727581, 0.007592292577329006, 0.009326839532058356, 0.008506133221591886, 0.007695220643347976, 0.009687611066769863, 0.01186370853562098, 0.008218999431487963, 0.011435920233248993, 0.009419398359489652, 0.011435557543676117, 0.006104909466642374, 0.009283025338247241, 0.009579564727698907, 0.007560527833425231, 0.009844193053114726, 0.00826175171844068, 0.009565992843172565, 0.008016579976602673, 0.011351230975932597, 0.010985454218721139, 0.010274421476070045, 0.009122165104107228, 0.009376250975548334, 0.007660365454705217, 0.010627642092096304, 0.010359236383165391, 0.007477372046203166, 0.009735076030639514, 0.009125101110918936, 0.009900189033303856, 0.008684006641130901, 0.011523139131138888, 0.010590208996656242, 0.008166128013005787, 0.00909035861580344, 0.009850291559992312, 0.009727120598673412, 0.008370310353295695, 0.00992844288415923, 0.011136095857631203, 0.011058124482619206, 0.009043579293740075, 0.010567658904836479, 0.009087828276561186, 0.006823732356409983, 0.009056513471075056, 0.009554155511960014, 0.010103288729734183, 0.006273937194130991, 0.00946994841339413, 0.011924026185071789, 0.010528774152210025, 0.009771372321688683, 0.008739422497563923, 0.012986410695128623, 0.01031771721673987, 0.008556142025703513, 0.01200947335177885, 0.010270843904523179, 0.007422144146491497, 0.008069959452276428, 0.007351808767446644, 0.007476733293785246, 0.00956021560942561, 0.010868328476015966, 0.011850442528937338, 0.009515339029835621, 0.010395617034398048, 0.010857525365146326, 0.008717695380357045, 0.010329209628492405, 0.008844767187292494, 0.011489182596060878, 0.009551117227241411, 0.009222458498896883, 0.009680005889479655, 0.009874838604430496, 0.010839506397921183, 0.01145149292940706, 0.009018181056994135, 0.00949735059232336, 0.0100979221499782, 0.01153892497968776, 0.009093279083081485, 0.009810453252253262, 0.008725473086429767, 0.00891771212212081, 0.009270418864572975, 0.007767704900192451, 0.008727118981200065, 0.00932457298022928, 0.008878974398697562, 0.00867698564525151, 0.00794865810826247, 0.008673870028409065, 0.010455715533747592, 0.008887157985593431, 0.009700358255647834, 0.010150227772307008, 0.007797730042833866, 0.006813068176317907, 0.00978590340688777, 0.009849544043337781, 0.009727221888481373, 0.008517577284113393, 0.007864040208501134, 0.009731004991237094, 0.009724335104770188, 0.0065337575895505805, 0.00525084185384853, 0.00857531553327749, 0.008924636929517098, 0.008568379788146781, 0.008708141484880342, 0.009699658502665963, 0.009940548993704381, 0.007992243685617413, 0.006329775161978507, 0.009934558583864326, 0.007695602914013481, 0.0102020684822207, 0.010130846900805072, 0.008747286226920635, 0.010090907461432841, 0.00699153134020615, 0.007867110176281736, 0.009431198298955164, 0.009397765074716811, 0.009642245367031996, 0.009703442877759103, 0.008519022516689357, 0.009705958809048938, 0.010862520555680816, 0.011001290209704249, 0.009711392426102111, 0.010675352182273414, 0.009924357009765466, 0.01033278876285891, 0.012250960600161336, 0.008510526243346061, 0.01107335630622553, 0.009773640603855632, 0.008197779064116858, 0.008571267766807177, 0.009319294594382523], "accuracy_valid": [0.5802251976656627, 0.6996540850903614, 0.7553299134036144, 0.7759097915097892, 0.8053199124623494, 0.8110263318900602, 0.8211390483810241, 0.8261542262801205, 0.8317591655685241, 0.839867281626506, 0.8362154673381024, 0.8450148249246988, 0.8478327371987951, 0.8426543086408133, 0.8519022378576807, 0.8545363092996988, 0.8540892083960843, 0.8527964396649097, 0.8556967126317772, 0.8621664391942772, 0.8617090432040663, 0.8631121164344879, 0.8621664391942772, 0.8606810052710843, 0.8622885095067772, 0.865147602127259, 0.8683008400790663, 0.8621664391942772, 0.8631327066076807, 0.8669168862951807, 0.871006977127259, 0.8686670510165663, 0.8662153496799698, 0.8729292168674698, 0.8672522119728916, 0.8710672769201807, 0.8701010095067772, 0.8762971809111446, 0.8700098244540663, 0.8754323936370482, 0.8704878106174698, 0.8733469032379518, 0.8803255012236446, 0.8784738563629518, 0.8806711219879518, 0.8769678322665663, 0.881749164627259, 0.8794607139495482, 0.8783414909638554, 0.8801828407379518, 0.880091655685241, 0.8792165733245482, 0.8810373329254518, 0.8776193641754518, 0.884119975997741, 0.8814035438629518, 0.8805387565888554, 0.8836522849209337, 0.8761236351656627, 0.8805387565888554, 0.880772602127259, 0.883753765060241, 0.8817903449736446, 0.8824006965361446, 0.8848215126129518, 0.8870599585843373, 0.8822580360504518, 0.883458149002259, 0.8860833960843373, 0.8860525108245482, 0.8900911262236446, 0.884312641189759, 0.881993305252259, 0.8849641730986446, 0.8871614387236446, 0.8859098503388554, 0.884119975997741, 0.8856760048004518, 0.8877409050263554, 0.8873849891754518, 0.8890939735504518, 0.8857980751129518, 0.888463031814759, 0.8860525108245482, 0.8880365210843373, 0.8902337867093373, 0.8870393684111446, 0.8845773719879518, 0.8873040992093373, 0.8885042121611446, 0.8895116599209337, 0.887608539627259, 0.8905794074736446, 0.8887277626129518, 0.8869378882718373, 0.889368999435241, 0.8874261695218373, 0.885340679122741, 0.889979350997741, 0.8875173545745482, 0.8905691123870482, 0.8854318641754518, 0.8853303840361446, 0.8897455054593373, 0.886998188064759, 0.892664897872741, 0.8907323630459337, 0.8913015342620482, 0.8884939170745482, 0.8899896460843373, 0.8945062476468373, 0.888392436935241, 0.8888498329254518, 0.8902543768825302, 0.8925737128200302, 0.8926546027861446, 0.892664897872741, 0.8897455054593373, 0.8920854315700302, 0.8924310523343373, 0.8902440817959337, 0.8925840079066265, 0.8910882788968373, 0.8910676887236446, 0.8903146766754518, 0.8929296286709337, 0.8919530661709337, 0.8910676887236446, 0.8934282050075302, 0.8930619940700302, 0.8914338996611446, 0.8937738257718373, 0.8909662085843373, 0.8923089820218373, 0.8892572242093373, 0.891200054122741, 0.890589702560241, 0.8914750800075302, 0.8920854315700302, 0.8940179663968373, 0.8943841773343373, 0.8942724021084337, 0.8918412909450302, 0.8931737692959337, 0.8936517554593373, 0.8907014777861446, 0.8919221809111446, 0.8903558570218373, 0.8929502188441265, 0.8931840643825302, 0.8892263389495482, 0.8916780402861446, 0.891688335372741, 0.8946283179593373, 0.891932475997741, 0.8937738257718373, 0.889002788497741, 0.8933870246611446, 0.8932958396084337, 0.8930414038968373, 0.891810405685241, 0.893031108810241, 0.8942724021084337, 0.891932475997741, 0.8947503882718373, 0.8950048239834337, 0.8945371329066265, 0.8979756918298193, 0.8956048804593373, 0.8955239904932228, 0.8938958960843373, 0.8950151190700302, 0.8941606268825302, 0.8957578360316265, 0.8947503882718373, 0.8957475409450302, 0.8961240469691265, 0.8949136389307228, 0.8937841208584337, 0.8959710913968373, 0.895106304122741, 0.8930619940700302, 0.8967343985316265, 0.8946592032191265, 0.893031108810241, 0.8914338996611446, 0.8936620505459337, 0.8963578925075302, 0.8937738257718373, 0.8926751929593373, 0.8935605704066265, 0.8936929358057228, 0.8953916250941265, 0.894862163497741, 0.8953607398343373, 0.8951165992093373, 0.8940385565700302, 0.8939164862575302, 0.8939061911709337, 0.8935502753200302, 0.8946592032191265, 0.8941709219691265, 0.8962358221950302, 0.8953916250941265, 0.8950151190700302, 0.8957475409450302, 0.8957372458584337, 0.8952489646084337, 0.8906911826995482, 0.8945268378200302, 0.8933164297816265, 0.894495952560241, 0.8950048239834337, 0.8956151755459337, 0.8935296851468373, 0.8958799063441265, 0.8970903143825302, 0.8953710349209337], "seed": 119021187, "model": "residualv3", "loss_std": [0.3028238117694855, 0.1985834836959839, 0.18044456839561462, 0.17057526111602783, 0.1625950038433075, 0.1579161137342453, 0.15411269664764404, 0.15133830904960632, 0.14486607909202576, 0.13943393528461456, 0.13656072318553925, 0.13171154260635376, 0.126300647854805, 0.12371858209371567, 0.11885008215904236, 0.11348115652799606, 0.11022266745567322, 0.10545419156551361, 0.10623402893543243, 0.10138627141714096, 0.0973333865404129, 0.09752450883388519, 0.09213536232709885, 0.08965223282575607, 0.085816890001297, 0.0829099789261818, 0.0800786167383194, 0.07947862148284912, 0.07293366640806198, 0.07311520725488663, 0.07048038393259048, 0.06798627972602844, 0.06803923100233078, 0.0656856894493103, 0.06117357313632965, 0.06253033131361008, 0.060925282537937164, 0.05718182027339935, 0.0554317869246006, 0.05520455166697502, 0.051324859261512756, 0.050519056618213654, 0.05035032704472542, 0.04836822301149368, 0.04756961017847061, 0.04946482554078102, 0.04512876272201538, 0.04624685272574425, 0.04432986304163933, 0.0398738794028759, 0.04005713015794754, 0.039167702198028564, 0.038144052028656006, 0.03659447655081749, 0.036871470510959625, 0.03703949600458145, 0.03408784046769142, 0.034782927483320236, 0.03411133959889412, 0.031241869553923607, 0.030427584424614906, 0.031784068793058395, 0.02911500446498394, 0.03052796982228756, 0.029704580083489418, 0.027777330949902534, 0.029359379783272743, 0.027911251410841942, 0.026672719046473503, 0.025870516896247864, 0.02438085712492466, 0.02512389048933983, 0.02458382397890091, 0.025624152272939682, 0.025040367618203163, 0.02416788972914219, 0.02189853973686695, 0.021999461576342583, 0.021124545484781265, 0.020238753408193588, 0.0203874334692955, 0.02132795751094818, 0.020435722544789314, 0.02088703215122223, 0.019384922459721565, 0.020737994462251663, 0.020141160115599632, 0.01891680620610714, 0.0188456978648901, 0.01871216669678688, 0.01784074306488037, 0.018610062077641487, 0.017888685688376427, 0.018463483080267906, 0.01701815240085125, 0.018024355173110962, 0.01792602427303791, 0.0169037114828825, 0.01543818973004818, 0.016522040590643883, 0.015654202550649643, 0.015529538504779339, 0.01525962259620428, 0.015224984847009182, 0.01598069630563259, 0.01532453391700983, 0.014872189611196518, 0.015065757557749748, 0.01462799683213234, 0.014026454649865627, 0.014195005409419537, 0.01371079869568348, 0.014635799452662468, 0.013415548019111156, 0.013706441037356853, 0.012746362015604973, 0.01292891800403595, 0.013097940012812614, 0.012341572903096676, 0.012913151644170284, 0.01200695987790823, 0.01286196056753397, 0.012674937956035137, 0.011988303624093533, 0.011770910583436489, 0.011181614361703396, 0.012681938707828522, 0.01130987610667944, 0.011308591812849045, 0.011415070854127407, 0.011544683016836643, 0.01143593154847622, 0.011845439672470093, 0.010655426420271397, 0.01093462947756052, 0.010956937447190285, 0.010955040343105793, 0.009960789233446121, 0.010684310458600521, 0.01116098091006279, 0.009839790873229504, 0.010679646395146847, 0.010570606216788292, 0.009955848567187786, 0.008719558827579021, 0.009776822291314602, 0.009433935396373272, 0.009799943305552006, 0.008843131363391876, 0.009244786575436592, 0.010064423084259033, 0.010266882367432117, 0.009540491737425327, 0.008897431194782257, 0.009330257773399353, 0.009569698013365269, 0.008712640963494778, 0.008705337531864643, 0.009182082489132881, 0.008685695938766003, 0.009094707667827606, 0.009357294999063015, 0.008478038012981415, 0.00863831490278244, 0.007674297317862511, 0.008030441589653492, 0.008515640161931515, 0.007778296712785959, 0.007848788984119892, 0.008041114546358585, 0.00837074313312769, 0.008088652975857258, 0.008190571330487728, 0.007370153442025185, 0.008128258399665356, 0.007708471268415451, 0.007408017758280039, 0.007695103995501995, 0.008398042991757393, 0.008189119398593903, 0.006896652281284332, 0.0073892297223210335, 0.007619955576956272, 0.0073346481658518314, 0.006995751056820154, 0.007131929975003004, 0.0071652792394161224, 0.0068277823738753796, 0.006469662766903639, 0.0072273616679012775, 0.007006539963185787, 0.007005995139479637, 0.0069091785699129105, 0.0071601103991270065, 0.00637807697057724, 0.00621411669999361, 0.006686032749712467, 0.00744740990921855, 0.006302248686552048, 0.006857588887214661, 0.007537871599197388, 0.007338314317166805, 0.006331114564090967, 0.006366095505654812, 0.006138794589787722, 0.006303028203547001, 0.006817378103733063, 0.0072677223943173885, 0.006604108028113842, 0.0066858879290521145, 0.006182586774230003, 0.006097245495766401, 0.007172624580562115, 0.00618582172319293, 0.005995987914502621, 0.006284500937908888, 0.0065617635846138, 0.005670533515512943]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:34 2016", "state": "available"}], "summary": "1eb6c903ca013dfc41c070b146dc5dad"}