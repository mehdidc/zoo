{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 32, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.98656165599823, 1.5135674476623535, 1.3545331954956055, 1.2460927963256836, 1.1571213006973267, 1.0884559154510498, 1.0276732444763184, 0.9782532453536987, 0.9318137168884277, 0.8908687829971313, 0.856503427028656, 0.8234465718269348, 0.7961248755455017, 0.7683842182159424, 0.7428845763206482, 0.7227886319160461, 0.7002919912338257, 0.6770491600036621, 0.6586143970489502, 0.641221284866333, 0.6224982142448425, 0.6081021428108215, 0.5906890034675598, 0.5777310132980347, 0.5639727115631104, 0.5479271411895752, 0.5398949980735779, 0.528544008731842, 0.517628014087677, 0.5056707859039307, 0.4930965304374695, 0.484218567609787, 0.47646087408065796, 0.46831175684928894, 0.4564197063446045, 0.44911330938339233, 0.4395947754383087, 0.43501076102256775, 0.4275292754173279, 0.41904643177986145, 0.4119676947593689, 0.4032721221446991, 0.39673295617103577, 0.38921111822128296, 0.3841026723384857, 0.37934908270835876, 0.3699893355369568, 0.36676961183547974, 0.3590632677078247, 0.3582776188850403, 0.35140520334243774, 0.34700217843055725, 0.34083887934684753, 0.3359355628490448, 0.3306449055671692, 0.3243297338485718, 0.3194904029369354, 0.31933167576789856, 0.3107886016368866, 0.3094785809516907, 0.3058818578720093, 0.2983705401420593, 0.2990608513355255, 0.293670654296875, 0.2904501259326935, 0.2861635088920593, 0.28319188952445984, 0.27883628010749817, 0.276667058467865, 0.27433302998542786, 0.26965445280075073, 0.2672022879123688, 0.2640153169631958, 0.26335951685905457, 0.26086315512657166, 0.25514963269233704, 0.25319141149520874, 0.25005418062210083, 0.25025495886802673, 0.24618420004844666, 0.24364984035491943, 0.24241071939468384, 0.23958005011081696, 0.2374635487794876, 0.2366541475057602, 0.23248277604579926, 0.23053625226020813, 0.2301027625799179, 0.22534042596817017, 0.22493112087249756, 0.22448785603046417, 0.22110356390476227, 0.22034603357315063, 0.22020162642002106, 0.2163831889629364, 0.2136380970478058, 0.21013210713863373, 0.20842035114765167, 0.20801423490047455, 0.206366166472435, 0.20729002356529236, 0.20479242503643036, 0.20333504676818848, 0.2024553120136261, 0.2010180503129959, 0.19984160363674164, 0.19551008939743042, 0.19450139999389648, 0.19660530984401703, 0.19321641325950623, 0.19011236727237701, 0.19012942910194397, 0.18874797224998474, 0.1867658793926239, 0.1837657243013382, 0.18348245322704315, 0.18194998800754547, 0.18158277869224548, 0.1804852932691574, 0.18057455122470856, 0.18033528327941895, 0.17728757858276367, 0.17702433466911316, 0.17311891913414001, 0.17367371916770935, 0.17275378108024597, 0.16894495487213135, 0.17027662694454193, 0.1697213500738144, 0.1712433397769928, 0.168161541223526, 0.16621161997318268, 0.16686856746673584, 0.1648634970188141, 0.16290578246116638, 0.16127395629882812, 0.16184520721435547, 0.15989674627780914, 0.1602616310119629, 0.1604681760072708, 0.15796415507793427, 0.15723520517349243, 0.1591821163892746, 0.15619775652885437, 0.15552960336208344, 0.15264637768268585, 0.15109792351722717, 0.15128140151500702, 0.15260133147239685, 0.1470651924610138, 0.15056809782981873, 0.1453266590833664, 0.146515354514122, 0.14544560015201569, 0.14652475714683533, 0.1436893194913864, 0.14382313191890717, 0.14206290245056152, 0.14398393034934998, 0.14387822151184082, 0.14096218347549438, 0.13985773921012878, 0.1382840871810913, 0.13954801857471466, 0.13814812898635864, 0.13869524002075195, 0.13695599138736725, 0.1358235478401184, 0.1337519884109497, 0.13447768986225128, 0.13471601903438568, 0.13443239033222198, 0.13232365250587463, 0.13278651237487793, 0.13203750550746918, 0.13074415922164917, 0.12911881506443024, 0.1283893883228302, 0.13037419319152832, 0.12743836641311646, 0.12861229479312897, 0.12740513682365417, 0.12498509883880615, 0.1259528547525406, 0.1260327845811844, 0.12669040262699127, 0.12677313387393951, 0.12302248924970627, 0.12400052696466446, 0.12493092566728592, 0.12053506076335907, 0.12084947526454926, 0.12008048593997955, 0.12060022354125977, 0.11793564260005951, 0.12115175276994705, 0.11758752912282944, 0.11831537634134293, 0.11777780205011368, 0.11503980308771133, 0.11309526115655899, 0.1159634068608284, 0.11659609526395798, 0.11477310955524445, 0.1145261898636818, 0.1136857122182846, 0.11407291889190674, 0.11262015253305435, 0.11440407484769821, 0.1116093322634697], "moving_avg_accuracy_train": [0.03478446050779807, 0.07478404414394146, 0.11373835677227526, 0.14697926015927806, 0.17954652655752523, 0.21609123511670442, 0.2531335036662189, 0.2881178228155623, 0.3122046359278322, 0.33658365337625423, 0.3704944729315782, 0.3985081327005282, 0.4220954719140948, 0.4478759615501586, 0.46438309116456866, 0.48263604554478956, 0.4979290679167595, 0.518153078835724, 0.5416339119982018, 0.5579385173780697, 0.5736264631497219, 0.5921411008879058, 0.6092202601962637, 0.6290111067772279, 0.643270401807331, 0.6531910047548278, 0.6666646005002753, 0.6698105892609252, 0.6748573052287049, 0.6880332579837968, 0.6982176164669786, 0.6992614157975786, 0.7045242781745391, 0.7170260582636006, 0.71754199767995, 0.7229604782425658, 0.7307424652962623, 0.7407455874624186, 0.7432016795848091, 0.7458723977639713, 0.7568733269094549, 0.7624780091167651, 0.7716859517912827, 0.7811840340934668, 0.7792503751124148, 0.7847490813719374, 0.7934918388862756, 0.8010906033872752, 0.8051583826918662, 0.8053626808602488, 0.7836414664725443, 0.78327750079036, 0.7798400721802701, 0.7876999281555339, 0.7955223522546631, 0.8010328744177626, 0.8052834263193788, 0.812037781408002, 0.8076046130978589, 0.8126457657657862, 0.8056011468246358, 0.8131092336233461, 0.814262236208086, 0.8128703382724934, 0.8190193177919587, 0.8260342307605941, 0.8325406037347377, 0.8336049647402322, 0.8413584344437652, 0.8435433259915445, 0.8505494613925746, 0.8499924417252624, 0.8546331275315107, 0.859365202980879, 0.8596960473987841, 0.8615693570472871, 0.8657521129665432, 0.868933161186777, 0.864564296981859, 0.8666971904887303, 0.8636489610058872, 0.8690441340613523, 0.8686743332890303, 0.872737359625825, 0.8744852082539586, 0.8715577932909658, 0.877099298332255, 0.8797686597504137, 0.8825244355481667, 0.8859810160220507, 0.8876693799629427, 0.8852574774098471, 0.8885755402308779, 0.8910250839318119, 0.8915816834889815, 0.8955182918104414, 0.897436140525992, 0.8994201516925695, 0.9018940057901084, 0.8917712306379155, 0.8863832601961709, 0.8903073959648059, 0.8909980386530706, 0.8922753450856133, 0.8959754288748556, 0.9008349835671965, 0.9045252413820346, 0.9074139236391799, 0.9038622590922608, 0.9031463703404268, 0.9046690010077961, 0.904734743833373, 0.9037175126728578, 0.9051595252771575, 0.9091867368840394, 0.912653333504098, 0.9142548761918943, 0.9100780381839544, 0.9095216412788572, 0.9109461433273742, 0.9122651812590794, 0.9148958002225034, 0.8995588451310393, 0.8963484768658591, 0.8967537010461982, 0.9030489201523112, 0.8993131214660299, 0.9024789471874133, 0.9074438955092312, 0.9122424119833634, 0.9141781597685081, 0.9086973931814228, 0.9057802828315346, 0.9060049391760112, 0.9108519841334562, 0.9150863693129955, 0.912392450826002, 0.9156870332339425, 0.9130052000655869, 0.914276802930706, 0.9120548986677665, 0.9146067447356059, 0.9006723174069788, 0.8942009264977686, 0.8897577049258804, 0.8890111479634234, 0.8924768940647831, 0.8991370508999992, 0.9034665296993496, 0.9048012513141322, 0.9086203659852291, 0.9142847012605526, 0.9131638753586114, 0.9161976285573387, 0.9157780065803885, 0.9198967159641086, 0.9239869876701157, 0.9251574680282425, 0.9278916945492923, 0.9324612641932003, 0.9349999313727636, 0.9331185338023478, 0.9354263524067015, 0.9339117552162806, 0.9355638671162103, 0.9343512340094712, 0.936214948106217, 0.9335099981172545, 0.9344280832711529, 0.9328364214406693, 0.9342680765407422, 0.9362190893462472, 0.9379448099854966, 0.9400397903310777, 0.9404069504694815, 0.9429368411725796, 0.9443162714137103, 0.9441790535331367, 0.9411381085145868, 0.9313732704159889, 0.9332325836244824, 0.9367635431180233, 0.9394948699443255, 0.9371038130382559, 0.9368858088512169, 0.9367573588377268, 0.9390337551694857, 0.9347269248779432, 0.935362665795003, 0.933956599618096, 0.9359667339992174, 0.9389359600029039, 0.940427340152715, 0.9427902144684697, 0.9437703587942786, 0.9451735022649338, 0.9463573123778184, 0.9476064642841857, 0.9474912885379838, 0.9478318419354774, 0.9500866344515089, 0.9486216816410479, 0.947024242303309, 0.949392130572978, 0.9506257946728415, 0.9487419495747895, 0.9490199995935472, 0.9471779351212265, 0.9413893691261765, 0.9391132405030569], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03502241387424698, 0.07427699077560239, 0.11182175969503011, 0.14468755294615962, 0.17726278414439, 0.21334833507859557, 0.24919564812570588, 0.2839719958696112, 0.3070803791610386, 0.3302644722690311, 0.3633215976136641, 0.3900108104520718, 0.41253066667154836, 0.4370090806143333, 0.45264684560448126, 0.46939535052068976, 0.4832025622212563, 0.5016087331922783, 0.5231244588470716, 0.5386686935911296, 0.5535374111107817, 0.5700779365189054, 0.585366211908807, 0.6027177625458631, 0.6151438578556594, 0.6239693275859067, 0.6358827710980238, 0.6394125756900286, 0.6424764480156041, 0.6535380970299323, 0.6619503476620294, 0.6625030656254952, 0.6667248329051897, 0.6766679428469748, 0.6766389850645365, 0.6809771573412153, 0.6869649437720035, 0.6943641407539898, 0.6957904255208348, 0.6977262020105435, 0.7065162700625012, 0.7103570952870493, 0.7166388097511908, 0.7236433622756951, 0.7222395282130352, 0.7261408283567167, 0.7320253100918281, 0.7374384134952959, 0.739768937968432, 0.7396364942374775, 0.7196951351469375, 0.7189983590663552, 0.7154728995716173, 0.7216714562823772, 0.726976455091263, 0.7308536636860523, 0.7337511839420706, 0.737579655297487, 0.7331299776065938, 0.7369065882796694, 0.7308142034068983, 0.7353820029927898, 0.7355864784747608, 0.7344124374138058, 0.7386111480210698, 0.7434999449753633, 0.7481440028592276, 0.7485993338421301, 0.7535289688878869, 0.7552617094708602, 0.759967648604723, 0.7588063094313742, 0.7614161540624085, 0.7647376057683664, 0.7646332387815147, 0.7660388613924445, 0.7684360871225525, 0.7706109448541978, 0.7667605643183262, 0.7683898189745959, 0.7660718214050731, 0.7696448326945357, 0.7691393102684555, 0.7718339012201492, 0.7727166820318692, 0.7706109117955497, 0.7743577201830129, 0.7760949879802236, 0.7781815193968096, 0.7801874979635293, 0.7811373569774173, 0.7795202327254587, 0.7821319683949309, 0.783612742752727, 0.7841031545184933, 0.7868059144149121, 0.7883950836567793, 0.7902271384970503, 0.7920702708446343, 0.7846395580015113, 0.7803903812393873, 0.7833129336180841, 0.7835230029727666, 0.783400712558773, 0.7864066797535734, 0.7897091652514842, 0.7922398900572845, 0.7940577932296433, 0.7917935389913928, 0.7912785005572385, 0.792348051433367, 0.7923371732478616, 0.7913934714539489, 0.7919775100389758, 0.7952153117929848, 0.7979482869201622, 0.7991262262533719, 0.7958159603204293, 0.7952598902202388, 0.7961429396959558, 0.7965969168577609, 0.7987938999178433, 0.7879440950634837, 0.784690912966774, 0.7852727911731087, 0.7894231464213851, 0.7871880512822587, 0.789371713445072, 0.7928140601728539, 0.7956843566687463, 0.7975188765741608, 0.79343955221682, 0.7918789471928037, 0.7921417654818065, 0.7954210883218036, 0.7983023252162798, 0.7958373153038386, 0.7983310145904727, 0.7965874686190009, 0.7974558596053688, 0.7965404870766843, 0.7982660093874646, 0.7881739128726639, 0.7839710441286957, 0.7806940980836725, 0.7803856834277902, 0.7828914604351618, 0.7876695442485734, 0.7906291052604629, 0.7918786064908172, 0.7946349288236633, 0.7982438133415228, 0.7973156810661055, 0.7991387004500823, 0.7984049297085379, 0.8009135107681811, 0.8035028825829292, 0.8042686111262176, 0.8064196691118639, 0.8100393091754515, 0.8117384561946533, 0.8102482866858808, 0.8123415750165397, 0.8114564503650363, 0.8123383785118912, 0.8119550913007623, 0.8130760060694059, 0.8105700867971792, 0.8115793314118891, 0.8105883551607604, 0.8113129522030428, 0.8130128352112777, 0.8141135718802854, 0.8153035183443653, 0.8150459627731066, 0.8166034488094254, 0.8176329453253202, 0.8175858711429388, 0.8162485295576359, 0.8095576409749898, 0.8109335963334396, 0.8134385459527312, 0.815481363044205, 0.8137828008173448, 0.8133038995006706, 0.8129318644545945, 0.8144913288468609, 0.8116212092810755, 0.8121113320935553, 0.8113286509738082, 0.8129131298617437, 0.8147358158401777, 0.816319316099157, 0.8183070192783979, 0.8190165858464165, 0.8198647743062025, 0.8202395779373293, 0.8211353361168644, 0.8210117250861267, 0.8217326123007821, 0.8236174094762009, 0.8228030494585507, 0.8211891601753463, 0.8230591784104472, 0.8240809561172188, 0.8226332744268071, 0.822598862646777, 0.8212942427601113, 0.8175677858222026, 0.8158242731944252], "moving_var_accuracy_train": [0.010889628235367075, 0.024200365631413853, 0.03543727531938616, 0.04183816670930404, 0.04719999160426323, 0.05449963395691501, 0.06139883749487266, 0.06627407702247344, 0.06486824041337484, 0.06373044479779155, 0.0677068934642361, 0.06799909032066685, 0.06620644442918287, 0.06556750279914131, 0.0614631204721896, 0.05831534151742846, 0.054588696165111764, 0.05281092210745415, 0.05249197563074579, 0.04963533947701017, 0.04688681031211787, 0.04528325557609175, 0.04338020916260496, 0.04256728672186584, 0.040140505502478926, 0.037012220217807985, 0.034944838236832844, 0.03153942962068878, 0.02861471073715489, 0.027315691242479116, 0.025517612537656817, 0.022975656937274186, 0.020927370727136203, 0.020241284202979853, 0.018219551524013958, 0.016661835756079584, 0.01554068608300673, 0.014887179552345493, 0.013452753093733961, 0.012171672404693128, 0.012043689142799378, 0.01112203239232391, 0.010772905027766351, 0.01050753663176127, 0.009490434302080174, 0.008813512806628778, 0.008620083806556555, 0.008277746423375766, 0.007598893237275923, 0.006839379553222771, 0.010401741988190064, 0.009362760028531328, 0.008532827264723377, 0.00823554056181806, 0.007962699374715982, 0.00743972212783449, 0.0068583546382660334, 0.006583110988408324, 0.006101676720962007, 0.005720228030857961, 0.005594845132006302, 0.0055427029251983815, 0.005000397367322297, 0.004517794049358031, 0.004406304186599463, 0.004408554803557284, 0.004348695326709555, 0.003924021573188755, 0.004072666047862327, 0.0037083632027561093, 0.003779300281798606, 0.0034041626918066975, 0.0032575701053968505, 0.003133345937383794, 0.0028209964659051453, 0.0025704804206671977, 0.0024708914023211298, 0.0023148738721040928, 0.0022551692548628075, 0.002070595441781411, 0.0019471612244239373, 0.002014416132667301, 0.0018142052929014604, 0.0017813584107326968, 0.0016307173431012447, 0.0015447734340811045, 0.001666670593776693, 0.0015641329478258154, 0.0014760683552705652, 0.001435993056895431, 0.0013180489063780274, 0.0012385994810708892, 0.0012138254009225618, 0.0011464452399153745, 0.0010345889435272088, 0.0010706020148637746, 0.0009966451066390468, 0.0009324072987570843, 0.0008942461557445663, 0.0017270567312067807, 0.001815623087416131, 0.0017726503524506459, 0.001599678203111263, 0.0014543939883036711, 0.0014321701699000267, 0.0015014905991807008, 0.0014739035639223948, 0.0014016135741748738, 0.0013749811062419646, 0.0012420954659627908, 0.001138751556709433, 0.0010249153001105234, 0.0009317366032047794, 0.0008572775460429336, 0.0009175156913780786, 0.0009339197513760854, 0.0008636122270659774, 0.0009342647860605218, 0.000843624505098485, 0.0007775249093646995, 0.0007154311680157233, 0.000706169456390681, 0.002752552234049886, 0.002570055190227591, 0.0023145275309318157, 0.002439742830184357, 0.0023213742735857137, 0.0021794389187106936, 0.0021833514333845262, 0.0021722481332187415, 0.001988747395286099, 0.002060221877196476, 0.0019307854846176587, 0.0017381611704139154, 0.0017757896567479627, 0.0017595808517114776, 0.0016489375378714196, 0.0015817322432686832, 0.0014882890812278398, 0.0013540129377242664, 0.00126304337093486, 0.001195346299026903, 0.002823326053915303, 0.002917903551222056, 0.0028037931575318953, 0.0025284299674624426, 0.0023836895350680116, 0.0025445397831882844, 0.0024587852849356777, 0.0022289400925428224, 0.00213731681512743, 0.0022123473806161574, 0.0020024188988767024, 0.001885009935226124, 0.0016980936851353678, 0.0016809582195097263, 0.0016634353012194068, 0.0015094219895163132, 0.0014257637425803948, 0.0014711160688970829, 0.0013820079414447028, 0.001275664058661934, 0.0011960318931911475, 0.0010970747457151133, 0.0010119325347126061, 0.0009239735927053844, 0.0008628371055445258, 0.0008424041849751636, 0.0007657496896259251, 0.0007119752071069006, 0.0006592244133262952, 0.000627560030698865, 0.000591607033151561, 0.0005719468136717414, 0.0005159653914096618, 0.0005219719749952903, 0.00048690022760707573, 0.00043837966356711046, 0.0004777678166629918, 0.001288159602823143, 0.0011904570530063305, 0.0011836204222109477, 0.001132399696078552, 0.001070614104623269, 0.0009639804265910407, 0.0008677308785856271, 0.0008275956130602723, 0.0009117751361955788, 0.000824235121198638, 0.0007596048079233535, 0.0007200100892025145, 0.0007273558078309821, 0.0006746381598091396, 0.0006574229191167057, 0.0006003267732997753, 0.0005580134003629784, 0.0005148247177769915, 0.0004773856703659215, 0.0004297664924019478, 0.000387833632710653, 0.00039480707305275043, 0.0003746411463793726, 0.0003601433436812387, 0.00037459106303184387, 0.0003508293007302881, 0.0003476862218383485, 0.0003136134059708939, 0.00031279087905548185, 0.0005830792576613693, 0.0005713981854760945], "duration": 62539.679907, "accuracy_train": [0.34784460507798076, 0.4347802968692322, 0.46432717042727945, 0.44614739064230347, 0.4726519241417498, 0.5449936121493171, 0.5865139206118494, 0.602976695159653, 0.5289859539382613, 0.5559948104120525, 0.6756918489294943, 0.6506310706210778, 0.6343815248361941, 0.6799003682747324, 0.6129472576942598, 0.6469126349667774, 0.6355662692644888, 0.7001691771064046, 0.752961410460502, 0.7046799657968807, 0.7148179750945921, 0.7587728405315615, 0.7629326939714839, 0.8071287260059062, 0.7716040570782576, 0.7424764312822998, 0.7879269622093023, 0.6981244881067736, 0.7202777489387228, 0.8066168327796235, 0.7898768428156147, 0.7086556097729789, 0.7518900395671835, 0.8295420790651532, 0.7221854524270949, 0.7717268033061092, 0.8007803487795312, 0.8307736869578257, 0.7653065086863234, 0.7699088613764304, 0.8558816892188077, 0.8129201489825582, 0.8545574358619417, 0.866666774813123, 0.7618474442829457, 0.8342374377076411, 0.8721766565153194, 0.8694794838962717, 0.8417683964331857, 0.8072013643756922, 0.5881505369832042, 0.7800018096507014, 0.748903214689461, 0.8584386319329088, 0.8659241691468254, 0.8506275738856589, 0.8435383934339239, 0.872826977205611, 0.7677060983065707, 0.8580161397771319, 0.742199576354282, 0.8806820148117387, 0.8246392594707457, 0.8003432568521595, 0.8743601334671466, 0.8891684474783131, 0.8910979605020304, 0.8431842137896824, 0.9111396617755629, 0.8632073499215578, 0.9136046800018457, 0.8449792647194537, 0.8963992997877446, 0.9019538820251938, 0.8626736471599299, 0.8784291438838132, 0.9033969162398486, 0.8975625951688816, 0.825244519137597, 0.8858932320505721, 0.8362148956602989, 0.9176006915605389, 0.8653461263381322, 0.9093045966569768, 0.8902158459071613, 0.8452110586240311, 0.9269728437038575, 0.9037929125138427, 0.9073264177279439, 0.9170902402870063, 0.9028646554309707, 0.863550354431986, 0.918438105620155, 0.9130709772402179, 0.8965910795035069, 0.9309477667035806, 0.9146967789659468, 0.9172762521917681, 0.9241586926679586, 0.8006662542681802, 0.8378915262204688, 0.9256246178825213, 0.897213822847453, 0.9037711029784975, 0.9292761829780363, 0.9445709757982651, 0.9377375617155776, 0.9334120639534883, 0.871897278169989, 0.8967033715739202, 0.9183726770141197, 0.9053264292635659, 0.8945624322282208, 0.9181376387158545, 0.9454316413459765, 0.9438527030846253, 0.9286687603820598, 0.8724864961124953, 0.9045140691329827, 0.9237666617640274, 0.924136522644426, 0.9385713708933187, 0.7615262493078626, 0.8674551624792359, 0.9004007186692506, 0.9597058921073275, 0.8656909332894979, 0.9309713786798633, 0.9521284304055924, 0.9554290602505537, 0.9315998898348099, 0.859370493897656, 0.8795262896825397, 0.9080268462763011, 0.9544753887504615, 0.9531958359288483, 0.8881471844430602, 0.945338274905408, 0.8888687015503876, 0.9257212287167773, 0.8920577603013106, 0.9375733593461609, 0.7752624714493356, 0.8359584083148762, 0.8497687107788853, 0.8822921353013106, 0.923668608977021, 0.9590784624169435, 0.9424318388935032, 0.9168137458471761, 0.9429923980251015, 0.9652637187384644, 0.9030764422411407, 0.9435014073458842, 0.9120014087878369, 0.9569651004175894, 0.9607994330241787, 0.9356917912513842, 0.9524997332387413, 0.9735873909883721, 0.9578479359888336, 0.9161859556686047, 0.9561967198458842, 0.9202803805024916, 0.9504328742155776, 0.9234375360488187, 0.9529883749769288, 0.9091654482165927, 0.9426908496562385, 0.9185114649663161, 0.947152972441399, 0.9537782045957919, 0.9534762957387413, 0.9588946134413067, 0.9437113917151162, 0.9657058575004615, 0.9567311435838871, 0.9429440926079733, 0.9137696033476375, 0.8434897275286084, 0.9499664025009228, 0.968542178559893, 0.9640768113810447, 0.9155843008836286, 0.9349237711678663, 0.9356013087163161, 0.9595213221553157, 0.8959654522540605, 0.9410843340485419, 0.9213020040259321, 0.9540579434293098, 0.9656589940360835, 0.9538497615010151, 0.9640560833102622, 0.9525916577265596, 0.9578017935008305, 0.9570116033937799, 0.9588488314414912, 0.9464547068221669, 0.9508968225129198, 0.9703797670957919, 0.9354371063468992, 0.9326472882636582, 0.970703125, 0.9617287715716132, 0.931787343692322, 0.9515224497623662, 0.9305993548703396, 0.8892922751707272, 0.9186280828949798], "end": "2016-01-30 09:05:42.219000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0], "moving_var_accuracy_valid": [0.01103912526221143, 0.023803509005330122, 0.03410964516371613, 0.040420123941578436, 0.045928422735984076, 0.05305508333841197, 0.059314843678848504, 0.06426790857260892, 0.06264709412043973, 0.06121990426755636, 0.06493287566525774, 0.06485041483613639, 0.06292966866983582, 0.062029436545241186, 0.058027350135700956, 0.054749226874485205, 0.050990056041535045, 0.04894013460571196, 0.04821245919921172, 0.04556582238329594, 0.042998948991079235, 0.04116135491896236, 0.03914880170664337, 0.03794360832157191, 0.035538918091247984, 0.03268602652575879, 0.03069479510003057, 0.02773745127414716, 0.02504819196937929, 0.02364461348268704, 0.021917045780693305, 0.019728090676948213, 0.01791569147992848, 0.017013911249765493, 0.015312527671767419, 0.013950652552909986, 0.012878269574685559, 0.012083175661021133, 0.010893166689044227, 0.009837575095702784, 0.009549205253354932, 0.008727052173669161, 0.00820948638578328, 0.007830111551821823, 0.007064837147318998, 0.006495334717886896, 0.006157445373715951, 0.005805416032454067, 0.005273756528087636, 0.004746538747355695, 0.007850805094020852, 0.007070094056777012, 0.006474944432940651, 0.006173248937315152, 0.005809211154844152, 0.005363584757747314, 0.0049027868946789075, 0.004544422941484214, 0.004268177331311293, 0.0039697246917640575, 0.00390680660352939, 0.003703909080688286, 0.003333894464624003, 0.0030129103698768775, 0.0028702818697611513, 0.002798356703727832, 0.002712626496013186, 0.0024432297831477865, 0.0024176185199921976, 0.002202878177343924, 0.0021819031277941214, 0.0019758511930946998, 0.001839567674768475, 0.0017548992802067262, 0.0015795073843975543, 0.0014393386202770145, 0.001347124979059138, 0.0012549825365293025, 0.0012629131553155413, 0.0011605120763987786, 0.0010928188833497254, 0.0010984346820863957, 0.0009908911901871853, 0.0009571494547410082, 0.0008684482269207769, 0.0008215118188222192, 0.0008657077947712714, 0.0008062999098871741, 0.0007648524390700628, 0.0007245827452543038, 0.0006602445600452527, 0.0006177559216571811, 0.0006173707983562037, 0.0005753679528089406, 0.0005199956908280662, 0.0005337403212644644, 0.0005030954190516892, 0.0004829937015863591, 0.0004652685630841222, 0.000915681146988297, 0.0009866125606914403, 0.0009648231162783338, 0.0008687379668544912, 0.0007819987646772345, 0.0007851214371954578, 0.0008047669876511082, 0.0007819314012702378, 0.0007334812086398671, 0.0007062747130747975, 0.0006380346230652231, 0.0005845266124483474, 0.0005260750162177917, 0.0004814826722785184, 0.0004364043146698674, 0.0004871141249872576, 0.0005056250899004662, 0.00046755045056492186, 0.0005194161504296336, 0.0004702574609936033, 0.0004302497022833211, 0.0003890795894259538, 0.00039361224157995694, 0.0014137154058211346, 0.0013675926090282006, 0.0012338805883484458, 0.0012655215676956667, 0.0011839302634546209, 0.0011084526610808806, 0.0011042551539212331, 0.0010679770562980956, 0.0009914685202185454, 0.0010420896531082348, 0.0009598000801662766, 0.000864441733226958, 0.0008747831845045999, 0.0008620186004329615, 0.0008305032052055672, 0.0008034197098744504, 0.0007504373118787309, 0.0006821805068377043, 0.0006215036179503656, 0.0005861501013603364, 0.0014441887998007717, 0.001458746870931918, 0.0014095175622766644, 0.0012694218824486649, 0.0011989899598998472, 0.0012845617282617303, 0.0012349365678834328, 0.001125494191017002, 0.001081320587138212, 0.0010904049555936098, 0.0009891173257202913, 0.0009201161902174585, 0.0008329503467060319, 0.0008062921224306338, 0.0007860065277426803, 0.0007126829367864715, 0.0006830580972263392, 0.0007326684352130683, 0.0006853854970275237, 0.0006368323938086506, 0.0006125858587452402, 0.0005583782837090067, 0.0005095406306440386, 0.0004599087493555693, 0.0004252259236870836, 0.00043922001390863156, 0.0004044651847486548, 0.0003728569716464987, 0.00034029664234500826, 0.0003322733982856785, 0.0003099506493875956, 0.00029169933773522203, 0.0002631264178122779, 0.00025864564081100425, 0.00024231984441605987, 0.0002181078037822758, 0.0002123933660460728, 0.0005940659396699242, 0.0005516986240389526, 0.0005530017149917583, 0.000535259458515542, 0.0005076995354106364, 0.0004589937001095837, 0.00041434002077820486, 0.00039479338141710726, 0.00042945232017253885, 0.0003886690714971029, 0.0003553154719642699, 0.0003423790848846613, 0.00033804083398001624, 0.00032680400821369956, 0.0003296822827512101, 0.0003012454169061369, 0.00027759568818535164, 0.0002511004192239685, 0.0002332118217474087, 0.00021002815675494804, 0.0001937024464657358, 0.00020630434535136145, 0.0001916425509613505, 0.00019592004343119547, 0.0002078007528845653, 0.00019641694473460677, 0.000195637290751924, 0.00017608421921217518, 0.00017379409472910906, 0.0002813930170469902, 0.0002806122418912674], "accuracy_test": 0.6642837213010204, "start": "2016-01-29 15:43:22.539000", "learning_rate_per_epoch": [0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235, 0.00022597500355914235], "accuracy_train_first": 0.34784460507798076, "accuracy_train_last": 0.9186280828949798, "batch_size_eval": 1024, "accuracy_train_std": [0.01630030114231074, 0.017038257905200072, 0.017743026032013432, 0.019089510010726687, 0.0172868014785069, 0.02134807423973593, 0.018015977210884607, 0.01794515067477337, 0.017867348759482267, 0.017086931431014685, 0.017528345665531537, 0.0196870737681114, 0.018633186783217886, 0.016681486860591337, 0.016997737402075927, 0.016477753643505774, 0.018950505480838795, 0.020185497012258025, 0.020056600426788945, 0.018940238330212876, 0.01621556599134797, 0.02009026768875227, 0.02009419339699458, 0.01862394986641177, 0.020595106988287006, 0.019608741719935426, 0.018579179017367234, 0.017828763937806146, 0.01892548797344498, 0.018004135932131755, 0.01872629064742107, 0.01596748667589353, 0.020842756008050065, 0.01608937526635382, 0.01618781839800493, 0.016402790868950568, 0.01924296779957425, 0.01615443274325331, 0.018127425486037307, 0.017546309999935998, 0.016096035227933375, 0.01677565480832883, 0.015384103616375154, 0.016525865969686446, 0.014430449396563908, 0.01618249063655948, 0.015454939117091747, 0.017158536308532625, 0.015981824512968767, 0.014774197205696853, 0.01623465174721082, 0.01951290092961742, 0.015410299756964192, 0.013270530677356068, 0.016253115422647, 0.015218776607016656, 0.015158805340060453, 0.01600354183771504, 0.01571331061627209, 0.016652339510378807, 0.01629923321081866, 0.016882190594863927, 0.014286840916105006, 0.018402614453934256, 0.01614927487812048, 0.014929991688040994, 0.01574418344840972, 0.017676033820704956, 0.013666318022089596, 0.013473049597846334, 0.01403786478627578, 0.015009466141666592, 0.01649046730619243, 0.01715774817594294, 0.013655352427534634, 0.015067784643321614, 0.014540124049435348, 0.016557807040963383, 0.01452411824642745, 0.013882693904234097, 0.014962666113355044, 0.015077130437705125, 0.0128984098514413, 0.013680126536700194, 0.015055994805274444, 0.015452391346985303, 0.012043980361491522, 0.015030503721840444, 0.014640087092636356, 0.01307625842166841, 0.01351730070870636, 0.01599685737552017, 0.013464913502509394, 0.011971579697413009, 0.012097438193698495, 0.011742592861697482, 0.014249579203216726, 0.015484303631167224, 0.015511922876692345, 0.016594660111193704, 0.014049123714537573, 0.012013560331334463, 0.013862264281819438, 0.014286024976573265, 0.011790696257504611, 0.012461459553370968, 0.011978600769812353, 0.012057729960116512, 0.014472885768593256, 0.014878065912982942, 0.012751299968883493, 0.015549249567559391, 0.01416354930374207, 0.013871517724835351, 0.011274673540426805, 0.010325461816434322, 0.01285014332814343, 0.012315051454283911, 0.013807288733633346, 0.012684381821099943, 0.01274357905096417, 0.013863050084830448, 0.014591788524098178, 0.016278181469519325, 0.01267214893651713, 0.00945183983797065, 0.015402097960784717, 0.011929560858129492, 0.011164720238413778, 0.01048103835768554, 0.012490515216447807, 0.011621606825487199, 0.014135825430136242, 0.013545311871374945, 0.009862323518223573, 0.01090861356571768, 0.014716036951813727, 0.010142131451183107, 0.01348015314982315, 0.01131801328296006, 0.011657232424521614, 0.012205106285584875, 0.013775786494472135, 0.012936543056172662, 0.012450280802219046, 0.012644299819203855, 0.01381613924432766, 0.009734139554019068, 0.010955332397688911, 0.012106359150999484, 0.00991233201777848, 0.0087861028373728, 0.012734965916181977, 0.011248826197483087, 0.01193378481913822, 0.008804902109254234, 0.010323021790315615, 0.010367730927524358, 0.009720381773908313, 0.007006315055282528, 0.009644650822595139, 0.012827408651805644, 0.00952771496253284, 0.010651927316831959, 0.007356770075184298, 0.01176060843239645, 0.010529908538804528, 0.013985879961884511, 0.009876921186640221, 0.011575881876243962, 0.010931818285635648, 0.011179214108567264, 0.00892361035583492, 0.008703862090170022, 0.009842892087058358, 0.0074651694311325045, 0.008836722464933548, 0.011095288986949727, 0.01274921984586214, 0.012392985774684541, 0.010214889923224975, 0.007896449686302607, 0.008876659074518756, 0.011298688843145027, 0.011899555488066132, 0.010698760636124134, 0.00913104304988013, 0.009215538958712409, 0.011550778035904687, 0.012802989366284953, 0.011076890415618585, 0.00784615176797028, 0.010030318013379025, 0.008437997928178833, 0.011023274802557364, 0.008086884043898042, 0.008787058637158663, 0.007876242128551291, 0.0114338284248543, 0.009456423423264533, 0.0073215096573071995, 0.01062239951014697, 0.009040345969201748, 0.007032412478308348, 0.009294655444228757, 0.011368375554555409, 0.010773631290222739, 0.013558074774632558, 0.009557619345574291, 0.011527380499102721], "accuracy_test_std": 0.009721110286973101, "error_valid": [0.6497758612575302, 0.5724318171121988, 0.5502753200301205, 0.5595203077936747, 0.5295601350715362, 0.4618817065135542, 0.4281785344503012, 0.40304087443524095, 0.48494417121611444, 0.4610786897590362, 0.3391642742846386, 0.36978627400225905, 0.3847906273531627, 0.34268519390060237, 0.40661326948418675, 0.37986810523343373, 0.3925325324736446, 0.33273572806852414, 0.2832340102597892, 0.32143319371234935, 0.31264413121234935, 0.2810573348079819, 0.27703930958207834, 0.24111828172063254, 0.2730212843561747, 0.29660144484186746, 0.25689623729292166, 0.3288191829819277, 0.3299487010542168, 0.24690706184111444, 0.26233939664909633, 0.33252247270331325, 0.29527926157756024, 0.23384406767695776, 0.3236216349774097, 0.2799792921686747, 0.25914497835090367, 0.23904308640813254, 0.29137301157756024, 0.28485180958207834, 0.21437311746987953, 0.2550754776920181, 0.2268257600715362, 0.2133156650037651, 0.29039497835090367, 0.23874747035015065, 0.21501435429216864, 0.21384365587349397, 0.23925634177334332, 0.26155549934111444, 0.45977709666792166, 0.28727262565888556, 0.31625623588102414, 0.2225415333207832, 0.2252785556287651, 0.23425145896084332, 0.2401711337537651, 0.2279641025037651, 0.3069171216114458, 0.22910391566265065, 0.32401726044804224, 0.22350780073418675, 0.2625732421875, 0.2761539321347892, 0.2236004565135542, 0.21250088243599397, 0.21005947618599397, 0.24730268731174698, 0.20210431570030118, 0.22914362528237953, 0.19767889919051207, 0.2516457431287651, 0.2150952442582832, 0.20536932887801207, 0.23630606410015065, 0.22131053510918675, 0.20998888130647586, 0.20981533556099397, 0.2678928605045181, 0.21694688911897586, 0.25479015672063254, 0.19819806570030118, 0.2354103915662651, 0.2039147802146084, 0.21933829066265065, 0.24834102033132532, 0.1919210043298193, 0.20826960184487953, 0.20303969785391573, 0.20175869493599397, 0.2103139118975903, 0.23503388554216864, 0.1943624105798193, 0.2030602880271084, 0.2114831395896084, 0.1888692465173193, 0.19730239316641573, 0.19328436794051207, 0.1913415380271084, 0.28223685758659633, 0.2578522096197289, 0.1903840949736446, 0.2145863728350903, 0.21769990116716864, 0.18653961549322284, 0.1805684652673193, 0.18498358669051207, 0.1895810782191265, 0.22858474915286142, 0.21335684535015065, 0.19802599068147586, 0.20776073042168675, 0.2170998446912651, 0.2027661426957832, 0.17564447242093373, 0.17745493693524095, 0.19027231974774095, 0.2339764330760542, 0.20974474068147586, 0.1959096150225903, 0.19931728868599397, 0.18143325254141573, 0.309704148625753, 0.24458772590361444, 0.20949030496987953, 0.1732236563441265, 0.23292780496987953, 0.1909753270896084, 0.1762048192771084, 0.17848297486822284, 0.1859704442771084, 0.24327436699924698, 0.22216649802334332, 0.20549286991716864, 0.17506500611822284, 0.17576654273343373, 0.22634777390813254, 0.1792256918298193, 0.21910444512424698, 0.1947286215173193, 0.21169786568147586, 0.18620428981551207, 0.30265495576054224, 0.2538547745670181, 0.2487984163215362, 0.22239004847515065, 0.19455654649849397, 0.16932770143072284, 0.18273484563253017, 0.19687588243599397, 0.18055817018072284, 0.16927622599774095, 0.21103750941265065, 0.1844541250941265, 0.20819900696536142, 0.17650925969503017, 0.17319277108433728, 0.18883983198418675, 0.1742208090173193, 0.15738393025225905, 0.17296922063253017, 0.2031632388930723, 0.16881883000753017, 0.19650967149849397, 0.17972426816641573, 0.19149449359939763, 0.17683576101280118, 0.21198318665286142, 0.17933746705572284, 0.19833043109939763, 0.18216567441641573, 0.1716882177146084, 0.1759797980986446, 0.17398696347891573, 0.18727203736822284, 0.16937917686370485, 0.1731015860316265, 0.18283779649849397, 0.1957875447100903, 0.2506603562688253, 0.17668280544051207, 0.1640169074736446, 0.16613328313253017, 0.20150425922439763, 0.19100621234939763, 0.1904164509600903, 0.17147349162274095, 0.21420986681099397, 0.1834775625941265, 0.19571547910391573, 0.17282656014683728, 0.16886001035391573, 0.16942918157003017, 0.16380365210843373, 0.17459731504141573, 0.17250152955572284, 0.17638718938253017, 0.1708028402673193, 0.18010077419051207, 0.1717794027673193, 0.15941941594503017, 0.18452619070030118, 0.19333584337349397, 0.1601106574736446, 0.16672304452183728, 0.19039586078689763, 0.17771084337349397, 0.19044733621987953, 0.21597032661897586, 0.1998673404555723], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.062338619170028524, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.00022597500832117107, "optimization": "rmsprop", "nb_data_augmentation": 1, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.172798562252263e-06, "rotation_range": [0, 0], "momentum": 0.9266780043154264}, "accuracy_valid_max": 0.842616069747741, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8001326595444277, "accuracy_valid_std": [0.012603340060512815, 0.014073912546104373, 0.012988864997722503, 0.018438998130793565, 0.026327223761534558, 0.013766467542501224, 0.009374176353199698, 0.01365256186865386, 0.011511935791440978, 0.012224970148307134, 0.016650377800370864, 0.007456728464566045, 0.013316004875719208, 0.014963892015588884, 0.010499939301755976, 0.01078562344681024, 0.013281936196517359, 0.011433436879802427, 0.01739887108127585, 0.017914050308773147, 0.01333315428176243, 0.011013578867292338, 0.015302605405973405, 0.012769415546358645, 0.011826859085582364, 0.012094544603534079, 0.012967185253199799, 0.014004961979952019, 0.015602814817777257, 0.011362182620971235, 0.014608742316572117, 0.010320505929963215, 0.012740626429006858, 0.013552851317710276, 0.011556069404440487, 0.009867724955824626, 0.012236139967157663, 0.010537594231173685, 0.009637158034032853, 0.011851571227985238, 0.013849079424997735, 0.010442450814001854, 0.007495159979919081, 0.008791553596321326, 0.020817526692710215, 0.013035436494456093, 0.012986008359434184, 0.017802559032344976, 0.013186426530502083, 0.01491090945938637, 0.01660046899539482, 0.014022040222665965, 0.009393782030352198, 0.016948749707891803, 0.014495293832846942, 0.009413691084011386, 0.018292182702020595, 0.01579916040745194, 0.00788137591751716, 0.014217790186537843, 0.015870695716162297, 0.01950417601118144, 0.008767844124929461, 0.010712038688890344, 0.010776167868517861, 0.01826314080847039, 0.01655119259099258, 0.015847298865319628, 0.015742286324483573, 0.02052643825611223, 0.01883313619199909, 0.02411569648647544, 0.018156107113747703, 0.01950951877740379, 0.015634573886813833, 0.017242710945490722, 0.013659042440731923, 0.01762517935550624, 0.015602775723730646, 0.017423743082257064, 0.016359544055936703, 0.016765795442364072, 0.020544647996085342, 0.020769751135283517, 0.01175990386003273, 0.013806606583897709, 0.01859834828177038, 0.012021128795125728, 0.020473798736151204, 0.014200989853416564, 0.017406982907620244, 0.018674199934937238, 0.020032993402276163, 0.021558865508092655, 0.021069537020102124, 0.017641885498900847, 0.01974664840165365, 0.01587402359948908, 0.014794896131851669, 0.01656902394453584, 0.012967626287409786, 0.024454154857711845, 0.017761453256288074, 0.014924314677451348, 0.017031894493385772, 0.016081899284456965, 0.013261823291433767, 0.01891871285604314, 0.013116383859617456, 0.010983704819049223, 0.00869474083193076, 0.016124309805090456, 0.01518490879652318, 0.012482976153486926, 0.018650855223476263, 0.018961511325634863, 0.02376830638498957, 0.01670764480863425, 0.010745917532599562, 0.013436942187315934, 0.016557526072249352, 0.014485832966844366, 0.014488098882850662, 0.01188282919942232, 0.014641745050898674, 0.01653337078849587, 0.019376264593598133, 0.01396369564321742, 0.011747908239462363, 0.015529722426656189, 0.015988293227387613, 0.01993978457103316, 0.007950179555436641, 0.011099019350113062, 0.014227460841836135, 0.019239673321434364, 0.016067879546771018, 0.016834185557680043, 0.013008354962616394, 0.01786814323931702, 0.013929957617555761, 0.014827963232587114, 0.011665606184297675, 0.013292463566572736, 0.01290117323862644, 0.013517808257016154, 0.013365428829052431, 0.013758616980371922, 0.020967462434335955, 0.013740528631910765, 0.014639936714079073, 0.016148615591829254, 0.012391348204320186, 0.017169656241186767, 0.012759419284016662, 0.016522695395670712, 0.0169484651079735, 0.012874448397900515, 0.013387029315986725, 0.017356887610266308, 0.016139887008277946, 0.013171447933332995, 0.014862094198609909, 0.014114907226164803, 0.013792602791585938, 0.016991059559215232, 0.01588615179481875, 0.012431649986038918, 0.016763210817289566, 0.01884676433632917, 0.01380337628488374, 0.010982048106761537, 0.021542328068477137, 0.012324766604212885, 0.019490662674164726, 0.012600916066053635, 0.01638721180740569, 0.013601371404464194, 0.014845167147570252, 0.011385885813161922, 0.010317122128003415, 0.017854899218030136, 0.015551172968526577, 0.013881446828740662, 0.012150657657374393, 0.014400076214182135, 0.0188632843300725, 0.017708630153389037, 0.019764940027517327, 0.017692448014003232, 0.017752240201222184, 0.012017032748119659, 0.015417867586605016, 0.01445064016348525, 0.01571050887530599, 0.011477716293292336, 0.018008417030271152, 0.016478540683231603, 0.014935380832014868, 0.012165104760760903, 0.012414354748152464, 0.014385039316929365, 0.015748544335517853, 0.016235915782009402, 0.015107325335639878, 0.016501666799557838, 0.017835122745656178, 0.012496538606338797, 0.015117524543606072, 0.01450657312037568], "accuracy_valid": [0.3502241387424699, 0.4275681828878012, 0.4497246799698795, 0.4404796922063253, 0.47043986492846385, 0.5381182934864458, 0.5718214655496988, 0.596959125564759, 0.5150558287838856, 0.5389213102409638, 0.6608357257153614, 0.630213725997741, 0.6152093726468373, 0.6573148060993976, 0.5933867305158133, 0.6201318947665663, 0.6074674675263554, 0.6672642719314759, 0.7167659897402108, 0.6785668062876506, 0.6873558687876506, 0.7189426651920181, 0.7229606904179217, 0.7588817182793675, 0.7269787156438253, 0.7033985551581325, 0.7431037627070783, 0.6711808170180723, 0.6700512989457832, 0.7530929381588856, 0.7376606033509037, 0.6674775272966867, 0.7047207384224398, 0.7661559323230422, 0.6763783650225903, 0.7200207078313253, 0.7408550216490963, 0.7609569135918675, 0.7086269884224398, 0.7151481904179217, 0.7856268825301205, 0.7449245223079819, 0.7731742399284638, 0.7866843349962349, 0.7096050216490963, 0.7612525296498494, 0.7849856457078314, 0.786156344126506, 0.7607436582266567, 0.7384445006588856, 0.5402229033320783, 0.7127273743411144, 0.6837437641189759, 0.7774584666792168, 0.7747214443712349, 0.7657485410391567, 0.7598288662462349, 0.7720358974962349, 0.6930828783885542, 0.7708960843373494, 0.6759827395519578, 0.7764921992658133, 0.7374267578125, 0.7238460678652108, 0.7763995434864458, 0.787499117564006, 0.789940523814006, 0.752697312688253, 0.7978956842996988, 0.7708563747176205, 0.8023211008094879, 0.7483542568712349, 0.7849047557417168, 0.7946306711219879, 0.7636939358998494, 0.7786894648908133, 0.7900111186935241, 0.790184664439006, 0.7321071394954819, 0.7830531108810241, 0.7452098432793675, 0.8018019342996988, 0.7645896084337349, 0.7960852197853916, 0.7806617093373494, 0.7516589796686747, 0.8080789956701807, 0.7917303981551205, 0.7969603021460843, 0.798241305064006, 0.7896860881024097, 0.7649661144578314, 0.8056375894201807, 0.7969397119728916, 0.7885168604103916, 0.8111307534826807, 0.8026976068335843, 0.8067156320594879, 0.8086584619728916, 0.7177631424134037, 0.7421477903802711, 0.8096159050263554, 0.7854136271649097, 0.7823000988328314, 0.8134603845067772, 0.8194315347326807, 0.8150164133094879, 0.8104189217808735, 0.7714152508471386, 0.7866431546498494, 0.8019740093185241, 0.7922392695783133, 0.7829001553087349, 0.7972338573042168, 0.8243555275790663, 0.822545063064759, 0.809727680252259, 0.7660235669239458, 0.7902552593185241, 0.8040903849774097, 0.800682711314006, 0.8185667474585843, 0.690295851374247, 0.7554122740963856, 0.7905096950301205, 0.8267763436558735, 0.7670721950301205, 0.8090246729103916, 0.8237951807228916, 0.8215170251317772, 0.8140295557228916, 0.756725633000753, 0.7778335019766567, 0.7945071300828314, 0.8249349938817772, 0.8242334572665663, 0.7736522260918675, 0.8207743081701807, 0.780895554875753, 0.8052713784826807, 0.7883021343185241, 0.8137957101844879, 0.6973450442394578, 0.7461452254329819, 0.7512015836784638, 0.7776099515248494, 0.805443453501506, 0.8306722985692772, 0.8172651543674698, 0.803124117564006, 0.8194418298192772, 0.830723774002259, 0.7889624905873494, 0.8155458749058735, 0.7918009930346386, 0.8234907403049698, 0.8268072289156627, 0.8111601680158133, 0.8257791909826807, 0.842616069747741, 0.8270307793674698, 0.7968367611069277, 0.8311811699924698, 0.803490328501506, 0.8202757318335843, 0.8085055064006024, 0.8231642389871988, 0.7880168133471386, 0.8206625329442772, 0.8016695689006024, 0.8178343255835843, 0.8283117822853916, 0.8240202019013554, 0.8260130365210843, 0.8127279626317772, 0.8306208231362951, 0.8268984139683735, 0.817162203501506, 0.8042124552899097, 0.7493396437311747, 0.8233171945594879, 0.8359830925263554, 0.8338667168674698, 0.7984957407756024, 0.8089937876506024, 0.8095835490399097, 0.828526508377259, 0.785790133189006, 0.8165224374058735, 0.8042845208960843, 0.8271734398531627, 0.8311399896460843, 0.8305708184299698, 0.8361963478915663, 0.8254026849585843, 0.8274984704442772, 0.8236128106174698, 0.8291971597326807, 0.8198992258094879, 0.8282205972326807, 0.8405805840549698, 0.8154738092996988, 0.806664156626506, 0.8398893425263554, 0.8332769554781627, 0.8096041392131024, 0.822289156626506, 0.8095526637801205, 0.7840296733810241, 0.8001326595444277], "seed": 850301588, "model": "residualv3", "loss_std": [0.4101450443267822, 0.10632991045713425, 0.09180813282728195, 0.08821744471788406, 0.0893918126821518, 0.08847218751907349, 0.09095200896263123, 0.08719900250434875, 0.08593018352985382, 0.08624971657991409, 0.0872817113995552, 0.0827489048242569, 0.08303728699684143, 0.08303552120923996, 0.08549655973911285, 0.08186326920986176, 0.08102516084909439, 0.08492319285869598, 0.08273962885141373, 0.07818014174699783, 0.07894802838563919, 0.0791369080543518, 0.08108841627836227, 0.07774940878152847, 0.07574588060379028, 0.07693248242139816, 0.07607366889715195, 0.07329007238149643, 0.07516497373580933, 0.07360228896141052, 0.07293137162923813, 0.07131193578243256, 0.07069610059261322, 0.07217881083488464, 0.07309422641992569, 0.0724806934595108, 0.0654163733124733, 0.0692150741815567, 0.06914674490690231, 0.06617560237646103, 0.06857343018054962, 0.06487934291362762, 0.0640321671962738, 0.06537777930498123, 0.06233111023902893, 0.06352182477712631, 0.06378874182701111, 0.061043351888656616, 0.062485743314027786, 0.06165508180856705, 0.061247289180755615, 0.05761365592479706, 0.05902034044265747, 0.0611337274312973, 0.05844757705926895, 0.057959698140621185, 0.05779099464416504, 0.0570656955242157, 0.056836146861314774, 0.055407632142305374, 0.05361836031079292, 0.05694460868835449, 0.05328243598341942, 0.053802490234375, 0.05312717333436012, 0.05348554626107216, 0.05250587314367294, 0.05094467103481293, 0.05413023754954338, 0.05356374382972717, 0.05063421651721001, 0.049471765756607056, 0.04944869130849838, 0.05127314478158951, 0.048443861305713654, 0.049360983073711395, 0.04989885538816452, 0.04673612490296364, 0.04747982323169708, 0.04759419709444046, 0.04717603698372841, 0.045030150562524796, 0.045943483710289, 0.047205742448568344, 0.047252584248781204, 0.047549355775117874, 0.046124234795570374, 0.04493056982755661, 0.046597424894571304, 0.046143289655447006, 0.04592433199286461, 0.047204699367284775, 0.04528004676103592, 0.045102525502443314, 0.04310028627514839, 0.04299578443169594, 0.045155443251132965, 0.043394140899181366, 0.041125454008579254, 0.04298293963074684, 0.045039065182209015, 0.04296739399433136, 0.040986016392707825, 0.042965736240148544, 0.040595587342977524, 0.04127363860607147, 0.04056956619024277, 0.040155354887247086, 0.041642170399427414, 0.04232891649007797, 0.03991638869047165, 0.04075171798467636, 0.041669465601444244, 0.040034666657447815, 0.039688024669885635, 0.042336054146289825, 0.04022662714123726, 0.04018302261829376, 0.040897663682699203, 0.04023924842476845, 0.04058584198355675, 0.0409814827144146, 0.04310189187526703, 0.03752472996711731, 0.038808077573776245, 0.03871916979551315, 0.03726434335112572, 0.03919234499335289, 0.03777206316590309, 0.0389627069234848, 0.03872928395867348, 0.03727128729224205, 0.038360029458999634, 0.03747301176190376, 0.037656303495168686, 0.03631899505853653, 0.03540007397532463, 0.03848631680011749, 0.04040495306253433, 0.03617490455508232, 0.03487919270992279, 0.03692205250263214, 0.03592174872756004, 0.037301816046237946, 0.03652060404419899, 0.03528781235218048, 0.03618299588561058, 0.03649533540010452, 0.03615715354681015, 0.03486588969826698, 0.03497918322682381, 0.03566405922174454, 0.037039563059806824, 0.036337338387966156, 0.03578215464949608, 0.035392895340919495, 0.034162238240242004, 0.03325371816754341, 0.03587296977639198, 0.03542785719037056, 0.033269938081502914, 0.03392164036631584, 0.033987078815698624, 0.03512221574783325, 0.034249693155288696, 0.03406703844666481, 0.03514751046895981, 0.03492693230509758, 0.032246630638837814, 0.033361632376909256, 0.03243996948003769, 0.035696692764759064, 0.03383539989590645, 0.03420421481132507, 0.03324500843882561, 0.033052220940589905, 0.03323540464043617, 0.03351718187332153, 0.03392678499221802, 0.03137378767132759, 0.033435650169849396, 0.03434450551867485, 0.03334541246294975, 0.03150921314954758, 0.0331156849861145, 0.033446382731199265, 0.032900724560022354, 0.032700687646865845, 0.031695183366537094, 0.030908646062016487, 0.03327910229563713, 0.03181534260511398, 0.032881058752536774, 0.03177972137928009, 0.031031064689159393, 0.03198675438761711, 0.029661012813448906, 0.03206478804349899, 0.03258728235960007, 0.03270145133137703, 0.029420463368296623, 0.029788143932819366, 0.03155294433236122, 0.031172050163149834, 0.031194690614938736, 0.032254304736852646, 0.032878678292036057, 0.031275369226932526, 0.030533749610185623, 0.033606722950935364]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:23 2016", "state": "available"}], "summary": "dc9390e9a8821dcaae31068b0ab72972"}