{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 16, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.6420949697494507, 1.3263843059539795, 1.182886004447937, 1.0773495435714722, 0.9959146976470947, 0.9266998767852783, 0.8663701415061951, 0.8138365149497986, 0.7670247554779053, 0.7266862392425537, 0.6942416429519653, 0.6599922180175781, 0.6335132718086243, 0.6073991060256958, 0.5887824296951294, 0.5664777159690857, 0.5466820001602173, 0.5286977291107178, 0.5115232467651367, 0.4960455596446991, 0.4820474088191986, 0.46789267659187317, 0.45502567291259766, 0.44201862812042236, 0.4305056929588318, 0.42505520582199097, 0.40746620297431946, 0.3967233896255493, 0.38874417543411255, 0.3787626326084137, 0.3706401586532593, 0.36013010144233704, 0.3558470904827118, 0.34432047605514526, 0.3362199664115906, 0.32632818818092346, 0.31868353486061096, 0.31493401527404785, 0.3086487054824829, 0.29942426085472107, 0.2920163571834564, 0.2865159809589386, 0.2798658013343811, 0.27401411533355713, 0.26947933435440063, 0.2623346149921417, 0.25731953978538513, 0.25152844190597534, 0.24636410176753998, 0.24035538733005524, 0.2423066794872284, 0.23404140770435333, 0.22909866273403168, 0.22623631358146667, 0.21723273396492004, 0.21869739890098572, 0.21169160306453705, 0.20983071625232697, 0.20615331828594208, 0.20392511785030365, 0.20068734884262085, 0.19248268008232117, 0.19076073169708252, 0.19009019434452057, 0.18224449455738068, 0.18107779324054718, 0.1801716536283493, 0.17317746579647064, 0.17351607978343964, 0.16910997033119202, 0.1665029376745224, 0.16327378153800964, 0.16030801832675934, 0.15681865811347961, 0.15415698289871216, 0.15177027881145477, 0.15262432396411896, 0.15238453447818756, 0.1448521614074707, 0.14644524455070496, 0.143107071518898, 0.14251692593097687, 0.1386333853006363, 0.13744351267814636, 0.1338135302066803, 0.1313720941543579, 0.13090761005878448, 0.1297793686389923, 0.12883242964744568, 0.1340785175561905, 0.12357494980096817, 0.1218184307217598, 0.11966528743505478, 0.12093852460384369, 0.11627263575792313, 0.11238950490951538, 0.11326571553945541, 0.11281600594520569, 0.10935068130493164, 0.11108852177858353, 0.10791533440351486, 0.10662679374217987, 0.10953400284051895, 0.10318055003881454, 0.10253381729125977, 0.10127424448728561, 0.10273569822311401, 0.09851524233818054, 0.09472320973873138, 0.09923581779003143, 0.097603440284729, 0.09702562540769577, 0.09711191803216934, 0.09325776994228363, 0.0876225158572197, 0.09202823042869568, 0.09012711048126221, 0.08976887911558151, 0.08694609999656677, 0.08494392037391663, 0.08685129135847092, 0.0839536190032959, 0.08405310660600662, 0.08554781228303909, 0.08506422489881516, 0.08443385362625122, 0.0790926143527031, 0.07904621213674545, 0.0799594596028328, 0.0806427150964737, 0.07676148414611816, 0.0766778513789177, 0.07893560826778412, 0.07360219210386276, 0.07535938173532486, 0.07510679215192795, 0.07221148908138275, 0.07148584723472595, 0.07083924114704132, 0.07327742129564285, 0.07072291523218155, 0.07279013097286224, 0.07213561981916428, 0.06943812966346741, 0.06693360954523087, 0.06902477890253067, 0.06845812499523163, 0.06525478512048721, 0.06673873960971832, 0.06393446028232574, 0.06841909140348434, 0.0652497336268425, 0.06842562556266785, 0.07215271145105362, 0.06072006747126579, 0.06334094703197479, 0.06189047917723656, 0.064817413687706, 0.060611575841903687, 0.06310800462961197, 0.061365339905023575, 0.06357832998037338, 0.056741394102573395, 0.05898670852184296, 0.05947154760360718, 0.05589894577860832, 0.06039983034133911, 0.05797839164733887, 0.05745096877217293, 0.05675840005278587, 0.057165488600730896, 0.056415922939777374, 0.0556943379342556, 0.05394437909126282, 0.057523854076862335, 0.05726680904626846, 0.0529240220785141, 0.052970655262470245, 0.051785387098789215, 0.05550838261842728, 0.051996730268001556, 0.05362590774893761, 0.054445959627628326, 0.05398547649383545, 0.051395393908023834, 0.0529884472489357, 0.05071232095360756, 0.0512281097471714, 0.048937033861875534, 0.053310371935367584, 0.050191186368465424, 0.05119230970740318, 0.0499260239303112, 0.050014644861221313, 0.04653137922286987, 0.05201907828450203, 0.049669049680233, 0.04862163960933685, 0.05706975981593132, 0.04616228863596916, 0.0468083992600441, 0.04463767260313034, 0.047734830528497696, 0.04915720224380493, 0.05025719478726387, 0.04511313512921333, 0.04539944976568222, 0.045786503702402115, 0.04371646046638489, 0.04608098417520523, 0.04293578490614891, 0.04378128796815872, 0.04626160487532616, 0.043978121131658554, 0.04448901116847992, 0.04510534182190895, 0.041642554104328156, 0.04453535005450249, 0.04420194402337074, 0.043069988489151, 0.043418701738119125, 0.04248151555657387, 0.04347345232963562, 0.04044969752430916, 0.04244919493794441, 0.042310554534196854, 0.04247404634952545, 0.038852863013744354, 0.040831249207258224, 0.03990708291530609, 0.04001852124929428, 0.04397963732481003, 0.04156510904431343, 0.039109449833631516, 0.04020817205309868, 0.043150611221790314, 0.04181886091828346, 0.04290961101651192, 0.03683823347091675, 0.03907854110002518], "moving_avg_accuracy_train": [0.04554112160852712, 0.09659440320459578, 0.14792356208471757, 0.19870442174810812, 0.24730121263900418, 0.29326749327040647, 0.3360737633635854, 0.37645469495335276, 0.41561053085784216, 0.4513273305313787, 0.4855276294434494, 0.5166658271857048, 0.5451783782572782, 0.570616315740705, 0.5953774097745618, 0.6178971262883386, 0.6396458467471293, 0.6603448148421193, 0.6787669839323813, 0.6953491891647893, 0.712137726926282, 0.7266104643330908, 0.740314547012231, 0.7524436443770378, 0.7630625734459324, 0.7739166100578269, 0.7839338897358759, 0.7932819377258818, 0.8038455470286905, 0.8108465733751017, 0.8188302559462294, 0.8271061731983672, 0.834268613568176, 0.840947108489044, 0.8475274874737959, 0.8539613252493491, 0.8594935795830335, 0.864821236609503, 0.8690116252916682, 0.874133778417494, 0.8765303548081642, 0.8797008942454448, 0.884044547784171, 0.887644555128539, 0.8909940600254305, 0.8946224176695282, 0.8977203485908367, 0.9013803451259482, 0.9042628988147192, 0.9073708747774241, 0.9093266016165422, 0.9102823263812907, 0.913330191357595, 0.9151270784660677, 0.9182994048802583, 0.9203105417328101, 0.9230366014334217, 0.9239024111128924, 0.9252349170946264, 0.9280242858733512, 0.9291699996182881, 0.9310821570946284, 0.9339863832744697, 0.93607252225184, 0.9375340980362998, 0.9386586016982014, 0.9393802276856348, 0.9412665260457166, 0.9432336234411449, 0.9443813398507219, 0.94620683592402, 0.9472524354388532, 0.9480863379128711, 0.9498947207501831, 0.9514036827144782, 0.9526991497085804, 0.9539253796770449, 0.955168567674872, 0.9562897259729071, 0.9571685240589867, 0.9572248395079237, 0.9574289111357581, 0.9579845273126955, 0.9592657597743015, 0.9596888804100128, 0.9598208620107151, 0.9607813132715761, 0.9610227958183111, 0.9613888314877259, 0.962485418502067, 0.963379340862593, 0.9634049821846948, 0.9641859857888536, 0.9639427697600329, 0.9649793114959622, 0.96586794913328, 0.9656889074556939, 0.9649327481435409, 0.9649357624637844, 0.9657892274745581, 0.9650230722093374, 0.9653214323241364, 0.9653621278929408, 0.9661101773429417, 0.9669787703967612, 0.9677513116964169, 0.96890214778868, 0.9697472380693358, 0.9698010461814682, 0.9703446941299974, 0.9700762311134999, 0.9706947392140823, 0.9708725053951105, 0.9715531119984565, 0.9718401731569534, 0.9721497896198663, 0.9726608511709841, 0.9728279099146276, 0.9731038568684399, 0.9737427620292334, 0.9739388495156327, 0.9744338015426594, 0.9744911027110679, 0.9748144998804372, 0.9749430492579343, 0.9750562383047784, 0.9753627575909949, 0.9759664348819138, 0.9765655119663507, 0.9767256460375727, 0.9769790486957202, 0.9772210980297288, 0.9770995067529648, 0.9774923067467344, 0.9779364714958797, 0.9781757845022534, 0.9784749076139513, 0.9789347806168603, 0.978686034957583, 0.9787690474582716, 0.9790390712088916, 0.9791890505832497, 0.9788637246535239, 0.9787429923286753, 0.9789737328648647, 0.9790419264676824, 0.9794659878756853, 0.9792291896083734, 0.9798484383927833, 0.9804359531844574, 0.9805368891160117, 0.9808371390425427, 0.9812281275192407, 0.9815009620887453, 0.980811911526327, 0.9809962314594269, 0.9814411372563598, 0.9820345037759712, 0.982415037773374, 0.9825994803496265, 0.9827189396432445, 0.9824358280075007, 0.9824507087484173, 0.9819619774188414, 0.9813268427710418, 0.9818083698034613, 0.9823510982243242, 0.9824024258269102, 0.9826462222692284, 0.982589018456619, 0.9828769346538234, 0.9831105186432214, 0.9835973648443754, 0.983324139036156, 0.9830549122230259, 0.9829335879269414, 0.9835032313663902, 0.9836928589726451, 0.9837425079337232, 0.9840035029356167, 0.9845429208337309, 0.9840984455646804, 0.9832380023094305, 0.9831541365273154, 0.9830461052400785, 0.982825716292298, 0.9829273464845428, 0.9832488952432499, 0.9828407444832291, 0.983531315458725, 0.9834878007283286, 0.9835021519424098, 0.9838219876779399, 0.9835844643554209, 0.9836890945567837, 0.9835414823106383, 0.9839759315498126, 0.9841832851579358, 0.9844256709278565, 0.9841091059922321, 0.9842659037263422, 0.984583732996565, 0.9842607705957642, 0.9846140625088253, 0.9841181510496094, 0.9833464180494381, 0.9829098777695036, 0.9833121924104196, 0.9835464645003577, 0.9836945664122635, 0.983553490573455, 0.983363635154214, 0.9836601922852488, 0.982638961262704, 0.9831566871602431, 0.9837923763311236, 0.984308765111125, 0.9847340956298205, 0.9851143877037433, 0.9852427729286163, 0.9857443303822017, 0.9862655226035331, 0.9864299650598648, 0.9863128963062777, 0.9858680266530402, 0.9861488765174982, 0.9853787561634135, 0.9851971084851951, 0.9853451234176372, 0.9854760117080257, 0.9859262714003184, 0.9859177007329241, 0.9862099313286978, 0.9865426572803611, 0.986814172802325, 0.987207346295902, 0.9871589877448924, 0.9869969545573356, 0.9865186284087726, 0.9868879139679045], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.04425225315323794, 0.09402742316923944, 0.1438027505529932, 0.19326583722585655, 0.24089246674687032, 0.28555292592685194, 0.3271807093883836, 0.36627233818599103, 0.40374472550820517, 0.4380355155703365, 0.47078843403401066, 0.5004816691791789, 0.5270427713689417, 0.550555079322409, 0.573392637796418, 0.5938090745532972, 0.6130993949782385, 0.6315259306780804, 0.647642857094459, 0.6620442575672421, 0.676512130379795, 0.6889991950620715, 0.700071655309253, 0.7102739506687645, 0.7192098168500056, 0.728080262593469, 0.7359211503495589, 0.7435557978334283, 0.7518440257025704, 0.7567296591357019, 0.7629355759405052, 0.7691444891672378, 0.7737934521010411, 0.7783112266198526, 0.7829703677474005, 0.7871849202987147, 0.7906829898275781, 0.7943358587194438, 0.7968819003418518, 0.8004916971770191, 0.8010415838410943, 0.8022465486685811, 0.8051092726138465, 0.8074171694770853, 0.8093397032823888, 0.8112520596672523, 0.8127605133390813, 0.8150387965307755, 0.8167770161340986, 0.8185855544020894, 0.8195642071697118, 0.8195354972961141, 0.8215930897916532, 0.8226727915429095, 0.82497611903395, 0.8265415660066845, 0.8281997564504437, 0.828447893098321, 0.8291106692064106, 0.8305871034623509, 0.8306320969941279, 0.8318291706154983, 0.8340562039022166, 0.835341201452507, 0.8364275455862473, 0.8363736876296557, 0.8360647497778346, 0.8369496092785904, 0.8381233712893609, 0.8388766403351235, 0.8404620208234486, 0.8410240759888447, 0.8414394759483186, 0.8425956154205049, 0.8436259929315417, 0.8446917280698635, 0.8454870507448049, 0.8460288541887733, 0.8466385476008448, 0.8473256670500977, 0.8467507269452386, 0.8467999518316636, 0.8475818236477441, 0.8485470034817649, 0.8488814974106969, 0.8484511495803952, 0.8493130717552624, 0.8492504875183656, 0.849332557083547, 0.8499700021470298, 0.8503250056503239, 0.8501073994282884, 0.8502167296097065, 0.8503293928215522, 0.8508702428372132, 0.8516510061099678, 0.8515947981006275, 0.8512705086614232, 0.85089113993007, 0.8515609797209486, 0.8511353563817603, 0.8512141035466716, 0.851071279411884, 0.8517332532685119, 0.8529648248731366, 0.8536226086697084, 0.8545553814529634, 0.855065287114143, 0.8548720820096564, 0.8550674968790973, 0.8549189279611424, 0.855477928190254, 0.8556707050719063, 0.8560711373885109, 0.8562809240638164, 0.8563934013581125, 0.8565109559888675, 0.8565099804012759, 0.8571815185998531, 0.8573768938953648, 0.8573859512584638, 0.8575049956751626, 0.8574778583064415, 0.8574879967510233, 0.8574930033165084, 0.8576969397600834, 0.8575122126044817, 0.8582360419370305, 0.8587237964594419, 0.8583662299723832, 0.8582763537277804, 0.8587377220259361, 0.8587246778918666, 0.8588939846226347, 0.8591785790067568, 0.8593380872111263, 0.8592873616037184, 0.85997824846669, 0.8597495254178373, 0.8596036803214603, 0.8597022943111516, 0.859295706163922, 0.8589124222568671, 0.8585796737717678, 0.8593117678121363, 0.8595759094138292, 0.8595094905827626, 0.8594619206660525, 0.8598097327410136, 0.8603242531604363, 0.8603538983922089, 0.8606054532066024, 0.8612286545915144, 0.8613153735638389, 0.8605724610192019, 0.8604663926751883, 0.8604462323703954, 0.8611025633408107, 0.861453238623823, 0.8618979761789858, 0.8617967221887227, 0.8615204291114167, 0.8615179649841606, 0.8610477620474914, 0.8602583684669893, 0.8607747944214952, 0.8614094467093909, 0.8613061585237681, 0.8617167759639365, 0.8613131706566994, 0.8618583937359843, 0.8621893735924311, 0.8625238765569831, 0.8622491397390107, 0.8618289191480163, 0.8617111863070098, 0.8621413066164444, 0.8623117768584144, 0.8618619080016392, 0.8624000559627705, 0.863106174707608, 0.8628240952168924, 0.8623066694583809, 0.8619498200483109, 0.8616805722302268, 0.8611442509352915, 0.8609952696482381, 0.8611092980768631, 0.8606911393535142, 0.8617899353390964, 0.861563149071753, 0.8614302246013248, 0.861698276124626, 0.8613891765806875, 0.8618576749147121, 0.8617960426359668, 0.8623428361509846, 0.862464621342362, 0.8624989268097825, 0.8617109011280512, 0.8617270404015412, 0.8617140631592034, 0.8609526071915511, 0.8612245928014622, 0.8611439080412708, 0.86039578700371, 0.8600398608824054, 0.8605425460102792, 0.8607375854604562, 0.8607147199396364, 0.8605822186723294, 0.8604232579120242, 0.860873337288367, 0.8598318019876177, 0.8606116406612204, 0.8616827949309417, 0.8622876823241428, 0.8628016369362316, 0.8627809153077439, 0.8622688370488069, 0.862669665363881, 0.8629174590402188, 0.8632625436614227, 0.8632954466277353, 0.8630422385613472, 0.8635366251626673, 0.862868674242786, 0.8625981377673025, 0.8623759804758886, 0.8624588596496853, 0.8631855711056504, 0.8635557611712902, 0.8638024535029564, 0.8642442031639559, 0.8638330252703766, 0.8642127416157035, 0.8643174051894494, 0.8645580867808207, 0.863819463249576, 0.8643714342344829], "moving_var_accuracy_train": [0.018665943816263908, 0.04025728749018487, 0.05994370170323347, 0.07715759290628682, 0.09069666637969948, 0.10064309033749298, 0.10707017213735538, 0.11103873164813706, 0.11373347385173704, 0.11384133447683921, 0.11298414504023015, 0.11041201676392925, 0.1066875052050181, 0.10184255265521287, 0.09717630338947306, 0.09202291173727357, 0.08707768213789782, 0.08222593944588473, 0.07705773232720811, 0.07182668486781454, 0.06718071138255467, 0.062347781396717206, 0.05780322019573587, 0.05334693320212695, 0.0490270947730462, 0.04518467629269267, 0.041569321692757684, 0.03819886353449301, 0.035383285754565175, 0.032286086508236944, 0.029631130543982004, 0.027284434746861902, 0.025017696240635327, 0.02291734726624432, 0.02101532502786657, 0.019286340941779136, 0.01763315938971436, 0.016125298815268144, 0.014670803149509897, 0.01343985090835857, 0.012147558023089578, 0.011023273103690789, 0.0100907517279021, 0.009198317031027426, 0.008379457975413378, 0.007659996990613387, 0.006980371875490845, 0.0064028948596750205, 0.005837387415625344, 0.005340584305325573, 0.004840949682016236, 0.004365075402248195, 0.004012173190247418, 0.0036400151007480344, 0.0033665864845767715, 0.0030663298790763243, 0.0028265795045903774, 0.0025506681917409255, 0.0023115815222890454, 0.002150448573713667, 0.0019472176562103374, 0.0017854030065182194, 0.00168277347319948, 0.0015536639083756649, 0.0014175233515015713, 0.001287151592722085, 0.0011631231300415306, 0.0010788339105666025, 0.001005775768977851, 0.0009170534686913747, 0.000855340045044877, 0.0007796455456491629, 0.0007079395311098064, 0.0006665778143753873, 0.0006204127288250525, 0.0005734755685378213, 0.0005296607711040855, 0.0004906043415751487, 0.00045285687078091137, 0.00041452175838769384, 0.00037309812541702533, 0.0003361631199389058, 0.00030532519196968506, 0.00028956668235877446, 0.0002622212937741791, 0.00023615593668307672, 0.00022084254263517332, 0.00019928311275505442, 0.00018056064048110404, 0.0001733271041531876, 0.000163186268417705, 0.00014687355887252663, 0.00013767590265265518, 0.00012444069871746772, 0.00012166639777862826, 0.0001166068496548849, 0.00010523466799021176, 9.985719333939193e-05, 8.98715557805915e-05, 8.744002292406609e-05, 8.397896564548763e-05, 7.638223790386478e-05, 6.875891927736123e-05, 6.691922916644433e-05, 6.701739128809182e-05, 6.568703269634678e-05, 7.10381428280102e-05, 7.036192678733946e-05, 6.335179192498687e-05, 5.967659055994694e-05, 5.43575830249938e-05, 5.2364795156869563e-05, 4.741272297723842e-05, 4.684047881617935e-05, 4.289806791301975e-05, 3.947102230867867e-05, 3.78745752590896e-05, 3.433829534763055e-05, 3.15897863047318e-05, 3.2104605914655915e-05, 2.924019804409188e-05, 2.85209758212025e-05, 2.5698429054191047e-05, 2.4069857711177218e-05, 2.1811596422153474e-05, 1.974574262286736e-05, 1.8616755015984743e-05, 2.003491595852769e-05, 2.1261464540551634e-05, 1.9366104373391878e-05, 1.800741010045865e-05, 1.6733960011259036e-05, 1.5193623957398895e-05, 1.5062888077607573e-05, 1.5332140189296693e-05, 1.431436260554333e-05, 1.3688198068555428e-05, 1.4222726870941167e-05, 1.3357323810931171e-05, 1.2083611107273425e-05, 1.1531465429635433e-05, 1.05807632012677e-05, 1.0475219526108853e-05, 9.558884221867887e-06, 9.082166555049473e-06, 8.215803206731864e-06, 9.012675585875269e-06, 8.616068801905345e-06, 1.1205683434654022e-05, 1.3191677765110812e-05, 1.1964202549108266e-05, 1.1579132459634243e-05, 1.1797067113867273e-05, 1.1287308723330876e-05, 1.4431693949118168e-05, 1.3294289093848434e-05, 1.3746330697764112e-05, 1.5540452067348718e-05, 1.5289661969228594e-05, 1.406686734771762e-05, 1.2788615318431277e-05, 1.2231123571229885e-05, 1.1010004142158936e-05, 1.2058728540524758e-05, 1.4483419873992042e-05, 1.5121892433150645e-05, 1.6260690439145625e-05, 1.4658332100316139e-05, 1.3727429237867681e-05, 1.2384136799674406e-05, 1.1891784749221136e-05, 1.1193659595226891e-05, 1.220746664790734e-05, 1.1658591063610793e-05, 1.114507964942385e-05, 1.0163047947864889e-05, 1.2067185986041075e-05, 1.1184095048923125e-05, 1.0087870718055982e-05, 9.692149165370688e-06, 1.1341679268087359e-05, 1.1985535724455838e-05, 1.745024551155525e-05, 1.5768522185087673e-05, 1.4296706797777456e-05, 1.3304177712733692e-05, 1.206671820524198e-05, 1.1790588822752096e-05, 1.2110813326626982e-05, 1.5191726443739775e-05, 1.3689595585218968e-05, 1.2322489642807494e-05, 1.2010894758025806e-05, 1.1317561240887332e-05, 1.028433242813334e-05, 9.452003562228612e-06, 1.0205518478777613e-05, 9.571926300115288e-06, 9.143491423244254e-06, 9.131062507121344e-06, 8.43922602120785e-06, 8.504442424181024e-06, 8.592740592742268e-06, 8.856803115977269e-06, 1.0184476382814045e-05, 1.452617515651391e-05, 1.4788664384910805e-05, 1.4766511579078152e-05, 1.378381113028609e-05, 1.2602837604049188e-05, 1.152167537430391e-05, 1.0693913558810193e-05, 1.0416037390637819e-05, 1.876064886424531e-05, 1.9296944922665022e-05, 2.1004156928170658e-05, 2.1303657584355047e-05, 2.080144627712402e-05, 2.002290020280757e-05, 1.816895507621802e-05, 1.861609848181986e-05, 1.9199260617824458e-05, 1.7522706449041995e-05, 1.5893781641735662e-05, 1.608558455290772e-05, 1.518691591491105e-05, 1.9005992561398786e-05, 1.7402356216278205e-05, 1.5859296376682933e-05, 1.4427552440061732e-05, 1.4809401310586895e-05, 1.3329122286584464e-05, 1.2764798547882086e-05, 1.2484677723285885e-05, 1.1899696058963225e-05, 1.2100995017530971e-05, 1.0911942460879554e-05, 1.0057040999619912e-05, 1.1110500039250046e-05, 1.1226796452975757e-05], "duration": 100984.224948, "accuracy_train": [0.4554112160852713, 0.5560739375692137, 0.609885992005814, 0.6557321587186231, 0.684672330657069, 0.706964018953027, 0.7213301942021964, 0.7398830792612587, 0.7680130539982466, 0.7727785275932078, 0.7933303196520857, 0.7969096068660022, 0.8017913379014396, 0.7995577530915466, 0.8182272560792728, 0.8205745749123293, 0.8353843308762459, 0.8466355276970285, 0.8445665057447398, 0.84458903625646, 0.8632345667797158, 0.8568651009943706, 0.8636512911244923, 0.8616055206602989, 0.8586329350659838, 0.8716029395648762, 0.8740894068383168, 0.8774143696359358, 0.8989180307539681, 0.8738558104928018, 0.8906833990863787, 0.901589428467608, 0.8987305768964563, 0.9010535627768549, 0.9067508983365633, 0.9118658652293282, 0.9092838685861941, 0.9127701498477298, 0.9067251234311554, 0.9202331565499261, 0.8980995423241971, 0.9082357491809707, 0.9231374296327058, 0.9200446212278516, 0.921139604097453, 0.9272776364664084, 0.9256017268826136, 0.9343203139419527, 0.9302058820136582, 0.9353426584417681, 0.9269281431686047, 0.9188838492640274, 0.9407609761443337, 0.931299062442322, 0.9468503426079733, 0.9384107734057769, 0.9475711387389257, 0.9316946982281286, 0.9372274709302326, 0.9531286048818751, 0.9394814233227206, 0.9482915743816908, 0.9601244188930418, 0.9548477730481728, 0.9506882800964378, 0.9487791346553157, 0.945874861572536, 0.9582432112864526, 0.9609375, 0.954710787536914, 0.9626363005837025, 0.9566628310723514, 0.955591460179033, 0.9661701662859912, 0.9649843403931341, 0.9643583526555003, 0.9649614493932264, 0.9663572596553157, 0.9663801506552234, 0.9650777068337025, 0.9577316785483574, 0.959265555786268, 0.9629850729051311, 0.970796851928756, 0.9634969661314139, 0.9610086964170359, 0.9694253746193245, 0.9631961387389257, 0.9646831525124585, 0.972354701631137, 0.9714246421073275, 0.9636357540836102, 0.9712150182262828, 0.961753825500646, 0.9743081871193245, 0.97386568786914, 0.9640775323574198, 0.9581273143341639, 0.9649628913459765, 0.9734704125715209, 0.9581276748223514, 0.9680066733573275, 0.9657283880121816, 0.9728426223929494, 0.974796107881137, 0.9747041833933187, 0.9792596726190477, 0.9773530505952381, 0.9702853191906607, 0.9752375256667589, 0.9676600639650241, 0.9762613121193245, 0.9724724010243633, 0.9776785714285714, 0.9744237235834257, 0.9749363377860835, 0.9772604051310447, 0.9743314386074198, 0.9755873794527501, 0.979492908476375, 0.9757036368932264, 0.9788883697858989, 0.9750068132267442, 0.9777250744047619, 0.976099993655408, 0.976074939726375, 0.9781214311669435, 0.9813995305001846, 0.9819572057262828, 0.9781668526785714, 0.9792596726190477, 0.9793995420358066, 0.9760051852620893, 0.9810275066906607, 0.9819339542381875, 0.9803296015596161, 0.9811670156192323, 0.9830736376430418, 0.9764473240240864, 0.9795161599644703, 0.9814692849644703, 0.9805388649524732, 0.9759357912859912, 0.9776564014050388, 0.9810503976905685, 0.9796556688930418, 0.9832825405477114, 0.9770980052025655, 0.9854216774524732, 0.9857235863095238, 0.9814453125, 0.9835393883813216, 0.9847470238095238, 0.9839564732142857, 0.9746104564645626, 0.9826551108573275, 0.985445289428756, 0.9873748024524732, 0.98583984375, 0.9842594635358989, 0.9837940732858066, 0.9798878232858066, 0.9825846354166666, 0.9775633954526578, 0.9756106309408453, 0.9861421130952381, 0.9872356540120893, 0.9828643742501846, 0.9848403902500923, 0.9820741841431341, 0.9854681804286637, 0.9852127745478036, 0.9879789806547619, 0.9808651067621816, 0.9806318709048542, 0.9818416692621816, 0.9886300223214286, 0.9853995074289406, 0.9841893485834257, 0.9863524579526578, 0.9893976819167589, 0.9800981681432264, 0.9754940130121816, 0.9823993444882798, 0.9820738236549464, 0.9808422157622739, 0.9838420182147471, 0.9861428340716132, 0.9791673876430418, 0.9897464542381875, 0.9830961681547619, 0.98363131286914, 0.9867005092977114, 0.9814467544527501, 0.9846307663690477, 0.9822129720953304, 0.9878859747023809, 0.9860494676310447, 0.9866071428571429, 0.9812600215716132, 0.9856770833333334, 0.9874441964285714, 0.9813541089885567, 0.987793689726375, 0.9796549479166666, 0.9764008210478959, 0.9789810152500923, 0.9869330241786637, 0.9856549133098007, 0.9850274836194168, 0.9822838080241787, 0.9816549363810447, 0.9863292064645626, 0.9734478820598007, 0.9878162202380952, 0.9895135788690477, 0.988956264131137, 0.9885620702980805, 0.9885370163690477, 0.9863982399524732, 0.9902583474644703, 0.990956252595515, 0.9879099471668512, 0.9852592775239941, 0.9818641997739018, 0.9886765252976191, 0.9784476729766519, 0.9835622793812293, 0.9866772578096161, 0.9866540063215209, 0.9899786086309523, 0.985840564726375, 0.9888400066906607, 0.9895371908453304, 0.9892578125, 0.9907459077380952, 0.9867237607858066, 0.9855386558693245, 0.9822136930717055, 0.9902114840000923], "end": "2016-02-01 02:40:19.439000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0], "moving_var_accuracy_valid": [0.01762435718224432, 0.038160029415116585, 0.056642275419043736, 0.07299742036600407, 0.08611234088519074, 0.09545211632417291, 0.10150275589503716, 0.10510587928398281, 0.10723290966021885, 0.10709234324196343, 0.1060378919287599, 0.10336929665636019, 0.09938179633653939, 0.09441907433057357, 0.08967115359100028, 0.08445551624052912, 0.07935901277534839, 0.07447894645889146, 0.069368849667001, 0.06429856772049818, 0.05975258504193023, 0.05518066759715142, 0.05076599522076499, 0.04662617717411287, 0.042682206796383, 0.03912214938593424, 0.03576325013457321, 0.032711515700942474, 0.030058616621745644, 0.02726757968595747, 0.024887442347854987, 0.022745653544183345, 0.020665603897003906, 0.018782736086728924, 0.017099830842473702, 0.015549709837096432, 0.014104867267245658, 0.012814471600791534, 0.011591365392199689, 0.01054950455170037, 0.009497275474620285, 0.008560615389277583, 0.007778310545830986, 0.007048416982630017, 0.006376840510459829, 0.005772070421898401, 0.00521534227202905, 0.004740523213540156, 0.004293663558690529, 0.003893734498822559, 0.003512980900096478, 0.0031616902283984082, 0.0028836243874578605, 0.002605753751557069, 0.002392926234180203, 0.0021756892287821757, 0.001982866665833929, 0.0017851341454147142, 0.0016105741803983322, 0.0014691354853675238, 0.0013222401565918874, 0.001202913008227525, 0.0011272588027461318, 0.0010293938908097894, 0.0009370757939210175, 0.0008433943206443097, 0.0007599138719464687, 0.0006909692717765203, 0.0006342717999202199, 0.0005759513482259363, 0.0005409770950381969, 0.0004897225396149134, 0.0004423032997904008, 0.0004101028961236838, 0.0003786477068485701, 0.00035100505862919584, 0.00032159739618175924, 0.0002920796153106465, 0.000266217188290092, 0.00024384466769895684, 0.0002224352060466404, 0.0002002134932469683, 0.00018569405575330245, 0.00017550879918597543, 0.00015896489496380878, 0.00014473519876283567, 0.00013694786740630081, 0.00012328833174604225, 0.00011102011729319976, 0.00010357513144450526, 9.435186568621385e-05, 8.534285132840915e-05, 7.691614399268855e-05, 6.933876658715003e-05, 6.503755858340008e-05, 6.402012431780209e-05, 5.7646545948847725e-05, 5.282836411737806e-05, 4.88408134145968e-05, 4.799490018213491e-05, 4.4825807205677055e-05, 4.039903652894349e-05, 3.65427214773497e-05, 3.683233381134372e-05, 4.6800017986070396e-05, 4.6014131894756026e-05, 4.9243304291913094e-05, 4.665900791244851e-05, 4.2329061032800695e-05, 3.8439837670308385e-05, 3.47945084137182e-05, 3.412738887766842e-05, 3.1049116324797885e-05, 2.9387319053949654e-05, 2.684468119077645e-05, 2.42740733472883e-05, 2.197103783346702e-05, 1.9773942616060658e-05, 2.18552203237897e-05, 2.0013241846277186e-05, 1.8012655984086244e-05, 1.633893454400204e-05, 1.4711669020631771e-05, 1.3241427211095429e-05, 1.1917510081267488e-05, 1.1100069730303168e-05, 1.029717985542316e-05, 1.3982821993803356e-05, 1.4725680061618095e-05, 1.440379618946344e-05, 1.303611622461219e-05, 1.3648250961038623e-05, 1.2284957209837372e-05, 1.1314444410604264e-05, 1.0911945640808225e-05, 1.0049736882078065e-05, 9.067920979092278e-06, 1.2457050798022777e-05, 1.1682173815908907e-05, 1.0705393563553251e-05, 9.722376677863481e-06, 1.0237964303285716e-05, 1.053632685362224e-05, 1.0479188157283329e-05, 1.4254924497041356e-05, 1.345736911904173e-05, 1.2151335357219902e-05, 1.0956567894280066e-05, 1.0949670260250252e-05, 1.2237284592251798e-05, 1.1021465690928304e-05, 1.0488837543636748e-05, 1.293537348467968e-05, 1.1709517757660809e-05, 1.5505837422704655e-05, 1.4056508122850205e-05, 1.2654515251569278e-05, 1.5265996810948654e-05, 1.4846155516895636e-05, 1.5141663401956466e-05, 1.3719768396658507e-05, 1.3034832338097621e-05, 1.1731403751596069e-05, 1.2548080591306427e-05, 1.6901552556618035e-05, 1.7611659199342066e-05, 1.9475545018188643e-05, 1.7624006559973067e-05, 1.7379066043509597e-05, 1.7107234635427635e-05, 1.8071925027548805e-05, 1.7250661513155542e-05, 1.653262546148713e-05, 1.5558685787684865e-05, 1.559208531477788e-05, 1.415762597996313e-05, 1.4406894707259517e-05, 1.3227746167109426e-05, 1.3726409445064249e-05, 1.4960197553185439e-05, 1.7951610934163716e-05, 1.6872569392488783e-05, 1.7594877193380936e-05, 1.6981462987248717e-05, 1.593576617641131e-05, 1.6930954341380145e-05, 1.543761772227048e-05, 1.4010878292855571e-05, 1.4183500924785514e-05, 2.363132439369326e-05, 2.1731080053823778e-05, 1.9716992281989258e-05, 1.839195762608742e-05, 1.7412644616045606e-05, 1.7646796355295685e-05, 1.5916303559816164e-05, 1.7015521536424052e-05, 1.5447454078331217e-05, 1.3913300456352498e-05, 1.8110830686329416e-05, 1.6302091903035557e-05, 1.4673398392100259e-05, 1.842439526894948e-05, 1.724774129004326e-05, 1.5581557435783238e-05, 1.9060567473774484e-05, 1.8294661360840318e-05, 1.8739426264826928e-05, 1.7207847122471965e-05, 1.549176789860598e-05, 1.4100600381287072e-05, 1.2917957053009714e-05, 1.3449304352790525e-05, 2.1867535961874863e-05, 2.5154117577305022e-05, 3.296504904545472e-05, 3.296154296699088e-05, 3.204273275987735e-05, 2.8842323956874224e-05, 2.831810885067073e-05, 2.693226800909015e-05, 2.4791656562478183e-05, 2.3384241468354133e-05, 2.10555607682482e-05, 1.9527033615378857e-05, 1.977409325792451e-05, 2.1812109814463147e-05, 2.0289608694119727e-05, 1.8704832583863336e-05, 1.6896169942519986e-05, 1.9959538810347586e-05, 1.919695109159826e-05, 1.782496994096443e-05, 1.7798757813806927e-05, 1.7540487373941184e-05, 1.70840991627221e-05, 1.5474279419473302e-05, 1.4448200133351304e-05, 1.7913462608191997e-05, 1.88641640609842e-05], "accuracy_test": 0.7208785076530612, "start": "2016-01-30 22:37:15.214000", "learning_rate_per_epoch": [0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214, 0.00031542108627036214], "accuracy_train_first": 0.4554112160852713, "accuracy_train_last": 0.9902114840000923, "batch_size_eval": 1024, "accuracy_train_std": [0.01639915150785039, 0.018810789766075378, 0.017733492907213197, 0.015686376664555, 0.01607968670039196, 0.015071190986321696, 0.015149520507948886, 0.01545430820414127, 0.016131923122090535, 0.01380192049899453, 0.01469939017437746, 0.015603034002952218, 0.015423927059314859, 0.015092574191588905, 0.01382886659547427, 0.012272836152961906, 0.014522344155674959, 0.012960077060898556, 0.0130703863942794, 0.013858756412698488, 0.01313631926142514, 0.012071461101468365, 0.01383208108530007, 0.013061523867725248, 0.012216429414291128, 0.013029984218520321, 0.012750345791065702, 0.012850392674784048, 0.013011769479708788, 0.012763173390442117, 0.01390830895424612, 0.010150422513022062, 0.013200397029943838, 0.013977166400778791, 0.01164338779673107, 0.01218409323183198, 0.01226738377342092, 0.013672776618466163, 0.012606444949793455, 0.01226380871836107, 0.012902101632702041, 0.013449995989179583, 0.0128558442718806, 0.01308469570835277, 0.011951031381752878, 0.01162625962930702, 0.013606101176624403, 0.012267496634946059, 0.011432638684094163, 0.012249003888553517, 0.012487311196944677, 0.012243109242123025, 0.011665942784518652, 0.011703784749243256, 0.011723080597139236, 0.0120293268481458, 0.011281360461920435, 0.01213774027544303, 0.011145160381037082, 0.011919231628370998, 0.011807324625220963, 0.011198666496727306, 0.0119510155673289, 0.011209722779995468, 0.010144724611036503, 0.012671985237630344, 0.010033995943194056, 0.010503071970364576, 0.011238048199300407, 0.01111632027693048, 0.010801080841601548, 0.011396040467997635, 0.012332394078005507, 0.009714698664111197, 0.010573797699861767, 0.010478535657156705, 0.010139632404506662, 0.010377272159957734, 0.009997796946629061, 0.010089344963767571, 0.0103781086364987, 0.010074753099775258, 0.009990132231267714, 0.009534117033630975, 0.00967235469675054, 0.011873464845107293, 0.008893503392899186, 0.008794860817686982, 0.00882559205658399, 0.010293671892051073, 0.009073409876403307, 0.009238133565944827, 0.009885022063422087, 0.009165066207784973, 0.007952023801820661, 0.008786978781788904, 0.010809550740995886, 0.008751998063291714, 0.009402367127563635, 0.009323869486208714, 0.010058303774443427, 0.009125459790355037, 0.009181181030868844, 0.009428804461282622, 0.007701012399973155, 0.00830295671383736, 0.008108604359701302, 0.00779282217461497, 0.009364343834667003, 0.00816267750648179, 0.00757142099888489, 0.007523307179799125, 0.008088806948134925, 0.007658603936043189, 0.008803552402201579, 0.007803089544538097, 0.007938254546680058, 0.008209960004874426, 0.008075624281761106, 0.007444991367202616, 0.007311810977309067, 0.006903692629879037, 0.007249677794263657, 0.007598079711867598, 0.006803910930050257, 0.007881617758282593, 0.00735692595380414, 0.006736965030223006, 0.00689380026276469, 0.008055256488953742, 0.006526009706727448, 0.006389925126478067, 0.007688814684185889, 0.006171254432765941, 0.006341414382132651, 0.00679880977794748, 0.006120039608648756, 0.006132346610798644, 0.006895619910912058, 0.006274854949635923, 0.007096544898400932, 0.00602623484289499, 0.0062519237432065436, 0.0065022337343029766, 0.006236068029154513, 0.007888969308211459, 0.005743668215798984, 0.006581432427427567, 0.005342878650124602, 0.00571400293528521, 0.0065231924497743555, 0.005678806345472009, 0.005970518543788703, 0.006742771190621971, 0.007354171418862843, 0.005910447980714514, 0.00576226306627869, 0.0051435341186209915, 0.005238400817809066, 0.004612980696853275, 0.006170018736649823, 0.005949166061398874, 0.006653867424060319, 0.00712313480998054, 0.0066115062331929975, 0.004971470480166139, 0.00547337596586472, 0.006427189370705078, 0.005538425507168758, 0.0062217336073388235, 0.006013905816229731, 0.004951697013496524, 0.0051122086170363994, 0.006409748522603414, 0.00721156943723359, 0.005865751756825304, 0.004514682233617301, 0.005199834142286266, 0.0057831499468684955, 0.004614366129963776, 0.004691706950925792, 0.005633037291326019, 0.005780167173924545, 0.00554856543400734, 0.005983111426686387, 0.006022480355389281, 0.0055640515649371496, 0.00461778194981091, 0.007556024846121323, 0.004512471090677654, 0.006423178871753703, 0.005070063336957275, 0.004225323319977611, 0.006022515149452912, 0.005228897292496037, 0.0054779897094691925, 0.004915531762429325, 0.004762640956054396, 0.0051467262125269855, 0.006101272232986836, 0.004265618413492793, 0.0049821162720371515, 0.005751887649836669, 0.004651877228673258, 0.006452905861794546, 0.007611589238308759, 0.006003092783420431, 0.004770513629652461, 0.0050783635875049525, 0.004600879018354369, 0.005358194060965141, 0.006374592556088866, 0.003983227926367998, 0.00752295705861484, 0.004394469737696223, 0.004257054753020211, 0.0038163674126377896, 0.004045719452304481, 0.00530220604665026, 0.004135402809230442, 0.004108387625649133, 0.003866592640210613, 0.004193389528936185, 0.005379137103001931, 0.005354792530967453, 0.004241022987694588, 0.006426159905539239, 0.005907315652995196, 0.004372527041499399, 0.004835370634482929, 0.00398713871072946, 0.004824691526026326, 0.004078988898032891, 0.004369508251285445, 0.004736459961499715, 0.003919238168553282, 0.005199196547778821, 0.0044377161375986065, 0.004887947804176844, 0.004195554299357319], "accuracy_test_std": 0.005748078820683975, "error_valid": [0.5574774684676205, 0.457996046686747, 0.40821930299322284, 0.3615663827183735, 0.33046786756400603, 0.31250294145331325, 0.29816923945783136, 0.28190300263554224, 0.25900378859186746, 0.2533473738704819, 0.23443529979292166, 0.23227921451430722, 0.23390730892319278, 0.23783414909638556, 0.2210693359375, 0.22244299463478923, 0.21328772119728923, 0.20263524802334332, 0.20730480515813254, 0.20834313817771077, 0.19327701430722888, 0.19861722279743976, 0.20027620246611444, 0.19790539109563254, 0.20036738751882532, 0.19208572571536142, 0.19351085984563254, 0.18773237481174698, 0.17356192347515065, 0.19929963996611444, 0.1812111728162651, 0.17497529179216864, 0.18436588149472888, 0.18102880271084332, 0.17509736210466864, 0.17488410673945776, 0.17783438441265065, 0.1727883212537651, 0.18020372505647586, 0.16702013130647586, 0.19400943618222888, 0.1869087678840362, 0.1691262118787651, 0.1718117587537651, 0.17335749246987953, 0.17153673286897586, 0.17366340361445776, 0.16445665474397586, 0.16757900743599397, 0.16513760118599397, 0.17162791792168675, 0.1807228915662651, 0.15988857774849397, 0.1676098926957832, 0.15429393354668675, 0.15936941123870485, 0.15687652955572284, 0.1693188770707832, 0.1649243458207832, 0.15612498823418675, 0.16896296121987953, 0.15739716679216864, 0.1459004965173193, 0.15309382059487953, 0.1537953572100903, 0.16411103397966864, 0.1667156908885542, 0.1550866552146084, 0.15131277061370485, 0.15434393825301207, 0.1452695547816265, 0.1539174275225903, 0.15482192441641573, 0.1469991293298193, 0.1471006094691265, 0.14571665568524095, 0.14735504518072284, 0.14909491481551207, 0.14787421169051207, 0.1464902579066265, 0.15842373399849397, 0.15275702419051207, 0.14538133000753017, 0.14276637801204817, 0.14810805722891573, 0.1554219808923193, 0.14292962867093373, 0.15131277061370485, 0.1499288168298193, 0.1442929922816265, 0.14647996282003017, 0.15185105657003017, 0.14879929875753017, 0.14865663827183728, 0.14426210702183728, 0.14132212443524095, 0.14891107398343373, 0.15164809629141573, 0.1525231786521084, 0.1424104621611446, 0.15269525367093373, 0.1480771719691265, 0.15021413780120485, 0.14230898202183728, 0.13595103068524095, 0.1404573371611446, 0.13704966349774095, 0.14034556193524095, 0.14686676393072284, 0.14317376929593373, 0.14641819230045183, 0.13949106974774095, 0.14259430299322284, 0.14032497176204817, 0.14183099585843373, 0.14259430299322284, 0.14243105233433728, 0.14349879988704817, 0.13677463761295183, 0.14086472844503017, 0.1425325324736446, 0.14142360457454817, 0.14276637801204817, 0.14242075724774095, 0.1424619375941265, 0.14046763224774095, 0.14415033179593373, 0.13524949407003017, 0.1368864128388554, 0.1448518684111446, 0.1425325324736446, 0.13710996329066272, 0.14139271931475905, 0.13958225480045183, 0.1382600715361446, 0.13922633894954817, 0.14116916886295183, 0.13380376976656627, 0.14230898202183728, 0.14170892554593373, 0.1394101797816265, 0.1443635871611446, 0.1445371329066265, 0.1444150625941265, 0.13409938582454817, 0.13804681617093373, 0.14108827889683728, 0.14096620858433728, 0.13705995858433728, 0.13504506306475905, 0.13937929452183728, 0.1371305534638554, 0.13316253294427716, 0.13790415568524095, 0.14611375188253017, 0.14048822242093373, 0.13973521037274095, 0.13299045792545183, 0.13539068382906627, 0.13409938582454817, 0.1391145637236446, 0.14096620858433728, 0.1385042121611446, 0.14318406438253017, 0.14684617375753017, 0.13457737198795183, 0.13287868269954817, 0.13962343514683728, 0.13458766707454817, 0.14231927710843373, 0.13323459855045183, 0.13483180769954817, 0.13446559676204817, 0.14022349162274095, 0.14195306617093373, 0.13934840926204817, 0.1339876105986446, 0.1361539909638554, 0.14218691170933728, 0.13275661238704817, 0.1305387565888554, 0.13971462019954817, 0.14235016236822284, 0.1412618246423193, 0.14074265813253017, 0.1436826407191265, 0.14034556193524095, 0.13786444606551207, 0.1430722891566265, 0.12832090079066272, 0.14047792733433728, 0.13976609563253017, 0.13588926016566272, 0.14139271931475905, 0.13392584007906627, 0.13875864787274095, 0.1327360222138554, 0.13643931193524095, 0.13719232398343373, 0.14538133000753017, 0.13812770613704817, 0.13840273202183728, 0.1459004965173193, 0.13632753670933728, 0.13958225480045183, 0.14633730233433728, 0.14316347420933728, 0.1349332878388554, 0.13750705948795183, 0.13949106974774095, 0.14061029273343373, 0.14100738893072284, 0.13507594832454817, 0.1495420157191265, 0.1323698112763554, 0.12867681664156627, 0.13226833113704817, 0.13257277155496983, 0.1374055793486446, 0.1423398672816265, 0.13372287980045183, 0.13485239787274095, 0.13363169474774095, 0.13640842667545183, 0.1392366340361446, 0.13201389542545183, 0.1431428840361446, 0.13983669051204817, 0.13962343514683728, 0.1367952277861446, 0.13027402579066272, 0.13311252823795183, 0.13397731551204817, 0.13178004988704817, 0.13986757577183728, 0.1323698112763554, 0.13474062264683728, 0.13327577889683728, 0.1428281485316265, 0.1306608269013554], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.058843468702956384, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.0003154210804864718, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 7.901666678571299e-07, "rotation_range": [0, 0], "momentum": 0.7891476866748325}, "accuracy_valid_max": 0.8716790992093373, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8693391730986446, "accuracy_valid_std": [0.012218035741992095, 0.01225298876039987, 0.015375431931069666, 0.013922886024454779, 0.00997691262722767, 0.0146585350767246, 0.016084994198589924, 0.013546723282110611, 0.018094475993657145, 0.0142684888570868, 0.012124966607822056, 0.015975117637435386, 0.015462469718789135, 0.013022698482792923, 0.017324955697711707, 0.020974522811635223, 0.023497249449159683, 0.0127127801000648, 0.01419018387753802, 0.017615100383300962, 0.016682215900848604, 0.012669803960923843, 0.020375859152859402, 0.014518280481565813, 0.01412086435886905, 0.012330312313025577, 0.015954635219821232, 0.01391785647624288, 0.018627746066967613, 0.021367733586339987, 0.013120959096483389, 0.013642315866843821, 0.01797074197449452, 0.018069919178002398, 0.012107764234974124, 0.014564795805005942, 0.018366593713914383, 0.015063169421579937, 0.012054821336031639, 0.013528133529397161, 0.017163036783818537, 0.017707954246048964, 0.016027908590393138, 0.01738147939504178, 0.013650297017961423, 0.01252020161283168, 0.017112949674461562, 0.012363640348539883, 0.010798750059641546, 0.009214534204158251, 0.011866335987016629, 0.01279194860152113, 0.014496319632751211, 0.013502939350778927, 0.014247624690996937, 0.01379483330236916, 0.013833703091172335, 0.012085719366203066, 0.015116311164458518, 0.016090364722323194, 0.009694292944265007, 0.017972267227148925, 0.012467543314902138, 0.01425477895830033, 0.012223366207026083, 0.01491137133616446, 0.01851852666563526, 0.01304582586727833, 0.010015570243741534, 0.01089464911293812, 0.012702023387165974, 0.014694141533833669, 0.008323553962547477, 0.010850172053190365, 0.011604381797614586, 0.006864093545406539, 0.008350348197748577, 0.009541444232141984, 0.011813256541392033, 0.009849549423727908, 0.010575721629894346, 0.012894694492314429, 0.010792872831868411, 0.012151057835456407, 0.011162286314715756, 0.012461666748308536, 0.011064403123871629, 0.01343206201167363, 0.011284780885109431, 0.006619103314123898, 0.010898425407320137, 0.015967469476734046, 0.008417785186938838, 0.011288511363967664, 0.009857484496718047, 0.007740708665654939, 0.009046672429335106, 0.007030517545635071, 0.01106756548986566, 0.010022349002875363, 0.007480044494468282, 0.010297570459123663, 0.009773843435413244, 0.00812883262700075, 0.01068350380468139, 0.007851469538558229, 0.01157792109770515, 0.00809763398981169, 0.008329855099369813, 0.011161270760175895, 0.011561016103784271, 0.007758327069267207, 0.006303753202511949, 0.005902689933373835, 0.010020453480524282, 0.010354214713049072, 0.006401216084173868, 0.009933551756093836, 0.012026814875501205, 0.010616310865236357, 0.011460746820262751, 0.009073882290155455, 0.009781255352789125, 0.00906060431472728, 0.005202909396431629, 0.010537729194394135, 0.008076909304658594, 0.009209839109775858, 0.010313055381018501, 0.011142456162558396, 0.012127833437958565, 0.01225739807373828, 0.011826389135471595, 0.012513756816669006, 0.007360261508294032, 0.008552721393666675, 0.009438134590792128, 0.010700327557677938, 0.011981817812243672, 0.009702190909866173, 0.011430413016861605, 0.00929088050700357, 0.0043673480040245976, 0.00967295558000773, 0.007507563753644272, 0.007976617101158526, 0.0131577515418818, 0.006177418928248841, 0.004427972802556895, 0.009868953732463753, 0.006282273428819865, 0.009487105809873638, 0.016465313756581633, 0.007771263429568409, 0.0065164099248052896, 0.008480782639740813, 0.0067928033848139195, 0.007240630804484947, 0.010230360140335924, 0.009721650383102824, 0.008633182887583211, 0.0057371853617303225, 0.006114507471544545, 0.008527420784562487, 0.008040086399958582, 0.009088620474026763, 0.007632406374783672, 0.008908124099351537, 0.0084591767350615, 0.006960502875239453, 0.006805863046392784, 0.008980248655487038, 0.011213364787621681, 0.008417420680812254, 0.007426860174453764, 0.007002692889281956, 0.006576377721104029, 0.010017296214655092, 0.010187573546693675, 0.009591199754835031, 0.01040428877178829, 0.006966153748496736, 0.006393566461660145, 0.006730336844953764, 0.0068080913917746766, 0.011309596039754531, 0.007453730335254152, 0.011067728387296779, 0.009380508143305273, 0.010630765096135987, 0.00896969263938871, 0.00930775111011875, 0.010124323351686058, 0.013350987649569306, 0.011364033643645317, 0.008012056510311744, 0.00916994001426495, 0.009159288408755234, 0.006780354872527849, 0.008309079775984362, 0.00849043403788457, 0.005220994079603579, 0.006550272282357697, 0.0075657421379177895, 0.008240291150253659, 0.008702964564451356, 0.009347973338232504, 0.008065505212592618, 0.007210852660598505, 0.007524317924383635, 0.004888846724536341, 0.007305039935255092, 0.007810417531221327, 0.007861048012782338, 0.00919204666321396, 0.008295290527877298, 0.006396480208864086, 0.01053891474377879, 0.008467219373870658, 0.0080063155078156, 0.006070227358569027, 0.0023964880503624646, 0.009325112066840065, 0.009092935589359709, 0.00641478569579115, 0.006842064311482707, 0.008871243738897172, 0.008399402214905769, 0.005520766817537878, 0.009201992448946511, 0.007317737006130552, 0.006236805015974181, 0.009123950078402034, 0.007969325337192298, 0.008047592508305333, 0.0053129028967913725, 0.0045232224028185115, 0.00620532866458714, 0.0077486919631612385, 0.0056900160123677795], "accuracy_valid": [0.4425225315323795, 0.542003953313253, 0.5917806970067772, 0.6384336172816265, 0.669532132435994, 0.6874970585466867, 0.7018307605421686, 0.7180969973644578, 0.7409962114081325, 0.7466526261295181, 0.7655647002070783, 0.7677207854856928, 0.7660926910768072, 0.7621658509036144, 0.7789306640625, 0.7775570053652108, 0.7867122788027108, 0.7973647519766567, 0.7926951948418675, 0.7916568618222892, 0.8067229856927711, 0.8013827772025602, 0.7997237975338856, 0.8020946089043675, 0.7996326124811747, 0.8079142742846386, 0.8064891401543675, 0.812267625188253, 0.8264380765248494, 0.8007003600338856, 0.8187888271837349, 0.8250247082078314, 0.8156341185052711, 0.8189711972891567, 0.8249026378953314, 0.8251158932605422, 0.8221656155873494, 0.8272116787462349, 0.8197962749435241, 0.8329798686935241, 0.8059905638177711, 0.8130912321159638, 0.8308737881212349, 0.8281882412462349, 0.8266425075301205, 0.8284632671310241, 0.8263365963855422, 0.8355433452560241, 0.832420992564006, 0.834862398814006, 0.8283720820783133, 0.8192771084337349, 0.840111422251506, 0.8323901073042168, 0.8457060664533133, 0.8406305887612951, 0.8431234704442772, 0.8306811229292168, 0.8350756541792168, 0.8438750117658133, 0.8310370387801205, 0.8426028332078314, 0.8540995034826807, 0.8469061794051205, 0.8462046427899097, 0.8358889660203314, 0.8332843091114458, 0.8449133447853916, 0.8486872293862951, 0.8456560617469879, 0.8547304452183735, 0.8460825724774097, 0.8451780755835843, 0.8530008706701807, 0.8528993905308735, 0.854283344314759, 0.8526449548192772, 0.8509050851844879, 0.8521257883094879, 0.8535097420933735, 0.841576266001506, 0.8472429758094879, 0.8546186699924698, 0.8572336219879518, 0.8518919427710843, 0.8445780191076807, 0.8570703713290663, 0.8486872293862951, 0.8500711831701807, 0.8557070077183735, 0.8535200371799698, 0.8481489434299698, 0.8512007012424698, 0.8513433617281627, 0.8557378929781627, 0.858677875564759, 0.8510889260165663, 0.8483519037085843, 0.8474768213478916, 0.8575895378388554, 0.8473047463290663, 0.8519228280308735, 0.8497858621987951, 0.8576910179781627, 0.864048969314759, 0.8595426628388554, 0.862950336502259, 0.859654438064759, 0.8531332360692772, 0.8568262307040663, 0.8535818076995482, 0.860508930252259, 0.8574056970067772, 0.8596750282379518, 0.8581690041415663, 0.8574056970067772, 0.8575689476656627, 0.8565012001129518, 0.8632253623870482, 0.8591352715549698, 0.8574674675263554, 0.8585763954254518, 0.8572336219879518, 0.857579242752259, 0.8575380624058735, 0.859532367752259, 0.8558496682040663, 0.8647505059299698, 0.8631135871611446, 0.8551481315888554, 0.8574674675263554, 0.8628900367093373, 0.858607280685241, 0.8604177451995482, 0.8617399284638554, 0.8607736610504518, 0.8588308311370482, 0.8661962302334337, 0.8576910179781627, 0.8582910744540663, 0.8605898202183735, 0.8556364128388554, 0.8554628670933735, 0.8555849374058735, 0.8659006141754518, 0.8619531838290663, 0.8589117211031627, 0.8590337914156627, 0.8629400414156627, 0.864954936935241, 0.8606207054781627, 0.8628694465361446, 0.8668374670557228, 0.862095844314759, 0.8538862481174698, 0.8595117775790663, 0.860264789627259, 0.8670095420745482, 0.8646093161709337, 0.8659006141754518, 0.8608854362763554, 0.8590337914156627, 0.8614957878388554, 0.8568159356174698, 0.8531538262424698, 0.8654226280120482, 0.8671213173004518, 0.8603765648531627, 0.8654123329254518, 0.8576807228915663, 0.8667654014495482, 0.8651681923004518, 0.8655344032379518, 0.859776508377259, 0.8580469338290663, 0.8606515907379518, 0.8660123894013554, 0.8638460090361446, 0.8578130882906627, 0.8672433876129518, 0.8694612434111446, 0.8602853798004518, 0.8576498376317772, 0.8587381753576807, 0.8592573418674698, 0.8563173592808735, 0.859654438064759, 0.8621355539344879, 0.8569277108433735, 0.8716790992093373, 0.8595220726656627, 0.8602339043674698, 0.8641107398343373, 0.858607280685241, 0.8660741599209337, 0.861241352127259, 0.8672639777861446, 0.863560688064759, 0.8628076760165663, 0.8546186699924698, 0.8618722938629518, 0.8615972679781627, 0.8540995034826807, 0.8636724632906627, 0.8604177451995482, 0.8536626976656627, 0.8568365257906627, 0.8650667121611446, 0.8624929405120482, 0.860508930252259, 0.8593897072665663, 0.8589926110692772, 0.8649240516754518, 0.8504579842808735, 0.8676301887236446, 0.8713231833584337, 0.8677316688629518, 0.8674272284450302, 0.8625944206513554, 0.8576601327183735, 0.8662771201995482, 0.865147602127259, 0.866368305252259, 0.8635915733245482, 0.8607633659638554, 0.8679861045745482, 0.8568571159638554, 0.8601633094879518, 0.8603765648531627, 0.8632047722138554, 0.8697259742093373, 0.8668874717620482, 0.8660226844879518, 0.8682199501129518, 0.8601324242281627, 0.8676301887236446, 0.8652593773531627, 0.8667242211031627, 0.8571718514683735, 0.8693391730986446], "seed": 654069860, "model": "residualv3", "loss_std": [0.2777838408946991, 0.1045248880982399, 0.10007265955209732, 0.09823142737150192, 0.09598679095506668, 0.09281769394874573, 0.09197719395160675, 0.08939597755670547, 0.09069069474935532, 0.0847906768321991, 0.0888277217745781, 0.08426037430763245, 0.08271235227584839, 0.08040232956409454, 0.0825246274471283, 0.07724189758300781, 0.07793574035167694, 0.07385823130607605, 0.07467442750930786, 0.07358884811401367, 0.07205621898174286, 0.07123532891273499, 0.0680718645453453, 0.06751932948827744, 0.06430190801620483, 0.06789401918649673, 0.06477625668048859, 0.06401883810758591, 0.06182447448372841, 0.061613135039806366, 0.062235698103904724, 0.05810314044356346, 0.058508165180683136, 0.0576431080698967, 0.05780521035194397, 0.05610622465610504, 0.05397297814488411, 0.052215974777936935, 0.05363195762038231, 0.053363386541604996, 0.05179978907108307, 0.049208272248506546, 0.051201995462179184, 0.04803203418850899, 0.048670824617147446, 0.0478181466460228, 0.046695925295352936, 0.04485328122973442, 0.04720817133784294, 0.045238934457302094, 0.046133872121572495, 0.04478961601853371, 0.04283744841814041, 0.04657905548810959, 0.04244198277592659, 0.04189573973417282, 0.04082474857568741, 0.04116610065102577, 0.04024774208664894, 0.04060985893011093, 0.03937240689992905, 0.03776117414236069, 0.03669596463441849, 0.03839753568172455, 0.03577844053506851, 0.03754749894142151, 0.03477476164698601, 0.03332453593611717, 0.034552935510873795, 0.035343922674655914, 0.0350642167031765, 0.033605966717004776, 0.03333323448896408, 0.03205127641558647, 0.03066769614815712, 0.031656961888074875, 0.03109295479953289, 0.030873537063598633, 0.03137606754899025, 0.03198360279202461, 0.03109676204621792, 0.03204302117228508, 0.032009322196245193, 0.028882555663585663, 0.03022109530866146, 0.029204657301306725, 0.028101883828639984, 0.030513839796185493, 0.02895406447350979, 0.033789731562137604, 0.030172381550073624, 0.028599238023161888, 0.027943415567278862, 0.02841700054705143, 0.02776493690907955, 0.026083584874868393, 0.025126593187451363, 0.026684748008847237, 0.026176990941166878, 0.026105189695954323, 0.026045311242341995, 0.025341933593153954, 0.02612210623919964, 0.02607831545174122, 0.02479192428290844, 0.02386554889380932, 0.02558729611337185, 0.024998845532536507, 0.0228432584553957, 0.02381545677781105, 0.02490617148578167, 0.023487955331802368, 0.023879075422883034, 0.025188367813825607, 0.021728726103901863, 0.024699615314602852, 0.02223753184080124, 0.022158851847052574, 0.0215927604585886, 0.02157771773636341, 0.022033121436834335, 0.0201480183750391, 0.02185986191034317, 0.022170415148139, 0.023673048242926598, 0.021657515317201614, 0.021276723593473434, 0.020831385627388954, 0.01997344009578228, 0.021197214722633362, 0.01988808810710907, 0.020063143223524094, 0.020665612071752548, 0.019344113767147064, 0.020618855953216553, 0.019531957805156708, 0.01893923059105873, 0.02004251629114151, 0.01964402198791504, 0.01969253085553646, 0.020169032737612724, 0.020476989448070526, 0.01997503824532032, 0.019742554053664207, 0.017492802813649178, 0.018626734614372253, 0.018173659220337868, 0.01873997040092945, 0.01980871893465519, 0.017910471186041832, 0.01851497031748295, 0.01712617836892605, 0.020876750349998474, 0.025403935462236404, 0.016846496611833572, 0.018564073368906975, 0.017154481261968613, 0.01802484691143036, 0.01745341531932354, 0.018943771719932556, 0.019274655729532242, 0.020799173042178154, 0.016195716336369514, 0.017707504332065582, 0.01791185885667801, 0.016338765621185303, 0.01780528575181961, 0.017307285219430923, 0.01753377541899681, 0.01661577634513378, 0.017043672502040863, 0.01747841201722622, 0.017568625509738922, 0.015919923782348633, 0.018436819314956665, 0.018060868605971336, 0.016313565894961357, 0.016535788774490356, 0.01551036536693573, 0.018217260017991066, 0.01541651226580143, 0.015465708449482918, 0.01845361664891243, 0.01732405088841915, 0.016233323141932487, 0.01692628115415573, 0.016278892755508423, 0.01601136475801468, 0.015841316431760788, 0.018337149173021317, 0.01550760492682457, 0.015718786045908928, 0.016072964295744896, 0.016945671290159225, 0.014674839563667774, 0.017703618854284286, 0.016601167619228363, 0.015735872089862823, 0.022137977182865143, 0.015367233194410801, 0.015035468153655529, 0.013645404949784279, 0.014590524137020111, 0.016198894008994102, 0.016956523060798645, 0.014243992045521736, 0.015538176521658897, 0.01508937869220972, 0.0146454693749547, 0.015030368231236935, 0.014390753582119942, 0.0158418919891119, 0.01573585905134678, 0.01411904115229845, 0.015895217657089233, 0.01485217921435833, 0.013054138980805874, 0.015074237249791622, 0.014814021997153759, 0.015165222808718681, 0.014680205844342709, 0.013330185785889626, 0.014970703050494194, 0.013485567644238472, 0.013748343102633953, 0.01409714575856924, 0.014467975124716759, 0.013625996187329292, 0.0130831990391016, 0.013280840590596199, 0.013444689102470875, 0.0158991776406765, 0.01398672815412283, 0.013693585991859436, 0.014524944126605988, 0.0159850362688303, 0.01356513798236847, 0.014084656722843647, 0.01339332852512598, 0.013806150294840336]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:27 2016", "state": "available"}], "summary": "a8e0b44edac9a4fb67c035872c3f1671"}