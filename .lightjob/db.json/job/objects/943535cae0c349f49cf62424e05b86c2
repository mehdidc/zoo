{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.012160576248563227, 0.010569256040320179, 0.018708142499883156, 0.016375716782489336, 0.021173102173791078, 0.025192553558591263, 0.019984515224899756, 0.01853108017760629, 0.01411663572228419, 0.01678494340959076, 0.015611369621818721, 0.014164724725310784, 0.014428633855542496, 0.018341005393844742, 0.017054989450304578, 0.018954148114402946, 0.011366026715554797, 0.016175008709511593, 0.018708068502886782, 0.014632195867295498, 0.014934935411890947, 0.017636349674574725, 0.01701810289283178, 0.014098530792480928, 0.013622037579468149, 0.015088559077736421, 0.010646076546905988, 0.012491444195615042, 0.01341353282245232, 0.013555501697597973, 0.015772701250267557, 0.012390337022786746, 0.009549604291044912, 0.01120073751179704, 0.010791317912301814, 0.012200457546766661, 0.012787773252252351, 0.009928176216691788, 0.012672930637344483, 0.013218844636302138, 0.009997784760552637, 0.011971471336895724, 0.010443989327791005, 0.011407809605791464, 0.01092241743702275, 0.010030781911703705, 0.011969342706297072, 0.013381895432177804, 0.012548010914644931, 0.01271240168829159, 0.014395150358007171, 0.011153463475577462, 0.010805184022715372, 0.012688663097992428, 0.009716368652327494, 0.012376070961298233, 0.011569772691247473, 0.01055669839941996, 0.00973817553261124, 0.013468532098975554, 0.01330424893914488, 0.013383786798709616, 0.01333934897215176, 0.011619438230726756, 0.012108261582868518, 0.011944757689066495, 0.013499030066902208, 0.01765471740296572, 0.012502893926047094, 0.013569468352561629, 0.015006443173971802, 0.012086832179090004, 0.013938232799349836, 0.012571002007065922, 0.013657415755944084, 0.013847559961018323, 0.014206922309589582, 0.00830656403307701, 0.01123048415833575, 0.010790520924169924, 0.011480976390320953, 0.011608520313226072, 0.013984573531221876, 0.010256304760096197, 0.010988607318015835, 0.013020873940682721, 0.013443074891941317, 0.011634319101330675, 0.014064169222446759, 0.013627779468920584, 0.016603978378414663, 0.01249343357596524, 0.011421594280759522, 0.009705852840161141, 0.009421136087609196, 0.013185643813754661, 0.012483726082220675, 0.011696246283396862, 0.013665741298305608, 0.010936601797026442, 0.009595750632997235, 0.014284483436945751, 0.015501251048375214, 0.015149457781785962, 0.012801412990291404, 0.010243631751444522, 0.011837567040563943, 0.01066885147931308, 0.012649791021802893, 0.012293535187427736, 0.007850140853769534, 0.01079450357313418, 0.01230105990061522, 0.005933603088197611, 0.011286003337036925, 0.015439727107682372, 0.007163170217791177, 0.009677146148532328, 0.011109871792539937, 0.010246454560767275, 0.012495546323457589, 0.014857715694834779, 0.012940382785431599, 0.012605932948138478, 0.013876827101921601, 0.014343651978167435, 0.011707621145568352, 0.00923651187494917, 0.013260006286354197, 0.012142963326431165, 0.012686345942876636, 0.008625805572030099, 0.01164776403432834, 0.010249399418867659, 0.012857164773876505, 0.012088748668735393, 0.014436500558926186, 0.01212139817697857, 0.013794015798686499, 0.012460498184948186, 0.01127880232244344, 0.011048432156964463, 0.014004339772785082, 0.011472534863436912, 0.013391894486799059, 0.012561294361679527, 0.011560823765982066, 0.01047197699787234, 0.014059477225402973, 0.010770927995928908, 0.01042758267982432, 0.012935132499321746, 0.013096334231935484, 0.011414606243933872, 0.012947983386384082, 0.014763839491457296, 0.015075642325681751, 0.012828470401018659, 0.01077626050230478, 0.015352713675128525, 0.012077463937963058, 0.009982168853708577, 0.014136104075823674, 0.016241092163745974, 0.013308564802188432, 0.013116540194380268, 0.012499776284609, 0.01482456452688508, 0.01031686183795821, 0.010033554549916744, 0.013250600350831487, 0.013327897319622617, 0.00997511613400514, 0.009104130159341719, 0.01211635392476816, 0.012311484994409604, 0.012067684867651984, 0.010166656597898623, 0.014296997826184184, 0.012671566476058067, 0.015759965106508192, 0.010857203022297786, 0.012357829807480365, 0.01180010172455392, 0.015043054606987854, 0.010528009885715386, 0.009815109186625853, 0.012811709766769083, 0.011803359458583199, 0.01364535214555123, 0.013497960686475765, 0.01365674643327771, 0.01153855756072743, 0.011284132613690332, 0.012644954390123574, 0.0139746170843233, 0.013129456112631928, 0.010762202872624048, 0.011034083785844735, 0.015732550993146084, 0.012081641278624851, 0.01308870938468285, 0.012096252353873904, 0.01046077077554028, 0.009479319234019686, 0.011593018613640215, 0.013666523583265689, 0.014869718784308898, 0.014292977100974486, 0.011114258281894187, 0.010703132482162429, 0.012796828304505724, 0.011193908408027333, 0.010150728124178476, 0.012186674214748953, 0.011183233646557314, 0.011965991785580924, 0.014492174803018683, 0.012331673881576768, 0.01178153070573756, 0.011843170300867427, 0.01119159864421893, 0.010645436012439167, 0.007998464407070912, 0.011133545628125095, 0.010782680101275775, 0.010842268334029997, 0.010803331350922544, 0.01123955436199847, 0.011762391017824851, 0.011494152906165475, 0.00998550359029696, 0.011036261391879484, 0.012349315422203992, 0.011261278523630966, 0.011021417043027662, 0.010953476092768177, 0.01087226242975889, 0.010105549399152296, 0.011151495937559522, 0.013423010143394823, 0.010899186026339222, 0.012036552662611907, 0.011158651848355692, 0.010077408748385848, 0.010590805386199203, 0.012989692209619421, 0.010804189757646366, 0.012213979519143386, 0.014934022081676126, 0.011272011399008509, 0.013445779728339241, 0.011961602449336917, 0.01330112300631142, 0.013479956223217604, 0.014365096662464608, 0.01290058104274376, 0.014076680560296376, 0.010883988487795631, 0.012176747660474775, 0.01359263876468298, 0.013468007330522325, 0.014915964374789564, 0.016740408027419367, 0.01173254977948403, 0.017057166681044886, 0.012085801336296026, 0.015467674969655308, 0.009422749077405704, 0.013034936024485362, 0.015784909282892588, 0.01265998601472302, 0.013449310063000096, 0.015279590379561482, 0.014982773421625616, 0.012338521807430867, 0.013418861012241304, 0.012179482336375953, 0.011498003296420405, 0.013031254922132715, 0.014708868909206904, 0.013494642479952985, 0.014862150086064004, 0.009284782882126438, 0.010115077163778035, 0.012450250074324772, 0.014462320114949606, 0.012664800766138745, 0.012002803344216544], "moving_avg_accuracy_train": [0.046202671505860084, 0.0976136420986757, 0.14674988338207132, 0.19438760340603656, 0.24124606341311655, 0.28724039293951437, 0.3297792627275581, 0.3684804471737022, 0.40609889796320725, 0.44011128864399984, 0.4715384593423998, 0.5002739197423698, 0.526914795002352, 0.5508311649161073, 0.5732600923348417, 0.5942249797652556, 0.6133864193002656, 0.6313336574805195, 0.647460631254662, 0.6624468047132674, 0.6751721085534947, 0.6875081141179497, 0.6988290470652355, 0.7089782870903933, 0.7176966898666808, 0.7264774935521242, 0.7344409951774395, 0.7415244773318994, 0.747852928050629, 0.7536949459748481, 0.759803622375656, 0.7647411423709254, 0.7687432762881333, 0.7731635410481166, 0.7772487361773396, 0.7812764732150597, 0.7848478499799325, 0.7878410557361382, 0.7910906154333808, 0.7937946544633631, 0.7967766642212072, 0.7987260143700075, 0.8008849332991473, 0.8028396221282396, 0.8046824032362905, 0.8058553106205334, 0.8075454405496206, 0.8086689570393706, 0.8097360335980305, 0.8108173102389196, 0.8111255387538334, 0.811016969714875, 0.8123325875678153, 0.8139049795354708, 0.8146416574886236, 0.8150580216285578, 0.8161371973461469, 0.8164344867765839, 0.8179805186210277, 0.8189767440810456, 0.8200661180533396, 0.8215162707367468, 0.8218846255233065, 0.8230924735906695, 0.823407767690628, 0.8243564167936581, 0.825853906718436, 0.8263579791210663, 0.827281108050045, 0.8278355918659799, 0.8280321777109895, 0.8295481743928713, 0.8306220359518308, 0.830746771437028, 0.831568239809429, 0.8312636776755697, 0.8320170712359936, 0.8318885150963828, 0.8325771358147346, 0.8331293209504999, 0.8335962408822586, 0.8342906921850903, 0.8344809676278955, 0.8352937403049361, 0.8357300139131006, 0.8363505607926008, 0.836046530922274, 0.8367238538532562, 0.8376241241411495, 0.8377090291181383, 0.8376970879426663, 0.8377047257823051, 0.8383650027022751, 0.8374829266314754, 0.8376887640093946, 0.8373624128137892, 0.8375034995651253, 0.8379326388401096, 0.8383142138899764, 0.83842754984917, 0.8389106963731123, 0.8391364450958971, 0.8393163674583082, 0.8399548088951554, 0.8399086996026314, 0.8394233862072906, 0.8402859657990015, 0.840811135311294, 0.8409954694199764, 0.8420309036749148, 0.8424911137353949, 0.8428400183790665, 0.8434284361667136, 0.8439415198410167, 0.84417561080865, 0.8434096941307012, 0.8440687030883398, 0.8445969232764604, 0.8451861455909794, 0.8453656005455396, 0.8451037526772167, 0.845263256746889, 0.8463204496964618, 0.8469420045618562, 0.8471735940073871, 0.8464194849988596, 0.8471076860006347, 0.8473598015367838, 0.8476542069324318, 0.8474446611872783, 0.8476863306928584, 0.8477597100705087, 0.847879374128288, 0.8483145212254259, 0.8475532402915138, 0.84750496193189, 0.8481894992785219, 0.8486404612761957, 0.848290653711007, 0.8485756071487379, 0.8482090695570184, 0.8479000760149378, 0.848386883687761, 0.8486550584372943, 0.8482666969214995, 0.8486517022881812, 0.8486192078622423, 0.8492200061086408, 0.8495561835327988, 0.8497122948883598, 0.8498503257642801, 0.8498560430609603, 0.8503402053315531, 0.850336570347724, 0.8508656858420214, 0.8506468144881163, 0.8507171502850596, 0.8507177095332701, 0.8510949230126212, 0.8511925636190281, 0.8516174785957189, 0.8514117475723874, 0.8519729984680648, 0.8518897534789088, 0.8518800092529726, 0.8522479135567728, 0.8525836416789933, 0.8528369688639916, 0.8528813126233565, 0.8535071234579663, 0.8539794561126312, 0.8537746204185422, 0.8539761348497868, 0.8540088685581914, 0.8541149867088321, 0.8541290046896193, 0.8544090129854229, 0.8542495051611793, 0.8544569734919606, 0.8547997683504518, 0.8545873422433043, 0.8552096363908362, 0.8556443233319945, 0.85537294626596, 0.8556378063493585, 0.856085479866093, 0.8567416830561171, 0.8566068555473861, 0.8571062173752149, 0.8575066706999858, 0.8576440086018402, 0.8576957133445078, 0.8575168163248411, 0.8575438576701624, 0.8578287557428933, 0.858145726023855, 0.8587005002457128, 0.8593115483835169, 0.8592220397361028, 0.8593904891689617, 0.8596209324251459, 0.859498232322397, 0.8594876754822761, 0.8592225521523948, 0.8597162188352266, 0.8601674221985662, 0.8605573373303615, 0.8611546185763306, 0.8613271593834262, 0.8614662061169643, 0.8616379232509767, 0.8623620219834648, 0.8623348394879606, 0.8619244365884448, 0.8622618471193382, 0.8613194170793312, 0.8612686479385354, 0.8612415569022953, 0.8615380815542124, 0.8617700765087949, 0.862332258538148, 0.86169424915028, 0.8621290471380759, 0.8624946084460937, 0.8620891549900502, 0.8624473321105542, 0.8631414629868004, 0.8635106667481055, 0.8636987909070897, 0.8638122990787469, 0.8640655911058575, 0.8642099206707516, 0.8643304806350995, 0.8647644333387084, 0.8641784643207752, 0.8643090732689117, 0.8640916196495694, 0.863651951011255, 0.8643558283307644, 0.8647196367052369, 0.8642799814280318, 0.8644003665678052, 0.8636133867066595, 0.8635865176280939, 0.8636368844145648, 0.8634634702901994, 0.8628380780069345, 0.8630490669197423, 0.8634528345829268, 0.8635933356334473, 0.8635638574134027, 0.8637767091962871, 0.864430764121066, 0.8646080064093562, 0.864488578709312, 0.864397658211489, 0.8646805897359935, 0.8646446566044945, 0.8653864110956232, 0.8658820012233717, 0.8663162984478414, 0.8665466946331883, 0.8664356500083709, 0.8669168168043223, 0.8667245821350105, 0.8662401451874286, 0.8662179563250627, 0.8668185487393449, 0.8671987187419793, 0.8668502664991029, 0.8667528262221623, 0.8665838579110388, 0.8670526011631704, 0.86710259047584, 0.8675729749429293, 0.8678195015073296, 0.8678810482938889, 0.8679946051708491, 0.8679084332577233, 0.8679587617204337, 0.8683898517951605, 0.8684223734851073, 0.8684400172620119, 0.8688719901516745, 0.8687005851333693, 0.8687693186096964, 0.868559064230039, 0.8680352662015073, 0.8684170694424677], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 54785134, "moving_var_accuracy_train": [0.01921218168850574, 0.041078754595313335, 0.058700211002922664, 0.0732543612243657, 0.08569036257004517, 0.0961606314502865, 0.10283056729085513, 0.10602754565957985, 0.10816112165184355, 0.10775659396506501, 0.10586993809151582, 0.10271448444194846, 0.09883066210931503, 0.09409553064704769, 0.08921348864873663, 0.08424787832859233, 0.07912753738121772, 0.07411371386778486, 0.06904305602901331, 0.06416001898049466, 0.05920141730288013, 0.054650868872168475, 0.05033925369012411, 0.0462323919789061, 0.04229324770374167, 0.03875784555362817, 0.03545281722149297, 0.03235911697423663, 0.02948364887330747, 0.0268424465468188, 0.024494045238465007, 0.022264052647951674, 0.020181801066177903, 0.01833946962449526, 0.016655722035240184, 0.015136153822521365, 0.013737331028239288, 0.012444231451706207, 0.011294845050569078, 0.01023116698919318, 0.009288081730036766, 0.008393473251056738, 0.007596074304434452, 0.00687085414975821, 0.006214331314692094, 0.005605279588810987, 0.005070460482524659, 0.0045747750379968545, 0.004127545405635541, 0.003725313297639178, 0.0033536370112319147, 0.0030183793952347064, 0.0027321191087260137, 0.002481158946352941, 0.0022379273013775998, 0.0020156948031130485, 0.0018246069048666479, 0.001642941643429029, 0.0015001594092624363, 0.001359075654840884, 0.0012338487102204025, 0.0011293903244451026, 0.0010176724592396256, 0.0009290352859001549, 0.0008370264506353573, 0.0007614232216579422, 0.0007054631841654467, 0.0006372036666327442, 0.000581152803145125, 0.0005258045935498167, 0.0004735719481449583, 0.00044689896678575376, 0.00041258767793747586, 0.0003714689406151345, 0.0003403953391353164, 0.000307190628062212, 0.0002815799819679837, 0.00025357072390047006, 0.0002324814379541126, 0.0002119774699761434, 0.0001927418509825919, 0.0001778080293923748, 0.00016035306915034942, 0.00015026315705620879, 0.00013694985330121623, 0.00012672057383801148, 0.00011488042391266923, 0.00010752127869691208, 0.00010406353014859188, 9.372205682978989e-05, 8.435113447185579e-05, 7.591654605401935e-05, 7.224858194802215e-05, 7.202624750531646e-05, 6.520494399012295e-05, 5.964299551696825e-05, 5.3857845207894616e-05, 5.01295053431118e-05, 4.64269504769286e-05, 4.1899860786052686e-05, 3.9810749779825574e-05, 3.6288337174393456e-05, 3.295085196541418e-05, 3.3324233983425396e-05, 3.001094518679646e-05, 2.9129612493390372e-05, 3.2913043212377356e-05, 3.210396604091382e-05, 2.919938100943581e-05, 3.592855977519279e-05, 3.424184349557737e-05, 3.191326919940043e-05, 3.1838061714835474e-05, 3.102354925487994e-05, 2.8414381559539328e-05, 3.0852598621626494e-05, 3.167597401569544e-05, 3.1019525718369454e-05, 3.1042219569876304e-05, 2.822783433933462e-05, 2.602212966070821e-05, 2.3648890628815328e-05, 3.134291395957222e-05, 3.168559661987448e-05, 2.899973999941872e-05, 3.121788957015876e-05, 3.235868618274216e-05, 2.9694877756577994e-05, 2.7505460813799803e-05, 2.515009950622715e-05, 2.3160726904950117e-05, 2.0893115012034223e-05, 1.893267889134872e-05, 1.874358796754232e-05, 2.2085167113830935e-05, 1.9897627602519595e-05, 2.212518725267298e-05, 2.174296903751941e-05, 2.0669960127737316e-05, 1.9333750270035948e-05, 1.8609523498324077e-05, 1.7607864229919212e-05, 1.797991319980422e-05, 1.6829181146408716e-05, 1.650368503432151e-05, 1.6187378722252987e-05, 1.457814383948153e-05, 1.636895625141318e-05, 1.5749197970893928e-05, 1.4393614971820467e-05, 1.3125726179004582e-05, 1.1813447748436082e-05, 1.2741820911982589e-05, 1.1467757738751264e-05, 1.284065082162612e-05, 1.1987727765505329e-05, 1.0833479107939595e-05, 9.750134011972685e-06, 1.0055730691812792e-05, 9.135960814806799e-06, 9.847339370071158e-06, 9.24353271871362e-06, 1.1154202557931083e-05, 1.0101149856114297e-05, 9.091889419954746e-06, 9.400882668751539e-06, 9.475214750323588e-06, 9.105265239224307e-06, 8.21243603625343e-06, 1.091594523906227e-05, 1.1832233945120278e-05, 1.1026629504764096e-05, 1.0289439148286614e-05, 9.270138694451134e-06, 8.444474382064881e-06, 7.601795477926533e-06, 7.547257741603756e-06, 7.021516681397877e-06, 6.7067529877526994e-06, 7.0936525240498925e-06, 6.7904109306251746e-06, 9.596619892034467e-06, 1.0337532534152004e-05, 9.966588888461953e-06, 9.601287773616292e-06, 1.0444863194523713e-05, 1.3275800514452212e-05, 1.2111826577002312e-05, 1.3144904035134306e-05, 1.3273679419501231e-05, 1.2116066771123299e-05, 1.0928520517739867e-05, 1.0123705758776617e-05, 9.117916292110056e-06, 8.936626869511073e-06, 8.947195613676383e-06, 1.0822445987449758e-05, 1.310061982912994e-05, 1.1862664027874015e-05, 1.093177452796101e-05, 1.0316533924052364e-05, 9.42037836857866e-06, 8.479343553580827e-06, 8.264022618649172e-06, 9.630981500427273e-06, 1.0500143626185658e-05, 1.0818433553593468e-05, 1.2947294179310825e-05, 1.1920497732398624e-05, 1.0902453906127426e-05, 1.007758948253532e-05, 1.3788701303800369e-05, 1.2416481165976802e-05, 1.2690707908758514e-05, 1.2446249915102767e-05, 1.919519434635917e-05, 1.7298872462637552e-05, 1.5575590534574822e-05, 1.4809373303867897e-05, 1.3812830904046558e-05, 1.527598552078977e-05, 1.7411890779779576e-05, 1.7372145313524067e-05, 1.6837646411448848e-05, 1.663341431546239e-05, 1.6124690530789128e-05, 1.8848580537934548e-05, 1.8190525240398237e-05, 1.668998900910005e-05, 1.5136947053486721e-05, 1.4200664007117951e-05, 1.296807681612894e-05, 1.1802081479548098e-05, 1.231670787231862e-05, 1.417527429488543e-05, 1.2911275141397012e-05, 1.2045722316342761e-05, 1.2580926688362495e-05, 1.5781823547804113e-05, 1.539484999305036e-05, 1.5595035858714116e-05, 1.4165965509747088e-05, 1.8323404675411064e-05, 1.6497561734316612e-05, 1.4870636879499495e-05, 1.3654225318313996e-05, 1.5808842358189866e-05, 1.4628605014321402e-05, 1.463299944539047e-05, 1.334736440762782e-05, 1.202044865597803e-05, 1.1226156723674386e-05, 1.395363165295381e-05, 1.2841001946483594e-05, 1.1685268531675743e-05, 1.0591140510827665e-05, 1.0252478687770753e-05, 9.238851528447562e-06, 1.3266763901587924e-05, 1.4150573683925031e-05, 1.4433043028171855e-05, 1.3467480345356357e-05, 1.2231710489128556e-05, 1.3092232809950943e-05, 1.211559704172495e-05, 1.3016149743194615e-05, 1.1718965879393023e-05, 1.379347052429382e-05, 1.3714886549991374e-05, 1.3436168585082558e-05, 1.2178003194706563e-05, 1.121715548671152e-05, 1.2072922065810805e-05, 1.0888120241660394e-05, 1.1790662139404359e-05, 1.1158574048059151e-05, 1.007680870567533e-05, 9.185184313852611e-06, 8.333496269973349e-06, 7.522943230405238e-06, 8.443196780115203e-06, 7.608396044956677e-06, 6.850358166232127e-06, 7.844727546239962e-06, 7.3246719143176246e-06, 6.634723339797992e-06, 6.369113143304009e-06, 8.201481201217583e-06, 8.693296514366452e-06], "duration": 288784.969067, "accuracy_train": [0.46202671505860093, 0.5603123774340163, 0.588976054932632, 0.6231270836217239, 0.6629722034768365, 0.7011893586770949, 0.712629090819952, 0.7167911071889996, 0.7446649550687523, 0.7462228047711333, 0.7543829956279993, 0.7588930633421004, 0.7666826723421927, 0.766078494139904, 0.7751204391034514, 0.7829089666389812, 0.7858393751153562, 0.7928588011028055, 0.7926033952219453, 0.7973223658407161, 0.7896998431155408, 0.7985321641980436, 0.8007174435908084, 0.8003214473168143, 0.7961623148532669, 0.8055047267211147, 0.8061125098052787, 0.8052758167220377, 0.8048089845191952, 0.8062731072928202, 0.8147817099829272, 0.8091788223283499, 0.8047624815430048, 0.8129459238879659, 0.814015492340347, 0.8175261065545404, 0.8169902408637875, 0.8147799075419897, 0.820336652708564, 0.8181310057332041, 0.8236147520418051, 0.81627016570921, 0.8203152036614065, 0.8204318215900701, 0.8212674332087486, 0.8164114770787191, 0.8227566099114065, 0.8187806054471208, 0.8193397226259689, 0.8205488000069213, 0.8138995953880583, 0.8100398483642488, 0.8241731482442783, 0.8280565072443706, 0.8212717590669989, 0.8188052988879659, 0.8258497788044481, 0.8191100916505168, 0.8318948052210224, 0.827942773221207, 0.8298704838039868, 0.8345676448874124, 0.825199818602344, 0.8339631061969361, 0.8262454145902547, 0.8328942587209303, 0.839331316041436, 0.8308946307447398, 0.8355892684108527, 0.8328259462093945, 0.8298014503160761, 0.8431921445298081, 0.8402867899824659, 0.8318693908038022, 0.8389614551610374, 0.828522618470838, 0.8387976132798081, 0.8307315098398856, 0.8387747222799004, 0.8380989871723883, 0.8377985202680879, 0.8405407539105758, 0.8361934466131414, 0.8426086943983019, 0.8396564763865817, 0.8419354827081026, 0.8333102620893319, 0.8428197602320967, 0.845726556732189, 0.8384731739110374, 0.8375896173634183, 0.837773466339055, 0.8443074949820044, 0.8295442419942783, 0.8395413004106681, 0.8344252520533407, 0.8387732803271503, 0.8417948923149685, 0.841748389338778, 0.8394475734819121, 0.8432590150885935, 0.8411681836009597, 0.8409356687200074, 0.845700781826781, 0.8394937159699151, 0.8350555656492249, 0.8480491821244001, 0.8455376609219268, 0.8426544763981173, 0.8513498119693614, 0.8466330042797158, 0.8459801601721114, 0.8487241962555371, 0.8485592729097453, 0.8462824295173496, 0.836516444029162, 0.8499997837070875, 0.8493509049695459, 0.8504891464216501, 0.8469806951365817, 0.8427471218623109, 0.8466987933739387, 0.8558351862426172, 0.8525359983504062, 0.849257899017165, 0.8396325039221114, 0.8533014950166113, 0.8496288413621264, 0.8503038554932633, 0.845558749480897, 0.8498613562430787, 0.8484201244693614, 0.8489563506483019, 0.8522308450996677, 0.8407017118863048, 0.847070456695275, 0.8543503353982096, 0.8526991192552602, 0.8451423856243078, 0.8511401880883168, 0.844910231231543, 0.8451191341362125, 0.852768152743171, 0.8510686311830934, 0.8447714432793466, 0.8521167505883168, 0.848326758028793, 0.8546271903262275, 0.8525817803502216, 0.8511172970884091, 0.8510926036475637, 0.8499074987310816, 0.8546976657668882, 0.8503038554932633, 0.8556277252906977, 0.8486769723029715, 0.851350172457549, 0.850722742767165, 0.854489844326781, 0.8520713290766887, 0.8554417133859358, 0.849560168362403, 0.857024256529162, 0.8511405485765043, 0.8517923112195459, 0.8555590522909744, 0.8556051947789776, 0.8551169135289776, 0.8532804064576411, 0.8591394209694537, 0.8582304500046143, 0.8519310991717424, 0.8557897647309893, 0.8543034719338316, 0.8550700500645996, 0.8542551665167036, 0.856929087647656, 0.8528139347429864, 0.8563241884689923, 0.8578849220768733, 0.8526755072789776, 0.8608102837186231, 0.8595565058024179, 0.8529305526716501, 0.8580215470999446, 0.8601145415167036, 0.8626475117663345, 0.8553934079688077, 0.8616004738256736, 0.8611107506229235, 0.8588800497185308, 0.8581610560285161, 0.8559067431478405, 0.8577872297780547, 0.8603928383974714, 0.8609984585525102, 0.8636934682424326, 0.8648109816237541, 0.8584164619093761, 0.8609065340646919, 0.8616949217308048, 0.858393931397656, 0.8593926639211886, 0.8568364421834626, 0.8641592189807125, 0.8642282524686231, 0.864066573516519, 0.8665301497900517, 0.8628800266472868, 0.8627176267188077, 0.8631833774570875, 0.8688789105758582, 0.8620901970284238, 0.8582308104928018, 0.8652985418973791, 0.8528375467192691, 0.8608117256713732, 0.8609977375761352, 0.8642068034214655, 0.863858031100037, 0.8673918968023256, 0.8559521646594684, 0.8660422290282392, 0.865784660218254, 0.8584400738856589, 0.8656709261950905, 0.8693886408730158, 0.8668335005998523, 0.8653919083379475, 0.8648338726236618, 0.8663452193498523, 0.8655088867547989, 0.8654155203142304, 0.8686700076711886, 0.8589047431593761, 0.8654845538021411, 0.862134537075489, 0.8596949332664268, 0.8706907242063492, 0.867993912075489, 0.8603230839331857, 0.8654838328257659, 0.8565305679563492, 0.863344695921004, 0.8640901854928018, 0.8619027431709118, 0.857209547457549, 0.8649479671350129, 0.8670867435515872, 0.8648578450881322, 0.8632985534330011, 0.8656923752422481, 0.8703172584440754, 0.8662031870039681, 0.8634137294089147, 0.8635793737310816, 0.8672269734565338, 0.864321258421004, 0.8720622015157806, 0.8703423123731081, 0.8702249734680694, 0.8686202603013106, 0.8654362483850129, 0.8712473179678849, 0.8649944701112033, 0.8618802126591916, 0.8660182565637689, 0.8722238804678849, 0.8706202487656883, 0.8637141963132153, 0.8658758637296974, 0.8650631431109265, 0.8712712904323551, 0.867552494289867, 0.8718064351467331, 0.8700382405869325, 0.8684349693729235, 0.869016617063492, 0.8671328860395902, 0.8684117178848283, 0.8722696624677003, 0.868715068694629, 0.8685988112541528, 0.8727597461586378, 0.8671579399686231, 0.8693879198966408, 0.866666774813123, 0.8633210839447213, 0.871853298611111], "end": "2016-01-26 03:22:13.708000", "learning_rate_per_epoch": [0.0016427250811830163, 0.0011615820694714785, 0.0009484277688898146, 0.0008213625405915082, 0.0007346489583142102, 0.0006706396816298366, 0.0006208916893228889, 0.0005807910347357392, 0.0005475750076584518, 0.0005194752593524754, 0.0004953002207912505, 0.0004742138844449073, 0.00045560995931737125, 0.0004390367539599538, 0.000424149795435369, 0.0004106812702957541, 0.00039841936086304486, 0.00038719401345588267, 0.000376866984879598, 0.0003673244791571051, 0.00035847199615091085, 0.0003502301697153598, 0.00034253185731358826, 0.0003353198408149183, 0.00032854502205736935, 0.0003221648803446442, 0.000316142599331215, 0.0003104458446614444, 0.00030504638561978936, 0.00029991919291205704, 0.0002950421185232699, 0.0002903955173678696, 0.000285961723420769, 0.00028172502061352134, 0.0002776712062768638, 0.0002737875038292259, 0.0002700623299460858, 0.00026648520724847913, 0.00026304653147235513, 0.0002597376296762377, 0.00025655055651441216, 0.0002534779778216034, 0.00025051322882063687, 0.00024765011039562523, 0.00024488300550729036, 0.0002422066027065739, 0.00023961607075762004, 0.00023710694222245365, 0.00023467501159757376, 0.0002323164080735296, 0.00023002752277534455, 0.00022780497965868562, 0.0002256456355098635, 0.00022354656539391726, 0.00022150500444695354, 0.0002195183769799769, 0.0002175842528231442, 0.00021570036187767982, 0.00021386459411587566, 0.0002120748977176845, 0.0002103293954860419, 0.00020862629753537476, 0.00020696390129160136, 0.00020534063514787704, 0.00020375497115310282, 0.0002022054832195863, 0.00020069080346729606, 0.00019920968043152243, 0.00019776086264755577, 0.00019634320051409304, 0.00019495560263749212, 0.00019359700672794133, 0.00019226642325520515, 0.00019096290634479374, 0.00018968555377796292, 0.000188433492439799, 0.00018720589287113398, 0.00018600198382046074, 0.0001848210085881874, 0.00018366223957855254, 0.00018252500740345567, 0.00018140864267479628, 0.00018031250510830432, 0.00017923599807545543, 0.0001781785540515557, 0.0001771396055119112, 0.00017611861403565854, 0.0001751150848576799, 0.00017412850866094232, 0.00017315841978415847, 0.0001722043816698715, 0.00017126592865679413, 0.00017034265329129994, 0.00016943414811976254, 0.000168540034792386, 0.00016765992040745914, 0.0001667934557190165, 0.00016594029148109257, 0.0001651000784477219, 0.00016427251102868468, 0.00016345725452993065, 0.00016265401791315526, 0.00016186251014005393, 0.0001610824401723221, 0.00016031354607548565, 0.00015955556591507047, 0.00015880822320468724, 0.0001580712996656075, 0.00015734451881144196, 0.0001566276914672926, 0.00015592057025060058, 0.0001552229223307222, 0.00015453457308467478, 0.00015385530423372984, 0.00015318489749915898, 0.00015252319280989468, 0.00015186998643912375, 0.00015122510376386344, 0.0001505883556092158, 0.00014995959645602852, 0.00014933863712940365, 0.00014872534666210413, 0.000148119535879232, 0.00014752105926163495, 0.00014692980039399117, 0.00014634558465331793, 0.00014576828107237816, 0.0001451977586839348, 0.0001446338719688356, 0.0001440765190636739, 0.0001435255544492975, 0.0001429808617103845, 0.0001424423244316131, 0.00014190982619766146, 0.000141383265145123, 0.00014086251030676067, 0.00014034747437108308, 0.00013983804092276841, 0.0001393341226503253, 0.0001388356031384319, 0.0001383424096275121, 0.00013785442570224404, 0.00013737156405113637, 0.00013689375191461295, 0.00013642088742926717, 0.0001359528978355229, 0.00013548968126997352, 0.0001350311649730429, 0.00013457727618515491, 0.0001341279421467334, 0.000133683075546287, 0.00013324260362423956, 0.00013280645362101495, 0.00013237455277703702, 0.0001319468574365601, 0.00013152326573617756, 0.00013110373402014375, 0.0001306881895288825, 0.00013027657405473292, 0.00012986881483811885, 0.00012946486822329462, 0.0001290646760025993, 0.00012866815086454153, 0.00012827527825720608, 0.00012788597086910158, 0.00012750019959639758, 0.0001271178771276027, 0.0001267389889108017, 0.00012636346218641847, 0.00012599126785062253, 0.00012562231859192252, 0.00012525661441031843, 0.0001248940679943189, 0.0001245346647920087, 0.0001241783465957269, 0.00012382505519781262, 0.0001234747760463506, 0.00012312745093367994, 0.00012278303620405495, 0.00012244150275364518, 0.00012210279237478971, 0.00012176688323961571, 0.00012143373169237748, 0.00012110330135328695, 0.00012077554856659845, 0.0001204504442284815, 0.00012012795195914805, 0.00011980803537881002, 0.00011949066538363695, 0.00011917580559384078, 0.00011886341235367581, 0.00011855347111122683, 0.00011824593821074814, 0.00011794078454840928, 0.00011763798829633743, 0.00011733750579878688, 0.0001170393152278848, 0.00011674338747980073, 0.00011644969345070422, 0.0001161582040367648, 0.00011586889013415202, 0.00011558172991499305, 0.00011529669427545741, 0.00011501376138767228, 0.00011473289487184957, 0.00011445408017607406, 0.00011417728819651529, 0.00011390248982934281, 0.00011362967052264139, 0.00011335880117258057, 0.00011308985995128751, 0.00011282281775493175, 0.00011255766730755568, 0.00011229437222937122, 0.00011203291796846315, 0.00011177328269695863, 0.00011151544458698481, 0.00011125938181066886, 0.00011100507254013792, 0.00011075250222347677, 0.00011050164903281257, 0.00011025249114027247, 0.00011000500671798363, 0.00010975918848998845, 0.00010951500735245645, 0.00010927244875347242, 0.0001090314908651635, 0.0001087921264115721, 0.00010855432628886774, 0.00010831808322109282, 0.00010808337538037449, 0.00010785018093883991, 0.00010761849989648908, 0.00010738829587353393, 0.00010715956886997446, 0.00010693229705793783, 0.00010670645860955119, 0.00010648205352481455, 0.00010625905269989744, 0.00010603744885884225, 0.00010581722017377615, 0.00010559836664469913, 0.00010538085916778073, 0.00010516469774302095, 0.00010494985326658934, 0.0001047363257384859, 0.00010452409333083779, 0.00010431314876768738, 0.00010410347022116184, 0.00010389505769126117, 0.00010368788935011253, 0.00010348195064580068, 0.00010327724157832563, 0.00010307374031981453, 0.00010287143231835216, 0.00010267031757393852, 0.00010247037425870076, 0.00010227159509668127, 0.00010207396553596482, 0.00010187748557655141, 0.00010168212611461058, 0.00010148789442609996, 0.00010129476868314669, 0.00010110274160979316, 0.00010091179865412414, 0.00010072193981613964, 0.00010053314326796681, 0.00010034540173364803, 0.00010015871521318331, 9.997306187869981e-05, 9.978844173019752e-05, 9.960484021576121e-05, 9.942224278347567e-05, 9.924064943334088e-05, 9.906004561344162e-05, 9.888043132377788e-05, 9.870178473647684e-05, 9.852410585153848e-05, 9.834738011704758e-05, 9.817160025704652e-05, 9.799675899557769e-05, 9.78228563326411e-05, 9.764987044036388e-05, 9.747780131874606e-05, 9.73066344158724e-05, 9.713636973174289e-05, 9.696699271444231e-05, 9.679850336397067e-05, 9.663088712841272e-05], "accuracy_valid": [0.45327648484563254, 0.5529799863516567, 0.574108445500753, 0.6100191782756024, 0.6494287697665663, 0.6855527579066265, 0.697730374623494, 0.6969670674887049, 0.721912062311747, 0.7280464631965362, 0.7384430299322289, 0.7413933076054217, 0.7509559723268072, 0.7502029602786144, 0.7579448653990963, 0.7637733551393072, 0.7699592314570783, 0.7750964796686747, 0.7746802640248494, 0.7806411191641567, 0.7684134977409638, 0.7741905120481928, 0.7791247999811747, 0.7798984022025602, 0.7751979598079819, 0.7825839490775602, 0.7870093655873494, 0.7840590879141567, 0.7815559111445783, 0.7784835631588856, 0.7939879635730422, 0.784313523625753, 0.7811294004141567, 0.7915568524096386, 0.7888507153614458, 0.7933879070971386, 0.7891757459525602, 0.7869887754141567, 0.792980515813253, 0.7939467832266567, 0.7932452466114458, 0.7905905849962349, 0.7941203289721386, 0.7926245999623494, 0.7927569653614458, 0.7889624905873494, 0.7944350644766567, 0.7918215832078314, 0.7891448606927711, 0.7876697218561747, 0.7825324736445783, 0.7834384412650602, 0.7925128247364458, 0.7982913097703314, 0.7925231198230422, 0.789196336125753, 0.7937232327748494, 0.789196336125753, 0.7984839749623494, 0.7955234022025602, 0.7986869352409638, 0.8013018872364458, 0.7933879070971386, 0.8020857845444277, 0.7954528073230422, 0.8022990399096386, 0.8052802028426205, 0.7926437194088856, 0.8067553416792168, 0.8003459149096386, 0.7993590573230422, 0.8099997646837349, 0.8037329983998494, 0.7981986539909638, 0.8051169521837349, 0.7904979292168675, 0.8042521649096386, 0.7969176510730422, 0.8048522213855422, 0.8029402767319277, 0.8049242869917168, 0.8060023296310241, 0.800915086125753, 0.8096541439194277, 0.8044654202748494, 0.8077113140060241, 0.7972323865775602, 0.8081995952560241, 0.8099497599774097, 0.8054331584149097, 0.8042124552899097, 0.8008444912462349, 0.8067141613328314, 0.7939982586596386, 0.8063788356551205, 0.7996752635542168, 0.802746140813253, 0.8066023861069277, 0.8052596126694277, 0.8041506847703314, 0.8058905544051205, 0.8044360057417168, 0.8096850291792168, 0.8068465267319277, 0.8051581325301205, 0.7970603115587349, 0.8055846432605422, 0.8050963620105422, 0.807152437876506, 0.8104174510542168, 0.8061038097703314, 0.8048831066453314, 0.8079245693712349, 0.8065920910203314, 0.8087996517319277, 0.7982604245105422, 0.8110175075301205, 0.8098982845444277, 0.8116484492658133, 0.8099291698042168, 0.8086775814194277, 0.8087790615587349, 0.8147810970444277, 0.8092776378953314, 0.8123808711408133, 0.8030932323042168, 0.8126956066453314, 0.8081584149096386, 0.8114646084337349, 0.8078333843185241, 0.8103056758283133, 0.8051272472703314, 0.8105086361069277, 0.8086466961596386, 0.8051581325301205, 0.8070906673569277, 0.8138457148908133, 0.8104983410203314, 0.8060435099774097, 0.8107836619917168, 0.8067038662462349, 0.8031535320971386, 0.8118308193712349, 0.8101321300828314, 0.8050154720444277, 0.8114543133471386, 0.8077010189194277, 0.8124411709337349, 0.8132456584149097, 0.8118308193712349, 0.8065817959337349, 0.8037638836596386, 0.8097556240587349, 0.8053199124623494, 0.8111189876694277, 0.8081893001694277, 0.8104571606739458, 0.8081790050828314, 0.8128073818712349, 0.8072833325489458, 0.8130721126694277, 0.8068259365587349, 0.8145678416792168, 0.8086878765060241, 0.8100203548569277, 0.8140692653426205, 0.8110778073230422, 0.8145369564194277, 0.8133265483810241, 0.8153811535203314, 0.8150252376694277, 0.8076701336596386, 0.8117087490587349, 0.8121058452560241, 0.8106204113328314, 0.8116278590926205, 0.8156870646649097, 0.8086569912462349, 0.810436570500753, 0.8108233716114458, 0.8092261624623494, 0.8196742046310241, 0.8182402461408133, 0.8101630153426205, 0.8149546427899097, 0.8160223903426205, 0.8175887142319277, 0.8096747340926205, 0.8172327983810241, 0.8137236445783133, 0.8149443477033133, 0.8165209666792168, 0.8128485622176205, 0.8150767131024097, 0.8139471950301205, 0.8131838878953314, 0.8187285273908133, 0.8191859233810241, 0.8143031108810241, 0.8177313747176205, 0.8178534450301205, 0.8125735363328314, 0.8122073253953314, 0.8132353633283133, 0.8152796733810241, 0.8185961619917168, 0.8184740916792168, 0.8193079936935241, 0.8168871776167168, 0.8178740352033133, 0.8186167521649097, 0.8212611186935241, 0.8160120952560241, 0.8128691523908133, 0.8196639095444277, 0.8076598385730422, 0.8172636836408133, 0.8161650508283133, 0.8190947383283133, 0.8184946818524097, 0.8144148861069277, 0.8086878765060241, 0.8162459407944277, 0.8150355327560241, 0.8129603374435241, 0.8193491740399097, 0.8198271602033133, 0.8199595256024097, 0.8157782497176205, 0.8161135753953314, 0.8168974727033133, 0.8182505412274097, 0.8191962184676205, 0.819847750376506, 0.8126956066453314, 0.8201933711408133, 0.8140177899096386, 0.8149237575301205, 0.8245070124246988, 0.822411226939006, 0.8145472515060241, 0.8162768260542168, 0.8047095608998494, 0.8129397472703314, 0.8142119258283133, 0.8125632412462349, 0.8097659191453314, 0.8140692653426205, 0.8148016872176205, 0.8152384930346386, 0.8143942959337349, 0.8152899684676205, 0.8173857539533133, 0.8169783626694277, 0.8128176769578314, 0.8109660320971386, 0.8169989528426205, 0.8144957760730422, 0.8191962184676205, 0.8171813229480422, 0.8147708019578314, 0.8149943524096386, 0.8108336666980422, 0.8209360881024097, 0.818504976939006, 0.8086261059864458, 0.8139471950301205, 0.8196330242846386, 0.8174769390060241, 0.8129191570971386, 0.8169268872364458, 0.8130618175828314, 0.8189314876694277, 0.8140177899096386, 0.8211596385542168, 0.8182402461408133, 0.8162768260542168, 0.8141295651355422, 0.8157679546310241, 0.8153811535203314, 0.8190020825489458, 0.8191859233810241, 0.8149031673569277, 0.8206610622176205, 0.8139266048569277, 0.8173651637801205, 0.8147913921310241, 0.8113631282944277, 0.8162253506212349], "accuracy_test": 0.1914, "start": "2016-01-22 19:09:08.739000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0], "accuracy_train_last": 0.871853298611111, "batch_size_eval": 1024, "accuracy_train_std": [0.016232389309286475, 0.01918667739314128, 0.01782887205982346, 0.02039103602168606, 0.02119212476728981, 0.021055417979880045, 0.01956802277777805, 0.019933608920418986, 0.020135477962485465, 0.019534572772386422, 0.01885074104771031, 0.01811165853928385, 0.01680265476916087, 0.01735292632073347, 0.019269776517719682, 0.0185188559967162, 0.015875316561107945, 0.016409744526720012, 0.016098241679916928, 0.016843121068436388, 0.01602818090692478, 0.016003022657093555, 0.01583208180154094, 0.016094508060453518, 0.014566963552158871, 0.016449886383865773, 0.015582602565486676, 0.01548471735819803, 0.015991088577051005, 0.01635180303249806, 0.0162986656120328, 0.016322422831645554, 0.015612014654957148, 0.015511889638772166, 0.015477898813709628, 0.015104427974334329, 0.015133687453990016, 0.01640153606919891, 0.01725277699434868, 0.015163483503254279, 0.016094749128702086, 0.015660768991694624, 0.015165978406567325, 0.01469538407141606, 0.015360752421106067, 0.01521115598646853, 0.014998806714678323, 0.016024043827911973, 0.01492313338813614, 0.01596496064626911, 0.01497260737137371, 0.015259310708268197, 0.01631706604195875, 0.015084685456746487, 0.014911383238404428, 0.015130908588116299, 0.01538673348684961, 0.013989803627946612, 0.014217618155019807, 0.013906817864768477, 0.0137284491214187, 0.014697425104565766, 0.01216754605727542, 0.013209209374803448, 0.012892518614276666, 0.01388852092932038, 0.013158388083866965, 0.013621010789300541, 0.013843015116874748, 0.013737905002482752, 0.013428296703446124, 0.013154519076271546, 0.012967395659267246, 0.013896622588795208, 0.012541336919515577, 0.014488760826028225, 0.012815778377031281, 0.01277719775299192, 0.013014325999555381, 0.014353868082952019, 0.013001217003068149, 0.01365092532359185, 0.013454843354226262, 0.013914125298839017, 0.01447205292751844, 0.01384691124938704, 0.013726260522699362, 0.013833167836525629, 0.013646461995716503, 0.013716165159972291, 0.01270816317262211, 0.013634508342923382, 0.013481788786195825, 0.014985296955959905, 0.014314774593206793, 0.014444574317038312, 0.013673832400512979, 0.014313136615480034, 0.015092949662061657, 0.014310422136662945, 0.013754225149665913, 0.01449147931035778, 0.01467114023964857, 0.014584233714618259, 0.01414285965209953, 0.013367951184985273, 0.013438993500238772, 0.014559301172175649, 0.013745770720175184, 0.012756302046209004, 0.014023952201757742, 0.012030093225368712, 0.013388775015935429, 0.013168653024459185, 0.013049200125326652, 0.014901679072788547, 0.014239825206036411, 0.01471689766816756, 0.01397301772367121, 0.012917921599989793, 0.014767165618108721, 0.014249650704820425, 0.013929884224513253, 0.013648166423148056, 0.01285531020990709, 0.013586095631526733, 0.014431768805060965, 0.013625048928256141, 0.013566373965206774, 0.014930373187026166, 0.013368674961422952, 0.01388404203232096, 0.013368665446153217, 0.015305091058535891, 0.014841483007989497, 0.014208886385320512, 0.01289783734211308, 0.012767587097839882, 0.014277690535323252, 0.013870986540034267, 0.013777474271028956, 0.014895553791605513, 0.013278700869177842, 0.014654545133087497, 0.013653872111064514, 0.013384731828230799, 0.014049700510479692, 0.013867617673995889, 0.013965689683615223, 0.013688162940532465, 0.014142884117620876, 0.014333200221086957, 0.012735931049329439, 0.013295879532173803, 0.013662375650582047, 0.013472671743576307, 0.013995415830595291, 0.01347943236574274, 0.013627923148307276, 0.013012874332982403, 0.013206949824124658, 0.013374995357582603, 0.012120507457681748, 0.013923265735739659, 0.011869513456067755, 0.012073314183607681, 0.013352119453256754, 0.012504117143916133, 0.014073679057616424, 0.013171855627768852, 0.014266095874604803, 0.013485734862832277, 0.013556842057767098, 0.012946863401647394, 0.01292093310840372, 0.013962529766026082, 0.01390544744004556, 0.013135108119695229, 0.013421405839647044, 0.012532961631579274, 0.013076507556023837, 0.013816986948254971, 0.012670870624562318, 0.013265538360373533, 0.013628099972340378, 0.012885321469033397, 0.012132262256271726, 0.014325793324302368, 0.014364781999740173, 0.014717932502284568, 0.014290558209301925, 0.013087345995549672, 0.012852829150166696, 0.015067671770081078, 0.013373145226386461, 0.012754244962275958, 0.013637857486812167, 0.012568278893002544, 0.013071035968459432, 0.011625390737279086, 0.011476753302311021, 0.014768663984185764, 0.013871750967505697, 0.013724353924907404, 0.012503781066257972, 0.013284458566485552, 0.012102374455217396, 0.014007971349329799, 0.013539156212517531, 0.013455418044610616, 0.013038808594083939, 0.012556923223898847, 0.014034231279362838, 0.013556281277105531, 0.014326486639868963, 0.01470164664476861, 0.012932003392909104, 0.01223264961734538, 0.012088777552899234, 0.013053384261391689, 0.012452017772975563, 0.013033392654914136, 0.014185648662391807, 0.013955785576257656, 0.012869001347547745, 0.013952271400189627, 0.013696545365056156, 0.013557544348594141, 0.013733537338571434, 0.013269389447738993, 0.013652072937926552, 0.013468702673119953, 0.012633555070806986, 0.01255369077168615, 0.014961376164869533, 0.01407821493465619, 0.01565802611107387, 0.013626093201653209, 0.013163016778522982, 0.014282153526968924, 0.01451391595430119, 0.015076154535398635, 0.015066017371798662, 0.014248789706952456, 0.013241508588507181, 0.014584188368276714, 0.014404440400767549, 0.015365679230618438, 0.014481363698562132, 0.012941736726833322, 0.014856249295143462, 0.014378737315018635, 0.015024254560584266, 0.014588980430431523, 0.014561748426091646, 0.01414903685124574, 0.014589106792058668, 0.014339765481333854, 0.014752413734611022, 0.013368420892527133, 0.014937568213501326, 0.014564831597394032, 0.01369584259098793, 0.014128152754607525, 0.015862358831638085, 0.014338704796818444, 0.014665524846063357, 0.014751482199518525, 0.015267112493326676, 0.016200448661046175, 0.01605382988470497, 0.01479673398840496, 0.01529125120616025, 0.015251271939372818, 0.013807856672422977, 0.015414760141820777, 0.01426886898129193, 0.01513016730983425, 0.0147172657431284, 0.015260452098498668, 0.014249253256097577, 0.01358766658760899, 0.014577701206836562, 0.01538903226842368, 0.015059417781537156, 0.01556663097514481, 0.01637957451838488, 0.015273660988491347, 0.01539395241392], "accuracy_test_std": 0.10205900254264687, "error_valid": [0.5467235151543675, 0.4470200136483433, 0.425891554499247, 0.38998082172439763, 0.35057123023343373, 0.3144472420933735, 0.30226962537650603, 0.30303293251129515, 0.278087937688253, 0.2719535368034638, 0.2615569700677711, 0.25860669239457834, 0.24904402767319278, 0.24979703972138556, 0.24205513460090367, 0.23622664486069278, 0.23004076854292166, 0.22490352033132532, 0.22531973597515065, 0.21935888083584332, 0.2315865022590362, 0.22580948795180722, 0.22087520001882532, 0.22010159779743976, 0.2248020401920181, 0.21741605092243976, 0.21299063441265065, 0.21594091208584332, 0.21844408885542166, 0.22151643684111444, 0.20601203642695776, 0.21568647637424698, 0.21887059958584332, 0.20844314759036142, 0.2111492846385542, 0.20661209290286142, 0.21082425404743976, 0.21301122458584332, 0.20701948418674698, 0.20605321677334332, 0.2067547533885542, 0.2094094150037651, 0.20587967102786142, 0.20737540003765065, 0.2072430346385542, 0.21103750941265065, 0.20556493552334332, 0.20817841679216864, 0.21085513930722888, 0.21233027814382532, 0.21746752635542166, 0.21656155873493976, 0.2074871752635542, 0.20170869022966864, 0.20747688017695776, 0.21080366387424698, 0.20627676722515065, 0.21080366387424698, 0.20151602503765065, 0.20447659779743976, 0.2013130647590362, 0.1986981127635542, 0.20661209290286142, 0.1979142154555723, 0.20454719267695776, 0.19770096009036142, 0.19471979715737953, 0.20735628059111444, 0.1932446583207832, 0.19965408509036142, 0.20064094267695776, 0.1900002353162651, 0.19626700160015065, 0.2018013460090362, 0.1948830478162651, 0.20950207078313254, 0.19574783509036142, 0.20308234892695776, 0.19514777861445776, 0.1970597232680723, 0.1950757130082832, 0.19399767036897586, 0.19908491387424698, 0.1903458560805723, 0.19553457972515065, 0.19228868599397586, 0.20276761342243976, 0.19180040474397586, 0.1900502400225903, 0.1945668415850903, 0.1957875447100903, 0.1991555087537651, 0.19328583866716864, 0.20600174134036142, 0.19362116434487953, 0.2003247364457832, 0.19725385918674698, 0.1933976138930723, 0.1947403873305723, 0.19584931522966864, 0.19410944559487953, 0.1955639942582832, 0.1903149708207832, 0.1931534732680723, 0.19484186746987953, 0.2029396884412651, 0.19441535673945776, 0.19490363798945776, 0.19284756212349397, 0.1895825489457832, 0.19389619022966864, 0.19511689335466864, 0.1920754306287651, 0.19340790897966864, 0.1912003482680723, 0.20173957548945776, 0.18898249246987953, 0.1901017154555723, 0.18835155073418675, 0.1900708301957832, 0.1913224185805723, 0.1912209384412651, 0.1852189029555723, 0.19072236210466864, 0.18761912885918675, 0.1969067676957832, 0.18730439335466864, 0.19184158509036142, 0.1885353915662651, 0.19216661568147586, 0.18969432417168675, 0.19487275272966864, 0.1894913638930723, 0.19135330384036142, 0.19484186746987953, 0.1929093326430723, 0.18615428510918675, 0.18950165897966864, 0.1939564900225903, 0.1892163380082832, 0.1932961337537651, 0.19684646790286142, 0.1881691806287651, 0.18986786991716864, 0.1949845279555723, 0.18854568665286142, 0.1922989810805723, 0.1875588290662651, 0.1867543415850903, 0.1881691806287651, 0.1934182040662651, 0.19623611634036142, 0.1902443759412651, 0.19468008753765065, 0.1888810123305723, 0.1918106998305723, 0.1895428393260542, 0.19182099491716864, 0.1871926181287651, 0.1927166674510542, 0.1869278873305723, 0.1931740634412651, 0.1854321583207832, 0.19131212349397586, 0.1899796451430723, 0.18593073465737953, 0.18892219267695776, 0.1854630435805723, 0.18667345161897586, 0.18461884647966864, 0.1849747623305723, 0.19232986634036142, 0.1882912509412651, 0.18789415474397586, 0.18937958866716864, 0.18837214090737953, 0.1843129353350903, 0.1913430087537651, 0.18956342949924698, 0.1891766283885542, 0.19077383753765065, 0.18032579536897586, 0.18175975385918675, 0.18983698465737953, 0.1850453572100903, 0.18397760965737953, 0.1824112857680723, 0.19032526590737953, 0.18276720161897586, 0.18627635542168675, 0.18505565229668675, 0.1834790333207832, 0.18715143778237953, 0.1849232868975903, 0.18605280496987953, 0.18681611210466864, 0.18127147260918675, 0.18081407661897586, 0.18569688911897586, 0.18226862528237953, 0.18214655496987953, 0.18742646366716864, 0.18779267460466864, 0.18676463667168675, 0.18472032661897586, 0.1814038380082832, 0.1815259083207832, 0.18069200630647586, 0.1831128223832832, 0.18212596479668675, 0.1813832478350903, 0.17873888130647586, 0.18398790474397586, 0.18713084760918675, 0.1803360904555723, 0.19234016142695776, 0.18273631635918675, 0.18383494917168675, 0.18090526167168675, 0.1815053181475903, 0.1855851138930723, 0.19131212349397586, 0.1837540592055723, 0.18496446724397586, 0.18703966255647586, 0.1806508259600903, 0.18017283979668675, 0.1800404743975903, 0.18422175028237953, 0.18388642460466864, 0.18310252729668675, 0.1817494587725903, 0.18080378153237953, 0.18015224962349397, 0.18730439335466864, 0.17980662885918675, 0.18598221009036142, 0.18507624246987953, 0.17549298757530118, 0.17758877306099397, 0.18545274849397586, 0.1837231739457832, 0.19529043910015065, 0.18706025272966864, 0.18578807417168675, 0.1874367587537651, 0.19023408085466864, 0.18593073465737953, 0.18519831278237953, 0.18476150696536142, 0.1856057040662651, 0.18471003153237953, 0.18261424604668675, 0.1830216373305723, 0.18718232304216864, 0.18903396790286142, 0.18300104715737953, 0.18550422392695776, 0.18080378153237953, 0.18281867705195776, 0.18522919804216864, 0.18500564759036142, 0.18916633330195776, 0.1790639118975903, 0.18149502306099397, 0.1913738940135542, 0.18605280496987953, 0.18036697571536142, 0.18252306099397586, 0.18708084290286142, 0.1830731127635542, 0.18693818241716864, 0.1810685123305723, 0.18598221009036142, 0.1788403614457832, 0.18175975385918675, 0.1837231739457832, 0.18587043486445776, 0.18423204536897586, 0.18461884647966864, 0.1809979174510542, 0.18081407661897586, 0.1850968326430723, 0.17933893778237953, 0.1860733951430723, 0.18263483621987953, 0.18520860786897586, 0.1886368717055723, 0.1837746493787651], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.811595486058498, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.001642725067094242, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "optimization": "adam", "nb_data_augmentation": 3, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0002599089394696888, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.09069556005500676}, "accuracy_valid_max": 0.8245070124246988, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8162253506212349, "loss_train": [2.8428421020507812, 1.7910891771316528, 1.5364525318145752, 1.4217008352279663, 1.3435183763504028, 1.2855000495910645, 1.243833303451538, 1.20810866355896, 1.1822926998138428, 1.1607375144958496, 1.1403071880340576, 1.1236532926559448, 1.1083471775054932, 1.0939916372299194, 1.0808409452438354, 1.0684356689453125, 1.0583730936050415, 1.048791766166687, 1.0403800010681152, 1.0326663255691528, 1.0230408906936646, 1.0160086154937744, 1.0106909275054932, 1.0046576261520386, 0.9970964789390564, 0.9916277527809143, 0.9847465753555298, 0.9807869791984558, 0.9746952056884766, 0.9722291827201843, 0.9648230075836182, 0.9618456959724426, 0.9555627107620239, 0.952113687992096, 0.9477834105491638, 0.9441803097724915, 0.9413152933120728, 0.9379153251647949, 0.9322402477264404, 0.9293357729911804, 0.9251469373703003, 0.9235997200012207, 0.9202699661254883, 0.9162068367004395, 0.914131224155426, 0.9100634455680847, 0.9090980887413025, 0.905757486820221, 0.9013023376464844, 0.8988509774208069, 0.896386981010437, 0.8918173909187317, 0.8900520205497742, 0.8887059688568115, 0.8853527903556824, 0.8852131962776184, 0.8824045062065125, 0.8771867752075195, 0.8761396408081055, 0.8750128746032715, 0.8749553561210632, 0.8723537921905518, 0.8685279488563538, 0.8643998503684998, 0.867026150226593, 0.863151490688324, 0.8624498844146729, 0.858486533164978, 0.8564141392707825, 0.8537378311157227, 0.8530036211013794, 0.8525941967964172, 0.8493205904960632, 0.8482927680015564, 0.8469528555870056, 0.8444502353668213, 0.8447524905204773, 0.842707097530365, 0.8417777419090271, 0.8383439779281616, 0.8371924757957458, 0.8356083631515503, 0.8372417092323303, 0.8336633443832397, 0.8303855657577515, 0.8299835920333862, 0.8289578557014465, 0.8290024995803833, 0.8283047080039978, 0.8250607848167419, 0.8234516978263855, 0.8222373127937317, 0.821855366230011, 0.8190876841545105, 0.8184952735900879, 0.8156641721725464, 0.8153769373893738, 0.8151876330375671, 0.8146363496780396, 0.8125464916229248, 0.81324702501297, 0.8100022673606873, 0.8103355169296265, 0.8084116578102112, 0.8089125752449036, 0.8047240972518921, 0.8072112202644348, 0.8060527443885803, 0.8033899664878845, 0.8010802268981934, 0.7996038198471069, 0.7984947562217712, 0.7995522618293762, 0.7995150685310364, 0.7951480150222778, 0.7975925207138062, 0.7947766780853271, 0.7930048704147339, 0.7947890758514404, 0.7902141809463501, 0.7913393378257751, 0.7899097800254822, 0.7867500185966492, 0.7865472435951233, 0.7872992157936096, 0.7869572043418884, 0.7844314575195312, 0.783598780632019, 0.7843170762062073, 0.7823112607002258, 0.7810506224632263, 0.7793643474578857, 0.7816950678825378, 0.7795199751853943, 0.7781801819801331, 0.7773348093032837, 0.7774606347084045, 0.7767829895019531, 0.7758740186691284, 0.7754542827606201, 0.7730929255485535, 0.7737478017807007, 0.7716885209083557, 0.7702698111534119, 0.7711469531059265, 0.7703030705451965, 0.7704640030860901, 0.767589807510376, 0.7669437527656555, 0.7669264078140259, 0.7670995593070984, 0.766201376914978, 0.7656069993972778, 0.762873113155365, 0.7634248733520508, 0.7626142501831055, 0.7628618478775024, 0.7594391703605652, 0.7626973986625671, 0.7603570818901062, 0.7592507600784302, 0.7577555775642395, 0.7587339282035828, 0.758232593536377, 0.7569835782051086, 0.756152868270874, 0.7545052766799927, 0.7533996105194092, 0.7537496089935303, 0.754666805267334, 0.7515574097633362, 0.7523418068885803, 0.7507748007774353, 0.7517829537391663, 0.7505443096160889, 0.7497379779815674, 0.7497945427894592, 0.7494155764579773, 0.748939573764801, 0.7478386759757996, 0.7465305328369141, 0.7476118803024292, 0.7457587718963623, 0.7427875399589539, 0.7456904649734497, 0.7425227165222168, 0.7423038482666016, 0.7431321740150452, 0.7427269220352173, 0.7408466935157776, 0.7399626970291138, 0.7408922910690308, 0.740444540977478, 0.740725040435791, 0.7407817840576172, 0.7375086545944214, 0.7379407286643982, 0.7377237677574158, 0.737269401550293, 0.7364975810050964, 0.7348495721817017, 0.7359391450881958, 0.7372661232948303, 0.7352524399757385, 0.7338405847549438, 0.7334386110305786, 0.7318469285964966, 0.7324952483177185, 0.7312546372413635, 0.7327747344970703, 0.732810378074646, 0.727206826210022, 0.7286535501480103, 0.728378415107727, 0.7295973300933838, 0.730451762676239, 0.729931116104126, 0.7293470501899719, 0.7289998531341553, 0.7295725345611572, 0.7257513999938965, 0.7255481481552124, 0.7256531715393066, 0.7258595824241638, 0.723864734172821, 0.7247371673583984, 0.7249957919120789, 0.7236812114715576, 0.7255067825317383, 0.7218279242515564, 0.7241297960281372, 0.7215772271156311, 0.7207474112510681, 0.7200942039489746, 0.7189549803733826, 0.7213777303695679, 0.7193065285682678, 0.7177337408065796, 0.7181941866874695, 0.7179292440414429, 0.7169719338417053, 0.7172218561172485, 0.7176312208175659, 0.715434730052948, 0.7178078293800354, 0.7156285643577576, 0.7152653336524963, 0.715425431728363, 0.7152094841003418, 0.7135400772094727, 0.7135879397392273, 0.713234543800354, 0.7123009562492371, 0.7116386890411377, 0.7146700620651245, 0.7129238247871399, 0.7112994194030762, 0.7112249135971069, 0.7126335501670837, 0.7103112936019897, 0.7104187607765198, 0.7083850502967834, 0.7089226245880127, 0.7074193954467773, 0.7071676254272461, 0.7069566249847412, 0.7078865170478821, 0.7093949913978577, 0.7065351605415344, 0.7081524133682251, 0.7092193961143494, 0.7062707543373108, 0.7064464688301086, 0.7059380412101746, 0.7064951658248901, 0.7034045457839966, 0.7048051953315735, 0.7047807574272156, 0.7036491632461548, 0.7033487558364868, 0.7016057372093201, 0.7023317813873291, 0.701789915561676, 0.7021294832229614, 0.702957034111023, 0.7008959650993347, 0.6995110511779785, 0.7003631591796875, 0.701021671295166], "accuracy_train_first": 0.46202671505860093, "model": "residualv4", "loss_std": [0.9214044809341431, 0.26306694746017456, 0.24781601130962372, 0.24399366974830627, 0.24432073533535004, 0.24105927348136902, 0.2406529039144516, 0.23898455500602722, 0.23932336270809174, 0.2383730113506317, 0.2359035760164261, 0.23719683289527893, 0.2363816201686859, 0.23521775007247925, 0.23381775617599487, 0.235133096575737, 0.23331917822360992, 0.2313251495361328, 0.23283152282238007, 0.23311689496040344, 0.23069170117378235, 0.23134730756282806, 0.23275616765022278, 0.23259034752845764, 0.22960549592971802, 0.22919876873493195, 0.2280549705028534, 0.2296852469444275, 0.2288794070482254, 0.22944098711013794, 0.22958271205425262, 0.2289775311946869, 0.22848284244537354, 0.22853723168373108, 0.22754117846488953, 0.22802357375621796, 0.22726678848266602, 0.2257767617702484, 0.22603674232959747, 0.22558355331420898, 0.2252284735441208, 0.2257433533668518, 0.22325661778450012, 0.22460375726222992, 0.22538796067237854, 0.2234134078025818, 0.2237170934677124, 0.2228878289461136, 0.2221979945898056, 0.2223009318113327, 0.2242538034915924, 0.22165824472904205, 0.22112569212913513, 0.22136129438877106, 0.220652773976326, 0.22218497097492218, 0.2211858332157135, 0.21973934769630432, 0.22170479595661163, 0.2198798507452011, 0.2228289544582367, 0.22065207362174988, 0.22152815759181976, 0.22080282866954803, 0.21945589780807495, 0.2218565195798874, 0.21930234134197235, 0.21841788291931152, 0.21949230134487152, 0.219660684466362, 0.21921740472316742, 0.21659432351589203, 0.2177424132823944, 0.21857811510562897, 0.21882791817188263, 0.2157461941242218, 0.21769022941589355, 0.21914631128311157, 0.21947228908538818, 0.21744363009929657, 0.2183029055595398, 0.21939918398857117, 0.21777065098285675, 0.21807163953781128, 0.21693143248558044, 0.21738317608833313, 0.21791869401931763, 0.21769684553146362, 0.21702024340629578, 0.21434906125068665, 0.2162395566701889, 0.21526409685611725, 0.21409019827842712, 0.2151397466659546, 0.2150316685438156, 0.21738335490226746, 0.2156289964914322, 0.2133219987154007, 0.2151763141155243, 0.2137375771999359, 0.21521273255348206, 0.21440304815769196, 0.21518267691135406, 0.21342436969280243, 0.21450595557689667, 0.21352045238018036, 0.2148219347000122, 0.21579429507255554, 0.21541737020015717, 0.21247068047523499, 0.21324223279953003, 0.21320508420467377, 0.21161499619483948, 0.21446989476680756, 0.21254214644432068, 0.2135745733976364, 0.21286752820014954, 0.21233069896697998, 0.2131313532590866, 0.21326161921024323, 0.2129795104265213, 0.21029984951019287, 0.21195092797279358, 0.2106969654560089, 0.21288733184337616, 0.210365891456604, 0.21042700111865997, 0.21349464356899261, 0.2100314199924469, 0.211608424782753, 0.21219268441200256, 0.21061885356903076, 0.21128088235855103, 0.21155141294002533, 0.21080200374126434, 0.21026481688022614, 0.20993132889270782, 0.20913943648338318, 0.2108554244041443, 0.2116136997938156, 0.2107478678226471, 0.21025142073631287, 0.20936138927936554, 0.21025431156158447, 0.20827427506446838, 0.2102220356464386, 0.20958298444747925, 0.20950178802013397, 0.20810392498970032, 0.20813918113708496, 0.20835158228874207, 0.20819374918937683, 0.20930801331996918, 0.20660793781280518, 0.2070002555847168, 0.20837891101837158, 0.20773562788963318, 0.2079705446958542, 0.20752999186515808, 0.2056412398815155, 0.20904140174388885, 0.2070525586605072, 0.20746660232543945, 0.20632721483707428, 0.20835785567760468, 0.2063073217868805, 0.20763486623764038, 0.20782692730426788, 0.2048725187778473, 0.2083970159292221, 0.20752744376659393, 0.20775875449180603, 0.2074168175458908, 0.2076820284128189, 0.20761516690254211, 0.20763090252876282, 0.2071254849433899, 0.20729777216911316, 0.20806339383125305, 0.20752006769180298, 0.20495066046714783, 0.20496045053005219, 0.20632903277873993, 0.20487500727176666, 0.2066206932067871, 0.20481330156326294, 0.20575359463691711, 0.20627033710479736, 0.20606064796447754, 0.20414011180400848, 0.20588232576847076, 0.2061769962310791, 0.20590375363826752, 0.20561529695987701, 0.20379993319511414, 0.20437996089458466, 0.20659449696540833, 0.20463305711746216, 0.2071908414363861, 0.20502154529094696, 0.20463700592517853, 0.20671425759792328, 0.20443753898143768, 0.20738503336906433, 0.20390963554382324, 0.2056308537721634, 0.20163539052009583, 0.20510907471179962, 0.20344753563404083, 0.20533670485019684, 0.2040761411190033, 0.20285139977931976, 0.20373210310935974, 0.20675456523895264, 0.20459051430225372, 0.20661543309688568, 0.2047806829214096, 0.20490503311157227, 0.20473997294902802, 0.2054566740989685, 0.20449011027812958, 0.20444746315479279, 0.2034483700990677, 0.2024824023246765, 0.20409592986106873, 0.20538434386253357, 0.20352676510810852, 0.2027561217546463, 0.20506057143211365, 0.20581448078155518, 0.20498384535312653, 0.20363712310791016, 0.20470993220806122, 0.20289745926856995, 0.20295022428035736, 0.2045312076807022, 0.20272845029830933, 0.2053207904100418, 0.20360492169857025, 0.20520631968975067, 0.20263713598251343, 0.20353637635707855, 0.20537473261356354, 0.2045949548482895, 0.2063596248626709, 0.20298443734645844, 0.20235100388526917, 0.20266187191009521, 0.20383135974407196, 0.20287735760211945, 0.2054029405117035, 0.20475856959819794, 0.20172075927257538, 0.20367605984210968, 0.20598898828029633, 0.20164407789707184, 0.203042134642601, 0.20384231209754944, 0.20346322655677795, 0.20177511870861053, 0.2025764137506485, 0.20020708441734314, 0.2018788456916809, 0.20163242518901825, 0.20194494724273682, 0.20296309888362885, 0.20087319612503052, 0.20220620930194855, 0.2018892616033554, 0.20288120210170746, 0.2033429592847824, 0.20084655284881592, 0.20019035041332245, 0.20366717875003815, 0.2040533423423767, 0.199327751994133, 0.20146454870700836, 0.19987116754055023, 0.2012600600719452, 0.20189692080020905, 0.20337438583374023, 0.2029479295015335, 0.20043934881687164, 0.2022622674703598, 0.2005147784948349, 0.2000216543674469, 0.2006986141204834, 0.20025913417339325, 0.20125584304332733]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:15 2016", "state": "available"}], "summary": "d9f9186417ab77f0da6a04fd76b33143"}