{"content": {"hp_model": {"f0": 64, "f1": 64, "f2": 32, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.521605372428894, 1.0474352836608887, 0.8547245860099792, 0.7315868139266968, 0.6417795419692993, 0.5778207182884216, 0.5289255380630493, 0.48459967970848083, 0.4491276443004608, 0.4182673990726471, 0.3881884515285492, 0.3669087886810303, 0.342883437871933, 0.32085782289505005, 0.30222809314727783, 0.2875068485736847, 0.2691437900066376, 0.2576284110546112, 0.2425099015235901, 0.23204559087753296, 0.22268158197402954, 0.21067096292972565, 0.20090320706367493, 0.19467873871326447, 0.18469156324863434, 0.17639221251010895, 0.17056983709335327, 0.16464689373970032, 0.1562965363264084, 0.15388357639312744, 0.1486310213804245, 0.14325706660747528, 0.1417933702468872, 0.13525895774364471, 0.13204355537891388, 0.1290585696697235, 0.12715041637420654, 0.12423630058765411, 0.1216907948255539, 0.11860982328653336, 0.11409572511911392, 0.11388182640075684, 0.11326491087675095, 0.11096019297838211, 0.11008833348751068, 0.10797850042581558, 0.10685423761606216, 0.10517061501741409, 0.10482105612754822, 0.1028527244925499, 0.10194128751754761, 0.10008926689624786, 0.10063396394252777, 0.09917318820953369, 0.09924167394638062, 0.09771932661533356, 0.09697305411100388, 0.09550977498292923, 0.09565304964780807, 0.09677291661500931, 0.09482134878635406, 0.09497293829917908, 0.09389776736497879, 0.09442504495382309, 0.09221092611551285, 0.09486353397369385, 0.09321720153093338, 0.09165502339601517, 0.09211112558841705, 0.09158376604318619, 0.09125924110412598, 0.09133576601743698, 0.0920255184173584, 0.0917128324508667, 0.08927503973245621, 0.09082891047000885, 0.08890169113874435, 0.08992380648851395, 0.08924965560436249, 0.08976873010396957, 0.08828302472829819, 0.08988580107688904, 0.08933602273464203, 0.08948016911745071, 0.09005622565746307, 0.08867587894201279, 0.08795776963233948, 0.0900576114654541, 0.08844464272260666, 0.08910854160785675, 0.08764398843050003, 0.0890791043639183, 0.08860268443822861, 0.08955838531255722, 0.08784319460391998, 0.09008985012769699, 0.08910112828016281, 0.0869351401925087, 0.08823883533477783, 0.0904664471745491, 0.08894450217485428, 0.08769764006137848, 0.08827215433120728, 0.09009803831577301, 0.08923087269067764, 0.08800455182790756, 0.08707103878259659, 0.08934606611728668, 0.08801263570785522, 0.0897153839468956, 0.08800750225782394, 0.08872734755277634, 0.08846800774335861, 0.08880103379487991, 0.08784154802560806], "moving_avg_accuracy_train": [0.0595973671384736, 0.12362711498419618, 0.1858360353725429, 0.24768457425984564, 0.3062656000379954, 0.36052068815735017, 0.4105518647158307, 0.4573048595957611, 0.5003984647733666, 0.5394385478998966, 0.5758530940708243, 0.609556353294925, 0.6406818379012944, 0.6695154434303325, 0.6957517177588571, 0.71976883240093, 0.7419120443585576, 0.762326747026338, 0.7813579604916168, 0.7984162981460818, 0.8143850385672617, 0.8286801029379719, 0.842131598371611, 0.8543588880488002, 0.8658587415035179, 0.8764270654544027, 0.8863826964816369, 0.8955426551061292, 0.9038145557027053, 0.9114173042610338, 0.9183923114456723, 0.9248535046677994, 0.9306731207188765, 0.9360549704398552, 0.9409870268923167, 0.9456165759507318, 0.9497483289199812, 0.9535947537280107, 0.9571076532802281, 0.9603390173415094, 0.9633960545204722, 0.9661497852279857, 0.9686792600897386, 0.9708953696450874, 0.9730107399341777, 0.9749773161633974, 0.9766798415030378, 0.9782539669872855, 0.9796775832718995, 0.980998509653089, 0.9822291239770935, 0.9832994744877452, 0.9843185935187603, 0.9852590881835878, 0.9861473500116852, 0.9869420993105351, 0.9876922869604616, 0.9882953762323003, 0.988926512231717, 0.9895200752192781, 0.9900287052711783, 0.9905097238059837, 0.9909402792896802, 0.9913301764714542, 0.9916625187933932, 0.9919685302319295, 0.9922973829004125, 0.9925678097139611, 0.992820494441393, 0.9930572112913197, 0.9932679313074443, 0.9934761805124326, 0.9936752305409696, 0.9938474001202244, 0.9939999915439255, 0.9941048438395605, 0.9942526893282512, 0.9943904005656918, 0.9945282555234268, 0.9946360489437216, 0.9947121366827012, 0.9948178180287353, 0.9948850294544517, 0.9949595066792722, 0.995026500132792, 0.9951169851266649, 0.9951938073723502, 0.9952629113446483, 0.995318129473288, 0.9953911133259776, 0.9954405227517317, 0.995482630037282, 0.9955437780823725, 0.9955825713301061, 0.9956198104018759, 0.9956439889224118, 0.9956402090028081, 0.9956437825215934, 0.9956446374908717, 0.995675669946565, 0.9956942985614508, 0.9957087391660384, 0.99571472421492, 0.9957247971053512, 0.9957478496484152, 0.9957616214907442, 0.995767004653593, 0.9957508871120525, 0.9957596328127613, 0.9957838160338844, 0.9957939912376665, 0.9957845116817754, 0.9957945812719496, 0.9957850427126302, 0.9957857225556621], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.058157826618975894, 0.12075818900602406, 0.18059399119917163, 0.23949095267789905, 0.29519303046169043, 0.34585392084549127, 0.392071280784662, 0.4350870383895542, 0.47425288039020724, 0.509376979352316, 0.5412919322548103, 0.5708790005598262, 0.597771798687202, 0.6225186034287981, 0.6451467906198038, 0.6649556361248415, 0.6837836912058816, 0.7003687598206096, 0.7153228241623438, 0.7289523805074046, 0.7419911127126882, 0.7531959218103954, 0.7638082408680607, 0.7730856257891612, 0.7821281315460885, 0.7901788784912538, 0.7974744083755622, 0.8043689456065299, 0.8102678238244915, 0.8157731562293165, 0.8208897353258878, 0.8252728709329827, 0.8293987394307989, 0.8327050710129449, 0.8358324013551744, 0.8387314183732715, 0.8411483097155378, 0.843593096119737, 0.8457923743748567, 0.8475722942698258, 0.8494346878661866, 0.8510365704067516, 0.8526623996706698, 0.8538529732860577, 0.8551574526423164, 0.8563213360490184, 0.8572579383251406, 0.8579920466010603, 0.8585530287820687, 0.8592451362483648, 0.8600623159593718, 0.8605404005343683, 0.8612402608480247, 0.861820277496656, 0.8623544995116742, 0.8627752936776002, 0.8632607831822047, 0.8636133040262582, 0.8640892641921565, 0.8645085098361939, 0.8648084706936889, 0.865180209750073, 0.8654272666647495, 0.8657350671067082, 0.8660517971242001, 0.8661130095428042, 0.8663400286657076, 0.8665178727965013, 0.8666321929151946, 0.8668439147946089, 0.8669378377447414, 0.8671332611897703, 0.8672592846566367, 0.8672984340806568, 0.8673713191646845, 0.8673748510753997, 0.8674634790137934, 0.8674700019708478, 0.8675724993735371, 0.8676281259422075, 0.8674940548766013, 0.8676063540199652, 0.8676230035389024, 0.8677244668333556, 0.8677293050709538, 0.8675861456011326, 0.8675671653595434, 0.8674758114459535, 0.8673834449097919, 0.8673359066123368, 0.8673419502696272, 0.867297531927529, 0.8672585849283002, 0.8672357396602443, 0.8673393082488132, 0.8673450117424559, 0.8672758731905749, 0.8672390920650415, 0.8673535029357211, 0.8673323433895135, 0.8674018375426555, 0.8673890810756641, 0.8673287721303719, 0.8673721503296088, 0.8673002979190124, 0.8673343165081352, 0.8673283121445958, 0.8672740800924104, 0.8673595485891934, 0.8673398434949579, 0.8673332864327362, 0.8672907639829867, 0.8672657303181217, 0.8673296787471528, 0.8673485522222116], "moving_var_accuracy_train": [0.031966615528542124, 0.06566823145836925, 0.09393095629548526, 0.11896503652838451, 0.13795416210652833, 0.15065127717742605, 0.15811421711011614, 0.16197537817128974, 0.1624913696189909, 0.15995938547182922, 0.1558976194801579, 0.15053104467308445, 0.14419710233360808, 0.1372597833704849, 0.12972888384921075, 0.12194739162586395, 0.11416554898548133, 0.10649983485205806, 0.09910953514050132, 0.09181746357825486, 0.08493072325618062, 0.07827679071882727, 0.07207759621155548, 0.06621539610604901, 0.060784076160763936, 0.05571087378486516, 0.05103181770873249, 0.04668377951588094, 0.04263122061960956, 0.03888831462841911, 0.03543733969260904, 0.03226932888403109, 0.02934720737446558, 0.026673165394791813, 0.024224775482965036, 0.021995192455026978, 0.019949315652914395, 0.01808753894185738, 0.016389849217047364, 0.014844839718611495, 0.013444465033572392, 0.01216826582550068, 0.01100902343063677, 0.009952321361624867, 0.008997362348602078, 0.00813243291232986, 0.007345276953885931, 0.006633050097858762, 0.0059879852380052495, 0.005404890332745427, 0.0048780310040008905, 0.0044005387555416725, 0.0039698323123818985, 0.0035808098530748307, 0.0032298299494446436, 0.0029125315925323816, 0.0026263434668700645, 0.00236698257021132, 0.0021338693070380257, 0.0019236532295160446, 0.001733616247331704, 0.0015623370320759708, 0.0014077717310892446, 0.0012683627362915176, 0.001142520525432933, 0.001029111259894275, 0.0009271734306029627, 0.000835114263496041, 0.0007521774832897329, 0.000677464048764113, 0.0006101172702144616, 0.0005494958527754198, 0.0004949028557226235, 0.0004456793514265482, 0.00040132097356717755, 0.0003612878222455594, 0.0003253557646177392, 0.0002929908676202222, 0.0002638628167625491, 0.00023758110987942392, 0.00021387510298768883, 0.00019258810961101608, 0.00017336995503163593, 0.00015608288124162518, 0.00014051498622279327, 0.00012653717540755954, 0.00011393657278369279, 0.0001025858937362098, 9.2354745738163e-05, 8.316721094912754e-05, 7.487246147639487e-05, 6.740117254022316e-05, 6.0694707036966414e-05, 5.4638780577897256e-05, 4.918738325630399e-05, 4.4273906338371346e-05, 3.98466442946641e-05, 3.586209479552627e-05, 3.227589189472585e-05, 2.9056969825010414e-05, 2.6154396070142436e-05, 2.354083324267591e-05, 2.1187072305699353e-05, 1.9069278243224176e-05, 1.7167133196577215e-05, 1.5452126849689715e-05, 1.3907174970701055e-05, 1.2518795449938752e-05, 1.126760429047286e-05, 1.0146107315080658e-05, 9.132428396520657e-06, 8.219994314687617e-06, 7.398907453035352e-06, 6.659835564756818e-06, 5.993856167960068e-06], "duration": 135928.316246, "accuracy_train": [0.5959736713847361, 0.6998948455956995, 0.7457163188676633, 0.8043214242455703, 0.8334948320413437, 0.848816481231543, 0.8608324537421558, 0.8780818135151348, 0.8882409113718162, 0.8907992960386674, 0.9035840096091732, 0.9128856863118309, 0.9208111993586194, 0.9290178931916758, 0.9318781867155776, 0.9359228641795865, 0.9412009519772055, 0.9460590710363603, 0.9526388816791252, 0.951941337036268, 0.9581037023578812, 0.9573356822743633, 0.9631950572743633, 0.9644044951435032, 0.9693574225959765, 0.9715419810123662, 0.9759833757267442, 0.9779822827265596, 0.97826166107189, 0.9798420412859912, 0.9811673761074198, 0.9830042436669435, 0.9830496651785714, 0.9844916179286637, 0.9853755349644703, 0.9872825174764673, 0.9869341056432264, 0.9882125770002769, 0.9887237492501846, 0.9894212938930418, 0.990909389131137, 0.9909333615956073, 0.991444533845515, 0.9908403556432264, 0.9920490725359912, 0.992676502226375, 0.9920025695598007, 0.992421096345515, 0.9924901298334257, 0.9928868470837948, 0.9933046528931341, 0.9929326290836102, 0.9934906647978959, 0.9937235401670359, 0.9941417064645626, 0.9940948430001846, 0.9944439758098007, 0.9937231796788483, 0.9946067362264673, 0.9948621421073275, 0.9946063757382798, 0.9948388906192323, 0.9948152786429494, 0.9948392511074198, 0.9946535996908453, 0.994722633178756, 0.9952570569167589, 0.9950016510358989, 0.9950946569882798, 0.9951876629406607, 0.9951644114525655, 0.9953504233573275, 0.9954666807978036, 0.995396926333518, 0.9953733143572352, 0.9950485145002769, 0.9955832987264673, 0.9956298017026578, 0.9957689501430418, 0.995606189726375, 0.995396926333518, 0.9957689501430418, 0.9954899322858989, 0.9956298017026578, 0.9956294412144703, 0.9959313500715209, 0.995885207583518, 0.9958848470953304, 0.9958150926310447, 0.9960479680001846, 0.995885207583518, 0.9958615956072352, 0.9960941104881875, 0.9959317105597084, 0.9959549620478036, 0.9958615956072352, 0.995606189726375, 0.9956759441906607, 0.995652332214378, 0.9959549620478036, 0.9958619560954227, 0.9958387046073275, 0.9957685896548542, 0.9958154531192323, 0.9959553225359912, 0.9958855680717055, 0.9958154531192323, 0.9956058292381875, 0.99583834411914, 0.9960014650239941, 0.9958855680717055, 0.995699195678756, 0.995885207583518, 0.995699195678756, 0.9957918411429494], "end": "2016-02-05 03:25:26.741000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0], "moving_var_accuracy_valid": [0.030440995173385752, 0.06266614399495497, 0.08862243861233685, 0.11097986339394346, 0.12780637027943303, 0.13812446558180508, 0.14353641826134636, 0.1458359750561173, 0.14505804616708662, 0.14165556250147807, 0.1366570842202461, 0.13086992729619262, 0.12429193788665145, 0.11737438320225445, 0.11024525858198976, 0.10275224596597285, 0.09566748229258763, 0.08857631457192602, 0.08173129947776397, 0.07523005278545626, 0.06923712434460054, 0.06344334163238502, 0.05811259931118169, 0.0530759682188319, 0.04850427359022527, 0.04423717696857853, 0.04029248207835621, 0.0366910456631834, 0.033335111974938124, 0.030274378941432853, 0.02748255548215281, 0.02490720683368918, 0.02256969126807171, 0.020411108598044406, 0.018458019493864834, 0.016687856241519295, 0.01507164289121026, 0.013618271427148651, 0.012299975708024765, 0.011098491170714852, 0.010019858642813257, 0.009040967027595836, 0.008160660211994969, 0.00735735138059839, 0.006636931240056697, 0.005985429737310596, 0.005394781777992273, 0.0048601538348400095, 0.004376970760422689, 0.003943584799084546, 0.003555236363296823, 0.0032017698107147875, 0.002886001069770992, 0.002600428736608098, 0.0023429544013992584, 0.0021102525708300286, 0.0019013486142787554, 0.0017123321913603106, 0.0015431378149399768, 0.001390405935636378, 0.0012521751307170029, 0.0011282013269796748, 0.0010159305283535122, 0.0009151901455267912, 0.0008245739921099354, 0.0007421503155406641, 0.0006683991231260718, 0.0006018438676271845, 0.0005417771026703085, 0.00048800282779128205, 0.00043928193869720815, 0.0003956974577332899, 0.00035627064918777, 0.0003206573783656029, 0.00028863945064830615, 0.00025977561785301524, 0.00023386875027088907, 0.00021048225818451878, 0.0001895285838240894, 0.0001706035742779588, 0.00015370499230585817, 0.0001384479929536749, 0.00012460568851663494, 0.000112237772866063, 0.0001010142062563442, 9.109723733490539e-05, 8.19907558475519e-05, 7.386679010055039e-05, 6.655689528351782e-05, 5.9921544762690406e-05, 5.392971901856236e-05, 4.855450401873895e-05, 4.3712705435605415e-05, 3.93461320484978e-05, 3.550805691649149e-05, 3.195754399339994e-05, 2.8804810848265932e-05, 2.5936505424198866e-05, 2.346066350774591e-05, 2.1118626694532745e-05, 1.9050228960967812e-05, 1.714667061192197e-05, 1.546473807067022e-05, 1.393519927712453e-05, 1.2588144269588728e-05, 1.1339745222283044e-05, 1.0206095171488361e-05, 9.211955693697772e-06, 8.356503899809199e-06, 7.524348126477789e-06, 6.772300269414822e-06, 6.111343671067648e-06, 5.505849463350013e-06, 4.9920691311950445e-06, 4.496068090622701e-06], "accuracy_test": 0.872297512755102, "start": "2016-02-03 13:39:58.425000", "learning_rate_per_epoch": [0.008145933970808983, 0.007544591091573238, 0.006987640168517828, 0.006471804343163967, 0.005994047969579697, 0.005551560316234827, 0.005141737405210733, 0.004762168042361736, 0.004410618916153908, 0.004085021559149027, 0.0037834602408111095, 0.0035041605588048697, 0.003245479194447398, 0.003005893900990486, 0.002783995121717453, 0.002578477142378688, 0.002388130873441696, 0.002211836166679859, 0.002048555761575699, 0.0018973288824781775, 0.001757265767082572, 0.0016275423113256693, 0.0015073951799422503, 0.0013961174990981817, 0.0012930544326081872, 0.0011975995730608702, 0.0011091913329437375, 0.0010273094521835446, 0.0009514722041785717, 0.0008812333690002561, 0.0008161796722561121, 0.0007559282821603119, 0.0007001247722655535, 0.0006484407349489629, 0.0006005720351822674, 0.0005562370643019676, 0.0005151749937795103, 0.00047714414540678263, 0.0004419207980390638, 0.00040929767419584095, 0.0003790828341152519, 0.00035109848249703646, 0.0003251799789723009, 0.00030117479036562145, 0.00027894170489162207, 0.0002583499008323997, 0.00023927820438984782, 0.00022161439119372517, 0.00020525454601738602, 0.00019010240794159472, 0.00017606881738174707, 0.0001630712067708373, 0.00015103309124242514, 0.00013988364662509412, 0.00012955727288499475, 0.00011999320122413337, 0.0001111351593863219, 0.00010293102968716994, 9.533253614790738e-05, 8.829497528495267e-05, 8.177693234756589e-05, 7.574006303912029e-05, 7.01488388585858e-05, 6.497036520158872e-05, 6.017417399561964e-05, 5.573204543907195e-05, 5.16178370162379e-05, 4.78073452541139e-05, 4.427814928931184e-05, 4.100948353880085e-05, 3.798211400862783e-05, 3.5178229154553264e-05, 3.258133074268699e-05, 3.017613744304981e-05, 2.7948499337071553e-05, 2.5885306968120858e-05, 2.3974422219907865e-05, 2.2204601918929256e-05, 2.056543053186033e-05, 1.9047265595872886e-05, 1.7641174054006115e-05, 1.6338881323463283e-05, 1.5132725820876658e-05, 1.4015609849593602e-05, 1.2980960491404403e-05, 1.2022690498270094e-05, 1.1135161003039684e-05, 1.0313149687135592e-05, 9.551820767228492e-06, 8.84669407241745e-06, 8.193620487872977e-06, 7.588757398480084e-06, 7.028545951470733e-06, 6.509690138045698e-06, 6.029136784491129e-06, 5.584058726526564e-06, 5.171836619410897e-06, 4.79004529552185e-06, 4.436438302946044e-06, 4.108935172553174e-06, 3.805608685070183e-06, 3.5246739571448416e-06, 3.2644782095303526e-06, 3.023490535269957e-06, 2.8002928047499154e-06, 2.5935717076208675e-06, 2.4021110220928676e-06, 2.22478433897777e-06, 2.06054801310529e-06, 1.9084359337284695e-06, 1.7675529306870885e-06, 1.637069999560481e-06, 1.5162195268203504e-06, 1.4042904012967483e-06, 1.3006240351387532e-06], "accuracy_train_first": 0.5959736713847361, "accuracy_train_last": 0.9957918411429494, "batch_size_eval": 1024, "accuracy_train_std": [0.02160914832212071, 0.02114098946457208, 0.017830762443260754, 0.021866796623338642, 0.02031375799030011, 0.018822268814244647, 0.020557200939933122, 0.020177958840033098, 0.01853954908581146, 0.01815857140877643, 0.016535487966895367, 0.016728018115899742, 0.017496579182772958, 0.017554752575187158, 0.017842110224810137, 0.01675459801823983, 0.014886866426782218, 0.015466214917473414, 0.013362194748418755, 0.013129663537554485, 0.01223472316092862, 0.013943934716397016, 0.01211860107096534, 0.011935017718437326, 0.010773568385108054, 0.009963714307334835, 0.008204440811087973, 0.007841818696199866, 0.007540407448954215, 0.008533463958128698, 0.006626469967083014, 0.006149025029068415, 0.007396933895957481, 0.006192543439807397, 0.005897341465930913, 0.0052147925440717445, 0.004856177170050356, 0.004391565969437199, 0.004134628381531395, 0.004083191558328767, 0.004179507139147318, 0.0042640246784707, 0.0036906842785624657, 0.004230196049275577, 0.00321547659334064, 0.00372388067027237, 0.0033582624873299263, 0.0035074291711537147, 0.0034201366756112547, 0.0033564851491511625, 0.0031218911217529605, 0.0029518335029956226, 0.0029963485834329207, 0.002835535097281313, 0.002945155840565636, 0.0031102611637079066, 0.0029641661834424555, 0.0027716869177964168, 0.0021439622410466064, 0.002584612474902761, 0.0026037523018316994, 0.0024698496635071213, 0.0026146626541674167, 0.0022778506359149788, 0.0027380550369733134, 0.0026195562718617513, 0.002350095293258452, 0.002356094542537115, 0.0020386803576542913, 0.002269547491461621, 0.0023245116361965625, 0.002053255687004318, 0.002075345281043669, 0.002058498756148978, 0.0019309343491510555, 0.0023085180898136494, 0.0021540368887848303, 0.0018598480329768648, 0.0019259346173834868, 0.001897290333196785, 0.001968276562777394, 0.0021593745545509997, 0.0020437055239515456, 0.0021854092348258846, 0.002035704595816462, 0.001964142748844722, 0.0019938876448112775, 0.00206138487798956, 0.0021344545157148272, 0.002032366734822036, 0.001959425617897507, 0.001939643064715849, 0.0019534868186472567, 0.0020208036086580153, 0.0019942691023493754, 0.002064402796947927, 0.001909220697333857, 0.0020787865074337873, 0.002046686224777025, 0.0019942691023493754, 0.002064106192244751, 0.001906866090861565, 0.0021491028091380846, 0.0018976382046146398, 0.001981817080786918, 0.0019699530090535795, 0.002013743127231771, 0.0020136736004069205, 0.002142666650763392, 0.0019157148516054665, 0.001981445916638974, 0.0019423127044373974, 0.0019938876448112775, 0.001988524803104795, 0.0021044867294064636], "accuracy_test_std": 0.010504633434557199, "error_valid": [0.41842173381024095, 0.31583854951054224, 0.2808837890625, 0.2304363940135542, 0.20348826948418675, 0.19819806570030118, 0.19197247976280118, 0.17777114316641573, 0.17325454160391573, 0.17450612998870485, 0.17147349162274095, 0.16283738469503017, 0.16019301816641573, 0.15476015389683728, 0.1511995246611446, 0.1567647543298193, 0.14676381306475905, 0.15036562264683728, 0.15009059676204817, 0.14838161238704817, 0.14066029743975905, 0.14596079631024095, 0.14068088761295183, 0.14341790992093373, 0.13648931664156627, 0.13736439900225905, 0.13686582266566272, 0.13358021931475905, 0.1366422722138554, 0.13467885212725905, 0.13306105280496983, 0.13527890860316272, 0.1334684440888554, 0.13753794474774095, 0.13602162556475905, 0.1351774284638554, 0.13709966820406627, 0.13440382624246983, 0.13441412132906627, 0.13640842667545183, 0.13380376976656627, 0.13454648672816272, 0.13270513695406627, 0.13543186417545183, 0.1331022331513554, 0.13320371329066272, 0.13431264118975905, 0.13540097891566272, 0.1363981315888554, 0.13452589655496983, 0.13258306664156627, 0.13515683829066272, 0.13246099632906627, 0.13295957266566272, 0.13283750235316272, 0.13343755882906627, 0.1323698112763554, 0.13321400837725905, 0.13162709431475905, 0.13171827936746983, 0.1324918815888554, 0.13147413874246983, 0.13234922110316272, 0.13149472891566272, 0.1310976327183735, 0.13333607868975905, 0.13161679922816272, 0.1318815300263554, 0.13233892601656627, 0.13125058829066272, 0.13221685570406627, 0.13110792780496983, 0.13160650414156627, 0.13234922110316272, 0.13197271507906627, 0.13259336172816272, 0.13173886954066272, 0.13247129141566272, 0.13150502400225905, 0.13187123493975905, 0.1337125847138554, 0.13138295368975905, 0.13222715079066272, 0.13136236351656627, 0.13222715079066272, 0.13370228962725905, 0.13260365681475905, 0.1333463737763554, 0.13344785391566272, 0.13309193806475905, 0.13260365681475905, 0.1331022331513554, 0.13309193806475905, 0.13296986775225905, 0.13172857445406627, 0.13260365681475905, 0.1333463737763554, 0.13309193806475905, 0.13161679922816272, 0.1328580925263554, 0.13197271507906627, 0.13272572712725905, 0.13321400837725905, 0.13223744587725905, 0.1333463737763554, 0.13235951618975905, 0.13272572712725905, 0.13321400837725905, 0.13187123493975905, 0.13283750235316272, 0.13272572712725905, 0.13309193806475905, 0.13295957266566272, 0.13209478539156627, 0.13248158650225905], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.07382120750551441, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.008795206439059613, "optimization": "nesterov_momentum", "nb_data_augmentation": 2, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.9202489081771673e-06, "rotation_range": [0, 0], "momentum": 0.9453172530373956}, "accuracy_valid_max": 0.8689023672816265, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            print(X_train.min(), X_train.max())\n            print(X_valid.min(), X_valid.max())\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n\n    # rescaling to [-1, 1]\n    X_min = X_train.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X_train.max(axis=(0, 2, 3))[None, :, None, None]\n    def preprocess(a):\n        return (a / 255.) * 2 - 1\n        # return 2 * ((a - X_min) / (X_max - X_min)) - 1\n    X_train = preprocess(X_train)\n    X_valid = preprocess(X_valid)\n\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = preprocess(X_test)\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.867518413497741, "accuracy_valid_std": [0.01976538614677666, 0.018168857581085662, 0.022241934503872372, 0.019029957892945395, 0.01943686481306923, 0.0190678977652057, 0.015743706114050907, 0.016161368611899474, 0.012721953564598836, 0.011514277478420688, 0.017099829054003528, 0.010703685396564548, 0.009922221718867466, 0.01262008519808756, 0.013755921137868407, 0.00768342683591324, 0.013354644759820223, 0.0111247855464887, 0.014300183174170268, 0.012883261625445045, 0.011473017893904085, 0.009134125242534829, 0.011239495568786612, 0.008707729143593692, 0.012300946746085645, 0.010018815276485656, 0.011120806811941022, 0.010884874514779295, 0.010127520723360142, 0.01001042544219629, 0.011573789301732, 0.011076719499716938, 0.008413607002814091, 0.005977881164869888, 0.008289576465012756, 0.009559046257306315, 0.01205734534007465, 0.011809702811149549, 0.01046218740574922, 0.00871812809136231, 0.01082218158282881, 0.009512319727211064, 0.011143176248506756, 0.008460789555858097, 0.0059574761913774145, 0.010077863350251669, 0.00895002800989436, 0.009893289513479606, 0.00892084889988323, 0.013199712586285531, 0.010020310147013895, 0.011108563072767239, 0.010315782764517764, 0.010001290772817318, 0.009355738718611707, 0.010565597837081624, 0.00858864865966309, 0.00952134841018863, 0.00842227154669321, 0.012015837864731519, 0.009421211394160382, 0.011452086396641002, 0.010677955123136362, 0.009782040814195835, 0.01198047651475203, 0.009020201471443461, 0.009240428345889425, 0.008563443967963382, 0.010791081788654592, 0.009548328527439691, 0.0107905577079913, 0.011335175629850537, 0.010486757541605718, 0.009949791712810657, 0.01084048894367549, 0.009994009036402324, 0.009261843406019293, 0.009619773814453851, 0.00867637674681381, 0.009183053305012097, 0.008247709206948003, 0.007976247349278502, 0.009632791651468891, 0.00969870222575671, 0.009470545574162475, 0.008563659171599696, 0.0074410019521975075, 0.007421535469575873, 0.009479905650907821, 0.007813839376070508, 0.007937121933286467, 0.007810397591332719, 0.008542658529410389, 0.007763693823867585, 0.009837731722232401, 0.008737811225561274, 0.008429308009912644, 0.009316935780502014, 0.009175697418725672, 0.007045572039114766, 0.010718843042410563, 0.007976843797905841, 0.008873282740515114, 0.008031125211267661, 0.00793391466027486, 0.008046345403992473, 0.008299111140141651, 0.008765146773460837, 0.008453038786803787, 0.009240350629657739, 0.007687657899078184, 0.008817334423290255, 0.009206901110576827, 0.009865167838361163, 0.008533837785522197], "accuracy_valid": [0.581578266189759, 0.6841614504894578, 0.7191162109375, 0.7695636059864458, 0.7965117305158133, 0.8018019342996988, 0.8080275202371988, 0.8222288568335843, 0.8267454583960843, 0.8254938700112951, 0.828526508377259, 0.8371626153049698, 0.8398069818335843, 0.8452398461031627, 0.8488004753388554, 0.8432352456701807, 0.853236186935241, 0.8496343773531627, 0.8499094032379518, 0.8516183876129518, 0.859339702560241, 0.854039203689759, 0.8593191123870482, 0.8565820900790663, 0.8635106833584337, 0.862635600997741, 0.8631341773343373, 0.866419780685241, 0.8633577277861446, 0.865321147872741, 0.8669389471950302, 0.8647210913968373, 0.8665315559111446, 0.862462055252259, 0.863978374435241, 0.8648225715361446, 0.8629003317959337, 0.8655961737575302, 0.8655858786709337, 0.8635915733245482, 0.8661962302334337, 0.8654535132718373, 0.8672948630459337, 0.8645681358245482, 0.8668977668486446, 0.8667962867093373, 0.865687358810241, 0.8645990210843373, 0.8636018684111446, 0.8654741034450302, 0.8674169333584337, 0.8648431617093373, 0.8675390036709337, 0.8670404273343373, 0.8671624976468373, 0.8665624411709337, 0.8676301887236446, 0.866785991622741, 0.868372905685241, 0.8682817206325302, 0.8675081184111446, 0.8685258612575302, 0.8676507788968373, 0.8685052710843373, 0.8689023672816265, 0.866663921310241, 0.8683832007718373, 0.8681184699736446, 0.8676610739834337, 0.8687494117093373, 0.8677831442959337, 0.8688920721950302, 0.8683934958584337, 0.8676507788968373, 0.8680272849209337, 0.8674066382718373, 0.8682611304593373, 0.8675287085843373, 0.868494975997741, 0.868128765060241, 0.8662874152861446, 0.868617046310241, 0.8677728492093373, 0.8686376364834337, 0.8677728492093373, 0.866297710372741, 0.867396343185241, 0.8666536262236446, 0.8665521460843373, 0.866908061935241, 0.867396343185241, 0.8668977668486446, 0.866908061935241, 0.867030132247741, 0.8682714255459337, 0.867396343185241, 0.8666536262236446, 0.866908061935241, 0.8683832007718373, 0.8671419074736446, 0.8680272849209337, 0.867274272872741, 0.866785991622741, 0.867762554122741, 0.8666536262236446, 0.867640483810241, 0.867274272872741, 0.866785991622741, 0.868128765060241, 0.8671624976468373, 0.867274272872741, 0.866908061935241, 0.8670404273343373, 0.8679052146084337, 0.867518413497741], "seed": 221663079, "model": "residualv4", "loss_std": [0.2853747606277466, 0.15169532597064972, 0.13316982984542847, 0.12677578628063202, 0.11949727684259415, 0.11478202790021896, 0.11108148097991943, 0.10944879800081253, 0.10486661642789841, 0.09834809601306915, 0.09417273104190826, 0.08912864327430725, 0.08765248209238052, 0.084163136780262, 0.08019515872001648, 0.0778893530368805, 0.07384735345840454, 0.0714341253042221, 0.06858151406049728, 0.06489571183919907, 0.0650116428732872, 0.05887172371149063, 0.06075745448470116, 0.05759793519973755, 0.056182146072387695, 0.05424985662102699, 0.05288172885775566, 0.051303207874298096, 0.04934714734554291, 0.047816503793001175, 0.046159107238054276, 0.04690735787153244, 0.0455084890127182, 0.04440891370177269, 0.042067281901836395, 0.043080274015665054, 0.04164325073361397, 0.040351394563913345, 0.0407983772456646, 0.04012993723154068, 0.03705083206295967, 0.03848152980208397, 0.03671110048890114, 0.03742324933409691, 0.03785349428653717, 0.03602702170610428, 0.03541136160492897, 0.03634423017501831, 0.035318683832883835, 0.03480853885412216, 0.03563692420721054, 0.03228297829627991, 0.034602127969264984, 0.03515488654375076, 0.034206364303827286, 0.03332822769880295, 0.03414102643728256, 0.03439560532569885, 0.0319746769964695, 0.03288799524307251, 0.03200753405690193, 0.03255552425980568, 0.03156334534287453, 0.033661726862192154, 0.03236055746674538, 0.033739618957042694, 0.033119697123765945, 0.031995274126529694, 0.031065240502357483, 0.03158329427242279, 0.032261162996292114, 0.03197997435927391, 0.03184296935796738, 0.03301285207271576, 0.030120879411697388, 0.031223010271787643, 0.03089042566716671, 0.031406886875629425, 0.030763281509280205, 0.03099624253809452, 0.031400516629219055, 0.030788561329245567, 0.032603055238723755, 0.03123057633638382, 0.03174497187137604, 0.030855124816298485, 0.029983557760715485, 0.031253959983587265, 0.03022630512714386, 0.03135472536087036, 0.030938606709241867, 0.030142391100525856, 0.03136181831359863, 0.032878875732421875, 0.030184146016836166, 0.03164409101009369, 0.032160405069589615, 0.02918940596282482, 0.03067110851407051, 0.032044678926467896, 0.030731042847037315, 0.031202420592308044, 0.03125279024243355, 0.03211415186524391, 0.032634928822517395, 0.0309781264513731, 0.03110545314848423, 0.03176788240671158, 0.03134329617023468, 0.032029662281274796, 0.031397465616464615, 0.03127652034163475, 0.030925335362553596, 0.031018368899822235, 0.03000517562031746]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:39 2016", "state": "available"}], "summary": "ba77e371ac8837bb6ceaab3b917dc504"}