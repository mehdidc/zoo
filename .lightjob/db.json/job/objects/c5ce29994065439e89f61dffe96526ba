{"content": {"hp_model": {"f0": 32, "f1": 64, "f2": 64, "f3": 64, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.019879003938041047, 0.02062829773878333, 0.014789456141281285, 0.017701317477417468, 0.021672643132502244, 0.01846635154070525, 0.016079755728349483, 0.016150034817628833, 0.0159909608322067, 0.015098980405706161, 0.014766309794559921, 0.010560090130964764, 0.012463947752248326, 0.013131585540461786, 0.019477065776541225, 0.013106146142832589, 0.014999078667841332, 0.014057194920607613, 0.016722500659990456, 0.017181608421895228, 0.013975091719153735, 0.018825563578328423, 0.01590533293336988, 0.015777332338188517, 0.014013711422988356, 0.016861435596970523, 0.018241031113098785, 0.016698198847169637, 0.014193265944793202, 0.010060361614870242, 0.014679120222194175, 0.014580148831841196, 0.01132530691256229, 0.01604515620025468, 0.01492999927339616, 0.015551939344134966, 0.015153908146305486, 0.0171167112979717, 0.015517613396773718, 0.016389106822072928, 0.014409708444901819, 0.015785231784292243, 0.014809091852716037, 0.012823014551167026, 0.015546146986950041, 0.014724585573505857, 0.012523587583495609, 0.01688569289911574, 0.012652176418065961, 0.01679865088118844, 0.015439222405252409, 0.014045289494261252, 0.008266594893104271, 0.013497214145106457, 0.015468261177917135, 0.013491535329101018, 0.012983312030480344, 0.012390631788324846, 0.009638106054025476, 0.01251738066777974, 0.013518325171960303, 0.013518600622508863, 0.013167262490167402, 0.008998976213444873, 0.009653731021823035, 0.01130664264947846, 0.009407045349977803, 0.009855112601966478, 0.011671545807676525, 0.009678707087181243, 0.011461646670440804, 0.010547701734520248, 0.015073708177490368, 0.014559884227641026, 0.014594127179119046, 0.014188131385800485, 0.01063288941110434, 0.0099599133761778, 0.012642759166785627, 0.013027213889403902, 0.01307893954797468, 0.012387584026217882, 0.01211570935359547, 0.011988773018154373, 0.012413742900706357, 0.009405990335417018, 0.01314445137715418, 0.010330760819224715, 0.011502472508422807, 0.012391605154351004, 0.011854821386649797, 0.012380066388771288, 0.013153662791584277, 0.008728373891320973, 0.01171049040247139, 0.012463436395887494, 0.009879967751163198, 0.012928613133652806, 0.013732892889475047, 0.012654925866429079, 0.010502131889911325, 0.011210573493873619, 0.012808652852970339, 0.007909881897733688, 0.011462194038449846, 0.010470214420884336, 0.010011542073185019, 0.008804149479067217, 0.013018925448078355, 0.011799492855868994, 0.011065431087246532, 0.011185307667153864, 0.010225071253906185, 0.011934354435359827, 0.012277025350815929, 0.011093744790031335, 0.01035296957032578, 0.011001591323992845, 0.010753382063985354, 0.012129813709299409, 0.010625175539183416, 0.008511292755936296, 0.008609934319088703, 0.008927033010937538, 0.010348995497904943, 0.010761499705075426, 0.009901954994479033, 0.011435789344779224, 0.009719298862903297, 0.010957773883835058, 0.011502990103670821, 0.010246469654478327, 0.009912789203790805, 0.010255503315368935, 0.010225885765771782, 0.011129123690489665, 0.008715529517625314, 0.00942237432180851, 0.010362909929159222, 0.009710811523929946, 0.008654371386241814, 0.010648771144382126, 0.008330648491863298, 0.011426849161796145, 0.010332899606303105, 0.012651373556705755, 0.010909908231959265, 0.011703894144373927, 0.011775767332543177, 0.0123038519468669, 0.01232368677301095, 0.00872955540142554, 0.007882429594583334, 0.012043133213325504, 0.011647623919783516, 0.010002349494829406, 0.011024979720262503, 0.008990332510904331, 0.01064950714417476, 0.010478790985425382, 0.010632744670463419, 0.011033379125217187, 0.011675291472141561, 0.011686670535027874, 0.008938313274893032, 0.01105795459739321, 0.012154679844503352, 0.011083372665098326, 0.01015034124864821, 0.009511848556814875, 0.011719438090864912, 0.010318642434512082, 0.011755268473275555, 0.010516515878677269, 0.011300026091801708, 0.011443037875238296, 0.012821917383740443, 0.011188262636875035, 0.011837669641035047, 0.010845076935926814, 0.011003573871763695, 0.010960941951438777, 0.011991103842194175, 0.01106761864921891, 0.012311752483498393, 0.010504477943514754, 0.00983448643318798, 0.010239491666952816, 0.010731532737413571, 0.0111255780313726, 0.011114129054660662, 0.011475740640182261, 0.012048260274950758, 0.010410451867046887, 0.010734679418149668, 0.008594249577470868, 0.01116489662459461, 0.009993541637644111, 0.01087135985549952, 0.011125298160001377, 0.009448356466770969, 0.010518389353685527, 0.00929738337310118, 0.010410143523630467, 0.009154943374499847, 0.010398685955613997, 0.009641207115735947, 0.010948199476600258, 0.00907085017912231, 0.009364983149485277, 0.009548057926760183, 0.010004624216484036, 0.010038375492321802, 0.011528536477714192, 0.009627492064520482, 0.010117897250888139, 0.011077160818648013, 0.00963072231941125, 0.00911976336722682, 0.009910966573974452, 0.010377670626267621, 0.01039999800370151, 0.011741262905159883, 0.010119693725786364, 0.011055657614204684, 0.009326409203269822, 0.01034258779541782, 0.010738425050931833, 0.009122794514264027, 0.010154972025615067, 0.008578115065528915, 0.009481022594867458, 0.008897486282895791, 0.010050886896809358, 0.008714652894977921, 0.008877285510175158, 0.008998972007060325, 0.01010866615505974, 0.010537935792538462, 0.009639866287013863, 0.009577160478319923, 0.008825742191997367, 0.008673435483482988, 0.009668667109630751, 0.009942981978082457, 0.009844494404346262, 0.010777557191372255, 0.009520709678995645, 0.010319509927691456, 0.0105480167202064, 0.011359106656206416, 0.008972078737472128, 0.010201426467139955, 0.009546026987561443, 0.010027782235507333, 0.009183192629763609, 0.009949624425802654, 0.009221070972198897, 0.010576816516754338, 0.010599361614937774, 0.01023815028176584], "moving_avg_accuracy_train": [0.046442918858434844, 0.09318401912606125, 0.13851955576319672, 0.18326412594592095, 0.22599123647448316, 0.2667917110989987, 0.30588543026803017, 0.34213222633083584, 0.37615804774075706, 0.40778585944185664, 0.4364553588728094, 0.46399683127964064, 0.4893258079719516, 0.5131630850270543, 0.534244610567123, 0.5551336177816824, 0.5750845647890438, 0.5930544040373451, 0.6098573386393784, 0.6255098613680485, 0.6404503893393093, 0.654131704543206, 0.6676142938826285, 0.6797811042738046, 0.6920053791246633, 0.7028813800641719, 0.7130859464978156, 0.7229792987726372, 0.7322297629925958, 0.7411990667667028, 0.749945589122886, 0.7574362790339639, 0.7649563561704807, 0.7717781563576962, 0.7786104545785157, 0.78482462714392, 0.7913496589789466, 0.797417572228108, 0.8028506842201828, 0.8089910545843865, 0.8147150255609792, 0.8197642568434749, 0.8253385698715212, 0.8292976530837046, 0.8333513262270229, 0.8371669346238388, 0.8408731327381438, 0.8443226433326849, 0.8485570449451068, 0.8521007224296474, 0.8560059977549735, 0.8595787661215488, 0.8632521677716679, 0.865484298897325, 0.8681046949985025, 0.8716485889918693, 0.8746800195156705, 0.8774012233942069, 0.8800201869432598, 0.8824748382897699, 0.8853280186242296, 0.8878516670490436, 0.8902227878349107, 0.8923567965421912, 0.894384180979888, 0.8972737451285769, 0.8994977508528916, 0.9020851853583186, 0.904725446353679, 0.9067041889495311, 0.9089638576964661, 0.910955742938955, 0.9122487129072411, 0.9140190694738906, 0.9158122810838566, 0.9174005588471026, 0.9190672461102328, 0.9209299518125171, 0.9226528899207634, 0.9239082403193756, 0.9256844470471741, 0.9270713364140699, 0.9287032584954851, 0.9301464477806727, 0.931663846076618, 0.9332945715072545, 0.9345459855555416, 0.9356118403787711, 0.9364757786184872, 0.9377694700211272, 0.9391430196275417, 0.9400071904637908, 0.9406269061950049, 0.9418309696245077, 0.9427542635408407, 0.9439338201428751, 0.9450536219025817, 0.9460427701982039, 0.9464448305607203, 0.9476530030048328, 0.9484218849152668, 0.9491532619691443, 0.9503951136688245, 0.951833506538976, 0.9528700767507114, 0.9535844259531782, 0.9544273030330173, 0.955095211601301, 0.9556846314710712, 0.9564593220765019, 0.9570706212618934, 0.9576440059680222, 0.958387844689234, 0.9591665815323722, 0.9598929492304639, 0.960679249689708, 0.9615008523946944, 0.9621123755958396, 0.9628927559649194, 0.9636255775733462, 0.9641665344316447, 0.9647044407314666, 0.964942054578678, 0.9654581403375876, 0.9659319902134819, 0.9665026143279771, 0.9671021344393378, 0.9674837005669711, 0.9679920875008609, 0.9685055835080653, 0.969004896246683, 0.969391462644763, 0.9697974290256355, 0.9702303362303533, 0.9707454386526759, 0.9710764973506235, 0.9714838042704614, 0.9718201535637918, 0.9722948928908751, 0.9727361452269261, 0.9729727289150585, 0.9732530835498538, 0.9735635674902265, 0.9739243832448953, 0.9742513704752691, 0.9746293643397484, 0.9748626019725417, 0.9751865202313599, 0.9754709630714115, 0.9758642175048573, 0.9762065928485484, 0.9763983290221191, 0.9765755779247706, 0.9768652742216715, 0.977047017926996, 0.9772710771796544, 0.977493620797514, 0.9776915488559593, 0.9779719906561792, 0.9781429720192251, 0.9784177990328803, 0.9786302661130271, 0.9788097886434741, 0.9789668167697136, 0.9791522838618915, 0.9794122101972323, 0.9796344821061728, 0.9797716757087245, 0.9799207986855634, 0.9800456727206616, 0.9801650347986784, 0.980302759701055, 0.9804917802310418, 0.9806339608734967, 0.9807712961445818, 0.9809507014599871, 0.9811586331712234, 0.9813016659815927, 0.9814698148942308, 0.9815910301275376, 0.981748879864876, 0.9818514531475375, 0.981997247524552, 0.9821354379102935, 0.9822923973896129, 0.9824545151626487, 0.9825841811655329, 0.9827497086931288, 0.9829218628584228, 0.9830768737048249, 0.9832186725665776, 0.983318353707622, 0.9834359685202761, 0.9835394967028553, 0.9836071314790906, 0.9837098915050926, 0.9837512583035036, 0.983781512975645, 0.9838295964222205, 0.9839030984586622, 0.9839158079176594, 0.9840039763414712, 0.9840739912788449, 0.9841439801689098, 0.9842488228485397, 0.9843152794744923, 0.9843960167771353, 0.9844570185566477, 0.9845491946367988, 0.9846066125208487, 0.9846187610867316, 0.9847016302138465, 0.9847274203520686, 0.9847623293181538, 0.9848192519268976, 0.9848124256521664, 0.9848736392227471, 0.9849218280874786, 0.9849582226193084, 0.9850397337253177, 0.9851363812576401, 0.9851651632188547, 0.9852050539256237, 0.9852061504272105, 0.9852513151060195, 0.9852849518217003, 0.9853663781396226, 0.9854163742888385, 0.9854497450790853, 0.9854635027486408, 0.9855340133714788, 0.9855555842046428, 0.9856075500378239, 0.985710158907934, 0.9856746958041468, 0.985728773467872, 0.9857448912818914, 0.9857849379025948, 0.9858372559028945, 0.9857984197436682, 0.9858354747158223, 0.9858711132907516, 0.9858590462296258, 0.9858830631067556, 0.9858814268080771, 0.9859240959178286, 0.9859624620677863, 0.9859970276515668, 0.9860374012233888, 0.9860645449892467, 0.9860679398927767, 0.9860897046428863, 0.9861091847715286, 0.9861593050194588, 0.9861393811735668, 0.9861562908955881, 0.9861599199501784, 0.9861771009433481, 0.9861903107860287, 0.9861881406051279, 0.9861932349863833], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 72916509, "moving_var_accuracy_train": [0.01941250240882047, 0.03713382625599319, 0.05191824156998734, 0.06474510646051923, 0.07470104958154705, 0.08221305318966396, 0.08774661777690144, 0.09079642802257895, 0.09213659392389972, 0.09192580078851169, 0.09013068248825312, 0.08794440856045406, 0.08492398124692534, 0.08154552511884836, 0.07739084907883262, 0.07357891977263858, 0.06980339037378963, 0.06572928743989875, 0.061697406197070745, 0.05773267878730749, 0.053968385293117, 0.050256152235180665, 0.04686655894932218, 0.04351218453024343, 0.04050586213788312, 0.03751986249202053, 0.03470507482770631, 0.03211547311803914, 0.029674065600797817, 0.027430694732447924, 0.02537614013914804, 0.02334352004332856, 0.02151813208024818, 0.019785151492371998, 0.018226759033938722, 0.016751626596598453, 0.015459648300971605, 0.014245059611668586, 0.013086222003767566, 0.012116937137277116, 0.011200118017217289, 0.010309558844392755, 0.009558259651565308, 0.008743502745337712, 0.008017042864379686, 0.007346368384882391, 0.0067353546865564495, 0.006168911327977466, 0.005713391608317243, 0.0052550712985154815, 0.004866824746963345, 0.004495024336477825, 0.0041669668199779165, 0.0037951118222392718, 0.003477398921558937, 0.0032426916911290357, 0.0030011286612018385, 0.0027676603500187045, 0.0025526250456582448, 0.0023515903601887362, 0.002189697066358391, 0.002028046572071149, 0.0018758418388945752, 0.0017292435934698558, 0.0015933118230468033, 0.0015091268694666185, 0.0014027299956760172, 0.0013227103519872824, 0.0012531781199011502, 0.001163099108256791, 0.0010927441230439872, 0.0010191781721127925, 0.0009323062969515216, 0.000867283128614079, 0.0008094952866557248, 0.0007512493942691463, 0.0007011250727399582, 0.0006622396182658615, 0.0006227322979629002, 0.0005746422097762703, 0.0005455721818575335, 0.0005083261227158563, 0.0004814620375625621, 0.00045206099162222753, 0.00042757737075684385, 0.00040875302255227996, 0.00038197205437930505, 0.0003539992674791894, 0.00032531684426966424, 0.0003078478968500804, 0.00029404285385660305, 0.00027135968957895507, 0.00024768014890868797, 0.0002359600526982145, 0.00022003629233182935, 0.00021055484709527346, 0.00020078496621512377, 0.0001895121987502027, 0.0001720158516911428, 0.0001679513924144444, 0.00015647686770273425, 0.00014564339248690811, 0.000144958814034206, 0.00014908369907090977, 0.00014384562939853484, 0.00013405371950626454, 0.00012704232350110035, 0.00011835300785127169, 0.00010964444911206417, 0.00010408131400814129, 9.703636285387036e-05, 9.029165675948568e-05, 8.624215547210332e-05, 8.307581956264136e-05, 7.951672790185629e-05, 7.71294708215384e-05, 7.549180278295293e-05, 7.130826813450726e-05, 6.965838300506189e-05, 6.752579229255154e-05, 6.340692196615762e-05, 5.9670318456034325e-05, 5.421142967391033e-05, 5.1187387301462985e-05, 4.8089451915281645e-05, 4.62110136441454e-05, 4.482473155506372e-05, 4.1652592787370386e-05, 3.981344897958236e-05, 3.8205207426358144e-05, 3.662850558223473e-05, 3.4310557245131774e-05, 3.23627798422073e-05, 3.081317968905527e-05, 3.0119836269494504e-05, 2.809425139592601e-05, 2.6777916598864556e-05, 2.5118302563092675e-05, 2.4634869164899407e-05, 2.392371486504293e-05, 2.203508995195168e-05, 2.05389694480177e-05, 1.9352674998280008e-05, 1.8589099577806573e-05, 1.7692475459474207e-05, 1.7209142167783192e-05, 1.59778260911642e-05, 1.532435082760999e-05, 1.4520085308158166e-05, 1.445991822216516e-05, 1.4068914283656918e-05, 1.2992887697591309e-05, 1.197635348925265e-05, 1.1534033640270411e-05, 1.0677907246069225e-05, 1.006193945977911e-05, 9.501476470451492e-06, 8.903908470285825e-06, 8.721346053052264e-06, 8.112323086327983e-06, 7.980859764606836e-06, 7.5890541294611856e-06, 7.120203766957927e-06, 6.63010388213476e-06, 6.2766758744491374e-06, 6.257063585238135e-06, 6.076000440250717e-06, 5.637799157455928e-06, 5.27415820170193e-06, 4.887084103306962e-06, 4.526601443992866e-06, 4.244654638205188e-06, 4.141748021193022e-06, 3.9095112348741315e-06, 3.688308901543069e-06, 3.609154416149619e-06, 3.63735934337407e-06, 3.4577488726160528e-06, 3.366440496746691e-06, 3.162034642142402e-06, 3.070080034128737e-06, 2.8577635355595105e-06, 2.763291185324757e-06, 2.6588313111948595e-06, 2.6146746834095683e-06, 2.5897467660752216e-06, 2.4820915402035193e-06, 2.4804766477110557e-06, 2.499162492592565e-06, 2.465501505853942e-06, 2.3999136100176684e-06, 2.249349217935006e-06, 2.1489134935426263e-06, 2.0304849054818297e-06, 1.8686065815412588e-06, 1.7767825298824621e-06, 1.6145051849912025e-06, 1.4612927731694947e-06, 1.3359716563636635e-06, 1.2509974349769366e-06, 1.127351464611255e-06, 1.084579356767167e-06, 1.0202402441894796e-06, 9.623022223632212e-07, 9.649998873746427e-07, 9.082482468342171e-07, 8.760900304934807e-07, 8.219719813772265e-07, 8.16242651007578e-07, 7.642897065857349e-07, 6.891890248042863e-07, 6.820757523830239e-07, 6.198543582104123e-07, 5.688366456075604e-07, 5.411146315226664e-07, 4.874225506107408e-07, 4.7240420655880027e-07, 4.4606328605997705e-07, 4.133780149779937e-07, 4.318367571060012e-07, 4.7271979093150897e-07, 4.329034234605793e-07, 4.039344974932997e-07, 3.6355186858553746e-07, 3.455553156342898e-07, 3.2118264184698426e-07, 3.4873658491566134e-07, 3.363594608519773e-07, 3.127460015420506e-07, 2.831748626322231e-07, 2.9960310776604437e-07, 2.7383050457996355e-07, 2.7075148448570457e-07, 3.3843355806474226e-07, 3.1590888783021285e-07, 3.1063754247298893e-07, 2.8191184358455684e-07, 2.681542456939858e-07, 2.6597337952287743e-07, 2.5295026694166697e-07, 2.4001287889951844e-07, 2.2744256321654795e-07, 2.0600883257280436e-07, 1.9059924279908946e-07, 1.7156341577946858e-07, 1.70792950544413e-07, 1.6696130865312483e-07, 1.6101819402666336e-07, 1.5958660233893044e-07, 1.5025899832955478e-07, 1.3533682682640875e-07, 1.260664832697463e-07, 1.1687511365007614e-07, 1.2779595555831895e-07, 1.1858899671863647e-07, 1.0930354533631429e-07, 9.849172113765837e-08, 9.129922776055932e-08, 8.373980447734293e-08, 7.540821119588739e-08, 6.81009645596748e-08], "duration": 174633.518396, "accuracy_train": [0.4644291885843485, 0.5138539215346991, 0.546539385497416, 0.5859652575904393, 0.6105352312315431, 0.6339959827196383, 0.6577289027893134, 0.6683533908960871, 0.682390440430048, 0.6924361647517534, 0.6944808537513842, 0.7118700829411222, 0.7172865982027501, 0.7276985785229789, 0.7239783404277409, 0.7431346827127169, 0.7546430878552971, 0.7547829572720561, 0.761083750057678, 0.7663825659260798, 0.7749151410806571, 0.7772635413782761, 0.7889575979374308, 0.789282397794389, 0.802023852782392, 0.800765388519749, 0.8049270444006091, 0.8120194692460319, 0.8154839409722223, 0.8219228007336655, 0.8286642903285345, 0.8248524882336655, 0.8326370503991326, 0.8331743580426356, 0.8401011385658915, 0.8407521802325582, 0.850074945494186, 0.8520287914705611, 0.8517486921488556, 0.8642543878622186, 0.8662307643503139, 0.8652073383859358, 0.8755073871239387, 0.8649294019933554, 0.8698343845168882, 0.8715074101951827, 0.8742289157668882, 0.8753682386835548, 0.8866666594569029, 0.8839938197905132, 0.8911534756829088, 0.8917336814207272, 0.8963127826227391, 0.8855734790282392, 0.8916882599090993, 0.9035436349321706, 0.901962894229882, 0.9018920583010337, 0.903590858884736, 0.9045667004083611, 0.911006641634367, 0.9105645028723699, 0.911562874907715, 0.911562874907715, 0.9126306409191584, 0.9232798224667773, 0.9195138023717239, 0.9253720959071613, 0.9284877953119232, 0.9245128723122, 0.9293008764188816, 0.9288827101213547, 0.9238854426218162, 0.9299522785737356, 0.9319511855735512, 0.9316950587163161, 0.9340674314784054, 0.937694303133075, 0.9381593328949798, 0.9352063939068845, 0.9416703075973607, 0.9395533407161315, 0.9433905572282208, 0.9431351513473607, 0.9453204307401256, 0.9479711003829827, 0.9458087119901256, 0.9452045337878369, 0.9442512227759321, 0.9494126926448875, 0.9515049660852714, 0.9477847279900333, 0.9462043477759321, 0.9526675404900333, 0.9510639087878369, 0.954549829561185, 0.9551318377399409, 0.954945104858804, 0.9500633738233666, 0.9585265550018457, 0.9553418221091732, 0.9557356554540422, 0.9615717789659468, 0.9647790423703396, 0.9621992086563308, 0.9600135687753784, 0.9620131967515688, 0.9611063887158545, 0.9609894102990033, 0.9634315375253784, 0.9625723139304172, 0.962804468323182, 0.9650823931801403, 0.9661752131206165, 0.966430258513289, 0.9677559538229051, 0.9688952767395718, 0.9676160844061462, 0.9699161792866371, 0.9702209720491879, 0.9690351461563308, 0.9695455974298633, 0.9670805792035806, 0.970102912167774, 0.9701966390965301, 0.9716382313584349, 0.9724978154415835, 0.9709177957156699, 0.9725675699058692, 0.9731270475729051, 0.9734987108942414, 0.9728705602274824, 0.9734511264534883, 0.9741265010728128, 0.9753813604535806, 0.9740560256321521, 0.9751495665490033, 0.9748472972037652, 0.9765675468346253, 0.9767074162513842, 0.9751019821082503, 0.9757762752630121, 0.9763579229535806, 0.977171725036914, 0.9771942555486341, 0.9780313091200628, 0.9769617406676817, 0.9781017845607235, 0.9780309486318751, 0.9794035074058692, 0.9792879709417681, 0.9781239545842562, 0.9781708180486341, 0.9794725408937799, 0.9786827112749169, 0.9792876104535806, 0.9794965133582503, 0.9794729013819674, 0.980495966858158, 0.9796818042866371, 0.9808912421557769, 0.9805424698343485, 0.9804254914174971, 0.9803800699058692, 0.9808214876914912, 0.9817515472153008, 0.9816349292866371, 0.9810064181316908, 0.9812629054771133, 0.9811695390365448, 0.9812392935008305, 0.9815422838224437, 0.9821929650009228, 0.9819135866555924, 0.9820073135843485, 0.9825653492986341, 0.9830300185723514, 0.9825889612749169, 0.9829831551079733, 0.9826819672272978, 0.9831695275009228, 0.9827746126914912, 0.9833093969176817, 0.9833791513819674, 0.9837050327034883, 0.9839135751199704, 0.9837511751914912, 0.9842394564414912, 0.9844712503460686, 0.9844719713224437, 0.9844948623223514, 0.984215483977021, 0.9844945018341639, 0.9844712503460686, 0.9842158444652085, 0.9846347317391103, 0.9841235594892026, 0.9840538050249169, 0.984262347441399, 0.9845646167866371, 0.9840301930486341, 0.9847974921557769, 0.9847041257152085, 0.9847738801794942, 0.9851924069652085, 0.9849133891080657, 0.9851226525009228, 0.9850060345722591, 0.985378779358158, 0.9851233734772978, 0.9847280981796788, 0.9854474523578812, 0.9849595315960686, 0.9850765100129198, 0.9853315554055924, 0.9847509891795865, 0.9854245613579733, 0.9853555278700628, 0.9852857734057769, 0.9857733336794019, 0.9860062090485419, 0.985424200869786, 0.9855640702865448, 0.9852160189414912, 0.9856577972153008, 0.9855876822628276, 0.9860992150009228, 0.9858663396317828, 0.9857500821913067, 0.98558732177464, 0.986168608977021, 0.9857497217031194, 0.9860752425364526, 0.9866336387389257, 0.9853555278700628, 0.986215472441399, 0.9858899516080657, 0.9861453574889257, 0.9863081179055924, 0.9854488943106312, 0.9861689694652085, 0.9861918604651162, 0.9857504426794942, 0.9860992150009228, 0.9858667001199704, 0.9863081179055924, 0.9863077574174051, 0.9863081179055924, 0.986400763369786, 0.9863088388819674, 0.9860984940245479, 0.9862855873938722, 0.9862845059293098, 0.9866103872508305, 0.9859600665605389, 0.9863084783937799, 0.9861925814414912, 0.9863317298818751, 0.986309199370155, 0.986168608977021, 0.9862390844176817], "end": "2016-01-29 00:48:46.712000", "learning_rate_per_epoch": [0.0004226555465720594, 0.00041444425005465746, 0.0004063924716319889, 0.00039849712629802525, 0.0003907551581505686, 0.00038316359859891236, 0.00037571953726001084, 0.00036842009285464883, 0.0003612624714151025, 0.0003542439080774784, 0.00034736169618554413, 0.0003406131872907281, 0.00033399579115211964, 0.0003275069466326386, 0.0003211441799066961, 0.00031490501714870334, 0.0003087870718445629, 0.00030278798658400774, 0.0002969054621644318, 0.0002911372284870595, 0.00028548104455694556, 0.0002799347566906363, 0.0002744962112046778, 0.00026916334172710776, 0.0002639340527821332, 0.00025880636530928314, 0.00025377830024808645, 0.000248847936745733, 0.0002440133539494127, 0.00023927268921397626, 0.00023462412355002016, 0.0002300658670719713, 0.00022559617355000228, 0.00022121331130620092, 0.00021691560687031597, 0.00021270140132401139, 0.0002085690648527816, 0.0002045170112978667, 0.00020054368360433728, 0.0001966475392691791, 0.0001928270939970389, 0.0001890808780444786, 0.00018540743621997535, 0.00018180535698775202, 0.0001782732579158619, 0.00017480978567618877, 0.0001714136014925316, 0.00016808339569251984, 0.0001648178877076134, 0.00016161582607310265, 0.00015847597387619317, 0.000155397123307921, 0.0001523780811112374, 0.00014941769768483937, 0.00014651482342742383, 0.00014366835239343345, 0.00014087717863731086, 0.0001381402398692444, 0.00013545647379942238, 0.0001328248472418636, 0.00013024434156250209, 0.0001277139672311023, 0.0001252327492693439, 0.00012279974180273712, 0.00012041399895679206, 0.00011807461123680696, 0.00011578066914808005, 0.00011353129229974002, 0.00011132562212878838, 0.00010916280007222667, 0.00010704199667088687, 0.0001049623970175162, 0.00010292320075677708, 0.00010092362208524719, 9.896288975141943e-05, 9.704024705570191e-05, 9.515495912637562e-05, 9.330629836767912e-05, 9.149355173576623e-05, 8.971602801466361e-05, 8.79730359883979e-05, 8.62639062688686e-05, 8.458798401989043e-05, 8.294462168123573e-05, 8.133318624459207e-05, 7.975305197760463e-05, 7.820362225174904e-05, 7.668429316254333e-05, 7.519448263337836e-05, 7.373361586360261e-05, 7.230112532852218e-05, 7.0896465331316e-05, 6.951909745112062e-05, 6.81684905430302e-05, 6.684412073809654e-05, 6.554547871928662e-05, 6.42720697214827e-05, 6.302339897956699e-05, 6.179898628033698e-05, 6.0598362324526533e-05, 5.942106508882716e-05, 5.826663982588798e-05, 5.7134642702294514e-05, 5.602463716058992e-05, 5.493619755725376e-05, 5.3868901886744425e-05, 5.282234269543551e-05, 5.179611616767943e-05, 5.078982576378621e-05, 4.9803085858002305e-05, 4.883551810053177e-05, 4.788674777955748e-05, 4.6956411097198725e-05, 4.60441478935536e-05, 4.5149608922656626e-05, 4.427244857652113e-05, 4.341232852311805e-05, 4.256891770637594e-05, 4.1741892346180975e-05, 4.093093593837693e-05, 4.0135735616786405e-05, 3.935598215321079e-05, 3.85913772333879e-05, 3.784162981901318e-05, 3.710644523380324e-05, 3.6385546991368756e-05, 3.5678651329362765e-05, 3.4985489037353545e-05, 3.430579454288818e-05, 3.3639305911492556e-05, 3.298576484667137e-05, 3.234492032788694e-05, 3.171652861055918e-05, 3.1100342312129214e-05, 3.0496128601953387e-05, 2.990365283039864e-05, 2.9322687623789534e-05, 2.875300924642943e-05, 2.81943994195899e-05, 2.7646641683531925e-05, 2.7109525035484694e-05, 2.6582843929645605e-05, 2.6066394639201462e-05, 2.5559978894307278e-05, 2.5063402063096873e-05, 2.4576473151682876e-05, 2.409900480415672e-05, 2.3630811483599246e-05, 2.3171714929048903e-05, 2.2721536879544146e-05, 2.228010635008104e-05, 2.1847250536666252e-05, 2.1422803911264054e-05, 2.1006604583817534e-05, 2.0598490664269775e-05, 2.0198305719532073e-05, 1.9805895135505125e-05, 1.9421107936068438e-05, 1.9043796783080325e-05, 1.86738161573885e-05, 1.831102417781949e-05, 1.7955278963199817e-05, 1.7606445908313617e-05, 1.726439040794503e-05, 1.6928979675867595e-05, 1.660008456383366e-05, 1.6277579561574385e-05, 1.5961340977810323e-05, 1.5651245121262036e-05, 1.5347173757618293e-05, 1.5049010471557267e-05, 1.4756639757251833e-05, 1.4469949746853672e-05, 1.4188829482009169e-05, 1.3913170732848812e-05, 1.3642867088492494e-05, 1.3377814866544213e-05, 1.311791220359737e-05, 1.2863059055234771e-05, 1.2613157196028624e-05, 1.236811021954054e-05, 1.2127823538321536e-05, 1.1892205293406732e-05, 1.1661164535325952e-05, 1.1434613043093123e-05, 1.1212462595722172e-05, 1.0994627700711135e-05, 1.0781025594042148e-05, 1.057157260220265e-05, 1.0366189599153586e-05, 1.0164796549361199e-05, 9.96731614577584e-06, 9.773671990842558e-06, 9.583790415490512e-06, 9.397597750648856e-06, 9.215022146236151e-06, 9.035993571160361e-06, 8.86044290382415e-06, 8.688302841619588e-06, 8.519507900928147e-06, 8.353991688636597e-06, 8.191691449610516e-06, 8.032544428715482e-06, 7.876488780311774e-06, 7.723465387243778e-06, 7.573414677608525e-06, 7.426279353239806e-06, 7.28200257071876e-06, 7.140528850868577e-06, 7.001803624007152e-06, 6.865773229947081e-06, 6.732385827490361e-06, 6.601589575438993e-06, 6.473334451584378e-06, 6.347571343212621e-06, 6.224251592357177e-06, 6.103327450546203e-06, 5.9847525335499085e-06, 5.868481366633205e-06, 5.754469384555705e-06, 5.642672022077022e-06, 5.533046987693524e-06, 5.425551535154227e-06, 5.320144737197552e-06, 5.216785666561918e-06, 5.115434760227799e-06, 5.016052455175668e-06, 4.9186010073754005e-06, 4.823043127544224e-06, 4.7293415263993666e-06, 4.637460278900107e-06, 4.5473643695004284e-06, 4.4590187826543115e-06, 4.37238941231044e-06, 4.2874430619121995e-06, 4.204146989650326e-06, 4.122469363210257e-06, 4.042378350277431e-06, 3.963843482779339e-06, 3.886834292643471e-06, 3.811321221292019e-06, 3.7372753922682023e-06, 3.6646679291152395e-06, 3.5934710922447266e-06, 3.5236575968156103e-06, 3.455200385360513e-06, 3.388073082533083e-06, 3.3222499951079953e-06, 3.2577056572336005e-06, 3.194415285179275e-06, 3.1323545499617467e-06, 3.0714995773450937e-06, 3.01182672046707e-06, 2.9533132419601316e-06, 2.895936631830409e-06, 2.8396746074577095e-06, 2.784505795716541e-06, 2.7304088234814117e-06, 2.677362772374181e-06, 2.625347178764059e-06, 2.5743422611412825e-06], "accuracy_valid": [0.45461925828313254, 0.5022899214043675, 0.5352297863328314, 0.5702551416603916, 0.5913541862763554, 0.6083734351468373, 0.6278340902673193, 0.6348435735128012, 0.6491978656814759, 0.6560029179216867, 0.6591767460466867, 0.6693085819841867, 0.6753312076430723, 0.6874676440135542, 0.6816185641001506, 0.6955345797251506, 0.7019028261483433, 0.701404249811747, 0.7060532167733433, 0.7088814241340362, 0.7170704301581325, 0.7172425051769578, 0.7285656297063253, 0.7245476044804217, 0.7352794968938253, 0.7302849091679217, 0.7358486681099398, 0.7413021225527108, 0.7437744140625, 0.7452083725527108, 0.7500911850527108, 0.7471409073795181, 0.7525737716490963, 0.7519222397402108, 0.7578022049134037, 0.7524208160768072, 0.7613216538027108, 0.7635909850338856, 0.7619731857115963, 0.7681178816829819, 0.7680869964231928, 0.7694297698606928, 0.7780776426016567, 0.7673854598079819, 0.7668765883847892, 0.7735095656061747, 0.7719123564570783, 0.7709563841302711, 0.7794807158320783, 0.777233445500753, 0.7782394225338856, 0.7804278637989458, 0.7813529508659638, 0.7783217832266567, 0.7784938582454819, 0.788952195500753, 0.7876300122364458, 0.7857680722891567, 0.7870196606739458, 0.7864901990775602, 0.7895831372364458, 0.7907023602221386, 0.7910376858998494, 0.7858695524284638, 0.7881182934864458, 0.7970500164721386, 0.791881883000753, 0.7971823818712349, 0.7976912532944277, 0.7909465008471386, 0.7964499599962349, 0.7964190747364458, 0.7956160579819277, 0.8008856715926205, 0.7972735669239458, 0.7952189617846386, 0.7964087796498494, 0.8003665050828314, 0.8012107021837349, 0.7986369305346386, 0.8013430675828314, 0.8000208843185241, 0.8017092785203314, 0.8036726986069277, 0.8051581325301205, 0.8026858410203314, 0.8041506847703314, 0.8027976162462349, 0.8025740657944277, 0.8052699077560241, 0.8058493740587349, 0.8057890742658133, 0.8045477809676205, 0.8039271343185241, 0.8061449901167168, 0.8059920345444277, 0.8073553981551205, 0.8083422557417168, 0.8073656932417168, 0.8114043086408133, 0.8101939006024097, 0.8074774684676205, 0.8107130671121988, 0.8073553981551205, 0.8106821818524097, 0.8074980586408133, 0.8095629588667168, 0.8063685405685241, 0.8081187052899097, 0.8116381541792168, 0.8083319606551205, 0.8094511836408133, 0.8115366740399097, 0.811058687876506, 0.810814547251506, 0.8144663615399097, 0.812401461314006, 0.8133574336408133, 0.8117705195783133, 0.8122896860881024, 0.814232516001506, 0.8096850291792168, 0.8107733669051205, 0.8139780802899097, 0.8134795039533133, 0.8116278590926205, 0.8117808146649097, 0.8115160838667168, 0.8110175075301205, 0.8145884318524097, 0.8127470820783133, 0.8130015177899097, 0.817040133189006, 0.8139368999435241, 0.8165621470256024, 0.8151781932417168, 0.8127161968185241, 0.8132250682417168, 0.815941500376506, 0.815453219126506, 0.8138457148908133, 0.814964937876506, 0.8132456584149097, 0.8163180064006024, 0.8163988963667168, 0.8159517954631024, 0.8160738657756024, 0.8153208537274097, 0.814964937876506, 0.818016695689006, 0.8174372293862951, 0.8145781367658133, 0.8155546992658133, 0.816429781626506, 0.8137339396649097, 0.8145781367658133, 0.8178843302899097, 0.8163886012801205, 0.8173048639871988, 0.8161547557417168, 0.8184946818524097, 0.8176401896649097, 0.8160326854292168, 0.8170298381024097, 0.8157988398908133, 0.8173960490399097, 0.8156561794051205, 0.816918062876506, 0.817406344126506, 0.8154017436935241, 0.8150767131024097, 0.8166430369917168, 0.8176401896649097, 0.8167856974774097, 0.8172430934676205, 0.8182505412274097, 0.817528414439006, 0.816673922251506, 0.8196344950112951, 0.8175387095256024, 0.8186064570783133, 0.8174166392131024, 0.8188505977033133, 0.8177622599774097, 0.8177622599774097, 0.8195830195783133, 0.8187388224774097, 0.818993258189006, 0.817894625376506, 0.819481539439006, 0.8183623164533133, 0.8193697642131024, 0.818871187876506, 0.819969820689006, 0.8172739787274097, 0.8170092479292168, 0.8186064570783133, 0.8166533320783133, 0.8188608927899097, 0.8196241999246988, 0.8192065135542168, 0.8179961055158133, 0.8172636836408133, 0.8181284709149097, 0.8182402461408133, 0.8181284709149097, 0.8173960490399097, 0.818138766001506, 0.8178740352033133, 0.8181181758283133, 0.820946383189006, 0.8178843302899097, 0.8193491740399097, 0.819603609751506, 0.8183726115399097, 0.8195933146649097, 0.8193491740399097, 0.8187285273908133, 0.8186064570783133, 0.8199492305158133, 0.8188608927899097, 0.8193491740399097, 0.8182505412274097, 0.8184843867658133, 0.8188917780496988, 0.8190947383283133, 0.8187388224774097, 0.8187388224774097, 0.8193388789533133, 0.8184843867658133, 0.8189829631024097, 0.8187285273908133, 0.8179961055158133, 0.8188608927899097, 0.8182402461408133, 0.8182402461408133, 0.8187388224774097, 0.8176401896649097, 0.8177622599774097, 0.8183726115399097, 0.8188608927899097, 0.8188608927899097, 0.8184843867658133, 0.8183623164533133, 0.8187388224774097, 0.8186167521649097, 0.8197359751506024, 0.8184946818524097, 0.8187388224774097, 0.8187388224774097, 0.8184946818524097, 0.8189829631024097, 0.8188814829631024, 0.819237398814006, 0.8183726115399097, 0.8188608927899097, 0.8182505412274097, 0.8189829631024097, 0.819237398814006, 0.8182505412274097, 0.818627047251506], "accuracy_test": 0.822249681122449, "start": "2016-01-27 00:18:13.194000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0], "accuracy_train_last": 0.9862390844176817, "batch_size_eval": 1024, "accuracy_train_std": [0.01352597020400545, 0.012427639071327299, 0.013342623897853536, 0.014438300527195474, 0.014447783306329396, 0.014069924250813787, 0.015445815593797506, 0.014724946345258104, 0.01322285083912642, 0.012038299540980566, 0.011585936044906278, 0.011860648211132677, 0.014355379021950856, 0.013979369993540651, 0.01505150097270481, 0.014851197059429113, 0.015086652619931527, 0.01412298990976911, 0.014701026094358305, 0.014552081355916431, 0.01424247589315619, 0.01524839551373769, 0.014383432252301228, 0.014212261377202705, 0.013790923453276255, 0.014795990789141638, 0.015026070627216372, 0.014361131663081807, 0.015040014785488217, 0.014345067968689878, 0.013163464897962303, 0.012226174318773899, 0.01382206511333829, 0.01284729713206096, 0.013479405196898553, 0.012154769394156644, 0.011891403473026875, 0.011637350943204816, 0.013100946824713555, 0.013554435523556176, 0.012422993213736105, 0.013249224593926487, 0.010939588756755363, 0.013159979621018196, 0.012011585628704786, 0.01160732142770808, 0.010725268521468961, 0.011494966006845079, 0.010151874274517065, 0.010637030106891836, 0.010539965863762357, 0.01159415377413292, 0.011039636845917196, 0.010289338021509348, 0.010980488016635308, 0.010623760139710798, 0.010411364030128161, 0.011538298236233872, 0.009678969286040463, 0.01118777192533248, 0.010060119499722138, 0.010455428425164651, 0.010810552799602698, 0.011206576634669124, 0.011208052409876178, 0.010628529238263434, 0.010381493718641615, 0.009618188904973762, 0.009663834096950217, 0.010516320841100105, 0.010632147308541685, 0.009702268726813177, 0.008859587861236461, 0.009600440926985627, 0.009036182408900934, 0.010112562045846077, 0.008903465369555297, 0.009112882931985268, 0.009175604247378656, 0.00905662566454364, 0.008086763176668902, 0.009236622103546697, 0.008204652681336857, 0.008106996928789129, 0.008497856959487078, 0.008304226458242296, 0.007562106687762392, 0.007995987441219201, 0.008780863894374486, 0.008164832859372199, 0.007888322911828921, 0.00880719615000259, 0.008706297569330109, 0.006913221592455053, 0.007641275077238119, 0.007786834456065416, 0.007409274877587907, 0.007816684165358327, 0.008255109804848537, 0.007406846775349606, 0.007219486646704812, 0.0071582108352747035, 0.006976643419113882, 0.006365223625156219, 0.007429831755942821, 0.007727220972004392, 0.00661697633309138, 0.0068937817633088665, 0.007559295725929552, 0.006661471490627294, 0.006803296860901713, 0.006646913370032005, 0.006786959855614049, 0.006509340395212166, 0.00622392430075811, 0.005931675468891439, 0.005477072789860489, 0.0061530430949760274, 0.006049756637070881, 0.006188669105754822, 0.005580368937887764, 0.005978124541742457, 0.006828826682812998, 0.005500383199666278, 0.0057094570943301524, 0.005683123773034286, 0.00546521444432108, 0.005489273602451306, 0.0053513500211400875, 0.005553614480935936, 0.005267291109758965, 0.00558766807786437, 0.004868135338748263, 0.005303931260390546, 0.0048893054901454625, 0.005558192236671539, 0.005084073864852477, 0.004933011664737339, 0.004860228549773254, 0.004765943529683265, 0.004927004098626074, 0.005098498930571102, 0.004785088063608441, 0.004695265080686888, 0.004262425503809101, 0.004177856682480994, 0.005040000475363784, 0.004134661206199118, 0.004691418801395732, 0.004284841344920236, 0.004644900763250002, 0.004290973987310117, 0.004314470644120617, 0.004523912613336491, 0.004563252408671909, 0.004950199892128138, 0.004369704772654494, 0.004655886707118952, 0.00393034066909222, 0.004631631538335238, 0.0038872706609386115, 0.004429546893941299, 0.004409992634153983, 0.0042251476565555255, 0.004617187339500448, 0.003793826518414202, 0.004127088811321289, 0.004013128692236393, 0.00448593719561012, 0.004237890239897538, 0.004598861676243798, 0.0039827872560839975, 0.004135239066256016, 0.004166815735895805, 0.004275621160364122, 0.004115043320706779, 0.0036011201108196987, 0.00399127536888479, 0.00354721250265861, 0.004314548955336116, 0.004056769462586357, 0.0038186117796531545, 0.004015103758137572, 0.004007554723959766, 0.0039012772850991664, 0.003762367686601791, 0.003395787958683407, 0.0034924699144382025, 0.003607222414091112, 0.0037081476310224094, 0.003459735649115476, 0.003845736377906069, 0.0035653684351006467, 0.0037249029162859447, 0.003960136158527657, 0.003635308041463496, 0.0040300596994039635, 0.003953956754396315, 0.004080317707701183, 0.0035313500864675683, 0.003733102645867439, 0.003958568371608226, 0.003591323977602644, 0.0036251911892176, 0.003777278473438152, 0.003465857230931225, 0.003572791461194051, 0.0037061749929355285, 0.0037840375201148475, 0.003842936351536126, 0.004133785969357596, 0.00376223303046481, 0.0034010322625976047, 0.004083335118999861, 0.003370015414735113, 0.004256088301901476, 0.0034819674627680954, 0.0035647582332455257, 0.00345086368663377, 0.0035828885050534567, 0.003428249353786366, 0.0033509958765047705, 0.0034102985292843203, 0.0038736560413109617, 0.0035675299496305754, 0.0036540191413536698, 0.00378777708349884, 0.0037323886590021646, 0.00334642887792639, 0.003484532020729801, 0.003530006894967895, 0.0036408441267125344, 0.00364058627316725, 0.0031093844462006894, 0.0038584100702776956, 0.0034710505174467745, 0.0036685615118514886, 0.0036584091982809807, 0.003280289221122555, 0.004088777957225274, 0.003641662326725864, 0.0035598012302273116, 0.003567387392657861, 0.0036223062462686193, 0.003523582361360629, 0.00339592688965399, 0.003483771445500774, 0.003174760059267888, 0.0031474691290825367, 0.003456889444801457, 0.003453317567009896, 0.0038216895880127557, 0.003137166880154104, 0.0034605343469393357, 0.003670499470250529, 0.0034201157587138487, 0.003611745363045765, 0.0033968542914826943, 0.003479848514068067, 0.0036501776490405376, 0.003718490347452635], "accuracy_test_std": 0.00794970492426352, "error_valid": [0.5453807417168675, 0.49771007859563254, 0.46477021366716864, 0.4297448583396084, 0.4086458137236446, 0.3916265648531627, 0.3721659097326807, 0.3651564264871988, 0.35080213431852414, 0.34399708207831325, 0.34082325395331325, 0.33069141801581325, 0.3246687923569277, 0.3125323559864458, 0.31838143589984935, 0.30446542027484935, 0.2980971738516567, 0.298595750188253, 0.2939467832266567, 0.2911185758659638, 0.28292956984186746, 0.28275749482304224, 0.2714343702936747, 0.27545239551957834, 0.2647205031061747, 0.26971509083207834, 0.26415133189006024, 0.2586978774472892, 0.2562255859375, 0.2547916274472892, 0.24990881494728923, 0.2528590926204819, 0.24742622835090367, 0.24807776025978923, 0.24219779508659633, 0.24757918392319278, 0.23867834619728923, 0.23640901496611444, 0.23802681428840367, 0.2318821183170181, 0.23191300357680722, 0.23057023013930722, 0.22192235739834332, 0.2326145401920181, 0.23312341161521077, 0.22649043439382532, 0.22808764354292166, 0.22904361586972888, 0.22051928416792166, 0.22276655449924698, 0.22176057746611444, 0.2195721362010542, 0.2186470491340362, 0.22167821677334332, 0.2215061417545181, 0.21104780449924698, 0.2123699877635542, 0.21423192771084332, 0.2129803393260542, 0.21350980092243976, 0.2104168627635542, 0.20929763977786142, 0.20896231410015065, 0.2141304475715362, 0.2118817065135542, 0.20294998352786142, 0.20811811699924698, 0.2028176181287651, 0.2023087467055723, 0.20905349915286142, 0.2035500400037651, 0.2035809252635542, 0.2043839420180723, 0.19911432840737953, 0.2027264330760542, 0.20478103821536142, 0.20359122035015065, 0.19963349491716864, 0.1987892978162651, 0.20136306946536142, 0.19865693241716864, 0.19997911568147586, 0.19829072147966864, 0.1963273013930723, 0.19484186746987953, 0.19731415897966864, 0.19584931522966864, 0.1972023837537651, 0.1974259342055723, 0.19473009224397586, 0.1941506259412651, 0.19421092573418675, 0.19545221903237953, 0.19607286568147586, 0.1938550098832832, 0.1940079654555723, 0.19264460184487953, 0.1916577442582832, 0.1926343067582832, 0.18859569135918675, 0.1898060993975903, 0.19252253153237953, 0.18928693288780118, 0.19264460184487953, 0.1893178181475903, 0.19250194135918675, 0.1904370411332832, 0.19363145943147586, 0.1918812947100903, 0.1883618458207832, 0.19166803934487953, 0.19054881635918675, 0.1884633259600903, 0.18894131212349397, 0.18918545274849397, 0.1855336384600903, 0.18759853868599397, 0.18664256635918675, 0.18822948042168675, 0.18771031391189763, 0.18576748399849397, 0.1903149708207832, 0.18922663309487953, 0.1860219197100903, 0.18652049604668675, 0.18837214090737953, 0.1882191853350903, 0.1884839161332832, 0.18898249246987953, 0.1854115681475903, 0.18725291792168675, 0.1869984822100903, 0.18295986681099397, 0.18606310005647586, 0.18343785297439763, 0.1848218067582832, 0.18728380318147586, 0.1867749317582832, 0.18405849962349397, 0.18454678087349397, 0.18615428510918675, 0.18503506212349397, 0.1867543415850903, 0.18368199359939763, 0.1836011036332832, 0.18404820453689763, 0.18392613422439763, 0.1846791462725903, 0.18503506212349397, 0.18198330431099397, 0.18256277061370485, 0.18542186323418675, 0.18444530073418675, 0.18357021837349397, 0.1862660603350903, 0.18542186323418675, 0.1821156697100903, 0.18361139871987953, 0.18269513601280118, 0.1838452442582832, 0.1815053181475903, 0.1823598103350903, 0.1839673145707832, 0.1829701618975903, 0.18420116010918675, 0.1826039509600903, 0.18434382059487953, 0.18308193712349397, 0.18259365587349397, 0.18459825630647586, 0.1849232868975903, 0.1833569630082832, 0.1823598103350903, 0.1832143025225903, 0.18275690653237953, 0.1817494587725903, 0.18247158556099397, 0.18332607774849397, 0.18036550498870485, 0.18246129047439763, 0.18139354292168675, 0.18258336078689763, 0.18114940229668675, 0.1822377400225903, 0.1822377400225903, 0.18041698042168675, 0.1812611775225903, 0.18100674181099397, 0.18210537462349397, 0.18051846056099397, 0.18163768354668675, 0.18063023578689763, 0.18112881212349397, 0.18003017931099397, 0.1827260212725903, 0.1829907520707832, 0.18139354292168675, 0.18334666792168675, 0.1811391072100903, 0.18037580007530118, 0.1807934864457832, 0.18200389448418675, 0.18273631635918675, 0.1818715290850903, 0.18175975385918675, 0.1818715290850903, 0.1826039509600903, 0.18186123399849397, 0.18212596479668675, 0.18188182417168675, 0.17905361681099397, 0.1821156697100903, 0.1806508259600903, 0.18039639024849397, 0.1816273884600903, 0.1804066853350903, 0.1806508259600903, 0.18127147260918675, 0.18139354292168675, 0.18005076948418675, 0.1811391072100903, 0.1806508259600903, 0.1817494587725903, 0.18151561323418675, 0.18110822195030118, 0.18090526167168675, 0.1812611775225903, 0.1812611775225903, 0.18066112104668675, 0.18151561323418675, 0.1810170368975903, 0.18127147260918675, 0.18200389448418675, 0.1811391072100903, 0.18175975385918675, 0.18175975385918675, 0.1812611775225903, 0.1823598103350903, 0.1822377400225903, 0.1816273884600903, 0.1811391072100903, 0.1811391072100903, 0.18151561323418675, 0.18163768354668675, 0.1812611775225903, 0.1813832478350903, 0.18026402484939763, 0.1815053181475903, 0.1812611775225903, 0.1812611775225903, 0.1815053181475903, 0.1810170368975903, 0.18111851703689763, 0.18076260118599397, 0.1816273884600903, 0.1811391072100903, 0.1817494587725903, 0.1810170368975903, 0.18076260118599397, 0.1817494587725903, 0.18137295274849397], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.9170971633114078, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00043102952761866326, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "l2_decay": 1.5204746036000052e-05, "optimization": "nesterov_momentum", "nb_data_augmentation": 1, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.019427886383694627}, "accuracy_valid_max": 0.820946383189006, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        #nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        nb_data_augmentation=make_constant_param(1),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.818627047251506, "loss_train": [1.8521922826766968, 1.5624126195907593, 1.4484978914260864, 1.365852952003479, 1.2962796688079834, 1.2344977855682373, 1.181462049484253, 1.1377617120742798, 1.0968390703201294, 1.0635533332824707, 1.033762812614441, 1.002053141593933, 0.9764630198478699, 0.9512577056884766, 0.9273815751075745, 0.9086592197418213, 0.885806143283844, 0.8657181859016418, 0.8462820649147034, 0.8289260864257812, 0.8071384429931641, 0.7939621806144714, 0.7775283455848694, 0.7628847360610962, 0.7481327056884766, 0.7328147292137146, 0.7206019759178162, 0.7097947597503662, 0.6951804161071777, 0.6865739226341248, 0.6727069020271301, 0.6624058485031128, 0.652047872543335, 0.6455394625663757, 0.6360303163528442, 0.624917209148407, 0.6166124939918518, 0.6077461242675781, 0.5988894701004028, 0.5914642810821533, 0.5832388997077942, 0.5775048732757568, 0.5674662590026855, 0.5642703771591187, 0.5565254092216492, 0.5494251847267151, 0.5431884527206421, 0.5363646745681763, 0.5319858193397522, 0.5274796485900879, 0.5198044776916504, 0.5184488892555237, 0.5087705850601196, 0.5036414265632629, 0.4985634386539459, 0.49635395407676697, 0.4907194972038269, 0.4835602045059204, 0.4816442131996155, 0.4771559238433838, 0.4743536710739136, 0.4679669141769409, 0.46321696043014526, 0.4605284333229065, 0.4582569897174835, 0.45817306637763977, 0.45115646719932556, 0.44514206051826477, 0.44351649284362793, 0.44132304191589355, 0.4350236654281616, 0.43315351009368896, 0.4296221137046814, 0.42689231038093567, 0.42572617530822754, 0.4226270318031311, 0.4203034043312073, 0.41436344385147095, 0.41655412316322327, 0.4112401008605957, 0.4085384011268616, 0.4077790379524231, 0.4038301706314087, 0.40251579880714417, 0.39699357748031616, 0.3964199125766754, 0.39446836709976196, 0.3922979533672333, 0.39353618025779724, 0.38777533173561096, 0.3863537311553955, 0.38335806131362915, 0.38242053985595703, 0.38107094168663025, 0.3806911110877991, 0.37803563475608826, 0.3758186101913452, 0.3741670250892639, 0.37448441982269287, 0.3744114339351654, 0.3678071200847626, 0.3713015019893646, 0.37113168835639954, 0.36760643124580383, 0.36614081263542175, 0.36462223529815674, 0.3626193702220917, 0.3626943826675415, 0.3609084486961365, 0.36104318499565125, 0.3584056794643402, 0.35741713643074036, 0.3561103045940399, 0.35464784502983093, 0.35428905487060547, 0.35270825028419495, 0.3519936501979828, 0.3503161072731018, 0.3497188985347748, 0.34911176562309265, 0.34730085730552673, 0.3485998511314392, 0.34562256932258606, 0.3451453447341919, 0.34644728899002075, 0.343384325504303, 0.3440808057785034, 0.34140637516975403, 0.3396527171134949, 0.34218257665634155, 0.3386656939983368, 0.3408185541629791, 0.3393633961677551, 0.33711400628089905, 0.33776602149009705, 0.33757540583610535, 0.3338172733783722, 0.33448702096939087, 0.33295783400535583, 0.33251190185546875, 0.3353084623813629, 0.33125361800193787, 0.331680566072464, 0.33083316683769226, 0.3296433389186859, 0.33024805784225464, 0.32825860381126404, 0.3289940059185028, 0.32928118109703064, 0.3311280310153961, 0.32648372650146484, 0.32593533396720886, 0.3297921121120453, 0.32729488611221313, 0.32508501410484314, 0.32352620363235474, 0.3242712616920471, 0.32359468936920166, 0.3253670334815979, 0.32371658086776733, 0.32534337043762207, 0.3231276571750641, 0.3231523334980011, 0.3215526044368744, 0.32245156168937683, 0.3214584290981293, 0.3228496015071869, 0.32338717579841614, 0.3224664330482483, 0.3209725618362427, 0.31927117705345154, 0.3208627700805664, 0.3205889165401459, 0.31841716170310974, 0.31972891092300415, 0.31749454140663147, 0.31705814599990845, 0.3182828724384308, 0.3172800540924072, 0.3170562982559204, 0.3182299733161926, 0.3161720931529999, 0.31643548607826233, 0.31731516122817993, 0.3164183795452118, 0.3174402415752411, 0.3142661154270172, 0.31561708450317383, 0.31615352630615234, 0.31401050090789795, 0.31314146518707275, 0.3152531683444977, 0.31357312202453613, 0.3147970736026764, 0.31477880477905273, 0.31271740794181824, 0.3110834062099457, 0.31624454259872437, 0.31220144033432007, 0.3157702386379242, 0.3129521310329437, 0.314470112323761, 0.31052571535110474, 0.3114332854747772, 0.3134153187274933, 0.3125838339328766, 0.3112642765045166, 0.3103152811527252, 0.3102004826068878, 0.31092965602874756, 0.3118148148059845, 0.3112609088420868, 0.3109375536441803, 0.3110925257205963, 0.3099305033683777, 0.30936363339424133, 0.31287696957588196, 0.31002524495124817, 0.31025201082229614, 0.3115204870700836, 0.3109927475452423, 0.3105178475379944, 0.30976226925849915, 0.3122020661830902, 0.31018850207328796, 0.31055188179016113, 0.30855560302734375, 0.308969646692276, 0.30937227606773376, 0.31270378828048706, 0.3112770915031433, 0.3100719153881073, 0.31196555495262146, 0.30873939394950867, 0.3079378604888916, 0.30905869603157043, 0.30629006028175354, 0.31018245220184326, 0.3091176748275757, 0.30664849281311035, 0.309437096118927, 0.3072737455368042, 0.3081865608692169, 0.30809998512268066, 0.30793002247810364, 0.30585071444511414, 0.3088185787200928, 0.30868107080459595, 0.30625614523887634, 0.30744361877441406, 0.3055962026119232, 0.3065744638442993, 0.30559200048446655, 0.30626997351646423, 0.30489999055862427, 0.3064136803150177, 0.30680519342422485, 0.30926141142845154, 0.3067993223667145, 0.30723071098327637, 0.306925892829895], "accuracy_train_first": 0.4644291885843485, "model": "residualv3", "loss_std": [0.30013424158096313, 0.12262324243783951, 0.1245785802602768, 0.12524744868278503, 0.12571296095848083, 0.12527993321418762, 0.12557603418827057, 0.1268118917942047, 0.12294796854257584, 0.12606514990329742, 0.1249418631196022, 0.12286142259836197, 0.12275447696447372, 0.12559235095977783, 0.12351178377866745, 0.12272480130195618, 0.12372377514839172, 0.12235824763774872, 0.12168729305267334, 0.12018483877182007, 0.1198468878865242, 0.1175195649266243, 0.11923927068710327, 0.12043565511703491, 0.11762895435094833, 0.1144387274980545, 0.11511363089084625, 0.11300582438707352, 0.11279437690973282, 0.11127487570047379, 0.11187534779310226, 0.10986695438623428, 0.10709977149963379, 0.11030296981334686, 0.10760113596916199, 0.1071765124797821, 0.10629072040319443, 0.10609409958124161, 0.103730708360672, 0.10221327096223831, 0.10261406004428864, 0.09870371967554092, 0.10071361064910889, 0.10036993771791458, 0.09892898052930832, 0.09624151885509491, 0.09827802330255508, 0.09674758464097977, 0.09489120543003082, 0.09332505613565445, 0.0937022790312767, 0.09153315424919128, 0.09245225787162781, 0.09202234447002411, 0.09080219268798828, 0.0900498703122139, 0.08828062564134598, 0.08675124496221542, 0.08556386828422546, 0.08817927539348602, 0.08526132255792618, 0.08572043478488922, 0.08486737310886383, 0.08589620888233185, 0.08189103752374649, 0.08441776037216187, 0.08120612800121307, 0.08296797424554825, 0.08195223659276962, 0.08214575052261353, 0.07806762307882309, 0.07948634028434753, 0.08082322031259537, 0.07817894965410233, 0.07736644148826599, 0.078874871134758, 0.07780729234218597, 0.0755016878247261, 0.07808215916156769, 0.07263533025979996, 0.0763661190867424, 0.07770706713199615, 0.07347653061151505, 0.0759006068110466, 0.07277299463748932, 0.07206981629133224, 0.07635869085788727, 0.07217986136674881, 0.07383233308792114, 0.07312741875648499, 0.06973741948604584, 0.07246788591146469, 0.07241678982973099, 0.07100556790828705, 0.07564860582351685, 0.07080384343862534, 0.068660207092762, 0.07041915506124496, 0.07000738382339478, 0.06772514432668686, 0.06794463098049164, 0.07126803696155548, 0.06933761388063431, 0.06885458528995514, 0.0678493082523346, 0.0660930797457695, 0.06971697509288788, 0.06949084252119064, 0.06714800000190735, 0.06470821052789688, 0.07051705569028854, 0.0678204819560051, 0.06692983210086823, 0.06424704194068909, 0.06809113174676895, 0.06552133709192276, 0.06600649654865265, 0.06707613915205002, 0.06626243889331818, 0.0662296712398529, 0.06575942784547806, 0.06763007491827011, 0.06701109558343887, 0.06362202018499374, 0.06505008041858673, 0.06461449712514877, 0.06228630989789963, 0.0662495568394661, 0.06560592353343964, 0.0638422891497612, 0.06454944610595703, 0.06491842865943909, 0.06339596211910248, 0.06363877654075623, 0.06416044384241104, 0.06333691626787186, 0.06442702561616898, 0.06251466274261475, 0.06256610155105591, 0.06120724231004715, 0.06511290371417999, 0.06168849393725395, 0.060715798288583755, 0.05993405357003212, 0.05981922894716263, 0.06211778149008751, 0.06308720260858536, 0.06245608627796173, 0.06268331408500671, 0.06130322068929672, 0.06079373136162758, 0.06162583455443382, 0.06152348965406418, 0.06170554459095001, 0.06190083175897598, 0.06009912118315697, 0.06111058220267296, 0.06070216745138168, 0.061915285885334015, 0.05931650102138519, 0.060436997562646866, 0.05946846306324005, 0.06214028224349022, 0.060814499855041504, 0.059729620814323425, 0.05999543517827988, 0.06072698161005974, 0.06154746189713478, 0.06086646392941475, 0.06085712090134621, 0.05925493314862251, 0.06044026464223862, 0.06189582124352455, 0.05934154987335205, 0.06070440635085106, 0.05989811196923256, 0.06047121807932854, 0.06061655282974243, 0.057951658964157104, 0.06122085452079773, 0.06173469126224518, 0.058866359293460846, 0.05917012318968773, 0.059513114392757416, 0.05864584445953369, 0.060682378709316254, 0.058335863053798676, 0.05852745100855827, 0.05832119658589363, 0.059350114315748215, 0.05828472971916199, 0.05910841375589371, 0.060253337025642395, 0.05955316498875618, 0.059634625911712646, 0.05679159611463547, 0.05713232234120369, 0.06083818897604942, 0.05821888521313667, 0.05993449687957764, 0.05791493505239487, 0.059149082750082016, 0.057529740035533905, 0.05996623635292053, 0.056729599833488464, 0.05937580764293671, 0.0586978979408741, 0.059720441699028015, 0.05921127274632454, 0.05799149349331856, 0.05998286232352257, 0.05998396873474121, 0.05892783775925636, 0.058941930532455444, 0.05807105451822281, 0.05740339308977127, 0.059775952249765396, 0.058127716183662415, 0.0585075207054615, 0.05895353481173515, 0.06145163252949715, 0.059304989874362946, 0.05735227093100548, 0.05911979079246521, 0.06076020374894142, 0.0584440752863884, 0.05961272120475769, 0.05755944177508354, 0.056983474642038345, 0.060249149799346924, 0.05889398604631424, 0.05958659201860428, 0.058656711131334305, 0.05693064630031586, 0.055978044867515564, 0.05938025191426277, 0.05751718953251839, 0.05898271128535271, 0.05852445587515831, 0.05678405985236168, 0.05997244641184807, 0.05936252698302269, 0.056709639728069305, 0.05739590525627136, 0.057227421551942825, 0.058615345507860184, 0.05722551792860031, 0.057008855044841766, 0.05808299779891968, 0.05744766816496849, 0.05725949630141258, 0.057940855622291565, 0.05680396780371666, 0.05722488835453987, 0.0577540397644043, 0.05917968228459358, 0.0575256422162056, 0.05796360597014427, 0.05843179672956467, 0.05709339678287506, 0.05697210133075714]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:21 2016", "state": "available"}], "summary": "552c7e11dda8ce8ed7da17ef39d56a7c"}