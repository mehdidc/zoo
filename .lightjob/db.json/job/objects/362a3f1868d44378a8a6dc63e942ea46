{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 64, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [2.0012779235839844, 1.7433606386184692, 1.6522653102874756, 1.5850186347961426, 1.5282597541809082, 1.4834511280059814, 1.4435110092163086, 1.4094276428222656, 1.3797321319580078, 1.3526161909103394, 1.3260945081710815, 1.300532341003418, 1.2788103818893433, 1.259032130241394, 1.238613486289978, 1.2159574031829834, 1.1986418962478638, 1.1813156604766846, 1.158935546875, 1.1437169313430786, 1.1283153295516968, 1.1107892990112305, 1.0943816900253296, 1.0800679922103882, 1.060975432395935, 1.0487513542175293, 1.0333653688430786, 1.019359827041626, 1.0046836137771606, 0.9928603172302246, 0.979254961013794, 0.9647848010063171, 0.9525243639945984, 0.9415028095245361, 0.9296475648880005, 0.9184485673904419, 0.9060037732124329, 0.8955443501472473, 0.8832002878189087, 0.8741292357444763, 0.864705502986908, 0.853670597076416, 0.8443521857261658, 0.8362764120101929, 0.827429473400116, 0.8174396753311157, 0.8066272139549255, 0.800520122051239, 0.7924123406410217, 0.7835325002670288, 0.7738307118415833, 0.7667434811592102, 0.7607930898666382, 0.7540016174316406, 0.7455825209617615, 0.7390599846839905, 0.7314471006393433, 0.7237781286239624, 0.7167922854423523, 0.7092417478561401, 0.7037773132324219, 0.6977968215942383, 0.6909132599830627, 0.6840311288833618, 0.6795844435691833, 0.6723047494888306, 0.6667098999023438, 0.6574932336807251, 0.6536323428153992, 0.6468986868858337, 0.6415553689002991, 0.6342594027519226, 0.6276630163192749, 0.6237356662750244, 0.6167556047439575, 0.6120076179504395, 0.6092926263809204, 0.601851761341095, 0.599715530872345, 0.5899481773376465, 0.5880290865898132, 0.5826855301856995, 0.5768610835075378, 0.5722150206565857, 0.566622793674469, 0.5631100535392761, 0.5579000115394592, 0.5532791018486023, 0.5470025539398193, 0.5446010828018188, 0.5391035676002502, 0.5332914590835571, 0.5290572643280029, 0.5259746313095093, 0.5206976532936096, 0.5166577696800232, 0.5136685967445374, 0.5100102424621582, 0.5040180087089539, 0.49983954429626465, 0.4936758577823639, 0.46940526366233826, 0.4599069654941559, 0.45898717641830444, 0.45617666840553284, 0.45653560757637024, 0.45449182391166687, 0.4527278244495392, 0.4531857967376709, 0.45278215408325195, 0.4534297585487366, 0.45175936818122864, 0.45206695795059204, 0.4498139023780823, 0.44877833127975464, 0.45120862126350403, 0.44537919759750366, 0.44943854212760925, 0.4450713098049164, 0.4467272460460663, 0.4442959725856781, 0.4422386884689331, 0.44312408566474915, 0.4433777928352356, 0.44324034452438354, 0.4431230425834656, 0.443157434463501, 0.443523108959198, 0.4415873885154724, 0.44412127137184143, 0.4416591227054596, 0.44057780504226685, 0.4434894919395447, 0.4427674412727356, 0.44291990995407104, 0.44199344515800476, 0.44604042172431946, 0.44254136085510254, 0.44404348731040955, 0.4435485005378723, 0.4417702555656433, 0.4428067207336426, 0.44342365860939026, 0.4428682327270508, 0.4438839256763458, 0.44529280066490173, 0.44370657205581665, 0.44250452518463135, 0.44269827008247375, 0.44451338052749634, 0.44415655732154846, 0.44237014651298523, 0.44249022006988525, 0.4414699077606201, 0.44088613986968994, 0.44280895590782166, 0.44273561239242554, 0.4457316994667053, 0.44297295808792114, 0.44353213906288147, 0.4443003833293915, 0.4429132044315338, 0.44367507100105286, 0.4424915611743927, 0.44419631361961365, 0.4446958005428314, 0.44116753339767456, 0.44325995445251465, 0.4457164704799652, 0.44558560848236084, 0.442588746547699, 0.4449259042739868, 0.4429609775543213, 0.4430057406425476, 0.44524452090263367, 0.4429205060005188, 0.44260719418525696, 0.44330140948295593, 0.4408387839794159, 0.44274699687957764, 0.4434328079223633, 0.44305869936943054, 0.4435977339744568, 0.4416206181049347, 0.4431036710739136, 0.4431406259536743, 0.4446450173854828], "moving_avg_accuracy_train": [0.03524629994924325, 0.07217093196290142, 0.1088275402881598, 0.14458748767130394, 0.17878912875051906, 0.21089350724797545, 0.24180327981590585, 0.270679657347189, 0.29765894656701974, 0.32325816155640485, 0.34730188328374706, 0.36984335452763145, 0.39088820852438844, 0.41140023352143285, 0.42982621483544864, 0.44699531922515034, 0.46379799204839023, 0.4796225564809635, 0.49502705863094765, 0.509558680615998, 0.5231575771988702, 0.5360755275758363, 0.5483852766651058, 0.5601080089192302, 0.5711955412741233, 0.581873865745825, 0.5919633023762998, 0.601113657954469, 0.6095255811378889, 0.6183353279278929, 0.6270334719531176, 0.6353221449912868, 0.6432237289994486, 0.6507511759996053, 0.658409326700909, 0.6653687311593711, 0.6722576241529301, 0.678355357348333, 0.6842688555051571, 0.6901208493843203, 0.6959807731149081, 0.7013752877711636, 0.706156234590439, 0.7109241164896914, 0.7160102668966009, 0.7209734525258316, 0.7256774847707106, 0.7300689715684181, 0.7343955504982318, 0.7386426778611993, 0.7428675234760115, 0.7469742266816587, 0.7510562342691223, 0.7548601052358977, 0.7581326707262892, 0.7617125650485477, 0.7649597942337538, 0.7684428055588096, 0.7717076880358743, 0.7751457008687302, 0.7783467971659012, 0.7812117601334196, 0.7842806169100833, 0.786891381238824, 0.7898013579001483, 0.7925481479822264, 0.7950783877763349, 0.797885881714879, 0.8003776408809694, 0.8029178071292512, 0.8054131480479245, 0.807591273217523, 0.8098773229964075, 0.8125623416830624, 0.814279168953479, 0.8166796798682086, 0.8185356533438738, 0.8202664472922014, 0.8225005278075365, 0.8248366129582151, 0.8261837046212805, 0.8275889663227737, 0.8291417319159485, 0.8310648487760333, 0.8326817216584429, 0.8343600494406883, 0.8360285464173006, 0.8379324083914805, 0.8396715329027846, 0.8416854265855589, 0.843297787858343, 0.8453279471550577, 0.8465088072995094, 0.84799704761284, 0.8497503764317517, 0.8515861033984418, 0.8533059032768515, 0.8549280558316876, 0.8558415471119832, 0.8579167642284888, 0.8591989186703501, 0.8631964065156167, 0.8669104390656516, 0.8702739946999687, 0.8733733464815868, 0.8761649800873964, 0.8787007739183578, 0.8810434061864518, 0.8831029110539178, 0.885068108626313, 0.8868321361438497, 0.8884592884393946, 0.8899330621494418, 0.891303528169409, 0.8925718608683411, 0.8937087820973985, 0.894759804842808, 0.8957383494946476, 0.8966051608860836, 0.8974643101490809, 0.8982957453036542, 0.8990231466523031, 0.8996893615124973, 0.9002842685402344, 0.9008638987413973, 0.9013739401783963, 0.9018166653812101, 0.9021640008387517, 0.9024881924457681, 0.9028217815218353, 0.9030988322998382, 0.9033179871143358, 0.9035803306140502, 0.9037955134245075, 0.9039542286241388, 0.9041157095431017, 0.9042796796094633, 0.9044110126763409, 0.9045500666781789, 0.9046543249893662, 0.9047690477599017, 0.904928137873631, 0.9049876136188445, 0.905052659387128, 0.9051019360321638, 0.9051254668198666, 0.9051930393585333, 0.9052469152457236, 0.9053140407834898, 0.905351202279384, 0.905398598518546, 0.9054388939361635, 0.9054774849608288, 0.9055354683711229, 0.9055481619594443, 0.9055712479818, 0.9055430530816451, 0.9055851790846194, 0.9055766616087433, 0.9055875610221121, 0.9055927922941627, 0.9055694544580188, 0.9055624373471653, 0.905593396425987, 0.9056072726552507, 0.9056639030401501, 0.9056847155496732, 0.9056731477760828, 0.9056999752096225, 0.9057007963140755, 0.9057015353080833, 0.9056720455658039, 0.9056594196417909, 0.9056876198887598, 0.9057199395086416, 0.9056955126950975, 0.9057177063902888, 0.9056586977540746, 0.9056846089921868, 0.9056894000136492, 0.9057005792329376, 0.9057199411255352, 0.9057095010919777, 0.9057302598986621, 0.9057629658151728, 0.905752801512633, 0.9057088845546606], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.035073301016566256, 0.0722068547628012, 0.10900148837537649, 0.14468528273249245, 0.17856468720585467, 0.2100612458290192, 0.2403918647043251, 0.2686080375618293, 0.294826641279291, 0.3196095256735757, 0.3428612695952995, 0.36450702445994126, 0.3844133909145495, 0.4037604319059259, 0.4210364324370954, 0.43701310851755754, 0.4524042710750638, 0.46704565637343093, 0.48157700117471736, 0.4953265982146251, 0.5081427476928614, 0.5203741125131837, 0.5319093022125431, 0.5425584981208068, 0.5527429779868135, 0.5628632173210388, 0.5724058853762091, 0.5807613235234526, 0.5887939131684718, 0.5971504087586277, 0.6055939886941354, 0.6133661680909116, 0.6205279099508716, 0.6273163040084954, 0.6343577110699953, 0.6405220199705259, 0.6465358241858228, 0.6515840960594093, 0.656408302464387, 0.6614530955707345, 0.6664338920001068, 0.6707823314427919, 0.6749512450887988, 0.6790074136427955, 0.6832480208760311, 0.6871256025421931, 0.6910894412431695, 0.6945104116990484, 0.6979341705103181, 0.701320729221711, 0.7045273234682146, 0.7080542009670256, 0.7112588347577478, 0.714303755592967, 0.7168610788759143, 0.7197405183339554, 0.722256712641373, 0.724960740643049, 0.7275307022056267, 0.7302017895528351, 0.7325548810230035, 0.7348843009120435, 0.7374222909544987, 0.7395376425725279, 0.7413752763292059, 0.7433210859515563, 0.74535822387372, 0.7472516536512576, 0.7489780954962222, 0.7507923588475789, 0.7526805140113904, 0.7543148475405977, 0.7558579603957247, 0.7576994516302487, 0.758765708698022, 0.7604109928263373, 0.7612305098370018, 0.762482829476419, 0.7640534883115331, 0.7653286858847472, 0.765911751737161, 0.7666512370962009, 0.7676260677352253, 0.7688777152444588, 0.7699086007700883, 0.7705362224325373, 0.7719760172167685, 0.7726441263855284, 0.7737154688768701, 0.7747355647320295, 0.7754624565363115, 0.7764584560351653, 0.7768471607422662, 0.7774818747320457, 0.7781395960502567, 0.7788658225803967, 0.7797381235113631, 0.7804662772276213, 0.7808611498813651, 0.7819621936846444, 0.7822817463888456, 0.7847127808519943, 0.7868162921587376, 0.7888824097896259, 0.7908019213050157, 0.7922354834102069, 0.793745415867379, 0.7950687634937436, 0.7961844751526523, 0.7971397875206702, 0.7982590048341152, 0.7993263060638061, 0.8001515703181182, 0.8007966518969991, 0.8016101884204017, 0.8021104376977138, 0.8025463959987256, 0.8030628877994554, 0.8033069743489527, 0.8038196209935001, 0.8043420381298428, 0.8048386866323706, 0.8052469901735763, 0.8056154928693211, 0.8060346535315608, 0.8064596967439167, 0.8065960359927178, 0.8066810907142292, 0.8068329411684088, 0.8069807840997607, 0.8072745931615467, 0.8075288733032233, 0.8076447736235035, 0.8077002557867555, 0.8078234319211824, 0.8078976693484167, 0.8082117121839063, 0.8083447778348681, 0.8084279158269837, 0.8084406753549781, 0.8085640812287423, 0.8085621947079012, 0.8086002064588731, 0.8086079439549285, 0.8087156524773573, 0.8088359747013836, 0.8087835142794381, 0.8087495364395967, 0.8087677845087394, 0.8087709712310582, 0.8088104603748952, 0.8088348230817581, 0.8088323354554348, 0.808768031926834, 0.8088444360948434, 0.8089640869883711, 0.8088266026588864, 0.8089368593734194, 0.8089862327828395, 0.8090164028027484, 0.8090822359317357, 0.8089827943415742, 0.8089644800806095, 0.8090843336068105, 0.8089826232318222, 0.8089521190505828, 0.8090121735235367, 0.8091262281967855, 0.8091556352152094, 0.8091322438981312, 0.8090756001276705, 0.8091975781890752, 0.8091099869270202, 0.8090545393450109, 0.808918157793793, 0.8089571943299256, 0.8089424695787855, 0.8089037737315997, 0.8088567404378825, 0.8089253032634467, 0.8089259746502044, 0.8087912720458768, 0.8088175535856414, 0.8087557577526797, 0.8088354483554239, 0.8087097983805742, 0.8086709850993693], "moving_var_accuracy_train": [0.011180714941008224, 0.022333499491004032, 0.032193511947106256, 0.040483125284002774, 0.04696258302820559, 0.05154254479375651, 0.054987016676191505, 0.056992921622535116, 0.057844567881547085, 0.05795798936604722, 0.057365095419959294, 0.056201647210513184, 0.05456745540716522, 0.05289739839176305, 0.05066330963904688, 0.04824998198504247, 0.045965952112581816, 0.043623108456649615, 0.04139648578938444, 0.03915734954809358, 0.03690598448772914, 0.03471724701643204, 0.03260929161855577, 0.030585164520217173, 0.028633048431682677, 0.026795983110220908, 0.0250325553828821, 0.02328286090945628, 0.021591418883304455, 0.02013078174150989, 0.018798622952710876, 0.01753707956404285, 0.016345286876180917, 0.015220720313624333, 0.014226473731736817, 0.01323972615231129, 0.012342865157170518, 0.011443219792554322, 0.010613622957355752, 0.009860473152876041, 0.009183474192743204, 0.008527033868857892, 0.007880047554370748, 0.0072966370791806515, 0.00679979370491793, 0.006341513238737951, 0.005906513189111909, 0.005489428276850667, 0.005108959016288778, 0.004760405932195308, 0.004445009223196754, 0.004152293401850542, 0.0038870291351624743, 0.003628551130633123, 0.0033620831815699167, 0.0031412156536397714, 0.0029219945647070856, 0.0027389774192505788, 0.002561014795626923, 0.0024112927062141676, 0.002262386593126602, 0.002110020049061209, 0.001983778981396153, 0.001846745896678559, 0.0017382829845357733, 0.0016323583878772245, 0.0015267415698307135, 0.0014450056127822968, 0.001356384825180233, 0.0012788183437824003, 0.0012069770461078063, 0.0011289774047869706, 0.0010631138766321131, 0.0010216864170980772, 0.0009460452382762827, 0.0009033027883142786, 0.0008439742473642089, 0.0007865376518518965, 0.0007528039284077043, 0.0007266391800479243, 0.0006703071655814378, 0.0006210492930704461, 0.0005806440926495297, 0.0005558650895024564, 0.0005238070818130546, 0.0004967774309336605, 0.00047215462728897176, 0.000457561378310627, 0.0004390262270719344, 0.00043162551425440614, 0.0004118603426947306, 0.0004077682293555881, 0.00037954128254682145, 0.00036152088736414375, 0.00035303625615276397, 0.00034806167200358666, 0.000339874909399233, 0.0003295698286597602, 0.0003041230426663694, 0.00031246947312547413, 0.00029601780592798964, 0.00041023520699267626, 0.0004933580263378739, 0.0005458437822504022, 0.0005777132372213366, 0.0005900808772009707, 0.0005889450426591485, 0.0005794418718848742, 0.0005596717273884291, 0.0005384625681365187, 0.0005126224490665053, 0.0004851888254959278, 0.00045621802348217285, 0.0004274998151409186, 0.00039922784414345044, 0.00037093836865883715, 0.0003437863710952694, 0.00031802568070653616, 0.0002929853705307905, 0.00027033007058269236, 0.00024951862327076557, 0.00022932877544183628, 0.00021039047805714487, 0.00019253665959628787, 0.00017630673416756118, 0.0001610173411579097, 0.00014667965748897696, 0.00013309746902066995, 0.00012073362390114124, 0.0001096617965560703, 9.938643110279124e-05, 8.988004748696916e-05, 8.151145974485407e-05, 7.377704654761537e-05, 6.662605652419956e-05, 6.019813565648185e-05, 5.4420297734797514e-05, 4.913350333141703e-05, 4.439417713711989e-05, 4.0052587582472514e-05, 3.616578065093935e-05, 3.2776989564422964e-05, 2.953112688639897e-05, 2.6616092765503392e-05, 2.397633717866692e-05, 2.1583686742529447e-05, 1.9466412500113287e-05, 1.754589475108676e-05, 1.5831857816361616e-05, 1.4261100825719365e-05, 1.2855208374527746e-05, 1.1584301023203713e-05, 1.0439274325545803e-05, 9.425605575815126e-06, 8.484495162893885e-06, 7.64084232645836e-06, 6.8839126653652245e-06, 6.211492799968004e-06, 5.590996446528906e-06, 5.0329659767820996e-06, 4.529915674969287e-06, 4.081825998835251e-06, 3.6740865575543076e-06, 3.3153040828522532e-06, 2.985506622214214e-06, 2.715818964437529e-06, 2.4481355129676546e-06, 2.2045262821434455e-06, 1.990551054642065e-06, 1.7915020170905638e-06, 1.6123567303907987e-06, 1.4589478614490435e-06, 1.3144878009187843e-06, 1.1901963061888864e-06, 1.0805776960337704e-06, 9.778899494096673e-07, 8.84533995424875e-07, 8.274187682131091e-07, 7.507194217364036e-07, 6.758540645426403e-07, 6.093934325834723e-07, 5.518280352898148e-07, 4.976261804669863e-07, 4.517419149149593e-07, 4.161948161966928e-07, 3.755051519921104e-07, 3.5531292957086204e-07], "duration": 125417.759303, "accuracy_train": [0.3524629994924326, 0.40449262008582504, 0.43873701521548536, 0.4664270141196013, 0.48660389846345514, 0.4998329137250831, 0.5199912329272794, 0.5305670551287376, 0.5404725495454965, 0.5536510964608712, 0.5636953788298266, 0.5727165957225914, 0.5802918944952011, 0.5960084584948321, 0.595660046661591, 0.6015172587324659, 0.615022047457549, 0.6220436363741233, 0.6336675779808048, 0.6403432784814507, 0.6455476464447213, 0.6523370809685308, 0.6591730184685308, 0.6656125992063492, 0.6709833324681617, 0.6779787859911407, 0.6827682320505721, 0.6834668581579919, 0.6852328897886674, 0.6976230490379292, 0.7053167681801403, 0.7099202023348099, 0.7143379850729051, 0.7184981990010152, 0.7273326830126431, 0.7280033712855297, 0.7342576610949612, 0.7332349561069582, 0.7374903389165743, 0.7427887942967885, 0.7487200866901993, 0.749925919677464, 0.7491847559639165, 0.7538350535829641, 0.7617856205587855, 0.7656421231889073, 0.7680137749746216, 0.769592352747785, 0.773334760866556, 0.776866824127907, 0.7808911340093209, 0.7839345555324843, 0.7877943025562938, 0.789094943936877, 0.7875857601398117, 0.793931613948874, 0.7941848569006091, 0.7997899074843117, 0.8010916303294574, 0.8060878163644334, 0.8071566638404393, 0.8069964268410853, 0.8119003279000554, 0.8103882601974898, 0.8159911478520672, 0.8172692587209303, 0.8178505459233113, 0.8231533271617755, 0.8228034733757843, 0.8257793033637875, 0.8278712163159838, 0.8271943997439092, 0.8304517710063677, 0.8367275098629567, 0.8297306143872278, 0.8382842781007751, 0.8352394146248615, 0.8358435928271503, 0.8426072524455519, 0.8458613793143227, 0.8383075295888703, 0.8402363216362125, 0.843116622254522, 0.8483729005167959, 0.8472335776001293, 0.849464999480897, 0.8510450192068106, 0.8550671661590993, 0.855323653504522, 0.8598104697305279, 0.8578090393133997, 0.863599380825489, 0.8571365485995754, 0.8613912104328165, 0.8655303358019564, 0.8681076460986527, 0.8687841021825397, 0.8695274288252122, 0.8640629686346438, 0.8765937182770396, 0.8707383086471022, 0.8991737971230158, 0.9003367320159652, 0.9005459954088224, 0.9012675125161499, 0.9012896825396824, 0.9015229183970099, 0.9021270965992986, 0.901638454861111, 0.90275488677787, 0.9027083838016795, 0.9031036590992986, 0.903197025539867, 0.903637722349114, 0.9039868551587301, 0.9039410731589147, 0.9042190095514949, 0.9045452513612033, 0.904406463409007, 0.9051966535160576, 0.9057786616948136, 0.905569758790144, 0.9056852952542451, 0.905638431789867, 0.9060805705518641, 0.9059643131113879, 0.9058011922065338, 0.9052900199566261, 0.9054059169089147, 0.9058240832064415, 0.9055922893018641, 0.9052903804448136, 0.9059414221114802, 0.9057321587186231, 0.9053826654208195, 0.9055690378137689, 0.9057554102067183, 0.9055930102782392, 0.9058015526947213, 0.9055926497900517, 0.9058015526947213, 0.9063599488971945, 0.9055228953257659, 0.9056380713016795, 0.9055454258374861, 0.9053372439091916, 0.9058011922065338, 0.9057317982304356, 0.905918170623385, 0.9056856557424326, 0.905825164671004, 0.9058015526947213, 0.9058248041828165, 0.9060573190637689, 0.9056624042543374, 0.9057790221830011, 0.905289298980251, 0.9059643131113879, 0.9055000043258582, 0.9056856557424326, 0.9056398737426172, 0.9053594139327242, 0.9054992833494832, 0.905872028135382, 0.9057321587186231, 0.9061735765042451, 0.905872028135382, 0.9055690378137689, 0.9059414221114802, 0.9057081862541528, 0.9057081862541528, 0.9054066378852897, 0.9055457863256736, 0.9059414221114802, 0.9060108160875784, 0.9054756713732004, 0.9059174496470099, 0.905127620028147, 0.9059178101351975, 0.9057325192068106, 0.9058011922065338, 0.9058941981589147, 0.9056155407899593, 0.9059170891588224, 0.9060573190637689, 0.9056613227897747, 0.9053136319329088], "end": "2016-02-04 22:28:46.630000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0], "moving_var_accuracy_valid": [0.011071227997788011, 0.02237421252242988, 0.032321396834339794, 0.040549255768394285, 0.04682465661878193, 0.05107048980282569, 0.0542429587947747, 0.05598403461181826, 0.05657236777867607, 0.05644285323091282, 0.055664360266434294, 0.05431477257273231, 0.05244966614428547, 0.0505734714859549, 0.04820226608653612, 0.04567932708510261, 0.043243385340436605, 0.04084837827749011, 0.03866398028534597, 0.03649904502564994, 0.034327423710121416, 0.032241137907419636, 0.030214569529279527, 0.028213760937784813, 0.026325897515276187, 0.024615080961386572, 0.02297313548774841, 0.021304142058665286, 0.019754430320446183, 0.01840746645533621, 0.017208366188948367, 0.016031190523234585, 0.014889686389129462, 0.013815458395150741, 0.012880145276287329, 0.011934119086649042, 0.011066199748243433, 0.01018894521360588, 0.009379507399185747, 0.008670606096639829, 0.008026820484613478, 0.007394318766432426, 0.00681130545867995, 0.006278247442857834, 0.005812267445931175, 0.005366361457537856, 0.004971133467010299, 0.004579347470049231, 0.004226911842624041, 0.003907439677513036, 0.0036092359297171224, 0.003360262120769989, 0.0031166630082867333, 0.002888440593492828, 0.0026584556555050835, 0.002467230634287292, 0.002277488674992695, 0.002115545714398054, 0.001963433464856387, 0.0018313024869185, 0.0016980055934294593, 0.0015770408072616102, 0.001477309267635869, 0.001369850753083365, 0.0012632577581881688, 0.0011710075581472378, 0.001091256180557769, 0.0010143962494041881, 0.0009397820374601726, 0.0008754277972868399, 0.0008199711868618042, 0.0007620134829378456, 0.000707242910196984, 0.0006670384288787411, 0.0006105667232020562, 0.0005738726896478258, 0.000522529893859959, 0.00048439164478739544, 0.0004581552028955545, 0.0004269748422625806, 0.0003873370501305822, 0.0003535248924836337, 0.0003267250562082985, 0.00030815214397380224, 0.0002869014542789922, 0.0002617564894116703, 0.0002542379216567978, 0.00023283145824354743, 0.00021987828502298163, 0.00020725581650410328, 0.0001912855801098838, 0.00018108515711434832, 0.00016433646354681536, 0.00015152857383152898, 0.00014026909244024027, 0.00013098882795392885, 0.00012473812538601884, 0.00011703618335792358, 0.00010673588473620396, 0.00010697297337323833, 9.719470141277537e-05, 0.00014066458832064235, 0.0001664209678469519, 0.0001881984496442636, 0.00020253932479926458, 0.00020078129510430018, 0.00020122222982086555, 0.00019686124730062027, 0.0001883784351229831, 0.00017775418709507662, 0.000171252594938005, 0.00016437952267830182, 0.00015407112021548032, 0.00014240918038463613, 0.00013412483742036095, 0.00012296459773338773, 0.00011237867472203845, 0.00010354168127182513, 9.372371733745176e-05, 8.671660484319891e-05, 8.050122133798014e-05, 7.467103681974977e-05, 6.870433917362492e-05, 6.3056053387203e-05, 5.833170899540469e-05, 5.4124493687193176e-05, 4.8879339835346696e-05, 4.40565146026744e-05, 3.985839018631761e-05, 3.606926895884233e-05, 3.3239255946046093e-05, 3.0497255865501393e-05, 2.756842623712047e-05, 2.4839288047360585e-05, 2.249191048345562e-05, 2.029232019553119e-05, 1.915069429867954e-05, 1.739498307600453e-05, 1.5717692100001203e-05, 1.4147388139992842e-05, 1.2869710413109192e-05, 1.1582771402446229e-05, 1.0437498301109172e-05, 9.394287290605129e-06, 8.559268693778833e-06, 7.833638762752706e-06, 7.0750437493138225e-06, 6.377929816785027e-06, 5.74313376335347e-06, 5.168911783810359e-06, 4.666055137758096e-06, 4.20479149735347e-06, 3.7843680421806468e-06, 3.4431457320770957e-06, 3.151369530872223e-06, 2.965079604682818e-06, 2.8386891118992407e-06, 2.664229088605904e-06, 2.4197457817652014e-06, 2.185963274500363e-06, 2.0063729549005365e-06, 1.894733328095149e-06, 1.7082787046777647e-06, 1.6667346438955295e-06, 1.5931661829282918e-06, 1.4422241102932698e-06, 1.3304605567597249e-06, 1.3144907174926464e-06, 1.1908246003366149e-06, 1.0766665237348163e-06, 9.978765219493847e-07, 1.0319966969307163e-06, 9.978470899333113e-07, 9.257322900960314e-07, 1.0005584086999706e-06, 9.142172282091695e-07, 8.247468700535062e-07, 7.557485003529818e-07, 7.000828267786792e-07, 6.723822935448888e-07, 6.051481210320063e-07, 7.079364334427263e-07, 6.433592640901047e-07, 6.133918624240014e-07, 6.09208005673022e-07, 6.903784507231014e-07, 6.34898842831886e-07], "accuracy_test": 0.799348294005102, "start": "2016-02-03 11:38:28.871000", "learning_rate_per_epoch": [0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 0.000274989492027089, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894883891102e-05, 2.749894974840572e-06, 2.749895031683991e-07, 2.7498950672111278e-08, 2.7498949783932858e-09, 2.749895033904437e-10, 2.749895103293376e-11, 2.749895146661463e-12, 2.7498950382412457e-13, 2.7498950043599278e-14, 2.749895004359928e-15, 2.749895110239046e-16, 2.7498951102390462e-17, 2.749895151598077e-18, 2.7498952549956534e-19, 2.749895384242624e-20, 2.7498953034632674e-21, 2.7498954044374633e-22, 2.7498952782197185e-23, 2.749895357105809e-24, 2.7498954064096156e-25, 2.749895468039374e-26, 2.7498955450765716e-27, 2.749895496928323e-28, 2.749895436743012e-29, 2.7498954367430122e-30, 2.7498955307825603e-31, 2.7498956483319953e-32, 2.7498956483319953e-33, 2.7498956942497434e-34, 2.7498956942497434e-35, 2.749895730122984e-36, 2.749895774964535e-37, 2.749895774964535e-38, 2.749895494704842e-39, 2.7498940934063778e-40, 2.749908106391021e-41, 2.749347587005291e-42, 2.7465449900766415e-43, 2.802596928649634e-44, 2.802596928649634e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_train_first": 0.3524629994924326, "accuracy_train_last": 0.9053136319329088, "batch_size_eval": 1024, "accuracy_train_std": [0.01653807804080958, 0.01671424046994526, 0.016237142777663187, 0.016038121395390258, 0.016649187052186716, 0.017915188510483362, 0.01642919205743333, 0.015651636962860288, 0.016174313994769342, 0.016374589754348266, 0.016714207997997613, 0.01829624735394542, 0.01842153217700124, 0.017548608237519633, 0.016322371938373454, 0.015161643150134312, 0.018331796093075097, 0.01687592635635338, 0.016142079133814713, 0.01690163338278368, 0.017004820182815662, 0.016741112372535276, 0.016103719247765335, 0.01557353745927391, 0.015229962265635472, 0.01649303155949913, 0.015553777221932442, 0.015325242975478857, 0.01612130373417065, 0.015910119330016282, 0.015552086822650376, 0.016330211362899888, 0.017050124330033205, 0.0157665184463008, 0.016343014207934436, 0.01611774227009315, 0.015590338117316804, 0.01650865328069416, 0.015393691954512538, 0.016117748236453903, 0.016214283650709645, 0.01457529380409415, 0.01463660661283982, 0.015636827976758493, 0.014996050816110912, 0.016146410988039973, 0.015632465526921557, 0.015670084128743263, 0.015939076586652754, 0.01632249745903393, 0.014954241890429255, 0.015964036746105692, 0.014436796832068399, 0.014848862731735185, 0.01459611812049645, 0.015368443751987952, 0.015112449461140098, 0.014452577942627274, 0.015100678746702147, 0.01523728568806783, 0.015720440478051444, 0.01531845964459764, 0.014737834105514559, 0.015195675561273311, 0.01478614483245245, 0.014340353814063246, 0.014850579475598785, 0.015037297181904066, 0.01439357696044719, 0.013972797324844733, 0.013649003716842, 0.01559408045947357, 0.013367053898452181, 0.014344973565845071, 0.01500066138837771, 0.014304638427095156, 0.014174611885406932, 0.014289155422439517, 0.014431748918475703, 0.014227439159242752, 0.013188150363605013, 0.014420635306160116, 0.01576613216293513, 0.014542826153550011, 0.014421904338228757, 0.015549935201057677, 0.014828008110334256, 0.014776632682350197, 0.014853643074383858, 0.014047901857392476, 0.015046494150467979, 0.01368511687631277, 0.013646714132972151, 0.013908692483990544, 0.013202781558969765, 0.015095164097890487, 0.01361432816124287, 0.013581830574205983, 0.01453553568857893, 0.014520288942131214, 0.012825212994640896, 0.010485000396856, 0.01085409761538125, 0.010655706366678527, 0.010319474286738593, 0.011181513598231009, 0.010370899678305791, 0.011061658140622647, 0.010450982784618462, 0.010679004085170874, 0.010242253913534458, 0.010450116087878191, 0.010077307889468659, 0.00953327796540945, 0.009630071631090567, 0.009627551477699075, 0.010095333480972492, 0.009692565123636374, 0.009592657497573848, 0.009835125802309379, 0.00926529624125002, 0.009388862144379105, 0.008704915588638045, 0.009366115563065132, 0.009253388039669665, 0.009361547623362599, 0.009707308083375053, 0.009486846163952399, 0.009700865602058907, 0.009594850474069187, 0.009325755524436952, 0.00933150897280376, 0.009685370784647922, 0.009343358374374713, 0.009933600872002747, 0.0094678755375612, 0.00937978547995768, 0.009233237917003674, 0.009404788870690415, 0.009145358942072976, 0.009339373694725999, 0.00884432202956939, 0.009303815719327207, 0.009153391658005387, 0.009429670751608896, 0.009180606241507728, 0.009180760834338407, 0.009187436129240207, 0.008773025537922632, 0.00882055008630167, 0.00884635487916038, 0.009344234967888596, 0.0094600296572135, 0.009222207291306957, 0.009215632201793415, 0.00955143741975584, 0.009326449849697363, 0.009405105476964848, 0.009191628883808253, 0.008604232657362156, 0.008753005866410807, 0.009481220250907212, 0.009326036841161607, 0.008906170086410165, 0.009191449060157236, 0.009284019213257045, 0.00901009440451063, 0.009359331139236352, 0.009460029930234913, 0.009515884855001704, 0.009269300522675786, 0.00970395531423221, 0.00947935818710799, 0.009027705536192586, 0.009039572486958768, 0.009119298443824536, 0.009299941699302412, 0.009581322929976144, 0.009124154030849988, 0.009020796471272297, 0.009424843540660144, 0.009197188064626518, 0.009279774041022017, 0.009641014792798292, 0.009359072541350016, 0.009335435438492095, 0.009310731450730822], "accuracy_test_std": 0.008596875025267329, "error_valid": [0.6492669898343373, 0.5935911615210843, 0.5598468091114458, 0.5341605680534638, 0.5165206725338856, 0.5064697265625, 0.48663256541792166, 0.47744640672063254, 0.4692059252635542, 0.4573445147778614, 0.44787303510918675, 0.4406811817582832, 0.43642931099397586, 0.42211619917168675, 0.4234795627823795, 0.4191968067582832, 0.4090752659073795, 0.4011818759412651, 0.38764089561370485, 0.38092702842620485, 0.37651190700301207, 0.36954360410391573, 0.36427399049322284, 0.3615987387048193, 0.3555967032191265, 0.34605462867093373, 0.34171010212725905, 0.3440397331513554, 0.3389127800263554, 0.3276411309299698, 0.31841379188629515, 0.31668421733810237, 0.31501641330948793, 0.3115881494728916, 0.30226962537650603, 0.3039991999246988, 0.29933993787650603, 0.30298145707831325, 0.30017383989081325, 0.2931437664721386, 0.28873894013554224, 0.29008171357304224, 0.2875285320971386, 0.2844870693712349, 0.27858651402484935, 0.27797616246234935, 0.27323601044804224, 0.27470085419804224, 0.271252000188253, 0.268200242375753, 0.266613328313253, 0.2602039015436747, 0.259899461125753, 0.25829195689006024, 0.26012301157756024, 0.2543445265436747, 0.25509753859186746, 0.25070300734186746, 0.24933964373117468, 0.24575842432228923, 0.2462672957454819, 0.24415092008659633, 0.23973579866340367, 0.24142419286521077, 0.24208601986069278, 0.23916662744728923, 0.23630753482680722, 0.23570747835090367, 0.23548392789909633, 0.23287927099021077, 0.23032608951430722, 0.2309761506965362, 0.23025402390813254, 0.2257271272590362, 0.2316379776920181, 0.22478145001882532, 0.2313938370670181, 0.22624629376882532, 0.22181058217243976, 0.22319453595632532, 0.22884065559111444, 0.22669339467243976, 0.2236004565135542, 0.21985745717243976, 0.22081342949924698, 0.22381518260542166, 0.21506582972515065, 0.22134289109563254, 0.2166424487010542, 0.2160835725715362, 0.21799551722515065, 0.21457754847515065, 0.21965449689382532, 0.21680569935993976, 0.21594091208584332, 0.21459813864834332, 0.21241116810993976, 0.2129803393260542, 0.21558499623493976, 0.20812841208584332, 0.21484227927334332, 0.19340790897966864, 0.1942521060805723, 0.19252253153237953, 0.19192247505647586, 0.1948624576430723, 0.1926651920180723, 0.19302110786897586, 0.19377411991716864, 0.19426240116716864, 0.19166803934487953, 0.19106798286897586, 0.1924210513930723, 0.1933976138930723, 0.19106798286897586, 0.19338731880647586, 0.19352997929216864, 0.19228868599397586, 0.1944962467055723, 0.1915665592055723, 0.1909562076430723, 0.19069147684487953, 0.1910782779555723, 0.19106798286897586, 0.1901929005082832, 0.18971491434487953, 0.1921769107680723, 0.19255341679216864, 0.19180040474397586, 0.1916886295180723, 0.19008112528237953, 0.19018260542168675, 0.19131212349397586, 0.19180040474397586, 0.19106798286897586, 0.19143419380647586, 0.18896190229668675, 0.19045763130647586, 0.19082384224397586, 0.1914444888930723, 0.19032526590737953, 0.19145478397966864, 0.19105768778237953, 0.1913224185805723, 0.1903149708207832, 0.19008112528237953, 0.1916886295180723, 0.19155626411897586, 0.19106798286897586, 0.1912003482680723, 0.1908341373305723, 0.19094591255647586, 0.19119005318147586, 0.1918106998305723, 0.1904679263930723, 0.18995905496987953, 0.19241075630647586, 0.1900708301957832, 0.19056940653237953, 0.1907120670180723, 0.19032526590737953, 0.19191217996987953, 0.1912003482680723, 0.18983698465737953, 0.1919327701430723, 0.1913224185805723, 0.19044733621987953, 0.18984727974397586, 0.19057970161897586, 0.1910782779555723, 0.19143419380647586, 0.1897046192582832, 0.19167833443147586, 0.1914444888930723, 0.19230927616716864, 0.19069147684487953, 0.19119005318147586, 0.1914444888930723, 0.1915665592055723, 0.19045763130647586, 0.19106798286897586, 0.1924210513930723, 0.19094591255647586, 0.19180040474397586, 0.19044733621987953, 0.1924210513930723, 0.19167833443147586], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.07383357936062844, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.00027498948127524454, "optimization": "nesterov_momentum", "nb_data_augmentation": 1, "learning_rate_decay_method": "discrete", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 2.896501355255304e-06, "rotation_range": [0, 0], "momentum": 0.7224960519676911}, "accuracy_valid_max": 0.8110380977033133, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8083216655685241, "accuracy_valid_std": [0.012013085472737918, 0.015483489494062351, 0.016118744403626345, 0.016440200110423988, 0.013783399688510663, 0.010229900051534818, 0.008833214052111023, 0.00921660063978641, 0.010170725098540143, 0.006724331958812633, 0.011712998486661658, 0.009632071607135115, 0.009257908307951548, 0.008536012372637578, 0.011763896648154333, 0.012558033875238458, 0.012285676106519417, 0.019363653738053314, 0.01666246139977101, 0.020726773100449805, 0.02120975985609248, 0.01754015001195604, 0.018583664336652407, 0.021269068623194044, 0.021358385259079647, 0.02024859323800165, 0.014938759538567754, 0.01492897060013353, 0.017062008843633264, 0.01811345176973701, 0.011775141224106566, 0.014712351974593914, 0.015729002852809326, 0.015757921887857334, 0.013777188310536252, 0.01775976045763468, 0.015330032935979973, 0.014018232034158003, 0.01405438451563207, 0.009467312187771582, 0.010622406944142643, 0.011918950214751804, 0.015261655540742188, 0.012620907188348997, 0.010210207630309078, 0.011754803757588283, 0.013342017770020604, 0.013390854914254045, 0.011064857151989536, 0.011637103736498637, 0.014625803900252948, 0.0085882352406647, 0.01376157345093635, 0.013085198796702937, 0.010755850186230835, 0.010982581169194991, 0.0113707009366459, 0.012574632410966154, 0.010133957583880315, 0.00926898192695338, 0.008520117926722456, 0.008354635559878696, 0.00598758218594349, 0.010817840620117028, 0.011186143819564863, 0.01085871384700181, 0.008238261943731498, 0.008679330595741988, 0.010391883968467703, 0.008427307248146115, 0.007949653891151931, 0.00851640789206613, 0.0099339489252563, 0.010703152792571778, 0.006555463939470886, 0.008302192313660247, 0.010200183031089091, 0.010664042442272134, 0.009594065612245458, 0.011412903673345427, 0.011479701969648171, 0.011776670203667093, 0.013426108583979093, 0.011029255139703644, 0.012950204371023786, 0.010443219788543168, 0.012965448993950144, 0.008012786483363695, 0.012454673869582043, 0.00959752888872382, 0.011674075599385521, 0.009679603663762587, 0.012837701212613677, 0.012216815280705383, 0.011256584422580079, 0.011552357732433186, 0.013744294000957962, 0.012719907926907102, 0.01051611644054768, 0.009447539142005043, 0.010066319276300726, 0.008919276950580627, 0.01011288493011403, 0.009507418595734098, 0.008785859468123906, 0.01029243180257832, 0.008137978069923812, 0.010758198514690115, 0.010813638135730276, 0.010772785537600965, 0.008877677915480827, 0.009604402711489789, 0.009380887684227245, 0.009236003683192067, 0.008988907589223365, 0.00957355698255789, 0.010196305968425287, 0.009754822474010631, 0.009416045415482575, 0.009872640787964593, 0.009821289733008024, 0.009614441966948458, 0.009856406593102059, 0.008882179406811424, 0.00958281328269915, 0.009800420561300309, 0.009666630630843144, 0.010071585970474972, 0.009883685823291882, 0.009136055500045148, 0.009543229547291686, 0.010995086384666616, 0.01021131946676557, 0.010605149567914533, 0.010029416818191729, 0.009641278011126806, 0.010045754691610892, 0.009083964000060311, 0.00983809681209521, 0.00884876134489761, 0.009257439960567514, 0.009009639207751271, 0.009402986529085812, 0.010182661269006778, 0.010561380182055276, 0.009341227592060698, 0.009393395641722776, 0.009546956528915577, 0.009028605395347729, 0.010644584311123494, 0.009989495814763168, 0.009277251304529999, 0.009208802842409242, 0.010610840898186317, 0.01000356703257534, 0.00945640048164659, 0.010156360708550144, 0.010129444470199383, 0.010868141692226923, 0.00900877403684438, 0.010165784252925492, 0.010937720480207698, 0.009841559490172715, 0.009417943615263852, 0.010509507260031234, 0.010356778901079918, 0.010101606787222581, 0.009780114198498571, 0.00907620346209081, 0.008658858069751483, 0.009727444255381173, 0.010290976040229154, 0.00974816699786273, 0.00929552629109333, 0.010591948746689566, 0.010716755141896572, 0.009967225447212472, 0.010533941459675398, 0.009236324409309282, 0.009766934279797121, 0.010993397151775238, 0.010530395877545935, 0.009753322396663761, 0.009614678190834395, 0.00943024060313815, 0.010631792160767182, 0.009500441475857258], "accuracy_valid": [0.35073301016566266, 0.4064088384789157, 0.4401531908885542, 0.46583943194653615, 0.48347932746611444, 0.4935302734375, 0.5133674345820783, 0.5225535932793675, 0.5307940747364458, 0.5426554852221386, 0.5521269648908133, 0.5593188182417168, 0.5635706890060241, 0.5778838008283133, 0.5765204372176205, 0.5808031932417168, 0.5909247340926205, 0.5988181240587349, 0.6123591043862951, 0.6190729715737951, 0.6234880929969879, 0.6304563958960843, 0.6357260095067772, 0.6384012612951807, 0.6444032967808735, 0.6539453713290663, 0.658289897872741, 0.6559602668486446, 0.6610872199736446, 0.6723588690700302, 0.6815862081137049, 0.6833157826618976, 0.6849835866905121, 0.6884118505271084, 0.697730374623494, 0.6960008000753012, 0.700660062123494, 0.6970185429216867, 0.6998261601091867, 0.7068562335278614, 0.7112610598644578, 0.7099182864269578, 0.7124714679028614, 0.7155129306287651, 0.7214134859751506, 0.7220238375376506, 0.7267639895519578, 0.7252991458019578, 0.728747999811747, 0.731799757624247, 0.733386671686747, 0.7397960984563253, 0.740100538874247, 0.7417080431099398, 0.7398769884224398, 0.7456554734563253, 0.7449024614081325, 0.7492969926581325, 0.7506603562688253, 0.7542415756777108, 0.7537327042545181, 0.7558490799134037, 0.7602642013365963, 0.7585758071347892, 0.7579139801393072, 0.7608333725527108, 0.7636924651731928, 0.7642925216490963, 0.7645160721009037, 0.7671207290097892, 0.7696739104856928, 0.7690238493034638, 0.7697459760918675, 0.7742728727409638, 0.7683620223079819, 0.7752185499811747, 0.7686061629329819, 0.7737537062311747, 0.7781894178275602, 0.7768054640436747, 0.7711593444088856, 0.7733066053275602, 0.7763995434864458, 0.7801425428275602, 0.779186570500753, 0.7761848173945783, 0.7849341702748494, 0.7786571089043675, 0.7833575512989458, 0.7839164274284638, 0.7820044827748494, 0.7854224515248494, 0.7803455031061747, 0.7831943006400602, 0.7840590879141567, 0.7854018613516567, 0.7875888318900602, 0.7870196606739458, 0.7844150037650602, 0.7918715879141567, 0.7851577207266567, 0.8065920910203314, 0.8057478939194277, 0.8074774684676205, 0.8080775249435241, 0.8051375423569277, 0.8073348079819277, 0.8069788921310241, 0.8062258800828314, 0.8057375988328314, 0.8083319606551205, 0.8089320171310241, 0.8075789486069277, 0.8066023861069277, 0.8089320171310241, 0.8066126811935241, 0.8064700207078314, 0.8077113140060241, 0.8055037532944277, 0.8084334407944277, 0.8090437923569277, 0.8093085231551205, 0.8089217220444277, 0.8089320171310241, 0.8098070994917168, 0.8102850856551205, 0.8078230892319277, 0.8074465832078314, 0.8081995952560241, 0.8083113704819277, 0.8099188747176205, 0.8098173945783133, 0.8086878765060241, 0.8081995952560241, 0.8089320171310241, 0.8085658061935241, 0.8110380977033133, 0.8095423686935241, 0.8091761577560241, 0.8085555111069277, 0.8096747340926205, 0.8085452160203314, 0.8089423122176205, 0.8086775814194277, 0.8096850291792168, 0.8099188747176205, 0.8083113704819277, 0.8084437358810241, 0.8089320171310241, 0.8087996517319277, 0.8091658626694277, 0.8090540874435241, 0.8088099468185241, 0.8081893001694277, 0.8095320736069277, 0.8100409450301205, 0.8075892436935241, 0.8099291698042168, 0.8094305934676205, 0.8092879329819277, 0.8096747340926205, 0.8080878200301205, 0.8087996517319277, 0.8101630153426205, 0.8080672298569277, 0.8086775814194277, 0.8095526637801205, 0.8101527202560241, 0.8094202983810241, 0.8089217220444277, 0.8085658061935241, 0.8102953807417168, 0.8083216655685241, 0.8085555111069277, 0.8076907238328314, 0.8093085231551205, 0.8088099468185241, 0.8085555111069277, 0.8084334407944277, 0.8095423686935241, 0.8089320171310241, 0.8075789486069277, 0.8090540874435241, 0.8081995952560241, 0.8095526637801205, 0.8075789486069277, 0.8083216655685241], "seed": 203477741, "model": "residualv3", "loss_std": [0.24575930833816528, 0.13784871995449066, 0.14256882667541504, 0.1508919894695282, 0.15716120600700378, 0.1625574678182602, 0.16530068218708038, 0.1675366461277008, 0.16862447559833527, 0.16964955627918243, 0.17231228947639465, 0.1712268441915512, 0.17392617464065552, 0.1758360117673874, 0.1751231551170349, 0.17753668129444122, 0.17648833990097046, 0.17660245299339294, 0.17559611797332764, 0.1762397289276123, 0.1770494282245636, 0.17415018379688263, 0.17525918781757355, 0.17519555985927582, 0.1742173135280609, 0.1761559098958969, 0.1725454032421112, 0.17451848089694977, 0.1749696284532547, 0.17494340240955353, 0.17486220598220825, 0.17354823648929596, 0.17506292462348938, 0.17422740161418915, 0.17404082417488098, 0.17385447025299072, 0.1723310649394989, 0.1726040542125702, 0.1703641414642334, 0.1699078530073166, 0.1709914356470108, 0.17173899710178375, 0.16762158274650574, 0.1701526939868927, 0.17028243839740753, 0.16970011591911316, 0.1697867512702942, 0.16753020882606506, 0.16874699294567108, 0.16641965508460999, 0.163031667470932, 0.16528938710689545, 0.16622117161750793, 0.16662411391735077, 0.16220813989639282, 0.16596561670303345, 0.1645495891571045, 0.16123482584953308, 0.1624976396560669, 0.160406231880188, 0.16142696142196655, 0.1595362275838852, 0.16027618944644928, 0.1604638248682022, 0.15875715017318726, 0.15963633358478546, 0.1591106504201889, 0.15769901871681213, 0.1592479646205902, 0.15695539116859436, 0.15467512607574463, 0.15575812757015228, 0.15511968731880188, 0.15256267786026, 0.15333639085292816, 0.15243445336818695, 0.15369130671024323, 0.154913991689682, 0.15099425613880157, 0.14835070073604584, 0.1490519940853119, 0.15017077326774597, 0.15048910677433014, 0.14694109559059143, 0.14749860763549805, 0.14650572836399078, 0.1464841067790985, 0.14570951461791992, 0.14477720856666565, 0.14639349281787872, 0.14542147517204285, 0.14267116785049438, 0.1421014815568924, 0.14005720615386963, 0.13963209092617035, 0.14109587669372559, 0.14130091667175293, 0.13874411582946777, 0.1377934366464615, 0.13785557448863983, 0.13630127906799316, 0.13164500892162323, 0.12824922800064087, 0.1270221620798111, 0.12693387269973755, 0.12874077260494232, 0.12737858295440674, 0.12535519897937775, 0.1295773833990097, 0.12763845920562744, 0.12694880366325378, 0.12738943099975586, 0.12489280849695206, 0.1274345964193344, 0.12997347116470337, 0.1262003630399704, 0.12639383971691132, 0.12711770832538605, 0.12633444368839264, 0.1274803876876831, 0.1269044429063797, 0.12523464858531952, 0.12627209722995758, 0.1239704117178917, 0.1271364986896515, 0.12644685804843903, 0.12480627000331879, 0.12668636441230774, 0.12437169998884201, 0.12423275411128998, 0.12614496052265167, 0.12438112497329712, 0.1259857416152954, 0.12501341104507446, 0.1260438859462738, 0.12591806054115295, 0.12674088776111603, 0.12965188920497894, 0.125722274184227, 0.12711060047149658, 0.12480733543634415, 0.1269427388906479, 0.12524880468845367, 0.12552812695503235, 0.12556785345077515, 0.12625475227832794, 0.12651240825653076, 0.12437368929386139, 0.12609469890594482, 0.12446150183677673, 0.12591302394866943, 0.12605661153793335, 0.12384919077157974, 0.12649299204349518, 0.12589873373508453, 0.12482935935258865, 0.1274157464504242, 0.12590478360652924, 0.12659773230552673, 0.12675735354423523, 0.12350144982337952, 0.12572205066680908, 0.12421275675296783, 0.12776228785514832, 0.12606953084468842, 0.12715809047222137, 0.12313804030418396, 0.12789130210876465, 0.12566983699798584, 0.12608106434345245, 0.12478069961071014, 0.12605825066566467, 0.12662705779075623, 0.12694232165813446, 0.12623924016952515, 0.12665407359600067, 0.1231459230184555, 0.1253756582736969, 0.12660963833332062, 0.12476103007793427, 0.12428231537342072, 0.1263149529695511, 0.1256324052810669, 0.12390898913145065, 0.12790735065937042, 0.12366288900375366, 0.12687468528747559]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:38 2016", "state": "available"}], "summary": "d217e17cd00ccb4fc15654e36086977c"}