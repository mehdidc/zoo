{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 64, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4714086055755615, 1.0296040773391724, 0.7764608263969421, 0.6485125422477722, 0.5625464916229248, 0.4935110807418823, 0.43409761786460876, 0.38128241896629333, 0.3336247205734253, 0.29054224491119385, 0.25142624974250793, 0.21601083874702454, 0.18422800302505493, 0.15583090484142303, 0.13044637441635132, 0.1081041768193245, 0.08874422311782837, 0.0722503587603569, 0.05849112942814827, 0.04719070345163345, 0.03810027241706848, 0.030985897406935692, 0.02544853277504444, 0.021248770877718925, 0.018100550398230553, 0.015746694058179855, 0.013973811641335487, 0.012613336555659771, 0.011554060503840446, 0.010714536532759666, 0.010037792846560478, 0.009484921582043171, 0.009026230312883854, 0.008641015738248825, 0.008314838632941246, 0.008034948259592056, 0.0077934847213327885, 0.007582369726151228, 0.007397156208753586, 0.007232929579913616, 0.007086960133165121, 0.0069563682191073895, 0.006838936824351549, 0.00673277024179697, 0.0066368659026920795, 0.006549319718033075, 0.006469441577792168, 0.0063959211111068726, 0.006328216288238764, 0.006265787873417139, 0.0062080309726297855, 0.006154252216219902, 0.006104277912527323, 0.0060577248223125935, 0.006014298181980848, 0.005973507184535265, 0.005935200490057468, 0.005899261683225632, 0.005865377839654684, 0.0058333901688456535, 0.005803153850138187, 0.005774577613919973, 0.005747456103563309, 0.005721760913729668, 0.005697297398000956, 0.0056739985011518, 0.005651857703924179, 0.005630678031593561, 0.0056104641407728195, 0.005591162014752626, 0.005572681315243244, 0.0055549838580191135, 0.005538003519177437, 0.005521721206605434, 0.005506112240254879, 0.0054911058396101, 0.005476673599332571, 0.00546278664842248, 0.005449368618428707, 0.005436442792415619, 0.005423994269222021, 0.005411984398961067, 0.005400368012487888, 0.00538914930075407, 0.005378318019211292, 0.005367843434214592, 0.005357680376619101, 0.005347844213247299, 0.0053383116610348225, 0.0053290268406271935, 0.005320045165717602, 0.005311303306370974, 0.005302812438458204, 0.005294577684253454], "moving_avg_accuracy_train": [0.03260165045911775, 0.08026610156538388, 0.1418147750409514, 0.2021437906270187, 0.2599595671221795, 0.3144044766486566, 0.36544143718907884, 0.41339017310749104, 0.45840830009583755, 0.5007356890150559, 0.5403739134125075, 0.5775060755273291, 0.6120154441246978, 0.644089749599179, 0.6738075208440414, 0.7012742389977326, 0.7266290509610546, 0.7500738467578063, 0.7717112723498828, 0.7916685863351326, 0.8100556711540002, 0.8269132922826479, 0.8424083469829545, 0.8566422146656114, 0.8697526397764311, 0.8817845372571214, 0.8927946065968855, 0.9028571288241017, 0.9120482574595487, 0.9204179294814508, 0.9280366648071152, 0.9349493301716418, 0.9411986307854301, 0.9468695043140299, 0.9519965419778651, 0.9566387776610309, 0.9608307406687373, 0.9646081576732922, 0.9680124832750105, 0.9710880020606047, 0.9738606192652586, 0.9763629501958755, 0.9786196983310499, 0.9806507716527068, 0.982488038237436, 0.9841415781636924, 0.9856297640973232, 0.9869691314375908, 0.9881792123414508, 0.9892706103037343, 0.9902528684697894, 0.9911462014144771, 0.9919525262135056, 0.9926805436814408, 0.9933357594025825, 0.9939254535516099, 0.9944585034345441, 0.9949382483291849, 0.9953700187343616, 0.9957586120990206, 0.9961060209784043, 0.9964256644162781, 0.9967133435103646, 0.9969722546950424, 0.9972052747612524, 0.9974149928208415, 0.9976037390744716, 0.9977736107027387, 0.9979264951681791, 0.998066416335885, 0.9981946705356299, 0.9983100993154004, 0.9984186355148127, 0.9985209683919029, 0.998613067981284, 0.9986982827605365, 0.9987773012106733, 0.9988484178157965, 0.9989100976115978, 0.998965609427819, 0.999015570062418, 0.9990605346335572, 0.9991010027475824, 0.9991397491990146, 0.9991746210053036, 0.9992083307797733, 0.9992386695767961, 0.9992659744941165, 0.9992905489197048, 0.9993126659027344, 0.999332571187461, 0.9993504859437149, 0.9993666092243434, 0.9993834453257185], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.03170592526355421, 0.07721682628953311, 0.13503425322383278, 0.1903984860339796, 0.2424115012295274, 0.29029140367622824, 0.3338279165465572, 0.3733800775933322, 0.40890981032722185, 0.44089877681897255, 0.46991269125868673, 0.4964342233376373, 0.5200818166288735, 0.5411571310597362, 0.5600709383792144, 0.5773161800552237, 0.5924787756227434, 0.6062726255171709, 0.6187847466721557, 0.6298737277654822, 0.6399270529369762, 0.6490249032249804, 0.6571864954043649, 0.6646804717581303, 0.6715491798063383, 0.6778164662684756, 0.6836279225218992, 0.6888592626586401, 0.6934209844067067, 0.6975021199174668, 0.7012727981271508, 0.7046053733596165, 0.7076270461140164, 0.7102977234679761, 0.71271354011779, 0.714949839767532, 0.7170113375773, 0.718903306699841, 0.720679321097628, 0.7222777340556362, 0.723703069177934, 0.7249980778192522, 0.726225650261348, 0.727404737155394, 0.7284292942662853, 0.7293147745723375, 0.7300618492141249, 0.7307840740253931, 0.7313974552617845, 0.7319494983745367, 0.7324341301447638, 0.7328957423091278, 0.7333234002883053, 0.7337082924695653, 0.7340546954326992, 0.73431660046586, 0.7345645220269548, 0.73473882330694, 0.7348712803964267, 0.7349782847457147, 0.7350491450889143, 0.735076298304044, 0.7351617713539107, 0.7352264900675407, 0.7352847369098077, 0.735337159067848, 0.7353721319788342, 0.7353914005674719, 0.7353965352659957, 0.7354133635259172, 0.7354163019285965, 0.7353812958885984, 0.7353253763901, 0.7352750488414515, 0.7352053399851677, 0.7351181879520123, 0.7350519581534226, 0.7349923513346919, 0.7349498827204246, 0.7348740103651743, 0.7348057252454491, 0.734794126271356, 0.7347836871946722, 0.7347620849944068, 0.7347426430141679, 0.734725145231953, 0.7347093972279595, 0.7346830169931153, 0.7346470677505056, 0.7346147134321568, 0.7345855945456429, 0.7345715945790304, 0.7345467875778292, 0.7345366683079981], "moving_var_accuracy_train": [0.009565808513926435, 0.02905632675588852, 0.06024484693971796, 0.0869766733400017, 0.10836298211164702, 0.12420491746059883, 0.13522736778538053, 0.14239636249240512, 0.1463964120610146, 0.1478812415293821, 0.1472338168768884, 0.14491961235909212, 0.14114571981208435, 0.13628999747590886, 0.13060931107817575, 0.12433816542556692, 0.11769014729026896, 0.11086805861080454, 0.10399485642599791, 0.09718002021695075, 0.09050478218848179, 0.08401191848068684, 0.07777159711410761, 0.07181786430556332, 0.06618302709428471, 0.060867623397728804, 0.055871855699753635, 0.05119595931193726, 0.04683665499108353, 0.0427834521797631, 0.03902751311344954, 0.035554826284081915, 0.03235082747912717, 0.029405173990410823, 0.026701235228227194, 0.024225064874647, 0.021960711371904116, 0.019893060147750403, 0.018008059028198003, 0.016292382467583088, 0.01473233087629666, 0.013315452729443896, 0.012029743665810022, 0.010863896628770539, 0.009807886902423752, 0.008851705960770893, 0.007986467641051312, 0.007203966020795763, 0.006496748080861165, 0.0058577936183837375, 0.005280697736488402, 0.004759810356590142, 0.004289680758064882, 0.0038654827671609623, 0.0034827982592159465, 0.003137648085998927, 0.0028264405569983003, 0.0025458678977738755, 0.0022929589391415665, 0.002065022088454923, 0.0018596061159747025, 0.0016745650517236148, 0.001507853379901823, 0.0013576713569256023, 0.001222392906394351, 0.001100549450735576, 0.000990815131996353, 0.000891993326127529, 0.0008030043564527331, 0.0007228801222060095, 0.0006507401522431783, 0.0005857860512476538, 0.0005273134670821343, 0.0004746763685335228, 0.0004272850726894481, 0.00038462191944793085, 0.000346215922742296, 0.0003116398486117846, 0.00028051010332549696, 0.00025248682704860886, 0.00022726060892883383, 0.00020455274434987, 0.00018411220892915783, 0.00016571449962372937, 0.00014915399404722115, 0.0001342488217825522, 0.00012083222358774001, 0.00010875571125555487, 9.788557525153638e-05, 8.81014201748277e-05, 7.929484414058534e-05, 7.136824817295153e-05, 6.423376299726042e-05, 5.7812937786320016e-05], "duration": 17969.10549, "accuracy_train": [0.32601650459117754, 0.5092461615217793, 0.6957528363210594, 0.7451049309016242, 0.7803015555786268, 0.8044086623869509, 0.8247740820528792, 0.8449287963732004, 0.863571442990956, 0.8816821892880213, 0.8971179329895718, 0.9116955345607235, 0.9225997615010151, 0.9327584988695091, 0.9412674620478036, 0.9484747023809523, 0.9548223586309523, 0.9610770089285714, 0.9664481026785714, 0.9712844122023809, 0.9755394345238095, 0.9786318824404762, 0.9818638392857143, 0.9847470238095238, 0.9877464657738095, 0.9900716145833334, 0.9918852306547619, 0.9934198288690477, 0.9947684151785714, 0.9957449776785714, 0.9966052827380952, 0.9971633184523809, 0.9974423363095238, 0.9979073660714286, 0.9981398809523809, 0.9984188988095238, 0.9985584077380952, 0.9986049107142857, 0.9986514136904762, 0.9987676711309523, 0.9988141741071429, 0.9988839285714286, 0.9989304315476191, 0.9989304315476191, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990234375, 0.9990699404761905, 0.9990931919642857, 0.9990931919642857, 0.9991861979166666, 0.9992094494047619, 0.9992327008928571, 0.9992327008928571, 0.9992327008928571, 0.9992559523809523, 0.9992559523809523, 0.9992559523809523, 0.9992559523809523, 0.9992327008928571, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993024553571429, 0.9993257068452381, 0.9993489583333334, 0.9993489583333334, 0.9993954613095238, 0.9994419642857143, 0.9994419642857143, 0.9994652157738095, 0.9994884672619048, 0.9994884672619048, 0.9994652157738095, 0.9994652157738095, 0.9994652157738095, 0.9994652157738095, 0.9994652157738095, 0.9994884672619048, 0.9994884672619048, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.99951171875, 0.9995349702380952], "end": "2016-02-01 14:46:52.460000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0], "moving_var_accuracy_valid": [0.009047391271362767, 0.026783831153994526, 0.05419114175432284, 0.07635881205079581, 0.09307111459330683, 0.1043963686587265, 0.11101558336902873, 0.1139933860233561, 0.11395530459429516, 0.11176941992975879, 0.10816874301681842, 0.10368239368946984, 0.09834703233673235, 0.09250984900829666, 0.08647845307333211, 0.0805071930101746, 0.07452561244825469, 0.06878548385761919, 0.06331591405403042, 0.058091012163820774, 0.05319153507047284, 0.048617319482191994, 0.04435509181609611, 0.040425019768803645, 0.03680713014418694, 0.03347992704615465, 0.03043589155560828, 0.027638604676683932, 0.025062027956776603, 0.022705726164613624, 0.020563115675601134, 0.018606758627161414, 0.016828257320557413, 0.015209624246262255, 0.013741187352405688, 0.01241207794227605, 0.011209118107025543, 0.010120422220768829, 0.009136768042962266, 0.008246085554524999, 0.007439761220970201, 0.0067108785253029764, 0.006053353079678018, 0.005460529984843613, 0.004923924441820554, 0.004438588675990155, 0.003999752893074754, 0.003604472081869382, 0.0032474110025528576, 0.0029254126666826068, 0.0026349852115887668, 0.0023734044625424895, 0.002137710038412629, 0.001925272312492121, 0.0017338250363587199, 0.0015610598809404027, 0.0014055070787504632, 0.0012652297993012574, 0.0011388647232961292, 0.0010250813003434155, 0.0009226183610032192, 0.0008303631605767242, 0.0007473925952993334, 0.0006726910323764454, 0.0006054524633905075, 0.0005449319497953392, 0.000490449762756331, 0.0004414081279872707, 0.00039726755247470404, 0.00035754334594022155, 0.0003217890890540922, 0.00028962120895421016, 0.0002606872309716, 0.00023464130363381674, 0.0002112209071922345, 0.00019016717576495902, 0.0001711899356644543, 0.00015410291885356177, 0.00013870885921698573, 0.0001248897828239082, 0.00011244277025970043, 0.0001011997040595305, 9.108071442247554e-05, 8.197684287573475e-05, 7.378256050352176e-05, 6.640706000461158e-05, 5.9768586000818434e-05, 5.3797990651850476e-05, 4.842982271906334e-05, 4.359626166439931e-05, 3.924426668392565e-05, 3.5321604007119436e-05, 3.179498209218487e-05, 2.861640547956362e-05], "accuracy_test": 0.717432637117347, "start": "2016-02-01 09:47:23.354000", "learning_rate_per_epoch": [0.0009117136942222714, 0.0004558568471111357, 0.00030390455503948033, 0.00022792842355556786, 0.00018234273011330515, 0.00015195227751974016, 0.0001302448072237894, 0.00011396421177778393, 0.00010130152077181265, 9.117136505665258e-05, 8.288305980386212e-05, 7.597613875987008e-05, 7.013182039372623e-05, 6.51224036118947e-05, 6.078091246308759e-05, 5.6982105888891965e-05, 5.363021409721114e-05, 5.0650760385906324e-05, 4.798492955160327e-05, 4.558568252832629e-05, 4.3414936953922734e-05, 4.144152990193106e-05, 3.963972631026991e-05, 3.798806937993504e-05, 3.646854747785255e-05, 3.5065910196863115e-05, 3.3767173590604216e-05, 3.256120180594735e-05, 3.143840149277821e-05, 3.0390456231543794e-05, 2.941011916846037e-05, 2.8491052944445983e-05, 2.7627687813946977e-05, 2.681510704860557e-05, 2.604896144475788e-05, 2.5325380192953162e-05, 2.4640910851303488e-05, 2.3992464775801636e-05, 2.337727346457541e-05, 2.2792841264163144e-05, 2.2236918084672652e-05, 2.1707468476961367e-05, 2.1202644347795285e-05, 2.072076495096553e-05, 2.026030415436253e-05, 1.9819863155134954e-05, 1.939816320373211e-05, 1.899403468996752e-05, 1.8606400772114284e-05, 1.8234273738926277e-05, 1.7876738638733514e-05, 1.7532955098431557e-05, 1.720214459055569e-05, 1.6883586795302108e-05, 1.6576612324570306e-05, 1.6280600902973674e-05, 1.599497591087129e-05, 1.5719200746389106e-05, 1.5452773368451744e-05, 1.5195228115771897e-05, 1.4946125702408608e-05, 1.4705059584230185e-05, 1.4471645954472478e-05, 1.4245526472222991e-05, 1.4026363714947365e-05, 1.3813843906973489e-05, 1.3607666915049776e-05, 1.3407553524302784e-05, 1.3213241800258402e-05, 1.302448072237894e-05, 1.2841037460020743e-05, 1.2662690096476581e-05, 1.2489228538470343e-05, 1.2320455425651744e-05, 1.2156182492617518e-05, 1.1996232387900818e-05, 1.1840436854981817e-05, 1.1688636732287705e-05, 1.1540679224708583e-05, 1.1396420632081572e-05, 1.1255724530201405e-05, 1.1118459042336326e-05, 1.0984502296196297e-05, 1.0853734238480683e-05, 1.0726043001341168e-05, 1.0601322173897643e-05, 1.0479467164259404e-05, 1.0360382475482766e-05, 1.0243973520118743e-05, 1.0130152077181265e-05, 1.0018831744673662e-05, 9.909931577567477e-06, 9.803372449823655e-06, 9.699081601866055e-06], "accuracy_train_first": 0.32601650459117754, "accuracy_train_last": 0.9995349702380952, "batch_size_eval": 1024, "accuracy_train_std": [0.01529583677123899, 0.018089353233967063, 0.02129143372163465, 0.021688080506601683, 0.022596153049431193, 0.02332079538795464, 0.023092411997874988, 0.023703845999666337, 0.025720927702647958, 0.02588269988935612, 0.024920390016695753, 0.024010946774912785, 0.022021780111442547, 0.02164981381981547, 0.020386003534392072, 0.01980579171289531, 0.018563324670434214, 0.01712080187657855, 0.015475799918923323, 0.01395959007794177, 0.012491481932194529, 0.01100778097461776, 0.01009071722537216, 0.009138515183156469, 0.007862338650461397, 0.006640203268441943, 0.005501569380506647, 0.004798658764728041, 0.0037206013820018377, 0.003086848504313559, 0.0025504667412206265, 0.0022432565281235747, 0.002065590803061087, 0.001764663872861819, 0.0016888969305556992, 0.001506150924544424, 0.001368483907139338, 0.0013669027582495412, 0.0013637349608087033, 0.0012972996869943566, 0.0012880988638824906, 0.0012162106427289826, 0.001182858755764221, 0.0011438219750975487, 0.0010655170421679315, 0.0010655170421679315, 0.00108661843801599, 0.00108661843801599, 0.0010429530083708057, 0.0010084285919922545, 0.0010084285919922545, 0.0009020258901260613, 0.0008847794638411667, 0.0008665664598950997, 0.0008665664598950997, 0.0008665664598950997, 0.0008473245516317242, 0.0008473245516317242, 0.0008473245516317242, 0.0008473245516317242, 0.0008399549789894178, 0.000859990792824913, 0.000859990792824913, 0.000859990792824913, 0.0008860006921157761, 0.0008860006921157761, 0.0008860006921157761, 0.0008860006921157761, 0.0008860006921157761, 0.0008653178044051523, 0.0008699910218503398, 0.0008699910218503398, 0.000824034837549728, 0.0008014177799299704, 0.0008014177799299704, 0.0007743129559778047, 0.000775359561036694, 0.000775359561036694, 0.0007743129559778047, 0.0007743129559778047, 0.0007743129559778047, 0.0007743129559778047, 0.0007743129559778047, 0.0007454994206604074, 0.0007454994206604074, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007458619295175521, 0.0007454994206604074], "accuracy_test_std": 0.008986917817719839, "error_valid": [0.6829407473644579, 0.5131850644766567, 0.3446089043674698, 0.3113234186746988, 0.28947136201054224, 0.2787894743034638, 0.2743434676204819, 0.2706504729856928, 0.2713225950677711, 0.2712005247552711, 0.26896207878388556, 0.2648719879518072, 0.26708984375, 0.2691650390625, 0.2697047957454819, 0.2674766448606928, 0.27105786426957834, 0.2695827254329819, 0.2686061629329819, 0.27032544239457834, 0.26959302051957834, 0.2690944441829819, 0.2693591749811747, 0.2678737410579819, 0.2666324477597892, 0.2657779555722892, 0.2640689711972892, 0.2640586761106928, 0.2655235198606928, 0.2657676604856928, 0.2647910979856928, 0.2654014495481928, 0.26517789909638556, 0.26566618034638556, 0.26554411003388556, 0.2649234633847892, 0.2644351821347892, 0.2640689711972892, 0.2633365493222892, 0.2633365493222892, 0.26346891472138556, 0.26334684440888556, 0.2627261977597892, 0.2619834807981928, 0.2623496917356928, 0.2627159026731928, 0.2632144790097892, 0.2627159026731928, 0.2630821136106928, 0.2630821136106928, 0.2632041839231928, 0.26294974821159633, 0.26282767789909633, 0.26282767789909633, 0.26282767789909633, 0.2633262542356928, 0.2632041839231928, 0.2636924651731928, 0.2639366057981928, 0.2640586761106928, 0.2643131118222892, 0.2646793227597892, 0.2640689711972892, 0.2641910415097892, 0.2641910415097892, 0.2641910415097892, 0.2643131118222892, 0.2644351821347892, 0.2645572524472892, 0.2644351821347892, 0.2645572524472892, 0.26493375847138556, 0.26517789909638556, 0.26517789909638556, 0.26542203972138556, 0.26566618034638556, 0.26554411003388556, 0.26554411003388556, 0.2654323348079819, 0.26580884083207834, 0.26580884083207834, 0.2653102644954819, 0.2653102644954819, 0.2654323348079819, 0.2654323348079819, 0.2654323348079819, 0.2654323348079819, 0.2655544051204819, 0.2656764754329819, 0.2656764754329819, 0.2656764754329819, 0.2655544051204819, 0.2656764754329819, 0.2655544051204819], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.034232127911066924, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.0009117136702367521, "optimization": "rmsprop", "nb_data_augmentation": 0, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 8.954123179174325e-07, "rotation_range": [0, 0], "momentum": 0.8689078120229967}, "accuracy_valid_max": 0.7380165192018072, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7344455948795181, "accuracy_valid_std": [0.015610756918571058, 0.017484854520555503, 0.014680536232264112, 0.017028424585402095, 0.016843965487527382, 0.017460925162774896, 0.016575340759849254, 0.017926631110559567, 0.01370207349831415, 0.014416615062916967, 0.015179967022360968, 0.01796945842327821, 0.0180993681570807, 0.017986637003053862, 0.013951128873866995, 0.013561979286742631, 0.01251887748148262, 0.012553381066888976, 0.012404564357523582, 0.01153905254256523, 0.01156618604132746, 0.011072042000467588, 0.012085729657238701, 0.012839636691126545, 0.013345396616727824, 0.01422452030480405, 0.013554581671711783, 0.013088645511631924, 0.012204924473758153, 0.011685562096080583, 0.010774441000842594, 0.010462419891354139, 0.00977622796743239, 0.010308406964645914, 0.009731141027476945, 0.010162781963020727, 0.010327156371520388, 0.010013999281483802, 0.009799688222872157, 0.009775328746763259, 0.009816875139309681, 0.009819663679570819, 0.009741375635110596, 0.009688516754352007, 0.00992103485996367, 0.009566222575635927, 0.009159529640715272, 0.009466005796205386, 0.009663849188856825, 0.009502133424481493, 0.009439720386991465, 0.00993371757179513, 0.010330197681000654, 0.010444959067395475, 0.010167355802819602, 0.010026588887678167, 0.010227684421519069, 0.010133018918484402, 0.010396732240536881, 0.010557915418048694, 0.010236945536595932, 0.010636352020739783, 0.010284153291783142, 0.01009734977495752, 0.010502434134351396, 0.010502434134351396, 0.010891433859098718, 0.010690161516697683, 0.010630400472464753, 0.010723563259961159, 0.010896213108388453, 0.010716671177407048, 0.010982193955529618, 0.010982193955529618, 0.011415079219359426, 0.01163401567813758, 0.01140092344521602, 0.01140092344521602, 0.011518797180691981, 0.011549666438711465, 0.011549666438711465, 0.011427781587253293, 0.011427781587253293, 0.011518797180691981, 0.011518797180691981, 0.011518797180691981, 0.011518797180691981, 0.011452733471314112, 0.011551294922355543, 0.011551294922355543, 0.011551294922355543, 0.011669271362261287, 0.011897001558068741, 0.012090718524899876], "accuracy_valid": [0.31705925263554213, 0.4868149355233434, 0.6553910956325302, 0.6886765813253012, 0.7105286379894578, 0.7212105256965362, 0.7256565323795181, 0.7293495270143072, 0.7286774049322289, 0.7287994752447289, 0.7310379212161144, 0.7351280120481928, 0.73291015625, 0.7308349609375, 0.7302952042545181, 0.7325233551393072, 0.7289421357304217, 0.7304172745670181, 0.7313938370670181, 0.7296745576054217, 0.7304069794804217, 0.7309055558170181, 0.7306408250188253, 0.7321262589420181, 0.7333675522402108, 0.7342220444277108, 0.7359310288027108, 0.7359413238893072, 0.7344764801393072, 0.7342323395143072, 0.7352089020143072, 0.7345985504518072, 0.7348221009036144, 0.7343338196536144, 0.7344558899661144, 0.7350765366152108, 0.7355648178652108, 0.7359310288027108, 0.7366634506777108, 0.7366634506777108, 0.7365310852786144, 0.7366531555911144, 0.7372738022402108, 0.7380165192018072, 0.7376503082643072, 0.7372840973268072, 0.7367855209902108, 0.7372840973268072, 0.7369178863893072, 0.7369178863893072, 0.7367958160768072, 0.7370502517884037, 0.7371723221009037, 0.7371723221009037, 0.7371723221009037, 0.7366737457643072, 0.7367958160768072, 0.7363075348268072, 0.7360633942018072, 0.7359413238893072, 0.7356868881777108, 0.7353206772402108, 0.7359310288027108, 0.7358089584902108, 0.7358089584902108, 0.7358089584902108, 0.7356868881777108, 0.7355648178652108, 0.7354427475527108, 0.7355648178652108, 0.7354427475527108, 0.7350662415286144, 0.7348221009036144, 0.7348221009036144, 0.7345779602786144, 0.7343338196536144, 0.7344558899661144, 0.7344558899661144, 0.7345676651920181, 0.7341911591679217, 0.7341911591679217, 0.7346897355045181, 0.7346897355045181, 0.7345676651920181, 0.7345676651920181, 0.7345676651920181, 0.7345676651920181, 0.7344455948795181, 0.7343235245670181, 0.7343235245670181, 0.7343235245670181, 0.7344455948795181, 0.7343235245670181, 0.7344455948795181], "seed": 718013790, "model": "residualv3", "loss_std": [0.3489639461040497, 0.13784953951835632, 0.10918699204921722, 0.09307660162448883, 0.0886300578713417, 0.08396590501070023, 0.07929438352584839, 0.07449550181627274, 0.06950657069683075, 0.06435465812683105, 0.05891247093677521, 0.053568821400403976, 0.048224691301584244, 0.04304090887308121, 0.03806036710739136, 0.0332215391099453, 0.02843778021633625, 0.023896876722574234, 0.01952827163040638, 0.015469872392714024, 0.011879517696797848, 0.008949575014412403, 0.006568334065377712, 0.0048037199303507805, 0.0035659796558320522, 0.002725288737565279, 0.002165260724723339, 0.0017681267345324159, 0.00147904921323061, 0.001262293546460569, 0.0010955121833831072, 0.0009646365651860833, 0.000860002008266747, 0.0007751178345642984, 0.0007048616535030305, 0.0006462761666625738, 0.0005969402263872325, 0.0005543426377698779, 0.0005178635474294424, 0.00048552805674262345, 0.0004573280457407236, 0.000432367465691641, 0.00041023013181984425, 0.00039019863470457494, 0.0003724793205037713, 0.0003563881909940392, 0.0003417023690417409, 0.00032820829073898494, 0.00031583927921019495, 0.0003045452758669853, 0.00029400730272755027, 0.0002841477980837226, 0.00027511751977726817, 0.00026669297949410975, 0.00025886850198730826, 0.0002514733059797436, 0.00024457304971292615, 0.00023809545382391661, 0.00023201598378363997, 0.0002263225760543719, 0.00022093307052273303, 0.00021586232469417155, 0.00021103520703036338, 0.00020644013420678675, 0.00020212255185469985, 0.0001980206579901278, 0.0001941294758580625, 0.00019040128972847015, 0.00018683202506508678, 0.00018342763360124081, 0.0001801617763703689, 0.00017704132187645882, 0.0001740243606036529, 0.00017115016817115247, 0.00016841839533299208, 0.00016576946654822677, 0.0001632290513953194, 0.0001607821905054152, 0.00015843209985177964, 0.0001561655808473006, 0.00015397679817397147, 0.00015186578093562275, 0.0001498417550465092, 0.00014788711268920451, 0.0001459935010643676, 0.00014417050988413393, 0.00014240625023376197, 0.00014070459292270243, 0.0001390553079545498, 0.00013744199532084167, 0.0001358888257527724, 0.00013437814777716994, 0.0001329087681369856, 0.00013149797450751066]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:28 2016", "state": "available"}], "summary": "021fe3e19beec91046f973ae39bcfd63"}