{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.6338485479354858, 1.206669569015503, 0.95846027135849, 0.8344441652297974, 0.7559693455696106, 0.6960597038269043, 0.6517601013183594, 0.6121065616607666, 0.5829755663871765, 0.5565304756164551, 0.5326616168022156, 0.5086371898651123, 0.4913129210472107, 0.47342920303344727, 0.45942869782447815, 0.44298097491264343, 0.42962464690208435, 0.4182630181312561, 0.4073282778263092, 0.3968152701854706, 0.38565176725387573, 0.37570762634277344, 0.3678600490093231, 0.35866284370422363, 0.35206931829452515, 0.34230726957321167, 0.3372045159339905, 0.32797059416770935, 0.3213762044906616, 0.3151043653488159, 0.3093782663345337, 0.3045642673969269, 0.300235778093338, 0.29585760831832886, 0.2889742851257324, 0.2838074564933777, 0.2805444300174713, 0.2752738296985626, 0.27000775933265686, 0.2681560516357422, 0.26505789160728455, 0.2604018747806549, 0.25630906224250793, 0.25119748711586, 0.2468533217906952, 0.24721741676330566, 0.24444003403186798, 0.24013479053974152, 0.23646526038646698, 0.23437274992465973, 0.23190318048000336, 0.22985652089118958, 0.22585001587867737, 0.22197553515434265, 0.22066503763198853, 0.2217027097940445, 0.21649640798568726, 0.21399955451488495, 0.2106054276227951, 0.21125948429107666, 0.20873956382274628, 0.20731402933597565, 0.20276673138141632, 0.20479772984981537, 0.2012096792459488, 0.19888341426849365, 0.19820332527160645, 0.19573643803596497, 0.19786375761032104, 0.19322063028812408, 0.19138184189796448, 0.192216694355011, 0.18914151191711426, 0.18897993862628937, 0.18739880621433258, 0.18565107882022858, 0.18336151540279388, 0.1841520071029663, 0.18055538833141327, 0.18014270067214966, 0.17867381870746613, 0.17792756855487823, 0.17603729665279388, 0.17628203332424164, 0.17265531420707703, 0.17477944493293762, 0.17291653156280518, 0.17294305562973022, 0.17047321796417236, 0.1705353707075119, 0.1698719710111618, 0.1691979467868805, 0.16498921811580658, 0.166646808385849, 0.16326165199279785, 0.16242465376853943, 0.16305145621299744, 0.16293802857398987, 0.16253404319286346, 0.16148333251476288, 0.15901978313922882, 0.1581331044435501, 0.1577364057302475, 0.1583714634180069, 0.15655341744422913, 0.1552237868309021, 0.15570005774497986, 0.15380960702896118, 0.15260441601276398, 0.1545928418636322, 0.1537759155035019, 0.14957304298877716, 0.1508832722902298, 0.1483963280916214, 0.14986206591129303, 0.14915837347507477, 0.14777405560016632, 0.14505675435066223, 0.14519518613815308, 0.14796212315559387, 0.14437399804592133, 0.14593103528022766, 0.14402343332767487, 0.14598239958286285, 0.14307360351085663, 0.14571920037269592, 0.1446189284324646, 0.14522050321102142, 0.14111199975013733, 0.1386600136756897, 0.14110416173934937, 0.140196293592453, 0.14203950762748718, 0.13919666409492493, 0.1378127932548523, 0.13887053728103638, 0.1358129233121872, 0.13462892174720764, 0.14018750190734863, 0.13782639801502228, 0.1363547295331955, 0.1356665939092636, 0.133271723985672, 0.13556817173957825, 0.13217271864414215, 0.13196268677711487, 0.13254083693027496, 0.13288889825344086, 0.13194261491298676, 0.1335035264492035, 0.1295466125011444, 0.13024629652500153, 0.13155265152454376, 0.12971694767475128, 0.12918704748153687, 0.13003292679786682, 0.12971153855323792, 0.12706799805164337, 0.1280006319284439, 0.12663288414478302, 0.12753157317638397, 0.12683002650737762, 0.12746860086917877, 0.1265314221382141, 0.1259204000234604, 0.12686671316623688, 0.12444743514060974, 0.1257363110780716, 0.12476757168769836, 0.12429211288690567, 0.12479986995458603, 0.12356963753700256, 0.12156400829553604, 0.12394382059574127, 0.12203633785247803, 0.12017741054296494, 0.1206056997179985, 0.12110700458288193, 0.12066587060689926, 0.12069064378738403, 0.119050532579422, 0.11971927434206009, 0.12060434371232986, 0.12089791893959045, 0.1196870505809784, 0.11883190274238586, 0.11796180158853531, 0.11854821443557739, 0.11910177022218704, 0.12038451433181763, 0.11844652891159058, 0.11574810743331909, 0.11698168516159058, 0.11843288689851761, 0.11488258838653564, 0.11753138154745102, 0.11538006365299225, 0.11644065380096436, 0.11296491324901581, 0.11628113687038422, 0.11341769993305206, 0.11400942504405975, 0.11364871263504028, 0.11318880319595337, 0.1144934743642807, 0.11360921710729599, 0.11305996775627136, 0.1135365217924118, 0.11261951178312302, 0.11230087280273438, 0.11028186976909637, 0.1097814217209816, 0.11161956191062927, 0.11180294305086136, 0.10938168317079544, 0.10820383578538895, 0.11191024631261826, 0.1119309663772583, 0.10924103111028671, 0.11011787503957748, 0.11151884496212006, 0.10875486582517624, 0.1108403280377388, 0.10784381628036499, 0.10884255915880203, 0.1067582294344902, 0.10739969462156296, 0.10878116637468338, 0.10740622133016586, 0.10881233960390091, 0.10814478993415833, 0.10516391694545746, 0.10816525667905807, 0.10561133176088333, 0.10643066465854645, 0.10491029173135757, 0.10730887949466705], "moving_avg_accuracy_train": [0.05255386054009781, 0.1085959219413298, 0.17003872454232416, 0.2300284238627318, 0.2867064845426269, 0.33942801262952327, 0.38846757340053184, 0.43384920551461303, 0.47575762862086673, 0.5140959160021816, 0.5493605541108044, 0.5817216519966047, 0.6116325043426253, 0.6389103443707105, 0.6639346226066738, 0.6869143831392419, 0.708014766501905, 0.7275698703472848, 0.7454439395141068, 0.7619072037737519, 0.776805485766947, 0.7907626386310515, 0.803451851246813, 0.8151602808092856, 0.8259095280548152, 0.8359719701828886, 0.8451979039612498, 0.8537638780307948, 0.8614036804731934, 0.8685909284165533, 0.8752803767513008, 0.8816052945025272, 0.8873629688405729, 0.8927168286102624, 0.89779339392084, 0.9022785252455796, 0.9066104373366548, 0.9104790394305549, 0.9143164569852845, 0.9179048832690373, 0.9211111793875009, 0.9240317591750797, 0.9268906149113185, 0.9295586998822114, 0.9318089498298522, 0.9341968258993771, 0.936225042672673, 0.9381991751948114, 0.9401108251933258, 0.9419289664419888, 0.943688418306234, 0.9452835146792835, 0.9466121085209712, 0.9478682968475378, 0.9491617349045707, 0.9504745665820723, 0.9515839994299097, 0.9527034327798773, 0.9537946281519911, 0.9547929439797415, 0.9556379498020977, 0.9566053572374472, 0.9574877578197657, 0.9582401017140996, 0.9591519431023057, 0.9598865698457388, 0.9606825925457811, 0.9613268973139052, 0.9620253902433212, 0.962651744779805, 0.9632177529626311, 0.9638317199259657, 0.9643400402679483, 0.9647743852340936, 0.965244386811967, 0.9657185415058627, 0.9662080236994071, 0.9666996748985879, 0.9670676841183082, 0.9673780021255897, 0.9677642091285623, 0.968077026345551, 0.9684793974812986, 0.9687159734677572, 0.9690499798377588, 0.969401558600476, 0.9698272614809693, 0.9701243275186421, 0.9703800612084998, 0.9706032821317621, 0.9708182039531926, 0.9711325773793943, 0.9713433257034242, 0.9715655512783844, 0.9717353273613248, 0.9720275987157239, 0.9722628492954251, 0.9724675633219089, 0.9726633235433356, 0.972869806774781, 0.9729975490116624, 0.9732124623748464, 0.973482650361245, 0.9736025506132804, 0.9737383626258265, 0.9740140532585465, 0.9741994679077749, 0.9744081216730144, 0.9744610514307775, 0.9746202593068028, 0.9748310838571579, 0.9750533059381734, 0.9751998634372872, 0.9754456614293373, 0.9756599402245727, 0.975750556690303, 0.9758227388165847, 0.9758854136302474, 0.9759744451435146, 0.9760753556494658, 0.9761546575072305, 0.9763282996780192, 0.9763264314638626, 0.9763596633520832, 0.9764919506967383, 0.9765993114652427, 0.9766890328081056, 0.9768279107369203, 0.9769458172799688, 0.9770798349544267, 0.9771772354221624, 0.9772625346454962, 0.9773672057322109, 0.9774357970245307, 0.9775093351757598, 0.9776056382999335, 0.9776365075402613, 0.9776201120291753, 0.9776542923406543, 0.9777431472924046, 0.9778718727763425, 0.9779924120583243, 0.9781101980073461, 0.9781185491114657, 0.978212059562307, 0.978168371832359, 0.9782662366551679, 0.9783776025326097, 0.9784290036973075, 0.9784287978181636, 0.9785913008459632, 0.9786259464281258, 0.9786477908080153, 0.9787326630630389, 0.978834588680646, 0.9788240512376921, 0.9789354752771289, 0.979054394151917, 0.9791636741903982, 0.9791365763357733, 0.9792097003213359, 0.9791779277559797, 0.9792468805507029, 0.9792415808481151, 0.9793321061681578, 0.9792904542157477, 0.9793179995276078, 0.9793520909035199, 0.9794431909620697, 0.9794694495409735, 0.9794907931619962, 0.9795773596387553, 0.9796041522428476, 0.9796515170746259, 0.9797104214648932, 0.9797773863089907, 0.9797958019901071, 0.9797797879709598, 0.9798467916108793, 0.9798489661665688, 0.9799392428726325, 0.9800576582402234, 0.9800643227698832, 0.9801470147084725, 0.9801586944841646, 0.9802063365656023, 0.9802190235531911, 0.9802327309420119, 0.9802985820633884, 0.980355486874999, 0.98033240459, 0.9803883243953965, 0.9804502419154821, 0.9805385558157114, 0.9805669211009269, 0.980634194389736, 0.9806250219341972, 0.9806098633754212, 0.9805892091772755, 0.9806798663441734, 0.9806894863277424, 0.9807282270522033, 0.9806656176983118, 0.9806719762000291, 0.9806334489265562, 0.9805755589411542, 0.9805350476495213, 0.980589268290623, 0.9806148874771569, 0.9806612322819512, 0.9807237607990957, 0.9806847774609727, 0.9807147966233287, 0.9807163093301818, 0.9806989614294173, 0.9807623673294342, 0.9807590148192206, 0.9807838632969238, 0.9808830289352085, 0.9809675916632269, 0.9810227717791578, 0.9811026608180193, 0.9810119086827843, 0.9810928479824645, 0.9810796988950431, 0.9810957665020781, 0.9811382012317613, 0.9812064752277251, 0.981254006980054, 0.9812433431833499, 0.9812360709151257, 0.9812783539987238, 0.9812768812442002, 0.9813081438972812, 0.9814083238493304, 0.9813798671680704, 0.9813100783275552], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.05291336243411143, 0.10903810064476654, 0.1695055667003953, 0.22809917889330755, 0.28310599669674785, 0.3337790072492116, 0.3805526207844561, 0.42387266461715506, 0.4632188260074727, 0.49932617204000856, 0.5321198702539294, 0.5618996648079791, 0.5894380198162625, 0.6141248830737176, 0.6360805352972193, 0.6563727312027384, 0.6746936541479767, 0.6915161926770796, 0.7068039912369319, 0.72064537063357, 0.7331067301251829, 0.7443422496954959, 0.754468483357347, 0.7639524226251514, 0.7724014892387657, 0.780004619682359, 0.7867700768594544, 0.7930695963760692, 0.7990952268645918, 0.8041409058441717, 0.8088539448719534, 0.8131292125647279, 0.8170776982642038, 0.8208022338312323, 0.824196084478606, 0.8271446577419653, 0.8297495455539887, 0.8320064363487405, 0.8344954752722249, 0.8363938134283608, 0.8380870222116542, 0.8395153128839375, 0.8411680149351523, 0.8426066186562454, 0.8441709462013889, 0.845554426929518, 0.8467639679997438, 0.8478128453432182, 0.8488188996172549, 0.8498006791773667, 0.8506058910506692, 0.8514913321602108, 0.8520440885337982, 0.8526259889801172, 0.8531486698731446, 0.8535723135691885, 0.8540665447028569, 0.85423868000102, 0.8548106998491861, 0.855077259052897, 0.8556874913083754, 0.8561553691541944, 0.8565133650418623, 0.856897626005673, 0.8571925737307834, 0.8574081690497232, 0.8578107538766786, 0.858226026380577, 0.8585356479518567, 0.8587400356698487, 0.8586777849737223, 0.8589788517794373, 0.8591999542709213, 0.8595841109993261, 0.8598698464073, 0.8601737773821574, 0.8603720140547098, 0.8604405637787568, 0.8606630089539684, 0.8607126072020204, 0.8607847482137461, 0.8609727749454589, 0.86113082148141, 0.860879349837787, 0.8611443951345054, 0.8610746715943228, 0.8612947411442279, 0.8613930884718232, 0.8616433809988878, 0.8617567219746768, 0.8621038989865464, 0.8623176725385695, 0.8624744771502999, 0.8625758916811282, 0.8628289446911028, 0.8629580066414202, 0.8630243047630463, 0.8630707365326, 0.8630504604602889, 0.863208257976007, 0.8632648265214032, 0.8632648510699407, 0.8636474091670129, 0.8637821329058085, 0.863902354762065, 0.864207925950015, 0.8644442599081009, 0.8643284001352879, 0.8645791597546657, 0.8646318859572865, 0.8648400899632144, 0.8650376215824802, 0.8650577381422292, 0.8652701260373437, 0.8654612751429467, 0.8655468306105797, 0.8656269190574284, 0.8657112056908421, 0.8657249989960049, 0.8657374129706513, 0.8658727148776525, 0.8659446289602939, 0.8661446584870808, 0.8661670231635986, 0.8662939261277357, 0.8660266323007302, 0.8659478477886541, 0.8661088753215357, 0.8661449663285388, 0.8662130398199319, 0.8663475481496857, 0.8666192080561027, 0.866579851727149, 0.8666176732185908, 0.8664675775834788, 0.8666509038330376, 0.8665086626590711, 0.8665759581025013, 0.8666243169703385, 0.8666546034114824, 0.8667337778594908, 0.8670237319165387, 0.8671992413491318, 0.867038787517306, 0.8672483829749128, 0.8674492259180089, 0.8676442506153645, 0.867858452954054, 0.8677795918453955, 0.8677330309101029, 0.8678996751082493, 0.8681340745966714, 0.8681395736223204, 0.8682167354242449, 0.8683095655998174, 0.8681611791640826, 0.8681497016844214, 0.8681383424440666, 0.8680335514037262, 0.8680989603823295, 0.8680703202270031, 0.8682642706497095, 0.8682068924363952, 0.8683892446554815, 0.8685004154930207, 0.8682973524828752, 0.8682732871799943, 0.8682272143449016, 0.8680605899548391, 0.8678272378023523, 0.867959017740114, 0.8679178987691899, 0.8679531043741987, 0.8680855341946855, 0.8679941129758946, 0.8680105196376425, 0.8680385221731253, 0.8680647539637194, 0.8682236694276638, 0.8681815288591445, 0.8681690459186366, 0.8682412014736103, 0.8682451063168366, 0.86811537284065, 0.8682661378909223, 0.8682298984900079, 0.8684811332739137, 0.8686970965654982, 0.868791748260605, 0.8687782490275415, 0.868669472976444, 0.8686224616727755, 0.8686248615898352, 0.8686565831209873, 0.8687085170528644, 0.8688264407617347, 0.8685673906708775, 0.8687747282227657, 0.8684821692747361, 0.8685138939888287, 0.8686380434641928, 0.8686430032367495, 0.868718650202231, 0.868724667806255, 0.8686802260162169, 0.8688020083374115, 0.8686532057529173, 0.8685569340292821, 0.8684061657957817, 0.8683966627327697, 0.86838502145008, 0.8684386679778883, 0.8685479850091657, 0.8685975422123154, 0.8684712452576502, 0.868566127038361, 0.8686148995472508, 0.8686058486456131, 0.8686353534365487, 0.8686130796233908, 0.8686306837939584, 0.8686210839763094, 0.8686511242514947, 0.8687493436693422, 0.8687421439127243, 0.8688089063192681, 0.868742804138019, 0.8688095005220333, 0.8689071778700559, 0.8686990302072973, 0.8688555532031339, 0.8689587732969771, 0.8689560741487553, 0.8690146800716056, 0.869100957969942, 0.8690830108457641, 0.8691370120955251], "moving_var_accuracy_train": [0.02485717431901245, 0.05063787070200633, 0.07955104555498854, 0.10398481722046596, 0.12249795856032424, 0.13526419841864845, 0.14338168526230458, 0.14757894953611436, 0.14862789792777795, 0.1469935266489908, 0.14348652629248085, 0.1385630395706019, 0.13275866740613074, 0.12617952567489793, 0.11919750361848629, 0.11203037780384524, 0.10483437562592286, 0.09779255684096287, 0.09088864229408959, 0.0842391296954268, 0.07781284598302299, 0.07178478042936852, 0.0660554474377037, 0.06068368859930778, 0.05565523658648672, 0.051000987602065465, 0.04666694952860327, 0.04266063778158401, 0.03891987323565552, 0.035492794709083945, 0.03234625370938485, 0.029471669599484388, 0.026822859963582843, 0.024398548297126055, 0.022190637105586497, 0.020152621022029287, 0.018306248081109585, 0.016610318012446976, 0.015081818172606405, 0.01368952758409112, 0.012413097838875477, 0.011248556131648454, 0.01019725802356924, 0.009241600317919457, 0.008363012909569228, 0.007578029187722994, 0.006857249238466006, 0.006206599107554086, 0.005618828848250059, 0.005086696701825862, 0.004605888069406639, 0.004168198254419817, 0.003767264883343371, 0.0034047404770152535, 0.0030793232673801563, 0.0027869026837632053, 0.0025192899865816307, 0.0022786391671486468, 0.0020614916164948846, 0.0018643121652728272, 0.0016843072623038877, 0.0015242994303872237, 0.001378877164437584, 0.0012460836400118986, 0.0011289583684659199, 0.0010209196196888325, 0.0009245305269707916, 0.0008358136319817581, 0.0007566233001355802, 0.0006844918501703852, 0.0006189259525205813, 0.0005604259561571192, 0.0005067088666720673, 0.0004577358799514029, 0.0004139504053050939, 0.00037457876883827335, 0.00033927722731461936, 0.00030752499269806025, 0.0002779913705004472, 0.0002510589088411904, 0.0002272954205993771, 0.00020544657004064053, 0.00018635903581452182, 0.0001682268460093892, 0.0001524082037052656, 0.0001382798519722835, 0.00012608287325719693, 0.00011426882000812443, 0.00010343053548846676, 9.353593016485854e-05, 8.459805965231635e-05, 7.702772954700021e-05, 6.972469029703306e-05, 6.319667912282766e-05, 5.713642647559233e-05, 5.219158672945361e-05, 4.7470513573755745e-05, 4.310063271013271e-05, 3.913546801775666e-05, 3.560563913979395e-05, 3.219193793756586e-05, 2.9388433926885154e-05, 2.71066044661444e-05, 2.4525328653473207e-05, 2.2238799912892258e-05, 2.0698967846329323e-05, 1.8938478391032806e-05, 1.74364580956671e-05, 1.5718026319412196e-05, 1.4374348017567203e-05, 1.3336936135102563e-05, 1.2447686401209987e-05, 1.139622966600698e-05, 1.0800356575469386e-05, 1.0133559536710039e-05, 9.194105677791993e-06, 8.321587444203637e-06, 7.524781890192132e-06, 6.843643194364824e-06, 6.250925246830376e-06, 5.6824317839518005e-06, 5.385553036842106e-06, 4.847029145175111e-06, 4.3722654562099605e-06, 4.092538384592018e-06, 3.787021557657619e-06, 3.480768676178037e-06, 3.306275520567142e-06, 3.100765544553206e-06, 2.9523356237018314e-06, 2.7424837213676823e-06, 2.5337189667430452e-06, 2.3789513976150452e-06, 2.1833991462923286e-06, 2.013729968838843e-06, 1.895825597485555e-06, 1.7148192277227335e-06, 1.5457566200043826e-06, 1.4016956012391042e-06, 1.3325828631702426e-06, 1.348456828788449e-06, 1.3443786124158941e-06, 1.334802519256897e-06, 1.2019499357913514e-06, 1.1604527819609988e-06, 1.061585063496937e-06, 1.0416242690377423e-06, 1.0490830700595257e-06, 9.679534806440672e-07, 8.711585140556572e-07, 1.0217077690468316e-06, 9.303398394126297e-07, 8.416004478661831e-07, 8.222701001345195e-07, 8.33542573842452e-07, 7.511876557942597e-07, 7.878067392944957e-07, 8.363013543927031e-07, 8.601503602475898e-07, 7.807439677502834e-07, 7.507936263562375e-07, 6.847997269044334e-07, 6.591101453152174e-07, 5.934519124113704e-07, 6.078602232896931e-07, 5.626881672168765e-07, 5.132480483444085e-07, 4.723832407142257e-07, 4.998379026528177e-07, 4.560597290819447e-07, 4.1455370759896317e-07, 4.4054213092530916e-07, 4.0294851053922434e-07, 3.828445050898352e-07, 3.757875993155932e-07, 3.7856745248918943e-07, 3.4376294303911147e-07, 3.1169468801844877e-07, 3.209306090787957e-07, 2.888801064029356e-07, 3.3334104868200767e-07, 4.2620673734908496e-07, 3.839858072144571e-07, 4.071288368620338e-07, 3.676437076177804e-07, 3.513072481694741e-07, 3.1762516023925445e-07, 2.875536767898861e-07, 2.978256407897865e-07, 2.971864949707291e-07, 2.7226297240062325e-07, 2.7317989688074577e-07, 2.803659208347113e-07, 3.225234335144528e-07, 2.975123948112121e-07, 3.084924138148404e-07, 2.7840037789884976e-07, 2.52628377246437e-07, 2.3120490263116067e-07, 2.820529095574064e-07, 2.5468051535647516e-07, 2.4272005740662387e-07, 2.537274324182799e-07, 2.2871856407325856e-07, 2.1920586487718528e-07, 2.2744653207808895e-07, 2.194723616182173e-07, 2.2398402674977603e-07, 2.0749270854270551e-07, 2.0607400607137064e-07, 2.206549445708175e-07, 2.1226675597460295e-07, 1.991504313541636e-07, 1.7925598275695993e-07, 1.6403893142970544e-07, 1.8381781169933506e-07, 1.6553718445199445e-07, 1.545404876043229e-07, 2.2759085319164598e-07, 2.6918946260179785e-07, 2.6967412308895697e-07, 3.001470375521724e-07, 3.442558842442547e-07, 3.6879082791434273e-07, 3.334678316230551e-07, 3.0244456042322967e-07, 2.8840646093055706e-07, 3.015178615612413e-07, 2.9169948272030716e-07, 2.635529834896121e-07, 2.3767365810678054e-07, 2.2999702472323482e-07, 2.0701684330389096e-07, 1.9511134027240995e-07, 2.65924411378544e-07, 2.466200146157427e-07, 2.6579235349808005e-07], "duration": 221476.082238, "accuracy_train": [0.5255386054009782, 0.6129744745524179, 0.7230239479512736, 0.7699357177464008, 0.7968090306616832, 0.8139217654115909, 0.8298236203396088, 0.8422838945413437, 0.8529334365771503, 0.8591405024340162, 0.8667422970884091, 0.8729715329688077, 0.8808301754568106, 0.8844109046234773, 0.8891531267303433, 0.8937322279323551, 0.8979182167658729, 0.9035658049557033, 0.906310562015504, 0.9100765821105574, 0.9108900237057033, 0.9163770144079919, 0.9176547647886674, 0.9205361468715393, 0.922652753264581, 0.9265339493355482, 0.9282313079665007, 0.9308576446567, 0.9301619024547803, 0.9332761599067922, 0.9354854117640274, 0.9385295542635659, 0.9391820378829827, 0.9409015665374677, 0.9434824817160392, 0.9426447071682356, 0.9455976461563308, 0.9452964582756552, 0.9488532149778516, 0.9502007198228128, 0.9499678444536729, 0.950316977263289, 0.9526203165374677, 0.9535714646202473, 0.9520611993586194, 0.9556877105251015, 0.9544789936323367, 0.9559663678940569, 0.9573156751799556, 0.9582922376799556, 0.9595234850844407, 0.9596393820367294, 0.9585694530961609, 0.9591739917866371, 0.9608026774178663, 0.9622900516795865, 0.9615688950604466, 0.9627783329295865, 0.9636153865010151, 0.9637777864294942, 0.9632430022033037, 0.9653120241555924, 0.9654293630606312, 0.9650111967631044, 0.9673585155961609, 0.9664982105366371, 0.9678467968461609, 0.967125640227021, 0.9683118266080657, 0.968288935608158, 0.9683118266080657, 0.9693574225959765, 0.9689149233457919, 0.9686834899294019, 0.9694744010128276, 0.9699859337509228, 0.9706133634413067, 0.9711245356912146, 0.9703797670957919, 0.9701708641911223, 0.9712400721553157, 0.9708923812984496, 0.9721007377030271, 0.9708451573458842, 0.972056037167774, 0.9725657674649317, 0.973658587405408, 0.9727979218576966, 0.9726816644172205, 0.9726122704411223, 0.9727525003460686, 0.9739619382152085, 0.9732400606196937, 0.9735655814530271, 0.9732633121077889, 0.9746580409053157, 0.9743801045127353, 0.9743099895602622, 0.9744251655361758, 0.9747281558577889, 0.9741472291435955, 0.9751466826435032, 0.9759143422388336, 0.9746816528815985, 0.9749606707387413, 0.9764952689530271, 0.9758681997508305, 0.9762860055601699, 0.974937419250646, 0.97605313019103, 0.9767285048103543, 0.9770533046673128, 0.9765188809293098, 0.9776578433577889, 0.9775884493816908, 0.9765661048818751, 0.9764723779531194, 0.9764494869532114, 0.9767757287629198, 0.9769835502030271, 0.9768683742271133, 0.9778910792151162, 0.9763096175364526, 0.9766587503460686, 0.9776825367986341, 0.9775655583817828, 0.9774965248938722, 0.9780778120962532, 0.9780069761674051, 0.9782859940245479, 0.9780538396317828, 0.9780302276555003, 0.9783092455126431, 0.978053118655408, 0.9781711785368217, 0.9784723664174971, 0.9779143307032114, 0.9774725524294019, 0.9779619151439645, 0.978542841858158, 0.9790304021317828, 0.9790772655961609, 0.9791702715485419, 0.9781937090485419, 0.9790536536198781, 0.9777751822628276, 0.9791470200604466, 0.9793798954295865, 0.9788916141795865, 0.9784269449058692, 0.9800538280961609, 0.9789377566675894, 0.978844390227021, 0.9794965133582503, 0.9797519192391103, 0.9787292142511074, 0.9799382916320598, 0.9801246640250092, 0.9801471945367294, 0.9788926956441492, 0.979867816191399, 0.978891974667774, 0.9798674557032114, 0.9791938835248246, 0.9801468340485419, 0.9789155866440569, 0.9795659073343485, 0.9796589132867294, 0.980263091489018, 0.9797057767511074, 0.9796828857511997, 0.9803564579295865, 0.9798452856796788, 0.9800778005606312, 0.9802405609772978, 0.9803800699058692, 0.979961543120155, 0.9796356617986341, 0.980449824370155, 0.979868537167774, 0.9807517332272055, 0.9811233965485419, 0.9801243035368217, 0.9808912421557769, 0.9802638124653931, 0.9806351152985419, 0.9803332064414912, 0.980356097441399, 0.9808912421557769, 0.9808676301794942, 0.9801246640250092, 0.9808916026439645, 0.9810074995962532, 0.981333380917774, 0.9808222086678663, 0.981239653989018, 0.9805424698343485, 0.9804734363464378, 0.9804033213939645, 0.9814957808462532, 0.9807760661798633, 0.9810768935723514, 0.980102133513289, 0.9807292027154854, 0.9802867034653008, 0.980054549072536, 0.9801704460248246, 0.9810772540605389, 0.9808454601559615, 0.9810783355251015, 0.981286517453396, 0.9803339274178663, 0.980984969084533, 0.9807299236918604, 0.980542830322536, 0.9813330204295865, 0.9807288422272978, 0.9810074995962532, 0.9817755196797711, 0.9817286562153931, 0.981519392822536, 0.981821662167774, 0.9801951394656699, 0.9818213016795865, 0.9809613571082503, 0.9812403749653931, 0.981520113798911, 0.981820941191399, 0.9816817927510151, 0.9811473690130121, 0.9811706205011074, 0.9816589017511074, 0.9812636264534883, 0.9815895077750092, 0.982309943417774, 0.9811237570367294, 0.9806819787629198], "end": "2016-02-06 01:09:45.033000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0], "moving_var_accuracy_valid": [0.02519841531675272, 0.05102844993800859, 0.07883243500490528, 0.10184809401273534, 0.11889503465520972, 0.13011531717573968, 0.1367937237664654, 0.14000398716882148, 0.13993667219731565, 0.13767666891520364, 0.1335878418065947, 0.12821058309906797, 0.1222147737582214, 0.11547826733982984, 0.10826889658688106, 0.10114796586020462, 0.09405407523227236, 0.0871956479321135, 0.08057953420216174, 0.07424583483436067, 0.0682188206743375, 0.06253307070703774, 0.05720262910990361, 0.05229187213523188, 0.04770516546148033, 0.04345491724821295, 0.039521368220727666, 0.035926386913916794, 0.03266052222758303, 0.029623599892109508, 0.026861154534795092, 0.02433954030591952, 0.022045901129198266, 0.019966160502988977, 0.018073208452640193, 0.01634413436598075, 0.014770789894001725, 0.013339552909136469, 0.012061355451086404, 0.010887653095773138, 0.009824690390050224, 0.008860581479245986, 0.007999106147952191, 0.007217821759154061, 0.006518063669255108, 0.0058834834726555416, 0.005308302031795057, 0.004787373121750437, 0.00431774511639616, 0.003894645624698425, 0.003511016357676748, 0.0031669707755352682, 0.002853023554458614, 0.0025707686721775885, 0.0023161505628032535, 0.0020861507723537085, 0.001879734074839723, 0.0016920273424036142, 0.0015257694685235162, 0.0013738320059529115, 0.0012398002560082564, 0.0011177904175149055, 0.0010071648252636992, 0.0009077772511321083, 0.0008177824734638278, 0.0007364225581913836, 0.0006642389732582977, 0.0005993671372049144, 0.000540293213141038, 0.0004866398608803282, 0.0004380107511348095, 0.00039502544701486015, 0.00035596287911903796, 0.00032169477873494266, 0.0002902601033717791, 0.00026206545937190083, 0.00023621259343981234, 0.0002126336256778335, 0.00019181559981382474, 0.00017265617970833066, 0.00015543740066765283, 0.00014021184706743473, 0.00012641547072842654, 0.00011434306554350162, 0.00010354100007296377, 9.323065241416757e-05, 8.434346263390959e-05, 7.599616614212483e-05, 6.89603666698521e-05, 6.217994559400197e-05, 5.7046737932738585e-05, 5.175335632336579e-05, 4.67993098673685e-05, 4.2211943044200035e-05, 3.856707117249452e-05, 3.486027693842273e-05, 3.141380821296075e-05, 2.8291830574679753e-05, 2.5466347589187105e-05, 2.3143813333969617e-05, 2.0858232003526924e-05, 1.8772408808597908e-05, 1.8212324206457675e-05, 1.655444615796773e-05, 1.5029081194666778e-05, 1.4366536833347389e-05, 1.3432566807713337e-05, 1.221012150954876e-05, 1.1555032838988555e-05, 1.0424550027074968e-05, 9.772235197127615e-06, 9.146180342903187e-06, 8.23520439239807e-06, 7.817661515078499e-06, 7.364737188726025e-06, 6.694141112230611e-06, 6.08245443487522e-06, 5.538147120537774e-06, 4.986044705889817e-06, 4.48882719619955e-06, 4.204703930922896e-06, 3.830778255369963e-06, 3.8078067341122237e-06, 3.431527669502725e-06, 3.2333141633135435e-06, 3.5529966565793945e-06, 3.2535599850089807e-06, 3.161572783621417e-06, 2.857138552337728e-06, 2.6131306991779774e-06, 2.514650046218567e-06, 2.9273769843869777e-06, 2.6485795716066446e-06, 2.396595801379865e-06, 2.359694518359236e-06, 2.4262016905187934e-06, 2.365674485608983e-06, 2.169865127406338e-06, 1.9739258355521834e-06, 1.7847886686514128e-06, 1.6627271407431682e-06, 2.2531146234556994e-06, 2.305035209472531e-06, 2.306240577853619e-06, 2.4709888227126876e-06, 2.5869309305648337e-06, 2.670549530716644e-06, 2.8164383547452614e-06, 2.5907661894002416e-06, 2.351200856718086e-06, 2.366013370028792e-06, 2.6239001145785957e-06, 2.3617822566685453e-06, 2.179189524087937e-06, 2.038827545150516e-06, 2.0331115994260554e-06, 1.8309860323378265e-06, 1.6490487201769851e-06, 1.582974307379873e-06, 1.463181886979213e-06, 1.3242460247553332e-06, 1.530372320491416e-06, 1.4069654227105662e-06, 1.5655398666910932e-06, 1.5202164760944856e-06, 1.7393061032889816e-06, 1.5705877421848256e-06, 1.4326333231677442e-06, 1.539243177124099e-06, 1.8753979030442613e-06, 1.8441516807082723e-06, 1.6749534405661184e-06, 1.5186130081257775e-06, 1.5245906235005886e-06, 1.4473521143573342e-06, 1.3050395098689875e-06, 1.1815928368232422e-06, 1.0696265146808717e-06, 1.1899509853385491e-06, 1.0869383344409398e-06, 9.796469152303414e-07, 9.28540040729355e-07, 8.358232668620189e-07, 9.037179137671386e-07, 1.0179170258430445e-06, 9.279449708665302e-07, 1.4032207235777979e-06, 1.6826599410282592e-06, 1.5950244374047602e-06, 1.4371620573040133e-06, 1.399935915204959e-06, 1.2798328877379652e-06, 1.1519014353812143e-06, 1.0457675916907478e-06, 9.654650320436841e-07, 9.940725388626089e-07, 1.4986278311344442e-06, 1.7356647918277507e-06, 2.332414955294577e-06, 2.1082315771234712e-06, 2.03612624950978e-06, 1.8327350186531228e-06, 1.7009636872670964e-06, 1.53119322256408e-06, 1.3958495546238288e-06, 1.3897430029613101e-06, 1.4500485850344641e-06, 1.3884579294760714e-06, 1.454191678624215e-06, 1.3095852846212655e-06, 1.1798464313230754e-06, 1.0877633377037208e-06, 1.0865389238791702e-06, 9.999882789474364e-07, 1.0435477378721914e-06, 1.0202159348827983e-06, 9.39603160005174e-07, 8.463801133887596e-07, 7.69576896243305e-07, 6.970843113923084e-07, 6.301650416454182e-07, 5.679779459708968e-07, 5.193019145727009e-07, 5.541952094961696e-07, 4.992422170047722e-07, 4.894329656520239e-07, 4.798151543798121e-07, 4.718693077071695e-07, 5.10550155786959e-07, 8.494241858151077e-07, 9.84976801264398e-07, 9.823686110950194e-07, 8.84197318595627e-07, 8.266894744743625e-07, 8.11015408699073e-07, 7.328127612254886e-07, 6.85776699884627e-07], "accuracy_test": 0.8382712850765307, "start": "2016-02-03 11:38:28.950000", "learning_rate_per_epoch": [0.0032752968836575747, 0.0016376484418287873, 0.001091765589080751, 0.0008188242209143937, 0.0006550593534484506, 0.0005458827945403755, 0.0004678995464928448, 0.00040941211045719683, 0.000363921863026917, 0.0003275296767242253, 0.000297754246275872, 0.00027294139727018774, 0.00025194589397870004, 0.0002339497732464224, 0.0002183531178161502, 0.00020470605522859842, 0.00019266452000010759, 0.0001819609315134585, 0.00017238403961528093, 0.00016376483836211264, 0.00015596651064697653, 0.000148877123137936, 0.00014240421296563, 0.00013647069863509387, 0.00013101186777930707, 0.00012597294698935002, 0.0001213072901009582, 0.0001169748866232112, 0.00011294127034489065, 0.0001091765589080751, 0.0001056547334883362, 0.00010235302761429921, 9.925141785060987e-05, 9.633226000005379e-05, 9.357991075376049e-05, 9.098046575672925e-05, 8.852153405314311e-05, 8.619201980764046e-05, 8.398196951020509e-05, 8.188241918105632e-05, 7.98852852312848e-05, 7.798325532348827e-05, 7.616969378432259e-05, 7.4438561568968e-05, 7.27843726053834e-05, 7.1202106482815e-05, 6.968716479605064e-05, 6.823534931754693e-05, 6.684278923785314e-05, 6.550593388965353e-05, 6.422150909202173e-05, 6.298647349467501e-05, 6.179805495776236e-05, 6.06536450504791e-05, 5.955084998277016e-05, 5.84874433116056e-05, 5.746134775108658e-05, 5.647063517244533e-05, 5.551350477617234e-05, 5.458827945403755e-05, 5.369339123717509e-05, 5.28273667441681e-05, 5.198883809498511e-05, 5.1176513807149604e-05, 5.0389182433718815e-05, 4.9625708925304934e-05, 4.888502735411748e-05, 4.8166130000026897e-05, 4.746807098854333e-05, 4.6789955376880243e-05, 4.613093915395439e-05, 4.549023287836462e-05, 4.4867079850519076e-05, 4.426076702657156e-05, 4.367062501842156e-05, 4.309600990382023e-05, 4.25363214162644e-05, 4.1990984755102545e-05, 4.14594542235136e-05, 4.094120959052816e-05, 4.0435763366986066e-05, 3.99426426156424e-05, 3.94614071410615e-05, 3.899162766174413e-05, 3.853290400002152e-05, 3.8084846892161295e-05, 3.764708890230395e-05, 3.7219280784484e-05, 3.680108784465119e-05, 3.63921863026917e-05, 3.599227420636453e-05, 3.56010532414075e-05, 3.521824692143127e-05, 3.484358239802532e-05, 3.447680865065195e-05, 3.411767465877347e-05, 3.3765947591746226e-05, 3.342139461892657e-05, 3.308380473754369e-05, 3.275296694482677e-05, 3.242868115194142e-05, 3.211075454601087e-05, 3.179899795213714e-05, 3.1493236747337505e-05, 3.119330358458683e-05, 3.089902747888118e-05, 3.0610251997131854e-05, 3.032682252523955e-05, 3.0048595363041386e-05, 2.977542499138508e-05, 2.9507178624044172e-05, 2.92437216558028e-05, 2.8984926757402718e-05, 2.873067387554329e-05, 2.8480841137934476e-05, 2.8235317586222664e-05, 2.799399044306483e-05, 2.775675238808617e-05, 2.7523503376869485e-05, 2.7294139727018774e-05, 2.7068568670074455e-05, 2.6846695618587546e-05, 2.6628429623087868e-05, 2.641368337208405e-05, 2.6202375011052936e-05, 2.5994419047492556e-05, 2.5789739083847962e-05, 2.5588256903574802e-05, 2.538989792810753e-05, 2.5194591216859408e-05, 2.5002265829243697e-05, 2.4812854462652467e-05, 2.462629163346719e-05, 2.444251367705874e-05, 2.4261456928797998e-05, 2.4083065000013448e-05, 2.3907276045065373e-05, 2.3734035494271666e-05, 2.3563286958960816e-05, 2.3394977688440122e-05, 2.322905493201688e-05, 2.3065469576977193e-05, 2.290417432959657e-05, 2.274511643918231e-05, 2.258825406897813e-05, 2.2433539925259538e-05, 2.2280930352280848e-05, 2.213038351328578e-05, 2.198185757151805e-05, 2.183531250921078e-05, 2.1690706489607692e-05, 2.1548004951910116e-05, 2.1407167878351174e-05, 2.12681607081322e-05, 2.1130947061465122e-05, 2.0995492377551273e-05, 2.0861763914581388e-05, 2.07297271117568e-05, 2.0599351046257652e-05, 2.047060479526408e-05, 2.034345925494563e-05, 2.0217881683493033e-05, 2.009384479606524e-05, 1.99713213078212e-05, 1.9850283933919854e-05, 1.973070357053075e-05, 1.961255657079164e-05, 1.9495813830872066e-05, 1.938045534188859e-05, 1.926645200001076e-05, 1.9153781977365725e-05, 1.9042423446080647e-05, 1.8932350940303877e-05, 1.8823544451151974e-05, 1.8715982150752097e-05, 1.8609640392242e-05, 1.8504500985727645e-05, 1.8400543922325596e-05, 1.829774737416301e-05, 1.819609315134585e-05, 1.809556306398008e-05, 1.7996137103182264e-05, 1.7897797079058364e-05, 1.780052662070375e-05, 1.7704307538224384e-05, 1.7609123460715637e-05, 1.751495619828347e-05, 1.742179119901266e-05, 1.732961209199857e-05, 1.7238404325325973e-05, 1.714815152809024e-05, 1.7058837329386733e-05, 1.6970448996289633e-05, 1.6882973795873113e-05, 1.6796393538243137e-05, 1.6710697309463285e-05, 1.662587237660773e-05, 1.6541902368771844e-05, 1.6458778191008605e-05, 1.6376483472413383e-05, 1.629500911803916e-05, 1.621434057597071e-05, 1.6134466932271607e-05, 1.6055377273005433e-05, 1.597705704625696e-05, 1.589949897606857e-05, 1.5822690329514444e-05, 1.5746618373668753e-05, 1.5671275832573883e-05, 1.5596651792293414e-05, 1.552273351990152e-05, 1.544951373944059e-05, 1.5376979717984796e-05, 1.5305125998565927e-05, 1.5233938938763458e-05, 1.5163411262619775e-05, 1.5093533875187859e-05, 1.5024297681520693e-05, 1.495569358667126e-05, 1.488771249569254e-05, 1.4820347132626921e-05, 1.4753589312022086e-05, 1.4687429938931018e-05, 1.46218608279014e-05, 1.455687470297562e-05, 1.4492463378701359e-05, 1.4428620488615707e-05, 1.4365336937771644e-05, 1.430260635970626e-05, 1.4240420568967238e-05, 1.4178774108586367e-05, 1.4117658793111332e-05, 1.405706825607922e-05, 1.3996995221532416e-05, 1.3937433323008008e-05, 1.3878376194043085e-05, 1.3819817468174733e-05], "accuracy_train_first": 0.5255386054009782, "accuracy_train_last": 0.9806819787629198, "batch_size_eval": 1024, "accuracy_train_std": [0.017254301351608752, 0.017917518509931566, 0.016845100909857722, 0.01677505671283451, 0.015923006352247793, 0.014835773452748788, 0.014379651206831531, 0.01423820049597291, 0.012945029076780204, 0.01221119803246981, 0.013171393294179079, 0.01199352655674946, 0.011345844348228152, 0.012423907304174815, 0.012133591653477438, 0.012422614081171736, 0.010579858603982145, 0.011519216881861614, 0.01059101591277591, 0.010531600529820384, 0.01092861599612808, 0.011999166826803428, 0.010502506236534722, 0.011309548072542428, 0.010742552308298868, 0.0104050610674588, 0.010857416743796918, 0.011056082665318549, 0.010535560674806047, 0.011525374684381572, 0.010506262088095977, 0.011381621402271112, 0.009583920336518458, 0.0103961168649739, 0.009240192146067833, 0.010382343707828794, 0.00974244543954031, 0.009583740654798167, 0.00911764326945115, 0.009601272596310335, 0.009525213295284319, 0.008978420681811674, 0.009360506233828437, 0.00979479724715984, 0.009232765702011899, 0.009187569799141242, 0.00874462682451638, 0.008911387311695091, 0.008785190224741819, 0.008609664970692389, 0.008857174052551549, 0.009023559344114467, 0.009117817757399997, 0.009090380819309242, 0.00815226178053809, 0.008437928508886182, 0.00871338708132261, 0.00847060063438691, 0.008353752891787473, 0.008956611477981557, 0.007978064777046096, 0.007881060715818698, 0.007317855105536275, 0.007823880308996771, 0.007296221721427869, 0.008359301003481652, 0.007675891942777892, 0.008236556226781995, 0.006958225116711535, 0.007048663592616505, 0.007367169189134371, 0.007226272179489716, 0.007779780148719448, 0.007968944374082413, 0.008332363130065468, 0.007356655841881968, 0.007037275801082431, 0.007356956978106385, 0.0077170988638159965, 0.008286418540380256, 0.007344589979675116, 0.007329318162095004, 0.006995928823942745, 0.007696244001088066, 0.006626209272870159, 0.00762822392708507, 0.007210652634753482, 0.00677605419250689, 0.0074646400081508505, 0.0069788769202451155, 0.00670582314316127, 0.007021787998433971, 0.00735598904700398, 0.006966940719355384, 0.006398109380824624, 0.006311799555031239, 0.00642134189322882, 0.006259490680351231, 0.0062765958091014875, 0.006391317388859463, 0.006666237646126296, 0.006163262348825079, 0.006171723093706598, 0.005877534096182718, 0.0067929222445786966, 0.006352096193794108, 0.006732961954877505, 0.006814005201611479, 0.006339382504894098, 0.006883627113015454, 0.0064099157511438186, 0.005964180629292981, 0.006888740462128628, 0.005714875417131928, 0.005179869267311044, 0.0065114578573316475, 0.0064137438428118095, 0.0061063170831077065, 0.005729488152488819, 0.005663049629481321, 0.0056142617495303325, 0.005599710329137154, 0.00621331397949459, 0.005398052555036857, 0.005988667625247999, 0.005910275989355492, 0.005454553317139304, 0.005106900923248811, 0.005189646705622101, 0.005826695940418488, 0.005769052816084584, 0.004979801753528104, 0.005707488507412988, 0.00538339762248798, 0.00557147307560974, 0.005814743008501301, 0.005510305296975453, 0.005545235697921185, 0.005741521436733391, 0.006014268375018638, 0.005788151604941099, 0.005243279657970613, 0.004863639428162172, 0.005241824733593371, 0.0051924411605658236, 0.004976087603346875, 0.004993370614344619, 0.00529366340551037, 0.00553208242798069, 0.004972538895682424, 0.005043942204853792, 0.0060477764455464855, 0.005110874633251408, 0.005409884087651613, 0.005082677172256127, 0.004993812041392232, 0.005187555800244402, 0.004987275126583206, 0.004866026882315007, 0.005481317783855291, 0.005412407439294104, 0.005094581438775545, 0.005251722977193905, 0.005320695537220681, 0.004494057736403059, 0.005043809560777948, 0.005146455383525307, 0.005210070640684503, 0.004866885618912979, 0.0047025631177397545, 0.005216516284528801, 0.004387528494384458, 0.004526698331974194, 0.00503577168636962, 0.004943477905368614, 0.004267924228613337, 0.004890285653536536, 0.004809676979465724, 0.0049464107512560435, 0.004606881002921173, 0.00485908529490065, 0.004739215893743629, 0.005119631793765725, 0.004763911697330051, 0.004750095002880382, 0.005001816915487479, 0.00464090545125665, 0.004039040880449464, 0.004806617545023964, 0.004683470443638077, 0.005261988509562547, 0.0045273107256755185, 0.004417886533500199, 0.005146838612146516, 0.004432140916942922, 0.004156476031921961, 0.004765393367632291, 0.005104752036847552, 0.004407063266958094, 0.004824083325197439, 0.004564133130127001, 0.004529979694022167, 0.005576398647443675, 0.004849295596903821, 0.005145217036796038, 0.005169658977630535, 0.0047230849941370615, 0.004558221221912161, 0.004468500147260822, 0.004490896226666159, 0.0044774423721843405, 0.004828618273349869, 0.004413571961909127, 0.004407169286728822, 0.004899767237181706, 0.004950815760782167, 0.004268900679051692, 0.005037460323355207, 0.0046406097053124686, 0.004133982140207386, 0.005256644847385558, 0.004525466350367624, 0.005025143644699327, 0.004006060576206691, 0.004680663365327728, 0.0046379363032189045, 0.004838183603219604, 0.004108808416782145, 0.004220693025282213, 0.0045137311306616195, 0.004547776187824744, 0.0047726719909109904, 0.005116080692446687, 0.0048742093602470804, 0.004409362090059667, 0.004516716976147125, 0.004841586942581536], "accuracy_test_std": 0.00947573349215551, "error_valid": [0.47086637565888556, 0.3858392554593373, 0.2862872387989458, 0.2445583113704819, 0.22183264307228923, 0.21016389777861444, 0.19848485739834332, 0.1862469408885542, 0.18266572147966864, 0.17570771366716864, 0.1727368458207832, 0.1700821842055723, 0.16271678510918675, 0.16369334760918675, 0.1663185946912651, 0.1609975056475903, 0.16041803934487953, 0.15708096056099397, 0.15560582172439763, 0.15478221479668675, 0.15474103445030118, 0.15453807417168675, 0.15439541368599397, 0.1506921239646084, 0.15155691123870485, 0.15156720632530118, 0.15234080854668675, 0.15023472797439763, 0.14667409873870485, 0.1504479833396084, 0.14872870387801207, 0.14839337820030118, 0.14738593044051207, 0.14567694606551207, 0.14525925969503017, 0.14631818288780118, 0.14680646413780118, 0.14768154649849397, 0.14310317441641573, 0.14652114316641573, 0.14667409873870485, 0.14763007106551207, 0.14395766660391573, 0.14444594785391573, 0.1417501058923193, 0.1419942465173193, 0.14235016236822284, 0.14274725856551207, 0.14212661191641573, 0.1413633047816265, 0.1421472020896084, 0.14053969785391573, 0.14298110410391573, 0.14213690700301207, 0.1421472020896084, 0.14261489316641573, 0.1414853750941265, 0.14421210231551207, 0.1400411215173193, 0.14252370811370485, 0.1388204183923193, 0.13963373023343373, 0.1402646719691265, 0.13964402532003017, 0.14015289674322284, 0.1406514730798193, 0.13856598268072284, 0.13803652108433728, 0.1386777579066265, 0.13942047486822284, 0.14188247129141573, 0.1383115469691265, 0.13881012330572284, 0.13695847844503017, 0.13755853492093373, 0.1370908438441265, 0.1378438558923193, 0.1389424887048193, 0.1373349844691265, 0.13884100856551207, 0.13856598268072284, 0.1373349844691265, 0.13744675969503017, 0.1413838949548193, 0.13647019719503017, 0.1395528402673193, 0.1367246329066265, 0.1377217855798193, 0.13610398625753017, 0.13722320924322284, 0.1347715079066265, 0.13575836549322284, 0.1361142813441265, 0.13651137754141573, 0.1348935782191265, 0.13588043580572284, 0.1363790121423193, 0.13651137754141573, 0.13713202419051207, 0.13537156438253017, 0.13622605657003017, 0.13673492799322284, 0.13290956795933728, 0.13500535344503017, 0.1350156485316265, 0.13304193335843373, 0.1334287344691265, 0.13671433782003017, 0.13316400367093373, 0.1348935782191265, 0.13328607398343373, 0.1331845938441265, 0.13476121282003017, 0.1328183829066265, 0.1328183829066265, 0.13368317018072284, 0.13365228492093373, 0.13353021460843373, 0.13415086125753017, 0.13415086125753017, 0.13290956795933728, 0.13340814429593373, 0.13205507577183728, 0.13363169474774095, 0.13256394719503017, 0.1363790121423193, 0.13476121282003017, 0.13244187688253017, 0.13353021460843373, 0.13317429875753017, 0.13244187688253017, 0.1309358527861446, 0.13377435523343373, 0.13304193335843373, 0.13488328313253017, 0.13169915992093373, 0.1347715079066265, 0.1328183829066265, 0.1329404532191265, 0.13307281861822284, 0.13255365210843373, 0.13036668157003017, 0.13122117375753017, 0.1344052969691265, 0.1308652579066265, 0.1307431875941265, 0.13060052710843373, 0.13021372599774095, 0.13293015813253017, 0.13268601750753017, 0.13060052710843373, 0.12975633000753017, 0.13181093514683728, 0.13108880835843373, 0.13085496282003017, 0.13317429875753017, 0.13195359563253017, 0.1319638907191265, 0.13290956795933728, 0.13131235881024095, 0.13218744117093373, 0.12999017554593373, 0.13230951148343373, 0.12996958537274095, 0.1304990469691265, 0.13353021460843373, 0.13194330054593373, 0.13218744117093373, 0.13343902955572284, 0.13427293157003017, 0.13085496282003017, 0.1324521719691265, 0.13173004518072284, 0.13072259742093373, 0.13282867799322284, 0.1318418204066265, 0.13170945500753017, 0.13169915992093373, 0.13034609139683728, 0.13219773625753017, 0.13194330054593373, 0.1311093985316265, 0.1317197500941265, 0.13305222844503017, 0.1303769766566265, 0.13209625611822284, 0.12925775367093373, 0.12935923381024095, 0.13035638648343373, 0.13134324407003017, 0.13230951148343373, 0.13180064006024095, 0.1313535391566265, 0.1310579230986446, 0.13082407756024095, 0.13011224585843373, 0.13376406014683728, 0.12935923381024095, 0.13415086125753017, 0.13120058358433728, 0.13024461125753017, 0.13131235881024095, 0.13060052710843373, 0.13122117375753017, 0.1317197500941265, 0.13010195077183728, 0.13268601750753017, 0.13230951148343373, 0.13295074830572284, 0.13168886483433728, 0.1317197500941265, 0.13107851327183728, 0.13046816170933728, 0.13095644295933728, 0.13266542733433728, 0.13057993693524095, 0.13094614787274095, 0.1314756094691265, 0.13109910344503017, 0.13158738469503017, 0.13121087867093373, 0.13146531438253017, 0.13107851327183728, 0.13036668157003017, 0.13132265389683728, 0.13059023202183728, 0.13185211549322284, 0.13059023202183728, 0.13021372599774095, 0.13317429875753017, 0.12973573983433728, 0.13011224585843373, 0.13106821818524095, 0.13045786662274095, 0.13012254094503017, 0.13107851327183728, 0.1303769766566265], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.08465648052722516, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.003275296805317935, "optimization": "rmsprop", "nb_data_augmentation": 1, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 6.269909739968305e-07, "rotation_range": [0, 0], "momentum": 0.5452480221456879}, "accuracy_valid_max": 0.8707422463290663, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8696230233433735, "accuracy_valid_std": [0.02075404283793378, 0.012520215433923522, 0.011334233677637652, 0.01168526083646618, 0.016216880631293392, 0.013337328778151927, 0.014029572864296484, 0.01107740382946433, 0.01136809630841161, 0.013366028264290404, 0.009055327444787674, 0.013071958761962666, 0.010989770208404899, 0.011162235059573476, 0.014932060246077333, 0.01058468313705392, 0.010744327733721562, 0.01015505381833906, 0.009719072303636177, 0.01047740508999227, 0.00816905665373194, 0.010677383150489076, 0.008638687201665711, 0.006252251028789599, 0.0069328886176372815, 0.009697956853135025, 0.011630668201726715, 0.009731034888253507, 0.008405958116252412, 0.007569548638145914, 0.006619822206479516, 0.007896749287587797, 0.008023585770353444, 0.008410569088886162, 0.005456662879957704, 0.010844028084024395, 0.010818502037452979, 0.011616529819005956, 0.006874236021119506, 0.009936830865597388, 0.010106007336905908, 0.010403074885095079, 0.008895250029682734, 0.0071965713621784146, 0.009447740961402861, 0.007779295866820189, 0.008335941554008937, 0.009653308319094037, 0.01018980554015423, 0.00787190007881067, 0.010987082068036612, 0.007970067908614322, 0.0076143307240730115, 0.009858631724528727, 0.010315563853889806, 0.008588101627650063, 0.006615969828875493, 0.0088938739591918, 0.0077859395484148036, 0.01009840110354261, 0.007919093642359617, 0.010278602521638503, 0.008858629837670964, 0.005692787362191719, 0.00837230303390959, 0.008845700362041178, 0.008003263667606163, 0.008278380552802864, 0.007568992109689178, 0.007402753718488573, 0.008779954706504191, 0.00971968865266212, 0.010547568847112632, 0.00864656186898425, 0.007426183289912999, 0.0067535843338093135, 0.009533999249237798, 0.009806053632445407, 0.010069656218095977, 0.009269554931947744, 0.008281436006886399, 0.00813093024466498, 0.008135371661824552, 0.009750679486114517, 0.008366023655395632, 0.008800864565214084, 0.007879149271499943, 0.008881349433238431, 0.007480984396595295, 0.008588744361498687, 0.008849657435488344, 0.00842335462998424, 0.007663903265077491, 0.010608020848106544, 0.0086649551926094, 0.010619628665270298, 0.011252478709652533, 0.009826294393822037, 0.010524344744518632, 0.007544026690319685, 0.008064800797386813, 0.007524373118962782, 0.006656887079706133, 0.006413172180976021, 0.008899867071149084, 0.010787188010049107, 0.008700271835735355, 0.00658401321177218, 0.00862844420316347, 0.009567253025186299, 0.007632566920155001, 0.008520455445595074, 0.0070716133314560545, 0.011785488361595408, 0.007866926647140936, 0.007694376348162292, 0.006953961282642455, 0.008099051202487889, 0.006916766641621055, 0.006246612950062137, 0.006250514926925947, 0.007329039109444866, 0.008693604352012989, 0.00864860494674988, 0.007984797968012965, 0.008387579653464686, 0.007433231050482784, 0.008120738395805157, 0.007374886925421099, 0.008770411044302814, 0.009833737275177007, 0.009801189038444215, 0.009087856481261678, 0.009200747477441134, 0.007876168445725215, 0.009833569993551831, 0.00825011744305055, 0.010770773060813732, 0.008569451472540552, 0.01070564300131358, 0.010160513803374077, 0.009181569123779196, 0.007051464868411617, 0.008754251211845088, 0.008508932509779042, 0.009960449673594421, 0.007989964013484218, 0.008953206857977226, 0.007753028161603548, 0.00753454916915703, 0.008812933820508552, 0.009593202190742417, 0.006751696981282743, 0.008987858845019202, 0.008633096698234838, 0.0064709024685973325, 0.009815317221519206, 0.009135675613467127, 0.007305754690503769, 0.008002493903468534, 0.006661875356856818, 0.010106060417388048, 0.0085305853249251, 0.00885180990648022, 0.009425615206568242, 0.008201436486020692, 0.008423602172326117, 0.008952282956627908, 0.010240531465498354, 0.008717283490984763, 0.009662578659451974, 0.00933543313749125, 0.009437634505578264, 0.007016058469458461, 0.009910974430856704, 0.008958697199611187, 0.00852847339464959, 0.008997970471021778, 0.008051339512948008, 0.008091192776726437, 0.009513537567274617, 0.008420744849690477, 0.009044031809640446, 0.008505549729861207, 0.00899948589251816, 0.009080522095996295, 0.009490562421045415, 0.007888795725412174, 0.007827473661976, 0.0077914305350612265, 0.008129893343149326, 0.007238222741466939, 0.00852259385451834, 0.008027407572850667, 0.008059721635108909, 0.009786380943503889, 0.00800258134353687, 0.005652781479181991, 0.00882510066466319, 0.008541552968395755, 0.00934797704048777, 0.00881077565733234, 0.009799287377941508, 0.007620223557022325, 0.009887798348145705, 0.007683111949548163, 0.007597572342455921, 0.008572405830519934, 0.0109009985962209, 0.005952446326001155, 0.008330470890682411, 0.0067622186832890195, 0.00878709491214092, 0.008220796853217452, 0.0072063397049371225, 0.006516972201652621, 0.0075790925559431725, 0.009450268204050545, 0.010867543803299563, 0.009585498077041416, 0.007964003042968335, 0.00820781859136213, 0.008468484317910342, 0.00905080249390737, 0.008171918336999652, 0.008063193540238212, 0.009607213297026863, 0.005791704207392932, 0.006822235219369829, 0.00816505425485107, 0.008346629691828197, 0.00738422899068046, 0.009020400502565414, 0.007537381996939297, 0.011008829742799701, 0.007900436827019911, 0.009476931663591924], "accuracy_valid": [0.5291336243411144, 0.6141607445406627, 0.7137127612010542, 0.7554416886295181, 0.7781673569277108, 0.7898361022213856, 0.8015151426016567, 0.8137530591114458, 0.8173342785203314, 0.8242922863328314, 0.8272631541792168, 0.8299178157944277, 0.8372832148908133, 0.8363066523908133, 0.8336814053087349, 0.8390024943524097, 0.8395819606551205, 0.842919039439006, 0.8443941782756024, 0.8452177852033133, 0.8452589655496988, 0.8454619258283133, 0.845604586314006, 0.8493078760353916, 0.8484430887612951, 0.8484327936746988, 0.8476591914533133, 0.8497652720256024, 0.8533259012612951, 0.8495520166603916, 0.8512712961219879, 0.8516066217996988, 0.8526140695594879, 0.8543230539344879, 0.8547407403049698, 0.8536818171121988, 0.8531935358621988, 0.852318453501506, 0.8568968255835843, 0.8534788568335843, 0.8533259012612951, 0.8523699289344879, 0.8560423333960843, 0.8555540521460843, 0.8582498941076807, 0.8580057534826807, 0.8576498376317772, 0.8572527414344879, 0.8578733880835843, 0.8586366952183735, 0.8578527979103916, 0.8594603021460843, 0.8570188958960843, 0.8578630929969879, 0.8578527979103916, 0.8573851068335843, 0.8585146249058735, 0.8557878976844879, 0.8599588784826807, 0.8574762918862951, 0.8611795816076807, 0.8603662697665663, 0.8597353280308735, 0.8603559746799698, 0.8598471032567772, 0.8593485269201807, 0.8614340173192772, 0.8619634789156627, 0.8613222420933735, 0.8605795251317772, 0.8581175287085843, 0.8616884530308735, 0.8611898766942772, 0.8630415215549698, 0.8624414650790663, 0.8629091561558735, 0.8621561441076807, 0.8610575112951807, 0.8626650155308735, 0.8611589914344879, 0.8614340173192772, 0.8626650155308735, 0.8625532403049698, 0.8586161050451807, 0.8635298028049698, 0.8604471597326807, 0.8632753670933735, 0.8622782144201807, 0.8638960137424698, 0.8627767907567772, 0.8652284920933735, 0.8642416345067772, 0.8638857186558735, 0.8634886224585843, 0.8651064217808735, 0.8641195641942772, 0.8636209878576807, 0.8634886224585843, 0.8628679758094879, 0.8646284356174698, 0.8637739434299698, 0.8632650720067772, 0.8670904320406627, 0.8649946465549698, 0.8649843514683735, 0.8669580666415663, 0.8665712655308735, 0.8632856621799698, 0.8668359963290663, 0.8651064217808735, 0.8667139260165663, 0.8668154061558735, 0.8652387871799698, 0.8671816170933735, 0.8671816170933735, 0.8663168298192772, 0.8663477150790663, 0.8664697853915663, 0.8658491387424698, 0.8658491387424698, 0.8670904320406627, 0.8665918557040663, 0.8679449242281627, 0.866368305252259, 0.8674360528049698, 0.8636209878576807, 0.8652387871799698, 0.8675581231174698, 0.8664697853915663, 0.8668257012424698, 0.8675581231174698, 0.8690641472138554, 0.8662256447665663, 0.8669580666415663, 0.8651167168674698, 0.8683008400790663, 0.8652284920933735, 0.8671816170933735, 0.8670595467808735, 0.8669271813817772, 0.8674463478915663, 0.8696333184299698, 0.8687788262424698, 0.8655947030308735, 0.8691347420933735, 0.8692568124058735, 0.8693994728915663, 0.869786274002259, 0.8670698418674698, 0.8673139824924698, 0.8693994728915663, 0.8702436699924698, 0.8681890648531627, 0.8689111916415663, 0.8691450371799698, 0.8668257012424698, 0.8680464043674698, 0.8680361092808735, 0.8670904320406627, 0.868687641189759, 0.8678125588290663, 0.8700098244540663, 0.8676904885165663, 0.870030414627259, 0.8695009530308735, 0.8664697853915663, 0.8680566994540663, 0.8678125588290663, 0.8665609704442772, 0.8657270684299698, 0.8691450371799698, 0.8675478280308735, 0.8682699548192772, 0.8692774025790663, 0.8671713220067772, 0.8681581795933735, 0.8682905449924698, 0.8683008400790663, 0.8696539086031627, 0.8678022637424698, 0.8680566994540663, 0.8688906014683735, 0.8682802499058735, 0.8669477715549698, 0.8696230233433735, 0.8679037438817772, 0.8707422463290663, 0.870640766189759, 0.8696436135165663, 0.8686567559299698, 0.8676904885165663, 0.868199359939759, 0.8686464608433735, 0.8689420769013554, 0.869175922439759, 0.8698877541415663, 0.8662359398531627, 0.870640766189759, 0.8658491387424698, 0.8687994164156627, 0.8697553887424698, 0.868687641189759, 0.8693994728915663, 0.8687788262424698, 0.8682802499058735, 0.8698980492281627, 0.8673139824924698, 0.8676904885165663, 0.8670492516942772, 0.8683111351656627, 0.8682802499058735, 0.8689214867281627, 0.8695318382906627, 0.8690435570406627, 0.8673345726656627, 0.869420063064759, 0.869053852127259, 0.8685243905308735, 0.8689008965549698, 0.8684126153049698, 0.8687891213290663, 0.8685346856174698, 0.8689214867281627, 0.8696333184299698, 0.8686773461031627, 0.8694097679781627, 0.8681478845067772, 0.8694097679781627, 0.869786274002259, 0.8668257012424698, 0.8702642601656627, 0.8698877541415663, 0.868931781814759, 0.869542133377259, 0.8698774590549698, 0.8689214867281627, 0.8696230233433735], "seed": 351568768, "model": "residualv3", "loss_std": [0.3791659474372864, 0.2741813361644745, 0.2622520625591278, 0.25387051701545715, 0.24900004267692566, 0.2423250675201416, 0.2377786636352539, 0.23260346055030823, 0.22883446514606476, 0.22273138165473938, 0.2239598035812378, 0.2183038741350174, 0.21504196524620056, 0.2105458527803421, 0.20979063212871552, 0.20884321630001068, 0.20234516263008118, 0.19845393300056458, 0.19800956547260284, 0.19307398796081543, 0.19295592606067657, 0.18829509615898132, 0.18782785534858704, 0.18338221311569214, 0.18173907697200775, 0.1794063150882721, 0.1764809489250183, 0.1738162785768509, 0.17059187591075897, 0.16942556202411652, 0.17002691328525543, 0.16321565210819244, 0.16369807720184326, 0.16518522799015045, 0.16006189584732056, 0.15768137574195862, 0.15680035948753357, 0.15470479428768158, 0.15154290199279785, 0.15332014858722687, 0.15254376828670502, 0.14823636412620544, 0.15085181593894958, 0.1462026685476303, 0.14206989109516144, 0.1464422643184662, 0.14139169454574585, 0.13985806703567505, 0.1394093781709671, 0.1377851814031601, 0.1381697654724121, 0.1370133012533188, 0.13466916978359222, 0.13284729421138763, 0.13293704390525818, 0.13585792481899261, 0.13061589002609253, 0.1313447505235672, 0.12936970591545105, 0.1267721951007843, 0.12776987254619598, 0.12734247744083405, 0.1252053678035736, 0.12410053610801697, 0.12482868880033493, 0.12499038130044937, 0.1210099309682846, 0.11962263286113739, 0.1226952075958252, 0.1220903992652893, 0.12057951837778091, 0.12008985877037048, 0.11845734715461731, 0.11882824450731277, 0.11736956238746643, 0.11676424741744995, 0.11743985116481781, 0.1160350814461708, 0.11423729360103607, 0.11568018049001694, 0.11450619995594025, 0.11458709836006165, 0.11396730691194534, 0.11468828469514847, 0.11317338794469833, 0.11264379322528839, 0.11296654492616653, 0.11337503045797348, 0.11007867008447647, 0.10998829454183578, 0.11017210781574249, 0.10967715084552765, 0.10720044374465942, 0.10903916507959366, 0.10647507011890411, 0.10946372151374817, 0.10766914486885071, 0.11251480877399445, 0.10801304131746292, 0.10642996430397034, 0.10686759650707245, 0.1055244505405426, 0.10287649184465408, 0.10957510024309158, 0.1034010648727417, 0.1057816669344902, 0.10501408576965332, 0.10248319059610367, 0.10204445570707321, 0.10422024875879288, 0.10441873967647552, 0.1016666442155838, 0.10246849060058594, 0.10091909021139145, 0.10507017374038696, 0.10170914977788925, 0.10158856213092804, 0.09923908859491348, 0.09972329437732697, 0.10425198078155518, 0.0991206169128418, 0.10184109210968018, 0.09796850383281708, 0.09992848336696625, 0.09888234734535217, 0.09921251982450485, 0.1004294902086258, 0.10145575553178787, 0.09832248091697693, 0.09667456150054932, 0.09744851291179657, 0.10002858191728592, 0.09679657965898514, 0.09636825323104858, 0.09588650614023209, 0.09548007696866989, 0.09752621501684189, 0.09459377080202103, 0.09768616408109665, 0.09707717597484589, 0.09644193202257156, 0.09864550828933716, 0.09375162422657013, 0.09732722491025925, 0.09533987939357758, 0.09439147263765335, 0.0960504412651062, 0.09264811128377914, 0.09580642729997635, 0.09567669034004211, 0.09276727586984634, 0.09302188456058502, 0.09282806515693665, 0.09321685880422592, 0.0935540646314621, 0.09303351491689682, 0.09378067404031754, 0.09145408868789673, 0.09358315914869308, 0.09313338249921799, 0.09273219853639603, 0.09115820378065109, 0.09320755302906036, 0.09405151009559631, 0.09044216573238373, 0.09301451593637466, 0.08923772722482681, 0.09155752509832382, 0.08985212445259094, 0.08875813335180283, 0.09044063836336136, 0.08910610526800156, 0.0889294296503067, 0.09185688942670822, 0.08965364098548889, 0.08634356409311295, 0.08945977687835693, 0.09121774137020111, 0.08763603866100311, 0.08950375765562057, 0.08624180406332016, 0.08978176862001419, 0.09002584218978882, 0.0893082395195961, 0.08878463506698608, 0.08494897931814194, 0.086469367146492, 0.0869964137673378, 0.08711524307727814, 0.08905703574419022, 0.08564478158950806, 0.08506172895431519, 0.08619197458028793, 0.09031538665294647, 0.0854296088218689, 0.0867655947804451, 0.08749930560588837, 0.08725645393133163, 0.08497360348701477, 0.08596178144216537, 0.08686189353466034, 0.08715245872735977, 0.08647950738668442, 0.0851774662733078, 0.08448489755392075, 0.0859936848282814, 0.08462826162576675, 0.0866311639547348, 0.08459368348121643, 0.0847792848944664, 0.0816318541765213, 0.0832630917429924, 0.08412492275238037, 0.0867447778582573, 0.08383683860301971, 0.08126161992549896, 0.08418074995279312, 0.08648037165403366, 0.0814640149474144, 0.08610018342733383, 0.08453913778066635, 0.08378845453262329, 0.08407821506261826, 0.08165495842695236, 0.08192374557256699, 0.08086121082305908, 0.08045168220996857, 0.08170684427022934, 0.08209086954593658, 0.08465030789375305, 0.08206826448440552, 0.07961463183164597, 0.08274731040000916, 0.08264140784740448, 0.08122493326663971, 0.08082301169633865, 0.08237607777118683]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:41 2016", "state": "available"}], "summary": "5fcf989fec0afaaf053c8cd053c9144e"}