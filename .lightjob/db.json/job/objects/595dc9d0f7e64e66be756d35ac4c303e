{"content": {"hp_model": {"f0": 32, "f1": 32, "f2": 64, "f3": 32, "nonlin": "leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.011145965790407449, 0.007784890593961426, 0.010440150594816289, 0.013384690849255141, 0.00841682345794787, 0.014617523163032511, 0.005146215060657086, 0.005030201447957219, 0.011754743677184841, 0.007256155601285893, 0.006182370721990916, 0.01081419380090482, 0.00815930889872066, 0.012604365644408219, 0.00784024834168033, 0.011585834512179666, 0.005680982654855175, 0.005362334535675227, 0.006801508795813676, 0.006064392055994579, 0.014518124118733966, 0.007660728146947479, 0.00777084521566781, 0.01574200931765851, 0.009652508460657875, 0.011970403906684184, 0.013742117303536455, 0.006877741209971498, 0.00803054626183253, 0.010969586788976658, 0.015884263979199693, 0.009386631381274315, 0.012931155686645488, 0.0067539353513900394, 0.014195517611064815, 0.012026462631798492, 0.015050820699205368, 0.010383025942560348, 0.013157396531287191, 0.006843016453052114, 0.014700262769001845, 0.01458998849005332, 0.011193770728388381, 0.016932067592475078, 0.008382730645262036, 0.016013617362533053, 0.011039219715175961, 0.00774838196238466, 0.009859386011390293, 0.011970403906684184, 0.014237363835155522, 0.005268777409767276, 0.012726532080988177, 0.012468331383917576, 0.01212540830650751, 0.013516946074755046, 0.0063332828425636395, 0.0077712605070202395, 0.011652848522715862, 0.01229974216170915, 0.010338906714892319, 0.013206979203810598, 0.006765508714638303, 0.012700834361602412, 0.010035028256545593, 0.010308129037997937, 0.0075085536493122215, 0.007033154500443422, 0.007398109452218094, 0.01124660808537458, 0.014283306508467396, 0.006624450004261158, 0.009011216877361405, 0.009354360671424845, 0.009664571341868957, 0.007245953518082657, 0.006538701689291027, 0.010823118036429954, 0.006198835629102511, 0.010538995198668919, 0.0046279837367227275, 0.010143642479798603, 0.012567268317520534, 0.008328299903555577, 0.010422603797262077, 0.008804412848161422, 0.005438626868001913, 0.006700886147580599, 0.006071535859297829, 0.00911034893467313, 0.01191954263760327, 0.00593545612126417, 0.014012840853680566], "moving_avg_accuracy_train": [0.010526507417404943, 0.01988163730850867, 0.030528278135382052, 0.037495003201135094, 0.0443184411769795, 0.05058073148388473, 0.05468695298988902, 0.05925190565832352, 0.0630041106085949, 0.06751162206873024, 0.07085688684713776, 0.07396045085599172, 0.07595195075931835, 0.07984573051265931, 0.08308023478466764, 0.08435216686521711, 0.08483474301045989, 0.08637107393043642, 0.08782592346914803, 0.0907552318466703, 0.09155023572457247, 0.09240041760154305, 0.09329651060052496, 0.09583937577686043, 0.09671662515700015, 0.09694131868250538, 0.09740839352683328, 0.09690163934164718, 0.09999051128903469, 0.0998716122573073, 0.10101699316543591, 0.1010327913687336, 0.10094616318124193, 0.10089703686750126, 0.10107081039212987, 0.10133437970244623, 0.10145511834834225, 0.10035227245343051, 0.10032439556223105, 0.10114398425674623, 0.10117219135317386, 0.10120920348400635, 0.10445111161244218, 0.10594765832195285, 0.10543311553100895, 0.10618081671900255, 0.10653759964773905, 0.10524773664678944, 0.10609807761735413, 0.10538230074801443, 0.10696262009758545, 0.10607450266954525, 0.1060747237354165, 0.1059282941244256, 0.10427189478304247, 0.10302731275905716, 0.1026330319030481, 0.10327723609554137, 0.10287867295225707, 0.10298910545054372, 0.10315388725621841, 0.10517368333126102, 0.10369930537742618, 0.10311587210574115, 0.1032467985648791, 0.10336659703872526, 0.10357962414271542, 0.10312971561133424, 0.10291059354494057, 0.10278571564001278, 0.10254998449221675, 0.10255602995910804, 0.10282947582232421, 0.10367249146452885, 0.10300843076399696, 0.10114589518113731, 0.10076286452930265, 0.10023387340559903, 0.10014916341945958, 0.10175568329129177, 0.101569008321105, 0.10417694013595832, 0.10554097340872277, 0.10393024553651975, 0.10381715448000695, 0.1035452401290439, 0.10318483655380101, 0.10446017571703478, 0.10423614316632614, 0.10369740334212615, 0.10324723448839526, 0.10286118839397618, 0.10239934598268856], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 595790990, "moving_var_accuracy_train": [0.0009972662256781317, 0.0016852057006251204, 0.0025368437786306326, 0.0027199767240436955, 0.0028670128039310866, 0.00293325804252961, 0.0027916817337839987, 0.002700062696191024, 0.002556767804471491, 0.002483949960093605, 0.0023362721320231298, 0.0021893339048343003, 0.00200609516113542, 0.0019419393319296298, 0.0018419035597074288, 0.0016722735046944643, 0.0015071420718486342, 0.0013776706789248542, 0.0012589528956549734, 0.0012102852342250748, 0.001094944991295483, 0.0009919557751812977, 0.0008999870416285875, 0.0008681838072109053, 0.0007882915247644146, 0.0007099167569116089, 0.0006408885114122834, 0.0005791108585088877, 0.0006070699418242167, 0.0005464901804595066, 0.000503648239235906, 0.0004532856615613623, 0.00040802463539103893, 0.00036724389240425076, 0.0003307912783045823, 0.0002983373695061899, 0.0002686348329410862, 0.00025271777125829075, 0.0002274529882220282, 0.00021075322005341916, 0.00018968505881067715, 0.0001707288820100683, 0.00024824570862802645, 0.00024357800624894878, 0.00022160299417746496, 0.0002044742083584619, 0.00018517243404675592, 0.00018162890969304908, 0.00016997373661973222, 0.0001575873916978946, 0.0001643053357477623, 0.00015497357526688473, 0.00013947621818002735, 0.00012572157104079912, 0.00013784234293992936, 0.00013799896837578274, 0.00012559818807894173, 0.00011677336064568072, 0.00010652569779377459, 9.598288604449764e-05, 8.662897483138055e-05, 0.00011468226301106032, 0.00012277814986674245, 0.0001135638843226501, 0.00010236177152970672, 9.225475944575887e-05, 8.343770842449286e-05, 7.691569676152966e-05, 6.965625740520238e-05, 6.283098208493455e-05, 5.7048006442812226e-05, 5.134353472756041e-05, 4.688213501579475e-05, 4.8589999871230576e-05, 4.769978941002556e-05, 7.41511596457878e-05, 6.805645600341298e-05, 6.376929488368658e-05, 5.745694743108364e-05, 7.493940757530068e-05, 6.775909471821867e-05, 0.0001221949604047142, 0.0001267207452871192, 0.00013739866926303245, 0.00012377390862029785, 0.00011206195448660494, 0.00010202477567137518, 0.00010646070793573817, 9.626635239615756e-05, 8.925188254015303e-05, 8.215056225796217e-05, 7.527679031531196e-05, 6.966879699955638e-05], "duration": 50053.269529, "accuracy_train": [0.10526507417404946, 0.10407780632844223, 0.12634804557724252, 0.1001955287929125, 0.10572938295957918, 0.10694134424603174, 0.09164294654392766, 0.10033647967423402, 0.09677395516103728, 0.10807922520994831, 0.10096426985280546, 0.10189252693567738, 0.09387544988925803, 0.11488974829272794, 0.11219077323274271, 0.09579955559016241, 0.08917792831764489, 0.10019805221022518, 0.10091956931755261, 0.1171190072443706, 0.09870527062569213, 0.10005205449427834, 0.10136134759136213, 0.11872516236387967, 0.10461186957825766, 0.09896356041205243, 0.10161206712578442, 0.09234085167497232, 0.12779035881552234, 0.0988015209717608, 0.11132542133859358, 0.10117497519841269, 0.1001665094938169, 0.10045490004383535, 0.10263477211378737, 0.10370650349529346, 0.10254176616140642, 0.09042665939922481, 0.10007350354143595, 0.1085202825073828, 0.10142605522102252, 0.10154231266149871, 0.1336282847683647, 0.1194165787075489, 0.10080223041251384, 0.112910127410945, 0.10974864600636766, 0.09363896963824289, 0.11375114635243631, 0.09894030892395718, 0.12118549424372463, 0.09808144581718346, 0.10607671332825766, 0.10461042762550757, 0.08936430071059431, 0.09182607454318938, 0.0990845041989664, 0.1090750738279808, 0.0992916046626984, 0.10398299793512367, 0.10463692350729052, 0.12335184800664452, 0.09042990379291252, 0.09786497266057587, 0.1044251366971207, 0.10444478330334071, 0.1054968680786268, 0.09908053882890366, 0.10093849494739757, 0.1016618144956626, 0.10042840416205243, 0.10261043916112958, 0.10529048859126984, 0.1112596322443706, 0.09703188445921003, 0.08438307493540052, 0.0973155886627907, 0.09547295329226653, 0.0993867735442045, 0.11621436213778147, 0.09988893358942413, 0.12764832646963825, 0.1178172728636028, 0.08943369468669252, 0.10279933497139167, 0.10109801097037652, 0.09994120437661498, 0.11593822818613879, 0.10221985020994831, 0.09884874492432633, 0.09919571480481727, 0.0993867735442045, 0.09824276428110004], "end": "2016-01-21 21:53:16.363000", "learning_rate_per_epoch": [0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843, 0.0023659677244722843], "accuracy_valid": [0.10486281061746988, 0.10936911709337349, 0.12927687311746988, 0.10245081890060241, 0.10147572712725904, 0.09957407756024096, 0.0956869470067771, 0.0978842126317771, 0.09838131824171686, 0.11037656485316265, 0.09588990728539157, 0.1027273155120482, 0.09496482021837349, 0.11217820500753012, 0.09967408697289157, 0.09560458631400602, 0.08708025461219879, 0.09799598785768072, 0.10083449030496988, 0.12253359139683735, 0.0979945171310241, 0.10129188629518072, 0.10231992422816265, 0.11721397307981928, 0.10619528896837349, 0.10353915662650602, 0.0954030967620482, 0.0911703454442771, 0.1265207313629518, 0.09280726421310241, 0.10889995528990964, 0.09828130882906627, 0.09863575395331325, 0.09961378717996988, 0.09687823559864459, 0.10756747693900602, 0.11160609233810241, 0.08837155261671686, 0.09839161332831325, 0.10359063205948796, 0.09553546216114459, 0.09590167309864459, 0.13335813958960843, 0.12052752023719879, 0.10341855704066265, 0.10767189853162651, 0.10661150461219879, 0.09658114881400602, 0.1155844079442771, 0.10353915662650602, 0.11782432464231928, 0.09198365728539157, 0.10811752870858433, 0.0990652061370482, 0.08924810570406627, 0.09263371846762047, 0.10205519342996988, 0.11240028473268072, 0.10417009836219879, 0.10507753670933735, 0.1066335655120482, 0.11458872599774096, 0.08636842291039157, 0.09606198230421686, 0.10689829631024096, 0.1000814782567771, 0.10879994587725904, 0.09479127447289157, 0.10202430817018072, 0.10403773296310241, 0.10279643966490964, 0.10510695124246988, 0.1086264001317771, 0.10791456842996988, 0.09747682134789157, 0.08685670416039157, 0.09961378717996988, 0.09729298051581325, 0.10217726374246988, 0.1161947595067771, 0.09677528473268072, 0.12521913827183734, 0.11345773719879518, 0.09098650461219879, 0.10909409120858433, 0.10174928228539157, 0.0973959313817771, 0.11357098315135541, 0.09820924322289157, 0.09353086172816265, 0.10402743787650602, 0.10192282803087349, 0.10024325818900602], "accuracy_test": 0.13415605095541402, "start": "2016-01-21 07:59:03.094000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0], "accuracy_train_last": 0.09824276428110004, "batch_size_eval": 1024, "accuracy_train_std": [0.008192632935903827, 0.009631892626816846, 0.010775775649320004, 0.00846196851878752, 0.009560154685053855, 0.010011637061323039, 0.008902910345926095, 0.00961909538547455, 0.009993162977552716, 0.009924556146149125, 0.009279599540271964, 0.00981763170304387, 0.008916588813915164, 0.009459925996080067, 0.0093964330749501, 0.007190231025471849, 0.011420029936181538, 0.0090966758882934, 0.009474437190799316, 0.008895510193782492, 0.009899075390034612, 0.008682491743540402, 0.010142791614578256, 0.009730121007025309, 0.008772227823932197, 0.009434891474407599, 0.007747934299994274, 0.008002994135414446, 0.009524414941183747, 0.009710528842802149, 0.009348986441746924, 0.010450577556660656, 0.009568234323089352, 0.009548537539622579, 0.008069095997652345, 0.011643275014382129, 0.009716526574460295, 0.008801723097214633, 0.009410526198896717, 0.009641222177566806, 0.00781982430790017, 0.007845627628707084, 0.01230333847294473, 0.012378906872612724, 0.009895626020513077, 0.008298015770644943, 0.01170792637629701, 0.0095705218310321, 0.010891273592945032, 0.009366842850068452, 0.008449810082900891, 0.008057109001159139, 0.008537495653395278, 0.010483406596246378, 0.009699301289707965, 0.00707673316059086, 0.009899932654997251, 0.00804398771399262, 0.009920565287027753, 0.009386478338131417, 0.010652539401462215, 0.011225811574063358, 0.009669448376125513, 0.00997683619607562, 0.009323378689219567, 0.010108255337037656, 0.00977733528216444, 0.009177272275801354, 0.009255724994129418, 0.010487275625210464, 0.010240233179461981, 0.008003067205583001, 0.010168157514598977, 0.008332256107513623, 0.007547147642846647, 0.007963335616116647, 0.010229130480669316, 0.008764618717299675, 0.009905608101798762, 0.01075810872070748, 0.010078719376724454, 0.008889897059568896, 0.00913245537278316, 0.007874325341476055, 0.00987117324358229, 0.009402517003158358, 0.009881589876885616, 0.010162921210604125, 0.009231430144347123, 0.009380535585099886, 0.009573170198526108, 0.009910191622354902, 0.008584459104001033], "accuracy_test_std": 0.042619485130031734, "error_valid": [0.8951371893825302, 0.8906308829066265, 0.8707231268825302, 0.8975491810993976, 0.898524272872741, 0.900425922439759, 0.9043130529932228, 0.9021157873682228, 0.9016186817582832, 0.8896234351468374, 0.9041100927146084, 0.8972726844879518, 0.9050351797816265, 0.8878217949924698, 0.9003259130271084, 0.904395413685994, 0.9129197453878012, 0.9020040121423193, 0.8991655096950302, 0.8774664086031626, 0.9020054828689759, 0.8987081137048193, 0.8976800757718374, 0.8827860269201807, 0.8938047110316265, 0.896460843373494, 0.9045969032379518, 0.9088296545557228, 0.8734792686370482, 0.9071927357868976, 0.8911000447100903, 0.9017186911709337, 0.9013642460466867, 0.9003862128200302, 0.9031217644013554, 0.892432523060994, 0.8883939076618976, 0.9116284473832832, 0.9016083866716867, 0.8964093679405121, 0.9044645378388554, 0.9040983269013554, 0.8666418604103916, 0.8794724797628012, 0.8965814429593374, 0.8923281014683735, 0.8933884953878012, 0.903418851185994, 0.8844155920557228, 0.896460843373494, 0.8821756753576807, 0.9080163427146084, 0.8918824712914156, 0.9009347938629518, 0.9107518942959337, 0.9073662815323795, 0.8979448065700302, 0.8875997152673193, 0.8958299016378012, 0.8949224632906626, 0.8933664344879518, 0.885411274002259, 0.9136315770896084, 0.9039380176957832, 0.893101703689759, 0.8999185217432228, 0.891200054122741, 0.9052087255271084, 0.8979756918298193, 0.8959622670368976, 0.8972035603350903, 0.8948930487575302, 0.8913735998682228, 0.8920854315700302, 0.9025231786521084, 0.9131432958396084, 0.9003862128200302, 0.9027070194841867, 0.8978227362575302, 0.8838052404932228, 0.9032247152673193, 0.8747808617281627, 0.8865422628012049, 0.9090134953878012, 0.8909059087914156, 0.8982507177146084, 0.9026040686182228, 0.8864290168486446, 0.9017907567771084, 0.9064691382718374, 0.895972562123494, 0.8980771719691265, 0.899756741810994], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.5822482905277321, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0023659676515466136, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "rmsprop", "nb_data_augmentation": 4, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 2.5070674846543978e-05, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.00037683697679228304}, "accuracy_valid_max": 0.13335813958960843, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-6, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.10024325818900602, "loss_train": [34683.046875, 16149.6455078125, 43320.71484375, 74769.625, 44208.87890625, 251886.890625, 698417.6875, 156734.890625, 77537.109375, 775575.9375, 286633.25, 48193.2734375, 6095.7802734375, 100874.6015625, 462232.71875, 102481.6015625, 176218.03125, 109940.0546875, 53371.30859375, 18800.1796875, 163189.5625, 227182.5625, 47865.10546875, 27866.990234375, 90614.46875, 23497.021484375, 13522.384765625, 14246.41796875, 7590065.0, 36752.2578125, 25767.765625, 24796.392578125, 18247.291015625, 11779.2529296875, 79525.7890625, 52816.1328125, 5386.57763671875, 23495.990234375, 25729.6171875, 105191.671875, 31960.673828125, 42099.03125, 40506.8984375, 134467.171875, 54382.875, 100174.296875, 32759.794921875, 48153.234375, 23660.513671875, 9183.2421875, 37389.6015625, 54391.6796875, 20543.91796875, 138560.765625, 48371.9296875, 26045.275390625, 10812.3173828125, 51749.23828125, 53989.70703125, 33576.28125, 102080.625, 8419.5517578125, 119163.6171875, 14191.2734375, 162159.59375, 108634.1015625, 77483.9296875, 26267.07421875, 114555.3046875, 54440.46484375, 333528.125, 103761.4296875, 140467.421875, 140005.78125, 51658.453125, 51466.515625, 135231.453125, 82356.8359375, 2408684.25, 48015.94140625, 41109.953125, 87034.6796875, 57357.75, 18431.763671875, 14657.328125, 44693.76171875, 72628.1484375, 84142.7578125, 4997.85009765625, 43449.8984375, 187209.046875, 34381.71484375, 47331.2421875], "accuracy_train_first": 0.10526507417404946, "model": "residualv2", "loss_std": [356109.46875, 219522.265625, 911551.375, 831422.125, 419919.78125, 4872450.5, 15554429.0, 1665489.375, 591999.125, 7649061.5, 3530602.5, 695476.0625, 42110.0859375, 1146235.375, 8860322.0, 988340.125, 3195439.75, 1402771.625, 692132.625, 135758.015625, 2851357.75, 4748376.5, 594581.125, 569404.0, 1091586.375, 178375.796875, 112693.5390625, 196434.34375, 137546608.0, 221139.9375, 423409.625, 207364.28125, 196460.5625, 104955.7890625, 1073807.0, 619066.625, 34508.0703125, 157273.78125, 300539.125, 1165503.25, 192251.5625, 382130.84375, 423623.375, 2371083.0, 631392.1875, 1338468.375, 539699.5, 516965.40625, 207218.734375, 75995.5703125, 381755.53125, 705917.0625, 251817.234375, 2004560.125, 530471.5, 286632.71875, 86779.6953125, 511806.15625, 383748.9375, 381028.625, 1433558.875, 59171.60546875, 1268986.375, 232238.953125, 3011828.25, 1292182.125, 978743.9375, 138090.828125, 1307691.5, 674644.9375, 6730267.5, 1281820.75, 1319879.5, 1644967.875, 439715.4375, 507684.59375, 1937487.75, 1016864.75, 54678400.0, 635501.75, 544645.5, 1066201.875, 786846.5, 144122.734375, 98151.375, 591073.0625, 908055.875, 1501696.125, 38503.21484375, 472221.96875, 2240500.25, 508555.625, 459566.8125]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:06 2016", "state": "available"}], "summary": "c2a0c09e6213ad53e4493caf0202642e"}