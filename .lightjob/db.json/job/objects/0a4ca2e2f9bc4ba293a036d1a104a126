{"content": {"hp_model": {"f0": 16, "f1": 32, "f2": 64, "f3": 16, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.019649334621563007, 0.013338530348251219, 0.019677016252505546, 0.018701243956690306, 0.027019010278530407, 0.02787701146611321, 0.0342388073990913, 0.030142332218165167, 0.025392679333567113, 0.022419879602977567, 0.02584171590465691, 0.03007303040401131, 0.03204120638234133, 0.025508880525357363, 0.022105296254753166, 0.024351719785318558, 0.020761894304452206, 0.023920229397007668, 0.028606184614741854, 0.02525296318819799, 0.028454831443272884, 0.027306898791875953, 0.024547629025576966, 0.026013860625692276, 0.024746386575786455, 0.025000232237327977, 0.023515556948647483, 0.026821535225942727, 0.025577071015986896, 0.02378254363955109, 0.024588246980713612, 0.03194479728780444, 0.027772027669298805, 0.025316826719142368, 0.025043738678215733, 0.025717848368669614, 0.025725607562802615, 0.022954894300738042, 0.023954337826420685, 0.02350243679573239, 0.028951043582776205, 0.027774640769386384, 0.026415290084653455, 0.024169240104910433, 0.02273968617474964, 0.027216385790333333, 0.027418958168675716, 0.025041565151356603, 0.022390727106875164, 0.02431145295835879, 0.02600548975967301, 0.02432040690364734, 0.031042619712737, 0.021215726758833167, 0.02503069468600564, 0.026404298025884804, 0.02600269887216125, 0.021800324008520753, 0.024435767143068044, 0.021875099530519283, 0.024643527211269983, 0.027249697577042573, 0.024696479819753963, 0.03081913035734793, 0.025561460095893346, 0.02652769608215198, 0.02255462197279664, 0.026700854315757198, 0.025623846712105998, 0.02500386066541595, 0.020704137184161447, 0.02402845087191954, 0.02239234768568573, 0.026849931404385085, 0.02648183176457612, 0.026717836784951376, 0.024180497844635405, 0.01976992617478504, 0.027967332661096356, 0.01871772979811743, 0.026453726321912667, 0.027223717880732287, 0.0230235567017473, 0.023994447795426168, 0.02482471317899947, 0.025024895173720658, 0.020180481124758252, 0.02484516909680274, 0.026550940208632842, 0.022621291169429663, 0.023446013861879483, 0.02248372064948778, 0.022161857838010644, 0.0244186836069497, 0.023741311472009488, 0.021215726758833167, 0.0227404840444776, 0.02066290869509123, 0.018895244454273978, 0.022535307371118564, 0.023016463193531914, 0.02234611513367213, 0.024940650699911936, 0.02309672871956834, 0.023933878601768613, 0.022812178045306827, 0.02515073279522372, 0.025330439650682122, 0.024781554362230885, 0.01950010522157882, 0.02140473853230739, 0.02411437741105625, 0.023077867828730687, 0.020811646461021512, 0.020544026305746855, 0.019681626072470985, 0.018518931113406235, 0.02117292373181957, 0.02314616543535624, 0.022535307371118564, 0.019194386153598822, 0.022882854553428793, 0.02304088719475582, 0.02119091153361028, 0.025783375245701293, 0.019043497233912632, 0.02079507563460112, 0.02085693087375637, 0.019715705240874987, 0.01998443106397956, 0.024788142767613073, 0.01944979671092895, 0.02098960492438667, 0.021380991291502664, 0.02113776057345694, 0.024569054134368322, 0.025258710335106304, 0.02326578869864646, 0.022085588705883168, 0.020506900114535126, 0.02224765390308468, 0.02404656618582414, 0.021529824541561597, 0.020519282975340218, 0.020617198128930474, 0.02403373591561524, 0.02010030480077668, 0.023083370513805945, 0.020483883513154184, 0.02149608928965478, 0.022770782378229267, 0.02463100789949361, 0.019748806905292297, 0.02677210829483803, 0.019653950934236015, 0.020727784549214808, 0.02267016401540983, 0.024373317106681388, 0.022640532418586955, 0.026215343740921403, 0.017825015290596196, 0.02363714881853289, 0.02426439053697713, 0.02241907032329773, 0.02169018694569389, 0.021339370030681128, 0.021990086570196677, 0.020774125171082677, 0.023795509350187052, 0.02238262245279024, 0.024327120199858047, 0.020838654783857876, 0.02382522755453589, 0.02173447570207969, 0.025160830305284206, 0.024037510235395344, 0.02336151227228319, 0.02034345344616007, 0.022368837801648583, 0.024146708879629913, 0.020762768176721652, 0.023493943380708808, 0.0228209251988657, 0.02210939978302456, 0.024639845721055195, 0.025094400860661895, 0.02193142750805049, 0.02147920179448022, 0.02378101779708075, 0.018952770194596815, 0.021388627208558213, 0.019628085599370737, 0.021749496650796778, 0.019016801620380493, 0.02162232509247965, 0.018418727154094063, 0.020387997956349307, 0.02021371926972421, 0.021773675271832098, 0.021030192953958773, 0.022791489610021712, 0.019314060699283323, 0.019852350831830703, 0.020203843370848407, 0.02174866242581322, 0.021308739340206787, 0.020034302677112942, 0.020824719378281085, 0.025364082354694974, 0.022990434938358062, 0.023770334157316875, 0.024324882640317506, 0.02569526284513526, 0.018621519028863637, 0.02155761638202986, 0.020996519066029985, 0.02185933488696206, 0.016264503069098685, 0.020799437658359503, 0.022178225534361454, 0.01868377250474106, 0.020281821362843438, 0.025617473237346065, 0.019221779056415114, 0.02790758443650592, 0.020910795657677835, 0.024217985848671207, 0.020489197331440594, 0.01954749992852558, 0.02130533321177387, 0.02352481382747945, 0.021818626134552464, 0.022204388752818573, 0.021330865917630427, 0.02283523149545349, 0.021131751259739637, 0.020161591855676356, 0.0218734406294036, 0.017631587553687482, 0.024397126445877635, 0.019481487587754618, 0.021442002487692784, 0.02489842157195257, 0.021157493444042955, 0.021237095921558587, 0.02227210636025815, 0.017753621110555395, 0.022905836871713492, 0.02374207568141441, 0.01801737349914436, 0.019111971875579687, 0.01898911302796246, 0.01942926330496278, 0.018841395302060505, 0.02019306415433998, 0.020348803935915365, 0.02085432098437948, 0.020526355541849367, 0.02003973570844729, 0.023308640513279383, 0.01761614517701704, 0.020835171806266463, 0.02111371305648674, 0.01893553082251643, 0.02014358560768332, 0.020590780489247156, 0.02007320690754004], "moving_avg_accuracy_train": [0.013709525602409636, 0.022113610692771082, 0.03015968561746988, 0.04030495576054217, 0.059015424039909635, 0.07497476266001506, 0.10005682329160391, 0.12961486460702182, 0.1671310701643919, 0.20418537655156715, 0.24711633061327787, 0.2884720921302633, 0.32736772930277913, 0.3637127523062362, 0.4054241201479017, 0.44590345135600307, 0.4832784676661859, 0.5114189943935432, 0.5439202613698515, 0.5682109347810591, 0.5935646342246399, 0.6199880089045856, 0.6436749196105126, 0.6682263847277745, 0.6897297063453585, 0.7105698945963648, 0.7276929691427524, 0.7441414809634169, 0.7595922613309306, 0.7746957234508496, 0.786629859690102, 0.7992131086608508, 0.811051022192356, 0.8226369967803493, 0.8330314296324348, 0.8420428574523239, 0.8510591101107059, 0.8579853903646956, 0.8657321261776236, 0.87180998660203, 0.8780307198695378, 0.88321992950909, 0.8885514568895062, 0.8935616161704352, 0.8985460983786928, 0.9011707807094982, 0.906161477487946, 0.9114037634740911, 0.9113472538435494, 0.9153626602363029, 0.919722478550022, 0.9227450537371885, 0.9252088766767227, 0.9279487194307371, 0.9313417239936875, 0.933974211985885, 0.9367034850644049, 0.9395598684856752, 0.9416646873599992, 0.9449073865456861, 0.946785717921238, 0.9492786446230901, 0.9497550535041546, 0.9502426505633776, 0.9527169736094495, 0.9554545006460948, 0.9566358013344974, 0.9585296383697224, 0.958937499080943, 0.9592763357692342, 0.9593600914995397, 0.9607555959038027, 0.9619150701989645, 0.9632103854682247, 0.9644938273430889, 0.9660913196087799, 0.9668278201780225, 0.9683448687325094, 0.9695807884857645, 0.9711661019564651, 0.9722634413090113, 0.9719285693166644, 0.9731049706681304, 0.9734483704386667, 0.9744280815875711, 0.9742838427059225, 0.9755541594895472, 0.976563314323725, 0.9775915649696657, 0.9786864182618558, 0.9792317448091641, 0.9789765861415007, 0.9795140743647001, 0.979851917681242, 0.9805983712444432, 0.981211350385059, 0.9813300496839026, 0.9821545936612954, 0.98297904393372, 0.9826833044499866, 0.9829113030712531, 0.9816740131255735, 0.9827488934395221, 0.9827350168967747, 0.9831437441227598, 0.983892810975544, 0.9842892979502788, 0.9847567348721183, 0.9809229100294847, 0.981630506074729, 0.9827826851359308, 0.9835513857488437, 0.9842949858787786, 0.9846041921101778, 0.9850471991039793, 0.9854694370249067, 0.9861788939248257, 0.9868385835986082, 0.9872346386423618, 0.9876875678504148, 0.9882269812460962, 0.9883806573684745, 0.9885848544328318, 0.9888580519714764, 0.989289829605654, 0.9890054249583417, 0.9890083086673268, 0.9894603580716785, 0.9900578087102938, 0.990066052688662, 0.9894498841667837, 0.9897471773766113, 0.9901912284642514, 0.9907250047142119, 0.9909206706584534, 0.9907367361227285, 0.9908300429321424, 0.9900174640907353, 0.9902838840973244, 0.9908578111996401, 0.9908284118567845, 0.9911737521470096, 0.9914822052455616, 0.9915480283957042, 0.9918496449838445, 0.9916928243107613, 0.9917517045302876, 0.9917435144989456, 0.9919691065731475, 0.9923886304037846, 0.9923285135983458, 0.992575613292728, 0.9928097688309251, 0.9929734455622905, 0.9925089323313626, 0.992975659580154, 0.9933957141040662, 0.993651398717756, 0.9937779757134503, 0.9939436645878884, 0.9941751452676537, 0.9944799575481172, 0.994420139504149, 0.994528671487469, 0.9946122312965534, 0.9947933274440065, 0.9945515700008106, 0.9946610779103682, 0.9942089949687289, 0.9944657121887236, 0.9946073375059958, 0.9946759712252757, 0.9943000533196157, 0.9946159064213891, 0.9948272261708164, 0.994970350692289, 0.9949556198399275, 0.9951141429462962, 0.9952850516938352, 0.9953682746871023, 0.9955631866762235, 0.9956021240326974, 0.9955971638884639, 0.9954609226502198, 0.9955383243611013, 0.9954362050274008, 0.9951442788017693, 0.9953874751685803, 0.9954439836758187, 0.995447778079321, 0.9956017954521118, 0.9957474705755753, 0.995431477283078, 0.995215325036698, 0.9954514167800161, 0.9956121297706892, 0.9957238271851866, 0.9957631726293186, 0.9958762378965073, 0.9959897624502301, 0.9961648825907492, 0.9962236578858912, 0.9964012732720009, 0.9963964057339574, 0.9964179097388749, 0.9965243303613729, 0.9965236292529465, 0.9966006526228325, 0.9966417357039228, 0.996471632163651, 0.9965232641280087, 0.9966285619621958, 0.9967798059165787, 0.9968876875237159, 0.9968553570243565, 0.997014512586981, 0.9971648120812949, 0.9972859626502739, 0.9973620538852465, 0.9974493612979266, 0.9974385177886159, 0.997318159985658, 0.9973651466979356, 0.9973438993474192, 0.9974518475150869, 0.9974454617093613, 0.9975456068034855, 0.9975604361833779, 0.9975926079264859, 0.9975956777061264, 0.9976431505981643, 0.9977141141528058, 0.9977638623760794, 0.9979051154457004, 0.9978604623348654, 0.9978226276977643, 0.9978921156809999, 0.9978817068237433, 0.9979264615931762, 0.9978914396808466, 0.9978740389356534, 0.9979077946806423, 0.9979264090378792, 0.9979666935858985, 0.9980170686550195, 0.9980365214280718, 0.9980093188334573, 0.998010721287461, 0.9980402214478715, 0.9981138348452531, 0.9981094920233783, 0.9978490887547754, 0.9979488749094183, 0.9978857268763078, 0.9979936150320505, 0.997965996751737, 0.998058798431985, 0.9978764125646902, 0.9979311094106308, 0.9979779834093268, 0.9979636941045387, 0.9980873171639643, 0.9980903324355197, 0.9981871726859436, 0.9982390314715661, 0.9982080500111564, 0.9982531147389564], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234423, "moving_var_accuracy_train": [0.0016915598301881281, 0.0021580616630236353, 0.002524909391966072, 0.0031987570092526915, 0.006029615917426369, 0.007718958728404427, 0.012609050745304278, 0.019211245928409424, 0.029957312450374106, 0.039318775801848616, 0.05197449957150223, 0.06216974071019999, 0.06956860195868395, 0.07450038803691193, 0.08270889309822532, 0.08918519008389933, 0.0928386976731873, 0.09068183110630658, 0.09112063919126336, 0.08731890660506655, 0.08437230662383878, 0.08221882852674603, 0.07904657332318646, 0.07656688594550501, 0.0730717329162578, 0.06967338064166846, 0.06534483971479195, 0.061245337613343616, 0.057269343377695583, 0.05359544015199647, 0.04951770860679016, 0.04599098113804981, 0.04265310879525939, 0.039595911180116086, 0.03660871817095312, 0.03367869883603544, 0.031042464260429937, 0.028369978057798204, 0.0260730874938161, 0.023798242230481572, 0.021766695708902724, 0.019832377208161448, 0.018104966145218462, 0.01652038479487912, 0.015091951881351146, 0.013644757309254811, 0.012504445067339012, 0.011501334621849917, 0.010351229899710022, 0.00946121830622971, 0.008686168617164505, 0.007899775402306724, 0.007164431673372424, 0.0065155491508857135, 0.0059676065554749615, 0.005433215837189042, 0.004956934637304341, 0.004534671509817681, 0.004121076721279309, 0.0038036049312310644, 0.0034549975969154017, 0.0031654299890911267, 0.002850929678979628, 0.0025679764691111328, 0.002366279293026921, 0.002197097852211511, 0.001989947308838143, 0.0018232321463982357, 0.001642406084996228, 0.0014791987692085948, 0.0013313420274889663, 0.0012157347176209236, 0.0011062606716291021, 0.001010735179287199, 0.0009244866687738754, 0.0008550058357469744, 0.0007743871499687275, 0.0007176613618218922, 0.000659642704368078, 0.0006162974031347351, 0.0005655050457130814, 0.0005099637944030989, 0.00047142269622037035, 0.00042534173721997314, 0.0003914460689155644, 0.0003524887057188213, 0.0003317631777237646, 0.00030775240126548823, 0.00028649285565683765, 0.00026863190367392857, 0.0002444451426953295, 0.00022058658193695036, 0.00020112796605395702, 0.0001820424124073505, 0.000168852907464756, 0.00015534930755975253, 0.00013994118251569072, 0.00013206591920001548, 0.000124976791545324, 0.00011326626897094195, 0.00010240749241554216, 0.0001059447208611045, 0.00010574855797882377, 9.517543520688898e-05, 8.716141319355397e-05, 8.349518222365957e-05, 7.65604812915025e-05, 7.087090864544211e-05, 0.0001960677340968434, 0.00018096719015636738, 0.00017481812044237732, 0.00016265441408877423, 0.00015136544305904972, 0.00013708937519496992, 0.0001251467344444863, 0.00011423662475685925, 0.00010734292411675689, 0.00010052534589633847, 9.18845476858489e-05, 8.45423967248315e-05, 7.870685835531327e-05, 7.104871967508511e-05, 6.431911567740611e-05, 5.8558936165758376e-05, 5.4380929877567095e-05, 4.9670810920526336e-05, 4.47038046704713e-05, 4.207256217919637e-05, 4.1077831351513015e-05, 3.697065988497574e-05, 3.6690566722660746e-05, 3.381695932388134e-05, 3.220989570740218e-05, 3.155315990185797e-05, 2.8742410367295304e-05, 2.617265655145662e-05, 2.363374634245797e-05, 2.7212931069733325e-05, 2.5130454541958527e-05, 2.5581939956715684e-05, 2.303152485328717e-05, 2.180171161243364e-05, 2.0477830277247556e-05, 1.8469041433375098e-05, 1.7440890386210822e-05, 1.591813585914629e-05, 1.4357524195494828e-05, 1.2922375465465794e-05, 1.2088163974403351e-05, 1.2463349777214546e-05, 1.1249541072158473e-05, 1.0674111295616992e-05, 1.010015951067057e-05, 9.33125421111743e-06, 1.034008166536888e-05, 1.1266582421711987e-05, 1.1727936407073643e-05, 1.114351436146545e-05, 1.017335854786982e-05, 9.403097921095938e-06, 8.945037874928108e-06, 8.886728824327756e-06, 8.030259727352782e-06, 7.3332464772479285e-06, 6.662762004771165e-06, 6.291648135895232e-06, 6.188503274370978e-06, 5.6775807872347445e-06, 6.9492335836018955e-06, 6.847443804617366e-06, 6.34321899858774e-06, 5.751292385528737e-06, 6.447991593138806e-06, 6.7010610709236264e-06, 6.4328592923136165e-06, 5.9739350209030244e-06, 5.378494500914371e-06, 5.066811228097953e-06, 4.823018305156485e-06, 4.403051074115831e-06, 4.304662118232512e-06, 3.8878409659719454e-06, 3.4992782966521143e-06, 3.3164055419711476e-06, 3.0386842114006705e-06, 2.82867101509951e-06, 3.3127922044934225e-06, 3.513813239514833e-06, 3.191170818076121e-06, 2.8721833137499657e-06, 2.7984571424673476e-06, 2.7096026025856117e-06, 3.3373081904565805e-06, 3.4240735139473453e-06, 3.583319963919662e-06, 3.4574459558674736e-06, 3.223988171929232e-06, 2.915521930501767e-06, 2.7390235292515066e-06, 2.5811115950079278e-06, 2.5990040080461884e-06, 2.3701944251127716e-06, 2.4171000110474875e-06, 2.1756032462821794e-06, 1.9622047217013946e-06, 1.8679123895671115e-06, 1.6811255745876311e-06, 1.5664064127063373e-06, 1.4249561474025088e-06, 1.5428774623792343e-06, 1.4125824538323094e-06, 1.3711129134094816e-06, 1.439874225704733e-06, 1.400632773561039e-06, 1.2699768469044755e-06, 1.370953600243181e-06, 1.4371676821381153e-06, 1.4255480571995973e-06, 1.335102135836553e-06, 1.2701951810330507e-06, 1.1442338981772934e-06, 1.1601845149554215e-06, 1.0640358236357759e-06, 9.61695290407919e-07, 9.70401023492485e-07, 8.737279277761168e-07, 8.766164938926322e-07, 7.909340390753105e-07, 7.211558246592444e-07, 6.49125054116695e-07, 6.044956280110582e-07, 5.89368499996039e-07, 5.527056214663887e-07, 6.770069264158737e-07, 6.272513365395576e-07, 5.774093407666773e-07, 5.631256250173919e-07, 5.077881613001509e-07, 4.7503624965306266e-07, 4.385714337768012e-07, 3.974393637985953e-07, 3.6795048029651993e-07, 3.3427388092498166e-07, 3.1545209611456424e-07, 3.067457148036083e-07, 2.7947683673805355e-07, 2.581889834480494e-07, 2.323877869983359e-07, 2.1698134347672277e-07, 2.4405359959549804e-07, 2.1981798055246652e-07, 8.081249431888586e-07, 8.169279387958081e-07, 7.711242116877582e-07, 7.987704778650491e-07, 7.257583547458148e-07, 7.306918859828876e-07, 9.570041386847896e-07, 8.88229429418974e-07, 8.191810322608181e-07, 7.391005871166802e-07, 8.027344758008352e-07, 7.225428549837258e-07, 7.346908764048918e-07, 6.854257915805698e-07, 6.255218704245317e-07, 5.812471506072854e-07], "duration": 80006.642794, "accuracy_train": [0.1370952560240964, 0.0977503765060241, 0.10257435993975904, 0.13161238704819278, 0.22740963855421686, 0.21860881024096385, 0.3257953689759036, 0.39563723644578314, 0.5047769201807228, 0.5376741340361446, 0.6334949171686747, 0.6606739457831325, 0.6774284638554217, 0.6908179593373494, 0.7808264307228916, 0.8102174322289156, 0.8196536144578314, 0.764683734939759, 0.8364316641566265, 0.7868269954819277, 0.8217479292168675, 0.8577983810240963, 0.8568571159638554, 0.8891895707831325, 0.8832596009036144, 0.8981315888554217, 0.881800640060241, 0.8921780873493976, 0.8986492846385542, 0.9106268825301205, 0.8940370858433735, 0.9124623493975904, 0.9175922439759037, 0.9269107680722891, 0.9265813253012049, 0.9231457078313253, 0.9322053840361446, 0.9203219126506024, 0.9354527484939759, 0.9265107304216867, 0.9340173192771084, 0.9299228162650602, 0.936535203313253, 0.9386530496987951, 0.9434064382530121, 0.924792921686747, 0.9510777484939759, 0.9585843373493976, 0.9108386671686747, 0.9515013177710844, 0.958960843373494, 0.9499482304216867, 0.9473832831325302, 0.9526073042168675, 0.961878765060241, 0.9576666039156626, 0.9612669427710844, 0.9652673192771084, 0.9606080572289156, 0.9740916792168675, 0.9636907003012049, 0.971714984939759, 0.9540427334337349, 0.9546310240963856, 0.9749858810240963, 0.9800922439759037, 0.9672675075301205, 0.975574171686747, 0.9626082454819277, 0.9623258659638554, 0.9601138930722891, 0.9733151355421686, 0.9723503388554217, 0.9748682228915663, 0.9760448042168675, 0.98046875, 0.9734563253012049, 0.9819983057228916, 0.9807040662650602, 0.9854339231927711, 0.9821394954819277, 0.9689147213855421, 0.9836925828313253, 0.976538968373494, 0.9832454819277109, 0.9729856927710844, 0.9869870105421686, 0.9856457078313253, 0.9868458207831325, 0.9885400978915663, 0.9841396837349398, 0.9766801581325302, 0.984351468373494, 0.9828925075301205, 0.987316453313253, 0.9867281626506024, 0.982398343373494, 0.9895754894578314, 0.9903990963855421, 0.9800216490963856, 0.9849632906626506, 0.9705384036144579, 0.9924228162650602, 0.9826101280120482, 0.9868222891566265, 0.9906344126506024, 0.9878576807228916, 0.9889636671686747, 0.9464184864457831, 0.9879988704819277, 0.993152296686747, 0.9904696912650602, 0.9909873870481928, 0.9873870481927711, 0.9890342620481928, 0.989269578313253, 0.9925640060240963, 0.9927757906626506, 0.9907991340361446, 0.9917639307228916, 0.9930817018072289, 0.9897637424698795, 0.9904226280120482, 0.9913168298192772, 0.993175828313253, 0.9864457831325302, 0.9890342620481928, 0.9935288027108434, 0.9954348644578314, 0.9901402484939759, 0.9839043674698795, 0.9924228162650602, 0.9941876882530121, 0.9955289909638554, 0.9926816641566265, 0.9890813253012049, 0.9916698042168675, 0.9827042545180723, 0.9926816641566265, 0.9960231551204819, 0.9905638177710844, 0.9942818147590361, 0.9942582831325302, 0.9921404367469879, 0.9945641942771084, 0.9902814382530121, 0.9922816265060241, 0.9916698042168675, 0.9939994352409639, 0.9961643448795181, 0.9917874623493976, 0.9947995105421686, 0.9949171686746988, 0.9944465361445783, 0.9883283132530121, 0.9971762048192772, 0.9971762048192772, 0.9959525602409639, 0.9949171686746988, 0.9954348644578314, 0.9962584713855421, 0.9972232680722891, 0.9938817771084337, 0.9955054593373494, 0.9953642695783133, 0.9964231927710844, 0.9923757530120482, 0.9956466490963856, 0.9901402484939759, 0.9967761671686747, 0.9958819653614458, 0.9952936746987951, 0.9909167921686747, 0.9974585843373494, 0.9967291039156626, 0.9962584713855421, 0.9948230421686747, 0.9965408509036144, 0.9968232304216867, 0.996117281626506, 0.9973173945783133, 0.9959525602409639, 0.9955525225903614, 0.9942347515060241, 0.9962349397590361, 0.9945171310240963, 0.9925169427710844, 0.9975762424698795, 0.9959525602409639, 0.9954819277108434, 0.9969879518072289, 0.997058546686747, 0.9925875376506024, 0.9932699548192772, 0.9975762424698795, 0.997058546686747, 0.9967291039156626, 0.996117281626506, 0.9968938253012049, 0.9970114834337349, 0.9977409638554217, 0.9967526355421686, 0.9979998117469879, 0.9963525978915663, 0.9966114457831325, 0.9974821159638554, 0.9965173192771084, 0.9972938629518072, 0.9970114834337349, 0.9949407003012049, 0.9969879518072289, 0.9975762424698795, 0.9981410015060241, 0.9978586219879518, 0.9965643825301205, 0.9984469126506024, 0.9985175075301205, 0.9983763177710844, 0.998046875, 0.9982351280120482, 0.9973409262048193, 0.9962349397590361, 0.9977880271084337, 0.9971526731927711, 0.9984233810240963, 0.9973879894578314, 0.9984469126506024, 0.9976939006024096, 0.9978821536144579, 0.9976233057228916, 0.998070406626506, 0.9983527861445783, 0.9982115963855421, 0.9991763930722891, 0.9974585843373494, 0.9974821159638554, 0.9985175075301205, 0.9977880271084337, 0.9983292545180723, 0.9975762424698795, 0.9977174322289156, 0.9982115963855421, 0.9980939382530121, 0.9983292545180723, 0.9984704442771084, 0.9982115963855421, 0.9977644954819277, 0.998023343373494, 0.9983057228915663, 0.9987763554216867, 0.998070406626506, 0.9955054593373494, 0.9988469503012049, 0.9973173945783133, 0.9989646084337349, 0.9977174322289156, 0.9988940135542169, 0.9962349397590361, 0.9984233810240963, 0.9983998493975904, 0.9978350903614458, 0.9991999246987951, 0.9981174698795181, 0.999058734939759, 0.9987057605421686, 0.9979292168674698, 0.9986586972891566], "end": "2016-01-21 06:44:18.227000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0], "accuracy_valid": [0.13173491379310345, 0.09832974137931035, 0.10183189655172414, 0.13321659482758622, 0.2260237068965517, 0.21861530172413793, 0.31640625, 0.38591056034482757, 0.4888200431034483, 0.5243803879310345, 0.6111260775862069, 0.6342941810344828, 0.6462823275862069, 0.6597521551724138, 0.7378771551724138, 0.7601023706896551, 0.767645474137931, 0.7271012931034483, 0.771551724137931, 0.73046875, 0.7592941810344828, 0.7869073275862069, 0.787176724137931, 0.8053609913793104, 0.8005118534482759, 0.8122306034482759, 0.8009159482758621, 0.798760775862069, 0.8076508620689655, 0.8084590517241379, 0.8030711206896551, 0.8091325431034483, 0.8127693965517241, 0.8209859913793104, 0.8125, 0.8108836206896551, 0.8213900862068966, 0.8091325431034483, 0.8177532327586207, 0.8153286637931034, 0.8204471982758621, 0.8118265086206896, 0.8209859913793104, 0.8176185344827587, 0.8234105603448276, 0.8036099137931034, 0.8257004310344828, 0.8348599137931034, 0.8032058189655172, 0.8251616379310345, 0.8329741379310345, 0.8235452586206896, 0.8275862068965517, 0.8275862068965517, 0.8328394396551724, 0.8297413793103449, 0.8336476293103449, 0.837823275862069, 0.8305495689655172, 0.8403825431034483, 0.8332435344827587, 0.841864224137931, 0.8302801724137931, 0.8263739224137931, 0.8387661637931034, 0.8432112068965517, 0.8335129310344828, 0.8436153017241379, 0.8362068965517241, 0.8371497844827587, 0.8316271551724138, 0.8368803879310345, 0.8360721982758621, 0.8391702586206896, 0.8422683189655172, 0.8441540948275862, 0.841729525862069, 0.8491379310344828, 0.8424030172413793, 0.8512931034482759, 0.84765625, 0.8333782327586207, 0.8481950431034483, 0.8386314655172413, 0.845770474137931, 0.8332435344827587, 0.8515625, 0.8459051724137931, 0.8487338362068966, 0.8502155172413793, 0.8406519396551724, 0.8406519396551724, 0.8471174568965517, 0.845635775862069, 0.853448275862069, 0.8510237068965517, 0.8461745689655172, 0.8560075431034483, 0.8529094827586207, 0.8498114224137931, 0.8500808189655172, 0.8375538793103449, 0.8566810344827587, 0.8479256465517241, 0.8511584051724138, 0.8538523706896551, 0.8527747844827587, 0.8521012931034483, 0.8259698275862069, 0.8519665948275862, 0.8601831896551724, 0.8533135775862069, 0.8566810344827587, 0.8537176724137931, 0.8561422413793104, 0.8566810344827587, 0.8622036637931034, 0.859375, 0.8566810344827587, 0.8615301724137931, 0.8581627155172413, 0.8537176724137931, 0.8556034482758621, 0.8599137931034483, 0.8588362068965517, 0.853448275862069, 0.8551993534482759, 0.8585668103448276, 0.8585668103448276, 0.8499461206896551, 0.8504849137931034, 0.8553340517241379, 0.8564116379310345, 0.8617995689655172, 0.8572198275862069, 0.857354525862069, 0.8568157327586207, 0.8484644396551724, 0.8577586206896551, 0.865301724137931, 0.8558728448275862, 0.8553340517241379, 0.8592403017241379, 0.8581627155172413, 0.8591056034482759, 0.8565463362068966, 0.8551993534482759, 0.8589709051724138, 0.8588362068965517, 0.8605872844827587, 0.8560075431034483, 0.8609913793103449, 0.861395474137931, 0.8659752155172413, 0.8522359913793104, 0.8619342672413793, 0.8640894396551724, 0.8577586206896551, 0.8620689655172413, 0.8600484913793104, 0.8669181034482759, 0.8591056034482759, 0.8592403017241379, 0.861260775862069, 0.8561422413793104, 0.8599137931034483, 0.8577586206896551, 0.8605872844827587, 0.8547952586206896, 0.8626077586206896, 0.8640894396551724, 0.8584321120689655, 0.8578933189655172, 0.8643588362068966, 0.8615301724137931, 0.8600484913793104, 0.861260775862069, 0.8619342672413793, 0.8634159482758621, 0.8626077586206896, 0.8662446120689655, 0.8655711206896551, 0.8604525862068966, 0.8570851293103449, 0.8674568965517241, 0.8578933189655172, 0.8587015086206896, 0.8657058189655172, 0.8617995689655172, 0.8628771551724138, 0.8677262931034483, 0.8644935344827587, 0.8577586206896551, 0.8603178879310345, 0.8658405172413793, 0.8679956896551724, 0.86328125, 0.8646282327586207, 0.8688038793103449, 0.8658405172413793, 0.861260775862069, 0.8634159482758621, 0.8688038793103449, 0.8661099137931034, 0.8634159482758621, 0.8670528017241379, 0.8647629310344828, 0.8644935344827587, 0.8597790948275862, 0.8568157327586207, 0.8630118534482759, 0.8646282327586207, 0.8647629310344828, 0.8688038793103449, 0.869073275862069, 0.8669181034482759, 0.8704202586206896, 0.8663793103448276, 0.8683997844827587, 0.8657058189655172, 0.8666487068965517, 0.8643588362068966, 0.865167025862069, 0.8644935344827587, 0.8659752155172413, 0.8616648706896551, 0.8675915948275862, 0.8669181034482759, 0.8659752155172413, 0.8628771551724138, 0.8643588362068966, 0.8663793103448276, 0.8655711206896551, 0.8702855603448276, 0.8648976293103449, 0.8636853448275862, 0.8697467672413793, 0.8681303879310345, 0.8647629310344828, 0.865167025862069, 0.8662446120689655, 0.8661099137931034, 0.8644935344827587, 0.8640894396551724, 0.8654364224137931, 0.8624730603448276, 0.8648976293103449, 0.8693426724137931, 0.8662446120689655, 0.8673221982758621, 0.8659752155172413, 0.8642241379310345, 0.8677262931034483, 0.8636853448275862, 0.8670528017241379, 0.8670528017241379, 0.8685344827586207, 0.8624730603448276, 0.865167025862069, 0.8685344827586207, 0.8682650862068966, 0.8694773706896551, 0.869073275862069, 0.8677262931034483, 0.8689385775862069, 0.8661099137931034, 0.8661099137931034], "accuracy_test": 0.8588741987179487, "start": "2016-01-20 08:30:51.584000", "learning_rate_per_epoch": [0.00246377638541162, 0.001742152962833643, 0.0014224619371816516, 0.00123188819270581, 0.0011018343502655625, 0.0010058324551209807, 0.0009312199545092881, 0.0008710764814168215, 0.0008212588145397604, 0.0007791144889779389, 0.0007428565295413136, 0.0007112309685908258, 0.000683328602463007, 0.0006584719521924853, 0.000636144308373332, 0.000615944096352905, 0.0005975535605102777, 0.0005807176930829883, 0.000565229041967541, 0.0005509171751327813, 0.0005376400658860803, 0.0005252789123915136, 0.0005137328989803791, 0.0005029162275604904, 0.0004927552654407918, 0.00048318630433641374, 0.00047415398876182735, 0.00046560997725464404, 0.00045751177822239697, 0.0004498219641391188, 0.0004425072984304279, 0.00043553824070841074, 0.0004288884229026735, 0.00042253415449522436, 0.0004164542187936604, 0.0004106294072698802, 0.000405042344937101, 0.00039967731572687626, 0.00039451997145079076, 0.00038955724448896945, 0.0003847772313747555, 0.00038016895996406674, 0.0003757223894353956, 0.0003714282647706568, 0.00036727808765135705, 0.00036326400004327297, 0.0003593787259887904, 0.0003556154842954129, 0.00035196804674342275, 0.0003484305925667286, 0.0003449977084528655, 0.0003416643012315035, 0.00033842571428976953, 0.00033527749474160373, 0.0003322155389469117, 0.00032923597609624267, 0.00032633516821078956, 0.0003235096810385585, 0.0003207563713658601, 0.000318072154186666, 0.00031545423553325236, 0.00031289990874938667, 0.0003104066418018192, 0.0003079720481764525, 0.000305593857774511, 0.0003032699169125408, 0.00030099818832241, 0.0002987767802551389, 0.0002966038300655782, 0.00029447759152390063, 0.00029239646391943097, 0.00029035884654149413, 0.00028836322599090636, 0.00028640817617997527, 0.0002844923874363303, 0.0002826145209837705, 0.00028077338356524706, 0.00027896775281988084, 0.00027719649369828403, 0.00027545858756639063, 0.0002737529284786433, 0.0002720785851124674, 0.0002704345970414579, 0.00026882003294304013, 0.00026723407790996134, 0.00026567582972347736, 0.0002641445607878268, 0.0002626394561957568, 0.000261159788351506, 0.00025970482965931296, 0.00025827393983490765, 0.00025686644949018955, 0.0002554817183408886, 0.00025411913520656526, 0.00025277811801061034, 0.0002514581137802452, 0.00025015859864652157, 0.00024887899053283036, 0.0002476188528817147, 0.0002463776327203959, 0.0002451549225952476, 0.00024395021318923682, 0.0002427630970487371, 0.00024159315216820687, 0.00024043995654210448, 0.00023930311726871878, 0.00023818225599825382, 0.00023707699438091367, 0.00023598698317073286, 0.00023491185856983066, 0.00023385130043607205, 0.00023280498862732202, 0.0002317725884495303, 0.00023075380886439234, 0.0002297483297297731, 0.00022875588911119848, 0.00022777621052227914, 0.0002268090029247105, 0.0002258540189359337, 0.0002249109820695594, 0.00022397967404685915, 0.00022305983293335885, 0.00022215124045033008, 0.00022125364921521395, 0.00022036685550119728, 0.00021949064102955163, 0.0002186248020734638, 0.00021776912035420537, 0.0002169234212487936, 0.00021608748647850007, 0.00021526114142034203, 0.00021444421145133674, 0.00021363650739658624, 0.000212837869185023, 0.00021204810764174908, 0.00021126707724761218, 0.00021049461793154478, 0.00020973056962247938, 0.0002089747868012637, 0.0002082271093968302, 0.00020748740644194186, 0.00020675551786553115, 0.00020603132725227624, 0.0002053147036349401, 0.00020460548694245517, 0.00020390358986333013, 0.00020320885232649744, 0.0002025211724685505, 0.0002018404338741675, 0.00020116650557611138, 0.00020049928571097553, 0.00019983865786343813, 0.00019918452017009258, 0.00019853675621561706, 0.0001978952786885202, 0.00019725998572539538, 0.0001966307609109208, 0.0001960075314855203, 0.00019539018103387207, 0.00019477862224448472, 0.00019417278235778213, 0.00019357255951035768, 0.00019297786639072, 0.00019238861568737775, 0.00019180473464075476, 0.00019122613593935966, 0.00019065274682361633, 0.00019008447998203337, 0.00018952126265503466, 0.00018896302208304405, 0.0001884096855064854, 0.0001878611947176978, 0.00018731744785327464, 0.00018677840125747025, 0.0001862439967226237, 0.0001857141323853284, 0.0001851887791417539, 0.00018466784968040884, 0.0001841513003455475, 0.00018363904382567853, 0.00018313105101697147, 0.0001826272637117654, 0.00018212759459856898, 0.00018163200002163649, 0.00018114043632522225, 0.00018065284530166537, 0.0001801691687433049, 0.0001796893629943952, 0.00017921336984727532, 0.00017874113109428436, 0.00017827260307967663, 0.00017780774214770645, 0.00017734650464262813, 0.00017688883235678077, 0.0001764346961863339, 0.00017598402337171137, 0.00017553679936099797, 0.00017509296594653279, 0.00017465247947257012, 0.0001742152962833643, 0.00017378138727508485, 0.0001733507087919861, 0.00017292320262640715, 0.00017249885422643274, 0.00017207760538440198, 0.00017165944154839963, 0.00017124430451076478, 0.00017083215061575174, 0.00017042297986336052, 0.00017001671949401498, 0.0001696133695077151, 0.00016921285714488477, 0.00016881518240552396, 0.00016842028708197176, 0.00016802815662231296, 0.00016763874737080187, 0.00016725204477552325, 0.0001668679906288162, 0.0001664865849306807, 0.00016610776947345585, 0.00016573152970522642, 0.0001653578510740772, 0.00016498667537234724, 0.00016461798804812133, 0.00016425175999756902, 0.00016388796211685985, 0.0001635265798540786, 0.00016316758410539478, 0.00016281093121506274, 0.00016245660663116723, 0.0001621045812498778, 0.00016175484051927924, 0.00016140735533554107, 0.00016106209659483284, 0.00016071904974523932, 0.00016037818568293005, 0.00016003947530407459, 0.0001597029040567577, 0.0001593684428371489, 0.000159036077093333, 0.00015870579227339476, 0.0001583775447215885, 0.0001580513344379142, 0.00015772711776662618, 0.00015740489470772445, 0.00015708465070929378, 0.00015676634211558849, 0.00015644995437469333, 0.00015613548748660833, 0.00015582289779558778, 0.0001555121853016317, 0.0001552033209009096, 0.0001548962900415063, 0.00015459107817150652, 0.00015428765618707985, 0.00015398602408822626, 0.0001536861527711153, 0.00015338801313191652, 0.00015309161972254515, 0.0001527969288872555, 0.00015250392607413232, 0.00015221261128317565, 0.000151922955410555, 0.0001516349584562704, 0.00015134857676457614, 0.00015106382488738745, 0.0001507806737208739], "accuracy_train_last": 0.9986586972891566, "error_valid": [0.8682650862068966, 0.9016702586206896, 0.8981681034482758, 0.8667834051724138, 0.7739762931034483, 0.7813846982758621, 0.68359375, 0.6140894396551724, 0.5111799568965517, 0.4756196120689655, 0.38887392241379315, 0.36570581896551724, 0.35371767241379315, 0.3402478448275862, 0.2621228448275862, 0.23989762931034486, 0.23235452586206895, 0.2728987068965517, 0.22844827586206895, 0.26953125, 0.24070581896551724, 0.21309267241379315, 0.21282327586206895, 0.1946390086206896, 0.1994881465517241, 0.1877693965517241, 0.1990840517241379, 0.20123922413793105, 0.19234913793103448, 0.1915409482758621, 0.19692887931034486, 0.1908674568965517, 0.1872306034482759, 0.1790140086206896, 0.1875, 0.18911637931034486, 0.17860991379310343, 0.1908674568965517, 0.18224676724137934, 0.18467133620689657, 0.1795528017241379, 0.1881734913793104, 0.1790140086206896, 0.18238146551724133, 0.17658943965517238, 0.19639008620689657, 0.17429956896551724, 0.16514008620689657, 0.19679418103448276, 0.17483836206896552, 0.16702586206896552, 0.1764547413793104, 0.1724137931034483, 0.1724137931034483, 0.16716056034482762, 0.17025862068965514, 0.16635237068965514, 0.16217672413793105, 0.16945043103448276, 0.1596174568965517, 0.16675646551724133, 0.15813577586206895, 0.16971982758620685, 0.17362607758620685, 0.16123383620689657, 0.1567887931034483, 0.16648706896551724, 0.1563846982758621, 0.1637931034482759, 0.16285021551724133, 0.1683728448275862, 0.16311961206896552, 0.1639278017241379, 0.1608297413793104, 0.15773168103448276, 0.1558459051724138, 0.15827047413793105, 0.15086206896551724, 0.15759698275862066, 0.1487068965517241, 0.15234375, 0.16662176724137934, 0.1518049568965517, 0.16136853448275867, 0.15422952586206895, 0.16675646551724133, 0.1484375, 0.15409482758620685, 0.15126616379310343, 0.14978448275862066, 0.15934806034482762, 0.15934806034482762, 0.1528825431034483, 0.15436422413793105, 0.14655172413793105, 0.1489762931034483, 0.15382543103448276, 0.1439924568965517, 0.14709051724137934, 0.15018857758620685, 0.14991918103448276, 0.16244612068965514, 0.14331896551724133, 0.1520743534482759, 0.1488415948275862, 0.14614762931034486, 0.14722521551724133, 0.1478987068965517, 0.17403017241379315, 0.1480334051724138, 0.13981681034482762, 0.14668642241379315, 0.14331896551724133, 0.14628232758620685, 0.1438577586206896, 0.14331896551724133, 0.13779633620689657, 0.140625, 0.14331896551724133, 0.13846982758620685, 0.14183728448275867, 0.14628232758620685, 0.1443965517241379, 0.1400862068965517, 0.1411637931034483, 0.14655172413793105, 0.1448006465517241, 0.14143318965517238, 0.14143318965517238, 0.15005387931034486, 0.14951508620689657, 0.1446659482758621, 0.14358836206896552, 0.13820043103448276, 0.14278017241379315, 0.14264547413793105, 0.14318426724137934, 0.15153556034482762, 0.14224137931034486, 0.13469827586206895, 0.1441271551724138, 0.1446659482758621, 0.1407596982758621, 0.14183728448275867, 0.1408943965517241, 0.14345366379310343, 0.1448006465517241, 0.1410290948275862, 0.1411637931034483, 0.13941271551724133, 0.1439924568965517, 0.13900862068965514, 0.13860452586206895, 0.13402478448275867, 0.1477640086206896, 0.13806573275862066, 0.13591056034482762, 0.14224137931034486, 0.13793103448275867, 0.1399515086206896, 0.1330818965517241, 0.1408943965517241, 0.1407596982758621, 0.13873922413793105, 0.1438577586206896, 0.1400862068965517, 0.14224137931034486, 0.13941271551724133, 0.1452047413793104, 0.1373922413793104, 0.13591056034482762, 0.14156788793103448, 0.14210668103448276, 0.13564116379310343, 0.13846982758620685, 0.1399515086206896, 0.13873922413793105, 0.13806573275862066, 0.1365840517241379, 0.1373922413793104, 0.13375538793103448, 0.13442887931034486, 0.13954741379310343, 0.14291487068965514, 0.1325431034482759, 0.14210668103448276, 0.1412984913793104, 0.13429418103448276, 0.13820043103448276, 0.1371228448275862, 0.1322737068965517, 0.13550646551724133, 0.14224137931034486, 0.13968211206896552, 0.13415948275862066, 0.13200431034482762, 0.13671875, 0.13537176724137934, 0.13119612068965514, 0.13415948275862066, 0.13873922413793105, 0.1365840517241379, 0.13119612068965514, 0.13389008620689657, 0.1365840517241379, 0.1329471982758621, 0.13523706896551724, 0.13550646551724133, 0.1402209051724138, 0.14318426724137934, 0.1369881465517241, 0.13537176724137934, 0.13523706896551724, 0.13119612068965514, 0.13092672413793105, 0.1330818965517241, 0.1295797413793104, 0.13362068965517238, 0.13160021551724133, 0.13429418103448276, 0.1333512931034483, 0.13564116379310343, 0.13483297413793105, 0.13550646551724133, 0.13402478448275867, 0.13833512931034486, 0.1324084051724138, 0.1330818965517241, 0.13402478448275867, 0.1371228448275862, 0.13564116379310343, 0.13362068965517238, 0.13442887931034486, 0.12971443965517238, 0.13510237068965514, 0.1363146551724138, 0.13025323275862066, 0.13186961206896552, 0.13523706896551724, 0.13483297413793105, 0.13375538793103448, 0.13389008620689657, 0.13550646551724133, 0.13591056034482762, 0.13456357758620685, 0.13752693965517238, 0.13510237068965514, 0.13065732758620685, 0.13375538793103448, 0.1326778017241379, 0.13402478448275867, 0.13577586206896552, 0.1322737068965517, 0.1363146551724138, 0.1329471982758621, 0.1329471982758621, 0.13146551724137934, 0.13752693965517238, 0.13483297413793105, 0.13146551724137934, 0.13173491379310343, 0.13052262931034486, 0.13092672413793105, 0.1322737068965517, 0.13106142241379315, 0.13389008620689657, 0.13389008620689657], "accuracy_train_std": [0.020795088869588665, 0.016978031832331417, 0.020064861980343837, 0.021815188502377073, 0.02609176729898277, 0.02484217661033028, 0.029281901657015566, 0.02913987925095061, 0.0310445302579258, 0.03112330498047826, 0.031664835496860146, 0.03173319886228309, 0.03176706826689462, 0.0308492084665682, 0.02652823279254295, 0.026095512834637128, 0.029524680814901946, 0.03071352362788396, 0.028625341074080938, 0.029008578573488767, 0.026240000546218497, 0.02553224851805216, 0.027168432223476896, 0.023106871031961154, 0.02537854008410326, 0.024068252962490377, 0.02463797255379046, 0.023768061079499435, 0.02375017348355958, 0.023021195988380965, 0.025929471378044223, 0.022562547589391448, 0.02229680905389057, 0.020293214102362938, 0.021483382679580082, 0.021486372389139075, 0.020211311129296933, 0.021399190713885363, 0.01961906935521744, 0.019698107952590034, 0.018125341288469963, 0.020588384711482062, 0.019076197173772732, 0.019933121199499356, 0.018545026871393862, 0.020150603201060956, 0.016987503829456404, 0.015571252615427392, 0.02005127947646645, 0.01822717014926209, 0.016471264499185383, 0.016503926003670514, 0.017409587256823997, 0.01734011052987626, 0.016423389568102156, 0.015532388714193155, 0.015732929424302017, 0.013992673656702344, 0.014184399126728394, 0.013189660332182485, 0.015026836807021776, 0.01319585132626629, 0.016196478520490512, 0.015469283912709396, 0.011858935887245006, 0.010975328198153922, 0.014492979566368096, 0.012298106199983226, 0.014466133185373086, 0.014521301700641557, 0.014309570275733013, 0.012252816464570897, 0.011448879947815826, 0.012370386036104413, 0.012032556153449524, 0.010485075945496596, 0.01224440774331452, 0.010234634530660444, 0.009755725358576078, 0.008759867239689032, 0.011051174368899987, 0.012786683971961013, 0.00987064080440575, 0.011168502622450761, 0.00906575571521351, 0.012175837504984167, 0.008373457419272748, 0.009077475522809067, 0.008239598265034615, 0.008181869044514027, 0.009222956766008239, 0.010782647302651731, 0.00881318318291645, 0.00993171246420804, 0.007829386247449482, 0.00875439760799199, 0.009440142457215162, 0.007662679528958417, 0.007748732718756914, 0.011018657413759235, 0.009516470225822388, 0.013890996376767018, 0.005889867869332834, 0.01036655619582745, 0.00803776432236792, 0.005923803628507369, 0.007975798254636618, 0.00806681866932787, 0.01409622995225708, 0.008164219733214007, 0.0063659465114703625, 0.006620923267497923, 0.0071831614876388455, 0.007971492605237626, 0.007858435908615959, 0.0067479580364015095, 0.00609737091915169, 0.005935243474651376, 0.006738802134695266, 0.0062432913034849305, 0.005682583294774035, 0.007000134842312738, 0.006251135723059925, 0.006084506917449708, 0.005468863404253126, 0.008040657264639267, 0.007596743817195748, 0.005140085092866198, 0.004863025688250075, 0.006815930641420684, 0.009887652325973712, 0.005936502843799053, 0.004750183910947962, 0.004314701952065671, 0.005289174747569483, 0.007981489255759958, 0.006481927371865474, 0.009108806601259645, 0.005691006016532246, 0.0044449865929386675, 0.006822102212694578, 0.004590838804938566, 0.004975812364468966, 0.006048314693681229, 0.005069140576321831, 0.00741081868848591, 0.0063733793304785276, 0.005903015331428899, 0.005066736793527722, 0.004382508792366487, 0.006774370695032712, 0.005205385139069779, 0.005117790655810322, 0.005022996415528328, 0.007123050940701632, 0.003654000177669742, 0.0035777359883277537, 0.0041546484408797775, 0.004607393919623651, 0.004301334158884584, 0.004230525734797108, 0.0034584286654506463, 0.0052053319498954614, 0.004489116491356629, 0.0046498041442422575, 0.004209991469371008, 0.006298744361566871, 0.005026137286707707, 0.007234626260917934, 0.0038818625836723633, 0.0043145094417350914, 0.004568288176720539, 0.00687655167509413, 0.0035322531242396077, 0.0036205837318874653, 0.004421754796626045, 0.0049673474404965225, 0.004054342867231937, 0.0036534697393420927, 0.004361991790760204, 0.00331720824297931, 0.004176714558044765, 0.004695075504033029, 0.004957807125265978, 0.0037352334183950436, 0.004812490901783123, 0.005727039060683831, 0.0030180171055788916, 0.004019708779853944, 0.004944106169679555, 0.003420757183617955, 0.003845459464867341, 0.005698396052574892, 0.006042819055728708, 0.003444711850175786, 0.0034948228634426423, 0.003866139531935093, 0.004101326906955803, 0.003750619425997135, 0.0038807212370098394, 0.003243952284505026, 0.0036290620573525977, 0.002702861099895604, 0.004025284015813347, 0.0038954615863470033, 0.0037871299937206446, 0.0035622250508596117, 0.0035269975510081077, 0.0035074755648763223, 0.004893729743546982, 0.003921529848265866, 0.0033086002433581974, 0.0026673905683079735, 0.0035501574625414604, 0.003948267541634854, 0.0026735076123350497, 0.002520082293972181, 0.0026831214165022846, 0.00283602475366951, 0.002696707970575927, 0.004068522271519039, 0.003832405513278622, 0.003103321069622466, 0.0035460997816820993, 0.002499342339204559, 0.0033319486873652857, 0.0025682913497067496, 0.0030641756044160447, 0.003168304344824328, 0.0032306960736058765, 0.0028359271263521894, 0.0026165644999844953, 0.0028312370562302396, 0.0021356814703645845, 0.0031469096721393323, 0.003092327918462462, 0.0025920062562711376, 0.003013151035863915, 0.0024374267288142268, 0.0032241763404185853, 0.0030966225718855856, 0.002594034973554343, 0.0029312700233647994, 0.0025117186790113754, 0.0025284182435446746, 0.0030197596363023913, 0.0031889478196011965, 0.0029000283326438055, 0.0026564694637933144, 0.0023427858555447366, 0.0028033269224087783, 0.004279457740437089, 0.002238969651158798, 0.0031172078375914705, 0.002063818895828379, 0.003036674116291485, 0.002093785891664319, 0.0039505108756463314, 0.0024246712074802827, 0.0025392358735346785, 0.0030771594575070642, 0.0016337118747844297, 0.0027695434826439185, 0.001973292102149532, 0.0023243958915829155, 0.00302195929154342, 0.0022160995935974204], "accuracy_test_std": 0.018132602968786698, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.9687780718817098, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0024637764000073337, "patience_threshold": 1, "do_flip": true, "batch_size": 256, "optimization": "rmsprop", "nb_data_augmentation": 2, "learning_rate_decay_method": "sqrt", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 9.470063145570236e-07, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.007828500050962707}, "accuracy_valid_max": 0.8704202586206896, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234423\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -4], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8661099137931034, "loss_train": [102607.5234375, 1656.2896728515625, 124.63573455810547, 4.546714782714844, 2.2394943237304688, 1.798140287399292, 1.572904109954834, 1.382095456123352, 1.2292331457138062, 1.1070441007614136, 1.0156294107437134, 0.928739607334137, 0.8659980297088623, 0.8090261220932007, 0.7565457224845886, 0.7118324637413025, 0.6766422986984253, 0.6425515413284302, 0.6107538938522339, 0.5842499732971191, 0.5616839528083801, 0.5409376621246338, 0.5152449607849121, 0.4980825185775757, 0.4782862961292267, 0.465221107006073, 0.446532666683197, 0.43388622999191284, 0.4212246239185333, 0.4092518389225006, 0.3950338661670685, 0.38533806800842285, 0.374480277299881, 0.36119213700294495, 0.35338860750198364, 0.34473830461502075, 0.333005428314209, 0.32329806685447693, 0.3166030943393707, 0.30903160572052, 0.30274009704589844, 0.29629912972450256, 0.2913420498371124, 0.28270405530929565, 0.27554190158843994, 0.27286064624786377, 0.2659289538860321, 0.25973549485206604, 0.25456011295318604, 0.25151199102401733, 0.2436039000749588, 0.23932567238807678, 0.2350432276725769, 0.22956393659114838, 0.2272534817457199, 0.22469955682754517, 0.2169470489025116, 0.2152116447687149, 0.2126653492450714, 0.20843201875686646, 0.20434650778770447, 0.2007686197757721, 0.19664375483989716, 0.19275760650634766, 0.19313190877437592, 0.18712584674358368, 0.18558108806610107, 0.18271473050117493, 0.1811390519142151, 0.17508944869041443, 0.1754668653011322, 0.17012418806552887, 0.16989490389823914, 0.16511781513690948, 0.162493035197258, 0.16169291734695435, 0.160813108086586, 0.1599152535200119, 0.15664935111999512, 0.15311816334724426, 0.15191666781902313, 0.15029439330101013, 0.14616526663303375, 0.14459146559238434, 0.1432417929172516, 0.14257065951824188, 0.13795776665210724, 0.13942505419254303, 0.1351224035024643, 0.13764293491840363, 0.13449183106422424, 0.12980671226978302, 0.13019908964633942, 0.12984247505664825, 0.1274973452091217, 0.12493907660245895, 0.12687042355537415, 0.124130479991436, 0.12312280386686325, 0.12010642886161804, 0.11877162754535675, 0.11653507500886917, 0.11594114452600479, 0.11385306715965271, 0.11647408455610275, 0.11302260309457779, 0.11090227216482162, 0.10984354466199875, 0.11041990667581558, 0.10688702017068863, 0.10608454048633575, 0.10505682975053787, 0.10497718304395676, 0.10327870398759842, 0.10487917065620422, 0.10111825913190842, 0.10135818272829056, 0.10008689761161804, 0.10126442462205887, 0.09977194666862488, 0.09802530705928802, 0.0970131903886795, 0.09576515108346939, 0.09710440039634705, 0.09434918314218521, 0.0919347032904625, 0.09313970804214478, 0.09248431771993637, 0.09216592460870743, 0.09023433178663254, 0.08963165432214737, 0.0867617204785347, 0.09030094742774963, 0.0884718969464302, 0.08843500912189484, 0.08634143322706223, 0.08752897381782532, 0.08426271378993988, 0.08510927855968475, 0.08218739926815033, 0.08526832610368729, 0.08282476663589478, 0.08194713294506073, 0.08216527849435806, 0.08094479143619537, 0.08073476701974869, 0.08027158677577972, 0.07908442616462708, 0.08019546419382095, 0.0781555324792862, 0.07740511000156403, 0.07680875062942505, 0.0727471187710762, 0.07659361511468887, 0.07599370926618576, 0.0751160979270935, 0.07287023961544037, 0.07481659203767776, 0.07548248022794724, 0.07282770425081253, 0.07324112951755524, 0.0725608542561531, 0.07193395495414734, 0.07084190845489502, 0.07250503450632095, 0.07028423994779587, 0.07087322324514389, 0.06963212788105011, 0.07005620747804642, 0.07079418003559113, 0.06929071247577667, 0.07074596732854843, 0.06716565787792206, 0.06829240918159485, 0.06799814850091934, 0.06577432155609131, 0.06790035218000412, 0.06738678365945816, 0.0677153542637825, 0.0666845366358757, 0.06631908565759659, 0.06552480161190033, 0.0646149218082428, 0.06416162848472595, 0.0641251653432846, 0.06466464698314667, 0.06516443938016891, 0.06356052309274673, 0.06472137570381165, 0.06206659600138664, 0.06318017840385437, 0.06212925910949707, 0.06319661438465118, 0.06266174465417862, 0.06055773049592972, 0.06143006309866905, 0.06142270192503929, 0.060749705880880356, 0.05897703021764755, 0.05946323648095131, 0.061563413590192795, 0.06065746024250984, 0.060361262410879135, 0.06100040301680565, 0.05937451869249344, 0.06122973933815956, 0.05777472257614136, 0.057947319000959396, 0.058205850422382355, 0.05689980089664459, 0.058111097663640976, 0.05907859280705452, 0.057463228702545166, 0.056905347853899, 0.05766855925321579, 0.05849086120724678, 0.05749088153243065, 0.055504582822322845, 0.05707797408103943, 0.05635404214262962, 0.0561084970831871, 0.05581977963447571, 0.05559539049863815, 0.054717205464839935, 0.05576057732105255, 0.05464894324541092, 0.05425814166665077, 0.0537618026137352, 0.05463527515530586, 0.053393345326185226, 0.05392257496714592, 0.05521363019943237, 0.05430503562092781, 0.05263237655162811, 0.053410328924655914, 0.05331198126077652, 0.05274829640984535, 0.05230475962162018, 0.053174939006567, 0.05173211544752121, 0.053842682391405106, 0.05245918408036232, 0.05222182348370552, 0.05180104821920395, 0.0508529394865036, 0.05106864124536514, 0.05181387811899185, 0.050761573016643524, 0.050632935017347336, 0.05254068225622177, 0.04997795447707176, 0.05165059119462967, 0.0489034578204155, 0.049909546971321106, 0.05147602781653404, 0.05024993419647217, 0.04994770511984825, 0.05036298185586929, 0.04867243021726608, 0.05011679604649544, 0.048415206372737885, 0.04845595359802246, 0.049134351313114166, 0.0492781326174736, 0.049094125628471375, 0.049440961331129074, 0.048989083617925644], "accuracy_train_first": 0.1370952560240964, "model": "residualv2", "loss_std": [740583.0, 10796.033203125, 751.0198974609375, 11.947652816772461, 0.3714520335197449, 0.14211589097976685, 0.2747010290622711, 0.12352044135332108, 0.11846642941236496, 0.12829908728599548, 0.11822561919689178, 0.11274230480194092, 0.11357539147138596, 0.10940879583358765, 0.09807366132736206, 0.08261175453662872, 0.08779315650463104, 0.07845206558704376, 0.08616986125707626, 0.07528626173734665, 0.07880812883377075, 0.07810673862695694, 0.06957916915416718, 0.07021385431289673, 0.06705274432897568, 0.07601489871740341, 0.06543461978435516, 0.0682966336607933, 0.05994362756609917, 0.06440307945013046, 0.06074533984065056, 0.058196552097797394, 0.05503954738378525, 0.0596097856760025, 0.05896744132041931, 0.05623571202158928, 0.055783260613679886, 0.05205817520618439, 0.05466948077082634, 0.05294236168265343, 0.0487118661403656, 0.05232003703713417, 0.050877973437309265, 0.0508846677839756, 0.04490678012371063, 0.047437578439712524, 0.04472402483224869, 0.045560747385025024, 0.04154108464717865, 0.04496948793530464, 0.04475533962249756, 0.04391302913427353, 0.04019107297062874, 0.041003067046403885, 0.03619471937417984, 0.03855985030531883, 0.03996347263455391, 0.04167687147855759, 0.0374915674328804, 0.03705248981714249, 0.039144933223724365, 0.04099895805120468, 0.038127172738313675, 0.035378921777009964, 0.03674834594130516, 0.035267241299152374, 0.035210274159908295, 0.03715601563453674, 0.034290723502635956, 0.02885795384645462, 0.033043961971998215, 0.03125161677598953, 0.029553288593888283, 0.0313866026699543, 0.028477750718593597, 0.032371122390031815, 0.0292682908475399, 0.02822466380894184, 0.0293290838599205, 0.026537669822573662, 0.030732788145542145, 0.0265271607786417, 0.026741139590740204, 0.026402030140161514, 0.025997137650847435, 0.028482133522629738, 0.025619979947805405, 0.026234857738018036, 0.028156975284218788, 0.028162119910120964, 0.024476217105984688, 0.0246799997985363, 0.021675867959856987, 0.02814367040991783, 0.026519963517785072, 0.023495234549045563, 0.02698841504752636, 0.023442545905709267, 0.02568160928785801, 0.024759529158473015, 0.02124560996890068, 0.019637757912278175, 0.023092711344361305, 0.022149192169308662, 0.02256261743605137, 0.021711256355047226, 0.02435465343296528, 0.020446719601750374, 0.02226596511900425, 0.02528061717748642, 0.01927553303539753, 0.021404292434453964, 0.022159282118082047, 0.01979663036763668, 0.021837320178747177, 0.019704468548297882, 0.020103776827454567, 0.020480751991271973, 0.021496295928955078, 0.021029088646173477, 0.02001800201833248, 0.021216370165348053, 0.018182627856731415, 0.01877206563949585, 0.019311023876070976, 0.019413787871599197, 0.01918807625770569, 0.01821126416325569, 0.018326295539736748, 0.02082386426627636, 0.016736483201384544, 0.018114235252141953, 0.01786857284605503, 0.020202793180942535, 0.017746340483427048, 0.016698824241757393, 0.01798268035054207, 0.01667618565261364, 0.018240895122289658, 0.01492930855602026, 0.01653522625565529, 0.017443154007196426, 0.015840943902730942, 0.01651408150792122, 0.015281479805707932, 0.015615026466548443, 0.017295612022280693, 0.016105161979794502, 0.017396055161952972, 0.01600550301373005, 0.014051948674023151, 0.01506503950804472, 0.014185218140482903, 0.017163215205073357, 0.016583982855081558, 0.014540489763021469, 0.013566199690103531, 0.015559467487037182, 0.021436782553792, 0.015819372609257698, 0.014109054580330849, 0.016429878771305084, 0.013638140633702278, 0.013814182952046394, 0.021741077303886414, 0.014443895779550076, 0.015093653462827206, 0.011831889860332012, 0.015416860580444336, 0.015379649586975574, 0.013658792711794376, 0.013870248571038246, 0.014073671773076057, 0.01271770428866148, 0.013701549731194973, 0.013726457953453064, 0.014199684374034405, 0.01387107651680708, 0.014209546148777008, 0.013523705303668976, 0.013971791602671146, 0.012435405515134335, 0.01430924329906702, 0.013397470116615295, 0.013885991647839546, 0.01177783589810133, 0.013213083148002625, 0.0122075155377388, 0.016166580840945244, 0.011249441653490067, 0.013250139541924, 0.01170206256210804, 0.012373194098472595, 0.01236440148204565, 0.013493594713509083, 0.012994433753192425, 0.013285008259117603, 0.014060713350772858, 0.011744947172701359, 0.011514025740325451, 0.012586358934640884, 0.012408854439854622, 0.011116066947579384, 0.012469702400267124, 0.011748538352549076, 0.013245822861790657, 0.013092472217977047, 0.012295310385525227, 0.010898767039179802, 0.010342859663069248, 0.011802718043327332, 0.010630250908434391, 0.010747754015028477, 0.010086131282150745, 0.012747214175760746, 0.01219188328832388, 0.010089208371937275, 0.009836001321673393, 0.010579382069408894, 0.01234368421137333, 0.010874307714402676, 0.011204899288713932, 0.010701073333621025, 0.01065577007830143, 0.01229007262736559, 0.01147055346518755, 0.011105447076261044, 0.010242477059364319, 0.01014761533588171, 0.010243959724903107, 0.011137749068439007, 0.01184668205678463, 0.009848996065557003, 0.009634803980588913, 0.01015482097864151, 0.011311703361570835, 0.009843822568655014, 0.011469966731965542, 0.011624854989349842, 0.010685242712497711, 0.009222354739904404, 0.009474514052271843, 0.009808407165110111, 0.010082042776048183, 0.009545912966132164, 0.009682816453278065, 0.010001133196055889, 0.010518532246351242, 0.009592602960765362, 0.009839766658842564, 0.009697023779153824, 0.009011455811560154, 0.00930311344563961, 0.008967079222202301, 0.010624932125210762, 0.010124736465513706, 0.009040603414177895, 0.009500604122877121, 0.008974192664027214, 0.01155315712094307, 0.009832296520471573, 0.008378822356462479, 0.010648312047123909, 0.010703817009925842, 0.008925581350922585, 0.009725014679133892, 0.008928908966481686]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:04 2016", "state": "available"}], "summary": "ab0fe219ff7bf97b96198c607b48b1f9"}