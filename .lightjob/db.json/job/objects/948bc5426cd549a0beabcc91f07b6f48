{"content": {"hp_model": {"f0": 16, "f1": 64, "f2": 16, "f3": 16, "nonlin": "very_leaky_rectify", "nbg1": 2, "nbg3": 2, "nbg2": 2, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.02647155274708506, 0.027562835263854876, 0.031854931927325324, 0.031443321100791864, 0.02587259012821825, 0.029184488284376812, 0.03198396307652802, 0.031038528120262476, 0.02877692401897063, 0.0234808111509859, 0.022649345861603408, 0.022998325399151986, 0.025245777414729744, 0.02579885188498766, 0.024792534065194122, 0.028255190853017746, 0.024906436046454292, 0.031234319973738957, 0.02855031558706726, 0.03452955556382597, 0.03274470481990284, 0.03311934516940303, 0.033404086119712406, 0.03565919027345798, 0.03708779499968239, 0.03657796102999213, 0.037782326141721334, 0.03642934730475603, 0.03446749645408808, 0.036034746998288715, 0.036305121120049556, 0.0355751381520439, 0.03497645056785996, 0.0333905044618549, 0.0345956991700766, 0.0347495446426615, 0.03173624016606443, 0.032518964771655244, 0.03195729014296749, 0.02893160935291285, 0.03105313847501304, 0.029208724025734233, 0.029542252364593586, 0.029934551561570627, 0.02797900760740371, 0.029260235833770375, 0.027401085950697224, 0.028748537870590733, 0.027688278255087, 0.028212778161177066, 0.025224207811998096, 0.025821346800986685, 0.0273646434742036, 0.027626613095588164, 0.028629642444522235, 0.024277846252286735, 0.02662191390697897, 0.026957833306604093, 0.02801659378396131, 0.027152312597426707, 0.027854222561317202, 0.02615575546347668, 0.027513421160487654, 0.02786985124682876, 0.026740237129682206, 0.029775327326827798, 0.027734110050693057, 0.02779749491689629, 0.030128484608030123, 0.026862767433567834, 0.028367981357924874, 0.02689719174919594, 0.02784901105043174, 0.02766467805150944, 0.026703572236602576, 0.02752397027993993, 0.025078489488657388, 0.02775438280859812, 0.025042289681270716, 0.0268208587600294, 0.025964992529945257, 0.028787640390648486, 0.02650785410301726, 0.027096793861119833, 0.029097945434795013, 0.028325097007845614, 0.028214707393926855, 0.0270263959157113, 0.029305466561271653, 0.029024274890228307, 0.02934135359751073, 0.028079987141333616, 0.030733648409883633, 0.027800105623163318, 0.029097945434795013, 0.029984211374949412, 0.027982249783574525, 0.028896469225344643, 0.029359280665818912, 0.028215350442196373, 0.027589810892339573, 0.026740237129682206, 0.02987934466061215, 0.02799002947413314, 0.029812474565745203, 0.02609324991777666, 0.03006397925948896, 0.030037413501651625, 0.02920437550186994, 0.026531115613223345, 0.02947153950684772, 0.028912789595926944, 0.02768041375627609, 0.027399761618952384, 0.027290282892519557, 0.02715030787367347, 0.02499587742836987, 0.02704183209338277, 0.027885471173091786, 0.028212778161177066, 0.02837437644837288, 0.02855794052682407, 0.029241007100741356, 0.027793578397691664, 0.030012033342069734, 0.030473977893058772, 0.0302384879204749, 0.030613572686328784, 0.03252510153068856, 0.030112220592281407, 0.02849624718770349, 0.03015135984190173, 0.030748993692629904, 0.03010981036131006, 0.02945984017495543, 0.029684395176838532, 0.02940497607193925, 0.027787049638963623, 0.031087008053344085, 0.030678696684109365, 0.03233375928848628, 0.031037358994770222, 0.03143581886294641, 0.028944149059358486, 0.03004345323659728, 0.029677059658972778, 0.03233656484509409, 0.032307936736627324, 0.03021207561010874, 0.030449557489953403, 0.03187315296809878, 0.030142332218165167, 0.029859906987704396, 0.030046472648795397, 0.028132920794733996, 0.030109207773420642, 0.027324832614452513, 0.027527266050703596, 0.02928378931401119, 0.028556034482758622, 0.02912349920285963, 0.02817996099657925, 0.0286017444827306, 0.02814968385204046, 0.027708584545468522, 0.02632240056237146, 0.028292410125346383, 0.029208724025734236, 0.029094827586206896, 0.0275325384633263, 0.029026150186627558, 0.028054129603604604, 0.029683172716416854, 0.027931628978081522, 0.02766730129047338, 0.029195676511080456, 0.02727099576608036, 0.028922828323574925, 0.026938308155978925, 0.028729598190117042, 0.02845674426595904, 0.02689449339528173, 0.028969212188321238, 0.025454766834089905, 0.027728875965239378, 0.02847076770550949, 0.026071685532187947, 0.02825968543522275, 0.027206384300796967, 0.02576155147265764, 0.02870495792324037, 0.027075358640629824, 0.028366702166827434, 0.028533152022569185, 0.029124745154611165, 0.027771374355858917, 0.028285355061221307, 0.02876620365508667, 0.029847752014072176, 0.028994879411796792, 0.028816617650396722, 0.028366702166827434, 0.02864801488378142, 0.029439509232485245, 0.02953733868792197, 0.029226732446369648, 0.029870842235080783, 0.029175783364056594, 0.030015055915002184, 0.02935124574785204, 0.02885877160637411, 0.030933129855949714, 0.030847963810990597, 0.02957355786131248, 0.02849561047831155, 0.029420397670108584, 0.02952689440996673, 0.029810648734639827, 0.029896342257486677, 0.02807352498969549, 0.029749113694780893, 0.029346918342366368, 0.028016593783961312, 0.02759309879897982, 0.02838204865485334, 0.025921632423819424, 0.027116204893609167, 0.028266746906200322, 0.027647620931404153, 0.0273646434742036, 0.027822286735536522, 0.02685871461339336, 0.026148123911740696, 0.028287920742668938, 0.026511276193387057, 0.027971873497027507, 0.026524960139892008, 0.0275167181947552, 0.02781902591643369, 0.0278945787575274, 0.028076110028834457, 0.027523970279939934, 0.026205652557036264, 0.028328299574084333, 0.028161927468474096, 0.027730184579221807, 0.02705189442039712, 0.028045073833050934, 0.02901302056637347, 0.027070667423642232, 0.028132920794733996, 0.02762004487003812, 0.028347507373493702, 0.02758191831730662, 0.02884367876335982, 0.028715701151855712, 0.027666645504050354, 0.028210848796494378, 0.027654182607284226, 0.027139613512697797, 0.02832701859103753, 0.027932278543295455, 0.027498909513496723, 0.026702892782326255, 0.027569417119206675, 0.028233992471064447, 0.027992622223846835, 0.027112189958134168, 0.028232064556156754, 0.027595728842239757, 0.02878953110098213, 0.02790693429650894, 0.027404396500063617, 0.026822211674795326, 0.027997807002965912, 0.02606124474624518, 0.028528700523959394, 0.027584549426567326, 0.02787310611997818, 0.027377900896363147, 0.027841191954989714, 0.026784304229702564, 0.026703572236602576, 0.026701533821904887, 0.027485710458539578, 0.0269921363806149, 0.027428882146766302, 0.027717750251922375, 0.02690191321728433, 0.028375015878145653, 0.02721171888600525, 0.02759309879897982, 0.02712824613481162, 0.027922533478440623, 0.028020479131552017, 0.028661944740443746, 0.028092261134113596, 0.02838077009780358, 0.027951109367973504, 0.027809241165008495, 0.027687622965507225, 0.028065121968085787], "moving_avg_accuracy_train": [0.025536521084337342, 0.055477692018072275, 0.0879735033885542, 0.12116128106174698, 0.15404232916039154, 0.18580724157567768, 0.21628289919521834, 0.24567588186605793, 0.27311318825776537, 0.30012462922114547, 0.32626803979300684, 0.35171964319322424, 0.37771578881366086, 0.40291248929976464, 0.42663903027942673, 0.4494330527032913, 0.47088187845705853, 0.49074352118364184, 0.5100732541556391, 0.5283806877762197, 0.5449115007757062, 0.5609940517523524, 0.5763154861855508, 0.5904295136212127, 0.6039416262651155, 0.6165260969217364, 0.6283792289464302, 0.6392423602686547, 0.6491862530068494, 0.6586393332784536, 0.6673353585349455, 0.6758183136453064, 0.6839188994494505, 0.6913247316430596, 0.6983453081775488, 0.7052191734441313, 0.7114456559491158, 0.7172942191192645, 0.7231673950989043, 0.7285991495649174, 0.7341489672891486, 0.7393249967650529, 0.7444352305222826, 0.7493827089760784, 0.754028398921844, 0.7587342751441174, 0.7631625230815129, 0.7674538573697471, 0.7713913594339773, 0.7753751527074471, 0.7790217488824854, 0.7828378533617067, 0.7864441282664999, 0.7899180324579221, 0.7931410258988768, 0.7962440919836878, 0.799018026158813, 0.8018040059224497, 0.80473025066153, 0.8076297783062204, 0.8102205278852369, 0.8127381023557493, 0.8152015850418611, 0.8174140131340605, 0.8196593399833051, 0.8216966062861794, 0.8236430977659951, 0.8255337766942149, 0.82699065881395, 0.8284853994084586, 0.8298400785941187, 0.8312922529636224, 0.832385072094971, 0.8336556951565582, 0.83492867985777, 0.8362979165406678, 0.8376996572661191, 0.8390529972623987, 0.8405839738915806, 0.8418277225867599, 0.8434059631292887, 0.8445910633525044, 0.8460106279509889, 0.8471846969329985, 0.8483519576613853, 0.8493154252988612, 0.8507025951183727, 0.8518263303354511, 0.8530447703440747, 0.8544284521952094, 0.8556008178190618, 0.8569195010973966, 0.8581322008370545, 0.8594613000304576, 0.8606551361418697, 0.8617978303590081, 0.8630027423532278, 0.8643295389010376, 0.8656060164868374, 0.866863091795985, 0.8681615341224105, 0.8695089725776393, 0.8707193140246946, 0.8719921680137913, 0.873093026513617, 0.8740202637718938, 0.874937137997114, 0.8759576372998122, 0.8768949119734455, 0.8776255073724866, 0.87819126988825, 0.8787686978693046, 0.8791095426908079, 0.879616321855462, 0.8800841889169038, 0.8805711578264183, 0.8809011843630535, 0.881282922101447, 0.8818312112166035, 0.8824540953660274, 0.8832382415523161, 0.8838663187525062, 0.8845586590158098, 0.8852076500419397, 0.8857517382003963, 0.8862155327538506, 0.886689423755574, 0.8872477027655589, 0.887804276615509, 0.8882957804298617, 0.8887310743748272, 0.8892357907325252, 0.8898618163279474, 0.8903405255084057, 0.8909337319937097, 0.8914534988545797, 0.8919495269811699, 0.8924571345240168, 0.8928951560113741, 0.8932917285126464, 0.8936298184625866, 0.8941247055922315, 0.8944736243402372, 0.8949994358519966, 0.8953855991945078, 0.895737852528069, 0.8960219362511657, 0.8965905822344828, 0.896956467535131, 0.8974010692755938, 0.8979023968359862, 0.8983747701041949, 0.8987599022805224, 0.8991229933777714, 0.8994662475038496, 0.899864596398043, 0.9001501623606484, 0.9003977590763907, 0.9007076631386313, 0.900741847878985, 0.900857328000725, 0.901050680291014, 0.9012694074426355, 0.9014191986260828, 0.9015210664140769, 0.9017162865798981, 0.9020637656026312, 0.9024376789520067, 0.9027694946411434, 0.9032046121951013, 0.9035609205539045, 0.9039874903961044, 0.904307867862518, 0.9046362113473505, 0.9050940887065914, 0.9054426429383418, 0.9057516354216161, 0.9060862045601774, 0.9065167407306657, 0.9068148031033822, 0.907344260293044, 0.907771355348077, 0.9082051573132692, 0.9087085308891713, 0.9092603999388084, 0.909601773348542, 0.9099796042968203, 0.9104584887466564, 0.9109341948418702, 0.9112587911709362, 0.9117274150658908, 0.9122527157279765, 0.9125890028901187, 0.9128987208239984, 0.9131515821753334, 0.913468577572258, 0.9137303418029841, 0.9140835877431676, 0.9143497395110195, 0.9145869229394357, 0.9147745032358535, 0.9149339128520272, 0.9150938536451377, 0.9152778041239974, 0.9154410063923205, 0.9156467175000764, 0.9158083258705507, 0.9159373012654234, 0.9161569182774352, 0.9164487000942699, 0.9167018910788188, 0.9169697667299731, 0.9171849700268553, 0.9174210099217601, 0.9176357989898252, 0.9179373546330113, 0.9180487396516378, 0.9183631239696065, 0.9186343040425253, 0.918892485084056, 0.9191130822081804, 0.9194175119391697, 0.9197667999018793, 0.9199987983755468, 0.9202217159777512, 0.9204764645606989, 0.9206186712672796, 0.9208478432971782, 0.9211152803530025, 0.9213183231008348, 0.9215410653389441, 0.9217415333532424, 0.9218866571263519, 0.9220996292149215, 0.9223454268355981, 0.9225807636701105, 0.9227996263091236, 0.9231048481661631, 0.9233160124459323, 0.9235907741531464, 0.9237698179727716, 0.9239686080128438, 0.9241381063983063, 0.924354190336789, 0.9245533722067245, 0.9247326358896665, 0.9248798542284106, 0.9250429418477382, 0.925142657452121, 0.9253312343273908, 0.9255127193283866, 0.9257042937810902, 0.9258178817222583, 0.9260024715620806, 0.9261686024179207, 0.9261604582905865, 0.9261884260157447, 0.9262394817575437, 0.9262195433709459, 0.9262769000278273, 0.9262179223744421, 0.9261036602574799, 0.925981999051009, 0.9257760242965105, 0.9257177178005943, 0.9256605356289687, 0.9255973058612526, 0.9255003953052479, 0.9254672985458074, 0.9253104406791786, 0.9252916330570439, 0.9253570668898937, 0.9253265371587357, 0.9253649489549103, 0.9253595158064072, 0.9253946297378147, 0.9253838753483706, 0.9254730292291963, 0.9256003309749514, 0.9257902037509502, 0.9259352044601925, 0.9261339468153781, 0.9262516327061294, 0.9264752081403358, 0.9266928981696757, 0.9268582280816238, 0.9271082109963529, 0.9273261361316574, 0.9274940308016242, 0.9277110245588112, 0.9278945531270265, 0.9280714946516733, 0.9282025040720481, 0.9282898214359276, 0.9283966450152265, 0.9285116115378003, 0.9286503788478757, 0.9288152731920039, 0.9288977895475022, 0.929023823845764, 0.9291301952262478, 0.9292588737457917], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 1234, "moving_var_accuracy_train": [0.005869025181817252, 0.01335038611558373, 0.021519147313658837, 0.02928008986426041, 0.03608255079442277, 0.041555382661737694, 0.04575873576165512, 0.048958389058084105, 0.05083780219056758, 0.05232058345777433, 0.053239826358957104, 0.05374590076383901, 0.05445350697152562, 0.05472201971285087, 0.054316356463302046, 0.053560827941308606, 0.052345214283116975, 0.05066105652099123, 0.048957698059810574, 0.04707838738577723, 0.04482995865301543, 0.042674798800961714, 0.04052003609868275, 0.038260884422906, 0.03607799067352907, 0.03389551172154236, 0.031770431198541525, 0.02965545667780242, 0.027579840035120682, 0.02562610257120115, 0.023744080011434958, 0.02201731675693104, 0.020406160494570637, 0.018859161599432656, 0.017416841893378977, 0.01610040791736924, 0.014839288885096212, 0.013663211216983565, 0.012607337860075571, 0.011612139683279501, 0.010728130005901263, 0.00989643853553002, 0.009141825083458784, 0.008447940462569872, 0.007797388331962578, 0.0072169569379405465, 0.006671745662301919, 0.0061703110458321015, 0.005692815243801238, 0.005266369199032799, 0.004859411252103763, 0.004504534007460386, 0.0041711275749148164, 0.0038626269104039676, 0.003569853399847508, 0.0032995292320031023, 0.0030388287060741396, 0.002804800984657268, 0.002601387060648499, 0.002416913699644562, 0.002235630180110674, 0.002069110793030791, 0.0019168184362306662, 0.0017691901351759786, 0.001637644555597827, 0.001511234185937489, 0.0013942102290727, 0.0012869612074519583, 0.0011773676363039981, 0.001079739117677446, 0.0009882816071742496, 0.0009084327400518183, 0.00082833774893121, 0.000760034320719825, 0.0006986152990935124, 0.0006456270510282953, 0.0005987482394779642, 0.0005553571778399399, 0.0005209164650078542, 0.00048274701585791053, 0.0004568899031628547, 0.00042384107569816247, 0.00039959344097178015, 0.0003720400386452545, 0.000347098513253038, 0.0003207430909239054, 0.0003059869428049862, 0.00028675327606740754, 0.0002714393129521981, 0.0002615265608434143, 0.0002477438751629937, 0.00023861981794373217, 0.00022799360207645657, 0.00022109278386195092, 0.00021181070742395928, 0.00020238138734649566, 0.00019520956483617589, 0.00019153211006607714, 0.00018704345430291415, 0.00018256125386843919, 0.00017947870075707705, 0.0001778711441970346, 0.00017326836754347154, 0.00017052294628716125, 0.00016437765658819126, 0.00015567781132760325, 0.00014767595529870212, 0.0001422811292101001, 0.0001359593706135987, 0.00012716736028613754, 0.00011733140927571003, 0.00010859907600788124, 9.878474513820356e-05, 9.121769671993121e-05, 8.406602333257734e-05, 7.779366946882272e-05, 7.09945601558918e-05, 6.520661744852625e-05, 6.13915442878656e-05, 5.8744251831511995e-05, 5.840379382160264e-05, 5.6113743164029864e-05, 5.481638420934849e-05, 5.312544995638745e-05, 5.047719227830329e-05, 4.736542154079824e-05, 4.465003352034788e-05, 4.299010924521916e-05, 4.147906837473212e-05, 3.95053455329683e-05, 3.726013834638528e-05, 3.5826771927298157e-05, 3.577126714968156e-05, 3.4256602749808736e-05, 3.399798788268848e-05, 3.30296074013474e-05, 3.194104178253009e-05, 3.106592636227239e-05, 2.9686099136525964e-05, 2.81329169617611e-05, 2.634836859383995e-05, 2.591775117424996e-05, 2.4421674691214158e-05, 2.446780693518123e-05, 2.3363125385557775e-05, 2.2143554546047247e-05, 2.065553114699892e-05, 2.1500202321383816e-05, 2.0555030568318597e-05, 2.027856388008972e-05, 2.0512671397362005e-05, 2.0469632798288555e-05, 1.9757610657644474e-05, 1.8968365895993166e-05, 1.813193986202176e-05, 1.7746882449365146e-05, 1.670612547541703e-05, 1.5587250130693107e-05, 1.4892889867761911e-05, 1.3414118249243192e-05, 1.2192727350972755e-05, 1.1309920589315283e-05, 1.0609502632091799e-05, 9.75048895662948e-06, 8.868833477043895e-06, 8.324948347628891e-06, 8.579128554021791e-06, 8.979516434190002e-06, 9.072479654786242e-06, 9.869177261168737e-06, 1.0024860354028637e-05, 1.0660030791095959e-05, 1.0517803200857066e-05, 1.0436307877059164e-05, 1.1279542174301655e-05, 1.124499842911214e-05, 1.0979785778680865e-05, 1.0889235777111495e-05, 1.146856474628879e-05, 1.1121278873924783e-05, 1.2532075227693196e-05, 1.2920559379226236e-05, 1.3322160746345973e-05, 1.4270409283958556e-05, 1.5584403387088772e-05, 1.5074785292238353e-05, 1.4852112792306658e-05, 1.5430874359728872e-05, 1.592445352496872e-05, 1.5280273164059927e-05, 1.5728721041955417e-05, 1.6639316008048113e-05, 1.599318590603764e-05, 1.5257194102534237e-05, 1.430692445927193e-05, 1.3780606748386563e-05, 1.301923068593612e-05, 1.2840351865647783e-05, 1.2193847550859314e-05, 1.14807666042104e-05, 1.0649367252227333e-05, 9.81313335856239e-06, 9.062049538413594e-06, 8.460384592626721e-06, 7.854060956836443e-06, 7.449508399840237e-06, 6.9396129485224e-06, 6.395363526013147e-06, 6.189911861097066e-06, 6.337150332706072e-06, 6.280386371347095e-06, 6.298164014544247e-06, 6.08515974399056e-06, 5.978077257471688e-06, 5.795478625566372e-06, 6.034353016446499e-06, 5.5425773161718625e-06, 5.877857079016787e-06, 5.951919058649644e-06, 5.956644204637113e-06, 5.7989476047215e-06, 6.053149994240679e-06, 6.545853722860639e-06, 6.375677976630995e-06, 6.18534049532078e-06, 6.1508780104138e-06, 5.717794935941226e-06, 5.618693815937493e-06, 5.700527643795712e-06, 5.501512096441686e-06, 5.397887828538929e-06, 5.2197858684955985e-06, 4.887355467339882e-06, 4.806833915193285e-06, 4.869898756646114e-06, 4.881359712086683e-06, 4.824331433679783e-06, 5.18034172844328e-06, 5.0636207330530664e-06, 5.236704621508104e-06, 5.001544363470868e-06, 4.857047247411095e-06, 4.629909846739873e-06, 4.587149278297333e-06, 4.4854951062668504e-06, 4.326164807837575e-06, 4.088607480417232e-06, 3.919124876577061e-06, 3.616701204736217e-06, 3.5750822252413892e-06, 3.514005252995438e-06, 3.4929116660536996e-06, 3.25974048285758e-06, 3.24042711526263e-06, 3.1647795550959453e-06, 2.8488985408766767e-06, 2.571048429643739e-06, 2.3374037856152033e-06, 2.1072412603947712e-06, 1.9261252091526992e-06, 1.764817960626788e-06, 1.7058386469184406e-06, 1.6684678246661393e-06, 1.8834514376159253e-06, 1.7257031210484724e-06, 1.582561015710098e-06, 1.4602869458680283e-06, 1.398783154067616e-06, 1.2687633980299825e-06, 1.3633265711374163e-06, 1.2301774538769372e-06, 1.1456939868220127e-06, 1.0395131685010556e-06, 9.488410464191963e-07, 8.542226137011849e-07, 7.798972459410613e-07, 7.029484333777984e-07, 7.041893202363814e-07, 7.796219984633312e-07, 1.0261248382065345e-06, 1.1127392055128873e-06, 1.3569519986639474e-06, 1.3459065187350046e-06, 1.6611896398864603e-06, 1.92157121576392e-06, 1.9754199122503906e-06, 2.3403010399338635e-06, 2.5336932173177376e-06, 2.5340214774152927e-06, 2.7043959455968557e-06, 2.7371009691974934e-06, 2.7451656005765755e-06, 2.625120254561484e-06, 2.4312271274191733e-06, 2.2908059085251147e-06, 2.1806810294868905e-06, 2.1359202236482385e-06, 2.1670395038122898e-06, 2.011616093753719e-06, 1.9534162834235094e-06, 1.8599084903554939e-06, 1.8229410938480086e-06], "duration": 33994.171607, "accuracy_train": [0.2553652108433735, 0.32494823042168675, 0.38043580572289154, 0.41985128012048195, 0.4499717620481928, 0.471691453313253, 0.4905638177710843, 0.5102127259036144, 0.5200489457831325, 0.5432275978915663, 0.561558734939759, 0.5807840737951807, 0.6116810993975904, 0.6296827936746988, 0.6401778990963856, 0.6545792545180723, 0.6639213102409639, 0.6694983057228916, 0.6840408509036144, 0.6931475903614458, 0.6936888177710844, 0.7057370105421686, 0.7142083960843374, 0.7174557605421686, 0.725550640060241, 0.7297863328313253, 0.7350574171686747, 0.7370105421686747, 0.7386812876506024, 0.7437170557228916, 0.7455995858433735, 0.7521649096385542, 0.756824171686747, 0.7579772213855421, 0.7615304969879518, 0.7670839608433735, 0.7674839984939759, 0.7699312876506024, 0.7760259789156626, 0.7774849397590361, 0.7840973268072289, 0.7859092620481928, 0.7904273343373494, 0.793910015060241, 0.7958396084337349, 0.8010871611445783, 0.8030167545180723, 0.8060758659638554, 0.8068288780120482, 0.8112292921686747, 0.8118411144578314, 0.8171827936746988, 0.8189006024096386, 0.8211831701807228, 0.8221479668674698, 0.8241716867469879, 0.8239834337349398, 0.8268778237951807, 0.831066453313253, 0.8337255271084337, 0.8335372740963856, 0.8353962725903614, 0.8373729292168675, 0.8373258659638554, 0.839867281626506, 0.8400320030120482, 0.8411615210843374, 0.8425498870481928, 0.8401025978915663, 0.8419380647590361, 0.8420321912650602, 0.8443618222891566, 0.8422204442771084, 0.8450913027108434, 0.8463855421686747, 0.848621046686747, 0.8503153237951807, 0.8512330572289156, 0.8543627635542169, 0.8530214608433735, 0.8576101280120482, 0.8552569653614458, 0.8587867093373494, 0.8577513177710844, 0.8588573042168675, 0.8579866340361446, 0.8631871234939759, 0.8619399472891566, 0.8640107304216867, 0.8668815888554217, 0.8661521084337349, 0.8687876506024096, 0.8690464984939759, 0.8714231927710844, 0.8713996611445783, 0.872082078313253, 0.8738469503012049, 0.8762707078313253, 0.8770943147590361, 0.8781767695783133, 0.879847515060241, 0.8816359186746988, 0.8816123870481928, 0.8834478539156626, 0.8830007530120482, 0.8823653990963856, 0.8831890060240963, 0.8851421310240963, 0.8853303840361446, 0.8842008659638554, 0.8832831325301205, 0.8839655496987951, 0.8821771460843374, 0.8841773343373494, 0.8842949924698795, 0.8849538780120482, 0.8838714231927711, 0.8847185617469879, 0.8867658132530121, 0.8880600527108434, 0.8902955572289156, 0.8895190135542169, 0.8907897213855421, 0.8910485692771084, 0.890648531626506, 0.8903896837349398, 0.8909544427710844, 0.8922722138554217, 0.8928134412650602, 0.8927193147590361, 0.8926487198795181, 0.8937782379518072, 0.895496046686747, 0.8946489081325302, 0.8962725903614458, 0.8961314006024096, 0.8964137801204819, 0.8970256024096386, 0.8968373493975904, 0.8968608810240963, 0.8966726280120482, 0.8985786897590361, 0.8976138930722891, 0.8997317394578314, 0.8988610692771084, 0.8989081325301205, 0.8985786897590361, 0.9017083960843374, 0.9002494352409639, 0.901402484939759, 0.9024143448795181, 0.9026261295180723, 0.9022260918674698, 0.9023908132530121, 0.9025555346385542, 0.9034497364457831, 0.9027202560240963, 0.9026261295180723, 0.9034967996987951, 0.9010495105421686, 0.9018966490963856, 0.9027908509036144, 0.9032379518072289, 0.9027673192771084, 0.9024378765060241, 0.9034732680722891, 0.9051910768072289, 0.9058028990963856, 0.9057558358433735, 0.9071206701807228, 0.9067676957831325, 0.9078266189759037, 0.907191265060241, 0.9075913027108434, 0.909214984939759, 0.9085796310240963, 0.9085325677710844, 0.9090973268072289, 0.9103915662650602, 0.9094973644578314, 0.912109375, 0.9116152108433735, 0.912109375, 0.9132388930722891, 0.9142272213855421, 0.9126741340361446, 0.9133800828313253, 0.9147684487951807, 0.9152155496987951, 0.9141801581325302, 0.9159450301204819, 0.916980421686747, 0.9156155873493976, 0.9156861822289156, 0.9154273343373494, 0.9163215361445783, 0.9160862198795181, 0.9172628012048193, 0.9167451054216867, 0.9167215737951807, 0.9164627259036144, 0.9163685993975904, 0.9165333207831325, 0.9169333584337349, 0.9169098268072289, 0.9174981174698795, 0.9172628012048193, 0.9170980798192772, 0.9181334713855421, 0.9190747364457831, 0.918980609939759, 0.9193806475903614, 0.9191217996987951, 0.9195453689759037, 0.9195689006024096, 0.9206513554216867, 0.9190512048192772, 0.9211925828313253, 0.9210749246987951, 0.9212161144578314, 0.9210984563253012, 0.9221573795180723, 0.9229103915662651, 0.9220867846385542, 0.9222279743975904, 0.9227692018072289, 0.921898531626506, 0.9229103915662651, 0.9235222138554217, 0.9231457078313253, 0.9235457454819277, 0.9235457454819277, 0.9231927710843374, 0.9240163780120482, 0.9245576054216867, 0.9246987951807228, 0.924769390060241, 0.9258518448795181, 0.9252164909638554, 0.9260636295180723, 0.9253812123493976, 0.925757718373494, 0.9256635918674698, 0.9262989457831325, 0.9263460090361446, 0.9263460090361446, 0.9262048192771084, 0.9265107304216867, 0.9260400978915663, 0.9270284262048193, 0.9271460843373494, 0.9274284638554217, 0.9268401731927711, 0.9276637801204819, 0.9276637801204819, 0.9260871611445783, 0.9264401355421686, 0.9266989834337349, 0.9260400978915663, 0.926793109939759, 0.9256871234939759, 0.9250753012048193, 0.9248870481927711, 0.9239222515060241, 0.9251929593373494, 0.9251458960843374, 0.9250282379518072, 0.9246282003012049, 0.9251694277108434, 0.9238987198795181, 0.9251223644578314, 0.9259459713855421, 0.9250517695783133, 0.9257106551204819, 0.9253106174698795, 0.9257106551204819, 0.9252870858433735, 0.9262754141566265, 0.926746046686747, 0.9274990587349398, 0.9272402108433735, 0.9279226280120482, 0.9273108057228916, 0.9284873870481928, 0.9286521084337349, 0.9283461972891566, 0.9293580572289156, 0.9292874623493976, 0.9290050828313253, 0.929663968373494, 0.9295463102409639, 0.929663968373494, 0.9293815888554217, 0.9290756777108434, 0.9293580572289156, 0.9295463102409639, 0.9298992846385542, 0.9302993222891566, 0.9296404367469879, 0.9301581325301205, 0.9300875376506024, 0.9304169804216867], "end": "2016-01-18 00:35:54.584000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0, 281.0, 282.0, 283.0, 284.0, 285.0, 286.0, 287.0, 288.0, 289.0, 290.0, 291.0, 292.0, 293.0, 294.0, 295.0, 296.0, 297.0, 298.0, 299.0, 300.0, 301.0], "accuracy_valid": [0.24892241379310345, 0.33230064655172414, 0.36853448275862066, 0.4124461206896552, 0.4401939655172414, 0.46565193965517243, 0.4870689655172414, 0.5037715517241379, 0.5158943965517241, 0.5315193965517241, 0.5509159482758621, 0.576104525862069, 0.6006196120689655, 0.6251346982758621, 0.6301185344827587, 0.6454741379310345, 0.6522090517241379, 0.6555765086206896, 0.6701239224137931, 0.671875, 0.6729525862068966, 0.6839978448275862, 0.6910021551724138, 0.6957165948275862, 0.7019127155172413, 0.7046066810344828, 0.7086476293103449, 0.7097252155172413, 0.7145743534482759, 0.7145743534482759, 0.7171336206896551, 0.7217133620689655, 0.7249461206896551, 0.7266971982758621, 0.7269665948275862, 0.7306034482758621, 0.7292564655172413, 0.7332974137931034, 0.7384159482758621, 0.7407058189655172, 0.7464978448275862, 0.7455549568965517, 0.7504040948275862, 0.7516163793103449, 0.7528286637931034, 0.7595635775862069, 0.7579471982758621, 0.7609105603448276, 0.7594288793103449, 0.7648168103448276, 0.763739224137931, 0.7673760775862069, 0.7712823275862069, 0.7708782327586207, 0.7723599137931034, 0.7707435344827587, 0.7735721982758621, 0.7755926724137931, 0.7784213362068966, 0.7790948275862069, 0.7799030172413793, 0.7785560344827587, 0.7808459051724138, 0.7824622844827587, 0.7852909482758621, 0.7811153017241379, 0.7848868534482759, 0.7838092672413793, 0.7834051724137931, 0.7846174568965517, 0.7856950431034483, 0.7850215517241379, 0.78515625, 0.7838092672413793, 0.787042025862069, 0.7879849137931034, 0.7900053879310345, 0.79296875, 0.7926993534482759, 0.7912176724137931, 0.7920258620689655, 0.7906788793103449, 0.7924299568965517, 0.7935075431034483, 0.7947198275862069, 0.7953933189655172, 0.7970096982758621, 0.7980872844827587, 0.7980872844827587, 0.7991648706896551, 0.7995689655172413, 0.8021282327586207, 0.8025323275862069, 0.8032058189655172, 0.8025323275862069, 0.8050915948275862, 0.8040140086206896, 0.8048221982758621, 0.8073814655172413, 0.8069773706896551, 0.8081896551724138, 0.8087284482758621, 0.8094019396551724, 0.8084590517241379, 0.8064385775862069, 0.80859375, 0.8096713362068966, 0.8094019396551724, 0.8084590517241379, 0.8057650862068966, 0.8054956896551724, 0.8077855603448276, 0.8058997844827587, 0.8061691810344828, 0.8052262931034483, 0.8045528017241379, 0.8041487068965517, 0.8057650862068966, 0.8049568965517241, 0.8077855603448276, 0.8092672413793104, 0.8046875, 0.8102101293103449, 0.8079202586206896, 0.8083243534482759, 0.8084590517241379, 0.8096713362068966, 0.8107489224137931, 0.8111530172413793, 0.8095366379310345, 0.8115571120689655, 0.8096713362068966, 0.8123653017241379, 0.8108836206896551, 0.8119612068965517, 0.8120959051724138, 0.8115571120689655, 0.8119612068965517, 0.8120959051724138, 0.8116918103448276, 0.8123653017241379, 0.8149245689655172, 0.8131734913793104, 0.8137122844827587, 0.8119612068965517, 0.8127693965517241, 0.8115571120689655, 0.8153286637931034, 0.8133081896551724, 0.8131734913793104, 0.8155980603448276, 0.8133081896551724, 0.8138469827586207, 0.8135775862068966, 0.8137122844827587, 0.8126346982758621, 0.8147898706896551, 0.8157327586206896, 0.8153286637931034, 0.8135775862068966, 0.8125, 0.814385775862069, 0.8172144396551724, 0.81640625, 0.8146551724137931, 0.8149245689655172, 0.8154633620689655, 0.8158674568965517, 0.8178879310344828, 0.8160021551724138, 0.818292025862069, 0.8153286637931034, 0.8150592672413793, 0.8172144396551724, 0.8178879310344828, 0.81640625, 0.8169450431034483, 0.8161368534482759, 0.8181573275862069, 0.8160021551724138, 0.8186961206896551, 0.8168103448275862, 0.8165409482758621, 0.8169450431034483, 0.8193696120689655, 0.8150592672413793, 0.8166756465517241, 0.8174838362068966, 0.8195043103448276, 0.8173491379310345, 0.81640625, 0.818292025862069, 0.8173491379310345, 0.8173491379310345, 0.8157327586206896, 0.8192349137931034, 0.8189655172413793, 0.8207165948275862, 0.8181573275862069, 0.8174838362068966, 0.8191002155172413, 0.8193696120689655, 0.8192349137931034, 0.8185614224137931, 0.8170797413793104, 0.8169450431034483, 0.8174838362068966, 0.8174838362068966, 0.8191002155172413, 0.8193696120689655, 0.8188308189655172, 0.8189655172413793, 0.8189655172413793, 0.8191002155172413, 0.818426724137931, 0.8219288793103449, 0.8201778017241379, 0.8201778017241379, 0.8207165948275862, 0.8200431034482759, 0.8203125, 0.8217941810344828, 0.8213900862068966, 0.8226023706896551, 0.8201778017241379, 0.8219288793103449, 0.8208512931034483, 0.8216594827586207, 0.8211206896551724, 0.8220635775862069, 0.8224676724137931, 0.8226023706896551, 0.8197737068965517, 0.8217941810344828, 0.8231411637931034, 0.8226023706896551, 0.8220635775862069, 0.8219288793103449, 0.8217941810344828, 0.8217941810344828, 0.8235452586206896, 0.8231411637931034, 0.8224676724137931, 0.8220635775862069, 0.8212553879310345, 0.8236799568965517, 0.8217941810344828, 0.8217941810344828, 0.8231411637931034, 0.8234105603448276, 0.8215247844827587, 0.8244881465517241, 0.822198275862069, 0.8239493534482759, 0.8224676724137931, 0.8220635775862069, 0.8234105603448276, 0.8228717672413793, 0.8236799568965517, 0.8239493534482759, 0.8226023706896551, 0.8217941810344828, 0.8224676724137931, 0.8220635775862069, 0.8216594827586207, 0.8226023706896551, 0.822198275862069, 0.8219288793103449, 0.8217941810344828, 0.8212553879310345, 0.822198275862069, 0.8209859913793104, 0.8212553879310345, 0.8212553879310345, 0.8213900862068966, 0.8227370689655172, 0.8217941810344828, 0.8209859913793104, 0.8216594827586207, 0.8228717672413793, 0.8224676724137931, 0.8236799568965517, 0.822198275862069, 0.8226023706896551, 0.8231411637931034, 0.8238146551724138, 0.8239493534482759, 0.8235452586206896, 0.8236799568965517, 0.8230064655172413, 0.8232758620689655, 0.8226023706896551, 0.8238146551724138, 0.8231411637931034, 0.8230064655172413, 0.8232758620689655, 0.8244881465517241, 0.8227370689655172, 0.8227370689655172, 0.8231411637931034, 0.8240840517241379, 0.8240840517241379], "accuracy_test": 0.8251201923076923, "start": "2016-01-17 15:09:20.412000", "learning_rate_per_epoch": [0.0008402162347920239, 0.0008273703278973699, 0.0008147208136506379, 0.0008022646652534604, 0.0007899989723227918, 0.0007779208244755864, 0.0007660273113287985, 0.0007543156389147043, 0.0007427830132655799, 0.0007314266986213624, 0.0007202440174296498, 0.000709232350345701, 0.0006983890198171139, 0.0006877114647068083, 0.0006771971820853651, 0.0006668436108157039, 0.0006566483643837273, 0.000646608998067677, 0.0006367231253534555, 0.0006269883597269654, 0.000617402431089431, 0.0006079630693420768, 0.000598668004386127, 0.0005895150825381279, 0.0005805020919069648, 0.0005716268788091838, 0.0005628873477689922, 0.0005542814615182579, 0.000545807124581188, 0.0005374623578973114, 0.0005292451824061573, 0.0005211536190472543, 0.0005131858051754534, 0.0005053397617302835, 0.0004976136842742562, 0.0004900057683698833, 0.0004825141513720155, 0.0004751370579469949, 0.0004678727709688246, 0.00046071954420767725, 0.00045367568964138627, 0.0004467395192477852, 0.0004399094032123685, 0.0004331837117206305, 0.0004265608440618962, 0.00042003922862932086, 0.0004136173229198903, 0.00040729358443059027, 0.00040106652886606753, 0.0003949347010347992, 0.00038889661664143205, 0.00038295084959827363, 0.0003770959738176316, 0.0003713306214194745, 0.00036565339541994035, 0.00036006298614665866, 0.0003545580548234284, 0.00034913726267404854, 0.00034379935823380947, 0.0003385430609341711, 0.00033336711931042373, 0.00032827031100168824, 0.0003232514427509159, 0.0003183092921972275, 0.0003134427242912352, 0.00030865054577589035, 0.00030393165070563555, 0.00029928487492725253, 0.00029470917070284486, 0.0002902034029830247, 0.00028576652402989566, 0.00028139748610556126, 0.00027709524147212505, 0.00027285877149552107, 0.0002686870866455138, 0.0002645791682880372, 0.0002605340559966862, 0.0002565507893450558, 0.00025262843701057136, 0.0002487660385668278, 0.0002449626917950809, 0.00024121749447658658, 0.00023752955894451588, 0.0002338980120839551, 0.00023032198077999055, 0.00022680062102153897, 0.00022333310334943235, 0.00021991859830450267, 0.00021655630553141236, 0.00021324541012290865, 0.00020998514082748443, 0.00020677471184171736, 0.00020361336646601558, 0.0002005003480007872, 0.0001974349288502708, 0.000194416381418705, 0.00019144397811032832, 0.00018851702043320984, 0.00018563480989541858, 0.00018279666255693883, 0.00018000190902967006, 0.000177249894477427, 0.00017453994951210916, 0.00017187143384944648, 0.00016924372175708413, 0.0001666561875026673, 0.00016410820535384119, 0.0001615991786820814, 0.0001591285108588636, 0.00015669561980757862, 0.00015429992345161736, 0.0001519408542662859, 0.00014961785927880555, 0.00014733037096448243, 0.0001450778654543683, 0.00014285978977568448, 0.00014067563461139798, 0.00013852486154064536, 0.00013640697579830885, 0.00013432146806735545, 0.0001322678435826674, 0.00013024562213104218, 0.00012825432349927723, 0.00012629346747417003, 0.00012436258839443326, 0.00012246123515069485, 0.00012058894208166748, 0.00011874527990585193, 0.00011692980478983372, 0.00011514208745211363, 0.0001133816986111924, 0.00011164822353748605, 0.00010994125477736816, 0.00010826037760125473, 0.0001066051991074346, 0.0001049753263941966, 0.00010337037383578718, 0.0001017899630824104, 0.00010023371578427032, 9.870126086752862e-05, 9.719223453430459e-05, 9.570628026267514e-05, 9.424304153071716e-05, 9.28021763684228e-05, 9.138333552982658e-05, 8.998619159683585e-05, 8.861040987540036e-05, 8.725566294742748e-05, 8.592162339482456e-05, 8.46079783514142e-05, 8.33144222269766e-05, 8.204064215533435e-05, 8.078633254626766e-05, 7.955120236147195e-05, 7.833495328668505e-05, 7.713730155956e-05, 7.595796341774985e-05, 7.479665509890765e-05, 7.365310011664405e-05, 7.252702926052734e-05, 7.141817332012579e-05, 7.032627036096528e-05, 6.925106572452933e-05, 6.819229747634381e-05, 6.714971823384985e-05, 6.612308061448857e-05, 6.511213723570108e-05, 6.411664799088612e-05, 6.313638004940003e-05, 6.217110058059916e-05, 6.122057675383985e-05, 6.028458665241487e-05, 5.936290472163819e-05, 5.8455316320760176e-05, 5.756160317105241e-05, 5.668155426974408e-05, 5.581495861406438e-05, 5.4961612477200106e-05, 5.412131213233806e-05, 5.3293861128622666e-05, 5.247905937721953e-05, 5.167671406525187e-05, 5.088663601782173e-05, 5.010863969800994e-05, 4.934253593091853e-05, 4.8588146455585957e-05, 4.7845289373071864e-05, 4.711379006039351e-05, 4.639347389456816e-05, 4.5684169890591875e-05, 4.498571070143953e-05, 4.4297932618064806e-05, 4.362066829344258e-05, 4.295375765650533e-05, 4.2297044274164364e-05, 4.165037171333097e-05, 4.101358717889525e-05, 4.038653787574731e-05, 3.976907464675605e-05, 3.91610519727692e-05, 3.856232433463447e-05, 3.797274985117838e-05, 3.739219027920626e-05, 3.682050737552345e-05, 3.625756289693527e-05, 3.570322587620467e-05, 3.5157365346094593e-05, 3.4619850339367986e-05, 3.40905535267666e-05, 3.356934757903218e-05, 3.3056112442864105e-05, 3.2550724426982924e-05, 3.20530598401092e-05, 3.156300590489991e-05, 3.108044256805442e-05, 3.060525705222972e-05, 3.0137338399072178e-05, 2.9676573831238784e-05, 2.9222854209365323e-05, 2.8776070394087583e-05, 2.8336116884020157e-05, 2.7902889996767044e-05, 2.7476287868921645e-05, 2.7056206818087958e-05, 2.664254861883819e-05, 2.6235215045744553e-05, 2.5834109692368656e-05, 2.5439136152272113e-05, 2.505020165699534e-05, 2.466721343807876e-05, 2.4290080546052195e-05, 2.391871385043487e-05, 2.355302422074601e-05, 2.319292616448365e-05, 2.2838332370156422e-05, 2.2489160983241163e-05, 2.214532833022531e-05, 2.1806752556585707e-05, 2.147335180779919e-05, 2.1145049686310813e-05, 2.082176615658682e-05, 2.0503424821072258e-05, 2.0189951101201586e-05, 1.9881270418409258e-05, 1.9577308194129728e-05, 1.9277993487776257e-05, 1.8983255358762108e-05, 1.869302286650054e-05, 1.8407228708383627e-05, 1.812580376281403e-05, 1.784868072718382e-05, 1.757579593686387e-05, 1.730708208924625e-05, 1.7042477338691242e-05, 1.678191802056972e-05, 1.6525342289241962e-05, 1.627268829906825e-05, 1.602389784238767e-05, 1.5778910892549902e-05, 1.5537669241894037e-05, 1.5300116501748562e-05, 1.5066195373947266e-05, 1.4835850379313342e-05, 1.4609027857659385e-05, 1.4385673239303287e-05, 1.4165732864057645e-05, 1.3949154890724458e-05, 1.3735888387600426e-05, 1.352588242298225e-05, 1.3319086974661332e-05, 1.3115453839418478e-05, 1.2914933904539794e-05, 1.2717479876300786e-05, 1.2523044460976962e-05, 1.2331581274338532e-05, 1.214304575114511e-05, 1.1957392416661605e-05, 1.1774577615142334e-05, 1.1594557690841611e-05, 1.1417290807003155e-05, 1.124273330788128e-05, 1.107084517570911e-05, 1.090158457373036e-05, 1.0734912393672857e-05, 1.057078770827502e-05, 1.0409172318759374e-05, 1.0250028026348446e-05, 1.009331663226476e-05, 9.939001756720245e-06, 9.78704611043213e-06, 9.637413313612342e-06, 9.490068805462215e-06, 9.34497711568838e-06, 9.202103683492169e-06, 9.061413948074915e-06, 8.922875167627353e-06, 8.786454600340221e-06, 8.652119504404254e-06, 8.519838956999592e-06, 8.389580216316972e-06, 8.261313269031234e-06, 8.135007192322519e-06], "accuracy_train_last": 0.9304169804216867, "error_valid": [0.7510775862068966, 0.6676993534482758, 0.6314655172413793, 0.5875538793103448, 0.5598060344827587, 0.5343480603448276, 0.5129310344827587, 0.4962284482758621, 0.4841056034482759, 0.4684806034482759, 0.4490840517241379, 0.42389547413793105, 0.3993803879310345, 0.3748653017241379, 0.3698814655172413, 0.3545258620689655, 0.3477909482758621, 0.3444234913793104, 0.32987607758620685, 0.328125, 0.3270474137931034, 0.3160021551724138, 0.3089978448275862, 0.3042834051724138, 0.2980872844827587, 0.29539331896551724, 0.29135237068965514, 0.2902747844827587, 0.2854256465517241, 0.2854256465517241, 0.28286637931034486, 0.2782866379310345, 0.27505387931034486, 0.2733028017241379, 0.2730334051724138, 0.2693965517241379, 0.2707435344827587, 0.2667025862068966, 0.2615840517241379, 0.25929418103448276, 0.2535021551724138, 0.2544450431034483, 0.2495959051724138, 0.24838362068965514, 0.24717133620689657, 0.24043642241379315, 0.2420528017241379, 0.23908943965517238, 0.24057112068965514, 0.23518318965517238, 0.23626077586206895, 0.23262392241379315, 0.22871767241379315, 0.22912176724137934, 0.22764008620689657, 0.22925646551724133, 0.2264278017241379, 0.22440732758620685, 0.22157866379310343, 0.22090517241379315, 0.22009698275862066, 0.22144396551724133, 0.2191540948275862, 0.21753771551724133, 0.2147090517241379, 0.2188846982758621, 0.2151131465517241, 0.21619073275862066, 0.21659482758620685, 0.2153825431034483, 0.2143049568965517, 0.2149784482758621, 0.21484375, 0.21619073275862066, 0.21295797413793105, 0.21201508620689657, 0.20999461206896552, 0.20703125, 0.2073006465517241, 0.20878232758620685, 0.20797413793103448, 0.20932112068965514, 0.2075700431034483, 0.2064924568965517, 0.20528017241379315, 0.20460668103448276, 0.2029903017241379, 0.20191271551724133, 0.20191271551724133, 0.20083512931034486, 0.20043103448275867, 0.19787176724137934, 0.19746767241379315, 0.19679418103448276, 0.19746767241379315, 0.1949084051724138, 0.1959859913793104, 0.1951778017241379, 0.19261853448275867, 0.19302262931034486, 0.1918103448275862, 0.1912715517241379, 0.19059806034482762, 0.1915409482758621, 0.19356142241379315, 0.19140625, 0.19032866379310343, 0.19059806034482762, 0.1915409482758621, 0.19423491379310343, 0.19450431034482762, 0.19221443965517238, 0.19410021551724133, 0.19383081896551724, 0.1947737068965517, 0.1954471982758621, 0.1958512931034483, 0.19423491379310343, 0.1950431034482759, 0.19221443965517238, 0.1907327586206896, 0.1953125, 0.18978987068965514, 0.1920797413793104, 0.1916756465517241, 0.1915409482758621, 0.19032866379310343, 0.18925107758620685, 0.18884698275862066, 0.19046336206896552, 0.18844288793103448, 0.19032866379310343, 0.1876346982758621, 0.18911637931034486, 0.1880387931034483, 0.1879040948275862, 0.18844288793103448, 0.1880387931034483, 0.1879040948275862, 0.18830818965517238, 0.1876346982758621, 0.18507543103448276, 0.1868265086206896, 0.18628771551724133, 0.1880387931034483, 0.1872306034482759, 0.18844288793103448, 0.18467133620689657, 0.18669181034482762, 0.1868265086206896, 0.18440193965517238, 0.18669181034482762, 0.18615301724137934, 0.18642241379310343, 0.18628771551724133, 0.1873653017241379, 0.18521012931034486, 0.1842672413793104, 0.18467133620689657, 0.18642241379310343, 0.1875, 0.18561422413793105, 0.18278556034482762, 0.18359375, 0.18534482758620685, 0.18507543103448276, 0.18453663793103448, 0.1841325431034483, 0.18211206896551724, 0.1839978448275862, 0.18170797413793105, 0.18467133620689657, 0.18494073275862066, 0.18278556034482762, 0.18211206896551724, 0.18359375, 0.1830549568965517, 0.1838631465517241, 0.18184267241379315, 0.1839978448275862, 0.18130387931034486, 0.1831896551724138, 0.1834590517241379, 0.1830549568965517, 0.18063038793103448, 0.18494073275862066, 0.1833243534482759, 0.18251616379310343, 0.18049568965517238, 0.18265086206896552, 0.18359375, 0.18170797413793105, 0.18265086206896552, 0.18265086206896552, 0.1842672413793104, 0.18076508620689657, 0.18103448275862066, 0.1792834051724138, 0.18184267241379315, 0.18251616379310343, 0.18089978448275867, 0.18063038793103448, 0.18076508620689657, 0.18143857758620685, 0.1829202586206896, 0.1830549568965517, 0.18251616379310343, 0.18251616379310343, 0.18089978448275867, 0.18063038793103448, 0.18116918103448276, 0.18103448275862066, 0.18103448275862066, 0.18089978448275867, 0.18157327586206895, 0.17807112068965514, 0.1798221982758621, 0.1798221982758621, 0.1792834051724138, 0.1799568965517241, 0.1796875, 0.17820581896551724, 0.17860991379310343, 0.17739762931034486, 0.1798221982758621, 0.17807112068965514, 0.1791487068965517, 0.17834051724137934, 0.17887931034482762, 0.17793642241379315, 0.17753232758620685, 0.17739762931034486, 0.1802262931034483, 0.17820581896551724, 0.17685883620689657, 0.17739762931034486, 0.17793642241379315, 0.17807112068965514, 0.17820581896551724, 0.17820581896551724, 0.1764547413793104, 0.17685883620689657, 0.17753232758620685, 0.17793642241379315, 0.17874461206896552, 0.1763200431034483, 0.17820581896551724, 0.17820581896551724, 0.17685883620689657, 0.17658943965517238, 0.17847521551724133, 0.1755118534482759, 0.17780172413793105, 0.1760506465517241, 0.17753232758620685, 0.17793642241379315, 0.17658943965517238, 0.17712823275862066, 0.1763200431034483, 0.1760506465517241, 0.17739762931034486, 0.17820581896551724, 0.17753232758620685, 0.17793642241379315, 0.17834051724137934, 0.17739762931034486, 0.17780172413793105, 0.17807112068965514, 0.17820581896551724, 0.17874461206896552, 0.17780172413793105, 0.1790140086206896, 0.17874461206896552, 0.17874461206896552, 0.17860991379310343, 0.17726293103448276, 0.17820581896551724, 0.1790140086206896, 0.17834051724137934, 0.17712823275862066, 0.17753232758620685, 0.1763200431034483, 0.17780172413793105, 0.17739762931034486, 0.17685883620689657, 0.1761853448275862, 0.1760506465517241, 0.1764547413793104, 0.1763200431034483, 0.17699353448275867, 0.17672413793103448, 0.17739762931034486, 0.1761853448275862, 0.17685883620689657, 0.17699353448275867, 0.17672413793103448, 0.1755118534482759, 0.17726293103448276, 0.17726293103448276, 0.17685883620689657, 0.1759159482758621, 0.1759159482758621], "accuracy_train_std": [0.023230375920167374, 0.02454705090122401, 0.027600631837406887, 0.02949691025144198, 0.029816752996968572, 0.031215968701046794, 0.030479125193751143, 0.02883487584326065, 0.028732299051275206, 0.030261131881791022, 0.029423454972241758, 0.030731051934046995, 0.029943363667841966, 0.02747527760273067, 0.026671258713099735, 0.027605767357500505, 0.026020489042221536, 0.02576446611762677, 0.027408931060916852, 0.026019127033843403, 0.026570249213459813, 0.02536396072328915, 0.02442955727000088, 0.025908961963931672, 0.025632682221855618, 0.024288662767377726, 0.024753492727393276, 0.022886729772670186, 0.022702898128691192, 0.022150161410440485, 0.02156304772893844, 0.023537320470752167, 0.023345887826720424, 0.022624713562545015, 0.022393801613685278, 0.022629057439065927, 0.022413883511405924, 0.022524044637459863, 0.02234756334848984, 0.02295760725817191, 0.02188138875419584, 0.022233589292107017, 0.021672308633656576, 0.022497711771608184, 0.02285840445139475, 0.022978015765434963, 0.021927195860771187, 0.022300049763600695, 0.022170001929924247, 0.02226788254889369, 0.02182349988937126, 0.021741554730674222, 0.02137889386506888, 0.022383821938939653, 0.021675732124844103, 0.021270403681993087, 0.020933732823605465, 0.020714528733658928, 0.021020223866882567, 0.020194797447431585, 0.02046282964011682, 0.021213797186427616, 0.02079536846464752, 0.02054062993938986, 0.021307143897762282, 0.019666358877439054, 0.019716526233178648, 0.020268764018521748, 0.019784389039841484, 0.019953279117116317, 0.019850778574738125, 0.01980216780995682, 0.020009092981894877, 0.01998123325064608, 0.01942846101349488, 0.02053356568853167, 0.020069939254277344, 0.01980887790733688, 0.02005072714755064, 0.020190409801687115, 0.020277340603605344, 0.02008924324345766, 0.019772686341894163, 0.020617210088896585, 0.020367734039626453, 0.02028847928531297, 0.019899354072370052, 0.01923109848875499, 0.01941610174538628, 0.019816214474690643, 0.018029464784386558, 0.01903102017478258, 0.018673276050158002, 0.01874553649257111, 0.019564124084014343, 0.01846529595784712, 0.018458232430918466, 0.018039904153701256, 0.018961191228113926, 0.019842240869073192, 0.019366685872562715, 0.018843646934306582, 0.018702610475239065, 0.017876557096772196, 0.01854041306955971, 0.017727375554546756, 0.017380810428474447, 0.018155515298506227, 0.01717752322580071, 0.018165821265987463, 0.01849567880212596, 0.018187329093123632, 0.018798883124711584, 0.019058990522562366, 0.019519693402919897, 0.018117900725175162, 0.01803574448219027, 0.019188147682750876, 0.017474478737069504, 0.01855481806500158, 0.017174283185806417, 0.017796896163690644, 0.01890638423499917, 0.018377160782542815, 0.018873024622838963, 0.017986230586568976, 0.01900848608718075, 0.019128187442398324, 0.019042495312796864, 0.018460092305216582, 0.01888872974074679, 0.018792092320280656, 0.01821847945990631, 0.018558339243115732, 0.01773304403493227, 0.017600712819390647, 0.018420619755359278, 0.01880793862351395, 0.018417372909380763, 0.018381936056841717, 0.01839982101227314, 0.017797129519191487, 0.018093801050978114, 0.017866704134184577, 0.01810504442124351, 0.01727772719858869, 0.017817777146748422, 0.01730701138087163, 0.01759846320835662, 0.017103332660138422, 0.018137755797427844, 0.018578841310771928, 0.018248666358770274, 0.018645128010027347, 0.018075735843557636, 0.018555474606512596, 0.018116234964961307, 0.017707419951347392, 0.018070711120589028, 0.019205627854346048, 0.018617621504846558, 0.018283831511706677, 0.018692704144589012, 0.01885122697086181, 0.01890443645711516, 0.01885140321451695, 0.019381962413964036, 0.018243567855325108, 0.01932863507383684, 0.018448810188131652, 0.018613323195384147, 0.01811496643931937, 0.017710609356325478, 0.01852010765629511, 0.01807026679431838, 0.01780790720924186, 0.0181006549839555, 0.017576297817569173, 0.017598762124290332, 0.018174034410422105, 0.017041788476439772, 0.017633841620216237, 0.017976268316468105, 0.01720850647264496, 0.017560349161577497, 0.017756401541459278, 0.01785424072067723, 0.017259064481068644, 0.0171735254763345, 0.01783599496735101, 0.01749411448360156, 0.017229200652151274, 0.017992263776191945, 0.01727966606679133, 0.017630952401864255, 0.017622470439071607, 0.017760065427845466, 0.01756001805779678, 0.017641313707067723, 0.01821142662330646, 0.01712203576012372, 0.017798062910598957, 0.017881636376921733, 0.017731295275610657, 0.01758152683369579, 0.017734542834244832, 0.017077023115022787, 0.01699115427343605, 0.01730195543586557, 0.017500016732355513, 0.017161010373174402, 0.01728496880166268, 0.01767989528152891, 0.017709561919016528, 0.017422241631317125, 0.017267404270289593, 0.017239546456543634, 0.016934745552569203, 0.017062100691904416, 0.01619488866532372, 0.016322554595253627, 0.01674149129340636, 0.017322218312005665, 0.016750766473042886, 0.01669341280030563, 0.01617223764677299, 0.01678497904146946, 0.016417724237048945, 0.016563055891245577, 0.016141323618312203, 0.0169474930930258, 0.016164651707200967, 0.016251071427894385, 0.015954251879166853, 0.01646070493891513, 0.01611516156553667, 0.01611119234983308, 0.016586525301225136, 0.016073117244805996, 0.01626809945877343, 0.01680212511459276, 0.016686113581213552, 0.016625006694542817, 0.016447782121838866, 0.01618141136535277, 0.01583690701652532, 0.016517391582928132, 0.01638093633553677, 0.016782999521213326, 0.016008788789410863, 0.01647193685332619, 0.016260609322048668, 0.016250202520115817, 0.015781425272169834, 0.01607573531932753, 0.01626484848218251, 0.015745946588888275, 0.016196478520490512, 0.015346824560064212, 0.015458989156492372, 0.015536220670410454, 0.015603154183257455, 0.015897072389718256, 0.016155468471822445, 0.01579245656871111, 0.015245679362659964, 0.015213155587783484, 0.0160559686474062, 0.015146838402266749, 0.01571722413367638, 0.015150932340034092, 0.015906909574802494, 0.01563444169322103, 0.015545217596737866, 0.01621846406284322, 0.01565129148368716, 0.015567073575776531, 0.01603823204446124, 0.016153960277554207, 0.016068448435284866, 0.01606257173208313, 0.016284990674987853, 0.016257969929242798, 0.016018125256246976, 0.016350399968772772, 0.015978182334026775, 0.015918793135680048, 0.015415514463403378, 0.015618920995254937, 0.016205433498873902, 0.01614516538592874, 0.015527610812139188, 0.015530534777476561, 0.015910442511837472, 0.015336483707839329, 0.015898465635388343, 0.015567571562775244, 0.01573616713053518, 0.015405722938678285, 0.015938330395179404, 0.015977697144798957, 0.01593146727375486], "accuracy_test_std": 0.019630388186371483, "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.9884930216017516, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0008532615906535701, "patience_threshold": 1, "do_flip": true, "batch_size": 256, "optimization": "nesterov_momentum", "nb_data_augmentation": 3, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.2783288048387651e-09, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.015288838708525621}, "accuracy_valid_max": 0.8244881465517241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = 1234\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -6], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256, 512],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_optimizer.learning_rate = learning_rate\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8240840517241379, "loss_train": [2.1982409954071045, 1.957756757736206, 1.7747682332992554, 1.6414836645126343, 1.5590027570724487, 1.498402714729309, 1.445252776145935, 1.394891619682312, 1.3412694931030273, 1.2879323959350586, 1.2361435890197754, 1.1859954595565796, 1.1414506435394287, 1.102077603340149, 1.062649130821228, 1.0320379734039307, 1.0037201642990112, 0.9756596088409424, 0.950689971446991, 0.9310194253921509, 0.9085068106651306, 0.8904850482940674, 0.8738787174224854, 0.8583797216415405, 0.8413422107696533, 0.825718879699707, 0.8124921321868896, 0.799548327922821, 0.7876852750778198, 0.7783762216567993, 0.7671425938606262, 0.7566981315612793, 0.7454890012741089, 0.7331710457801819, 0.7242935299873352, 0.7158616781234741, 0.7051997184753418, 0.6930830478668213, 0.6891806125640869, 0.6859847903251648, 0.6753299832344055, 0.664212167263031, 0.6573892831802368, 0.6504732966423035, 0.643805205821991, 0.6353782415390015, 0.6313051581382751, 0.6241313219070435, 0.6183443665504456, 0.6144295930862427, 0.606163501739502, 0.6023648381233215, 0.597358226776123, 0.589486837387085, 0.5845521092414856, 0.5811210870742798, 0.5762515068054199, 0.570164680480957, 0.565146803855896, 0.5581693649291992, 0.5544801950454712, 0.5498360991477966, 0.5486313700675964, 0.5411937236785889, 0.5368066430091858, 0.5347282886505127, 0.531248927116394, 0.525560736656189, 0.5244253277778625, 0.5228611826896667, 0.5169603824615479, 0.5169286727905273, 0.515390157699585, 0.5111387968063354, 0.5129809975624084, 0.5107452273368835, 0.5083626508712769, 0.5028844475746155, 0.49985578656196594, 0.49489617347717285, 0.4940488934516907, 0.48746395111083984, 0.48836201429367065, 0.4857105612754822, 0.4805056154727936, 0.47848108410835266, 0.4737887680530548, 0.4743300676345825, 0.4671890437602997, 0.468861848115921, 0.46335285902023315, 0.4619230031967163, 0.45975029468536377, 0.4575154185295105, 0.45579227805137634, 0.4536040127277374, 0.45257335901260376, 0.451078325510025, 0.44872426986694336, 0.4455132782459259, 0.4431779980659485, 0.44370949268341064, 0.4417687952518463, 0.4391516149044037, 0.43732118606567383, 0.43648022413253784, 0.43469393253326416, 0.43134185671806335, 0.43080249428749084, 0.4304220378398895, 0.4300461709499359, 0.42778855562210083, 0.4257359206676483, 0.4269507825374603, 0.4245290756225586, 0.42310845851898193, 0.421511173248291, 0.4226907193660736, 0.4215710163116455, 0.41991278529167175, 0.4198504686355591, 0.41769179701805115, 0.41502317786216736, 0.4147322475910187, 0.4114748239517212, 0.41309186816215515, 0.4092775881290436, 0.41109511256217957, 0.408372700214386, 0.4065161645412445, 0.40516918897628784, 0.40787702798843384, 0.4032512307167053, 0.40281495451927185, 0.40106073021888733, 0.3998750150203705, 0.3997631072998047, 0.3971925973892212, 0.397495836019516, 0.39730095863342285, 0.39526596665382385, 0.3960818946361542, 0.39339059591293335, 0.39208048582077026, 0.3906766176223755, 0.39230501651763916, 0.3908365070819855, 0.3894679844379425, 0.38770729303359985, 0.38809823989868164, 0.385623037815094, 0.3866133689880371, 0.38482657074928284, 0.38209351897239685, 0.38041386008262634, 0.3809316158294678, 0.382344514131546, 0.3796408176422119, 0.3789249360561371, 0.3788889944553375, 0.3779478073120117, 0.3758862614631653, 0.377257376909256, 0.3739287853240967, 0.37410223484039307, 0.3733440041542053, 0.3721625506877899, 0.36964401602745056, 0.3703576624393463, 0.37159308791160583, 0.36643409729003906, 0.3666274845600128, 0.36475399136543274, 0.36501848697662354, 0.3643886148929596, 0.3633440136909485, 0.36049577593803406, 0.3633385896682739, 0.36241066455841064, 0.3603825569152832, 0.3583246171474457, 0.35959458351135254, 0.3571932315826416, 0.356250137090683, 0.3561578392982483, 0.35726404190063477, 0.35539907217025757, 0.3554377257823944, 0.3551262617111206, 0.3536069393157959, 0.35455939173698425, 0.35306882858276367, 0.3532719612121582, 0.3537653982639313, 0.35162490606307983, 0.35100889205932617, 0.3511045575141907, 0.34943002462387085, 0.35069024562835693, 0.34891021251678467, 0.34921520948410034, 0.3505077362060547, 0.34744271636009216, 0.3495190143585205, 0.34693485498428345, 0.34678712487220764, 0.34835705161094666, 0.3478771448135376, 0.3478444516658783, 0.3466794490814209, 0.34660622477531433, 0.3462638854980469, 0.34549492597579956, 0.3478217124938965, 0.34633880853652954, 0.3449958860874176, 0.3428988456726074, 0.3455013334751129, 0.343387633562088, 0.3425627052783966, 0.3411291539669037, 0.3413045406341553, 0.34000998735427856, 0.34115976095199585, 0.34077128767967224, 0.3387719392776489, 0.340358167886734, 0.33795249462127686, 0.3395811915397644, 0.33838286995887756, 0.33959847688674927, 0.33877038955688477, 0.3383839428424835, 0.3380117416381836, 0.33762964606285095, 0.33718615770339966, 0.3372783660888672, 0.3367650508880615, 0.33556923270225525, 0.3368125855922699, 0.3366287350654602, 0.3362604081630707, 0.33402037620544434, 0.33386924862861633, 0.33371877670288086, 0.33295708894729614, 0.33344805240631104, 0.3313670754432678, 0.3324418067932129, 0.3314764201641083, 0.3312515318393707, 0.33374035358428955, 0.3308514654636383, 0.3293003737926483, 0.32996755838394165, 0.33098840713500977, 0.3298468291759491, 0.33284202218055725, 0.33046749234199524, 0.33093464374542236, 0.33020514249801636, 0.33007797598838806, 0.3299448490142822, 0.33185386657714844, 0.330574095249176, 0.33011594414711, 0.3303534984588623, 0.32948562502861023, 0.3290612995624542, 0.3285626769065857, 0.32856470346450806, 0.329416960477829, 0.32904767990112305, 0.3290391266345978, 0.3299509286880493, 0.32848289608955383, 0.3313828408718109, 0.3276827931404114, 0.32817816734313965, 0.32809725403785706, 0.3280075788497925, 0.32674843072891235, 0.32804450392723083, 0.3296607434749603, 0.32792314887046814, 0.32951438426971436, 0.32680538296699524, 0.32548293471336365, 0.32683655619621277, 0.3245719373226166, 0.3251926600933075, 0.32726871967315674, 0.3264617323875427, 0.32572564482688904, 0.32555559277534485, 0.32597556710243225, 0.32492801547050476, 0.325557142496109, 0.325076162815094, 0.32503142952919006, 0.3235091269016266, 0.32440921664237976], "accuracy_train_first": 0.2553652108433735, "model": "residual", "loss_std": [0.08725601434707642, 0.07408814132213593, 0.07540903985500336, 0.07021672278642654, 0.074519582092762, 0.07859580963850021, 0.08605591952800751, 0.08987674117088318, 0.09268850088119507, 0.09129741787910461, 0.0931905135512352, 0.09359100461006165, 0.08904184401035309, 0.08885063976049423, 0.09085949510335922, 0.08544335514307022, 0.08635207265615463, 0.08561543375253677, 0.08016040921211243, 0.08073266595602036, 0.08443015068769455, 0.08230544626712799, 0.08011612296104431, 0.07902435213327408, 0.07864413410425186, 0.07992326468229294, 0.07774529606103897, 0.07621192187070847, 0.07590845972299576, 0.07711715251207352, 0.07794694602489471, 0.07477977871894836, 0.0757380798459053, 0.07626569271087646, 0.07611432671546936, 0.07302360981702805, 0.07479695230722427, 0.07360433787107468, 0.07442845404148102, 0.07018119841814041, 0.07398442924022675, 0.07373218983411789, 0.07445750385522842, 0.07214218378067017, 0.0696045532822609, 0.07106128334999084, 0.07048264890909195, 0.07056811451911926, 0.0684119164943695, 0.07049182802438736, 0.06982681155204773, 0.06798660010099411, 0.0699838176369667, 0.06841066479682922, 0.06750539690256119, 0.07016627490520477, 0.06986542046070099, 0.06897006183862686, 0.06903136521577835, 0.06780221313238144, 0.06623817980289459, 0.06745510548353195, 0.0671229138970375, 0.06622765213251114, 0.06694559007883072, 0.06513865292072296, 0.06611336767673492, 0.06522171944379807, 0.06497418135404587, 0.06499160826206207, 0.06628412753343582, 0.06554827094078064, 0.06553777307271957, 0.06467211246490479, 0.06559576094150543, 0.06679495424032211, 0.06453899294137955, 0.06119499355554581, 0.06397052109241486, 0.06350672990083694, 0.06352221220731735, 0.061010390520095825, 0.06189391016960144, 0.06310683488845825, 0.06286371499300003, 0.0625094398856163, 0.061926811933517456, 0.06215401366353035, 0.06088382378220558, 0.06166708469390869, 0.061202649027109146, 0.0599139966070652, 0.06142842024564743, 0.059382542967796326, 0.06044374033808708, 0.06044118106365204, 0.060017719864845276, 0.060113608837127686, 0.060075655579566956, 0.05870930105447769, 0.05909041315317154, 0.05904824286699295, 0.05964156240224838, 0.05878040939569473, 0.05847638472914696, 0.057254232466220856, 0.05787557736039162, 0.05796201154589653, 0.05716528743505478, 0.05764105170965195, 0.05731941759586334, 0.05669684335589409, 0.05846498906612396, 0.056968413293361664, 0.05549827590584755, 0.057821933180093765, 0.05733203515410423, 0.05856836959719658, 0.056094761937856674, 0.054821040481328964, 0.05723577365279198, 0.05579995736479759, 0.05622987821698189, 0.056856244802474976, 0.0565168559551239, 0.05532502755522728, 0.05509692430496216, 0.055439699441194534, 0.05455148592591286, 0.05366189032793045, 0.05544063448905945, 0.05433252453804016, 0.052458081394433975, 0.05220748856663704, 0.0534026101231575, 0.05328330770134926, 0.052905865013599396, 0.05445467308163643, 0.05247659236192703, 0.052806708961725235, 0.05338853597640991, 0.053546685725450516, 0.05130014196038246, 0.05380493775010109, 0.052564918994903564, 0.05339440703392029, 0.05260614678263664, 0.05343352630734444, 0.051967937499284744, 0.05371110886335373, 0.0532018207013607, 0.054021354764699936, 0.051937416195869446, 0.05305544659495354, 0.05241962522268295, 0.051258765161037445, 0.0526205450296402, 0.052519988268613815, 0.05159309506416321, 0.051935985684394836, 0.051080554723739624, 0.051920127123594284, 0.05263746902346611, 0.052217110991477966, 0.05042644217610359, 0.0511983297765255, 0.04982507601380348, 0.050968144088983536, 0.05000406503677368, 0.05186416953802109, 0.05231989920139313, 0.05071660503745079, 0.051571667194366455, 0.05119244009256363, 0.05067043751478195, 0.04956892132759094, 0.050225839018821716, 0.0500950962305069, 0.051476385444402695, 0.04980193078517914, 0.04940470680594444, 0.05039243400096893, 0.05002690851688385, 0.04947003722190857, 0.05009577423334122, 0.04991183802485466, 0.04877789691090584, 0.0495728924870491, 0.050137005746364594, 0.04987018555402756, 0.04888789728283882, 0.04704560711979866, 0.049228485673666, 0.04866854101419449, 0.049438122659921646, 0.049920834600925446, 0.04983729124069214, 0.04860340803861618, 0.05011166259646416, 0.04840577766299248, 0.04954148828983307, 0.04958581551909447, 0.04963880032300949, 0.04923735931515694, 0.04919153451919556, 0.04920255020260811, 0.04924667626619339, 0.04982926696538925, 0.04920857772231102, 0.04958482086658478, 0.04950372502207756, 0.048524901270866394, 0.04979604855179787, 0.04918406903743744, 0.04888717085123062, 0.051105622202157974, 0.04987660422921181, 0.049686506390571594, 0.05048852413892746, 0.04845249280333519, 0.04924584925174713, 0.04915603995323181, 0.04859543219208717, 0.049241803586483, 0.048518531024456024, 0.047809898853302, 0.04789477214217186, 0.04731638357043266, 0.05002318695187569, 0.048800088465213776, 0.0488918237388134, 0.04888119176030159, 0.049369629472494125, 0.04783305153250694, 0.04979189857840538, 0.04801604524254799, 0.04936828464269638, 0.04994780942797661, 0.04777059331536293, 0.049034565687179565, 0.0479271374642849, 0.048001449555158615, 0.048410478979349136, 0.048571813851594925, 0.04839831590652466, 0.047359634190797806, 0.048297982662916183, 0.05035361275076866, 0.0473935566842556, 0.048021040856838226, 0.04813292622566223, 0.04983219504356384, 0.04825083166360855, 0.047585975378751755, 0.04815242812037468, 0.04910001531243324, 0.050366293638944626, 0.04937220737338066, 0.04734291881322861, 0.04957680031657219, 0.04737254977226257, 0.04758494719862938, 0.04783555492758751, 0.0487891249358654, 0.04766857996582985, 0.0479244701564312, 0.04851379618048668, 0.048079196363687515, 0.04617032781243324, 0.04875732213258743, 0.046775054186582565, 0.04836321622133255, 0.048176251351833344, 0.04697481915354729, 0.04639148712158203, 0.04771672189235687, 0.04840908572077751, 0.047283612191677094, 0.047915663570165634, 0.04724385216832161, 0.04669453576207161, 0.047675929963588715, 0.048108942806720734, 0.04958062991499901, 0.04710749164223671, 0.048752959817647934, 0.04773877561092377, 0.04688826575875282, 0.04713534936308861, 0.0472334660589695, 0.048473257571458817, 0.047970689833164215, 0.04773278906941414, 0.04903789982199669, 0.047137629240751266, 0.046751584857702255, 0.047971975058317184, 0.04744986444711685, 0.04681194946169853, 0.04729082062840462, 0.04663081467151642, 0.047654248774051666]}, "state": "available", "life": [{"dt": "Sun May 15 22:04:59 2016", "state": "available"}], "summary": "56686b831feb5ec49f2fe32b4a6ab29f"}