{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 16, "f3": 16, "nonlin": "leaky_rectify", "nbg1": 3, "nbg3": 7, "nbg2": 7, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.015364320910849617, 0.009458708508195416, 0.006610160792745945, 0.009863992534642537, 0.012357469320280154, 0.012179419733348566, 0.012282404444698665, 0.01658016682544803, 0.01254214859603207, 0.013820481231034847, 0.012803653993717775, 0.01037121473494049, 0.010215414116086395, 0.011675923212796037, 0.010179439568869823, 0.011011512672324374, 0.01230231261963744, 0.008696466290703198, 0.013687855067096796, 0.009486100743426725, 0.009688218477344876, 0.009459712826461747, 0.012721241739384485, 0.011405166418004084, 0.012703447193347376, 0.011207920266930417, 0.01028045128786738, 0.014573395041507745, 0.01588602441789594, 0.014527711878975905, 0.013744754793332856, 0.01561868438630263, 0.016070377538938873, 0.012983763428904909, 0.015945946343733808, 0.013436183964864672, 0.011859228813557204, 0.01292266302585241, 0.012239580221407044, 0.011693128615642282, 0.012609920041301062, 0.01278162939026916, 0.014039218636382663, 0.012114346009640254, 0.0123186659167578, 0.013423581225411388, 0.013165775152866925, 0.011092062489215586, 0.01370236522420782, 0.011728163816206345, 0.016448296578314005, 0.01417562831041898, 0.014976917783580077, 0.014514614711968674, 0.013486368091424115, 0.012119458740301495, 0.012359986734787567, 0.014728953501763445, 0.013159871131453706, 0.013628913336166573, 0.015376988140020663, 0.013698652754022194, 0.013659908955536015, 0.011034137400550403, 0.012773466167785172, 0.014490371684321334, 0.012194700598649773, 0.01588308084824076, 0.013879745146554049, 0.013064785671846052, 0.013675676590981343, 0.014707281567669308, 0.017238654533685047, 0.014307385844722811, 0.014281337071547984, 0.013513334568846033, 0.014200562829301886, 0.01631156221284885, 0.015636891900719405, 0.014060583048724463, 0.015562471374776593, 0.01636642703498947, 0.014242077646771326, 0.01728765534359342, 0.015041380226080512, 0.015727715140848815, 0.01427508468743425, 0.016304516841528553, 0.015010565027481135, 0.014487266376089264, 0.0166347598092425, 0.014298533746721716, 0.015476685677637112, 0.01689827321475184, 0.01359445403232653, 0.014695489492940757, 0.015607410527618815, 0.014510594883172596, 0.014569869255796904, 0.014571255431331078, 0.014899448476431066, 0.013248752419194426, 0.013822669295696094, 0.010744671178380303, 0.01662291235342822, 0.014221734144146568, 0.014105873002763272, 0.014841341568402078, 0.012215529357826684, 0.01357151718577398, 0.012812728125776723, 0.012929018426525395, 0.01590566332843841, 0.013793733146120868, 0.011937662687016853, 0.014400117672110248, 0.016137524632459366, 0.015129197412631154, 0.016556929112580075, 0.013651152600203168, 0.013317712729786465, 0.013602797835891545, 0.014918096593806465, 0.01449906809637571, 0.012815885756534896, 0.013576726259048842, 0.012030247385079601, 0.012662842407882553, 0.014994440763766843, 0.011541767207404605, 0.01257291901572193, 0.011434748236318421, 0.013357018364835884, 0.01265975663821821, 0.01468175468726816, 0.013480751375148356, 0.013083662039628621, 0.013206101724184845, 0.013678322701444432, 0.012513823191937301, 0.01358874772504711, 0.013494360369127125, 0.01156445294770825, 0.013494967140539013, 0.014164702430233276, 0.01299975142040605, 0.012039682728601026, 0.015264952961911668, 0.013280976372708257, 0.0120914640701987, 0.011924212029517194, 0.01322317078937846, 0.014162339869365381, 0.01500497351707918, 0.015563753371068452, 0.01591168226657625, 0.013237411123097412, 0.013786505308664208, 0.015431202112061676, 0.014320665664523322, 0.015529168624867562, 0.014807771398662782, 0.015329180609851913, 0.013564028055156387, 0.013893822550611522, 0.013393856468173957, 0.012666928646104376, 0.014721158960125791, 0.01406335799307463, 0.014199312527556558, 0.012625474806123253, 0.014483314003725363, 0.016380441947902773, 0.01262469980178666, 0.016372239855253937, 0.014281428552485353, 0.013868362821094552, 0.016752185235671874, 0.012442124209464129, 0.015223988771668228, 0.013158231559498421, 0.013294262631060086, 0.015838854829644793, 0.013461012024901705, 0.01594992257472455, 0.013389774309671403, 0.013806292933397652, 0.013752642837537877, 0.013706734291923518, 0.013715143606616215, 0.015320552452221973, 0.01621220172269213, 0.01667030660809036, 0.015216156398406882, 0.01515556574215246, 0.01340205926007497, 0.013685396910064698, 0.014245600214364293, 0.01787853985001307, 0.014024441533370756, 0.014742928748765519, 0.012841228676436752, 0.013420613074223667, 0.013013317907107786, 0.014576546329184042, 0.014912631922947764, 0.013448664239298407, 0.011090110290973452, 0.015538899067067366, 0.01450359066648207, 0.01314458277680571, 0.014478459194368475, 0.014486665630635791, 0.017423683741770172, 0.01442937762872852, 0.013069289847550675, 0.014787719988521282, 0.013802975196536702, 0.014782168124041404, 0.012618449970696296, 0.01229275113307369, 0.014885864297102008, 0.01212323605003914, 0.015802790799649715, 0.015726257733825147, 0.01590380611846919, 0.014312990923574144, 0.013440824710463354, 0.013438366435182005, 0.015084550882385358, 0.01444816117547331, 0.014630851982200061, 0.017427578432607355, 0.014527477821374523, 0.013094129113055788, 0.015356766321218407, 0.01391328055383856, 0.012345183539360968, 0.013688699452949562, 0.01326504971936461, 0.013941324486082386, 0.014857542376775662, 0.013617053296489426, 0.014358401176602786, 0.01480254393253396, 0.01471519782143404, 0.013391928486371683, 0.012773827107247499, 0.015228497820377246, 0.013669505114754272, 0.01498036047281368, 0.014357515350308424, 0.013847652979871497, 0.013204114056120085, 0.01440497861290233, 0.013253506777095723, 0.012963462219945246, 0.013839413428262372, 0.013773731335526392, 0.01613213239965294, 0.014537294878136198, 0.012552479609840345, 0.012849167379391882, 0.011546864089110254, 0.014410168598815899, 0.011496889084984325, 0.012537975628649748, 0.012542045032515005, 0.012631600523422572, 0.013351013895689993], "moving_avg_accuracy_train": [0.038816142372646724, 0.08561435478382243, 0.13115794249204038, 0.1765221642196728, 0.22022820961018244, 0.26052801043649343, 0.29781806682409173, 0.32979168981476303, 0.36174614053843623, 0.3897795916147144, 0.41594197410952755, 0.43957393256789923, 0.4618866509470912, 0.48227251173831787, 0.5011222709350103, 0.5180824039144144, 0.5327137586803188, 0.5474514534160614, 0.5603620281568196, 0.572518510603227, 0.5838197068216511, 0.594186204064689, 0.6035092563810884, 0.6121253266074591, 0.6202282737420712, 0.6275235757514005, 0.634407820849064, 0.6406802632012193, 0.6459861337872436, 0.6516469385229064, 0.6564000822029156, 0.6606826339101802, 0.6648947870704727, 0.6690040900575469, 0.6728492355114637, 0.676137517017534, 0.6793970948135195, 0.6824028304918205, 0.6851427977367968, 0.6879668051251234, 0.6902690295936926, 0.6922712771511192, 0.6942896108897265, 0.6963385179889691, 0.6981432591902567, 0.6996464743380453, 0.7014387850472363, 0.703198096718777, 0.7044584978315522, 0.70567896143664, 0.706937669753801, 0.708226148014209, 0.7093602739093089, 0.7102811500113644, 0.7112795662198533, 0.7124199562836837, 0.7133486510911312, 0.7142750130261303, 0.7151367126509813, 0.7158122609145376, 0.7168435035327092, 0.7177902230795398, 0.718639909474059, 0.7195091507790986, 0.7201868362572057, 0.7206573884542058, 0.721392311176707, 0.7220095277507583, 0.7226859664543186, 0.7234133799256273, 0.7238867264914809, 0.7241569173816924, 0.7248043766851898, 0.7252806739453806, 0.7257903972485169, 0.7260771593070724, 0.7266281778609536, 0.7271520684427984, 0.72759319883666, 0.7280042752304487, 0.7284996938741167, 0.7287714368344349, 0.7290995306117704, 0.7293158680983047, 0.7297521349706448, 0.7302029399248078, 0.7304831784454776, 0.7309632937462325, 0.7311885674193206, 0.7314331303548525, 0.7318647534408603, 0.7323318727407849, 0.7328802353928785, 0.7331228259524278, 0.7332808117334308, 0.7336925720029633, 0.7339562354491233, 0.7342632870149528, 0.7346326033277617, 0.7350465484617168, 0.7355328150810305, 0.7358333073074698, 0.7360364651910638, 0.736239837088578, 0.7365556936690336, 0.73674212809735, 0.7371307361221019, 0.7373343594575662, 0.7375871586308571, 0.7377659579082753, 0.7379617544900945, 0.7381450550066166, 0.7384609799000119, 0.7386614627516497, 0.7388883281966767, 0.7392854583995727, 0.7395984814618857, 0.7398968387478215, 0.740211755134898, 0.7403371418618567, 0.7405637419636925, 0.7408165822779821, 0.7410627037025002, 0.7411563298000428, 0.7413734151605239, 0.741600947531284, 0.7418084843996027, 0.7420275673226916, 0.7420573312391858, 0.7422817564128402, 0.742495328764358, 0.7426993138200466, 0.7430104230665027, 0.7432161968705021, 0.7433083873417207, 0.7434887987229049, 0.7436305670660537, 0.7438859696617739, 0.7440576672288652, 0.7442423498761338, 0.7443134134015787, 0.744430740850642, 0.7446037288214563, 0.7447221074677807, 0.7450125152495187, 0.7450459095232933, 0.7451900048078134, 0.7454916434293299, 0.7456701843339514, 0.7459029147123872, 0.7458798211232083, 0.7459382721965648, 0.7460328029387946, 0.7462036587710226, 0.7463226959831599, 0.7465530623609883, 0.7465672605545682, 0.7466450709978194, 0.746613010142039, 0.746707280112285, 0.746599135734316, 0.7466482901691439, 0.7468646622700312, 0.746903576141773, 0.7471108398823392, 0.7473390857321451, 0.7475606388433622, 0.7477206172601518, 0.7477855427757387, 0.7478882256647854, 0.7480851277660809, 0.7483205404751225, 0.7483232206180404, 0.7482954058121426, 0.7482796009844351, 0.7485119505597642, 0.7484698049108568, 0.7486761946959339, 0.7488082868357905, 0.7488828837878242, 0.7492129070554058, 0.749337794886687, 0.7495292850431825, 0.749503988535219, 0.7494465246900028, 0.7495133177209564, 0.7496802801475964, 0.749749166123239, 0.7499599009274895, 0.7500589895941998, 0.7501318212549348, 0.7502206933353291, 0.7502588615779313, 0.75036987080935, 0.7505324860378466, 0.7505602932030265, 0.7507154558873843, 0.7508667280473539, 0.7509286124246968, 0.7510540628285911, 0.7510065689730576, 0.7511496561637456, 0.7512157998127826, 0.751342794461211, 0.7514221763638349, 0.7515609051963975, 0.7515949721956762, 0.7516280657902927, 0.7518718358135613, 0.7520190771237704, 0.7519029836244332, 0.7519983541261925, 0.752191144423014, 0.7523298145068293, 0.7525197938465672, 0.7525373875285403, 0.752550824595869, 0.752581374951666, 0.7526764077338157, 0.7526967970222651, 0.7528384884152305, 0.7528148399474616, 0.752812121468127, 0.7528656226034295, 0.7529810226965842, 0.7531221572590132, 0.7532050365866372, 0.7532168129148229, 0.7534110983661424, 0.7534999247663775, 0.7537008844111406, 0.7538466906151908, 0.7539290159761984, 0.7540031808987429, 0.7541767780278147, 0.7543237869463788, 0.7543467769302201, 0.7543931166502195, 0.7544372196446659, 0.7544907550860687, 0.7545297805833681, 0.7545996726166241, 0.7547253905132304, 0.7547687461070717, 0.754858955464157, 0.7549494805295907, 0.7550170742932613, 0.7551125335709764, 0.7551195000078526, 0.755169947628422, 0.7552966225488116, 0.755433953562895, 0.7554901942577313, 0.7555662433247139, 0.7556161223433407, 0.755846989316048, 0.75587576918197, 0.756022578799395, 0.7560964705883833, 0.7562189930628136, 0.7561872489683262, 0.7562843454654582, 0.7564809422092871, 0.756478806771581, 0.7565420250931308, 0.7566502190516102, 0.7566474680201573, 0.756798307718003, 0.756899258311559, 0.7568762176029115], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 917826460, "moving_var_accuracy_train": [0.013560236178242226, 0.03191486672435169, 0.04739134548394182, 0.06117342445213181, 0.07224804764001423, 0.07963990839577587, 0.08419085230471067, 0.08497258017858586, 0.08566510445019221, 0.08417146341838774, 0.08191454939679313, 0.07874931960231768, 0.0753551042553081, 0.07155984371157073, 0.06760168013637327, 0.06343032711884758, 0.05901398328753461, 0.05506738177389656, 0.05106079005773724, 0.04728473164119181, 0.043705711800778535, 0.0403023190065099, 0.03705436084630778, 0.03401705475698877, 0.031206269051686764, 0.028564635029183993, 0.02613470700134794, 0.023875328098763145, 0.021741165652967565, 0.019855451479968537, 0.018073237705556976, 0.016430976177129842, 0.01494755866762871, 0.01360478014022203, 0.012377368418255819, 0.011236946733798714, 0.010208875687091586, 0.009269298141092735, 0.00840993511151535, 0.007640716759927723, 0.006924347221468061, 0.006267993456852241, 0.0056778571508906165, 0.005147853618513495, 0.004662382073894773, 0.004216480768530167, 0.0038237440907816786, 0.003469226279722084, 0.003136601150435643, 0.0028363468180941705, 0.0025669712559339667, 0.0023252157163884666, 0.0021042703186630466, 0.0019014754019547734, 0.001720299376087656, 0.0015599738439580398, 0.001411738725970654, 0.001278288171285126, 0.0011571420903478285, 0.001045535170420592, 0.0009505528054163327, 0.0008635640259778597, 0.0007837053261013541, 0.0007121350175087021, 0.0006450548342229673, 0.0005825421251315843, 0.0005291489152908625, 0.00047966263045532933, 0.0004358144912868641, 0.0003969952153823492, 0.00035931220658676335, 0.0003240380139824663, 0.000295407044531388, 0.00026790807179883724, 0.0002434556252307957, 0.00021985015501175883, 0.00020059773253107457, 0.00018300811135367863, 0.00016645866443780667, 0.00015133365220779956, 0.00013840924367946355, 0.00012523291743985924, 0.00011367843543640916, 0.00010273180906548803, 9.417158721405173e-05, 8.658345445292696e-05, 7.86319116638392e-05, 7.284331681562634e-05, 6.601571918414309e-05, 5.995244653065287e-05, 5.563388827296266e-05, 5.203430340892543e-05, 4.953718745193227e-05, 4.51131203229813e-05, 4.0826443853675485e-05, 3.826971814439734e-05, 3.506841204552595e-05, 3.2410096817679365e-05, 3.0396637986072268e-05, 2.8899129352790963e-05, 2.8137313443041154e-05, 2.6136242302090625e-05, 2.389407620287951e-05, 2.18769097408781e-05, 2.058710718154428e-05, 1.884121662794438e-05, 1.8316240737264022e-05, 1.6857778828247813e-05, 1.5747167743572555e-05, 1.4460173603662653e-05, 1.3359182956365155e-05, 1.2325656374944085e-05, 1.1991367581850457e-05, 1.1153971187872776e-05, 1.0501785440411143e-05, 1.0871018478840082e-05, 1.0665767568814034e-05, 1.0400344442571604e-05, 1.0252860975958111e-05, 9.369071360039034e-06, 8.894292679402839e-06, 8.580217432233462e-06, 8.267377489471689e-06, 7.519532355793907e-06, 7.191713603831551e-06, 6.938481061141737e-06, 6.63227692043108e-06, 6.401025173090273e-06, 5.768895672306926e-06, 5.645306032204205e-06, 5.491293772979195e-06, 5.3166535221798175e-06, 5.656088839035788e-06, 5.471565680843732e-06, 5.000900859610795e-06, 4.793745171796675e-06, 4.495255022689366e-06, 4.632803893526024e-06, 4.4348439950792026e-06, 4.298328717390249e-06, 3.913946067489192e-06, 3.6464430334734644e-06, 3.5511222725443297e-06, 3.322131580440008e-06, 3.748948539641803e-06, 3.384090283366013e-06, 3.232552314217669e-06, 3.728169804709561e-06, 3.6422445158460536e-06, 3.765490925683259e-06, 3.3937416578654166e-06, 3.085116243867654e-06, 2.857029170519571e-06, 2.834051692124378e-06, 2.678175243772761e-06, 2.8879757316992226e-06, 2.6009924568377223e-06, 2.395383396864458e-06, 2.1650961434383903e-06, 2.0285679747063323e-06, 1.930968035612413e-06, 1.759616658220427e-06, 2.0050069667801863e-06, 1.8181348748276002e-06, 2.022945710726072e-06, 2.289516651236235e-06, 2.502337015922028e-06, 2.482441158876546e-06, 2.2721349461569007e-06, 2.1398154328679194e-06, 2.274767827032554e-06, 2.546063336534017e-06, 2.2915216513751537e-06, 2.0693324570818286e-06, 1.8646473445834002e-06, 2.1640595365255678e-06, 1.963639884369435e-06, 2.1506465863900663e-06, 2.0926169284580967e-06, 1.9334375828867822e-06, 2.7203320389049768e-06, 2.5886715686334062e-06, 2.6598207320823762e-06, 2.399597878710467e-06, 2.1893569324027623e-06, 2.0105730200181822e-06, 2.0604037852021875e-06, 1.8970709054442275e-06, 2.1070462344021904e-06, 1.9847086857957166e-06, 1.8339778744649929e-06, 1.7216643070809863e-06, 1.5626092090629438e-06, 1.517255733298303e-06, 1.6035235728192434e-06, 1.4501303614554013e-06, 1.5217964528637365e-06, 1.5755662050141043e-06, 1.4524766699447238e-06, 1.4488692374854353e-06, 1.3242833105578533e-06, 1.3761204767528221e-06, 1.2778832698489475e-06, 1.2952437094288186e-06, 1.2224327166635296e-06, 1.2734006458548308e-06, 1.1565056252280243e-06, 1.050711736747044e-06, 1.4804549812717954e-06, 1.5275295140332406e-06, 1.4960758679250548e-06, 1.4283280745850034e-06, 1.620008154063196e-06, 1.6310718679647996e-06, 1.7927940269135243e-06, 1.6163004630304832e-06, 1.4562954097329998e-06, 1.3190657869136146e-06, 1.2684402753703534e-06, 1.1453377555845596e-06, 1.2114920375905151e-06, 1.0953760840818083e-06, 9.859049868426598e-07, 9.130758314662733e-07, 9.416228818205569e-07, 1.0267312760469072e-06, 9.858789949688193e-07, 8.885392326217675e-07, 1.139406838709339e-06, 1.0964773192470302e-06, 1.3502925967322573e-06, 1.4065983793148203e-06, 1.3269357269687378e-06, 1.2437460758960546e-06, 1.3905951373042232e-06, 1.4460402228101063e-06, 1.3061930547422868e-06, 1.1949000761146657e-06, 1.0929157355755273e-06, 1.0094185533936402e-06, 9.221836030094449e-07, 8.739293095224668e-07, 9.287812843142902e-07, 8.528205235387923e-07, 8.407780241367327e-07, 8.304533089690289e-07, 7.885282300566426e-07, 7.9168767036818e-07, 7.129556845161071e-07, 6.645647778546088e-07, 7.425271191705917e-07, 8.380126741161266e-07, 7.826785485056187e-07, 7.564618389552283e-07, 7.032069035522542e-07, 1.1125822449801934e-06, 1.008778546624546e-06, 1.1018782658783626e-06, 1.0408304076093393e-06, 1.071853177513365e-06, 9.737370475754186e-07, 9.612129106155158e-07, 1.212944136710948e-06, 1.0916907638876233e-06, 1.0184906931151502e-06, 1.0219950176667462e-06, 9.198636294665712e-07, 1.0326507965359693e-06, 1.021104917935991e-06, 9.237722944372419e-07], "duration": 162059.715504, "accuracy_train": [0.38816142372646734, 0.5067982664844038, 0.5410502318660022, 0.5848001597683646, 0.6135826181247692, 0.6232262178732927, 0.6334285743124769, 0.6175542967308048, 0.649336197051495, 0.6420806513012182, 0.6514034165628461, 0.6522615586932448, 0.6627011163598191, 0.6657452588593576, 0.6707701037052418, 0.6707236007290514, 0.6643959515734588, 0.6800907060377446, 0.6765572008236435, 0.6819268526208934, 0.6855304727874677, 0.6874846792520303, 0.6874167272286822, 0.6896699586447951, 0.6931547979535806, 0.6931812938353635, 0.6963660267280363, 0.6971322443706165, 0.6937389690614617, 0.7025941811438723, 0.6991783753229974, 0.6992255992755629, 0.7028041655131044, 0.7059878169412145, 0.7074555445967147, 0.7057320505721668, 0.7087332949773901, 0.7094544515965301, 0.7098025029415835, 0.7133828716200628, 0.7109890498108158, 0.7102915051679586, 0.7124546145371908, 0.7147786818821521, 0.7143859300018457, 0.7131754106681433, 0.7175695814299556, 0.7190319017626431, 0.7158021078465301, 0.716663133882429, 0.7182660446082503, 0.7198224523578811, 0.7195674069652086, 0.7185690349298633, 0.7202653120962532, 0.722683466858158, 0.721706904358158, 0.7226122704411222, 0.7228920092746401, 0.7218921952865449, 0.7261246870962532, 0.7263106990010152, 0.7262870870247324, 0.7273323225244555, 0.7262860055601698, 0.7248923582272057, 0.7280066156792174, 0.7275644769172204, 0.7287739147863602, 0.729960101167405, 0.7281468455841639, 0.7265886353935954, 0.7306315104166666, 0.7295673492870985, 0.7303779069767442, 0.7286580178340716, 0.7315873448458841, 0.731867083679402, 0.7315633723814138, 0.7317039627745479, 0.7329584616671281, 0.7312171234772978, 0.7320523746077888, 0.7312629054771134, 0.7336785368217055, 0.7342601845122739, 0.7330053251315061, 0.735284331453027, 0.7332160304771134, 0.7336341967746401, 0.7357493612149317, 0.736535946440107, 0.7378154992617202, 0.7353061409883721, 0.7347026837624584, 0.737398414428756, 0.7363292064645626, 0.7370267511074198, 0.7379564501430418, 0.7387720546673127, 0.7399092146548542, 0.7385377373454227, 0.7378648861434108, 0.7380701841662053, 0.7393984028931341, 0.7384200379521964, 0.7406282083448689, 0.7391669694767442, 0.7398623511904762, 0.7393751514050388, 0.7397239237264673, 0.7397947596553156, 0.7413043039405685, 0.7404658084163898, 0.7409301172019196, 0.7428596302256368, 0.7424156890227022, 0.742582054321244, 0.7430460026185862, 0.741465622404485, 0.7426031428802141, 0.7430921451065892, 0.7432777965231635, 0.7419989646779255, 0.7433271834048542, 0.7436487388681248, 0.7436763162144703, 0.743999313630491, 0.7423252064876339, 0.7443015829757291, 0.7444174799280178, 0.744535179321244, 0.7458104062846069, 0.7450681611064969, 0.7441381015826873, 0.7451125011535622, 0.7449064821543927, 0.7461845930232558, 0.7456029453326873, 0.7459044937015504, 0.7449529851305832, 0.7454866878922112, 0.7461606205587855, 0.7457875152846991, 0.7476261852851606, 0.7453464579872646, 0.7464868623684939, 0.7482063910229789, 0.7472770524755445, 0.7479974881183094, 0.745671978820598, 0.7464643318567736, 0.746883579618863, 0.7477413612610742, 0.7473940308923958, 0.7486263597614433, 0.7466950442967885, 0.74734536498708, 0.7463244624400148, 0.7475557098444998, 0.745625836332595, 0.747090680082595, 0.7488120111780178, 0.7472538009874492, 0.7489762135474345, 0.7493932983803987, 0.7495546168443152, 0.7491604230112587, 0.7483698724160207, 0.7488123716662053, 0.7498572466777409, 0.7504392548564969, 0.7483473419043005, 0.7480450725590624, 0.7481373575350683, 0.7506030967377261, 0.7480904940706903, 0.7505337027616279, 0.7499971160944998, 0.7495542563561277, 0.7521831164636398, 0.7504617853682171, 0.7512526964516427, 0.7492763199635475, 0.7489293500830565, 0.7501144549995387, 0.7511829419873569, 0.7503691399040237, 0.7518565141657438, 0.7509507875945921, 0.7507873062015504, 0.7510205420588778, 0.750602375761351, 0.7513689538921189, 0.7519960230943152, 0.7508105576896457, 0.7521119200466039, 0.75222817748708, 0.7514855718207826, 0.7521831164636398, 0.7505791242732558, 0.7524374408799372, 0.7518110926541159, 0.7524857462970653, 0.7521366134874492, 0.752809464689461, 0.7519015751891842, 0.751925908141842, 0.7540657660229789, 0.7533442489156515, 0.7508581421303987, 0.7528566886420266, 0.7539262570944075, 0.7535778452611664, 0.7542296079042082, 0.7526957306662975, 0.7526717582018273, 0.7528563281538391, 0.7535317027731635, 0.7528803006183094, 0.7541137109519196, 0.7526020037375416, 0.7527876551541159, 0.7533471328211517, 0.754019623534976, 0.7543923683208749, 0.7539509505352529, 0.7533227998684939, 0.7551596674280178, 0.7542993623684939, 0.7555095212140088, 0.7551589464516427, 0.7546699442252676, 0.7546706652016427, 0.755739152189461, 0.7556468672134551, 0.7545536867847914, 0.7548101741302141, 0.7548341465946844, 0.7549725740586932, 0.7548810100590624, 0.7552287009159284, 0.7558568515826873, 0.7551589464516427, 0.7556708396779255, 0.7557642061184939, 0.7556254181662975, 0.7559716670704134, 0.755182197939738, 0.7556239762135475, 0.7564366968323182, 0.7566699326896457, 0.7559963605112587, 0.7562506849275563, 0.7560650335109819, 0.7579247920704134, 0.7561347879752676, 0.75734386535622, 0.7567614966892765, 0.7573216953326873, 0.7559015521179402, 0.7571582139396457, 0.7582503129037468, 0.756459587832226, 0.75711098998708, 0.7576239646779255, 0.75662270873708, 0.7581558649986158, 0.7578078136535622, 0.7566688512250831], "end": "2016-01-26 18:03:35.787000", "learning_rate_per_epoch": [0.003847552230581641, 0.0019237761152908206, 0.0012825173325836658, 0.0009618880576454103, 0.0007695103995501995, 0.0006412586662918329, 0.0005496502853929996, 0.00048094402882270515, 0.00042750578722916543, 0.00038475519977509975, 0.0003497774596326053, 0.00032062933314591646, 0.0002959655539598316, 0.0002748251426964998, 0.00025650346651673317, 0.00024047201441135257, 0.00022632659238297492, 0.00021375289361458272, 0.0002025027497438714, 0.00019237759988754988, 0.00018321676179766655, 0.00017488872981630266, 0.00016728487389627844, 0.00016031466657295823, 0.00015390208864118904, 0.0001479827769799158, 0.00014250192907638848, 0.0001374125713482499, 0.00013267420581541955, 0.00012825173325836658, 0.0001241145801031962, 0.00012023600720567629, 0.00011659249139484018, 0.00011316329619148746, 0.00010993006435455754, 0.00010687644680729136, 0.00010398789891041815, 0.0001012513748719357, 9.8655182227958e-05, 9.618879994377494e-05, 9.384273289470002e-05, 9.160838089883327e-05, 8.947795868152753e-05, 8.744436490815133e-05, 8.550116035621613e-05, 8.364243694813922e-05, 8.18628104752861e-05, 8.015733328647912e-05, 7.852147246012464e-05, 7.695104432059452e-05, 7.544219988631085e-05, 7.39913884899579e-05, 7.259532139869407e-05, 7.125096453819424e-05, 6.995549483690411e-05, 6.870628567412496e-05, 6.750091415597126e-05, 6.633710290770978e-05, 6.521274917759001e-05, 6.412586662918329e-05, 6.307462172117084e-05, 6.20572900515981e-05, 6.107225635787472e-05, 6.0118003602838144e-05, 5.9193109336774796e-05, 5.829624569742009e-05, 5.7426150306127965e-05, 5.658164809574373e-05, 5.5761625844752416e-05, 5.496503217727877e-05, 5.419087392510846e-05, 5.343822340364568e-05, 5.270619294606149e-05, 5.1993949455209076e-05, 5.130069621372968e-05, 5.062568743596785e-05, 4.996821007807739e-05, 4.9327591113979e-05, 4.870319025940262e-05, 4.809439997188747e-05, 4.750064545078203e-05, 4.692136644735001e-05, 4.635605000657961e-05, 4.580419044941664e-05, 4.5265318476594985e-05, 4.473897934076376e-05, 4.422473648446612e-05, 4.3722182454075664e-05, 4.323092434788123e-05, 4.2750580178108066e-05, 4.2280793422833085e-05, 4.182121847406961e-05, 4.1371527913725004e-05, 4.093140523764305e-05, 4.0500548493582755e-05, 4.007866664323956e-05, 3.9665486838202924e-05, 3.926073623006232e-05, 3.886416379828006e-05, 3.847552216029726e-05, 3.809457484749146e-05, 3.772109994315542e-05, 3.735487553058192e-05, 3.699569424497895e-05, 3.664335235953331e-05, 3.6297660699347034e-05, 3.595843008952215e-05, 3.562548226909712e-05, 3.529864261508919e-05, 3.4977747418452054e-05, 3.4662632970139384e-05, 3.435314283706248e-05, 3.404913513804786e-05, 3.375045707798563e-05, 3.345697405165993e-05, 3.316855145385489e-05, 3.288506195531227e-05, 3.2606374588795006e-05, 3.233236930100247e-05, 3.2062933314591646e-05, 3.17979502142407e-05, 3.153731086058542e-05, 3.128091339021921e-05, 3.102864502579905e-05, 3.078041845583357e-05, 3.053612817893736e-05, 3.0295686883619055e-05, 3.0059001801419072e-05, 2.982598562084604e-05, 2.9596554668387398e-05, 2.9370627089519985e-05, 2.9148122848710045e-05, 2.8928963729413226e-05, 2.8713075153063983e-05, 2.8500386179075576e-05, 2.8290824047871865e-05, 2.808432145684492e-05, 2.7880812922376208e-05, 2.7680231141857803e-05, 2.7482516088639386e-05, 2.7287604098091833e-05, 2.709543696255423e-05, 2.690595829335507e-05, 2.671911170182284e-05, 2.6534842618275434e-05, 2.6353096473030746e-05, 2.617382415337488e-05, 2.5996974727604538e-05, 2.582249726401642e-05, 2.565034810686484e-05, 2.5480478143435903e-05, 2.5312843717983924e-05, 2.5147399355773814e-05, 2.4984105039038695e-05, 2.4822917112032883e-05, 2.46637955569895e-05, 2.4506702175131068e-05, 2.435159512970131e-05, 2.419844167889096e-05, 2.4047199985943735e-05, 2.3897839128039777e-05, 2.3750322725391015e-05, 2.3604614398209378e-05, 2.3460683223675005e-05, 2.3318498278968036e-05, 2.3178025003289804e-05, 2.303923429280985e-05, 2.290209522470832e-05, 2.2766580514144152e-05, 2.2632659238297492e-05, 2.2500304112327285e-05, 2.236948967038188e-05, 2.224018498964142e-05, 2.211236824223306e-05, 2.1986012143315747e-05, 2.1861091227037832e-05, 2.173758184653707e-05, 2.1615462173940614e-05, 2.1494704924407415e-05, 2.1375290089054033e-05, 2.1257194021018222e-05, 2.1140396711416543e-05, 2.102487451338675e-05, 2.0910609237034805e-05, 2.079757905448787e-05, 2.0685763956862502e-05, 2.0575145754264668e-05, 2.0465702618821524e-05, 2.035741817962844e-05, 2.0250274246791378e-05, 2.0144252630416304e-05, 2.003933332161978e-05, 1.9935503587475978e-05, 1.9832743419101462e-05, 1.97310364455916e-05, 1.963036811503116e-05, 1.9530722056515515e-05, 1.943208189914003e-05, 1.9334433090989478e-05, 1.923776108014863e-05, 1.9142051314702258e-05, 1.904728742374573e-05, 1.8953458493342623e-05, 1.886054997157771e-05, 1.8768547306535766e-05, 1.867743776529096e-05, 1.8587208614917472e-05, 1.8497847122489475e-05, 1.8409340555081144e-05, 1.8321676179766655e-05, 1.823484490159899e-05, 1.8148830349673517e-05, 1.8063625248032622e-05, 1.7979215044761077e-05, 1.7895590644911863e-05, 1.781274113454856e-05, 1.7730655599734746e-05, 1.7649321307544596e-05, 1.7568730982020497e-05, 1.7488873709226027e-05, 1.7409738575224765e-05, 1.7331316485069692e-05, 1.725359652482439e-05, 1.717657141853124e-05, 1.7100232071243227e-05, 1.702456756902393e-05, 1.694956881692633e-05, 1.6875228538992815e-05, 1.6801537640276365e-05, 1.6728487025829963e-05, 1.6656069419695996e-05, 1.6584275726927444e-05, 1.6513098671566695e-05, 1.6442530977656133e-05, 1.637256173125934e-05, 1.6303187294397503e-05, 1.6234396753134206e-05, 1.6166184650501236e-05, 1.609854371054098e-05, 1.6031466657295823e-05, 1.596494621480815e-05, 1.589897510712035e-05, 1.583354787726421e-05, 1.576865543029271e-05, 1.5704294128227048e-05, 1.5640456695109606e-05, 1.5577134035993367e-05, 1.5514322512899525e-05, 1.545201666885987e-05, 1.5390209227916785e-05, 1.5328892914112657e-05, 1.526806408946868e-05, 1.5207716387521941e-05, 1.5147843441809528e-05, 1.5088439795363229e-05, 1.5029500900709536e-05, 1.4971020391385537e-05, 1.491299281042302e-05, 1.4855413610348478e-05, 1.4798277334193699e-05, 1.4741579434485175e-05, 1.4685313544759993e-05, 1.4629476027039345e-05, 1.4574061424355023e-05, 1.4519064279738814e-05, 1.4464481864706613e-05, 1.4410307812795509e-05, 1.4356537576531991e-05, 1.4303167517937254e-05, 1.4250193089537788e-05], "accuracy_valid": [0.3829301581325301, 0.5090846785579819, 0.535778367375753, 0.5825842432228916, 0.6048216302710843, 0.6175684182040663, 0.6248632224209337, 0.613682758377259, 0.6375894201807228, 0.630579936935241, 0.6456254706325302, 0.6465211431664157, 0.6518819418298193, 0.6576501317771084, 0.6674466420368976, 0.6624623493975903, 0.6524319935993976, 0.672828030873494, 0.6669274755271084, 0.6746693806475903, 0.6750458866716867, 0.6776299534073795, 0.6816273884600903, 0.6833569630082832, 0.6848012165850903, 0.6832143025225903, 0.6884942112198795, 0.687232327748494, 0.6855939382530121, 0.6916165639118976, 0.690162015248494, 0.6880662297628012, 0.6922166203878012, 0.6958081348832832, 0.6972523884600903, 0.6960419804216867, 0.6976391895707832, 0.6976288944841867, 0.6999688205948795, 0.7035397449171686, 0.6995114246046686, 0.6982804263930723, 0.6992363987198795, 0.7029293933546686, 0.7024617022778614, 0.7028073230421686, 0.7050457690135542, 0.7056252353162651, 0.7036515201430723, 0.7037632953689759, 0.7044957172439759, 0.7073754000376506, 0.7069680087537651, 0.7080872317394578, 0.7073548098644578, 0.7085961031626506, 0.7075886554028614, 0.7125229433358433, 0.7091049745858433, 0.7096947359751506, 0.7142936982304217, 0.712268507624247, 0.7095417804028614, 0.7137539415474398, 0.7087490587349398, 0.7120552522590362, 0.7127773790474398, 0.7126861939947289, 0.7150055299322289, 0.7180469926581325, 0.7137436464608433, 0.7126758989081325, 0.7155952913215362, 0.7178234422063253, 0.7146393189947289, 0.712634718561747, 0.7160732774849398, 0.7172939806099398, 0.7162159379706325, 0.7198574571724398, 0.7137127612010542, 0.715808546686747, 0.7145981386483433, 0.7156055864081325, 0.7202339631965362, 0.7207325395331325, 0.7184837984751506, 0.7191147402108433, 0.7177719667733433, 0.7186367540474398, 0.7202442582831325, 0.7199795274849398, 0.718127882624247, 0.7194500658885542, 0.7221973832831325, 0.7255138718938253, 0.7201015977974398, 0.7208340196724398, 0.7264595491340362, 0.7226753694465362, 0.7226547792733433, 0.7242622835090362, 0.7268463502447289, 0.7242622835090362, 0.7273037462349398, 0.7252491410956325, 0.7244152390813253, 0.7253609163215362, 0.7244961290474398, 0.7231533556099398, 0.7284435593938253, 0.7267242799322289, 0.7279140977974398, 0.722034132624247, 0.7266022096197289, 0.7295318971197289, 0.7265713243599398, 0.7288906602974398, 0.7277008424322289, 0.7268257600715362, 0.7302540239081325, 0.7304981645331325, 0.7291450960090362, 0.7287994752447289, 0.7293892366340362, 0.7301319535956325, 0.7297657426581325, 0.7317188676581325, 0.7286568147590362, 0.7317497529179217, 0.7297657426581325, 0.7305084596197289, 0.7326954301581325, 0.7328380906438253, 0.7290127306099398, 0.7292671663215362, 0.7304775743599398, 0.7316070924322289, 0.7339058381965362, 0.7320644884224398, 0.7329395707831325, 0.7334072618599398, 0.7319733033697289, 0.7317085725715362, 0.7347603303840362, 0.7320644884224398, 0.7347706254706325, 0.7314232516001506, 0.7329189806099398, 0.7337940629706325, 0.7334278520331325, 0.7357368928840362, 0.7338043580572289, 0.7359810335090362, 0.7331528261483433, 0.7350147660956325, 0.7311997011483433, 0.7335293321724398, 0.7327969102974398, 0.7330307558358433, 0.731555616999247, 0.7326851350715362, 0.7349941759224398, 0.7335190370858433, 0.7343941194465362, 0.7369678910956325, 0.7370796663215362, 0.7377106080572289, 0.7345264848456325, 0.7340279085090362, 0.7348824006965362, 0.7380562288215362, 0.7373341020331325, 0.7350044710090362, 0.736560499811747, 0.7367031602974398, 0.7337837678840362, 0.7335999270519578, 0.7368561158697289, 0.7378120881965362, 0.7379444535956325, 0.7378223832831325, 0.7369370058358433, 0.7362148790474398, 0.7379341585090362, 0.7380665239081325, 0.7381782991340362, 0.7378223832831325, 0.7362148790474398, 0.7391754518072289, 0.7373135118599398, 0.7382900743599398, 0.7349941759224398, 0.7378120881965362, 0.7376797227974398, 0.7356045274849398, 0.7389313111822289, 0.7380459337349398, 0.738635695124247, 0.7387886506965362, 0.7372017366340362, 0.7353603868599398, 0.7378017931099398, 0.7378223832831325, 0.7369575960090362, 0.7396431428840362, 0.7374458772590362, 0.7385548051581325, 0.7385445100715362, 0.7373032167733433, 0.7344955995858433, 0.7379135683358433, 0.7376694277108433, 0.7351868411144578, 0.7368149355233433, 0.735339796686747, 0.7360516283885542, 0.7390224962349398, 0.736926710749247, 0.7408947312688253, 0.7397755082831325, 0.735950148249247, 0.7369473009224398, 0.7372826266001506, 0.734973585749247, 0.7355736422251506, 0.7370693712349398, 0.7371811464608433, 0.7378017931099398, 0.735706007624247, 0.736804640436747, 0.7384121446724398, 0.7374046969126506, 0.7379444535956325, 0.7403755647590362, 0.7385342149849398, 0.7371914415474398, 0.7367134553840362, 0.7371914415474398, 0.7370590761483433, 0.7357163027108433, 0.7392769319465362, 0.7371811464608433, 0.7362045839608433, 0.7370590761483433, 0.7369370058358433, 0.7369370058358433, 0.735706007624247, 0.7342514589608433, 0.7374252870858433, 0.739368116999247, 0.737292921686747, 0.7373032167733433, 0.7358383730233433, 0.737048781061747, 0.7393784120858433, 0.7381680040474398, 0.737048781061747, 0.7371811464608433, 0.7366619799510542, 0.7376797227974398, 0.7389107210090362, 0.7373135118599398, 0.7367134553840362, 0.736438429499247, 0.7391651567206325, 0.7363472444465362, 0.7396534379706325, 0.7398769884224398, 0.7386871705572289], "accuracy_test": 0.30582150829081634, "start": "2016-01-24 21:02:36.072000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0], "accuracy_train_last": 0.7566688512250831, "batch_size_eval": 1024, "accuracy_train_std": [0.021913711414428338, 0.01649644720609241, 0.016199819812171536, 0.014817189814735357, 0.013694844635108823, 0.01319374615191851, 0.01668417103345315, 0.013709598087961692, 0.013297124341615505, 0.013464496827497587, 0.013553130338162652, 0.015965078252851504, 0.016439761807735778, 0.014821949702598513, 0.012883303316057313, 0.015153696574952375, 0.017146043208298878, 0.015054407655534036, 0.013741005500431792, 0.014270843902102877, 0.014264858706490628, 0.013713953082353243, 0.012271723974912373, 0.01478118993317005, 0.015236593185091078, 0.013222950654953903, 0.013148789073814367, 0.01395935386474312, 0.011654807165116871, 0.013497614059362345, 0.013611525473047434, 0.012288449433289982, 0.01324191689232495, 0.011062932796867174, 0.01166445469263499, 0.012906947811261756, 0.01286120461909603, 0.012679556978625234, 0.012011789373267566, 0.012978168347395553, 0.013033446431643366, 0.012991338576382268, 0.01216152792528859, 0.011940339313380864, 0.012807838168758252, 0.010977893890364092, 0.012095021112907577, 0.012038441999877837, 0.012405905363747916, 0.011765417805296684, 0.011434042061076628, 0.012485506074648007, 0.011611026116058984, 0.012152819823254207, 0.011716149552638068, 0.01310286454404325, 0.012498277871251682, 0.012863191953541957, 0.012210622896585092, 0.0124351822753676, 0.012168624126881196, 0.011938469613026666, 0.012997494484885724, 0.01216658377660648, 0.013176974442986053, 0.01270055794384029, 0.013088381989864178, 0.011599000168957034, 0.012941370249699, 0.012159611572997055, 0.013078670571870694, 0.01285260011564133, 0.01347601770774553, 0.011928670764394122, 0.012244764584354086, 0.011472616311143116, 0.011874859857726777, 0.011561193001162168, 0.012185888982661175, 0.012095203253157803, 0.01187806936955003, 0.012673724782175218, 0.011180180624593729, 0.01101792912995745, 0.011679515463126566, 0.011889389927716024, 0.012331612266839419, 0.012084137496871683, 0.01200174149960162, 0.011287736261688263, 0.012023130890973515, 0.012119171425994587, 0.012614079615064215, 0.011043145812640641, 0.011599976232159156, 0.012892467565922489, 0.011488572844419377, 0.012657025098761834, 0.012321220995720392, 0.012672011782777229, 0.012782289877228193, 0.0117115784689842, 0.013104017700404027, 0.01237985291718329, 0.012379819514264844, 0.011222034802810638, 0.012966025058527647, 0.013117081004495554, 0.012144935779055075, 0.012510514075281974, 0.01228712481850082, 0.012451628033553503, 0.012287988043051505, 0.012354627543597221, 0.013014659118076012, 0.013167128448676202, 0.013549954001977553, 0.013706211616895496, 0.013189841332863123, 0.01272635122036594, 0.012582536914243684, 0.012872262612409254, 0.012547687175872131, 0.01367990366568629, 0.012460613358725418, 0.012439021749702909, 0.012537500977756825, 0.013732068440863544, 0.012531839577730469, 0.013049329766951343, 0.013399514782533978, 0.01312059958659382, 0.013378142748466377, 0.012869206935756675, 0.01368156279821021, 0.014007836344202404, 0.013215363679739685, 0.013368454671046122, 0.012756420575672426, 0.012922488164252083, 0.013429069377588298, 0.01366512618089555, 0.013708246099755371, 0.014127671771308805, 0.01374443451528011, 0.014014110077329984, 0.013463705754443831, 0.013874911929493076, 0.013547947177203446, 0.013063293560310127, 0.013616995630921775, 0.013295046177885846, 0.012527898996625854, 0.014054591804422397, 0.013130849780446745, 0.012952372514178963, 0.01321924690095838, 0.012544326428394306, 0.01410954696883648, 0.012948488104965843, 0.012626634867647984, 0.012948802054037221, 0.013274667346247028, 0.012917687315136837, 0.012418273302958796, 0.012561867949412976, 0.014185458846139769, 0.013452488806831248, 0.013563445451310253, 0.012891733489757615, 0.013503173284143, 0.012748389942168295, 0.012861606874769619, 0.013425637688933758, 0.013352742556911256, 0.01266576038427843, 0.011665797631518395, 0.013352505610704125, 0.013521613640602349, 0.013911242114265003, 0.011315648088995177, 0.012320994101615903, 0.012115951501388294, 0.01373317298185263, 0.01165751721639927, 0.011978306107166343, 0.013297566174099386, 0.012709653507559138, 0.011985083832809513, 0.012488078667673744, 0.013401559694728334, 0.011704310542819162, 0.012026469494282566, 0.013197376865586898, 0.01280781765299191, 0.01268194626940767, 0.012842107952933697, 0.012702353573760022, 0.013243120679866187, 0.012050312417912355, 0.012569493785719567, 0.013220895982737482, 0.012524715418043697, 0.012695897911304236, 0.012967762107397307, 0.012997484117983288, 0.013349736482975362, 0.013043055659256623, 0.012601956027300295, 0.01322098394825254, 0.012431752725870514, 0.011966661270877622, 0.01213856811704781, 0.013405448496857666, 0.012743437202672724, 0.013146056427817085, 0.012340145078910136, 0.013531240603389344, 0.012204392413471944, 0.012430235374532132, 0.01300121198040307, 0.012601607794299731, 0.012253664414161609, 0.012560496958366411, 0.012849510486280557, 0.013017734499002497, 0.01273726379305426, 0.0126474030724276, 0.012808676674393551, 0.01255929093841623, 0.012297019266932843, 0.013284334429307296, 0.012404355010270122, 0.012708098500365889, 0.012333271331278206, 0.01389074793051039, 0.012404560934624751, 0.013006340460317302, 0.012898128488334869, 0.012564101233150354, 0.01210497767556825, 0.012536040335067668, 0.012920706798545803, 0.012280682424526842, 0.012929872518709105, 0.013303605184137226, 0.012099456436633304, 0.012463376476570538, 0.012047732268995553, 0.012780071324106617, 0.013508884673901675, 0.012760193694226174, 0.012276540316083419, 0.01142920698619432, 0.012510477173983535, 0.013442162471207306, 0.012786508531336666, 0.013079959347260504, 0.013450132379877694, 0.012164733867251863, 0.012951409916873153, 0.012768767501804494, 0.01280555763936176, 0.01313957600426158, 0.013127568652921298, 0.013139293282793714, 0.013345710866501456, 0.013479215273760189, 0.013173500326132079, 0.012780413464109342], "accuracy_test_std": 0.015891691664934683, "error_valid": [0.6170698418674698, 0.4909153214420181, 0.464221632624247, 0.4174157567771084, 0.39517836972891573, 0.38243158179593373, 0.37513677757906627, 0.38631724162274095, 0.36241057981927716, 0.36942006306475905, 0.3543745293674698, 0.35347885683358427, 0.3481180581701807, 0.3423498682228916, 0.33255335796310237, 0.3375376506024097, 0.34756800640060237, 0.32717196912650603, 0.3330725244728916, 0.3253306193524097, 0.32495411332831325, 0.3223700465926205, 0.3183726115399097, 0.3166430369917168, 0.3151987834149097, 0.3167856974774097, 0.3115057887801205, 0.31276767225150603, 0.31440606174698793, 0.30838343608810237, 0.30983798475150603, 0.3119337702371988, 0.3077833796121988, 0.3041918651167168, 0.3027476115399097, 0.30395801957831325, 0.3023608104292168, 0.30237110551581325, 0.3000311794051205, 0.29646025508283136, 0.30048857539533136, 0.3017195736069277, 0.3007636012801205, 0.29707060664533136, 0.2975382977221386, 0.29719267695783136, 0.2949542309864458, 0.2943747646837349, 0.2963484798569277, 0.29623670463102414, 0.29550428275602414, 0.29262459996234935, 0.2930319912462349, 0.29191276826054224, 0.29264519013554224, 0.29140389683734935, 0.2924113445971386, 0.2874770566641567, 0.2908950254141567, 0.29030526402484935, 0.28570630176957834, 0.287731492375753, 0.2904582195971386, 0.28624605845256024, 0.29125094126506024, 0.2879447477409638, 0.28722262095256024, 0.2873138060052711, 0.2849944700677711, 0.28195300734186746, 0.2862563535391567, 0.28732410109186746, 0.2844047086784638, 0.2821765577936747, 0.2853606810052711, 0.287365281438253, 0.28392672251506024, 0.28270601939006024, 0.28378406202936746, 0.28014254282756024, 0.2862872387989458, 0.284191453313253, 0.2854018613516567, 0.28439441359186746, 0.2797660368034638, 0.27926746046686746, 0.28151620152484935, 0.2808852597891567, 0.2822280332266567, 0.28136324595256024, 0.27975574171686746, 0.28002047251506024, 0.281872117375753, 0.2805499341114458, 0.27780261671686746, 0.2744861281061747, 0.27989840220256024, 0.27916598032756024, 0.2735404508659638, 0.2773246305534638, 0.2773452207266567, 0.2757377164909638, 0.2731536497552711, 0.2757377164909638, 0.27269625376506024, 0.27475085890436746, 0.2755847609186747, 0.2746390836784638, 0.27550387095256024, 0.27684664439006024, 0.2715564406061747, 0.2732757200677711, 0.27208590220256024, 0.277965867375753, 0.2733977903802711, 0.2704681028802711, 0.27342867564006024, 0.27110933970256024, 0.2722991575677711, 0.2731742399284638, 0.26974597609186746, 0.26950183546686746, 0.2708549039909638, 0.2712005247552711, 0.2706107633659638, 0.26986804640436746, 0.27023425734186746, 0.26828113234186746, 0.2713431852409638, 0.26825024708207834, 0.27023425734186746, 0.2694915403802711, 0.26730456984186746, 0.2671619093561747, 0.27098726939006024, 0.2707328336784638, 0.26952242564006024, 0.2683929075677711, 0.2660941618034638, 0.26793551157756024, 0.26706042921686746, 0.26659273814006024, 0.2680266966302711, 0.2682914274284638, 0.2652396696159638, 0.26793551157756024, 0.26522937452936746, 0.26857674839984935, 0.26708101939006024, 0.26620593702936746, 0.26657214796686746, 0.2642631071159638, 0.2661956419427711, 0.2640189664909638, 0.2668471738516567, 0.26498523390436746, 0.2688002988516567, 0.26647066782756024, 0.26720308970256024, 0.2669692441641567, 0.268444383000753, 0.2673148649284638, 0.26500582407756024, 0.2664809629141567, 0.2656058805534638, 0.26303210890436746, 0.2629203336784638, 0.2622893919427711, 0.26547351515436746, 0.2659720914909638, 0.2651175993034638, 0.2619437711784638, 0.26266589796686746, 0.2649955289909638, 0.263439500188253, 0.26329683970256024, 0.2662162321159638, 0.26640007294804224, 0.2631438841302711, 0.2621879118034638, 0.26205554640436746, 0.26217761671686746, 0.2630629941641567, 0.26378512095256024, 0.2620658414909638, 0.26193347609186746, 0.2618217008659638, 0.26217761671686746, 0.26378512095256024, 0.2608245481927711, 0.26268648814006024, 0.26170992564006024, 0.26500582407756024, 0.2621879118034638, 0.26232027720256024, 0.26439547251506024, 0.2610686888177711, 0.26195406626506024, 0.261364304875753, 0.2612113493034638, 0.2627982633659638, 0.26463961314006024, 0.26219820689006024, 0.26217761671686746, 0.2630424039909638, 0.2603568571159638, 0.2625541227409638, 0.26144519484186746, 0.2614554899284638, 0.2626967832266567, 0.2655044004141567, 0.2620864316641567, 0.2623305722891567, 0.26481315888554224, 0.2631850644766567, 0.264660203313253, 0.2639483716114458, 0.26097750376506024, 0.263073289250753, 0.2591052687311747, 0.26022449171686746, 0.264049851750753, 0.26305269907756024, 0.26271737339984935, 0.265026414250753, 0.26442635777484935, 0.26293062876506024, 0.2628188535391567, 0.26219820689006024, 0.264293992375753, 0.263195359563253, 0.26158785532756024, 0.26259530308734935, 0.26205554640436746, 0.2596244352409638, 0.26146578501506024, 0.26280855845256024, 0.2632865446159638, 0.26280855845256024, 0.2629409238516567, 0.2642836972891567, 0.2607230680534638, 0.2628188535391567, 0.2637954160391567, 0.2629409238516567, 0.2630629941641567, 0.2630629941641567, 0.264293992375753, 0.2657485410391567, 0.2625747129141567, 0.260631883000753, 0.262707078313253, 0.2626967832266567, 0.2641616269766567, 0.262951218938253, 0.2606215879141567, 0.26183199595256024, 0.262951218938253, 0.2628188535391567, 0.2633380200489458, 0.26232027720256024, 0.2610892789909638, 0.26268648814006024, 0.2632865446159638, 0.263561570500753, 0.26083484327936746, 0.2636527555534638, 0.26034656202936746, 0.26012301157756024, 0.2613128294427711], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "momentum": 0.6900632565973805, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.0038475521357894684, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "optimization": "adam", "nb_data_augmentation": 2, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0005199211056131009, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.04510673790977501}, "accuracy_valid_max": 0.7408947312688253, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7386871705572289, "loss_train": [2.789125442504883, 1.8151217699050903, 1.5974527597427368, 1.505820393562317, 1.4496179819107056, 1.4104604721069336, 1.3792295455932617, 1.3529917001724243, 1.3367061614990234, 1.3194791078567505, 1.3050987720489502, 1.2942821979522705, 1.2830127477645874, 1.273830771446228, 1.2651463747024536, 1.2555265426635742, 1.2477481365203857, 1.2452008724212646, 1.2347922325134277, 1.2298232316970825, 1.2236945629119873, 1.2189666032791138, 1.2133146524429321, 1.2066160440444946, 1.202113389968872, 1.1979305744171143, 1.1947075128555298, 1.1905285120010376, 1.1883615255355835, 1.1843675374984741, 1.181176781654358, 1.1776626110076904, 1.1737900972366333, 1.1722407341003418, 1.166197657585144, 1.1658191680908203, 1.1622263193130493, 1.1585803031921387, 1.1578757762908936, 1.1522454023361206, 1.1540498733520508, 1.1518317461013794, 1.1468620300292969, 1.1419122219085693, 1.1422905921936035, 1.1387834548950195, 1.1374307870864868, 1.1357991695404053, 1.1345460414886475, 1.1320239305496216, 1.1285014152526855, 1.1273083686828613, 1.125685214996338, 1.123777985572815, 1.1218019723892212, 1.1207795143127441, 1.119604468345642, 1.1173585653305054, 1.1155043840408325, 1.1134459972381592, 1.1113407611846924, 1.1109108924865723, 1.109510064125061, 1.1081352233886719, 1.1043962240219116, 1.105102300643921, 1.104296326637268, 1.1029547452926636, 1.1009724140167236, 1.0985125303268433, 1.097549319267273, 1.0967165231704712, 1.0962841510772705, 1.0944817066192627, 1.0941282510757446, 1.0916519165039062, 1.0912582874298096, 1.090364933013916, 1.0879743099212646, 1.0869083404541016, 1.0866535902023315, 1.08525812625885, 1.0856270790100098, 1.082476258277893, 1.0834459066390991, 1.0819435119628906, 1.0810346603393555, 1.0802098512649536, 1.080700159072876, 1.078579306602478, 1.0793492794036865, 1.0760868787765503, 1.072953224182129, 1.072898268699646, 1.0731185674667358, 1.0702143907546997, 1.0705657005310059, 1.0720514059066772, 1.0728049278259277, 1.0694278478622437, 1.0683702230453491, 1.0685621500015259, 1.065600037574768, 1.065057635307312, 1.0629491806030273, 1.066720962524414, 1.0625033378601074, 1.0615252256393433, 1.0625625848770142, 1.062577724456787, 1.0601468086242676, 1.059381127357483, 1.060514211654663, 1.0583778619766235, 1.0578895807266235, 1.0565954446792603, 1.0560290813446045, 1.0549402236938477, 1.0549026727676392, 1.0552021265029907, 1.0547128915786743, 1.0544809103012085, 1.052290916442871, 1.0519241094589233, 1.0522321462631226, 1.0526847839355469, 1.0505536794662476, 1.0521272420883179, 1.0504804849624634, 1.0493836402893066, 1.050028681755066, 1.0477131605148315, 1.0461279153823853, 1.0458416938781738, 1.044350504875183, 1.0453771352767944, 1.045842170715332, 1.045760989189148, 1.044565200805664, 1.0432268381118774, 1.0437105894088745, 1.0420544147491455, 1.0427201986312866, 1.0419042110443115, 1.0404586791992188, 1.039211630821228, 1.0411417484283447, 1.039099931716919, 1.0383267402648926, 1.0402390956878662, 1.0393080711364746, 1.0377349853515625, 1.0395443439483643, 1.040069580078125, 1.0407203435897827, 1.0366485118865967, 1.0349009037017822, 1.0351974964141846, 1.0343950986862183, 1.0358482599258423, 1.0368109941482544, 1.033142328262329, 1.033722996711731, 1.0332432985305786, 1.0332082509994507, 1.0343782901763916, 1.0324255228042603, 1.032749056816101, 1.030280590057373, 1.0314579010009766, 1.0306051969528198, 1.0318893194198608, 1.0309512615203857, 1.030428171157837, 1.027501106262207, 1.0305235385894775, 1.0308136940002441, 1.0294543504714966, 1.0293424129486084, 1.0283750295639038, 1.0282061100006104, 1.0285794734954834, 1.0254042148590088, 1.0262669324874878, 1.0276718139648438, 1.0254460573196411, 1.0254096984863281, 1.023992657661438, 1.0246716737747192, 1.024843692779541, 1.0234129428863525, 1.0240117311477661, 1.0241023302078247, 1.0239243507385254, 1.025425910949707, 1.021583080291748, 1.0221869945526123, 1.0233701467514038, 1.0215781927108765, 1.0238174200057983, 1.021636962890625, 1.0231486558914185, 1.0200663805007935, 1.0199460983276367, 1.0224854946136475, 1.0204331874847412, 1.0209778547286987, 1.0192980766296387, 1.0204966068267822, 1.0207321643829346, 1.0197672843933105, 1.0187138319015503, 1.0182961225509644, 1.0169339179992676, 1.0182952880859375, 1.0179637670516968, 1.0172728300094604, 1.0177267789840698, 1.0165729522705078, 1.016086459159851, 1.014927864074707, 1.0165934562683105, 1.0156303644180298, 1.0164129734039307, 1.0149298906326294, 1.0167303085327148, 1.013716697692871, 1.0140888690948486, 1.0144621133804321, 1.0143183469772339, 1.0138969421386719, 1.012410044670105, 1.0153727531433105, 1.0140721797943115, 1.011375904083252, 1.0118080377578735, 1.0114200115203857, 1.0109339952468872, 1.012333869934082, 1.0127456188201904, 1.0091187953948975, 1.0103451013565063, 1.0110666751861572, 1.0098623037338257, 1.0113011598587036, 1.0098806619644165, 1.0099695920944214, 1.0089832544326782, 1.0086036920547485, 1.0088545083999634, 1.0094941854476929, 1.0099605321884155, 1.0086936950683594, 1.0093176364898682, 1.0092591047286987, 1.0076913833618164, 1.006326675415039, 1.008119821548462, 1.0091174840927124, 1.0078545808792114, 1.007241129875183, 1.0064091682434082, 1.0056945085525513, 1.0053514242172241, 1.0074557065963745, 1.0056082010269165, 1.0063114166259766, 1.0056465864181519, 1.0058835744857788, 1.0052781105041504], "accuracy_train_first": 0.38816142372646734, "model": "residualv5", "loss_std": [0.911896824836731, 0.1823483258485794, 0.17012834548950195, 0.17081224918365479, 0.17171722650527954, 0.16895903646945953, 0.1705285757780075, 0.17094896733760834, 0.16895641386508942, 0.17027093470096588, 0.17058074474334717, 0.16973206400871277, 0.17138436436653137, 0.17026419937610626, 0.1681240051984787, 0.16868311166763306, 0.16889691352844238, 0.16977374255657196, 0.16737627983093262, 0.16854210197925568, 0.16812385618686676, 0.16597841680049896, 0.16974428296089172, 0.1665991097688675, 0.16933898627758026, 0.16634495556354523, 0.16895663738250732, 0.167778879404068, 0.16694368422031403, 0.1660792976617813, 0.16666924953460693, 0.167107492685318, 0.1659041941165924, 0.1666598916053772, 0.16652317345142365, 0.16778837144374847, 0.1671725958585739, 0.16605044901371002, 0.1667507141828537, 0.16450488567352295, 0.16734392940998077, 0.16441835463047028, 0.1624232679605484, 0.16520649194717407, 0.1627892702817917, 0.16416491568088531, 0.1661340296268463, 0.1649010181427002, 0.16647544503211975, 0.1635991334915161, 0.16341543197631836, 0.16479934751987457, 0.16554543375968933, 0.16416408121585846, 0.16444960236549377, 0.1633722484111786, 0.16504548490047455, 0.16449755430221558, 0.16453707218170166, 0.1634729951620102, 0.16525058448314667, 0.16312983632087708, 0.16278362274169922, 0.16309012472629547, 0.16120250523090363, 0.16627290844917297, 0.16338573396205902, 0.16385819017887115, 0.16580988466739655, 0.165628582239151, 0.16348396241664886, 0.16402997076511383, 0.16356968879699707, 0.1626328080892563, 0.1628018468618393, 0.16355665028095245, 0.16294042766094208, 0.16335758566856384, 0.16295689344406128, 0.16297243535518646, 0.16269665956497192, 0.16473537683486938, 0.1651788204908371, 0.16340747475624084, 0.16220299899578094, 0.16386255621910095, 0.16589029133319855, 0.16510090231895447, 0.16268645226955414, 0.16415202617645264, 0.16200292110443115, 0.1622181236743927, 0.1660555750131607, 0.16402405500411987, 0.16189652681350708, 0.16483750939369202, 0.16392406821250916, 0.1602698564529419, 0.16334977746009827, 0.16321982443332672, 0.15953215956687927, 0.16121432185173035, 0.16332411766052246, 0.16346360743045807, 0.16257977485656738, 0.164590984582901, 0.16076843440532684, 0.16328011453151703, 0.1630186289548874, 0.16355599462985992, 0.16226014494895935, 0.161872997879982, 0.16234531998634338, 0.162313312292099, 0.1654697209596634, 0.16163749992847443, 0.16357462108135223, 0.16304172575473785, 0.16154064238071442, 0.16259613633155823, 0.1640719771385193, 0.1632017195224762, 0.1629200279712677, 0.16320405900478363, 0.16156920790672302, 0.1622346192598343, 0.16416849195957184, 0.1634945571422577, 0.16080819070339203, 0.1627878099679947, 0.16277465224266052, 0.1622779220342636, 0.1625644713640213, 0.16374628245830536, 0.16105550527572632, 0.16465526819229126, 0.1636386662721634, 0.16249431669712067, 0.1613663136959076, 0.16261132061481476, 0.16211634874343872, 0.16100525856018066, 0.16332276165485382, 0.16261456906795502, 0.16217365860939026, 0.16302695870399475, 0.16294294595718384, 0.1633462756872177, 0.16282929480075836, 0.16138425469398499, 0.16261357069015503, 0.16247737407684326, 0.16374818980693817, 0.16235481202602386, 0.16300269961357117, 0.16383275389671326, 0.16101762652397156, 0.16123953461647034, 0.16129563748836517, 0.16252528131008148, 0.16224727034568787, 0.16092829406261444, 0.16273415088653564, 0.1623789668083191, 0.1613340824842453, 0.16365709900856018, 0.16232869029045105, 0.16254302859306335, 0.1617385596036911, 0.16323673725128174, 0.16267560422420502, 0.1623162031173706, 0.1601339876651764, 0.16113699972629547, 0.1617748737335205, 0.16138912737369537, 0.16262689232826233, 0.16215215623378754, 0.16267043352127075, 0.16124044358730316, 0.1632855236530304, 0.16315944492816925, 0.162533700466156, 0.16343127191066742, 0.16174212098121643, 0.16308270394802094, 0.1618519276380539, 0.1605881303548813, 0.16397397220134735, 0.16280242800712585, 0.16364164650440216, 0.16193369030952454, 0.1632244884967804, 0.1651323437690735, 0.1644703596830368, 0.16301043331623077, 0.16168850660324097, 0.16249051690101624, 0.16033978760242462, 0.16210615634918213, 0.1621139645576477, 0.16220079362392426, 0.16289252042770386, 0.16257283091545105, 0.16421358287334442, 0.16136808693408966, 0.16148291528224945, 0.16220302879810333, 0.1627366840839386, 0.1629851907491684, 0.16300106048583984, 0.16221465170383453, 0.16219447553157806, 0.15977579355239868, 0.16153296828269958, 0.1637745201587677, 0.16162556409835815, 0.1620425432920456, 0.1605997234582901, 0.16040202975273132, 0.16175870597362518, 0.16126284003257751, 0.16294993460178375, 0.1602354496717453, 0.16284602880477905, 0.1605142056941986, 0.16301025450229645, 0.16167084872722626, 0.15967373549938202, 0.15958251059055328, 0.1615062803030014, 0.1610773205757141, 0.16322708129882812, 0.1621708869934082, 0.1603187620639801, 0.16191217303276062, 0.16303704679012299, 0.16102783381938934, 0.16226401925086975, 0.1619713306427002, 0.1620795577764511, 0.1625136137008667, 0.16265027225017548, 0.15996153652668, 0.16209924221038818, 0.1631104052066803, 0.16099603474140167, 0.16085711121559143, 0.16151677072048187, 0.16251957416534424, 0.1628923863172531, 0.16068214178085327, 0.16085471212863922, 0.16030417382717133, 0.16211803257465363, 0.16180625557899475, 0.16419196128845215, 0.16173915565013885, 0.1615336835384369, 0.16208623349666595, 0.1614082157611847, 0.16349440813064575, 0.1635204702615738, 0.1615799218416214, 0.16252383589744568, 0.16085185110569, 0.1608615219593048, 0.1608622819185257, 0.16215860843658447, 0.16168245673179626]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:16 2016", "state": "available"}], "summary": "d7b2b60b01ffc4171795d8a2a6a76f9f"}