{"content": {"hp_model": {"f0": 64, "f1": 32, "f2": 16, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.015093510429937214, 0.008045452326823969, 0.010906268596924661, 0.01014595044063348, 0.01192797146972389, 0.01467039268407874, 0.01390797886540946, 0.007256700650847507, 0.007907300423568192, 0.011386075786861715, 0.013646134569040482, 0.011890138387032121, 0.011729243333341778, 0.010983901847196154, 0.01087441406034069, 0.011242078234927943, 0.007331336060105859, 0.013316314561839985, 0.008766497650220008, 0.008537943579123882, 0.007951941991285951, 0.009383759684071883, 0.008873446552198029, 0.013237522645392125, 0.013014348329668938, 0.015290125252655608, 0.014166285827954143, 0.009561341382981738, 0.009071061929323103, 0.010052061866870186, 0.015269995003493013, 0.007522760954234358, 0.013695874670317423, 0.013395052848263438, 0.015360895275864914, 0.010817950192651778, 0.011541504831112992, 0.016075475630122002, 0.012587606297019084, 0.015094710667306952, 0.019280406781665895, 0.016623136164896433, 0.016926259174470073, 0.017491447285846763, 0.013788484556790492, 0.016358183204947144, 0.015367276790282679, 0.015616806898420066, 0.012550502604950048, 0.016469641018487503, 0.014779465574897448, 0.017744805559824415, 0.014925776987353171, 0.01658776466476265, 0.0136790886913684, 0.013742950879304815, 0.01854637048133305, 0.01431722592584408, 0.016124970267100525, 0.015670085321047217, 0.014752153769152294, 0.016664175972564824, 0.018001373934612205, 0.018977581124379198, 0.016017931612258566, 0.015412855464256324, 0.018559748494629064, 0.019832488463778636, 0.01401619934776907, 0.01635365820926852, 0.014466734858215646, 0.015267510778663196, 0.01730924532351941, 0.015251562716744936, 0.014586565847223764, 0.016334523432647404, 0.016354386715497774, 0.015980497339365945, 0.014275694412335222, 0.01684916322742659, 0.015545942733186746, 0.01633005870580075, 0.013077835651208418, 0.014699211175818627, 0.014370888223904614, 0.013520895532228685, 0.014729196326348998, 0.014990851751761841, 0.018097274955889517, 0.01608568673226997, 0.016875037866472407, 0.01723427492873608, 0.0172879886609018, 0.01747582785374258, 0.014864431977638077, 0.016412595458350162, 0.017440913229339463, 0.01667494907435984, 0.015539572578567713, 0.017715204780596135, 0.018574449191946035, 0.018148673919667575, 0.018173125804435517, 0.01876042020597981, 0.016713242925628067, 0.017308891421139186, 0.016782782932577987, 0.01765786028483652, 0.017098392520412672, 0.018839863062915685, 0.01775057424651203, 0.0187089513604643, 0.01881215935182651, 0.017080314467650265, 0.01865744006143009, 0.017190574920949806, 0.018689707739056434, 0.020122749289391534, 0.017795343299367838, 0.020356235740385097, 0.017841233645817776, 0.018557794639524193, 0.018276919401845355, 0.01851695838951542, 0.018311174078971496, 0.018640959506713347, 0.017032830705724034, 0.0175202746828869, 0.01830924426099694, 0.01860463430727275, 0.017503813311868083, 0.01645986155301422, 0.01785812284541405, 0.01761352946500846, 0.019534627451023277, 0.017941488943675393, 0.0181930870576431, 0.019018107600175506, 0.01844181822743182, 0.01811694059166246, 0.018067136510171285, 0.016790310213095957, 0.01805067008052179, 0.018089534617893484, 0.017937162466121613, 0.01761448240929565, 0.017447713269176976, 0.017090191999842092, 0.017444240143416254, 0.017724675118004674, 0.01691890085747254, 0.018194890996313762, 0.017631556426508193, 0.017125141126605188, 0.017241735258111023, 0.017410128890151463, 0.016996229305204797, 0.0166254605030657, 0.017120847642857272, 0.015860573749239434, 0.017167961975729725, 0.01624978615200647, 0.016475002807985376, 0.017179184315282647, 0.01601563498347787, 0.01740303283492798, 0.014490128589443338, 0.016689206224470933, 0.01810844659030428, 0.017204435207035226, 0.01732799130707658, 0.01652998571117498, 0.015499845752089948, 0.017274197419167286, 0.01728887847653265, 0.016258296617246575, 0.016053729401511275, 0.01757272603062086, 0.015487765945678184, 0.016507977942087148, 0.016372418673453522, 0.01618206368220374, 0.01787018538932215, 0.015601242591471814, 0.01581073019724537, 0.01615483864645227, 0.01670954678403064, 0.015632098893435902, 0.015486424513499733, 0.015996912317810506, 0.01594081211932126, 0.016368168058394195, 0.016225053276352923, 0.014278995702270283, 0.01588477360531419, 0.015027449136257191, 0.01482292908897099, 0.014794408102994344, 0.016476331692524868, 0.017733776862141334, 0.016002118905250905, 0.015794113707471327, 0.01791858897124836, 0.015762391136115817, 0.016736349291248374, 0.016843712441638167, 0.015360950475052565, 0.015306973090573777, 0.01591107922452507, 0.016182850437585657, 0.01540461201612804, 0.014948973841935017, 0.0156619371423155, 0.01608046812658814, 0.0156380239449471, 0.017332026810391428, 0.016026214350700143, 0.016008459914693386, 0.015075405296640434, 0.016078653237929612, 0.014770215143343039, 0.016186839163986763, 0.015862068315980794, 0.0161930763819897, 0.014935757375814228, 0.015244542517331807, 0.015391517536369597, 0.015384266434204468, 0.015659627186769914, 0.015344573736926107, 0.01474478078666449, 0.015965829247237242, 0.016017106438463078, 0.016141667139464307, 0.01614529909170595, 0.015468774930917717, 0.015712824497280377, 0.015576291534598673, 0.01574543995637972, 0.015496530196449101, 0.0153037062777843, 0.015119754446178428, 0.01538803048416102, 0.015432022172030676, 0.015319309123959478, 0.016365272153520564, 0.014621166978193916, 0.01582391266624456, 0.015062709973643758, 0.015844736148554042, 0.015561738946688036, 0.01617911782173766, 0.015278024886847777, 0.016318109591862372, 0.015584119181514052, 0.015391515217552665], "moving_avg_accuracy_train": [0.04277491550156883, 0.0911262299856958, 0.14038666611872458, 0.1874059926835317, 0.23207171479183963, 0.2735098445654242, 0.31113400805323393, 0.34733449440645614, 0.3815959786648231, 0.4144237507342027, 0.44433826401326487, 0.47401340093442823, 0.5018879244264874, 0.5273145393931687, 0.5513769107237854, 0.574386173382027, 0.5955823944874382, 0.6140057348132884, 0.6324071884291357, 0.6493146194166484, 0.6660309561899153, 0.6808198208191704, 0.6947900691497672, 0.7079907944353258, 0.7202433628553959, 0.7312243517013624, 0.7417091668138489, 0.7518337805115246, 0.7614411534870424, 0.7701807951173895, 0.7782835656656357, 0.7860107177911634, 0.7931627923529477, 0.799850811578801, 0.8060257417546696, 0.8119925132498838, 0.8170904570384059, 0.8223204556659607, 0.827489906702124, 0.8320169266965941, 0.8365561663070658, 0.8406438431541186, 0.8445856022783984, 0.8481678824782994, 0.8515758016582565, 0.8546172080880381, 0.8576264441879183, 0.8606627829040472, 0.8634464247294601, 0.866279620452112, 0.8689409235012623, 0.8714011643633454, 0.8736920750011156, 0.8758168538370598, 0.8778685916203435, 0.8797731761990806, 0.88175698353303, 0.8837191935407458, 0.8853549742143567, 0.8869643606003684, 0.8884685037727512, 0.8901290441242966, 0.8915609316669242, 0.8930424375623858, 0.8943666004195192, 0.8955050488124141, 0.8968340666159733, 0.8978929988594146, 0.8989367186820834, 0.8999504352355713, 0.9009929884670437, 0.9020289426253689, 0.9028799932571657, 0.9036598897186401, 0.9045476281946351, 0.905339761571877, 0.9062037441863762, 0.90695346280253, 0.9078420151010883, 0.9086673248555144, 0.9094938810892782, 0.9101376921543998, 0.91075668569159, 0.9115207541679274, 0.9122386066823363, 0.9129033832822366, 0.9136154703185386, 0.9142192904655331, 0.9147835107418387, 0.9153192468250468, 0.9158711637642198, 0.916402838339256, 0.9170232155829882, 0.9175791578559, 0.9181260088777112, 0.9186785926175702, 0.9191828934298719, 0.9196112596216761, 0.920068760660939, 0.9205503381581988, 0.9209512058223992, 0.9213979811773132, 0.9217674908645836, 0.9222744357438414, 0.922707434647078, 0.9231924647611817, 0.923596511878179, 0.9240368841941909, 0.9243842830071455, 0.9247828642983006, 0.9251253835163111, 0.9254220250684729, 0.9257355414904277, 0.9260502583535204, 0.9263566829207616, 0.9266790040562879, 0.9270318720961187, 0.9274097990545578, 0.9277918941421807, 0.92811703433529, 0.9283957817138688, 0.9286652555450658, 0.9289193716883721, 0.9292086021840329, 0.9294618981348802, 0.9297550768037658, 0.930018901556944, 0.9302261529490994, 0.9304916621639254, 0.9307282953084595, 0.9309668417754449, 0.9312047129861895, 0.9313630295532498, 0.9315753410255273, 0.9317989734339104, 0.931946764178836, 0.932135543371879, 0.9322380513789601, 0.9323908345520183, 0.9325167857613605, 0.9326485988449698, 0.9327300642880845, 0.9329196406273639, 0.933050659705316, 0.9331709741219198, 0.9333094119337496, 0.9334665940965485, 0.9335801202085345, 0.9336776794605216, 0.9337352198039673, 0.9338428096844972, 0.9339605669162596, 0.9340246957462744, 0.9341289146694783, 0.9342065077563326, 0.9343042433202158, 0.9344108065181869, 0.934499773998751, 0.9346007710705444, 0.9347079084280064, 0.9347902730104088, 0.9349434561940948, 0.9350790319594213, 0.9351545471720247, 0.9352272332586243, 0.9352600265555933, 0.9353941722192938, 0.9354451849011572, 0.9355027581077008, 0.9355568630935808, 0.9356427239130064, 0.9357316964921746, 0.9357629797372446, 0.9358422158339798, 0.935953091899622, 0.9360226173753574, 0.9361015384428235, 0.9361306786761528, 0.9362104193575871, 0.9362821138732403, 0.9363188092492515, 0.9363541241876523, 0.9364277603107845, 0.9364824431263745, 0.9365456085532627, 0.9366024574374621, 0.936637309342756, 0.9367244435801305, 0.936749458068786, 0.9368207992335758, 0.9368431896521341, 0.9368493540871606, 0.9368757923691515, 0.9368739741372197, 0.9368933361654043, 0.9369316883300561, 0.9369452428901384, 0.9369040356692309, 0.9369041515513665, 0.9369390970286127, 0.9369729091557624, 0.9370010149213877, 0.9370332495080603, 0.937043587347952, 0.9370924910312538, 0.9371063134605204, 0.9371489084837467, 0.9371755822117839, 0.9372089252110744, 0.9372343196616355, 0.9372502352695307, 0.9372645232678176, 0.9372680818710376, 0.9372805852091738, 0.937308114255163, 0.9373328543477345, 0.9373179540989153, 0.9373743704369012, 0.9373785700672606, 0.9374032760738698, 0.937404621189351, 0.9373802912051981, 0.9373931993539658, 0.9373723006533422, 0.9373860078572955, 0.9373960552408628, 0.937400483637273, 0.9373811095594907, 0.937400875270439, 0.9373629329365014, 0.9373985032514246, 0.9373863747562932, 0.9374010357475797, 0.937428145483776, 0.9374316539558856, 0.9374208606879271, 0.9374343982348597, 0.9374302699366137, 0.9374103144753444, 0.9374597478268594, 0.9375042738920417, 0.9374978083256965, 0.937510590506462, 0.9375383705108177, 0.9375727091587945, 0.9375431240241073, 0.9375839267183651, 0.9375648455717686, 0.9375453834398408, 0.9375674310996865, 0.9375663476542621, 0.9375722759021711, 0.9375636964812507, 0.9375745401440798, 0.9375796491430071, 0.9375749466468034], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 726169413, "moving_var_accuracy_train": [0.01646724056549719, 0.035861163020034004, 0.05411436183017647, 0.0686002792826306, 0.07969549193747685, 0.08718001013592111, 0.09120220822574593, 0.09387626431305977, 0.09505328161403073, 0.09524691702397994, 0.09377612826409065, 0.09232403919928973, 0.09008453681854502, 0.08689469787466525, 0.08341620751367107, 0.07983942227498754, 0.0758989981498341, 0.07136387355370954, 0.0672750076549242, 0.06312025789280935, 0.05932315533958389, 0.055359234458827386, 0.05157982155871153, 0.047990171735423436, 0.04454228345787762, 0.041173294156407025, 0.038045346872253555, 0.035163382407772656, 0.03247775870641179, 0.029917414858212674, 0.027516567387409152, 0.02530229056840765, 0.023232431046402793, 0.02131175435225096, 0.01952374678111753, 0.01789179336169067, 0.016336515303359986, 0.014949039743822008, 0.013694644785577411, 0.012509625497292662, 0.01144410521373487, 0.010450076610414761, 0.00954490613431788, 0.00870591010376152, 0.00793984431161944, 0.0072291112580975475, 0.006587699649431193, 0.006011903859679637, 0.005480451430021367, 0.005004649269044913, 0.004567927147415166, 0.00416560949856882, 0.0037962829926641802, 0.003457286859312849, 0.003149444824763749, 0.0028671473240454446, 0.0026158520154849845, 0.0023889192269659076, 0.0021741093099787476, 0.001980009499836192, 0.0018023705699998069, 0.0016469500613318232, 0.0015007077726112285, 0.0013703907328146904, 0.0012491323249831294, 0.001135883675174381, 0.00103819190255654, 0.0009444647497666852, 0.0008598224344041012, 0.0007830887822210287, 0.0007145621591630077, 0.0006527647524100675, 0.0005940068617699965, 0.0005400803220085776, 0.0004931650062235767, 0.00044949578318728527, 0.0004112643984919696, 0.00037519666067344104, 0.00034478272129155716, 0.00031643467487915857, 0.000290939964259407, 0.0002655764020216239, 0.0002424671388112099, 0.00022347463065888314, 0.00020576497768498214, 0.00018916583126645986, 0.00017481285966523802, 0.00016061296262796142, 0.00014741676704691534, 0.0001352582086998847, 0.00012447389859961158, 0.00011457060942330889, 0.00010657735980184493, 9.87012701189551e-05, 9.152255746756367e-05, 8.511844082681625e-05, 7.889547052772764e-05, 7.265740182348272e-05, 6.727542644947326e-05, 6.263513577732847e-05, 5.7817876157409135e-05, 5.383256250149507e-05, 4.9678142932226406e-05, 4.7023266634454804e-05, 4.4008332422847397e-05, 4.172478708484842e-05, 3.902159503114859e-05, 3.686478551842103e-05, 3.426448038375848e-05, 3.226783575631283e-05, 3.009692691304015e-05, 2.7879200115956807e-05, 2.597591302587944e-05, 2.4269742058525685e-05, 2.2687831991353563e-05, 2.135406702188083e-05, 2.0339303001499023e-05, 1.9590831774584238e-05, 1.8945718500995482e-05, 1.8002591957472682e-05, 1.6901633671306345e-05, 1.586501561547611e-05, 1.4859689182528176e-05, 1.4126608780856899e-05, 1.3291377451212255e-05, 1.2735823293096502e-05, 1.208867246729291e-05, 1.1266383476516588e-05, 1.0774201417283253e-05, 1.0200738481383379e-05, 9.692804385445843e-06, 9.232768363010979e-06, 8.535068745361641e-06, 8.087247322171114e-06, 7.728625676666806e-06, 7.1523420475713464e-06, 6.757846096347714e-06, 6.1766325103548135e-06, 5.769053541046953e-06, 5.334921551155308e-06, 4.9578015971349814e-06, 4.521751003218323e-06, 4.3930285986276776e-06, 4.108219727851591e-06, 3.827677784651004e-06, 3.617395255883932e-06, 3.4780118210148184e-06, 3.246204241837222e-06, 3.007244086488026e-06, 2.7363176979539904e-06, 2.566866169690363e-06, 2.4349804434127493e-06, 2.2284949606231683e-06, 2.103399720144815e-06, 1.947245932278544e-06, 1.8384915030787263e-06, 1.7568437892271687e-06, 1.6523963236857752e-06, 1.5789603679147771e-06, 1.5243700513987256e-06, 1.4329883661677394e-06, 1.500875319428455e-06, 1.5162148807806336e-06, 1.4159163187134874e-06, 1.3218740915087025e-06, 1.1993652852926334e-06, 1.2413842885703444e-06, 1.1406665031115084e-06, 1.0564319198057132e-06, 9.771348732988052e-07, 9.457701087808567e-07, 9.224381764972734e-07, 8.39002131646585e-07, 8.116071497142905e-07, 8.410879521336112e-07, 8.004832829064649e-07, 7.764917686257137e-07, 7.064849705495188e-07, 6.930636599748345e-07, 6.700182261501575e-07, 6.151353591205338e-07, 5.648461270767501e-07, 5.571620220384546e-07, 5.283577127223141e-07, 5.114307818357992e-07, 4.893738643646517e-07, 4.513683756517988e-07, 4.7456291599208154e-07, 4.327381461771166e-07, 4.352703877016382e-07, 3.962553265203994e-07, 3.569717962011254e-07, 3.275654613726546e-07, 2.9483866894160814e-07, 2.6872879526625196e-07, 2.550939125409982e-07, 2.3123805617810333e-07, 2.2339656605458747e-07, 2.0105703030715286e-07, 1.9194200469608194e-07, 1.8303714370802623e-07, 1.7184283588968698e-07, 1.6401016950229432e-07, 1.4857099095469304e-07, 1.552380240236346e-07, 1.4143375757875314e-07, 1.4361940585370365e-07, 1.3566085517500986e-07, 1.321005700726285e-07, 1.246944161390497e-07, 1.1450473369718921e-07, 1.0489158238287839e-07, 9.451639705649238e-08, 8.647175853177e-08, 8.464521803628569e-08, 8.168934585669417e-08, 7.551856800489873e-08, 9.66119399300716e-08, 8.710947799345988e-08, 8.389201105724132e-08, 7.551909397243787e-08, 7.329471773511385e-08, 6.746482870309397e-08, 6.464914702258059e-08, 5.987521928228575e-08, 5.479624660297931e-08, 4.949311819557452e-08, 4.792200038525162e-08, 4.664595031034984e-08, 5.4937941620998774e-08, 6.083137319247138e-08, 5.6072139420593405e-08, 5.2399427468064106e-08, 5.3773924890931056e-08, 4.8507316790736405e-08, 4.470503681066677e-08, 4.188391972218348e-08, 3.7848913367639655e-08, 3.764800594112902e-08, 5.5876111525082364e-08, 6.813163469811327e-08, 6.169470316177868e-08, 5.6995690151704074e-08, 5.8241678914526216e-08, 6.302979572701913e-08, 6.460433790442003e-08, 7.312764284221468e-08, 6.909168995695472e-08, 6.559149217379765e-08, 6.34072366984783e-08, 5.707707771452221e-08, 5.1685667052501657e-08, 4.717955851720487e-08, 4.351986787745585e-08, 3.9402797920052664e-08, 3.5661539362954075e-08], "duration": 238761.661384, "accuracy_train": [0.42774915501568844, 0.5262880603428387, 0.5837305913159837, 0.6105799317667958, 0.6340632137666113, 0.6464530125276855, 0.6497514794435216, 0.6731388715854558, 0.6899493369901255, 0.7098736993586194, 0.7135688835248247, 0.7410896332248985, 0.7527586358550203, 0.7561540740933002, 0.7679382526993356, 0.7814695373062015, 0.7863483844361389, 0.7798157977459395, 0.7980202709717608, 0.8014814983042636, 0.8164779871493172, 0.8139196024824659, 0.8205223041251385, 0.8267973220053525, 0.8305164786360282, 0.8300532513150609, 0.8360725028262275, 0.8429553037906055, 0.8479075102667036, 0.8488375697905132, 0.8512085005998523, 0.8555550869209118, 0.857531463409007, 0.8600429846114802, 0.8616001133374861, 0.8656934567068106, 0.8629719511351052, 0.8693904433139534, 0.8740149660275931, 0.8727601066468254, 0.8774093228013106, 0.8774329347775931, 0.8800614343969176, 0.8804084042774087, 0.88224707427787, 0.8819898659560724, 0.8847095690868402, 0.8879898313492063, 0.8884992011581765, 0.8917783819559801, 0.8928926509436139, 0.893543332122093, 0.8943102707410484, 0.8949398633605574, 0.8963342316698967, 0.896914437407715, 0.8996112495385751, 0.9013790836101883, 0.9000770002768549, 0.901448838074474, 0.9020057923241971, 0.9050739072882059, 0.9044479195505721, 0.9063759906215393, 0.9062840661337209, 0.9057510843484681, 0.9087952268480066, 0.9074233890503876, 0.9083301970861019, 0.9090738842169619, 0.9103759675502953, 0.9113525300502953, 0.910539448943337, 0.9106789578719084, 0.9125372744785898, 0.9124689619670543, 0.9139795877168696, 0.9137009303479143, 0.9158389857881136, 0.9160951126453488, 0.9169328871931525, 0.9159319917404946, 0.9163276275263011, 0.9183973704549648, 0.9186992793120154, 0.91888637268134, 0.9200242536452565, 0.9196536717884828, 0.9198614932285898, 0.9201408715739202, 0.9208384162167773, 0.921187909514581, 0.922606610776578, 0.9225826383121077, 0.9230476680740125, 0.9236518462763011, 0.9237216007405868, 0.9234665553479143, 0.9241862700143041, 0.9248845356335363, 0.924559014800203, 0.9254189593715393, 0.9250930780500184, 0.9268369396571613, 0.9266044247762089, 0.9275577357881136, 0.9272329359311554, 0.9280002350382982, 0.9275108723237356, 0.928370095918697, 0.9282080564784054, 0.9280917990379292, 0.9285571892880213, 0.9288827101213547, 0.9291145040259321, 0.9295798942760245, 0.9302076844545959, 0.9308111416805095, 0.9312307499307864, 0.9310432960732743, 0.930904508121078, 0.9310905200258398, 0.9312064169781286, 0.9318116766449798, 0.9317415616925065, 0.9323936848237356, 0.9323933243355482, 0.9320914154784975, 0.9328812450973607, 0.9328579936092655, 0.9331137599783131, 0.9333455538828904, 0.9327878786567922, 0.9334861442760245, 0.9338116651093578, 0.9332768808831673, 0.9338345561092655, 0.9331606234426911, 0.9337658831095422, 0.9336503466454411, 0.933834916597453, 0.9334632532761166, 0.9346258276808784, 0.9342298314068845, 0.9342538038713547, 0.9345553522402179, 0.9348812335617387, 0.9346018552164084, 0.9345557127284054, 0.9342530828949798, 0.9348111186092655, 0.9350203820021227, 0.9346018552164084, 0.9350668849783131, 0.9349048455380213, 0.9351838633951642, 0.9353698752999261, 0.9353004813238279, 0.935509744716685, 0.9356721446451642, 0.9355315542520304, 0.9363221048472684, 0.9362992138473607, 0.9358341840854559, 0.9358814080380213, 0.9355551662283131, 0.9366014831925988, 0.9359042990379292, 0.9360209169665927, 0.9360438079665007, 0.9364154712878369, 0.936532449704688, 0.9360445289428755, 0.9365553407045959, 0.9369509764904023, 0.9366483466569768, 0.9368118280500184, 0.9363929407761166, 0.9369280854904946, 0.9369273645141197, 0.9366490676333518, 0.9366719586332595, 0.9370904854189737, 0.936974588466685, 0.9371140973952565, 0.9371140973952565, 0.9369509764904023, 0.9375086517165007, 0.936974588466685, 0.937462869716685, 0.9370447034191584, 0.9369048340023993, 0.937113736907069, 0.9368576100498339, 0.9370675944190661, 0.9372768578119232, 0.9370672339308784, 0.9365331706810631, 0.9369051944905868, 0.9372536063238279, 0.9372772183001107, 0.9372539668120154, 0.9373233607881136, 0.9371366279069768, 0.9375326241809707, 0.9372307153239202, 0.9375322636927832, 0.9374156457641197, 0.937509012204688, 0.937462869716685, 0.9373934757405868, 0.9373931152523993, 0.9373001093000184, 0.9373931152523993, 0.9375558756690661, 0.9375555151808784, 0.9371838518595422, 0.9378821174787744, 0.9374163667404946, 0.9376256301333518, 0.9374167272286821, 0.937161321347822, 0.9375093726928755, 0.9371842123477298, 0.9375093726928755, 0.9374864816929678, 0.9374403392049648, 0.9372067428594499, 0.9375787666689737, 0.9370214519310631, 0.9377186360857327, 0.9372772183001107, 0.9375329846691584, 0.9376721331095422, 0.9374632302048725, 0.9373237212763011, 0.9375562361572536, 0.9373931152523993, 0.9372307153239202, 0.9379046479904946, 0.9379050084786821, 0.9374396182285898, 0.9376256301333518, 0.9377883905500184, 0.9378817569905868, 0.9372768578119232, 0.937951150966685, 0.9373931152523993, 0.9373702242524916, 0.9377658600382982, 0.9375565966454411, 0.9376256301333518, 0.9374864816929678, 0.9376721331095422, 0.9376256301333518, 0.9375326241809707], "end": "2016-01-24 02:16:53.075000", "learning_rate_per_epoch": [0.00016032806888688356, 0.00015599797188770026, 0.00015178481407929212, 0.0001476854522479698, 0.0001436968013877049, 0.0001398158783558756, 0.00013603977276943624, 0.00013236564700491726, 0.00012879075075034052, 0.000125312406453304, 0.00012192800204502419, 0.00011863500549225137, 0.00011543094296939671, 0.00011231341341044754, 0.0001092800812330097, 0.00010632867633830756, 0.0001034569795592688, 0.00010066284448839724, 9.794416837394238e-05, 9.529892122372985e-05, 9.272511670133099e-05, 9.022081940202042e-05, 8.778415940469131e-05, 8.541331044398248e-05, 8.310648991027847e-05, 8.086197340162471e-05, 7.867807289585471e-05, 7.65531585784629e-05, 7.448562973877415e-05, 7.247394387377426e-05, 7.051658758427948e-05, 6.861209112685174e-05, 6.675903568975627e-05, 6.495602428913116e-05, 6.320171087281778e-05, 6.149477849248797e-05, 5.983394294162281e-05, 5.821796366944909e-05, 5.664562922902405e-05, 5.5115760915214196e-05, 5.362720912671648e-05, 5.2178860642015934e-05, 5.076962770544924e-05, 4.9398455303162336e-05, 4.806431388715282e-05, 4.676620665122755e-05, 4.550315861706622e-05, 4.427422027220018e-05, 4.307847484597005e-05, 4.191502375761047e-05, 4.078299389220774e-05, 3.968153760069981e-05, 3.860982906189747e-05, 3.756706428248435e-05, 3.655246473499574e-05, 3.556526644388214e-05, 3.460473089944571e-05, 3.367013414390385e-05, 3.27607813233044e-05, 3.1875988497631624e-05, 3.101508991676383e-05, 3.0177443477441557e-05, 2.9362419809331186e-05, 2.8569407731993124e-05, 2.779781243589241e-05, 2.7047057301388122e-05, 2.631657844176516e-05, 2.560582652222365e-05, 2.4914270397857763e-05, 2.4241391656687483e-05, 2.358668643864803e-05, 2.2949663616600446e-05, 2.23298447963316e-05, 2.1726766135543585e-05, 2.113997470587492e-05, 2.056903213087935e-05, 2.001350912905764e-05, 1.9472989151836373e-05, 1.8947068383567967e-05, 1.8435350284562446e-05, 1.7937452867045067e-05, 1.7453003238188103e-05, 1.6981637600110844e-05, 1.65230012498796e-05, 1.60767522174865e-05, 1.5642555808881298e-05, 1.5220085515466053e-05, 1.4809025742579252e-05, 1.440906726202229e-05, 1.4019910850038286e-05, 1.364126455882797e-05, 1.3272844626044389e-05, 1.2914375474792905e-05, 1.2565587894641794e-05, 1.2226219951116946e-05, 1.1896017895196564e-05, 1.1574733434827067e-05, 1.1262126463407185e-05, 1.0957962331303861e-05, 1.066201275534695e-05, 1.037405581882922e-05, 1.009387597150635e-05, 9.82126312010223e-06, 9.556012628308963e-06, 9.297926226281561e-06, 9.046810191648547e-06, 8.802476259006653e-06, 8.564741619920824e-06, 8.33342710393481e-06, 8.108359907055274e-06, 7.889371772762388e-06, 7.676298082515132e-06, 7.468978765245993e-06, 7.267258752108319e-06, 7.070986612234265e-06, 6.880015462229494e-06, 6.694202056678478e-06, 6.5134067881444935e-06, 6.337494596664328e-06, 6.166333150758874e-06, 5.999794666422531e-06, 5.8377536333864555e-06, 5.680089088855311e-06, 5.526682798517868e-06, 5.377419711294351e-06, 5.232187959336443e-06, 5.09087840327993e-06, 4.953385086992057e-06, 4.819605237571523e-06, 4.689438810601132e-06, 4.562787580653094e-06, 4.4395569602784235e-06, 4.319654635764891e-06, 4.2029905671370216e-06, 4.089477442903444e-06, 3.9790297705621924e-06, 3.871565240842756e-06, 3.767003136090352e-06, 3.6652650123869535e-06, 3.5662744721776107e-06, 3.4699573916441295e-06, 3.3762416933313943e-06, 3.2850571187736932e-06, 3.1963352284947177e-06, 3.110009402007563e-06, 3.0260150651884032e-06, 2.9442892355291406e-06, 2.864770749511081e-06, 2.7873998078575823e-06, 2.712118430281407e-06, 2.6388702281110454e-06, 2.5676004042907152e-06, 2.498255298633012e-06, 2.4307830699399346e-06, 2.3651330138818594e-06, 2.3012560177448904e-06, 2.2391043330571847e-06, 2.178631120841601e-06, 2.119791133736726e-06, 2.062540488623199e-06, 2.006835984502686e-06, 1.9526357846189057e-06, 1.8998995301444666e-06, 1.8485875443730038e-06, 1.7986614011533675e-06, 1.7500835838291096e-06, 1.7028178262989968e-06, 1.6568285445828224e-06, 1.6120814052555943e-06, 1.568542757013347e-06, 1.5261799717336544e-06, 1.4849613307887921e-06, 1.4448559113589e-06, 1.4058335864319815e-06, 1.3678652521775803e-06, 1.3309222595125902e-06, 1.2949770962222829e-06, 1.2600027048392803e-06, 1.2259729373909067e-06, 1.1928622143386747e-06, 1.1606457519519608e-06, 1.1292993349343305e-06, 1.0987995437972131e-06, 1.0691234137993888e-06, 1.0402487760075019e-06, 1.0121540299223852e-06, 9.848180297922227e-07, 9.582203119862243e-07, 9.323409244643699e-07, 9.07160483620828e-07, 8.826601174405369e-07, 8.588214654992044e-07, 8.356266221198894e-07, 8.130582500598393e-07, 7.910994099802338e-07, 7.69733617289603e-07, 7.489448421438283e-07, 7.287175662895606e-07, 7.090365556905454e-07, 6.898870879012975e-07, 6.712547815368453e-07, 6.531257099595678e-07, 6.354862875923573e-07, 6.183232699186192e-07, 6.016237534822721e-07, 5.853752327311668e-07, 5.695656000170857e-07, 5.541829182220681e-07, 5.392157049755042e-07, 5.246527052804595e-07, 5.104830052005127e-07, 4.966960318597557e-07, 4.832813829125371e-07, 4.702290539171372e-07, 4.5752923938380263e-07, 4.451724180398742e-07, 4.331493244080775e-07, 4.2145094880652323e-07, 4.100685089269973e-07, 3.9899347825667064e-07, 3.8821755765638954e-07, 3.777326753606758e-07, 3.6753095855601714e-07, 3.5760479022428626e-07, 3.4794669545590295e-07, 3.385494551366719e-07, 3.294059922609449e-07, 3.205094856184587e-07, 3.1185325610749715e-07, 3.0343079515660065e-07, 2.952358215679851e-07, 2.8726216783070413e-07, 2.795038653857773e-07, 2.7195508778277144e-07, 2.646102075232193e-07, 2.574636823737819e-07, 2.5051016905308643e-07, 2.4374446638830705e-07, 2.3716148689345573e-07, 2.307562994019463e-07, 2.2452410064488504e-07, 2.1846021525107062e-07, 2.125600957469942e-07, 2.0681932255683932e-07, 2.0123360400248202e-07, 1.957987336709266e-07, 1.9051064725772449e-07, 1.8536537993441016e-07, 1.803590805593558e-07, 1.7548799746691657e-07, 1.7074846425657597e-07, 1.661369282146552e-07, 1.6164995031431317e-07, 1.5728414837212767e-07, 1.530362538915142e-07, 1.4890309785187128e-07], "accuracy_valid": [0.41917474585843373, 0.5146690276731928, 0.5738554805158133, 0.6011801110692772, 0.6158285485692772, 0.6295313088290663, 0.6202936746987951, 0.6476903708584337, 0.6648316900414157, 0.681006741810994, 0.6820641942771084, 0.7107933687876506, 0.7213634812688253, 0.7210678652108433, 0.7326042451054217, 0.7424007553652108, 0.7481689453125, 0.7346897355045181, 0.7577624952936747, 0.750732421875, 0.7674869399472892, 0.7577816147402108, 0.7653205595820783, 0.7670692535768072, 0.7721359069088856, 0.7703445618411144, 0.7740890319088856, 0.7847503294427711, 0.7868358198418675, 0.790417039250753, 0.7834678557981928, 0.7921157285391567, 0.7910876906061747, 0.7903861539909638, 0.7919421827936747, 0.795055711125753, 0.7935702772025602, 0.7980662885918675, 0.8000502988516567, 0.7968558805534638, 0.7973735763365963, 0.7969573606927711, 0.8009856810052711, 0.7976897825677711, 0.8033359022025602, 0.7991649214043675, 0.8005076948418675, 0.8046683805534638, 0.8064288403614458, 0.8061435193900602, 0.807628953313253, 0.806774461125753, 0.8084937405873494, 0.8060111539909638, 0.8078833890248494, 0.807628953313253, 0.8099174039909638, 0.811168992375753, 0.8105689358998494, 0.8090732068900602, 0.8105792309864458, 0.8085643354668675, 0.8084731504141567, 0.8091643919427711, 0.8094497129141567, 0.8094394178275602, 0.8100394743034638, 0.8084113798945783, 0.8120543698230422, 0.8112601774284638, 0.8132647778614458, 0.8123999905873494, 0.8107718961784638, 0.8130309323230422, 0.8147296216114458, 0.8141398602221386, 0.8132544827748494, 0.8114028379141567, 0.8152487881212349, 0.812023484563253, 0.8126544262989458, 0.8133765530873494, 0.8147810970444277, 0.8153811535203314, 0.8157267742846386, 0.8152487881212349, 0.8142516354480422, 0.8148516919239458, 0.8150855374623494, 0.8156149990587349, 0.8136309887989458, 0.8149943524096386, 0.8158385495105422, 0.8156047039721386, 0.8155032238328314, 0.8169680675828314, 0.8168459972703314, 0.8160929852221386, 0.8169680675828314, 0.8185549816453314, 0.8166930416980422, 0.8164283108998494, 0.8168151120105422, 0.8164386059864458, 0.8179343349962349, 0.8186873470444277, 0.8180461102221386, 0.8167033367846386, 0.8181784756212349, 0.8176696041980422, 0.8181578854480422, 0.8171607327748494, 0.8186358716114458, 0.8163371258471386, 0.8168048169239458, 0.8160826901355422, 0.8175578289721386, 0.8186461666980422, 0.8191653332078314, 0.8176490140248494, 0.8189108974962349, 0.8178019695971386, 0.8187888271837349, 0.8181681805346386, 0.8184226162462349, 0.8175475338855422, 0.8192874035203314, 0.8178019695971386, 0.8187785320971386, 0.8180358151355422, 0.8174254635730422, 0.8176798992846386, 0.8197550945971386, 0.8181784756212349, 0.8181578854480422, 0.8170592526355422, 0.8201213055346386, 0.816662156438253, 0.8181475903614458, 0.8183917309864458, 0.8171607327748494, 0.8190123776355422, 0.8197550945971386, 0.8187579419239458, 0.8196330242846386, 0.8193785885730422, 0.8193888836596386, 0.8187785320971386, 0.8192668133471386, 0.8191447430346386, 0.8197550945971386, 0.8188903073230422, 0.8179137448230422, 0.8174254635730422, 0.8177916745105422, 0.8184226162462349, 0.8197550945971386, 0.8192771084337349, 0.8196433193712349, 0.8185240963855422, 0.8195109539721386, 0.8186770519578314, 0.8200095303087349, 0.8193888836596386, 0.8193888836596386, 0.8203757412462349, 0.8203963314194277, 0.8202639660203314, 0.8186461666980422, 0.8196330242846386, 0.8186461666980422, 0.8207419521837349, 0.8215052593185241, 0.8197653896837349, 0.8191447430346386, 0.8195315441453314, 0.8213728939194277, 0.8191344479480422, 0.8204066265060241, 0.8205184017319277, 0.8208846126694277, 0.8214949642319277, 0.8208743175828314, 0.8200198253953314, 0.8212508236069277, 0.8198771649096386, 0.8205081066453314, 0.8206198818712349, 0.8196639095444277, 0.8194094738328314, 0.8202536709337349, 0.8203860363328314, 0.8210066829819277, 0.8202742611069277, 0.8207625423569277, 0.8202742611069277, 0.8198874599962349, 0.8198977550828314, 0.8201418957078314, 0.8207419521837349, 0.8198977550828314, 0.8209963878953314, 0.8195315441453314, 0.8189108974962349, 0.8200301204819277, 0.8217493999435241, 0.8204978115587349, 0.8207728374435241, 0.8192874035203314, 0.8208743175828314, 0.8214949642319277, 0.8208846126694277, 0.8200301204819277, 0.8198874599962349, 0.8191550381212349, 0.8213728939194277, 0.8211390483810241, 0.8216273296310241, 0.8206404720444277, 0.8206301769578314, 0.8198977550828314, 0.8213728939194277, 0.8208846126694277, 0.8202536709337349, 0.8203963314194277, 0.8207728374435241, 0.8201418957078314, 0.8195315441453314, 0.8216170345444277, 0.8201521907944277, 0.8216273296310241, 0.8210066829819277, 0.8197756847703314, 0.8192874035203314, 0.8207625423569277, 0.8201418957078314, 0.8216170345444277, 0.8201418957078314, 0.8200301204819277, 0.8206404720444277, 0.8213831890060241, 0.8200301204819277, 0.8202742611069277, 0.8192976986069277, 0.8206301769578314, 0.8194094738328314, 0.8203963314194277, 0.8202639660203314, 0.8201418957078314, 0.8205184017319277, 0.8203860363328314, 0.8196639095444277, 0.8198977550828314, 0.8192976986069277, 0.8206507671310241, 0.8202845561935241], "accuracy_test": 0.8167794585987261, "start": "2016-01-21 07:57:31.414000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0], "accuracy_train_last": 0.9375326241809707, "batch_size_eval": 1024, "accuracy_train_std": [0.016686298909574012, 0.01446651331450126, 0.015377044649092961, 0.013410440698660967, 0.012501742750667452, 0.013597794236655483, 0.013837869657489833, 0.013661928609992737, 0.013329231977070699, 0.012798799359062517, 0.012489956441047684, 0.01317656222459011, 0.013654568203898173, 0.014210849453216356, 0.014426198751747336, 0.012914785463337226, 0.014669669792671333, 0.01734567128007577, 0.01467426018563436, 0.016249469958749818, 0.01496066159084364, 0.014268730196966022, 0.014825265111239095, 0.015767553206364627, 0.016811827643283612, 0.015447647799310888, 0.016694337327069573, 0.014455423377707152, 0.015347673291395084, 0.014783476725956379, 0.014004722588926169, 0.015481237580309781, 0.015283394761486322, 0.015300281799008223, 0.01564445149441111, 0.014286500584255553, 0.015104838929240754, 0.015007052685814334, 0.01407705116453427, 0.013756720001422144, 0.015516557578016427, 0.014147083863584943, 0.014117849230162587, 0.014081458375574096, 0.013271607686757126, 0.01446609117220489, 0.013770089505796996, 0.012161177835956471, 0.013534086090673664, 0.011880295854085898, 0.013901792472176676, 0.013424885625479664, 0.013179506443890019, 0.012364574572455806, 0.01282996802063452, 0.013203622319947038, 0.012784365864679726, 0.01207571621183517, 0.012676310003039445, 0.01186584397769919, 0.012875921998315453, 0.012383326926910966, 0.011823857655221714, 0.012494875395618946, 0.012186695856283191, 0.011609295116598991, 0.011354037236637252, 0.012117949068385625, 0.012343575161251783, 0.012111495592751279, 0.012118493762147634, 0.01134337902534161, 0.01188288116913653, 0.011671216092731546, 0.012729905150838355, 0.010607572726398054, 0.011699036156461042, 0.011395973912819232, 0.01150580729368931, 0.010978122627082832, 0.010521489943554015, 0.010792025915730759, 0.010409047720619484, 0.010715105182038855, 0.010804141517773756, 0.010789072941560306, 0.010644389323730873, 0.00993335485471102, 0.010791944558814208, 0.010104455970616325, 0.010110202936300593, 0.009815712807387474, 0.00903901196872309, 0.009142325536808714, 0.010104409708482047, 0.009072425230276413, 0.009375058746940088, 0.009787026815914389, 0.009444682945637377, 0.009397280686873245, 0.00965426997704435, 0.00947149763317632, 0.009516749129508941, 0.009322427007270878, 0.009588077418191374, 0.009240588424102114, 0.009047165650375054, 0.009192767689956801, 0.009178988596927255, 0.00932772753080649, 0.009244373060923976, 0.009440337965903739, 0.009215260931888855, 0.009816275185573781, 0.009824980429132203, 0.009696192177276488, 0.009257230214105072, 0.009313419922238515, 0.009385157215560446, 0.009921316556539878, 0.009865086873443204, 0.009707936857094857, 0.00949092266520387, 0.009191843044535278, 0.009135407926997869, 0.008971475005457386, 0.009048190162657122, 0.009704637278874046, 0.009069370981036695, 0.009284043232690962, 0.009447322164749453, 0.009271006536733644, 0.009449985853353089, 0.009167797092975312, 0.009210321963061919, 0.009006739702840355, 0.009012615664078917, 0.008904255419958785, 0.008580895011817075, 0.008866825386772817, 0.008820603048852797, 0.009087996850031078, 0.008222026608880913, 0.009107520161201383, 0.008790246541362729, 0.008832993665453334, 0.008751548239268417, 0.0089122842696819, 0.008657965058573277, 0.00916923313450829, 0.009316482920795875, 0.009042697318845395, 0.009148641363399516, 0.009515066331448397, 0.009272324824558982, 0.008800357827716413, 0.008857483145961327, 0.008499828719929044, 0.009047975969754487, 0.008683620348651236, 0.009379108986249439, 0.008852974210588057, 0.008504753012556467, 0.009512096110748113, 0.008389381692863263, 0.009454190105788629, 0.00879217414649473, 0.009009647665595383, 0.009001767471589716, 0.009078378297275523, 0.009091507138335429, 0.009018296753928604, 0.008873322877015819, 0.009063467079094981, 0.008788711201447072, 0.008859955191530282, 0.008946511961374255, 0.009115033604521858, 0.00895342750963162, 0.009146834402947768, 0.008759234514718663, 0.008795269329647889, 0.008702890264030833, 0.008607213813683214, 0.008454967908412835, 0.009227990799777626, 0.009078465384008829, 0.008427750989770848, 0.0087899399328141, 0.008731749558784302, 0.008880837514777942, 0.009171170633934207, 0.008919125108280359, 0.008894191333223708, 0.009179047458406088, 0.00871335516337152, 0.009108462996997451, 0.0086371055405702, 0.00871507771178998, 0.00899862196588931, 0.008617341044230321, 0.008709754861885934, 0.008724838192122596, 0.00931121732828345, 0.008833888195703087, 0.008870522209252388, 0.008924883072934887, 0.009197741663244762, 0.008790353337641367, 0.00888896209808415, 0.008852192951519788, 0.00899883713135689, 0.008971978998368081, 0.008958373776177867, 0.00866639373428908, 0.009139710812480762, 0.008568552713696363, 0.008849186343151355, 0.008916702025220213, 0.009081483480367596, 0.008561669032662199, 0.00885992975103987, 0.008788846826915886, 0.00893784701999353, 0.008710995159360902, 0.008739239667498002, 0.009279151596753347, 0.008737519763081587, 0.00905342149799053, 0.008949660379589577, 0.009077219306259213, 0.00883590764654099, 0.008534118925389264, 0.009192555855041916, 0.00911934172867322, 0.008893306967302459, 0.00871956032349498, 0.00900388226500433, 0.008496593217327764, 0.008852934467435142, 0.008630455634595588, 0.00859136684138494, 0.008796992621535852, 0.008556273185875858, 0.008899624144685403, 0.009165483258462875, 0.009043563691947356, 0.009121639643633269, 0.008708352355357765, 0.008933864931710509, 0.009157241068289163, 0.00909647297474717, 0.008539491624320132, 0.009005393020108256, 0.008768553785762512, 0.008839027479284946], "accuracy_test_std": 0.048668945233289136, "error_valid": [0.5808252541415663, 0.4853309723268072, 0.42614451948418675, 0.39881988893072284, 0.38417145143072284, 0.37046869117093373, 0.37970632530120485, 0.35230962914156627, 0.33516830995858427, 0.31899325818900603, 0.3179358057228916, 0.28920663121234935, 0.2786365187311747, 0.2789321347891567, 0.26739575489457834, 0.2575992446347892, 0.2518310546875, 0.2653102644954819, 0.24223750470632532, 0.249267578125, 0.23251306005271077, 0.24221838525978923, 0.23467944041792166, 0.23293074642319278, 0.22786409309111444, 0.22965543815888556, 0.22591096809111444, 0.21524967055722888, 0.21316418015813254, 0.20958296074924698, 0.21653214420180722, 0.20788427146084332, 0.20891230939382532, 0.2096138460090362, 0.20805781720632532, 0.20494428887424698, 0.20642972279743976, 0.20193371140813254, 0.19994970114834332, 0.2031441194465362, 0.20262642366340367, 0.20304263930722888, 0.19901431899472888, 0.20231021743222888, 0.19666409779743976, 0.20083507859563254, 0.19949230515813254, 0.1953316194465362, 0.1935711596385542, 0.19385648060993976, 0.19237104668674698, 0.19322553887424698, 0.19150625941265065, 0.1939888460090362, 0.19211661097515065, 0.19237104668674698, 0.1900825960090362, 0.18883100762424698, 0.18943106410015065, 0.19092679310993976, 0.1894207690135542, 0.19143566453313254, 0.19152684958584332, 0.19083560805722888, 0.19055028708584332, 0.19056058217243976, 0.1899605256965362, 0.19158862010542166, 0.18794563017695776, 0.1887398225715362, 0.1867352221385542, 0.18760000941265065, 0.1892281038215362, 0.18696906767695776, 0.1852703783885542, 0.18586013977786142, 0.18674551722515065, 0.18859716208584332, 0.1847512118787651, 0.18797651543674698, 0.1873455737010542, 0.18662344691265065, 0.1852189029555723, 0.18461884647966864, 0.18427322571536142, 0.1847512118787651, 0.18574836455195776, 0.1851483080760542, 0.18491446253765065, 0.1843850009412651, 0.1863690112010542, 0.18500564759036142, 0.18416145048945776, 0.18439529602786142, 0.18449677616716864, 0.18303193241716864, 0.18315400272966864, 0.18390701477786142, 0.18303193241716864, 0.18144501835466864, 0.18330695830195776, 0.18357168910015065, 0.18318488798945776, 0.1835613940135542, 0.1820656650037651, 0.1813126529555723, 0.18195388977786142, 0.18329666321536142, 0.1818215243787651, 0.18233039580195776, 0.18184211455195776, 0.18283926722515065, 0.1813641283885542, 0.18366287415286142, 0.1831951830760542, 0.18391730986445776, 0.18244217102786142, 0.18135383330195776, 0.18083466679216864, 0.18235098597515065, 0.1810891025037651, 0.18219803040286142, 0.1812111728162651, 0.18183181946536142, 0.1815773837537651, 0.18245246611445776, 0.18071259647966864, 0.18219803040286142, 0.18122146790286142, 0.18196418486445776, 0.18257453642695776, 0.18232010071536142, 0.18024490540286142, 0.1818215243787651, 0.18184211455195776, 0.18294074736445776, 0.17987869446536142, 0.18333784356174698, 0.1818524096385542, 0.1816082690135542, 0.18283926722515065, 0.18098762236445776, 0.18024490540286142, 0.1812420580760542, 0.18036697571536142, 0.18062141142695776, 0.18061111634036142, 0.18122146790286142, 0.18073318665286142, 0.18085525696536142, 0.18024490540286142, 0.18110969267695776, 0.18208625517695776, 0.18257453642695776, 0.18220832548945776, 0.1815773837537651, 0.18024490540286142, 0.1807228915662651, 0.1803566806287651, 0.18147590361445776, 0.18048904602786142, 0.18132294804216864, 0.1799904696912651, 0.18061111634036142, 0.18061111634036142, 0.1796242587537651, 0.1796036685805723, 0.17973603397966864, 0.18135383330195776, 0.18036697571536142, 0.18135383330195776, 0.1792580478162651, 0.17849474068147586, 0.1802346103162651, 0.18085525696536142, 0.18046845585466864, 0.1786271060805723, 0.18086555205195776, 0.17959337349397586, 0.1794815982680723, 0.1791153873305723, 0.1785050357680723, 0.17912568241716864, 0.17998017460466864, 0.1787491763930723, 0.18012283509036142, 0.17949189335466864, 0.1793801181287651, 0.1803360904555723, 0.18059052616716864, 0.1797463290662651, 0.17961396366716864, 0.1789933170180723, 0.1797257388930723, 0.1792374576430723, 0.1797257388930723, 0.1801125400037651, 0.18010224491716864, 0.17985810429216864, 0.1792580478162651, 0.18010224491716864, 0.17900361210466864, 0.18046845585466864, 0.1810891025037651, 0.1799698795180723, 0.17825060005647586, 0.1795021884412651, 0.17922716255647586, 0.18071259647966864, 0.17912568241716864, 0.1785050357680723, 0.1791153873305723, 0.1799698795180723, 0.1801125400037651, 0.1808449618787651, 0.1786271060805723, 0.17886095161897586, 0.17837267036897586, 0.1793595279555723, 0.17936982304216864, 0.18010224491716864, 0.1786271060805723, 0.1791153873305723, 0.1797463290662651, 0.1796036685805723, 0.17922716255647586, 0.17985810429216864, 0.18046845585466864, 0.1783829654555723, 0.1798478092055723, 0.17837267036897586, 0.1789933170180723, 0.18022431522966864, 0.18071259647966864, 0.1792374576430723, 0.17985810429216864, 0.1783829654555723, 0.17985810429216864, 0.1799698795180723, 0.1793595279555723, 0.17861681099397586, 0.1799698795180723, 0.1797257388930723, 0.1807023013930723, 0.17936982304216864, 0.18059052616716864, 0.1796036685805723, 0.17973603397966864, 0.17985810429216864, 0.1794815982680723, 0.17961396366716864, 0.1803360904555723, 0.18010224491716864, 0.1807023013930723, 0.17934923286897586, 0.17971544380647586], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.732225471169198, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00016477837029257815, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "rmsprop", "nb_data_augmentation": 4, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 6.504115608715803e-05, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.02700773426386718}, "accuracy_valid_max": 0.8217493999435241, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import os\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-6, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128, 256],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8202845561935241, "loss_train": [2.8482766151428223, 2.504551887512207, 2.3313117027282715, 2.209315538406372, 2.1161227226257324, 2.0378365516662598, 1.9732941389083862, 1.9150811433792114, 1.8656678199768066, 1.8175219297409058, 1.7764335870742798, 1.7383476495742798, 1.7054401636123657, 1.6747753620147705, 1.6447924375534058, 1.6174051761627197, 1.5916305780410767, 1.568949580192566, 1.5468899011611938, 1.5292727947235107, 1.507189154624939, 1.489578127861023, 1.4735922813415527, 1.4571362733840942, 1.4433093070983887, 1.4302347898483276, 1.4142802953720093, 1.4027866125106812, 1.3902777433395386, 1.378642201423645, 1.3672407865524292, 1.3557265996932983, 1.343726634979248, 1.3360121250152588, 1.3251488208770752, 1.3173693418502808, 1.3085284233093262, 1.3004038333892822, 1.2911275625228882, 1.2850512266159058, 1.27495539188385, 1.2690341472625732, 1.2629504203796387, 1.2552810907363892, 1.2495930194854736, 1.2412306070327759, 1.2383768558502197, 1.2316381931304932, 1.2264511585235596, 1.221842646598816, 1.2149335145950317, 1.2117187976837158, 1.2050390243530273, 1.2006909847259521, 1.1954681873321533, 1.1924769878387451, 1.1891555786132812, 1.1848759651184082, 1.1797149181365967, 1.1761174201965332, 1.171703577041626, 1.168264627456665, 1.16441810131073, 1.161192536354065, 1.1582677364349365, 1.1552026271820068, 1.152563214302063, 1.1496516466140747, 1.146515965461731, 1.144460678100586, 1.1426767110824585, 1.1389046907424927, 1.1340988874435425, 1.1318795680999756, 1.1316365003585815, 1.126785397529602, 1.1251152753829956, 1.1228631734848022, 1.121242642402649, 1.1193069219589233, 1.1187571287155151, 1.1147633790969849, 1.114457368850708, 1.1114555597305298, 1.108637809753418, 1.1088162660598755, 1.1049935817718506, 1.104507565498352, 1.1024694442749023, 1.1023764610290527, 1.0997352600097656, 1.098982810974121, 1.0987807512283325, 1.0955997705459595, 1.0955449342727661, 1.0927401781082153, 1.0909855365753174, 1.0899845361709595, 1.0889215469360352, 1.0878946781158447, 1.087537407875061, 1.085816502571106, 1.0838346481323242, 1.0834871530532837, 1.0831583738327026, 1.081024169921875, 1.0817877054214478, 1.0791895389556885, 1.0791058540344238, 1.078782558441162, 1.0765429735183716, 1.076975703239441, 1.077465295791626, 1.0755903720855713, 1.0731281042099, 1.0738751888275146, 1.073839545249939, 1.0706487894058228, 1.0698974132537842, 1.070955753326416, 1.0704492330551147, 1.0677722692489624, 1.0684924125671387, 1.0676153898239136, 1.0679717063903809, 1.0680948495864868, 1.0645276308059692, 1.06609046459198, 1.0646092891693115, 1.0639281272888184, 1.062825083732605, 1.0642379522323608, 1.0638200044631958, 1.0622416734695435, 1.0622611045837402, 1.0608052015304565, 1.059877872467041, 1.0599215030670166, 1.0601871013641357, 1.0608681440353394, 1.0607237815856934, 1.0593411922454834, 1.0583926439285278, 1.0577529668807983, 1.0586318969726562, 1.059374213218689, 1.0590704679489136, 1.056270718574524, 1.056730031967163, 1.0577480792999268, 1.0542157888412476, 1.0550100803375244, 1.056172490119934, 1.0553295612335205, 1.0544077157974243, 1.055999994277954, 1.0538625717163086, 1.0546408891677856, 1.0545814037322998, 1.054059386253357, 1.054601788520813, 1.054390549659729, 1.0537992715835571, 1.0519757270812988, 1.0527071952819824, 1.0522520542144775, 1.0517884492874146, 1.0516074895858765, 1.0525095462799072, 1.0533363819122314, 1.0517281293869019, 1.0522710084915161, 1.0523250102996826, 1.0508652925491333, 1.0503225326538086, 1.0504575967788696, 1.0509936809539795, 1.0511274337768555, 1.049908995628357, 1.0510926246643066, 1.0507690906524658, 1.0490856170654297, 1.051304578781128, 1.048873782157898, 1.0496406555175781, 1.0484727621078491, 1.0492433309555054, 1.0490481853485107, 1.0500338077545166, 1.0502252578735352, 1.0498020648956299, 1.0492624044418335, 1.0494428873062134, 1.0473783016204834, 1.0486342906951904, 1.0477849245071411, 1.0482885837554932, 1.0492351055145264, 1.047182321548462, 1.0474375486373901, 1.0493522882461548, 1.0475879907608032, 1.0465760231018066, 1.0467361211776733, 1.0468474626541138, 1.047687292098999, 1.0467933416366577, 1.0478934049606323, 1.047526478767395, 1.0478906631469727, 1.0470134019851685, 1.0466103553771973, 1.0469260215759277, 1.0468896627426147, 1.0479129552841187, 1.0477125644683838, 1.0484153032302856, 1.0458511114120483, 1.0469591617584229, 1.046720027923584, 1.0459811687469482, 1.04563570022583, 1.0458847284317017, 1.0456465482711792, 1.045878529548645, 1.0450034141540527, 1.047169804573059, 1.0472581386566162, 1.0467708110809326, 1.0457416772842407, 1.0456434488296509, 1.0451799631118774, 1.0479706525802612, 1.0441818237304688, 1.0457693338394165, 1.0457652807235718, 1.0457987785339355, 1.047363519668579, 1.0456030368804932, 1.0457638502120972, 1.0461212396621704, 1.0460524559020996, 1.0461037158966064, 1.0466039180755615, 1.0462349653244019, 1.0456464290618896, 1.0471092462539673, 1.0466892719268799, 1.0445219278335571, 1.04570472240448, 1.0451006889343262, 1.0446995496749878, 1.0451496839523315, 1.0460163354873657, 1.0463428497314453, 1.0459283590316772], "accuracy_train_first": 0.42774915501568844, "model": "residualv4", "loss_std": [0.2037237286567688, 0.11517138034105301, 0.1153433620929718, 0.11587484925985336, 0.11635784804821014, 0.1142851784825325, 0.11320500075817108, 0.11479891091585159, 0.113772451877594, 0.11356326937675476, 0.11056084930896759, 0.11052664369344711, 0.11009976267814636, 0.11214125156402588, 0.11039308458566666, 0.10922311991453171, 0.10918550938367844, 0.10960293561220169, 0.10857345163822174, 0.10834678262472153, 0.10730256140232086, 0.10762135684490204, 0.10683461278676987, 0.10540231317281723, 0.10720185190439224, 0.10345035791397095, 0.10334593057632446, 0.10248734056949615, 0.10225249081850052, 0.10153429955244064, 0.10361208021640778, 0.10059310495853424, 0.10107146203517914, 0.10123090445995331, 0.10011015832424164, 0.09989121556282043, 0.09930514544248581, 0.09814930707216263, 0.09912782162427902, 0.09743168950080872, 0.09687162935733795, 0.09622424840927124, 0.09591176360845566, 0.09298823028802872, 0.09421828389167786, 0.0922057032585144, 0.09476513415575027, 0.09378372877836227, 0.09462123364210129, 0.09556473046541214, 0.09295432269573212, 0.09258940070867538, 0.09178291261196136, 0.09183553606271744, 0.0909741148352623, 0.0915127843618393, 0.09131187945604324, 0.09001030027866364, 0.09033437818288803, 0.09131795912981033, 0.08883822709321976, 0.0888127014040947, 0.08923044800758362, 0.0889514833688736, 0.08843077719211578, 0.08775090426206589, 0.08717858791351318, 0.08774731308221817, 0.08733319491147995, 0.08841798454523087, 0.08803773671388626, 0.08731655776500702, 0.08659091591835022, 0.0858132541179657, 0.08704886585474014, 0.08434709906578064, 0.08452140539884567, 0.08500602841377258, 0.08444838970899582, 0.0842071920633316, 0.08485366404056549, 0.08387002348899841, 0.08445768058300018, 0.08367298543453217, 0.08277402073144913, 0.08288342505693436, 0.08447661995887756, 0.08265036344528198, 0.08183504641056061, 0.08120753616094589, 0.08260287344455719, 0.08200792968273163, 0.08238954097032547, 0.07998105138540268, 0.0822691097855568, 0.08074648678302765, 0.0813535675406456, 0.08376599848270416, 0.08134494721889496, 0.081590436398983, 0.08040214329957962, 0.0811624825000763, 0.08174904435873032, 0.0799119770526886, 0.08042389899492264, 0.08084291964769363, 0.07967182248830795, 0.08003412187099457, 0.08120794594287872, 0.08005928993225098, 0.07982002198696136, 0.07924836128950119, 0.08115994930267334, 0.07981643825769424, 0.07896559685468674, 0.07873934507369995, 0.08015567809343338, 0.07971881330013275, 0.07903960347175598, 0.08033829927444458, 0.07902796566486359, 0.07809427380561829, 0.07913028448820114, 0.0812903642654419, 0.07763315737247467, 0.0777897760272026, 0.07624507695436478, 0.0786997377872467, 0.07858892530202866, 0.07917188853025436, 0.07828418165445328, 0.07915978133678436, 0.07927744090557098, 0.07826919108629227, 0.0780203565955162, 0.07844914495944977, 0.07806422561407089, 0.07749323546886444, 0.07785956561565399, 0.0785759910941124, 0.07903328537940979, 0.07816275954246521, 0.07808901369571686, 0.07650338858366013, 0.0775831788778305, 0.07804127037525177, 0.07903244346380234, 0.07774267345666885, 0.07702700048685074, 0.07891003042459488, 0.07666510343551636, 0.07688885182142258, 0.07673341780900955, 0.07740617543458939, 0.07810480892658234, 0.07660318166017532, 0.07782291620969772, 0.07709677517414093, 0.0791173204779625, 0.07913275063037872, 0.07778283953666687, 0.07679693400859833, 0.07557305693626404, 0.0776180550456047, 0.07632975280284882, 0.07781323790550232, 0.07810366898775101, 0.07719874382019043, 0.07846285402774811, 0.07693137228488922, 0.07566535472869873, 0.0764167457818985, 0.07779677212238312, 0.07557566463947296, 0.0773060992360115, 0.0765838697552681, 0.0766073688864708, 0.07683084160089493, 0.07730022817850113, 0.07595884799957275, 0.07961110025644302, 0.07543154060840607, 0.07698209583759308, 0.07628386467695236, 0.07621157914400101, 0.07585988193750381, 0.07709217071533203, 0.0763825997710228, 0.07796849310398102, 0.07667915523052216, 0.0769178494811058, 0.07607246935367584, 0.07591310143470764, 0.07616313546895981, 0.07734325528144836, 0.07694610208272934, 0.07622406631708145, 0.07587336748838425, 0.07608281075954437, 0.0765114575624466, 0.07656504213809967, 0.07615932077169418, 0.0771375373005867, 0.07728192955255508, 0.07605178654193878, 0.07711877673864365, 0.07657527178525925, 0.07753930985927582, 0.07649051398038864, 0.07684348523616791, 0.074599988758564, 0.07622459530830383, 0.07611287385225296, 0.07552207261323929, 0.07624746859073639, 0.07451047748327255, 0.07679344713687897, 0.07706514000892639, 0.07616909593343735, 0.07620327919721603, 0.07678931206464767, 0.07604951411485672, 0.07603625953197479, 0.07589603960514069, 0.07546727359294891, 0.07477188110351562, 0.07671187818050385, 0.07643388956785202, 0.0760461613535881, 0.07710211724042892, 0.07645000517368317, 0.0750114843249321, 0.07672899961471558, 0.07543501257896423, 0.07420254498720169, 0.07576974481344223, 0.07506916671991348, 0.07745672762393951, 0.07646790891885757, 0.07670693844556808, 0.07636366784572601, 0.07558254152536392, 0.07492312788963318, 0.07635856419801712, 0.07722936570644379, 0.07653136551380157, 0.07694671303033829, 0.0773506686091423, 0.07570574432611465, 0.07627657055854797, 0.07623729854822159, 0.07565947622060776, 0.07703320682048798, 0.07712256163358688, 0.07691345363855362, 0.07767978310585022]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:10 2016", "state": "available"}], "summary": "37546533207946204b1ccb7ade75a4c5"}