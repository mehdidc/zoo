{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 16, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.6508686542510986, 1.3175100088119507, 1.1552743911743164, 1.0355865955352783, 0.9475657343864441, 0.8815215229988098, 0.8282480239868164, 0.7877471446990967, 0.7544996738433838, 0.7280222177505493, 0.7041729092597961, 0.6854162812232971, 0.6677339673042297, 0.6505802869796753, 0.634466826915741, 0.6228192448616028, 0.6107398867607117, 0.6010645031929016, 0.5900495648384094, 0.5824825763702393, 0.5721782445907593, 0.5627989172935486, 0.5581401586532593, 0.5485725998878479, 0.542041540145874, 0.5347909927368164, 0.5294838547706604, 0.52667635679245, 0.5195373892784119, 0.5157223343849182, 0.5131233334541321, 0.507820188999176, 0.5032767653465271, 0.4970526695251465, 0.49732115864753723, 0.49147146940231323, 0.4888954162597656, 0.48330333828926086, 0.480999618768692, 0.4781726598739624, 0.4754997491836548, 0.4725859463214874, 0.4682854115962982, 0.46674519777297974, 0.46298709511756897, 0.46219950914382935, 0.4590955674648285, 0.4542020857334137, 0.4543115198612213, 0.4513815641403198, 0.4518952965736389, 0.4476630389690399, 0.4458095133304596, 0.4459032714366913, 0.4432277977466583, 0.43929463624954224, 0.4380257725715637, 0.4361836910247803, 0.4349450170993805, 0.43411555886268616, 0.4313991069793701, 0.42984697222709656, 0.43064427375793457, 0.4282871186733246, 0.4260750114917755, 0.4242281913757324, 0.4232986867427826, 0.4235406219959259, 0.4201308786869049, 0.42230889201164246, 0.41844508051872253, 0.41746586561203003, 0.4151802062988281, 0.4144866466522217, 0.41399142146110535, 0.41301196813583374, 0.4116787016391754, 0.41143685579299927, 0.4108004570007324, 0.41042739152908325, 0.40848308801651, 0.40865829586982727, 0.4064866900444031, 0.40508386492729187, 0.4057106375694275, 0.40702176094055176, 0.4036889970302582, 0.3461155593395233, 0.32478514313697815, 0.3192790150642395, 0.3178280293941498, 0.3155880868434906, 0.314005047082901, 0.31317880749702454, 0.3102978765964508, 0.309395968914032, 0.30735787749290466, 0.30652230978012085, 0.30491405725479126, 0.30371618270874023, 0.3030011057853699, 0.2983279228210449, 0.29572436213493347, 0.29487359523773193, 0.2955077886581421, 0.2928629517555237, 0.29487499594688416, 0.29297035932540894, 0.293181836605072, 0.2940894663333893, 0.29486462473869324, 0.2950349748134613, 0.29515475034713745, 0.2954981029033661, 0.29527369141578674, 0.2946920096874237, 0.29593026638031006, 0.294487863779068, 0.2956427037715912, 0.2963618040084839, 0.2942459285259247, 0.2946794331073761, 0.29574885964393616, 0.2967204451560974, 0.2944352924823761, 0.2941904664039612, 0.2947993874549866, 0.2948188781738281, 0.29570886492729187, 0.29520490765571594, 0.2963859438896179, 0.29623299837112427, 0.29393455386161804, 0.2952401638031006, 0.2953207492828369, 0.2954537570476532, 0.2974288761615753, 0.2955895662307739, 0.2949226200580597, 0.29524073004722595, 0.2946806252002716, 0.29567569494247437, 0.29460057616233826, 0.2943978011608124, 0.2948448359966278, 0.29553496837615967, 0.293742299079895, 0.29547354578971863, 0.29628145694732666, 0.29443782567977905, 0.2936798930168152, 0.29495829343795776, 0.2939895987510681, 0.2945324182510376, 0.295030802488327, 0.29490548372268677, 0.29608529806137085, 0.29608970880508423, 0.293599009513855, 0.2953029274940491, 0.2955365777015686, 0.2942321002483368, 0.2953537404537201, 0.294288694858551, 0.29418107867240906, 0.2950269877910614, 0.29522860050201416, 0.294697642326355, 0.2945432960987091, 0.2960357666015625, 0.2948817312717438, 0.2951740324497223, 0.2962407171726227, 0.2949903905391693, 0.2947365939617157, 0.2930845320224762, 0.29442140460014343, 0.29437318444252014, 0.2944657504558563, 0.2929936647415161, 0.2951852083206177, 0.29367727041244507, 0.29502755403518677, 0.295418381690979, 0.29319050908088684, 0.29546019434928894, 0.29537153244018555, 0.2955355942249298, 0.29483315348625183, 0.29490527510643005, 0.2946985363960266, 0.29511624574661255, 0.2948109805583954, 0.29434165358543396, 0.2957882285118103, 0.2948116660118103, 0.2956151068210602, 0.29592183232307434, 0.2951645255088806, 0.2951660752296448, 0.2954404950141907, 0.29462236166000366, 0.2943743169307709, 0.29498547315597534, 0.2941478192806244, 0.2955121099948883, 0.2955327332019806, 0.2959679365158081, 0.2948167324066162, 0.29437902569770813, 0.2952740788459778, 0.2954525947570801, 0.2954559922218323, 0.29515907168388367, 0.29577553272247314, 0.2935366630554199, 0.2945137321949005, 0.2951681613922119, 0.29413652420043945, 0.29644161462783813, 0.29460588097572327, 0.29512158036231995, 0.294756144285202], "moving_avg_accuracy_train": [0.0485973584867571, 0.10371656652304814, 0.15830334918760378, 0.21055082996997848, 0.26150219899056093, 0.3111664841268038, 0.356970931338662, 0.39784387240791497, 0.43771677625700905, 0.47349797431767765, 0.5065425040995957, 0.5372009425854464, 0.5649096865167319, 0.5910355268524619, 0.6140120703166251, 0.6358321028163856, 0.6558443728780472, 0.6742204642966378, 0.6906264130912265, 0.7058589416729768, 0.7201169525155997, 0.7335256910322661, 0.7459632543579799, 0.7578127533154082, 0.7685283114556282, 0.7782794508711579, 0.7865368600141547, 0.7947240934594908, 0.801739289087702, 0.8087528709935774, 0.8139771413589206, 0.8203224323102378, 0.8263447280580808, 0.8311370401013868, 0.8364544410308015, 0.8404220099745098, 0.844727388803563, 0.8485138380461302, 0.8523330855572703, 0.8560122237934868, 0.859084066025157, 0.8618789509681839, 0.8649545640847284, 0.8678342230324756, 0.8704119651925909, 0.8717854894247622, 0.8735240736206673, 0.8750400433696194, 0.8760859789032278, 0.8784684805595552, 0.8807963827573833, 0.882759069399742, 0.8836236540791385, 0.8850896998988455, 0.8862675233521133, 0.8875576820945598, 0.8885049473211042, 0.8890993584583182, 0.8902668771044575, 0.8909175740954698, 0.8917543535076282, 0.8933675076963634, 0.8941453056531944, 0.8947313915226756, 0.895795797936115, 0.8961446107689338, 0.8974049139327658, 0.8977391553456446, 0.8985212423719882, 0.8993416304779049, 0.9006586894850702, 0.9019671673319675, 0.9025174037526098, 0.9035307642275242, 0.9039686745907168, 0.9046624857722874, 0.9051896200738885, 0.9057473858142848, 0.9065843045556692, 0.907379312003849, 0.9084968892071648, 0.9083427838735654, 0.9084483378447822, 0.9085155067308005, 0.9093337409472092, 0.9100212154705207, 0.9107677896772063, 0.9140020204513184, 0.917059384620657, 0.9199459070528327, 0.9227065376584576, 0.9252352830309009, 0.927608774067281, 0.9297332902559756, 0.9317034114484013, 0.9335253486465844, 0.9351952830106542, 0.9367215114752312, 0.9381370058207406, 0.9394434667662135, 0.9406913972790532, 0.9419099018906181, 0.9430322047755688, 0.9440398440767587, 0.9449653566871246, 0.9458030043828917, 0.9465382861186058, 0.947246542656939, 0.9478444460116769, 0.9484243396118751, 0.9488951266270627, 0.9493607236681216, 0.9497122956407797, 0.9501403175590292, 0.9504975994509206, 0.9507703971262604, 0.9510228904804948, 0.951254748748106, 0.9514378445520514, 0.9516119674196591, 0.9517617386028963, 0.9518988578166192, 0.9520105672672847, 0.9521576087490742, 0.9522782842898183, 0.9523962289205449, 0.9525140048322464, 0.952603727111111, 0.9526659480692505, 0.9527706308613011, 0.9528231368908503, 0.952874970517426, 0.9529285962277727, 0.9529652336230372, 0.9529935569811562, 0.9530144337546629, 0.9530401982972475, 0.9530587721367735, 0.9531079685780426, 0.953140655679956, 0.9531677128740497, 0.9531641986118385, 0.9531749866687056, 0.953189346217505, 0.9532068840602248, 0.9532737853436634, 0.9532689644297289, 0.9532738901536072, 0.9532481684682114, 0.9532760280298896, 0.9533012097818564, 0.9533098503681319, 0.9533478898791223, 0.9533449230580613, 0.953332988372687, 0.9533175608094123, 0.953313012646522, 0.9533089192999208, 0.9533377513224942, 0.9533497852987719, 0.9533489540845554, 0.9533482059917606, 0.9533266424177783, 0.953349051830947, 0.9533553054587603, 0.9533422604356786, 0.9533607828982477, 0.9533542016264647, 0.9533483145306787, 0.9533592200885004, 0.9533574453953111, 0.9533883642059553, 0.9533836030033831, 0.9533887266627624, 0.953393301907385, 0.953378854485888, 0.9533449254672549, 0.9533236538969045, 0.9533068706812173, 0.953305716679956, 0.9533418083621357, 0.9533418469392203, 0.9533302919633677, 0.9533267958338913, 0.9533050120780677, 0.9532970684906928, 0.95332243529657, 0.9533639026611544, 0.9533825860499855, 0.9533622347677998, 0.9533346180185945, 0.953349254425253, 0.9533903650257786, 0.9533971376317278, 0.9533707169425676, 0.9533747680104001, 0.9533853533690593, 0.9533391487180614, 0.9533207799714398, 0.9533065732482899, 0.9532892089974736, 0.9532990496621874, 0.9533195320044773, 0.9532823427852034, 0.953297556417582, 0.9533391504724369, 0.953374223924178, 0.9533848997402781, 0.95338520737953, 0.9534157472381993, 0.9534362576645732, 0.9534268152625954, 0.9534159559031871, 0.953408507628529, 0.9534319950670419, 0.9534577840593226, 0.953471693557137, 0.9534633218147032, 0.9534743884369888, 0.9534890347434837, 0.9534881934288345, 0.9534944477408975, 0.9534907760265162], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.048219685382153606, 0.10212089078972136, 0.15571951330713477, 0.20740889245458394, 0.258161349641731, 0.30725976545880784, 0.35254697250667705, 0.3928608581814611, 0.431150455957065, 0.46621644504697596, 0.498122779646194, 0.5277895997143306, 0.554545772461271, 0.5796955462128849, 0.6022244502700602, 0.6226601848364277, 0.641859039517318, 0.6591237426815502, 0.6749987719337265, 0.689281150717387, 0.7025167981174104, 0.7150087882981392, 0.7264692470059758, 0.7372719410930288, 0.7469953952800362, 0.7552704298295929, 0.7625429444520553, 0.7699203447545907, 0.7761551139783033, 0.7823676393368736, 0.786573340576379, 0.7921398158184398, 0.7970000706353157, 0.8009927934757751, 0.8058151832264656, 0.8086476921063792, 0.8122519023290997, 0.8157683642516868, 0.8189464165219247, 0.8222237616449581, 0.8245864052470286, 0.8267432285306842, 0.8294066433470434, 0.8318271012356071, 0.8337268106338838, 0.8349859184447423, 0.8360916128860363, 0.8374825104264989, 0.8380689614734574, 0.8402092721220454, 0.8418730269975667, 0.8437295578350842, 0.8444034299883227, 0.845636591554626, 0.84637713750082, 0.8470568653923043, 0.8474509529494594, 0.8477781291624201, 0.8483787930439944, 0.8484586118758901, 0.8488976892707559, 0.8502582439035448, 0.8507950312884162, 0.8512069567646197, 0.8517231445595432, 0.8517666445331823, 0.8524201170339304, 0.8525189315259439, 0.8529293654158947, 0.8534870089288986, 0.8545849736045329, 0.8551153046043959, 0.8554572956518629, 0.8558312702941314, 0.8559826829861038, 0.8564150116848579, 0.8564989317324866, 0.8566344654229427, 0.8572111944265821, 0.8572550587471016, 0.8578684141769848, 0.8575852083955815, 0.8572163418764299, 0.8569495152000821, 0.8575893069500288, 0.8579474519798, 0.8583033150743652, 0.8601525592917028, 0.8619898365421259, 0.8637664858886663, 0.8650338214394834, 0.866384001983788, 0.867484153649114, 0.8686259220662056, 0.8695649758968591, 0.8705352831829262, 0.8712722233793173, 0.8721572551358886, 0.8729873162845738, 0.8737862879693694, 0.8742479853207759, 0.8749229491192706, 0.8755426235691659, 0.8761857797928216, 0.8767290288090214, 0.8771935388611012, 0.877611597907973, 0.8780244721439077, 0.8783828224163391, 0.8787175446927775, 0.8790187947415721, 0.8792390326431679, 0.8795247549906734, 0.879770727580838, 0.8799422452783264, 0.8800833746661564, 0.8801737700214534, 0.8803060129835399, 0.8805104808681679, 0.8805093374782638, 0.8806802363735097, 0.8807496256691406, 0.8807988394952988, 0.8809163741263413, 0.8809733271692793, 0.8810978270954237, 0.8811610489039536, 0.8812067710090402, 0.8812590984262085, 0.88131840013291, 0.8813839787001913, 0.881431821888154, 0.8814982653111609, 0.8815346798380268, 0.8815786304347965, 0.8815571508156391, 0.8815612037122378, 0.8815536737965862, 0.8815723404436595, 0.8815270757611159, 0.8815229586405765, 0.8815802883883411, 0.8815820275276697, 0.8815835927530653, 0.8815850014559214, 0.8816371564308112, 0.8816708593683024, 0.8815791216995444, 0.8815199423515027, 0.8814677104469246, 0.8814329087640544, 0.8814015872494714, 0.8814222260113466, 0.8814540374369437, 0.8815060522738216, 0.8815162445332617, 0.8814389388393482, 0.8814314283797356, 0.8814623195684941, 0.8814636485585574, 0.881502495252024, 0.8814875996424842, 0.8814752231025581, 0.8815495334353746, 0.8816418563060691, 0.8815896400372845, 0.8815792664891282, 0.8816187584207877, 0.8816044435256216, 0.8816281812137221, 0.8816027760253319, 0.8816032959096209, 0.8817024495641408, 0.881680795063299, 0.881674542552451, 0.8816312646902782, 0.881566871043163, 0.8816696671843287, 0.8817001190464682, 0.8816298694723936, 0.881553408315817, 0.8814723862436479, 0.8815225661998554, 0.8814934564642825, 0.881369601452267, 0.8813690247313626, 0.8814183633162083, 0.8814373244714098, 0.8815286612072508, 0.8814379068146884, 0.8814427065887918, 0.8814714404479849, 0.8814240587337586, 0.8813936222222051, 0.8814394715493068, 0.8813454290912888, 0.8813472696064822, 0.8813733401326563, 0.8814456317312129, 0.8814873096160736, 0.8815726183287885, 0.8816249821077319, 0.8816243108924406, 0.8815962042101996, 0.8816462094010018, 0.8815945873313835, 0.8816569612413174, 0.881652062604008, 0.8817219255265891, 0.8817481810631622, 0.8817463674749183, 0.8817803268305892, 0.8816776424156025, 0.8816218475358646, 0.8816692883941004, 0.8817486062602626, 0.8817955782773087, 0.88176461090515, 0.8817855683952073, 0.8817922231050088, 0.8817249701563302, 0.8817132706275195, 0.8817027410515899], "moving_var_accuracy_train": [0.021255329267013446, 0.0464729401912435, 0.06864309774712604, 0.08634698120535497, 0.10107666113046358, 0.11316786598026357, 0.12073350584169235, 0.1236955310623788, 0.12563461410837282, 0.12459379990944669, 0.12196188845507466, 0.11822515826308341, 0.11331261284902107, 0.10812438736335143, 0.10206324257306151, 0.09614194268037081, 0.0901321669895216, 0.08415807691298904, 0.07816466562434614, 0.07243646840485611, 0.06702243942306568, 0.06193834389823409, 0.05713674634174099, 0.05268676733744574, 0.04845149928000908, 0.04446211183111807, 0.04062956389979989, 0.03716988463321577, 0.03389581289721285, 0.030948944587845376, 0.028099687136712674, 0.025652082878353223, 0.02341328700518829, 0.021278654597153203, 0.01940526191123514, 0.017606410150019337, 0.016012595716772344, 0.014540370925893956, 0.013217613697266704, 0.012017676850990745, 0.01090083509815812, 0.009881054024945136, 0.008978083186834566, 0.008154906789049173, 0.0073992189019405795, 0.006676276131093778, 0.0060358525930406595, 0.005452950812254235, 0.004917501561292993, 0.004476838232445314, 0.004077926566984662, 0.0037048031599910373, 0.003341050404002557, 0.003026288976711626, 0.002736145491824075, 0.002477511528868067, 0.002237836178666042, 0.0020172324821998346, 0.0018277771320815996, 0.0016488100780404525, 0.0014902308682979174, 0.0013646281793978296, 0.0012336100884129007, 0.0011133405493892606, 0.0010122031435670718, 0.000912077862741417, 0.0008351653530501594, 0.0007526542736438925, 0.0006828937873304785, 0.0006206617383963973, 0.0005742073644119526, 0.0005321956564531438, 0.00048170093187524065, 0.0004427729337567845, 0.0004002215297568291, 0.00036453174238219806, 0.00033057940329129837, 0.0003003213865526071, 0.00027659314471447, 0.00025462216182697595, 0.0002404007548926173, 0.00021657441548794977, 0.0001950172487067114, 0.00017555612876928066, 0.0001640260809884702, 0.00015187706387144546, 0.00014170571489909316, 0.00022167738171111106, 0.00028363692451559096, 0.00033026133782711496, 0.00036582493611081533, 0.00038679342092761375, 0.00039881521613284703, 0.00039955581584379, 0.0003945326318750148, 0.0003849544650746239, 0.00037155714558987453, 0.00035536579096564943, 0.00033786183004860554, 0.0003194372088621611, 0.00030150946305983255, 0.00028472129814949537, 0.00026758524222466495, 0.0002499647506539205, 0.00023267743791604436, 0.00021572457708445472, 0.0001990178724538828, 0.00018363073112532034, 0.00016848505380725098, 0.00015466303771448253, 0.00014119149766605698, 0.00012902337334123705, 0.00011723346167474189, 0.00010715894036978521, 9.759189948526864e-05, 8.850247668177917e-05, 8.022600505899424e-05, 7.26872288594322e-05, 6.57202226342907e-05, 5.942106932807704e-05, 5.3680845061223574e-05, 4.8481975664049185e-05, 4.3746089109956174e-05, 3.9566070975262045e-05, 3.574052715294081e-05, 3.2291672860901734e-05, 2.9187346063205666e-05, 2.6341062242807185e-05, 2.374179904721271e-05, 2.146624552505499e-05, 1.9344432920800598e-05, 1.7434170152316478e-05, 1.571663458837656e-05, 1.4157051818124775e-05, 1.2748566549848508e-05, 1.1477632451912133e-05, 1.033584351161229e-05, 9.305364048083666e-06, 8.396610251777222e-06, 7.566565246282945e-06, 6.8164975474246875e-06, 6.134958943032219e-06, 5.522510488267707e-06, 4.972115209216449e-06, 4.477671871640181e-06, 4.070186720007729e-06, 3.6633772189074244e-06, 3.2972578618182144e-06, 2.9734865215327898e-06, 2.6831232659716804e-06, 2.4205180250635423e-06, 2.1791381601378347e-06, 1.9742473836915763e-06, 1.77690186356729e-06, 1.6004936076453959e-06, 1.4425863342581832e-06, 1.2985138729034537e-06, 1.1688132849906904e-06, 1.0594135262227022e-06, 9.547755228659056e-07, 8.593041888329773e-07, 7.733788067351459e-07, 7.002258155676274e-07, 6.347228701979315e-07, 5.716025539255942e-07, 5.159738521778401e-07, 4.674642015366677e-07, 4.2110759962754216e-07, 3.7930876073592936e-07, 3.424482653849712e-07, 3.082317846697184e-07, 2.8601236186763183e-07, 2.576151471302765e-07, 2.3208989938616477e-07, 2.090693052177595e-07, 1.9004092658721197e-07, 1.813974386771349e-07, 1.6733001215598847e-07, 1.5313209789959217e-07, 1.378308735798318e-07, 1.3577127192492147e-07, 1.221941581261525e-07, 1.1117639951613003e-07, 1.0016876585635223e-07, 9.442267743076161e-08, 8.554831491112513e-08, 8.278475698371329e-08, 8.998216221553964e-08, 8.412556715788897e-08, 7.944058262151552e-08, 7.836068788934327e-08, 7.245263869925347e-08, 8.04181081095479e-08, 7.2789111020691e-08, 7.179267525993093e-08, 6.476110808919539e-08, 5.9293445641759886e-08, 7.257792904206896e-08, 6.835683380988849e-08, 6.33376292728182e-08, 5.971752120328168e-08, 5.46173172210201e-08, 5.293132261005926e-08, 6.008553262084525e-08, 5.616007085009872e-08, 6.611465235858227e-08, 7.05745102760896e-08, 6.454281669311032e-08, 5.8089386800983686e-08, 6.067459482879691e-08, 5.8393233656257216e-08, 5.3356340886625074e-08, 4.9082037978789456e-08, 4.467312533933072e-08, 4.517075071647996e-08, 4.663932475050551e-08, 4.3716659440523434e-08, 3.997576813888572e-08, 3.7080422484322965e-08, 3.5303008881378516e-08, 3.177907828629154e-08, 2.8953218232097733e-08, 2.6179229787373415e-08], "duration": 188909.588734, "accuracy_train": [0.4859735848675711, 0.5997894388496677, 0.6495843931686046, 0.680778157011351, 0.7200645201758029, 0.7581450503529901, 0.7692109562453857, 0.7657003420311923, 0.7965729108988556, 0.7955287568636952, 0.8039432721368586, 0.8131268889581026, 0.8142883818983019, 0.8261680898740311, 0.8208009614940938, 0.8322123953142304, 0.8359548034330011, 0.8396052870639534, 0.8382799522425249, 0.8429516989087301, 0.8484390500992063, 0.8542043376822629, 0.8579013242894058, 0.8644582439322629, 0.864968334717608, 0.8660397056109265, 0.860853542301126, 0.8684091944675157, 0.8648760497416021, 0.8718751081464563, 0.8609955746470099, 0.877430050872093, 0.8805453897886674, 0.8742678484911407, 0.8843110493955334, 0.8761301304678849, 0.8834757982650425, 0.8825918812292359, 0.8867063131575305, 0.8891244679194352, 0.8867306461101883, 0.8870329154554264, 0.8926350821336286, 0.8937511535622, 0.8936116446336286, 0.8841472075143041, 0.8891713313838132, 0.8886837711101883, 0.8854993987057033, 0.8999109954665007, 0.9017475025378369, 0.9004232491809707, 0.8914049161937062, 0.8982841122762089, 0.8968679344315246, 0.899169110776578, 0.8970303343600037, 0.8944490586932448, 0.9007745449197121, 0.896773847014581, 0.8992853682170543, 0.9078858953949798, 0.9011454872646733, 0.9000061643480066, 0.905375455657069, 0.8992839262643041, 0.9087476424072536, 0.9007473280615541, 0.9055600256090809, 0.9067251234311554, 0.912512220549557, 0.9137434679540422, 0.9074695315383905, 0.9126510085017534, 0.9079098678594499, 0.9109067864064231, 0.9099338287882982, 0.9107672774778516, 0.9141165732281286, 0.9145343790374677, 0.9185550840370063, 0.9069558358711702, 0.9093983235857327, 0.9091200267049648, 0.9166978488948875, 0.9162084861803249, 0.9174869575373754, 0.9431100974183279, 0.9445756621447029, 0.9459246089424143, 0.9475522131090809, 0.9479939913828904, 0.9489701933947029, 0.9488539359542267, 0.9494345021802326, 0.9499227834302326, 0.9502246922872831, 0.9504575676564231, 0.9508764549303249, 0.9512016152754706, 0.9519227718946106, 0.9528764433947029, 0.9531329307401256, 0.9531085977874677, 0.9532949701804172, 0.9533418336447952, 0.9531558217400333, 0.953620851501938, 0.953225576204319, 0.9536433820136582, 0.9531322097637505, 0.9535510970376523, 0.9528764433947029, 0.9539925148232743, 0.9537131364779439, 0.953225576204319, 0.9532953306686047, 0.9533414731566077, 0.95308570678756, 0.9531790732281286, 0.9531096792520304, 0.9531329307401256, 0.9530159523232743, 0.9534809820851791, 0.9533643641565154, 0.9534577305970838, 0.95357398803756, 0.9534112276208934, 0.9532259366925065, 0.9537127759897563, 0.9532956911567922, 0.9533414731566077, 0.9534112276208934, 0.9532949701804172, 0.9532484672042267, 0.9532023247162238, 0.9532720791805095, 0.9532259366925065, 0.9535507365494648, 0.9534348395971761, 0.9534112276208934, 0.953132570251938, 0.9532720791805095, 0.9533185821567, 0.9533647246447029, 0.9538758968946106, 0.953225576204319, 0.9533182216685124, 0.9530166732996493, 0.9535267640849945, 0.953527845549557, 0.9533876156446106, 0.9536902454780363, 0.9533182216685124, 0.953225576204319, 0.9531787127399409, 0.9532720791805095, 0.9532720791805095, 0.9535972395256552, 0.9534580910852714, 0.9533414731566077, 0.9533414731566077, 0.953132570251938, 0.9535507365494648, 0.9534115881090809, 0.9532248552279439, 0.9535274850613695, 0.9532949701804172, 0.9532953306686047, 0.9534573701088963, 0.9533414731566077, 0.9536666335017534, 0.9533407521802326, 0.9534348395971761, 0.9534344791089886, 0.9532488276924143, 0.953039564299557, 0.9531322097637505, 0.9531558217400333, 0.9532953306686047, 0.9536666335017534, 0.9533421941329827, 0.9532262971806941, 0.9532953306686047, 0.9531089582756552, 0.953225576204319, 0.9535507365494648, 0.9537371089424143, 0.9535507365494648, 0.9531790732281286, 0.9530860672757475, 0.9534809820851791, 0.9537603604305095, 0.9534580910852714, 0.9531329307401256, 0.9534112276208934, 0.9534806215969915, 0.9529233068590809, 0.9531554612518457, 0.9531787127399409, 0.9531329307401256, 0.9533876156446106, 0.9535038730850868, 0.9529476398117387, 0.9534344791089886, 0.9537134969661315, 0.9536898849898486, 0.9534809820851791, 0.9533879761327981, 0.9536906059662238, 0.953620851501938, 0.9533418336447952, 0.9533182216685124, 0.9533414731566077, 0.9536433820136582, 0.9536898849898486, 0.9535968790374677, 0.9533879761327981, 0.95357398803756, 0.953620851501938, 0.9534806215969915, 0.9535507365494648, 0.9534577305970838], "end": "2016-02-02 03:02:36.780000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0], "moving_var_accuracy_valid": [0.020926242525184907, 0.04498167777216573, 0.06633882101682673, 0.08375106616498283, 0.09855826674328327, 0.11039832999067423, 0.11781687709137598, 0.12066207378603445, 0.12179070608778877, 0.1206782477966937, 0.11777255070503968, 0.11391637755113246, 0.10896777481659627, 0.10376359741275293, 0.09795520133363435, 0.09191825442567415, 0.08604379317262825, 0.08012204363350682, 0.07437798825397322, 0.0687760665220555, 0.06347510112872966, 0.05853203938393553, 0.05386091446968825, 0.04952510681856548, 0.04542350618865041, 0.04149744134095257, 0.03782370242726268, 0.03453116650155106, 0.03142790097685254, 0.028632470121145195, 0.02592841441527447, 0.02361444379333132, 0.021465598105962876, 0.019462514816493123, 0.0177255623210119, 0.01602521404790382, 0.014539605625079506, 0.013196934602648595, 0.011968141288475016, 0.010867996079126755, 0.00983143523432772, 0.008890158690987218, 0.008064986828244516, 0.007311215692932858, 0.006612574185820678, 0.005965584939552897, 0.00538002948737518, 0.004859437902350248, 0.004376589435589532, 0.0039801588590827105, 0.0036070556957468296, 0.003277370486928025, 0.0029537203713454157, 0.002672034521248342, 0.0024097667438093273, 0.0021729483394865496, 0.001957051250562235, 0.0017623095239749573, 0.0015893257454651123, 0.001430450510331928, 0.0012891405599268744, 0.0011768864841134163, 0.0010617911019710886, 0.0009571391351554896, 0.0008638232701965932, 0.0007774579734062933, 0.0007035554128487691, 0.0006332877502983794, 0.0005714750790707227, 0.0005171262677520085, 0.0004762633788372729, 0.00043116829967828664, 0.00038910409059938637, 0.0003514523948369866, 0.0003165134875829009, 0.0002865443117585084, 0.0002579532637522035, 0.00023232326180822117, 0.0002120844827201497, 0.0001908933511556665, 0.00017518985999040486, 0.00015839272362294665, 0.00014377801384121063, 0.00013004098073398694, 0.00012072088401028587, 0.0001098032063704057, 9.996263261202669e-05, 0.0001207437069290322, 0.00013904962549042918, 0.00015355300904644899, 0.000152652962727088, 0.00015379455397434926, 0.00014930810175739086, 0.00014611000764606287, 0.00013943540575324232, 0.00013396533124247236, 0.00012545652579573784, 0.00011996040410742097, 0.00011416537729168875, 0.00010849404134046649, 9.956311720508125e-05, 9.370699064807862e-05, 8.779225939794726e-05, 8.273588281039598e-05, 7.71183699717745e-05, 7.134845927094558e-05, 6.57865736438933e-05, 6.0742102491791376e-05, 5.582362650237795e-05, 5.124961487323691e-05, 4.694141771300159e-05, 4.268381854139535e-05, 3.915017202603226e-05, 3.577967745943953e-05, 3.246647459846136e-05, 2.9399084675598684e-05, 2.653271809037228e-05, 2.4036840090527977e-05, 2.2009420124073184e-05, 1.980848987773012e-05, 1.8090498781523555e-05, 1.632478277250465e-05, 1.4714102501420373e-05, 1.3367021756726794e-05, 1.205951242295336e-05, 1.0993063265147557e-05, 9.929729912296938e-06, 8.955571519109166e-06, 8.08465779448576e-06, 7.307842246796508e-06, 6.615762958496855e-06, 5.974787398357167e-06, 5.41704121466929e-06, 4.887271253104124e-06, 4.415929022401349e-06, 3.978488486513522e-06, 3.5807874715997307e-06, 3.223219021107225e-06, 2.9040331124131373e-06, 2.6320698245438354e-06, 2.369015398223268e-06, 2.161694158209751e-06, 1.9455519638392123e-06, 1.7510188168301447e-06, 1.5759347951407618e-06, 1.4428225882784737e-06, 1.3087633214104265e-06, 1.2536291880916803e-06, 1.1597860263943783e-06, 1.0683609704575281e-06, 9.724252875871433e-07, 8.840120943104798e-07, 7.99444511305082e-07, 7.286077613613545e-07, 6.80096874524142e-07, 6.13022126444181e-07, 6.055054466028226e-07, 5.45462564974864e-07, 4.995046983635195e-07, 4.4957012445846124e-07, 4.1819470235216726e-07, 3.7837214476899576e-07, 3.419135389569862e-07, 3.5742041513094463e-07, 3.983899856972624e-07, 3.8308983565962803e-07, 3.4574934660579817e-07, 3.252109259409772e-07, 2.9453407935943335e-07, 2.70151971950695e-07, 2.4894558712993824e-07, 2.2405346093401087e-07, 2.901311396823571e-07, 2.653382823744869e-07, 2.391562991641742e-07, 2.3209742943600162e-07, 2.462065625915356e-07, 3.166893260792687e-07, 2.93366236641161e-07, 3.084446368959238e-07, 3.302169493917719e-07, 3.5627644005968566e-07, 3.433110480985943e-07, 3.1660633363484395e-07, 4.230062762838182e-07, 3.8070864211845065e-07, 3.6454644149776603e-07, 3.3132752600715257e-07, 3.732763672331472e-07, 4.10075968434213e-07, 3.692757120737891e-07, 3.3977885284357473e-07, 3.2600620914633665e-07, 3.0174301935166356e-07, 2.904881645776713e-07, 3.4103520331055855e-07, 3.0696217044509705e-07, 2.823830044155177e-07, 3.011793809708535e-07, 2.866948576518755e-07, 3.2352356007238693e-07, 3.158488921722815e-07, 2.842680577247584e-07, 2.629511222316746e-07, 2.591606819731062e-07, 2.5722815642083807e-07, 2.665198825427727e-07, 2.40083864115902e-07, 2.6000292926850546e-07, 2.40206815148286e-07, 2.1621573555432435e-07, 2.0497330253708647e-07, 2.793727740136993e-07, 2.794531140571007e-07, 2.7176351792275583e-07, 3.012090811632653e-07, 2.9094550651528174e-07, 2.7048175910942564e-07, 2.4738653070399355e-07, 2.230464440964807e-07, 2.4144843164052754e-07, 2.1853549924601426e-07, 1.9767979704474016e-07], "accuracy_test": 0.8744977678571428, "start": "2016-01-30 22:34:07.191000", "learning_rate_per_epoch": [0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.0037203114479780197, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 0.00037203115061856806, 3.7203113606665283e-05, 3.720311269717058e-06, 3.720311383403896e-07, 3.720311525512443e-08, 3.720311614330285e-09, 3.720311558819134e-10, 3.720311558819134e-11, 3.720311385346786e-12, 3.720311276926569e-13, 3.720311344689205e-14, 3.7203114293924994e-15, 3.72031137645294e-16, 3.720311310278491e-17, 3.7203113929965525e-18, 3.720311496394129e-19, 3.7203113671471583e-20, 3.720311447926515e-21, 3.720311447926515e-22, 3.72031157414426e-23, 3.720311416372079e-24, 3.720311416372079e-25, 3.720311478001837e-26, 3.720311555039035e-27, 3.720311651335532e-28, 3.720311651335532e-29, 3.7203117265671705e-30, 3.7203117265671705e-31, 3.720311785341888e-32, 3.720311785341888e-33, 3.72031173942414e-34, 3.72031162462977e-35, 3.7203115528832884e-36, 3.7203115528832884e-37, 3.72031149683135e-38, 3.72031149683135e-39, 3.720307292935957e-40, 3.720307292935957e-41, 3.7204474227823893e-42, 3.7274539151040134e-43, 3.783505853677006e-44, 4.203895392974451e-45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], "accuracy_train_first": 0.4859735848675711, "accuracy_train_last": 0.9534577305970838, "batch_size_eval": 1024, "accuracy_train_std": [0.017182732806415878, 0.016296804659891882, 0.016487339309079762, 0.01966621978692813, 0.020126449337936166, 0.0196484334273376, 0.017955812914735393, 0.019807006316557595, 0.018516838215885737, 0.01881577407307581, 0.018966487991668488, 0.018548779041675834, 0.01819469013719021, 0.018513590622638694, 0.014616893911209846, 0.016592586201746456, 0.01677010324523216, 0.016983057360464508, 0.0177529749103492, 0.017858806243337487, 0.01789294124484495, 0.016130757544646022, 0.01829596794799833, 0.01651502859435299, 0.015850703207779957, 0.015021171817904447, 0.017629201110405463, 0.01722331141901856, 0.01607606882487402, 0.015658229179750245, 0.017142029760378482, 0.01612957709786344, 0.015459513839540412, 0.01664124507058125, 0.01603031718488744, 0.01730380177659353, 0.016342213501505155, 0.015697039988595386, 0.015310336142286165, 0.014978325702977212, 0.015400623964785268, 0.0152841931678873, 0.014641320017029407, 0.01549832005403557, 0.014911087572593677, 0.017866105452903847, 0.016056623714422236, 0.015734603704640235, 0.015267002489730582, 0.01586382286719821, 0.01471415535640045, 0.014582740896847631, 0.015840112353588922, 0.015870159223761438, 0.015012406456035394, 0.015366051650548293, 0.014746077148951736, 0.015849056505964715, 0.014514992123158701, 0.015103060153023476, 0.015912623526441513, 0.014350839649317756, 0.01531692607650147, 0.015137676171092731, 0.013933545981199726, 0.01584616434871282, 0.013616628885840627, 0.014616687041879118, 0.01530959478231447, 0.013904875252520965, 0.016081342054121473, 0.0157888045378978, 0.014579196474870347, 0.01509638932171852, 0.014915313923952036, 0.014675172185498115, 0.013821580146792502, 0.015596557223668355, 0.014393499189142794, 0.013869526955882783, 0.015032641845010795, 0.013982121322603538, 0.01379761181623241, 0.013144486788882578, 0.014015717289514694, 0.014621074198754008, 0.014440524264857087, 0.00998705016656047, 0.00942980521852581, 0.00910218695012801, 0.009369649195579522, 0.00887078084291797, 0.009173126737457071, 0.009068391048069646, 0.008721578312728889, 0.008956910184884249, 0.009053751279573344, 0.008843690015901367, 0.009084197406104466, 0.009521756092280327, 0.009091707525573364, 0.008842297762062063, 0.008644282082696663, 0.008517429463270573, 0.00872265477309122, 0.008733265697598986, 0.008410124249042703, 0.008711453702549079, 0.00841902429088553, 0.008622322664717137, 0.008391317227049293, 0.008416933294612582, 0.008394403436596656, 0.008667984129584654, 0.00843004404558642, 0.008437882521659251, 0.008775793014917975, 0.008677252644677818, 0.008644475333083834, 0.008510652489716638, 0.008272468296375545, 0.008591586085904648, 0.008919254314184548, 0.008463286530062451, 0.008435039605461494, 0.008322202033936304, 0.008488338798998253, 0.008597671922497408, 0.008508667416757383, 0.008748356310255185, 0.008524884683169323, 0.008497448157942442, 0.008426952383572337, 0.008570341221605026, 0.008555227407283676, 0.00850112962397234, 0.008560101963202024, 0.008455126253064972, 0.00850423459575722, 0.008696584167561298, 0.008676540460775864, 0.00868250663579341, 0.008380493447312773, 0.008395791030660252, 0.008792325487113718, 0.008699666209512857, 0.008194882480564783, 0.008694792946435024, 0.008528568034612796, 0.008591354279356634, 0.008502620284904255, 0.008768293665138876, 0.00893636183313544, 0.008772788397194852, 0.008381180533368579, 0.008431640864477435, 0.008358789740085837, 0.008536195174446343, 0.008657922279514165, 0.008380583461792887, 0.008524127862941728, 0.008473364599304416, 0.008537458815881102, 0.008565425062508706, 0.00826225279985505, 0.008741837306165786, 0.008562572294138471, 0.008641579794647775, 0.008679531077270285, 0.008498943759255665, 0.008465321520455513, 0.008988390435952044, 0.008655941376258747, 0.008409873091396122, 0.008648217512374408, 0.00848453724853598, 0.008164519060831847, 0.00864981340177448, 0.008862349387511764, 0.008384116516553988, 0.008666863896090829, 0.008613922751700545, 0.008404898942648934, 0.008386824358828518, 0.008703449564072513, 0.008539529134055996, 0.008538874391545536, 0.00858982821361436, 0.008591893686976835, 0.008422147869283796, 0.008475980423690486, 0.008460603159778297, 0.008525780682553961, 0.00878535017805416, 0.008369352858409744, 0.008741720707883026, 0.008496666502852088, 0.008728427139290812, 0.008492132756176685, 0.008407368797867243, 0.008463777198307017, 0.008547998393336859, 0.00862431429776327, 0.008182661829613913, 0.008523922348021294, 0.00869922073224057, 0.00850803880821017, 0.008468650719879085, 0.00871774206108753, 0.008595657569403685, 0.008441403509943287, 0.008304121064412008, 0.008383680340227248, 0.008637911641089993, 0.008750410744994169, 0.008524036763067507, 0.008462877843661159, 0.008774856923206606, 0.008219245851090228, 0.008468259788441953, 0.008655525716087352, 0.008477492284444372, 0.008441399259118009], "accuracy_test_std": 0.007021388882942162, "error_valid": [0.5178031461784638, 0.41276826054216864, 0.3618928840361446, 0.3273866952183735, 0.2850665356739458, 0.2508544921875, 0.2398681640625, 0.2443141707454819, 0.2242431640625, 0.21818965314382532, 0.21472020896084332, 0.20520901967243976, 0.2046486728162651, 0.1939564900225903, 0.19501541321536142, 0.1934182040662651, 0.18535126835466864, 0.18549392884036142, 0.18212596479668675, 0.18217744022966864, 0.17836237528237953, 0.17256330007530118, 0.17038662462349397, 0.16550381212349397, 0.16549351703689763, 0.17025425922439763, 0.1720044239457832, 0.1636830525225903, 0.1677319630082832, 0.16171963243599397, 0.1755753482680723, 0.15776190700301207, 0.15925763601280118, 0.1630727009600903, 0.1507833090173193, 0.16585972797439763, 0.15531020566641573, 0.15258347844503017, 0.15245111304593373, 0.14828013224774095, 0.15414980233433728, 0.15384536191641573, 0.14662262330572284, 0.1463887777673193, 0.1491758047816265, 0.15368211125753017, 0.1539571371423193, 0.14999941170933728, 0.15665297910391573, 0.14052793204066272, 0.14315317912274095, 0.13956166462725905, 0.14953172063253017, 0.1432649543486446, 0.14695794898343373, 0.14682558358433728, 0.1490022590361446, 0.14927728492093373, 0.14621523202183728, 0.15082301863704817, 0.14715061417545183, 0.1374967644013554, 0.14437388224774095, 0.14508571394954817, 0.1436311652861446, 0.14784185570406627, 0.14169863045933728, 0.14659173804593373, 0.14337672957454817, 0.14149419945406627, 0.13553334431475905, 0.14011171639683728, 0.14146478492093373, 0.14080295792545183, 0.1426546027861446, 0.1396940300263554, 0.1427457878388554, 0.14214573136295183, 0.13759824454066272, 0.14235016236822284, 0.13661138695406627, 0.14496364363704817, 0.14610345679593373, 0.14545192488704817, 0.13665256730045183, 0.13882924275225905, 0.13849391707454817, 0.12320424275225905, 0.12147466820406627, 0.12024366999246983, 0.12356015860316272, 0.12146437311746983, 0.12261448136295183, 0.12109816217996983, 0.12198353962725905, 0.12073195124246983, 0.12209531485316272, 0.11987745905496983, 0.11954213337725905, 0.11902296686746983, 0.12159673851656627, 0.11900237669427716, 0.11888030638177716, 0.11802581419427716, 0.11838173004518071, 0.11862587067018071, 0.11862587067018071, 0.11825965973268071, 0.11839202513177716, 0.11826995481927716, 0.11826995481927716, 0.11877882624246983, 0.11790374388177716, 0.11801551910768071, 0.11851409544427716, 0.11864646084337349, 0.11901267178087349, 0.11850380035768071, 0.11764930817018071, 0.11950095303087349, 0.11778167356927716, 0.11862587067018071, 0.11875823606927716, 0.11802581419427716, 0.11851409544427716, 0.11778167356927716, 0.11826995481927716, 0.11838173004518071, 0.11826995481927716, 0.11814788450677716, 0.11802581419427716, 0.11813758942018071, 0.11790374388177716, 0.11813758942018071, 0.11802581419427716, 0.11863616575677716, 0.11840232021837349, 0.11851409544427716, 0.11825965973268071, 0.11888030638177716, 0.11851409544427716, 0.11790374388177716, 0.11840232021837349, 0.11840232021837349, 0.11840232021837349, 0.11789344879518071, 0.11802581419427716, 0.11924651731927716, 0.11901267178087349, 0.11900237669427716, 0.11888030638177716, 0.11888030638177716, 0.11839202513177716, 0.11825965973268071, 0.11802581419427716, 0.11839202513177716, 0.11925681240587349, 0.11863616575677716, 0.11825965973268071, 0.11852439053087349, 0.11814788450677716, 0.11864646084337349, 0.11863616575677716, 0.11778167356927716, 0.11752723785768071, 0.11888030638177716, 0.11851409544427716, 0.11802581419427716, 0.11852439053087349, 0.11815817959337349, 0.11862587067018071, 0.11839202513177716, 0.11740516754518071, 0.11851409544427716, 0.11838173004518071, 0.11875823606927716, 0.11901267178087349, 0.11740516754518071, 0.11802581419427716, 0.11900237669427716, 0.11913474209337349, 0.11925681240587349, 0.11802581419427716, 0.11876853115587349, 0.11974509365587349, 0.11863616575677716, 0.11813758942018071, 0.11839202513177716, 0.11764930817018071, 0.11937888271837349, 0.11851409544427716, 0.11826995481927716, 0.11900237669427716, 0.11888030638177716, 0.11814788450677716, 0.11950095303087349, 0.11863616575677716, 0.11839202513177716, 0.11790374388177716, 0.11813758942018071, 0.11765960325677716, 0.11790374388177716, 0.11838173004518071, 0.11865675592996983, 0.11790374388177716, 0.11887001129518071, 0.11778167356927716, 0.11839202513177716, 0.11764930817018071, 0.11801551910768071, 0.11826995481927716, 0.11791403896837349, 0.11924651731927716, 0.11888030638177716, 0.11790374388177716, 0.11753753294427716, 0.11778167356927716, 0.11851409544427716, 0.11802581419427716, 0.11814788450677716, 0.11888030638177716, 0.11839202513177716, 0.11839202513177716], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.02875777065648997, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 16, "valid_ratio": 0.15, "learning_rate": 0.003720311341753083, "optimization": "rmsprop", "nb_data_augmentation": 4, "learning_rate_decay_method": "discrete", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 5.381996951755238e-07, "rotation_range": [0, 0], "momentum": 0.5860198090725532}, "accuracy_valid_max": 0.8825948324548193, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8816079748682228, "accuracy_valid_std": [0.009414636678168047, 0.018053755774666443, 0.011801219200520073, 0.015612524575487986, 0.012715503515863869, 0.009009252189992696, 0.015025561328881722, 0.012838343231451096, 0.015540370634855817, 0.008277243221074456, 0.011107170751996168, 0.009938631341082029, 0.009232561762997525, 0.011596763528875075, 0.01030017615359947, 0.00925245255982005, 0.007319361822016419, 0.006853528148023021, 0.01047370324043807, 0.011690679453906444, 0.01082756106459095, 0.007441235083223247, 0.007685228914435814, 0.006054751404536532, 0.009468926905955381, 0.006665568805510575, 0.008788706131965513, 0.00870331996973716, 0.011118988346410943, 0.010206757274879774, 0.009534081037733573, 0.006756773728039871, 0.007242541267736206, 0.008648285810192755, 0.009751903824651735, 0.008605465361188499, 0.008074189018731102, 0.01064360390157313, 0.007829961838125864, 0.010137739967264086, 0.010943621610502087, 0.00813965121268412, 0.005664086665814367, 0.008820914702818037, 0.008250683213612121, 0.010188422795726576, 0.008529868600291582, 0.009340749296563321, 0.005587794402281201, 0.01223581894054737, 0.007389784157595278, 0.01162539744183635, 0.006546097124490751, 0.008526718507238375, 0.011059655972539701, 0.006700059893534836, 0.01182334859441042, 0.009847727279895697, 0.01161627313483654, 0.011578635958785052, 0.012833115416927344, 0.009706627355799, 0.008370966708686258, 0.009129113832460688, 0.008772419853334629, 0.01453767399586053, 0.005275028053473715, 0.011139050968967076, 0.00933185961138612, 0.013351827094833544, 0.00995141736996326, 0.009212096322189318, 0.0068497042641910725, 0.012818949972970619, 0.009867639027795654, 0.012454437672463799, 0.010217353492911831, 0.009888918873497658, 0.010202225057379402, 0.008916361472827273, 0.010623078798891718, 0.00932299601935915, 0.0036166621839014614, 0.010110965413179384, 0.008777889959998704, 0.011006128962886315, 0.0058178449923439604, 0.007853636141836345, 0.010627201645494463, 0.011606310952737944, 0.011576205923670731, 0.012848892981239257, 0.010164235656209962, 0.012015397088728433, 0.010289470986021771, 0.012084164334759237, 0.01202381845127534, 0.012688980850167293, 0.01018727576198821, 0.011668236256178941, 0.012194732969572433, 0.013695236999120786, 0.013758597407308289, 0.013641752356074496, 0.01425200273491271, 0.014060884950454018, 0.014204281095311754, 0.014951341438094167, 0.013921679381375415, 0.014131353996132376, 0.01399573036673619, 0.012329019718737316, 0.013127821062810309, 0.01429047863378759, 0.013594186403787178, 0.014072767269321825, 0.013121119250745498, 0.013812059313531504, 0.014135152902172524, 0.014030175991601041, 0.013879698082415326, 0.014287959519317182, 0.013409064591929325, 0.01360675321404992, 0.013768452184720816, 0.013619598433359068, 0.013134513609054137, 0.014426585601489085, 0.013953077639104344, 0.014068332448323857, 0.014381926982372704, 0.014017508340549881, 0.013757449072170934, 0.0139749220814242, 0.01457950169329314, 0.014161793003295375, 0.01447973797534664, 0.014127415046115444, 0.014089310131898144, 0.014126252210609775, 0.01313027562039849, 0.013809341637021884, 0.01339341824512313, 0.013770826089605675, 0.013788128529585423, 0.013334967564796801, 0.014071898816419275, 0.013502674073405085, 0.013426466477883793, 0.013071733470545422, 0.013389750643463259, 0.013575426787223214, 0.01381854311599434, 0.014349203320914933, 0.014105743887365475, 0.013636177752121809, 0.013184671894248877, 0.013559759604472215, 0.013910494952792833, 0.013143594326288206, 0.013646811623986952, 0.01324360274252619, 0.013881230779647542, 0.013019962238276733, 0.013706212252014472, 0.013138101159577094, 0.013541469362897912, 0.013995448156012301, 0.01334163710173043, 0.01343995823342019, 0.013933133420138518, 0.013299828483164826, 0.01454003187721719, 0.013880551757450557, 0.01425200273491271, 0.013768739048064525, 0.013802970730357448, 0.013652053918177585, 0.013296581619329952, 0.013599151153361362, 0.012579054850525821, 0.013479739836856935, 0.013952794565681827, 0.013501617958270753, 0.013189409663610784, 0.013329223438536689, 0.013435642719184699, 0.014817636901367982, 0.013819589724048922, 0.013160404981768663, 0.013940539700634788, 0.013492671748415539, 0.013782006466879288, 0.013636757037835956, 0.014068332448323857, 0.01336884536314111, 0.013382776578462529, 0.01311933939265126, 0.013679241125203651, 0.01438683278410694, 0.01370724621259827, 0.013626853132211174, 0.01356635896723341, 0.01318920827252063, 0.014276236839537661, 0.014443997434654517, 0.014007936948227854, 0.013218913361910212, 0.013965463686743992, 0.013986947870607204, 0.013377322205216204, 0.012894374176834205, 0.014199792675945394, 0.013862179683066049, 0.01355668756201311, 0.012619806590199059, 0.012742325506480566, 0.014228312578602841, 0.013116047849008172, 0.012984317180624854, 0.01374125778297559, 0.013609926081730095, 0.01350440909484522], "accuracy_valid": [0.48219685382153615, 0.5872317394578314, 0.6381071159638554, 0.6726133047816265, 0.7149334643260542, 0.7491455078125, 0.7601318359375, 0.7556858292545181, 0.7757568359375, 0.7818103468561747, 0.7852797910391567, 0.7947909803275602, 0.7953513271837349, 0.8060435099774097, 0.8049845867846386, 0.8065817959337349, 0.8146487316453314, 0.8145060711596386, 0.8178740352033133, 0.8178225597703314, 0.8216376247176205, 0.8274366999246988, 0.829613375376506, 0.834496187876506, 0.8345064829631024, 0.8297457407756024, 0.8279955760542168, 0.8363169474774097, 0.8322680369917168, 0.838280367564006, 0.8244246517319277, 0.8422380929969879, 0.8407423639871988, 0.8369272990399097, 0.8492166909826807, 0.8341402720256024, 0.8446897943335843, 0.8474165215549698, 0.8475488869540663, 0.851719867752259, 0.8458501976656627, 0.8461546380835843, 0.8533773766942772, 0.8536112222326807, 0.8508241952183735, 0.8463178887424698, 0.8460428628576807, 0.8500005882906627, 0.8433470208960843, 0.8594720679593373, 0.856846820877259, 0.860438335372741, 0.8504682793674698, 0.8567350456513554, 0.8530420510165663, 0.8531744164156627, 0.8509977409638554, 0.8507227150790663, 0.8537847679781627, 0.8491769813629518, 0.8528493858245482, 0.8625032355986446, 0.855626117752259, 0.8549142860504518, 0.8563688347138554, 0.8521581442959337, 0.8583013695406627, 0.8534082619540663, 0.8566232704254518, 0.8585058005459337, 0.864466655685241, 0.8598882836031627, 0.8585352150790663, 0.8591970420745482, 0.8573453972138554, 0.8603059699736446, 0.8572542121611446, 0.8578542686370482, 0.8624017554593373, 0.8576498376317772, 0.8633886130459337, 0.8550363563629518, 0.8538965432040663, 0.8545480751129518, 0.8633474326995482, 0.861170757247741, 0.8615060829254518, 0.876795757247741, 0.8785253317959337, 0.8797563300075302, 0.8764398413968373, 0.8785356268825302, 0.8773855186370482, 0.8789018378200302, 0.878016460372741, 0.8792680487575302, 0.8779046851468373, 0.8801225409450302, 0.880457866622741, 0.8809770331325302, 0.8784032614834337, 0.8809976233057228, 0.8811196936182228, 0.8819741858057228, 0.8816182699548193, 0.8813741293298193, 0.8813741293298193, 0.8817403402673193, 0.8816079748682228, 0.8817300451807228, 0.8817300451807228, 0.8812211737575302, 0.8820962561182228, 0.8819844808923193, 0.8814859045557228, 0.8813535391566265, 0.8809873282191265, 0.8814961996423193, 0.8823506918298193, 0.8804990469691265, 0.8822183264307228, 0.8813741293298193, 0.8812417639307228, 0.8819741858057228, 0.8814859045557228, 0.8822183264307228, 0.8817300451807228, 0.8816182699548193, 0.8817300451807228, 0.8818521154932228, 0.8819741858057228, 0.8818624105798193, 0.8820962561182228, 0.8818624105798193, 0.8819741858057228, 0.8813638342432228, 0.8815976797816265, 0.8814859045557228, 0.8817403402673193, 0.8811196936182228, 0.8814859045557228, 0.8820962561182228, 0.8815976797816265, 0.8815976797816265, 0.8815976797816265, 0.8821065512048193, 0.8819741858057228, 0.8807534826807228, 0.8809873282191265, 0.8809976233057228, 0.8811196936182228, 0.8811196936182228, 0.8816079748682228, 0.8817403402673193, 0.8819741858057228, 0.8816079748682228, 0.8807431875941265, 0.8813638342432228, 0.8817403402673193, 0.8814756094691265, 0.8818521154932228, 0.8813535391566265, 0.8813638342432228, 0.8822183264307228, 0.8824727621423193, 0.8811196936182228, 0.8814859045557228, 0.8819741858057228, 0.8814756094691265, 0.8818418204066265, 0.8813741293298193, 0.8816079748682228, 0.8825948324548193, 0.8814859045557228, 0.8816182699548193, 0.8812417639307228, 0.8809873282191265, 0.8825948324548193, 0.8819741858057228, 0.8809976233057228, 0.8808652579066265, 0.8807431875941265, 0.8819741858057228, 0.8812314688441265, 0.8802549063441265, 0.8813638342432228, 0.8818624105798193, 0.8816079748682228, 0.8823506918298193, 0.8806211172816265, 0.8814859045557228, 0.8817300451807228, 0.8809976233057228, 0.8811196936182228, 0.8818521154932228, 0.8804990469691265, 0.8813638342432228, 0.8816079748682228, 0.8820962561182228, 0.8818624105798193, 0.8823403967432228, 0.8820962561182228, 0.8816182699548193, 0.8813432440700302, 0.8820962561182228, 0.8811299887048193, 0.8822183264307228, 0.8816079748682228, 0.8823506918298193, 0.8819844808923193, 0.8817300451807228, 0.8820859610316265, 0.8807534826807228, 0.8811196936182228, 0.8820962561182228, 0.8824624670557228, 0.8822183264307228, 0.8814859045557228, 0.8819741858057228, 0.8818521154932228, 0.8811196936182228, 0.8816079748682228, 0.8816079748682228], "seed": 950244667, "model": "residualv3", "loss_std": [0.2916172742843628, 0.2665212154388428, 0.2660491466522217, 0.2659960389137268, 0.2617190182209015, 0.26132410764694214, 0.2579818367958069, 0.2530948221683502, 0.251157283782959, 0.25128820538520813, 0.24719804525375366, 0.24432721734046936, 0.24308335781097412, 0.240791454911232, 0.23823970556259155, 0.23961679637432098, 0.2367604523897171, 0.2339843213558197, 0.23319801688194275, 0.23209533095359802, 0.2300473302602768, 0.22649668157100677, 0.22925616800785065, 0.22658061981201172, 0.22325144708156586, 0.2231084406375885, 0.22097620368003845, 0.22364558279514313, 0.2197054773569107, 0.2181074619293213, 0.2178766280412674, 0.2186657041311264, 0.21577242016792297, 0.21634475886821747, 0.2142481803894043, 0.21247370541095734, 0.2125099152326584, 0.21138200163841248, 0.20965231955051422, 0.20644959807395935, 0.20477786660194397, 0.20784662663936615, 0.2049035280942917, 0.20247922837734222, 0.2029387652873993, 0.20541246235370636, 0.20322956144809723, 0.20111939311027527, 0.20218583941459656, 0.19888164103031158, 0.20059651136398315, 0.19748260080814362, 0.19738827645778656, 0.1994050294160843, 0.19529913365840912, 0.19305066764354706, 0.19451870024204254, 0.19513443112373352, 0.194784477353096, 0.19495166838169098, 0.18953801691532135, 0.1940050572156906, 0.19290417432785034, 0.1920255571603775, 0.19157561659812927, 0.1917538344860077, 0.18922922015190125, 0.19082000851631165, 0.18815019726753235, 0.1891130805015564, 0.18664996325969696, 0.18708369135856628, 0.18463143706321716, 0.18609701097011566, 0.18428395688533783, 0.18419058620929718, 0.18306735157966614, 0.18505682051181793, 0.18481993675231934, 0.18338967859745026, 0.18313491344451904, 0.18155686557292938, 0.180703267455101, 0.18120253086090088, 0.17877572774887085, 0.18204879760742188, 0.1842515915632248, 0.16057872772216797, 0.14946800470352173, 0.147136390209198, 0.14639298617839813, 0.14630146324634552, 0.14602677524089813, 0.1462840735912323, 0.14390817284584045, 0.14434684813022614, 0.14331164956092834, 0.14506381750106812, 0.14363481104373932, 0.14429472386837006, 0.14098942279815674, 0.14017383754253387, 0.1387985199689865, 0.1394638568162918, 0.1385650336742401, 0.1376999318599701, 0.13890421390533447, 0.13758119940757751, 0.13766469061374664, 0.13763897120952606, 0.1426423043012619, 0.1385355144739151, 0.14083780348300934, 0.1404569149017334, 0.13860659301280975, 0.13973194360733032, 0.1394125521183014, 0.13748449087142944, 0.1381395161151886, 0.14145375788211823, 0.1394040882587433, 0.13900667428970337, 0.14059317111968994, 0.14075572788715363, 0.13684214651584625, 0.13705193996429443, 0.13875405490398407, 0.1366717368364334, 0.1394956409931183, 0.13964122533798218, 0.1393910050392151, 0.13886451721191406, 0.13870906829833984, 0.1399517059326172, 0.14059150218963623, 0.13895703852176666, 0.13984227180480957, 0.13965818285942078, 0.14013102650642395, 0.13842913508415222, 0.13771535456180573, 0.13887743651866913, 0.1391603648662567, 0.13932430744171143, 0.13958686590194702, 0.1394767165184021, 0.13847659528255463, 0.1396486461162567, 0.13875441253185272, 0.13910022377967834, 0.13824157416820526, 0.13939058780670166, 0.13950315117835999, 0.13816332817077637, 0.13926613330841064, 0.13807475566864014, 0.14036516845226288, 0.13960158824920654, 0.14021335542201996, 0.138565793633461, 0.13983482122421265, 0.13878469169139862, 0.13916456699371338, 0.13869591057300568, 0.13916735351085663, 0.13773998618125916, 0.1403205245733261, 0.13985107839107513, 0.13810068368911743, 0.13937164843082428, 0.14035503566265106, 0.14053677022457123, 0.13987106084823608, 0.1394975185394287, 0.1383429914712906, 0.13922610878944397, 0.13849425315856934, 0.13802701234817505, 0.1381552368402481, 0.13796980679035187, 0.1400487720966339, 0.13803546130657196, 0.13738824427127838, 0.1395845264196396, 0.13643406331539154, 0.1404852569103241, 0.14000175893306732, 0.1410720944404602, 0.13841994106769562, 0.13932348787784576, 0.13706892728805542, 0.1393832117319107, 0.13698887825012207, 0.13867107033729553, 0.13968923687934875, 0.1388566493988037, 0.13852103054523468, 0.1395087093114853, 0.14040952920913696, 0.13798780739307404, 0.1395523101091385, 0.13904346525669098, 0.13902150094509125, 0.1396900862455368, 0.1377616971731186, 0.14079701900482178, 0.13997399806976318, 0.13949356973171234, 0.13953925669193268, 0.1374530792236328, 0.13984239101409912, 0.13872012495994568, 0.14053626358509064, 0.1388438194990158, 0.1402464210987091, 0.1388416886329651, 0.13799552619457245, 0.13920460641384125, 0.13806505501270294, 0.1415201872587204, 0.1405487060546875, 0.13858908414840698, 0.13974221050739288]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:30 2016", "state": "available"}], "summary": "67ac6c1e77fe1669278d25c2bbbcf7fc"}