{"content": {"hp_model": {"f0": 64, "f1": 16, "f2": 16, "f3": 16, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.5421409606933594, 1.1716169118881226, 1.0072532892227173, 0.8951407074928284, 0.8075999617576599, 0.7435176372528076, 0.6909653544425964, 0.6447935104370117, 0.6014044880867004, 0.5644149780273438, 0.5313828587532043, 0.5002672076225281, 0.47212332487106323, 0.44678622484207153, 0.42210274934768677, 0.39861446619033813, 0.37654030323028564, 0.3563397526741028, 0.3378235995769501, 0.3200397789478302, 0.3025309145450592, 0.28595176339149475, 0.2697813808917999, 0.2542458474636078, 0.23983752727508545, 0.2265327125787735, 0.21440435945987701, 0.20270675420761108, 0.1923186182975769, 0.18206895887851715, 0.17292916774749756, 0.1641618311405182, 0.1559842973947525, 0.14839179813861847, 0.1411532610654831, 0.1347171515226364, 0.12880901992321014, 0.12321849912405014, 0.11816830933094025, 0.11340387165546417, 0.10902802646160126, 0.10494019091129303, 0.10115864872932434, 0.09760002791881561, 0.09435458481311798, 0.09133939445018768, 0.08853445947170258, 0.08597146719694138, 0.08359582722187042, 0.0813983827829361, 0.07934875041246414, 0.07743105292320251, 0.07564419507980347, 0.07400906831026077, 0.07246466726064682, 0.07102780044078827, 0.06968630850315094, 0.06840842217206955, 0.06723262369632721, 0.0661112442612648, 0.06507155299186707, 0.06408765912055969, 0.06315911561250687, 0.06229158863425255, 0.061460964381694794, 0.060684334486722946, 0.05993974953889847, 0.059240542352199554, 0.058593831956386566, 0.05797139182686806, 0.05740155279636383, 0.05686850845813751], "moving_avg_accuracy_train": [0.047189580016841995, 0.09307033016392117, 0.13987485165911082, 0.19156288891268108, 0.24127354238944546, 0.28722478539002655, 0.3314118178271682, 0.3738651171144957, 0.4129216215932916, 0.4496369402848299, 0.483619798835712, 0.514195323277999, 0.5423737456844183, 0.568807931770277, 0.5943329358200858, 0.617814574956562, 0.6407286815816606, 0.6621302302978025, 0.68214253906135, 0.7011254570532862, 0.7189003280030886, 0.735599762603112, 0.7511452565347535, 0.7652920941899253, 0.7784450639652849, 0.7906314730357183, 0.8019036914978811, 0.8124159174304574, 0.8223070372507192, 0.8315787077008503, 0.8401906032190636, 0.8481900640592558, 0.8555569534808958, 0.862463846668705, 0.8689381781044092, 0.8750370467096198, 0.8808561995852617, 0.8862539084900154, 0.8913606013780939, 0.8962170055952126, 0.9007574692048959, 0.9049903708286108, 0.9089603815089925, 0.9126961154891841, 0.9162116998439662, 0.9196035542977847, 0.9228073940276593, 0.9258233832666892, 0.9287190991401402, 0.9314508014619605, 0.9340720939682653, 0.936521938027511, 0.9388662345117662, 0.9411132851273578, 0.9432449126754379, 0.9452680091651385, 0.9471841271070595, 0.9490202403976455, 0.9507378465258396, 0.952374336795967, 0.9539332085450339, 0.9554384996668133, 0.9568444149502242, 0.958181854367208, 0.9594320528186839, 0.9606037344012027, 0.9617024617016693, 0.9627331329018419, 0.9636932890653307, 0.9646038965398422, 0.9654536702014265, 0.9662417179849475], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.046734398531626496, 0.09202433758471384, 0.1374414562547063, 0.18721005300498866, 0.23453585210961025, 0.2777994285138601, 0.31886375924116384, 0.35762417948609865, 0.3931861214772478, 0.42624373297410134, 0.4565622543020677, 0.48359360534964707, 0.5080072705112185, 0.5303803421705635, 0.5516819516846818, 0.5709378199574787, 0.5887238795938845, 0.6048167824853997, 0.6197927943724019, 0.6333566542894539, 0.6456098678138217, 0.6570233845151203, 0.6670361133640601, 0.6757891626545366, 0.6834054118164172, 0.6900881081159502, 0.6962399006552588, 0.7015456098555461, 0.7066300419516933, 0.7111063155709065, 0.7151003997517678, 0.7185587391534735, 0.7216712446150086, 0.7242852760270018, 0.726536130013157, 0.7286239632656064, 0.7306139059827205, 0.7325422202978521, 0.734114893740582, 0.7355689799501082, 0.7368888350612721, 0.7380014034565003, 0.7388938812396154, 0.7396960817357593, 0.7402705482986291, 0.7408496328701216, 0.7412721232258052, 0.7417133997021704, 0.7420484838659895, 0.7423500596134267, 0.7425960342149605, 0.7427543171827716, 0.7428225001576421, 0.7429093084061851, 0.7430240569236238, 0.7431283600979783, 0.7432731200972167, 0.7433413394316215, 0.7434149438638359, 0.7434069161566691, 0.743375277157719, 0.743420044246164, 0.7434725416570145, 0.7435808244830299, 0.7436040073302841, 0.7435750142591533, 0.7435865710975451, 0.7435847652208478, 0.7435709329005703, 0.7435584838123205, 0.7435472796328957, 0.7434385101127536], "moving_var_accuracy_train": [0.020041708159493406, 0.03698292645007242, 0.0530006028966082, 0.07174542136308559, 0.08681122084855955, 0.09713374936338968, 0.10499281894745982, 0.11071408063612842, 0.11337136745143542, 0.11416636234588287, 0.11314323818889792, 0.11024267862429615, 0.1063646221656979, 0.10201705569532434, 0.09767908261147669, 0.0928736607391502, 0.0883118012070727, 0.08360285767340994, 0.078847004424497, 0.0742054645614445, 0.06962843244083923, 0.06517542924039943, 0.060832847750567826, 0.05655076011628711, 0.05245268962986212, 0.0485439977611634, 0.04483316416657557, 0.04134440979643576, 0.038090477078481164, 0.03505510422705556, 0.03221707650409959, 0.02957129121729355, 0.02710260163332023, 0.024821688031558462, 0.02271677193625675, 0.020779860527003688, 0.019006637336014147, 0.017368190955196844, 0.015866076669955532, 0.014491730960240408, 0.013228100152334088, 0.012066547242505115, 0.011001741381475716, 0.010027168618664964, 0.009135685756998774, 0.008325659271021899, 0.007585474645052211, 0.006908792900356489, 0.006293380144098648, 0.005731201907864126, 0.005219922286710204, 0.0047519456812707824, 0.004326212647198524, 0.003939034510699945, 0.0035860255836635533, 0.003264259299956947, 0.0029708769416674167, 0.0027041310556434753, 0.002460269487383617, 0.0022383454422832496, 0.002036381628225278, 0.0018531365776545204, 0.001685612299946225, 0.0015331497676985214, 0.0013939017564413249, 0.0012668671203745169, 0.001151045223464182, 0.0010455012492235523, 0.0009492482230257658, 0.0008617862544769168, 0.0007821066665125257, 0.0007094851736432853], "duration": 9795.086378, "accuracy_train": [0.4718958001684201, 0.5059970814876339, 0.5611155451158176, 0.6567552241948136, 0.6886694236803249, 0.7007859723952565, 0.7290951097614433, 0.755944810700443, 0.7644301619024548, 0.7800748085086747, 0.7894655257936508, 0.7893750432585824, 0.7959795473421927, 0.8067156065430048, 0.8240579722683647, 0.8291493271848468, 0.846955641207549, 0.8547441687430787, 0.862253317933278, 0.8719717189807125, 0.8788741665513106, 0.8858946740033223, 0.8910547019195275, 0.892613633086471, 0.8968217919435216, 0.9003091546696198, 0.9033536576573459, 0.9070259508236435, 0.911327115633075, 0.9150237417520304, 0.9176976628829827, 0.9201852116209857, 0.9218589582756552, 0.9246258853589886, 0.9272071610257475, 0.9299268641565154, 0.9332285754660392, 0.9348332886327981, 0.9373208373708011, 0.9399246435492802, 0.9416216416920451, 0.9430864854420451, 0.944690477632429, 0.9463177213109081, 0.9478519590370063, 0.9501302443821521, 0.9516419515965301, 0.9529672864179586, 0.9547805420011997, 0.9560361223583426, 0.9576637265250092, 0.9585705345607235, 0.9599649028700628, 0.9613367406676817, 0.962429560608158, 0.9634758775724437, 0.9644291885843485, 0.9655452600129198, 0.9661963016795865, 0.9671027492271133, 0.9679630542866371, 0.9689861197628276, 0.9694976525009228, 0.9702188091200628, 0.9706838388819674, 0.9711488686438722, 0.9715910074058692, 0.972009173703396, 0.9723346945367294, 0.9727993638104466, 0.9731016331556847, 0.9733341480366371], "end": "2016-01-31 06:37:31.012000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0], "moving_var_accuracy_valid": [0.019656936055016044, 0.03615184966440574, 0.051101096712522776, 0.06828320604370046, 0.08161246678734944, 0.09029685349819175, 0.09644368147110502, 0.10032064492207009, 0.1016704458934998, 0.10133865240504196, 0.09947770178416693, 0.09610617706086746, 0.09185980277437265, 0.08717881151620308, 0.08254475747561056, 0.07762737789450326, 0.07271173536156096, 0.0677713955366865, 0.06301278437137453, 0.058367310596881765, 0.05388185071225735, 0.049666080912449, 0.04560176547222562, 0.041731131771936665, 0.03808008385640563, 0.03467400133925119, 0.03154720216834631, 0.02864583690257381, 0.026013916259979415, 0.023592857863608048, 0.02137714645324149, 0.019347072810673858, 0.01749955474183925, 0.015811097709661305, 0.014275585031698094, 0.012887257957738586, 0.011634171010121286, 0.010504219473990628, 0.009476057242408775, 0.008547480818510504, 0.007708410894289642, 0.006948710080767224, 0.006261007722030687, 0.0056406986805517395, 0.005079598918983265, 0.004574657077553404, 0.004118797852703875, 0.0037086705917908276, 0.003338814065183326, 0.003005751190047974, 0.0027057206025845743, 0.002435374023807209, 0.0021918784616890476, 0.001972758436568279, 0.001775601097911741, 0.0015981389004901907, 0.001438513609557587, 0.001294704133500108, 0.0011652824786620717, 0.0010487548107926056, 0.0009438883389496361, 0.0008495175418845431, 0.0007645905914994028, 0.0006882370588831516, 0.0006194181899944978, 0.0005574839363786104, 0.000501736744785372, 0.0004515630996575506, 0.0004064085116895539, 0.0003657690553387827, 0.0003291932796076337, 0.0002963804289234775], "accuracy_test": 0.5459761639030611, "start": "2016-01-31 03:54:15.926000", "learning_rate_per_epoch": [0.0019458209862932563, 0.001803457154892385, 0.0016715092351660132, 0.00154921505600214, 0.0014358684420585632, 0.0013308146735653281, 0.0012334471102803946, 0.0011432033497840166, 0.0010595620842650533, 0.0009820404229685664, 0.0009101905161514878, 0.0008435974013991654, 0.0007818765006959438, 0.0007246713503263891, 0.0006716515636071563, 0.0006225109100341797, 0.0005769655690528452, 0.000534752500243485, 0.0004956279299221933, 0.00045936586684547365, 0.00042575685074552894, 0.00039460681728087366, 0.0003657358465716243, 0.0003389771736692637, 0.0003141762863378972, 0.0002911899355240166, 0.0002698853495530784, 0.0002501394774299115, 0.00023183829034678638, 0.00021487609774339944, 0.00019915492157451808, 0.00018458397244103253, 0.0001710790820652619, 0.00015856226673349738, 0.00014696123253088444, 0.00013620896788779646, 0.00012624339433386922, 0.00011700693721650168, 0.00010844624921446666, 0.00010051189747173339, 9.315805073129013e-05, 8.634224650450051e-05, 8.002510730875656e-05, 7.417015876853839e-05, 6.874358223285526e-05, 6.371403287630528e-05, 5.905246507609263e-05, 5.473195415106602e-05, 5.0727550842566416e-05, 4.701612488133833e-05, 4.357624129625037e-05, 4.038803308503702e-05, 3.7433088436955586e-05, 3.469433795544319e-05, 3.2155963708646595e-05, 2.9803308279952034e-05, 2.7622781999525614e-05, 2.5601792003726587e-05, 2.3728664018562995e-05, 2.1992582333041355e-05, 2.038351885857992e-05, 1.889218037831597e-05, 1.750995397742372e-05, 1.622885793040041e-05, 1.504149167885771e-05, 1.3940997632744256e-05, 1.2921019333589356e-05, 1.1975666893704329e-05, 1.109948061639443e-05, 1.0287399163644295e-05, 9.534733180771582e-06, 8.837135283101816e-06], "accuracy_train_first": 0.4718958001684201, "accuracy_train_last": 0.9733341480366371, "batch_size_eval": 1024, "accuracy_train_std": [0.015905658935231128, 0.015004167974266533, 0.018349410217047474, 0.015595329365510368, 0.015107196093178413, 0.015654756520736033, 0.017672977976331012, 0.01849238067814977, 0.01893979857027056, 0.018894373198223673, 0.019796812113501077, 0.01820649602810102, 0.01753708353314183, 0.018245707397239432, 0.018445981088338774, 0.018571961160812084, 0.019195010582775056, 0.020348059173326473, 0.02114302833277364, 0.021109766220172854, 0.021683684346742605, 0.021575875592477037, 0.02173872103161964, 0.02093490259710161, 0.021015377147226736, 0.020977245773246875, 0.0217816666459595, 0.021497234930202475, 0.02060752794575676, 0.020002476297725315, 0.019370248053799576, 0.01896985358999318, 0.018873727482156443, 0.017673220774150452, 0.01740397547892706, 0.017114468925289818, 0.016171929144680602, 0.015774543247814726, 0.015307880254175602, 0.014998300594841566, 0.014596208126824628, 0.014654203519688514, 0.01454883738970702, 0.014583690783353816, 0.01408030958507983, 0.013295442649230316, 0.01312781500573441, 0.01287348663680965, 0.012414259110537534, 0.011913494881630867, 0.011508254118103805, 0.011121208997725937, 0.01102437815275453, 0.010363651606890675, 0.010034120985716967, 0.009448200764082247, 0.00921439458784697, 0.008691812987814872, 0.008543077933327039, 0.008323652135376326, 0.008070504340152712, 0.007952626354404031, 0.0076288746184756465, 0.007063707175535244, 0.00660919768788202, 0.00636998764707566, 0.006277602396395928, 0.006259648509383052, 0.006281169971908334, 0.006263215117802375, 0.006196086636764685, 0.00613068946084802], "accuracy_test_std": 0.019465267248375773, "error_valid": [0.5326560146837349, 0.5003662109375, 0.4538044757153614, 0.3648725762424698, 0.33953195594879515, 0.3328283838478916, 0.31155726421310237, 0.29353203830948793, 0.2867564006024097, 0.2762377635542168, 0.2705710537462349, 0.2731242352221386, 0.2722697430346386, 0.26826201289533136, 0.256603562688253, 0.25575936558734935, 0.2512015836784638, 0.2503470914909638, 0.24542309864457834, 0.24456860645707834, 0.24411121046686746, 0.24025496517319278, 0.2428493269954819, 0.24543339373117468, 0.24804834572665668, 0.24976762518825302, 0.2483939664909638, 0.25070300734186746, 0.2476100691829819, 0.24860722185617468, 0.2489528426204819, 0.2503162062311747, 0.2503162062311747, 0.25218844126506024, 0.2532061841114458, 0.25258553746234935, 0.251476609563253, 0.2501029508659638, 0.25173104527484935, 0.2513442441641567, 0.251232468938253, 0.2519854809864458, 0.25307381871234935, 0.2530841137989458, 0.25455925263554224, 0.2539386059864458, 0.25492546357304224, 0.25431511201054224, 0.2549357586596386, 0.2549357586596386, 0.2551901943712349, 0.2558211361069277, 0.25656385306852414, 0.2563094173569277, 0.2559432064194277, 0.25593291133283136, 0.2554240399096386, 0.2560446865587349, 0.2559226162462349, 0.25666533320783136, 0.25690947383283136, 0.25617705195783136, 0.25605498164533136, 0.25544463008283136, 0.2561873470444277, 0.25668592338102414, 0.2563094173569277, 0.2564314876694277, 0.2565535579819277, 0.2565535579819277, 0.2565535579819277, 0.25754041556852414], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.0731639078929538, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 128, "valid_ratio": 0.15, "learning_rate": 0.002099422877743344, "optimization": "adam", "nb_data_augmentation": 0, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.957532977283368e-07, "rotation_range": [0, 0], "momentum": 0.743812996315387}, "accuracy_valid_max": 0.7597450348268072, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.7424595844314759, "accuracy_valid_std": [0.011307251084181192, 0.008140360178090434, 0.012312944298565137, 0.014588897664043254, 0.01580594583926251, 0.01803150875708377, 0.016220757243720584, 0.02206574952773428, 0.01702843474740501, 0.020459980462831966, 0.01694083956032934, 0.01640891668565431, 0.018641341727944745, 0.020737967179944878, 0.017186937383478543, 0.01969027742705668, 0.016609467141984666, 0.01790169549737826, 0.016071605629320043, 0.01658003793116216, 0.01997680649431515, 0.015392180563147872, 0.017445042944801644, 0.01713932768699734, 0.0212582983925282, 0.022848398795061443, 0.019413943947325377, 0.01658869803841723, 0.016285898567837166, 0.01627109341806557, 0.015642652038555332, 0.016688596542303324, 0.017640085030653695, 0.01894542013255304, 0.022866540223687032, 0.02155223035661089, 0.02190046140794402, 0.019424834545738654, 0.022286276938346842, 0.02146420606684421, 0.022505946985198134, 0.024260716597139825, 0.022801522079414435, 0.02321176641718777, 0.02435782305387002, 0.023392510875280395, 0.023332625179994793, 0.023282275987026372, 0.024489472634730457, 0.02500013278588691, 0.025506054855488593, 0.026310616224567714, 0.027245212504877787, 0.026487434631735533, 0.026181062452050173, 0.025519336796302618, 0.02411066847066604, 0.024187797739970558, 0.02447016486921656, 0.024622074115916995, 0.024496353788785164, 0.02450706634210433, 0.024636904223792676, 0.025073065196212187, 0.025496304505870596, 0.02612717504961007, 0.025247764170162522, 0.025062835145155497, 0.024952489061766524, 0.024741388257272654, 0.02467867199362212, 0.025374974069228663], "accuracy_valid": [0.4673439853162651, 0.4996337890625, 0.5461955242846386, 0.6351274237575302, 0.6604680440512049, 0.6671716161521084, 0.6884427357868976, 0.7064679616905121, 0.7132435993975903, 0.7237622364457832, 0.7294289462537651, 0.7268757647778614, 0.7277302569653614, 0.7317379871046686, 0.743396437311747, 0.7442406344126506, 0.7487984163215362, 0.7496529085090362, 0.7545769013554217, 0.7554313935429217, 0.7558887895331325, 0.7597450348268072, 0.7571506730045181, 0.7545666062688253, 0.7519516542733433, 0.750232374811747, 0.7516060335090362, 0.7492969926581325, 0.7523899308170181, 0.7513927781438253, 0.7510471573795181, 0.7496837937688253, 0.7496837937688253, 0.7478115587349398, 0.7467938158885542, 0.7474144625376506, 0.748523390436747, 0.7498970491340362, 0.7482689547251506, 0.7486557558358433, 0.748767531061747, 0.7480145190135542, 0.7469261812876506, 0.7469158862010542, 0.7454407473644578, 0.7460613940135542, 0.7450745364269578, 0.7456848879894578, 0.7450642413403614, 0.7450642413403614, 0.7448098056287651, 0.7441788638930723, 0.7434361469314759, 0.7436905826430723, 0.7440567935805723, 0.7440670886671686, 0.7445759600903614, 0.7439553134412651, 0.7440773837537651, 0.7433346667921686, 0.7430905261671686, 0.7438229480421686, 0.7439450183546686, 0.7445553699171686, 0.7438126529555723, 0.7433140766189759, 0.7436905826430723, 0.7435685123305723, 0.7434464420180723, 0.7434464420180723, 0.7434464420180723, 0.7424595844314759], "seed": 992205251, "model": "residualv3", "loss_std": [0.28212618827819824, 0.12103783339262009, 0.11222857236862183, 0.10472104698419571, 0.0954781100153923, 0.09109807759523392, 0.09001923352479935, 0.08838652819395065, 0.08522796630859375, 0.08352714776992798, 0.08209228515625, 0.08071020245552063, 0.07954856753349304, 0.07840516418218613, 0.07604236155748367, 0.07435054332017899, 0.07184750586748123, 0.0695916935801506, 0.06794054806232452, 0.06626728177070618, 0.0644000694155693, 0.06273798644542694, 0.06076635792851448, 0.05846984311938286, 0.05652974545955658, 0.05458484962582588, 0.05286348983645439, 0.051130831241607666, 0.04972771182656288, 0.0481649748980999, 0.04680175706744194, 0.04529819265007973, 0.043914057314395905, 0.04252513870596886, 0.04114602133631706, 0.04003303125500679, 0.03886432573199272, 0.037630751729011536, 0.036473121494054794, 0.03540077432990074, 0.034453462809324265, 0.03348158299922943, 0.03266207128763199, 0.031936705112457275, 0.03122369572520256, 0.030532624572515488, 0.029965728521347046, 0.029458792880177498, 0.02893047407269478, 0.02838093414902687, 0.027895033359527588, 0.027396107092499733, 0.02694237418472767, 0.026496656239032745, 0.02610112726688385, 0.02572048082947731, 0.025375299155712128, 0.025042418390512466, 0.024731989949941635, 0.0244413111358881, 0.024157365784049034, 0.02390274405479431, 0.02365981787443161, 0.023427914828062057, 0.023206766694784164, 0.02300358936190605, 0.02280527539551258, 0.022615833207964897, 0.022437430918216705, 0.022273877635598183, 0.02211650274693966, 0.021968163549900055]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:25 2016", "state": "available"}], "summary": "02c0c57a5be6747ca55c1c538d5052db"}