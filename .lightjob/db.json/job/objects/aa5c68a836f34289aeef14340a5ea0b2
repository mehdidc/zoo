{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 64, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.4328171014785767, 0.9982923269271851, 0.7633289098739624, 0.6592234373092651, 0.590847909450531, 0.5422478318214417, 0.5048320889472961, 0.4740441143512726, 0.4470808207988739, 0.42544129490852356, 0.408725768327713, 0.39177432656288147, 0.3743509352207184, 0.3627317547798157, 0.34869372844696045, 0.33832865953445435, 0.32767319679260254, 0.31925955414772034, 0.30995485186576843, 0.2996708154678345, 0.29527246952056885, 0.28634628653526306, 0.2802201509475708, 0.2728811502456665, 0.2669355869293213, 0.2606804072856903, 0.25505331158638, 0.2518572211265564, 0.24478136003017426, 0.24032104015350342, 0.23638924956321716, 0.23099982738494873, 0.22903527319431305, 0.2249145209789276, 0.22048987448215485, 0.21842601895332336, 0.21493707597255707, 0.21041752398014069, 0.20731814205646515, 0.2052294909954071, 0.20125998556613922, 0.199153333902359, 0.19544710218906403, 0.19459035992622375, 0.19174228608608246, 0.18712806701660156, 0.18637795746326447, 0.184221088886261, 0.18133974075317383, 0.17981243133544922, 0.1774345338344574, 0.17711733281612396, 0.17366237938404083, 0.17179608345031738, 0.16909152269363403, 0.16722865402698517, 0.1658509075641632, 0.16313539445400238, 0.1643388271331787, 0.16025669872760773, 0.1593926101922989, 0.15826869010925293, 0.1564004272222519, 0.15441414713859558, 0.15385203063488007, 0.1532759666442871, 0.15072819590568542, 0.14985494315624237, 0.1487310826778412, 0.14744214713573456, 0.1449735313653946, 0.1442699283361435, 0.1433759480714798, 0.14160875976085663, 0.14021579921245575, 0.1392413228750229, 0.1382036805152893, 0.13850896060466766, 0.1384962499141693, 0.1363210827112198, 0.13298091292381287, 0.13279376924037933, 0.13274936378002167, 0.1319235861301422, 0.1293531358242035, 0.12823595106601715, 0.12721478939056396, 0.12816093862056732, 0.12706981599330902, 0.12505175173282623, 0.12618422508239746, 0.12532329559326172, 0.12449417263269424, 0.12240626662969589, 0.12138423323631287, 0.1209031343460083, 0.12051520496606827, 0.1199469193816185, 0.11789426952600479, 0.11767635494470596, 0.11806705594062805, 0.11705871671438217, 0.11604911834001541, 0.11428486555814743, 0.11541278660297394, 0.11286068707704544, 0.11213889718055725, 0.11203594505786896, 0.1116710975766182, 0.11132718622684479, 0.11030200868844986, 0.11023353040218353, 0.10806193202733994, 0.10941403359174728, 0.10800538212060928, 0.1070389449596405, 0.10754217952489853, 0.1074681356549263, 0.10441803932189941, 0.1054355576634407, 0.10535922646522522, 0.1046103984117508, 0.10301297158002853, 0.10338115692138672, 0.10150664299726486, 0.10297542810440063, 0.10166144371032715, 0.10050363838672638, 0.10092199593782425, 0.10061847418546677, 0.10019233077764511, 0.097673200070858, 0.09972350299358368, 0.09808167070150375, 0.09733555465936661, 0.09636498242616653, 0.09614484757184982, 0.0963757261633873, 0.09673336148262024, 0.09673871099948883, 0.09627624601125717, 0.09373484551906586, 0.09389174729585648, 0.09454531222581863, 0.092343270778656, 0.09422709792852402, 0.09415309876203537, 0.09219097346067429, 0.08993908017873764, 0.09209717065095901, 0.09053568542003632, 0.09018576145172119, 0.09103930741548538, 0.09124171733856201, 0.08770059794187546, 0.08886808156967163, 0.08805998414754868, 0.08707467466592789, 0.08809169381856918, 0.08660649508237839, 0.08665049821138382, 0.08683207631111145, 0.08632918447256088, 0.0854777991771698, 0.08544325828552246, 0.08553563058376312, 0.0856195017695427, 0.08557010442018509, 0.08470175415277481, 0.08393916487693787, 0.08380918204784393, 0.08174153417348862, 0.08354321122169495, 0.08197984844446182, 0.08258122950792313, 0.08176906406879425, 0.0820000171661377, 0.08115290105342865, 0.08078663051128387, 0.08194281160831451, 0.08103659749031067, 0.08113174140453339, 0.08026778697967529, 0.07912768423557281, 0.08080954849720001, 0.07839198410511017, 0.07912053912878036, 0.07823387533426285, 0.0800657793879509, 0.07757305353879929, 0.0773669183254242, 0.07811190187931061, 0.07669451832771301, 0.0790526494383812, 0.07529062777757645, 0.07580345869064331, 0.07734648883342743, 0.07592194527387619, 0.07522305101156235, 0.07587280124425888, 0.07479704916477203, 0.07529368251562119, 0.0749497041106224, 0.07434076070785522, 0.07337145507335663, 0.07384055852890015, 0.07328571379184723, 0.07241398841142654, 0.07386456429958344, 0.07330525666475296, 0.07251383364200592, 0.07291154563426971], "moving_avg_accuracy_train": [0.0575909439599483, 0.11623607434131594, 0.18363259512562286, 0.2474858945658568, 0.30709954382743276, 0.3625372540580154, 0.4136265360465476, 0.4608620736563631, 0.5042390849599775, 0.5437411718439631, 0.5801882683800356, 0.6136530342826652, 0.6442758448378796, 0.6721896888101639, 0.6978190308256961, 0.7212691242420651, 0.7426717552667789, 0.7623131584937924, 0.7804134903349816, 0.7967549783146802, 0.8117226620654381, 0.8255795521435011, 0.8382693172018532, 0.8498318677341135, 0.8604311866131569, 0.8700821446983343, 0.8790051361047467, 0.8872310687728804, 0.8948088303837337, 0.9017427481251684, 0.9080669794496025, 0.9138587690404026, 0.9191807337638079, 0.9240749895160262, 0.9286542779513745, 0.9328523674539022, 0.9365538099490066, 0.9401897747862857, 0.943473696786247, 0.9465385806778973, 0.9493922351839356, 0.9520047741643884, 0.9543630346932247, 0.9565389115429775, 0.9585577266744402, 0.9604861953379762, 0.9622590555649297, 0.9638894709525121, 0.9654661267953839, 0.9668827558563402, 0.9682321267731057, 0.969423345158918, 0.9706558769740063, 0.971813947683767, 0.9727911792535224, 0.9737426591329412, 0.974601424319684, 0.9754254302127432, 0.9762739563129159, 0.9770469664471283, 0.977758951609586, 0.9784625893712926, 0.9791306324425151, 0.9797016442720915, 0.9802923569270621, 0.9808193119700979, 0.9813028360552494, 0.9818263633866476, 0.9822394813623055, 0.9826949928975404, 0.9830165976244899, 0.9833571591037352, 0.9837613567338748, 0.984132110047429, 0.9844657880296277, 0.9847939639505022, 0.9851474870483461, 0.985433141801891, 0.9857203859169676, 0.9859742553229176, 0.986174872051377, 0.9864599867057816, 0.9867072892995077, 0.9869555103684033, 0.9871765841815999, 0.987426631789649, 0.9875680053285689, 0.9877603817290823, 0.9878892705645258, 0.988061146185491, 0.9881902936562739, 0.9883297418192548, 0.9885458178230528, 0.9887264434800702, 0.988835492099948, 0.988977813685219, 0.989115203707201, 0.9892411438269756, 0.9894219552990676, 0.9895520974917983, 0.9897343656807414, 0.9898310137841327, 0.9899341649723954, 0.9900758291668318, 0.9902197111299473, 0.9903165807157805, 0.9904083775918309, 0.9904980062755234, 0.9905646851491708, 0.990699136946177, 0.9908084817706161, 0.9908767012269062, 0.9909566999280436, 0.9909821957828767, 0.991109773748655, 0.9911432137095223, 0.9912314383945409, 0.9913410675455814, 0.991370015366051, 0.9914820628616071, 0.9915387277802268, 0.9916268925391181, 0.9917062408221202, 0.9917451021934889, 0.9918196049574826, 0.9919285461724671, 0.9919707536457057, 0.9920110655204301, 0.9920589719517297, 0.9921184358792035, 0.99218350706034, 0.9922560580650387, 0.9922655864466577, 0.9923252431662869, 0.9923533936258672, 0.9924182565692513, 0.9924603571766304, 0.9925075483185096, 0.99255467064382, 0.992618007075885, 0.9927122122456958, 0.9927039909461447, 0.9926943026765579, 0.9927298331589482, 0.9928128557204527, 0.9928922263234259, 0.9929240962875211, 0.9929737055944925, 0.9930253294171953, 0.993090392048104, 0.9931303472254457, 0.9931942086707675, 0.993230829729909, 0.9932498017414604, 0.9932947783375708, 0.993337546374061, 0.9933783988045305, 0.993419816289572, 0.9934919692582523, 0.9935150903003119, 0.9935103226012608, 0.9935408728554389, 0.9936381225484849, 0.9936605431055596, 0.9936876970533555, 0.9937167859039908, 0.9937522304159819, 0.9937422777982025, 0.9937472713350581, 0.9937657524599041, 0.9937986975627509, 0.9938073857672085, 0.9938408178369439, 0.9938499443116012, 0.9938627723875932, 0.9938534634143379, 0.9938799265217321, 0.9939061405648338, 0.9938530032929112, 0.9938330454850763, 0.9938825488223199, 0.993850335866306, 0.9939027244142269, 0.9939173220240224, 0.9938862459966386, 0.9939350074827075, 0.9939649779761311, 0.993998926866641, 0.9940086266264517, 0.9940475112471676, 0.9940871577034309, 0.9941251286140587, 0.9941081491598142, 0.9941208054855272, 0.9941461110227072, 0.9941526820621401, 0.9941352724118969, 0.9941614564052494, 0.9942059483385525, 0.9942250647392394, 0.9942051392165429, 0.9941825198996781, 0.994220291234738, 0.9942566105851014, 0.9942358195778094, 0.9942450094569609, 0.9942416546041496, 0.9942246843437623, 0.9942628895320329, 0.9943275011360002, 0.9943252337593419, 0.994346372510807], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.057354074501129504, 0.11563498623399845, 0.18065634265577932, 0.24121722618011102, 0.29770279601315414, 0.3497838965417333, 0.3974056339583431, 0.44115939944052085, 0.48092944288314043, 0.5168852914223866, 0.5496127955538678, 0.5791397619510412, 0.6059439062849281, 0.6300035125031973, 0.6523388399049861, 0.6726491836065056, 0.6909264339205539, 0.7076954010330165, 0.7228638021477118, 0.7364735945138894, 0.7488587440045186, 0.7599697869609945, 0.7702148957554824, 0.7793723994969523, 0.7874534024407057, 0.7950589834598129, 0.8017320784308496, 0.8079464129446924, 0.8136644728456297, 0.8186865974266541, 0.8233875560010067, 0.8276438622890837, 0.8316454363858531, 0.8352875922013341, 0.8387099577929477, 0.8417921458427191, 0.8442822648427846, 0.8466475012726628, 0.8486144341273242, 0.8504843889638387, 0.8522803001239307, 0.8538080824232847, 0.8550243950864532, 0.8564263112818742, 0.8576249416841838, 0.858594875273672, 0.8594281058844825, 0.8603255273178716, 0.860964367187741, 0.8614274007720543, 0.8621015081628458, 0.8626562881635793, 0.8633173700964684, 0.8639510239471379, 0.8646545602478306, 0.8650669868472946, 0.8652407992694927, 0.8653951714321519, 0.8660295941891627, 0.8662403937122645, 0.8668004422551947, 0.8670806413466933, 0.8672117797252016, 0.8675118802259495, 0.8677606451401015, 0.868119840415248, 0.8682478036628798, 0.8684595973270888, 0.8685993244825576, 0.8689468645022989, 0.8691599352527466, 0.8696233421416285, 0.869782001668053, 0.8699502388129947, 0.8699053102347826, 0.8699737082869821, 0.8702092534974405, 0.8704069781382838, 0.8706205219001332, 0.8708635984281169, 0.8708473451835733, 0.8708937524197341, 0.8709111048697789, 0.8710142303108883, 0.8707245072044982, 0.8708096713183858, 0.8710083893333846, 0.8711506144531336, 0.8711443397171575, 0.8712363487047792, 0.8713679849186385, 0.871535285636112, 0.8716614422193383, 0.8719733841702207, 0.8719671931553071, 0.8718924970890234, 0.872179274535618, 0.8722420617375531, 0.8723585758668853, 0.8724644680919437, 0.872386813639677, 0.8723036880927273, 0.8723662409702015, 0.8723940064627898, 0.8724719415657577, 0.8726142958372692, 0.87269255704797, 0.8727762286775104, 0.8726409250868677, 0.8726188671226087, 0.8726101924773659, 0.8723561856543282, 0.8724592283746634, 0.8727005102152844, 0.8727701499881837, 0.872820618752543, 0.8730522346351953, 0.8734173213185131, 0.8733410082849299, 0.8733476277595242, 0.8734237389481803, 0.8735054755578803, 0.8733826964979508, 0.8734939809238333, 0.8734364750095374, 0.8735200265390807, 0.8736186074695099, 0.8737205668468059, 0.873526421024324, 0.8736731906312288, 0.8737320410899433, 0.8738083910566267, 0.8740032943737803, 0.8742651860866283, 0.8744123508834625, 0.8743606642232036, 0.8742785546438802, 0.8741649464027602, 0.8741787393189601, 0.8740893786589014, 0.8742063255821678, 0.874139649866948, 0.873979926455931, 0.8739226541134253, 0.8740450959686491, 0.8742397133484409, 0.8743039762003438, 0.8744849125882161, 0.8746843764310511, 0.874817124781922, 0.8747992324279767, 0.8748451939743357, 0.8748600862862395, 0.8749854116655222, 0.8748886259583074, 0.8749277071689525, 0.8750117083835331, 0.8749764166867461, 0.8749934822846378, 0.8751054680640806, 0.8752947930103081, 0.8755485756633435, 0.8754962183323255, 0.8754989543680688, 0.8754515591665781, 0.8755564173688962, 0.8755897545947325, 0.8754335641032562, 0.8752797561210179, 0.8752308961903921, 0.8754076783239884, 0.875481333025475, 0.8756798405832438, 0.8756143567602357, 0.8758239760070283, 0.8758448234176206, 0.8758096104188555, 0.8759905857945152, 0.8759550626066299, 0.8758976481663736, 0.8760189326249621, 0.8759683677227821, 0.8760072790209106, 0.8758480161978858, 0.8759742638533231, 0.875989200984557, 0.8760901526387368, 0.8760833528774986, 0.8759510447452458, 0.8758472629834471, 0.8758281310939879, 0.875822089916065, 0.8756304588612055, 0.8754478428979012, 0.8755418952044967, 0.875353869558294, 0.8754684967214404, 0.875386496682203, 0.8754103528968893, 0.8755060951862667, 0.8754468083803658, 0.8753791842064859, 0.8754068601947228, 0.8754653011519071, 0.8753958277008731, 0.8753353606122617, 0.8753663894512614, 0.8756038939549305, 0.8757566128519827, 0.8757933150833507, 0.8757276613329222, 0.8757682882248559], "moving_var_accuracy_train": [0.029850451435781158, 0.05781866814923155, 0.09291742045877405, 0.12032087305753425, 0.14027287035632063, 0.15390564076117902, 0.16200610929199494, 0.1658862624823901, 0.16623172222085608, 0.16365228381248004, 0.15924257304442013, 0.1533973307522383, 0.14649740641371947, 0.13886030994012885, 0.13088604749545807, 0.12274660467704021, 0.11459459774235654, 0.10660720045465612, 0.09889507852404102, 0.09140896873615262, 0.08428435587430168, 0.0775840409105912, 0.07127490805465762, 0.0653506504224915, 0.05982669542653917, 0.05468229481154193, 0.049930643311137925, 0.04554657269437015, 0.04150871766421144, 0.037790558834995144, 0.03437146606810021, 0.0312362229012671, 0.028367510387794923, 0.02574634300332853, 0.02336043764616271, 0.021183009480787544, 0.019188014621609874, 0.01738819532213026, 0.015746433083233702, 0.01425633139433401, 0.012903988351259102, 0.011675017755452665, 0.010557568514404198, 0.009544421623551392, 0.008626659992011457, 0.007797464915286476, 0.007046005724216655, 0.0063653294408195765, 0.005751169089559373, 0.005194113721670548, 0.004691089566342604, 0.0042347516208926204, 0.003824948670880201, 0.0034545239537114316, 0.003117666392208629, 0.0028140475786362176, 0.0025392801195862486, 0.0022914629790337917, 0.0020687966500144814, 0.0018672948870213874, 0.001685127704163288, 0.0015210708886442543, 0.0013729803336849048, 0.001238616790902061, 0.001117895584778537, 0.0010086051608571107, 0.0009098488046396943, 0.000821330651976214, 0.0007407335849348975, 0.0006685276432699967, 0.0006026057453465636, 0.0005433890099022195, 0.0004905204904298917, 0.00044270556356250536, 0.00039943707616849316, 0.0003604626634670199, 0.0003255412043466998, 0.0002937214716560349, 0.0002650919071252471, 0.00023916276349021892, 0.00021560871078683697, 0.00019477945300355943, 0.00017585193485897602, 0.0001588212646644718, 0.00014337900087595614, 0.00012960381504497948, 0.00011682331183804223, 0.0001054740587695083, 9.507616387967546e-05, 8.583441855344778e-05, 7.740108832098926e-05, 6.983599160031921e-05, 6.327259199504326e-05, 5.723896344729549e-05, 5.1622091516041234e-05, 4.664218126714351e-05, 4.214784730369106e-05, 3.8075810797241396e-05, 3.456246481347806e-05, 3.125865124508915e-05, 2.8431781354885628e-05, 2.567267092239937e-05, 2.320116533891934e-05, 2.1061667500895107e-05, 1.9141818924595716e-05, 1.731209048207169e-05, 1.565672143193773e-05, 1.4163348997208023e-05, 1.2787028747205147e-05, 1.1671021443948262e-05, 1.0611525915238093e-05, 9.59225837166305e-06, 8.690630664149726e-06, 7.827417945257809e-06, 7.191161386901435e-06, 6.482109327056516e-06, 5.903950749770568e-06, 5.421722631614377e-06, 4.887092155242374e-06, 4.511374711061939e-06, 4.089135456975292e-06, 3.750179133671044e-06, 3.4318265704425027e-06, 3.1022357690601116e-06, 2.8419681487383795e-06, 2.6645850287652174e-06, 2.414159763063464e-06, 2.187369211951255e-06, 1.9892875261948633e-06, 1.8221824016108254e-06, 1.6780724889802342e-06, 1.5576380746273968e-06, 1.4026913776711636e-06, 1.2944525576762622e-06, 1.1721393372798464e-06, 1.0927902163719305e-06, 9.994633450098985e-07, 9.195600453557014e-07, 8.475886627040268e-07, 7.989333290741793e-07, 7.989115223386934e-07, 7.19628678001608e-07, 6.485105733097226e-07, 5.950212525887728e-07, 5.975538387989486e-07, 5.944956884659976e-07, 5.441873711222678e-07, 5.119183840536937e-07, 4.847117172824119e-07, 4.743388590210793e-07, 4.4127271888662374e-07, 4.338500047852661e-07, 4.025349220604897e-07, 3.6552086485518994e-07, 3.4717482614886693e-07, 3.2891928804105544e-07, 3.110476489143356e-07, 2.9538155662744285e-07, 3.12697858969126e-07, 2.862393163455066e-07, 2.5781996329913465e-07, 2.404378292423383e-07, 3.0151157149596806e-07, 2.7588454676224387e-07, 2.549321240141085e-07, 2.370543626942385e-07, 2.2465574729739976e-07, 2.030816639736322e-07, 1.8299791626922711e-07, 1.6777209242246024e-07, 1.6076330139449313e-07, 1.4536633532532733e-07, 1.4088903137393296e-07, 1.2754976109359072e-07, 1.1627582078713205e-07, 1.0542815155605409e-07, 1.0118800087705798e-07, 9.725378529104131e-08, 1.1294053376837422e-07, 1.0523130723369589e-07, 1.1676340009458708e-07, 1.1442613090146306e-07, 1.2768455739066197e-07, 1.1683391355726392e-07, 1.1384199750315318e-07, 1.2385694046565876e-07, 1.1955532070357882e-07, 1.179725331348457e-07, 1.0702204788481223e-07, 1.0992796665027006e-07, 1.1308174343338946e-07, 1.1474967957515564e-07, 1.0586942841562508e-07, 9.67241287990285e-08, 9.281504782685468e-08, 8.392215007722365e-08, 7.825779836380672e-08, 7.6602432098419e-08, 8.675797804995455e-08, 8.13711112220021e-08, 7.680723819237819e-08, 7.373121583196673e-08, 7.919815801861934e-08, 8.315019911413977e-08, 7.872557306065984e-08, 7.161310066396886e-08, 6.455308593403909e-08, 6.068968497914161e-08, 6.775744417828463e-08, 9.855363406544785e-08, 8.874453963110011e-08, 8.389170698956746e-08], "duration": 192873.553232, "accuracy_train": [0.5759094395994832, 0.644042247773625, 0.7902012821843853, 0.8221655895279623, 0.8436223871816169, 0.8614766461332595, 0.873430073943337, 0.8859819121447029, 0.8946321866925065, 0.8992599537998339, 0.908212137204688, 0.9148359274063308, 0.9198811398348099, 0.9234142845607235, 0.9284831089654854, 0.9323199649893872, 0.9352954344892026, 0.939085787536914, 0.9433164769056847, 0.9438283701319674, 0.9464318158222591, 0.9502915628460686, 0.952477202727021, 0.9538948225244556, 0.9558250565245479, 0.9569407674649317, 0.9593120587624585, 0.9612644627860835, 0.9630086848814139, 0.9641480077980805, 0.9649850613695091, 0.9659848753576044, 0.9670784162744556, 0.9681232912859912, 0.9698678738695091, 0.9706351729766519, 0.9698667924049464, 0.9729134583217978, 0.9730289947858989, 0.9741225357027501, 0.9750751257382798, 0.9755176249884644, 0.9755873794527501, 0.976121803190753, 0.9767270628576044, 0.9778424133098007, 0.9782147976075121, 0.978563209440753, 0.9796560293812293, 0.9796324174049464, 0.9803764650239941, 0.9801443106312293, 0.9817486633098007, 0.9822365840716132, 0.9815862633813216, 0.9823059780477114, 0.9823303110003692, 0.9828414832502769, 0.9839106912144703, 0.9840040576550388, 0.9841668180717055, 0.9847953292266519, 0.985143020083518, 0.9848407507382798, 0.9856087708217978, 0.9855619073574198, 0.9856545528216132, 0.9865381093692323, 0.9859575431432264, 0.9867945967146549, 0.9859110401670359, 0.9864222124169435, 0.9873991354051311, 0.9874688898694168, 0.9874688898694168, 0.9877475472383721, 0.9883291949289406, 0.9880040345837948, 0.9883055829526578, 0.9882590799764673, 0.9879804226075121, 0.9890260185954227, 0.9889330126430418, 0.9891894999884644, 0.9891662485003692, 0.9896770602620893, 0.9888403671788483, 0.9894917693337025, 0.989049270083518, 0.9896080267741787, 0.9893526208933187, 0.9895847752860835, 0.9904905018572352, 0.9903520743932264, 0.9898169296788483, 0.9902587079526578, 0.9903517139050388, 0.9903746049049464, 0.9910492585478959, 0.990723377226375, 0.9913747793812293, 0.9907008467146549, 0.9908625256667589, 0.9913508069167589, 0.9915146487979882, 0.9911884069882798, 0.9912345494762828, 0.991304664428756, 0.9911647950119971, 0.9919092031192323, 0.9917925851905685, 0.991490676333518, 0.9916766882382798, 0.991211658476375, 0.9922579754406607, 0.9914441733573275, 0.9920254605597084, 0.9923277299049464, 0.9916305457502769, 0.9924904903216132, 0.9920487120478036, 0.99242037536914, 0.99242037536914, 0.9920948545358066, 0.9924901298334257, 0.9929090171073275, 0.9923506209048542, 0.9923738723929494, 0.9924901298334257, 0.9926536112264673, 0.9927691476905685, 0.9929090171073275, 0.9923513418812293, 0.9928621536429494, 0.9926067477620893, 0.9930020230597084, 0.9928392626430418, 0.9929322685954227, 0.9929787715716132, 0.9931880349644703, 0.9935600587739941, 0.9926299992501846, 0.9926071082502769, 0.9930496075004615, 0.9935600587739941, 0.9936065617501846, 0.993210925964378, 0.9934201893572352, 0.9934899438215209, 0.9936759557262828, 0.9934899438215209, 0.9937689616786637, 0.9935604192621816, 0.9934205498454227, 0.9936995677025655, 0.9937224587024732, 0.993746070678756, 0.9937925736549464, 0.994141345976375, 0.9937231796788483, 0.9934674133098007, 0.9938158251430418, 0.9945133697858989, 0.9938623281192323, 0.993932082583518, 0.9939785855597084, 0.9940712310239018, 0.9936527042381875, 0.9937922131667589, 0.993932082583518, 0.9940952034883721, 0.9938855796073275, 0.9941417064645626, 0.993932082583518, 0.9939782250715209, 0.9937696826550388, 0.9941180944882798, 0.9941420669527501, 0.9933747678456073, 0.9936534252145626, 0.9943280788575121, 0.9935604192621816, 0.994374221345515, 0.9940487005121816, 0.9936065617501846, 0.9943738608573275, 0.9942347124169435, 0.9943044668812293, 0.9940959244647471, 0.9943974728336102, 0.9944439758098007, 0.9944668668097084, 0.9939553340716132, 0.9942347124169435, 0.9943738608573275, 0.9942118214170359, 0.9939785855597084, 0.9943971123454227, 0.9946063757382798, 0.9943971123454227, 0.9940258095122739, 0.9939789460478959, 0.9945602332502769, 0.9945834847383721, 0.9940487005121816, 0.9943277183693245, 0.9942114609288483, 0.9940719520002769, 0.9946067362264673, 0.9949090055717055, 0.9943048273694168, 0.9945366212739941], "end": "2016-02-05 17:13:02.420000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0], "moving_var_accuracy_valid": [0.02960540875693003, 0.0572148499329672, 0.08954335605802485, 0.11359760597145141, 0.13095342176857858, 0.14227004888213243, 0.148453512865108, 0.15083768952342186, 0.14998882776993033, 0.14662535239053223, 0.14160262289156408, 0.13528893630398597, 0.12822620205483393, 0.12061336371175416, 0.11304182899188457, 0.10545023664416077, 0.09791173389112608, 0.09065134482418317, 0.08365693387315147, 0.07695827852009052, 0.07064297801922854, 0.06468977769753155, 0.05916546021567644, 0.0540036530670841, 0.04919101123756828, 0.04479251387755528, 0.04071403425823204, 0.03699019241345827, 0.03358543905338882, 0.030453890765815905, 0.02760739279289433, 0.025009698802566215, 0.022652842279577014, 0.020506945742477488, 0.018561664444413685, 0.016790996948539704, 0.015167703487396116, 0.013701282228979511, 0.012365973429774281, 0.01116084666661229, 0.010073789672005548, 0.009087417773592966, 0.008191990744684926, 0.007390479991387286, 0.006664362425820624, 0.006006393123750719, 0.005412002270632772, 0.00487805033063145, 0.004393918344982319, 0.0039564561113859045, 0.0035649002872161924, 0.003211180286137498, 0.002893995521421679, 0.002608209624101725, 0.0023518433316290855, 0.0021181898597656852, 0.0019066427706121106, 0.0017161929704323361, 0.0015481961035006201, 0.0013937764211010178, 0.0012572216683248599, 0.0011322061052702636, 0.0010191402702120977, 0.0009180367859858302, 0.0008267900632298648, 0.0007452722481180662, 0.00067089239464096, 0.0006042068641826557, 0.0005439618908661688, 0.0004906527583674476, 0.00044199607483297044, 0.00039972918085164283, 0.0003599828183744058, 0.00032423927016940837, 0.00029183351034672904, 0.00026269226395395827, 0.00023692237147409156, 0.00021358198962905192, 0.0001926341991101696, 0.000173902554985262, 0.00015651467699835954, 0.00014088259198263628, 0.00012679704275207561, 0.00011421305218630424, 0.00010354720227306045, 9.325775838240262e-05, 8.42873821895278e-05, 7.604069583276329e-05, 6.843698060029106e-05, 6.16694734244903e-05, 5.56584789172345e-05, 5.034453679611536e-05, 4.545332246792547e-05, 4.1783760247616017e-05, 3.760572918084537e-05, 3.38953717836252e-05, 3.1246006340140766e-05, 2.8156885800668336e-05, 2.5463377101607516e-05, 2.301795786139725e-05, 2.0770434000869022e-05, 1.8755579309783188e-05, 1.691523714112765e-05, 1.5230651730222912e-05, 1.3762251479672332e-05, 1.2568408979263439e-05, 1.1366691435240282e-05, 1.029303076602569e-05, 9.428491244190166e-06, 8.490021103856437e-06, 7.641696238701588e-06, 7.458201810179242e-06, 6.807941849088128e-06, 6.6511000037004825e-06, 6.029637285055598e-06, 5.449597422133672e-06, 5.38745093379165e-06, 6.048300417436524e-06, 5.495883487544964e-06, 4.946689495785616e-06, 4.50415676355472e-06, 4.113868947486568e-06, 3.83815433075269e-06, 3.565796908673686e-06, 3.2389795894174727e-06, 2.9779093532768636e-06, 2.7675822165479065e-06, 2.5843854264603942e-06, 2.665180287298529e-06, 2.5925341161679944e-06, 2.3644510929693225e-06, 2.1804698403853797e-06, 2.30430858368414e-06, 2.691163148641236e-06, 2.616964130622247e-06, 2.3793113151984915e-06, 2.2020580308285935e-06, 2.0980137197990413e-06, 1.889924548654811e-06, 1.7728000418843948e-06, 1.718609283449447e-06, 1.5867592141051493e-06, 1.65768740493705e-06, 1.5214397553882135e-06, 1.5042238510450716e-06, 1.6946847865934973e-06, 1.562383735146385e-06, 1.7007871497380293e-06, 1.8887808561508287e-06, 1.8585018924659744e-06, 1.6755329301866843e-06, 1.5269918108613716e-06, 1.37628865835979e-06, 1.38001784875493e-06, 1.3263233219691926e-06, 1.2074370590017008e-06, 1.1501991895607573e-06, 1.0463888053636581e-06, 9.443710365098909e-07, 9.628012660357019e-07, 1.1891165568084617e-06, 1.6498556159630778e-06, 1.5095416653688053e-06, 1.3586548718562253e-06, 1.2430061307896177e-06, 1.2176627010510936e-06, 1.1058987665841171e-06, 1.2148681165740929e-06, 1.3062933635185638e-06, 1.1971496625536083e-06, 1.3587020011280963e-06, 1.271656936475146e-06, 1.4991384972495242e-06, 1.3878178272063853e-06, 1.6444981021192207e-06, 1.4839598226629547e-06, 1.3467234379349234e-06, 1.5068198734977302e-06, 1.3674949580457308e-06, 1.260413223790726e-06, 1.2667611804677054e-06, 1.1630963464131319e-06, 1.0604135138701642e-06, 1.1826539836635632e-06, 1.2078348198280068e-06, 1.0890593988507122e-06, 1.0718745873004556e-06, 9.651032593464714e-07, 1.0261419101540355e-06, 1.020463605876954e-06, 9.217115080377597e-07, 8.298688197102476e-07, 1.0773840884183724e-06, 1.2697829900584813e-06, 1.222417218435895e-06, 1.418358289261734e-06, 1.3947769391147097e-06, 1.315815303117681e-06, 1.1893558436183544e-06, 1.1529195330334506e-06, 1.0692619079153306e-06, 1.0034929771603144e-06, 9.100373223683107e-07, 8.49771699421085e-07, 8.082335730662497e-07, 7.603166350058797e-07, 6.929500711523352e-07, 1.131330567404776e-06, 1.2281050643156632e-06, 1.1174180419706108e-06, 1.0444699722814293e-06, 9.54877874187008e-07], "accuracy_test": 0.8654894770408162, "start": "2016-02-03 11:38:28.867000", "learning_rate_per_epoch": [0.001667053671553731, 0.0008335268357768655, 0.000555684557184577, 0.00041676341788843274, 0.0003334107168484479, 0.0002778422785922885, 0.00023815051827114075, 0.00020838170894421637, 0.00018522818572819233, 0.00016670535842422396, 0.00015155033906921744, 0.00013892113929614425, 0.00012823489669244736, 0.00011907525913557038, 0.00011113691289210692, 0.00010419085447210819, 9.806198067963123e-05, 9.261409286409616e-05, 8.773966692388058e-05, 8.335267921211198e-05, 7.938350609038025e-05, 7.577516953460872e-05, 7.248059409903362e-05, 6.946056964807212e-05, 6.668214336968958e-05, 6.411744834622368e-05, 6.174272857606411e-05, 5.953762956778519e-05, 5.748460898757912e-05, 5.556845644605346e-05, 5.377592606237158e-05, 5.209542723605409e-05, 5.051677726441994e-05, 4.9030990339815617e-05, 4.763010292663239e-05, 4.630704643204808e-05, 4.5055505324853584e-05, 4.386983346194029e-05, 4.2744966776808724e-05, 4.167633960605599e-05, 4.065984467160888e-05, 3.9691753045190126e-05, 3.8768688682466745e-05, 3.788758476730436e-05, 3.7045636418042704e-05, 3.624029704951681e-05, 3.5469227441353723e-05, 3.473028482403606e-05, 3.4021504689008e-05, 3.334107168484479e-05, 3.268732689321041e-05, 3.205872417311184e-05, 3.145384107483551e-05, 3.0871364288032055e-05, 3.0310065994854085e-05, 2.9768814783892594e-05, 2.9246555641293526e-05, 2.874230449378956e-05, 2.8255146389710717e-05, 2.778422822302673e-05, 2.7328747819410637e-05, 2.688796303118579e-05, 2.646116990945302e-05, 2.6047713618027046e-05, 2.5646979338489473e-05, 2.525838863220997e-05, 2.4881397621356882e-05, 2.4515495169907808e-05, 2.4160197426681407e-05, 2.3815051463316195e-05, 2.347962981730234e-05, 2.315352321602404e-05, 2.283635149069596e-05, 2.2527752662426792e-05, 2.2227382942219265e-05, 2.1934916730970144e-05, 2.165004661947023e-05, 2.1372483388404362e-05, 2.1101945094414987e-05, 2.0838169803027995e-05, 2.0580910131684504e-05, 2.032992233580444e-05, 2.008498449868057e-05, 1.9845876522595063e-05, 1.9612396499724127e-05, 1.9384344341233373e-05, 1.916153632919304e-05, 1.894379238365218e-05, 1.8730939700617455e-05, 1.8522818209021352e-05, 1.8319271475775167e-05, 1.8120148524758406e-05, 1.792530747479759e-05, 1.7734613720676862e-05, 1.7547932657180354e-05, 1.736514241201803e-05, 1.718611929391045e-05, 1.7010752344504e-05, 1.6838925148476847e-05, 1.6670535842422396e-05, 1.650548256293405e-05, 1.6343663446605206e-05, 1.618498754396569e-05, 1.602936208655592e-05, 1.587670158187393e-05, 1.5726920537417755e-05, 1.557994073664304e-05, 1.5435682144016027e-05, 1.5294070180971175e-05, 1.5155032997427043e-05, 1.5018501471786294e-05, 1.4884407391946297e-05, 1.4752687093277927e-05, 1.4623277820646763e-05, 1.4496118637907784e-05, 1.437115224689478e-05, 1.4248322258936241e-05, 1.4127573194855358e-05, 1.4008854122948833e-05, 1.3892114111513365e-05, 1.3777303138340358e-05, 1.3664373909705319e-05, 1.355328186036786e-05, 1.3443981515592895e-05, 1.3336429219634738e-05, 1.323058495472651e-05, 1.312640688411193e-05, 1.3023856809013523e-05, 1.2922896530653816e-05, 1.2823489669244736e-05, 1.2725600754492916e-05, 1.2629194316104986e-05, 1.2534237612271681e-05, 1.2440698810678441e-05, 1.2348545169516001e-05, 1.2257747584953904e-05, 1.216827513417229e-05, 1.2080098713340703e-05, 1.1993191947112791e-05, 1.1907525731658097e-05, 1.1823075510619674e-05, 1.173981490865117e-05, 1.1657717550406232e-05, 1.157676160801202e-05, 1.1496921615616884e-05, 1.141817574534798e-05, 1.1340501259837765e-05, 1.1263876331213396e-05, 1.118827913160203e-05, 1.1113691471109632e-05, 1.1040090612368658e-05, 1.0967458365485072e-05, 1.0895775631070137e-05, 1.0825023309735116e-05, 1.0755185030575376e-05, 1.0686241694202181e-05, 1.0618176020216197e-05, 1.0550972547207493e-05, 1.0484613994776737e-05, 1.0419084901513997e-05, 1.0354370715504047e-05, 1.0290455065842252e-05, 1.0227323400613386e-05, 1.016496116790222e-05, 1.0103355634782929e-05, 1.0042492249340285e-05, 9.98235736915376e-06, 9.922938261297531e-06, 9.864223102340475e-06, 9.806198249862064e-06, 9.748851880431175e-06, 9.692172170616686e-06, 9.636148206482176e-06, 9.58076816459652e-06, 9.526021131023299e-06, 9.47189619182609e-06, 9.418382433068473e-06, 9.365469850308727e-06, 9.313149348599836e-06, 9.261409104510676e-06, 9.210240932588931e-06, 9.159635737887584e-06, 9.109582606470212e-06, 9.060074262379203e-06, 9.011100701172836e-06, 8.962653737398796e-06, 8.914725185604766e-06, 8.867306860338431e-06, 8.820389666652773e-06, 8.773966328590177e-06, 8.72802957019303e-06, 8.682571206009015e-06, 8.63758396008052e-06, 8.593059646955226e-06, 8.548992809664924e-06, 8.505376172252e-06, 8.462201549264137e-06, 8.419462574238423e-06, 8.377153790206648e-06, 8.335267921211198e-06, 8.293799510283861e-06, 8.252741281467024e-06, 8.212086868297774e-06, 8.171831723302603e-06, 8.131969480018597e-06, 8.092493771982845e-06, 8.053399142227136e-06, 8.01468104327796e-06, 7.976333108672407e-06, 7.938350790936965e-06, 7.900728633103427e-06, 7.863460268708877e-06], "accuracy_train_first": 0.5759094395994832, "accuracy_train_last": 0.9945366212739941, "batch_size_eval": 1024, "accuracy_train_std": [0.02123463036859039, 0.025121594858861743, 0.02088177212369483, 0.020373074894574843, 0.020551904515506786, 0.01950361733371248, 0.017310719509184662, 0.018253222637273334, 0.017431107566980453, 0.01643455831413366, 0.01573956960148788, 0.015422556020697422, 0.015159424168461895, 0.015019980676872281, 0.014139455645701422, 0.013471907184273475, 0.013000948180309134, 0.012703009635207745, 0.012856800736514067, 0.012154949564615545, 0.012398010872760568, 0.011443098214714831, 0.011310462628976876, 0.01143860433341168, 0.010971087235452237, 0.0103877396284555, 0.010053040258729913, 0.01089254963309836, 0.010436339110508239, 0.010131626161491178, 0.009077751946367027, 0.00898287026098219, 0.009099867373584118, 0.009123866795688296, 0.008915242140603035, 0.008653551155229458, 0.00882877076457273, 0.007836544185346905, 0.008205685651594533, 0.0074293336459725625, 0.007721598350909995, 0.007478239879869832, 0.007576586352584884, 0.0073607462384201105, 0.006859122933799215, 0.006675497696802031, 0.0067233277154705815, 0.006525612641517029, 0.006305872253179603, 0.006368528955179621, 0.006562440038061625, 0.0056796531713494665, 0.005391471615633722, 0.005965672170622287, 0.005484035660749721, 0.005680124967700495, 0.005085262940058008, 0.00534325560695907, 0.005257332450386466, 0.004949490198901902, 0.0050519975774050135, 0.004281086154060292, 0.0049469555221701815, 0.005213834746627316, 0.0046565862925296115, 0.00475533658440211, 0.00463870884308406, 0.004614265152489297, 0.004062122012183466, 0.004249169395371135, 0.003926793342508396, 0.004486210130323981, 0.004283938119972683, 0.004220406803085162, 0.003655318514206163, 0.004178718090002747, 0.0035480237078180693, 0.0039263447662146, 0.0042608272653411475, 0.004228743453036617, 0.0037626919373526324, 0.004320455108342926, 0.003997575286912915, 0.003706928800603833, 0.0039178779321596404, 0.004322098015946285, 0.0041563163708265944, 0.0040934867366645014, 0.004174651074529244, 0.003416222474992148, 0.0036656424764824193, 0.004345606034689456, 0.003924689155015051, 0.003994315753976168, 0.0035039144743366775, 0.003427416326535092, 0.0034254935920752586, 0.003467458429359771, 0.0033018309043027763, 0.003510848818885372, 0.002968565707300596, 0.0032552162776369633, 0.003763768246932846, 0.003222570698799924, 0.0028553693222620647, 0.0031940237265642, 0.003459872613226064, 0.00346882393491265, 0.0033086784348953222, 0.0033248166361544013, 0.0033434759401515016, 0.0030019029529663654, 0.002870011938336457, 0.003274835093694893, 0.0030845946743136956, 0.00305086128248712, 0.0027707240578755303, 0.002800437444089764, 0.003030743416687489, 0.0025448062564680115, 0.003085957797541775, 0.002944368697544955, 0.0027695161396876374, 0.003494532960128137, 0.003157790128838957, 0.0023841037268323155, 0.002575001977245965, 0.0028775138108455395, 0.0027504083652130865, 0.002698178878513399, 0.0026967765745207163, 0.002256896268191691, 0.002644569457519852, 0.002987786778810841, 0.002422771782699295, 0.0024016983605555536, 0.0029356531456343577, 0.0022341369355495765, 0.0028458481680322307, 0.002425832484246284, 0.002576176648714197, 0.002655792230545575, 0.0028368938744990956, 0.0025835831844975604, 0.0024496741105249375, 0.0023468660131160716, 0.0024671197915912325, 0.0025406100406938953, 0.0023800811279946765, 0.0025599708158915977, 0.0025460206802350657, 0.002363627306905343, 0.0021845777568523786, 0.0022667722033819664, 0.001885440075375508, 0.0023169705149707963, 0.002205744423147937, 0.0024287711322722927, 0.0018215353968913592, 0.0020009473488117667, 0.002189073749824005, 0.0023609269439200335, 0.002173268777175229, 0.0023379013323287586, 0.0021691042522369174, 0.0024482263317640346, 0.002249791709805473, 0.002621430794907815, 0.0023138074725568393, 0.0019250781485383953, 0.002294755167684348, 0.0025226451124966834, 0.002214646410215159, 0.002271374888461259, 0.0022550870465115383, 0.0021833601783854046, 0.002083093374866328, 0.0023429539486328936, 0.002209115563379293, 0.0022174463027742693, 0.0019659194138966266, 0.002099779863282357, 0.0019968085657299057, 0.002409246984869765, 0.0023078405128550967, 0.002409714561355453, 0.0021920267617995363, 0.0023335550161448742, 0.002301604891354377, 0.002194534700311489, 0.002443495708310345, 0.0019264219924719054, 0.002248281218741796, 0.002030710561393519, 0.0020425116916463594, 0.002217363991605419, 0.0025571016647319526, 0.0022664615736964575, 0.001990958603979785, 0.0021534401258211226, 0.002354649078408381, 0.0024383861017919805, 0.0020004948900629303, 0.0021115783904938094, 0.0024651469348134455, 0.0019788839396470566, 0.0025959335896382583, 0.0022892229863205995, 0.002227078488181699, 0.002188855487937305, 0.0020527088548196004, 0.0020673167896394546], "accuracy_test_std": 0.007679447695928511, "error_valid": [0.42645925498870485, 0.3598368081701807, 0.23415144954819278, 0.21373482210090367, 0.19392707548945776, 0.1814861987010542, 0.17399872929216864, 0.16505671121987953, 0.1611401661332832, 0.15951207172439763, 0.15583966726280118, 0.15511754047439763, 0.1528187947100903, 0.15346003153237953, 0.14664321347891573, 0.1445577230798193, 0.14457831325301207, 0.1413838949548193, 0.14062058782003017, 0.14103827419051207, 0.1396749105798193, 0.14003082643072284, 0.1375791250941265, 0.1382100668298193, 0.13981757106551207, 0.13649078736822284, 0.1382100668298193, 0.13612457643072284, 0.13487298804593373, 0.1361142813441265, 0.1343038168298193, 0.13404938111822284, 0.13234039674322284, 0.13193300545933728, 0.13048875188253017, 0.13046816170933728, 0.1333066641566265, 0.13206537085843373, 0.13368317018072284, 0.13268601750753017, 0.13155649943524095, 0.13244187688253017, 0.13402879094503017, 0.13095644295933728, 0.13158738469503017, 0.13267572242093373, 0.13307281861822284, 0.1315976797816265, 0.13328607398343373, 0.1344052969691265, 0.13183152532003017, 0.1323506918298193, 0.13073289250753017, 0.13034609139683728, 0.12901361304593373, 0.13122117375753017, 0.13319488893072284, 0.13321547910391573, 0.12826060099774095, 0.1318624105798193, 0.12815912085843373, 0.1303975668298193, 0.13160797486822284, 0.1297872152673193, 0.13000047063253017, 0.12864740210843373, 0.13060052710843373, 0.12963425969503017, 0.13014313111822284, 0.12792527532003017, 0.12892242799322284, 0.12620599585843373, 0.1287900625941265, 0.12853562688253017, 0.1304990469691265, 0.12941070924322284, 0.12767083960843373, 0.1278135000941265, 0.12745758424322284, 0.12694871282003017, 0.1292989340173193, 0.1286885824548193, 0.1289327230798193, 0.1280576407191265, 0.13188300075301207, 0.1284238516566265, 0.1272031485316265, 0.1275693594691265, 0.1289121329066265, 0.1279355704066265, 0.1274472891566265, 0.1269590079066265, 0.1272031485316265, 0.12521913827183728, 0.12808852597891573, 0.12877976750753017, 0.12523972844503017, 0.12719285344503017, 0.1265927969691265, 0.12658250188253017, 0.12831207643072284, 0.1284444418298193, 0.12707078313253017, 0.12735610410391573, 0.12682664250753017, 0.1261045157191265, 0.12660309205572284, 0.1264707266566265, 0.12857680722891573, 0.12757965455572284, 0.1274678793298193, 0.12992987575301207, 0.1266133871423193, 0.1251279532191265, 0.12660309205572284, 0.12672516236822284, 0.12486322242093373, 0.12329689853162651, 0.1273458090173193, 0.1265927969691265, 0.12589126035391573, 0.1257588949548193, 0.12772231504141573, 0.12550445924322284, 0.1270810782191265, 0.12572800969503017, 0.1254941641566265, 0.12536179875753017, 0.12822089137801207, 0.1250058829066265, 0.1257383047816265, 0.12550445924322284, 0.12424257577183728, 0.12337778849774095, 0.12426316594503017, 0.1261045157191265, 0.12646043157003017, 0.1268575277673193, 0.12569712443524095, 0.1267148672816265, 0.12474115210843373, 0.12646043157003017, 0.12745758424322284, 0.1265927969691265, 0.12485292733433728, 0.12400873023343373, 0.12511765813253017, 0.12388665992093373, 0.12352044898343373, 0.12398814006024095, 0.12536179875753017, 0.12474115210843373, 0.1250058829066265, 0.12388665992093373, 0.1259824454066265, 0.12472056193524095, 0.12423228068524095, 0.12534120858433728, 0.12485292733433728, 0.12388665992093373, 0.12300128247364461, 0.12216738045933728, 0.12497499764683728, 0.12447642131024095, 0.12497499764683728, 0.12349985881024095, 0.12411021037274095, 0.12597215032003017, 0.1261045157191265, 0.12520884318524095, 0.12300128247364461, 0.12385577466114461, 0.12253359139683728, 0.12497499764683728, 0.12228945077183728, 0.12396754988704817, 0.12450730657003017, 0.12238063582454817, 0.12436464608433728, 0.12461908179593373, 0.12288950724774095, 0.12448671639683728, 0.12364251929593373, 0.12558534920933728, 0.12288950724774095, 0.12387636483433728, 0.12300128247364461, 0.12397784497364461, 0.12523972844503017, 0.12508677287274095, 0.12434405591114461, 0.12423228068524095, 0.12609422063253017, 0.12619570077183728, 0.12361163403614461, 0.12633836125753017, 0.12349985881024095, 0.12535150367093373, 0.12437494117093373, 0.12363222420933728, 0.12508677287274095, 0.12522943335843373, 0.12434405591114461, 0.12400873023343373, 0.12522943335843373, 0.12520884318524095, 0.12435435099774095, 0.12225856551204817, 0.12286891707454817, 0.12387636483433728, 0.12486322242093373, 0.12386606974774095], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.09121903938588113, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 32, "valid_ratio": 0.15, "learning_rate": 0.0016670536563107195, "optimization": "rmsprop", "nb_data_augmentation": 3, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 4.055931295679036e-07, "rotation_range": [0, 0], "momentum": 0.6475308280151453}, "accuracy_valid_max": 0.8778326195406627, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.876133930252259, "accuracy_valid_std": [0.013775819112395091, 0.013691894563592799, 0.010201636907511798, 0.015235334315661424, 0.008112888179384168, 0.013794041750684456, 0.009518493836739745, 0.011706089891657515, 0.010209707651047653, 0.010245810682458837, 0.0120719543756219, 0.011785261878559813, 0.013323596404426269, 0.014574279248748049, 0.010271886846707413, 0.008711706305139842, 0.008495133089788758, 0.008225424842781968, 0.006421676799473113, 0.010323732531003278, 0.006485252200616407, 0.006346824737465124, 0.005231265145889913, 0.007254410481707092, 0.009568425895558532, 0.006857677626958355, 0.00731984601979495, 0.006523368917366783, 0.0038749042386602103, 0.006911451267121367, 0.007867223041140323, 0.007202437651576725, 0.007517975900987489, 0.00583209344657392, 0.008104982321757107, 0.005957330413213576, 0.006320465217699558, 0.006904357265733354, 0.006806528051486669, 0.00521589181002167, 0.005446582755972593, 0.0071027589323799075, 0.004894284645229428, 0.0069818645899821456, 0.008490761527656692, 0.006527388949039314, 0.008282270600805847, 0.00916603625610177, 0.006876686931362553, 0.007696256103176214, 0.006777075080585239, 0.008156381664072796, 0.008707794349464308, 0.008962213766383807, 0.007997297004215564, 0.006880332186706369, 0.009237210651505524, 0.011473981254601487, 0.005602199771603376, 0.011168104036398263, 0.006861370969028917, 0.009988501129458021, 0.008774283619649397, 0.00946862079774228, 0.008038255162691486, 0.008163522378603924, 0.010003956665250521, 0.008461616812602926, 0.01041665502663759, 0.007477155663361593, 0.009796408471992864, 0.008751277913722206, 0.009150755715383044, 0.009928507807017302, 0.008729606940172488, 0.010270859910089775, 0.00846292872811107, 0.008432771520813162, 0.009713294258949574, 0.009759011467709959, 0.009930827213518382, 0.010946606550547003, 0.013045351413403095, 0.009254852583074007, 0.011897477263890007, 0.00972643744864646, 0.010284163387482543, 0.010063521167642388, 0.010181244836575199, 0.009210546602958515, 0.010052481142990486, 0.010076455692076698, 0.009918318437532037, 0.00789698197482489, 0.012575217595492256, 0.008734144749931633, 0.009071329352271269, 0.009420379659606497, 0.010378981162875936, 0.009758082398123837, 0.010490050642528628, 0.01249561322821721, 0.008342330825654071, 0.013074607113587948, 0.008828192311479282, 0.010453646051473912, 0.011787497886717855, 0.010949837210260601, 0.012559560632952509, 0.011001459691956665, 0.011389802145030681, 0.014364722100109745, 0.012565481532973788, 0.010129880828847755, 0.01167572276389178, 0.012719458983548383, 0.01204721598730246, 0.012898383459963225, 0.012246825471102184, 0.012185763291878794, 0.013165031215826847, 0.013194859913261654, 0.012541286172993882, 0.01164721833020829, 0.010105180272733601, 0.010677218552010067, 0.010982972308101174, 0.010521720762613939, 0.01325482932340409, 0.009740750443551613, 0.011847022648250924, 0.012667013344040596, 0.009422205361270888, 0.009483107600301285, 0.01141063245739642, 0.011223547402965137, 0.010235757872353915, 0.011406254222209313, 0.008865904788542748, 0.010660092622336375, 0.009213383075544965, 0.009697520464628307, 0.010423684574421683, 0.009726778918467694, 0.009558063239210537, 0.010920474526531785, 0.010099612630416243, 0.01096864420464723, 0.008709203173835084, 0.008658345577054877, 0.008711916853230011, 0.009839072956931283, 0.010797143599202204, 0.010014189684822731, 0.009567281173046194, 0.007132935737246943, 0.006995495224990681, 0.008254403538890976, 0.009356381545187371, 0.010237868335085174, 0.008713413758083122, 0.008824445731730302, 0.009026804922194475, 0.008323423117280711, 0.0084398583046155, 0.008012717511314172, 0.007688031542551168, 0.009511115376540206, 0.010304332789714033, 0.00810525720085465, 0.00906214446895396, 0.008115035764659339, 0.009112082931718377, 0.008866915143054864, 0.008512803595115656, 0.00918329968344088, 0.011579248221406258, 0.00984963539976736, 0.009587919637334854, 0.009925593158489697, 0.009168075284098022, 0.009078131143536663, 0.009693230700592838, 0.009640690752724805, 0.00910282986325578, 0.009225446173876165, 0.00789517069547981, 0.008496936504232874, 0.01097433318583085, 0.008696301010734327, 0.008036605454304731, 0.007755167739039616, 0.009861157195858694, 0.009389375036428078, 0.008223118801841697, 0.009733508131481692, 0.009293899599875505, 0.009769314298713413, 0.010325524197579875, 0.009473426582779415, 0.008599809370886538, 0.009227091028100138, 0.008988853687043016, 0.01055409639781057, 0.009888144089424915, 0.00826545816407798, 0.008548131430594082, 0.008838659504641501, 0.00728571667107192, 0.00773540481955022, 0.009350835091163669, 0.010516035707774667], "accuracy_valid": [0.5735407450112951, 0.6401631918298193, 0.7658485504518072, 0.7862651778990963, 0.8060729245105422, 0.8185138012989458, 0.8260012707078314, 0.8349432887801205, 0.8388598338667168, 0.8404879282756024, 0.8441603327371988, 0.8448824595256024, 0.8471812052899097, 0.8465399684676205, 0.8533567865210843, 0.8554422769201807, 0.8554216867469879, 0.8586161050451807, 0.8593794121799698, 0.8589617258094879, 0.8603250894201807, 0.8599691735692772, 0.8624208749058735, 0.8617899331701807, 0.8601824289344879, 0.8635092126317772, 0.8617899331701807, 0.8638754235692772, 0.8651270119540663, 0.8638857186558735, 0.8656961831701807, 0.8659506188817772, 0.8676596032567772, 0.8680669945406627, 0.8695112481174698, 0.8695318382906627, 0.8666933358433735, 0.8679346291415663, 0.8663168298192772, 0.8673139824924698, 0.868443500564759, 0.8675581231174698, 0.8659712090549698, 0.8690435570406627, 0.8684126153049698, 0.8673242775790663, 0.8669271813817772, 0.8684023202183735, 0.8667139260165663, 0.8655947030308735, 0.8681684746799698, 0.8676493081701807, 0.8692671074924698, 0.8696539086031627, 0.8709863869540663, 0.8687788262424698, 0.8668051110692772, 0.8667845208960843, 0.871739399002259, 0.8681375894201807, 0.8718408791415663, 0.8696024331701807, 0.8683920251317772, 0.8702127847326807, 0.8699995293674698, 0.8713525978915663, 0.8693994728915663, 0.8703657403049698, 0.8698568688817772, 0.8720747246799698, 0.8710775720067772, 0.8737940041415663, 0.8712099374058735, 0.8714643731174698, 0.8695009530308735, 0.8705892907567772, 0.8723291603915663, 0.8721864999058735, 0.8725424157567772, 0.8730512871799698, 0.8707010659826807, 0.8713114175451807, 0.8710672769201807, 0.8719423592808735, 0.8681169992469879, 0.8715761483433735, 0.8727968514683735, 0.8724306405308735, 0.8710878670933735, 0.8720644295933735, 0.8725527108433735, 0.8730409920933735, 0.8727968514683735, 0.8747808617281627, 0.8719114740210843, 0.8712202324924698, 0.8747602715549698, 0.8728071465549698, 0.8734072030308735, 0.8734174981174698, 0.8716879235692772, 0.8715555581701807, 0.8729292168674698, 0.8726438958960843, 0.8731733574924698, 0.8738954842808735, 0.8733969079442772, 0.8735292733433735, 0.8714231927710843, 0.8724203454442772, 0.8725321206701807, 0.8700701242469879, 0.8733866128576807, 0.8748720467808735, 0.8733969079442772, 0.8732748376317772, 0.8751367775790663, 0.8767031014683735, 0.8726541909826807, 0.8734072030308735, 0.8741087396460843, 0.8742411050451807, 0.8722776849585843, 0.8744955407567772, 0.8729189217808735, 0.8742719903049698, 0.8745058358433735, 0.8746382012424698, 0.8717791086219879, 0.8749941170933735, 0.8742616952183735, 0.8744955407567772, 0.8757574242281627, 0.876622211502259, 0.8757368340549698, 0.8738954842808735, 0.8735395684299698, 0.8731424722326807, 0.874302875564759, 0.8732851327183735, 0.8752588478915663, 0.8735395684299698, 0.8725424157567772, 0.8734072030308735, 0.8751470726656627, 0.8759912697665663, 0.8748823418674698, 0.8761133400790663, 0.8764795510165663, 0.876011859939759, 0.8746382012424698, 0.8752588478915663, 0.8749941170933735, 0.8761133400790663, 0.8740175545933735, 0.875279438064759, 0.875767719314759, 0.8746587914156627, 0.8751470726656627, 0.8761133400790663, 0.8769987175263554, 0.8778326195406627, 0.8750250023531627, 0.875523578689759, 0.8750250023531627, 0.876500141189759, 0.875889789627259, 0.8740278496799698, 0.8738954842808735, 0.874791156814759, 0.8769987175263554, 0.8761442253388554, 0.8774664086031627, 0.8750250023531627, 0.8777105492281627, 0.8760324501129518, 0.8754926934299698, 0.8776193641754518, 0.8756353539156627, 0.8753809182040663, 0.877110492752259, 0.8755132836031627, 0.8763574807040663, 0.8744146507906627, 0.877110492752259, 0.8761236351656627, 0.8769987175263554, 0.8760221550263554, 0.8747602715549698, 0.874913227127259, 0.8756559440888554, 0.875767719314759, 0.8739057793674698, 0.8738042992281627, 0.8763883659638554, 0.8736616387424698, 0.876500141189759, 0.8746484963290663, 0.8756250588290663, 0.8763677757906627, 0.874913227127259, 0.8747705666415663, 0.8756559440888554, 0.8759912697665663, 0.8747705666415663, 0.874791156814759, 0.875645649002259, 0.8777414344879518, 0.8771310829254518, 0.8761236351656627, 0.8751367775790663, 0.876133930252259], "seed": 684594629, "model": "residualv3", "loss_std": [0.36359962821006775, 0.19891756772994995, 0.17602886259555817, 0.16735027730464935, 0.15926171839237213, 0.15459749102592468, 0.14973117411136627, 0.14536616206169128, 0.14132310450077057, 0.13640964031219482, 0.13295210897922516, 0.13325992226600647, 0.12857995927333832, 0.1259312629699707, 0.12337786704301834, 0.12041527777910233, 0.11840158700942993, 0.1167498230934143, 0.11660725623369217, 0.1124081239104271, 0.11190604418516159, 0.11034677177667618, 0.10727153718471527, 0.1060817614197731, 0.10416790843009949, 0.10180541127920151, 0.10026378929615021, 0.09989745169878006, 0.09752500057220459, 0.09627774357795715, 0.09539461135864258, 0.09516163170337677, 0.09399215877056122, 0.09282781928777695, 0.09106260538101196, 0.09038001298904419, 0.08946952223777771, 0.08866044878959656, 0.08734333515167236, 0.08640053123235703, 0.08448802679777145, 0.0844547301530838, 0.08450547605752945, 0.08380139619112015, 0.08394906669855118, 0.07955236732959747, 0.08072498440742493, 0.07974395900964737, 0.07989287376403809, 0.07958156615495682, 0.07811013609170914, 0.07731309533119202, 0.07752905786037445, 0.0753793865442276, 0.07554157823324203, 0.07419547438621521, 0.07437177002429962, 0.07329172641038895, 0.07147668302059174, 0.07052723318338394, 0.0721861943602562, 0.07180182635784149, 0.07159308344125748, 0.06976667046546936, 0.07149749994277954, 0.06915979087352753, 0.06787894666194916, 0.0700032040476799, 0.0669947937130928, 0.06712567806243896, 0.06640461832284927, 0.06769367307424545, 0.06658114492893219, 0.06660778820514679, 0.06512756645679474, 0.06493325531482697, 0.06627386063337326, 0.06398381292819977, 0.06566264480352402, 0.06454553455114365, 0.062395088374614716, 0.06343952566385269, 0.06321937590837479, 0.062147121876478195, 0.06120610982179642, 0.061443641781806946, 0.06018724665045738, 0.06018475815653801, 0.06066254898905754, 0.05999371036887169, 0.060207877308130264, 0.05937660485506058, 0.05933045223355293, 0.0599001906812191, 0.05753784254193306, 0.05778605490922928, 0.05760671943426132, 0.0566704198718071, 0.05688970908522606, 0.05607030540704727, 0.055606015026569366, 0.05661459267139435, 0.05905560031533241, 0.05588012933731079, 0.05642351135611534, 0.05416805297136307, 0.052924130111932755, 0.054053895175457, 0.05398493632674217, 0.05377068743109703, 0.053517404943704605, 0.054625533521175385, 0.05188790336251259, 0.05280423164367676, 0.05361197888851166, 0.051297951489686966, 0.05268923565745354, 0.051280200481414795, 0.05068965256214142, 0.05083925276994705, 0.05205050855875015, 0.050266146659851074, 0.05172976478934288, 0.051008060574531555, 0.04937296360731125, 0.05144437775015831, 0.049818847328424454, 0.04965345561504364, 0.05160749331116676, 0.049592070281505585, 0.04906849563121796, 0.047305990010499954, 0.05008401721715927, 0.048765264451503754, 0.048093218356370926, 0.04714757576584816, 0.04774114862084389, 0.04769512638449669, 0.047095946967601776, 0.04767964407801628, 0.04748471826314926, 0.045284152030944824, 0.04826844856142998, 0.04613959789276123, 0.04675143212080002, 0.047270432114601135, 0.04679558053612709, 0.04580652713775635, 0.045122332870960236, 0.04680981859564781, 0.04515156149864197, 0.04538976028561592, 0.04494564235210419, 0.0476640984416008, 0.04586584120988846, 0.04349904507398605, 0.0435512438416481, 0.04241006076335907, 0.044108908623456955, 0.04424063116312027, 0.04372437298297882, 0.04418935626745224, 0.04519815742969513, 0.04296787083148956, 0.042534809559583664, 0.043642763048410416, 0.04349792003631592, 0.04379940405488014, 0.043166134506464005, 0.04328814148902893, 0.04231242462992668, 0.04060252383351326, 0.041851434856653214, 0.042463574558496475, 0.04146628826856613, 0.041652146726846695, 0.04233519732952118, 0.04298188537359238, 0.04097200930118561, 0.042054492980241776, 0.04263162240386009, 0.0416133813560009, 0.04019617661833763, 0.04024762660264969, 0.04156975448131561, 0.039724912494421005, 0.04152543470263481, 0.04122612997889519, 0.04206359013915062, 0.040560826659202576, 0.03991137444972992, 0.04067828506231308, 0.03882034495472908, 0.039653025567531586, 0.03824016451835632, 0.039938900619745255, 0.03940078988671303, 0.03999453783035278, 0.03948628529906273, 0.03974897414445877, 0.038828179240226746, 0.03806425258517265, 0.038497887551784515, 0.03967391327023506, 0.037125393748283386, 0.03925267979502678, 0.03879407048225403, 0.0376863107085228, 0.03953997418284416, 0.03799824044108391, 0.03833211585879326, 0.039538752287626266]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:40 2016", "state": "available"}], "summary": "1895601355ff0e569bea9e06859a4a52"}