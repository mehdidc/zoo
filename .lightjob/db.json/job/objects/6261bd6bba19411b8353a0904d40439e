{"content": {"hp_model": {"f0": 32, "f1": 16, "f2": 16, "f3": 64, "nonlin": "leaky_rectify", "nbg1": 1, "nbg3": 3, "nbg2": 6, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.010692680442007699, 0.00591992015254489, 0.0060605353158034855, 0.007592860787210128, 0.009279299111443524, 0.009646626978316595, 0.00909122423111351, 0.010045094395709962, 0.010401396084569409, 0.010275361643928005, 0.010981915748066591, 0.009560116057152986, 0.010366352128934988, 0.009361068648006461, 0.010167242090886052, 0.0101694356877695, 0.008885986720324639, 0.008927582534692138, 0.009209992355648813, 0.010079572860353552, 0.005821141309091429, 0.007216166164975951, 0.006754979328712591, 0.006988032464699829, 0.007508847049365308, 0.009129091678700853, 0.00931652101415332, 0.012621451924500735, 0.011168239127288086, 0.009170635843981529, 0.01263348470927131, 0.010323626198639869, 0.010086453037911489, 0.00998734900264249, 0.009350936524514433, 0.0072173697057775635, 0.007208255505671017, 0.008442289617762076, 0.010299053852505478, 0.010140608037982281, 0.00961459495069874, 0.008339870371682764, 0.00860171468665836, 0.007532027445470611, 0.008354462222787438, 0.008429041260562533, 0.007951128492804445, 0.009124012546770085, 0.008007477543966418, 0.009152136649371796, 0.008658391419094401, 0.008321399886305793, 0.006960086290721665, 0.008047489430277676, 0.008133034768122521, 0.00856147253178661, 0.007502209399841425, 0.007168368797152021, 0.007468269300753139, 0.00857025574731475, 0.008699881622347824, 0.008038348671908975, 0.007476246092667266, 0.006870726210678852, 0.007476246092667266, 0.007873298582322802, 0.005556484722735447, 0.007465275806357742, 0.007091418140648267, 0.007576230785733838, 0.0058363976495195225, 0.0066989051623395175, 0.006931527087269527, 0.007310104928621037, 0.006302248205326642, 0.006030804098184527, 0.006248026278843862, 0.006455422401179854, 0.0057845829550328765, 0.0059094344282310095, 0.005507332101682891, 0.006746149749433642, 0.006164774596766152, 0.006317096116875186, 0.005280966367460939, 0.005689052830923361, 0.0056720020290473355, 0.00565226411269054, 0.005932962921060661, 0.005521608339980602, 0.006110353508783889, 0.006147481905702444, 0.005089373678334075, 0.0053021486923113025, 0.004834044728648865, 0.006485983927786952, 0.004756085107500892, 0.006531275525487139, 0.00447188340407871, 0.005528178813464873, 0.006213606734679889, 0.00586477329913744, 0.004979027964318268, 0.004418551459744484, 0.006103008646237731, 0.004819661686673518, 0.005037526924307458, 0.005794040174490264, 0.006074148097961293, 0.005033454066981845, 0.0050679454429624505, 0.0057966796994054865, 0.005606020907162537, 0.006661171394154656, 0.006619919414339878, 0.00537759431830086, 0.005647499780809409, 0.005950608579949614, 0.005859438310305962, 0.005545212152045413, 0.005336302000584569, 0.00557871726950747, 0.006633772214007398, 0.00491281859070578, 0.005640388209056602, 0.0054138674820936985, 0.006199947260077946, 0.006318244284476335, 0.0055203076087422176, 0.006098182353745041, 0.006918082926815087, 0.006263251397042435, 0.005544465307214729, 0.005618263416718027, 0.005777421663183219, 0.005609924459509794, 0.005316113563862432, 0.005695473242489303, 0.005708571286405665, 0.006308803495811792, 0.005948971157720315, 0.005874613972419905, 0.005119806935600399, 0.0068089936443163175, 0.005728099511864331, 0.0064567062727403715, 0.005791498981125826, 0.006472975120047299, 0.005691285558420343, 0.005609924459509794, 0.004630633969333657, 0.0064253433660334544, 0.005812129391885011, 0.005567262817866884, 0.006680211927451516, 0.00509780591255398, 0.0055702793082852515, 0.006042581192192611, 0.005588634346806444, 0.005990444979914262, 0.005669455542540938, 0.005858103296241126, 0.005823587297387262, 0.0046818381129797625, 0.005313915737226298, 0.006113273449975056, 0.006852266699553803, 0.00620588932589434, 0.006263251397042434, 0.006129801685380978, 0.005980066460339472, 0.007306309510287217, 0.006909590913952931, 0.006807674377267017, 0.007242140010709248, 0.006605346317611662, 0.006869596388892784, 0.006815968564663143, 0.006834847499594443, 0.006619561453639463, 0.008602059690790557, 0.007248293509839617, 0.006549842981101715, 0.008493887903213499, 0.006782321476117725, 0.006771819509791328, 0.009079295370173797, 0.006693650260171132, 0.0069298928040852905, 0.007613805026135141, 0.0063690663090168525, 0.008016822811294021, 0.006342959500374307, 0.0074119030728150275, 0.008653570555011115, 0.0063853897513158194, 0.006586771781652597, 0.007562796091537241, 0.0064303149833975755, 0.0071686951295751354, 0.007295399451405999, 0.007358897188839428, 0.008128730446106198, 0.008766802984420072, 0.007032169660837931, 0.007616464960470377, 0.006253340884878911, 0.007549277462988121, 0.007861604914560024, 0.0078125474828417, 0.006515809755254971, 0.007550323770189401, 0.007520582293909615, 0.00663091641646409, 0.008011804891761279, 0.00639164725318042, 0.008792557980091278, 0.0070487371799032835, 0.00752083999308514, 0.007878224611295979, 0.008850853914723001, 0.00772542796452171, 0.0070375546059873425, 0.008646295693049847, 0.007831288836777, 0.006956990260110573, 0.008028113652474366, 0.00817260756446549, 0.008045168817270285, 0.008341075664711576, 0.00826858117689877, 0.007523875921939298, 0.008602081818863265, 0.007285831862441552, 0.008683901403000058, 0.007324466229541473, 0.010373125504370024, 0.008890148368770452, 0.008317726300383719, 0.009167416657918672, 0.007554780841172911, 0.008227463130779092, 0.007526547951800682, 0.008301708740978095, 0.008845089383360327, 0.008799670998445489, 0.008916733115843248, 0.007499803848865267, 0.007581835278670344, 0.0078035570053459884, 0.008919527826320287, 0.007627434598252754, 0.007649351988719586, 0.006498799947320861, 0.00812397668327993, 0.007504745466256558, 0.008072059506449342, 0.008069827711674797, 0.008187181015579179, 0.007381263392389708, 0.008709989949760463, 0.0077578983993902215, 0.008911649700036745, 0.008538430492434817, 0.008079728264033111, 0.008632778115892956, 0.00783269859554962], "moving_avg_accuracy_train": [0.012221612997185305, 0.02615271685527408, 0.0401692165798611, 0.05367202083549624, 0.06640114552151102, 0.07842912805315468, 0.08965416582923456, 0.10003117553368653, 0.10977506016055043, 0.11875374761994757, 0.1270763818095955, 0.13485256563975628, 0.14196967762736795, 0.14849362495668542, 0.15467198904947202, 0.16038365140559901, 0.16568207740106716, 0.17062733605769356, 0.1751478593617618, 0.17928604875089016, 0.18308246276538218, 0.18662021521415773, 0.18996706098117863, 0.19300004036432694, 0.1958089210639592, 0.19841360755552379, 0.2007950277788843, 0.20309638005013764, 0.2052187143192564, 0.20715221084483354, 0.20894816128928154, 0.21059917762851504, 0.21212233076359638, 0.21356757334707432, 0.21492409524363304, 0.2162356457541073, 0.21752521506112552, 0.21867892408865086, 0.2197729215895772, 0.22094109794990704, 0.22197843368370923, 0.22293070913224491, 0.22393645841328028, 0.224757963457888, 0.2256762823587308, 0.22653299630401313, 0.22728082341549075, 0.2280537771169926, 0.22884473050071602, 0.22957518973654326, 0.23027678087616874, 0.23090127350422185, 0.23151672319445118, 0.23217282631682037, 0.2327191412995717, 0.23326906165074224, 0.2338243356893871, 0.23431946807536716, 0.23476047297394895, 0.2351876403660151, 0.2355952704093324, 0.23610633272332718, 0.23655004881307456, 0.23701907566049543, 0.2374062865422126, 0.23771063455719585, 0.23802414739808017, 0.2383830028167716, 0.23874081387691798, 0.23908144502152592, 0.23931593343857782, 0.23966415679368644, 0.23996364296924583, 0.24026101021532603, 0.24055893976895953, 0.24088974723863057, 0.24117359516611486, 0.24150571611392752, 0.24185109189433063, 0.24217824218717884, 0.24245414835790358, 0.24269541636748976, 0.24296821695227086, 0.24319528048337266, 0.24345547728161163, 0.24373390432504513, 0.243954189631974, 0.24418038424274302, 0.24443504056860715, 0.2446130419392566, 0.24481513190023127, 0.24499232651867067, 0.2451681498145703, 0.24533569137611808, 0.24554682450410242, 0.24574385581453567, 0.24590029370345864, 0.24607596503563217, 0.24622705773934103, 0.24632358574055457, 0.2464336403321045, 0.24656291639902325, 0.2467442969282793, 0.2469169120974853, 0.24702343762477072, 0.2471658856731556, 0.24728696927499838, 0.24741222055832357, 0.24745995069310583, 0.24758646897627773, 0.24769582932878836, 0.24780809639244883, 0.24794873637714268, 0.24803349573361447, 0.24815617398417328, 0.2482526335168191, 0.24839303366527563, 0.24852393595004926, 0.24863713375754526, 0.24874824028189224, 0.24888783578120394, 0.24900177388889935, 0.24909043939060557, 0.2491864783349891, 0.24916846193259948, 0.24927526376444104, 0.2493433754809279, 0.2494279996114988, 0.2494786567897454, 0.24951033340612894, 0.24963642651323661, 0.24971041882869036, 0.24974671288043743, 0.24976310148534311, 0.2498919277166999, 0.24998218654156, 0.2500146634565716, 0.2500996241538731, 0.2502458432457302, 0.250249665390334, 0.2502925968014206, 0.2503381023713708, 0.2503582391914965, 0.25039031322246685, 0.25048181467292224, 0.25056656322477916, 0.25067771415359325, 0.2507567515526027, 0.25083478856050223, 0.2509539581390681, 0.25106815015738726, 0.2511569360321986, 0.2512671063028713, 0.25135470590006664, 0.25144746038158083, 0.251544854258982, 0.25161165450699485, 0.25173448165042606, 0.25174508072952334, 0.2518685521923776, 0.2519355707792029, 0.2519795033192228, 0.25206085923499344, 0.2521876300794435, 0.2522644493608587, 0.2523266112677038, 0.25240115817434056, 0.2524311201069988, 0.25244642405352485, 0.2525368914672938, 0.25264392482540937, 0.25272158155959973, 0.25275655933940944, 0.25280202628291404, 0.2528569334737441, 0.2529551420216724, 0.25304127666363585, 0.2530884988092416, 0.25314033538434366, 0.25324737007334563, 0.2533321115982185, 0.2534060538217946, 0.2534447000372988, 0.25358872757648143, 0.2536765717808119, 0.2537463309694712, 0.25385089482019846, 0.2539125223001572, 0.25394004919758706, 0.25397648519814026, 0.2540696593700483, 0.25411867494144136, 0.25422091767593324, 0.2543548248643661, 0.2544077678232045, 0.2544950521623772, 0.25456670471884163, 0.25465197416367025, 0.25468464698309135, 0.25475114675506644, 0.2548668722189101, 0.25496869998755983, 0.2550324071448116, 0.25518274953871917, 0.25530174560275054, 0.25535776088420675, 0.2554128249351364, 0.2555064883107165, 0.2555606305118523, 0.2556069612464275, 0.2557160521742026, 0.2557445155937333, 0.255853801979635, 0.2558709597627069, 0.25593969994599697, 0.2559876152181008, 0.25610056552491756, 0.25619742630815856, 0.25624757887621685, 0.2563298825196029, 0.2563550916248316, 0.2563637568290428, 0.2564669226628421, 0.2565318701275472, 0.25657411890175263, 0.2566307439890137, 0.25664217903778674, 0.25670358780667324, 0.25678908263319494, 0.25679165926397846, 0.2569240784185607, 0.25697818753983676, 0.2570525344835275, 0.2570775940542777, 0.2570861246774583, 0.2571170897752348, 0.2571845219418143, 0.2572381633476698, 0.2573098002474912, 0.2573881162037314, 0.25742368728338594, 0.25739996978128393, 0.2574483063960403, 0.25745704026363453, 0.25752760766468896, 0.25755624109349506, 0.2575679881889259, 0.2576507483343652, 0.2576880661331269, 0.2577192549055654, 0.2577961529257601, 0.2578909017320213, 0.25793897327670395, 0.2580008749062133, 0.2580775127120575, 0.2581557512837366, 0.2582353944958483, 0.2582420413177198, 0.25832715061456535, 0.258366546600774, 0.25841595388121896, 0.2584325186479051, 0.2584845932700563, 0.2585384358764209, 0.2586194463054824, 0.25865053906188507, 0.2586878231378855], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 216926772, "moving_var_accuracy_train": [0.0013443104182767193, 0.0029565602687927515, 0.004429064622677609, 0.005627089665303837, 0.006522656236222453, 0.007172441886633932, 0.007589210955640322, 0.0077994308337329, 0.007873977338954322, 0.007812131061500712, 0.0076543141140429085, 0.007433104017282705, 0.007145673162952287, 0.006814162845458435, 0.006476296206679906, 0.006122274367845499, 0.005762706793326024, 0.0054065363626218665, 0.005049798904843295, 0.004698940517141616, 0.004358761299752337, 0.00403552640127646, 0.003732786150442847, 0.0034422982108459855, 0.0031690766868242874, 0.0029132285436159096, 0.0026729461497763925, 0.0024533175352863786, 0.0022485245065066235, 0.0020573177351857303, 0.0018806149036573736, 0.001717086107863381, 0.0015662574563332153, 0.0014284302458257758, 0.0013021485861457874, 0.0011874152102049366, 0.001083640590162874, 0.0009872559318283274, 0.0008993018134337926, 0.0008216533561699146, 0.0007491726093745299, 0.0006824168052060316, 0.0006232789092321571, 0.0005670248531537852, 0.0005179121542712128, 0.00047272656790046247, 0.00043048711960836473, 0.0003928155244695172, 0.00035916443731957707, 0.0003280501298444674, 0.0002996751880048295, 0.00027321758858678074, 0.00024930483461893326, 0.00022824859292168353, 0.0002081098741729225, 0.00019002059828931414, 0.00017379350178231947, 0.0001586205563209045, 0.00014450886857397217, 0.0001317002295441764, 0.00012002566685969238, 0.00011037376237279443, 0.00010110834185022136, 9.297738331761317e-05, 8.502903538813347e-05, 7.735978127733829e-05, 7.050841586219872e-05, 6.461656917969667e-05, 5.930717105459476e-05, 5.442072013922755e-05, 4.9473511484888405e-05, 4.5617495881787544e-05, 4.186297401776943e-05, 3.847252212736447e-05, 3.542412808498239e-05, 3.286661751439558e-05, 3.0305082576390243e-05, 2.8267313234534995e-05, 2.6514141778283043e-05, 2.4825973427450835e-05, 2.302849402010153e-05, 2.1249536890138402e-05, 1.9794364632636792e-05, 1.827894879378095e-05, 1.7060375278727123e-05, 1.6052032317490618e-05, 1.4883559633780228e-05, 1.3855679687870692e-05, 1.3053760317807159e-05, 1.2033544677604153e-05, 1.1197753380784437e-05, 1.0360559437940982e-05, 9.60272797657598e-06, 8.895086752531162e-06, 8.406772856870163e-06, 7.915487606802515e-06, 7.3441941639383e-06, 6.887518500073019e-06, 6.404227696092143e-06, 5.847663821647483e-06, 5.3719055575737445e-06, 4.985125715118203e-06, 4.782703211145182e-06, 4.572596859790913e-06, 4.217466365482776e-06, 3.9783427473324205e-06, 3.712459620316218e-06, 3.4824046140560582e-06, 3.154667644547446e-06, 2.9832627638835418e-06, 2.7925736678064804e-06, 2.626751343272342e-06, 2.542092656597261e-06, 2.3525407275231237e-06, 2.2527362332123644e-06, 2.1112025828353346e-06, 2.0774921397313096e-06, 2.023961599188853e-06, 1.936889131867079e-06, 1.8543021564525817e-06, 1.8442540716600722e-06, 1.7766656959609509e-06, 1.6697532671002064e-06, 1.5857892499348861e-06, 1.4301316417369883e-06, 1.3897781591257174e-06, 1.2925531965182346e-06, 1.227749068140378e-06, 1.1280695086974859e-06, 1.0242932300573197e-06, 1.0649591519921756e-06, 1.0077370015088235e-06, 9.188186250879071e-07, 8.293540399159089e-07, 8.957844168946713e-07, 8.795258743913295e-07, 8.010660370302264e-07, 7.85924314100808e-07, 8.997520881022496e-07, 8.099083583963761e-07, 7.455054770776964e-07, 6.895917414383832e-07, 6.242819910175359e-07, 5.71112483079947e-07, 5.893538736909703e-07, 5.950593396984561e-07, 6.467441665146922e-07, 6.38291943842829e-07, 6.29270720875802e-07, 6.941561448883348e-07, 7.42098883829612e-07, 7.388353795407072e-07, 7.741892384475422e-07, 7.65833519461855e-07, 7.666807120843753e-07, 7.753827470730355e-07, 7.380049305769203e-07, 7.999830019904271e-07, 7.209957660907821e-07, 7.861030087359999e-07, 7.479161266830193e-07, 6.904951266681264e-07, 6.810146792791559e-07, 7.57550834374534e-07, 7.349065689113991e-07, 6.961928359838338e-07, 6.765887239874736e-07, 6.170093082662719e-07, 5.574162744530902e-07, 5.753338235941858e-07, 6.20905698980255e-07, 6.13090244368194e-07, 5.627922256551078e-07, 5.251181896544577e-07, 4.997395671326332e-07, 5.365698803950098e-07, 5.496854812710332e-07, 5.147863124644469e-07, 4.874909558827954e-07, 5.418496821422339e-07, 5.522948482680634e-07, 5.462724352876294e-07, 5.050869615140286e-07, 6.412736537496723e-07, 6.465957264847459e-07, 6.257332534579145e-07, 6.615623180224194e-07, 6.295876027947639e-07, 5.734484132542985e-07, 5.280518111556973e-07, 5.533794668368202e-07, 5.196642563040693e-07, 5.617800214810784e-07, 6.66982235358976e-07, 6.255106238381571e-07, 6.315265642377018e-07, 6.145807074448676e-07, 6.185605406928515e-07, 5.663121047838725e-07, 5.494808713601531e-07, 6.150642310606318e-07, 6.468778581683122e-07, 6.187174893173941e-07, 7.602712590383127e-07, 8.116847024290978e-07, 7.587556379957559e-07, 7.101685215392153e-07, 7.181071207108637e-07, 6.726788101342513e-07, 6.247297618173246e-07, 6.693642603411062e-07, 6.097193305693922e-07, 6.56239024803511e-07, 5.932646280026544e-07, 5.764650803911137e-07, 5.394814320591056e-07, 6.003532351431191e-07, 6.247560135993234e-07, 5.849179329849397e-07, 5.873911471180331e-07, 5.343715232841188e-07, 4.816101428319016e-07, 5.292378319202547e-07, 5.142776072727921e-07, 4.789144768422543e-07, 4.598806337239369e-07, 4.1506941341552176e-07, 4.075018041393901e-07, 4.325359119831919e-07, 3.893420720206228e-07, 5.082213573209868e-07, 4.837493946363204e-07, 4.851216674980822e-07, 4.422613395239516e-07, 3.9869014935819625e-07, 3.674506699451522e-07, 3.716294767571007e-07, 3.6036313288076695e-07, 3.70513428336915e-07, 3.8866258651953374e-07, 3.611840432376912e-07, 3.301283180675347e-07, 3.181433411957899e-07, 2.870155310645874e-07, 3.0313180078229396e-07, 2.8019747991081754e-07, 2.534196801792913e-07, 2.897208872195231e-07, 2.7328236143734647e-07, 2.547087810296031e-07, 2.824576525153671e-07, 3.35007913855136e-07, 3.2230498314324983e-07, 3.245607904521695e-07, 3.449648909684085e-07, 3.6555986875700737e-07, 3.8609125300062223e-07, 3.478797498694739e-07, 3.782841065684885e-07, 3.544240894758133e-07, 3.409513947769066e-07, 3.0932577875751513e-07, 3.027990973314433e-07, 2.9861042393951703e-07, 3.2781358809610464e-07, 3.0373306479293457e-07, 2.8587067922253766e-07], "duration": 80802.999778, "accuracy_train": [0.12221612997185308, 0.15153265157807308, 0.16631771410114432, 0.17519725913621262, 0.18096326769564414, 0.18668097083794757, 0.1906795058139535, 0.19342426287375414, 0.19747002180232556, 0.19956193475452197, 0.20198008951642674, 0.2048382201112034, 0.206023685515873, 0.20720915092054265, 0.21027726588455148, 0.21178861261074194, 0.21336791136028058, 0.21513466396733114, 0.2158325690983758, 0.2165297532530454, 0.21725018889581027, 0.2184599872531377, 0.22008867288436693, 0.2202968548126615, 0.2210888473606497, 0.22185578597960504, 0.22222780978912884, 0.22380855049141749, 0.2243197227413252, 0.22455367957502767, 0.2251117152893134, 0.22545832468161683, 0.2258307089793282, 0.2265747565983758, 0.2271327923126615, 0.2280396003483758, 0.2291313388242894, 0.22906230533637875, 0.22961889909791436, 0.23145468519287563, 0.23131445528792913, 0.2315011881690661, 0.23298820194259873, 0.2321515088593577, 0.233941152466316, 0.2342434218115541, 0.23401126741878922, 0.23501036043050944, 0.23596331095422665, 0.23614932285898854, 0.23659110113279808, 0.2365217071566999, 0.23705577040651532, 0.23807775441814322, 0.2376359761443337, 0.2382183448112772, 0.23882180203719083, 0.2387756595491879, 0.23872951706118495, 0.23903214689461055, 0.2392639407991879, 0.2407058935492802, 0.24054349362080102, 0.24124031728728315, 0.24089118447766703, 0.24044976669204504, 0.24084576296603913, 0.24161270158499448, 0.2419611134182355, 0.24214712532299743, 0.24142632919204504, 0.24279816698966408, 0.2426590185492802, 0.24293731543004798, 0.24324030575166114, 0.24386701446566997, 0.24372822651347362, 0.2444948046442414, 0.24495947391795866, 0.24512259482281284, 0.244937303894426, 0.24486682845376523, 0.24542342221530083, 0.24523885226328904, 0.24579724846576229, 0.24623974771594687, 0.2459367573943337, 0.24621613573966408, 0.24672694750138427, 0.24621505427510154, 0.2466339415490033, 0.24658707808462535, 0.24675055947766703, 0.24684356543004798, 0.2474470226559616, 0.24751713760843486, 0.24730823470376523, 0.24765700702519378, 0.24758689207272058, 0.24719233775147656, 0.24742413165605392, 0.247726401001292, 0.24837672169158362, 0.24847044862033962, 0.24798216737033962, 0.2484479181086194, 0.24837672169158362, 0.24853948210825028, 0.24788952190614616, 0.24872513352482464, 0.24868007250138427, 0.24881849996539313, 0.24921449623938724, 0.24879632994186046, 0.24926027823920266, 0.24912076931063123, 0.24965663500138427, 0.2497020565130122, 0.24965591402500925, 0.24974819900101514, 0.25014419527500925, 0.250027216858158, 0.2498884289059616, 0.25005082883444074, 0.24900631431109266, 0.25023648025101514, 0.24995638092930972, 0.25018961678663715, 0.24993457139396455, 0.24979542295358068, 0.2507712644772056, 0.2503763496677741, 0.250073359346161, 0.2499105989294943, 0.2510513637989111, 0.25079451596530083, 0.2503069556916759, 0.25086427042958653, 0.2515618150724437, 0.2502840646917682, 0.2506789795011997, 0.25074765250092285, 0.25053947057262826, 0.2506789795011997, 0.2513053277270211, 0.2513293001914913, 0.2516780725129199, 0.2514680881436877, 0.25153712163159836, 0.252026484346161, 0.25209587832225916, 0.2519560089055002, 0.2522586387389258, 0.25214310227482467, 0.2522822507152086, 0.2524213991555925, 0.25221285673911037, 0.2528399259413068, 0.25184047244139907, 0.25297979535806575, 0.2525387380606312, 0.252374896179402, 0.25279306247692873, 0.2533285676794943, 0.2529558228935954, 0.2528860684293097, 0.25307208033407164, 0.25270077750092285, 0.25258415957225916, 0.2533510981912145, 0.2536072250484496, 0.25342049216731266, 0.2530713593576966, 0.2532112287744555, 0.2533510981912145, 0.25383901895302696, 0.2538164884413068, 0.2535134981196936, 0.2536068645602621, 0.2542106822743633, 0.2540947853220746, 0.2540715338339793, 0.25379251597683644, 0.25488497542912514, 0.2544671696197859, 0.25437416366740495, 0.2547919694767442, 0.2544671696197859, 0.2541877912744555, 0.25430440920311925, 0.25490822691722037, 0.2545598150839793, 0.2551411022863603, 0.2555599895602621, 0.2548842544527501, 0.2552806112149317, 0.2552115777270211, 0.2554193991671281, 0.2549787023578811, 0.2553496447028424, 0.2559084013935031, 0.2558851499054079, 0.2556057715600775, 0.25653583108388706, 0.25637271017903285, 0.25586189841731266, 0.2559084013935031, 0.2563494586909376, 0.2560479103220746, 0.2560239378576043, 0.25669787052417864, 0.25600068636950907, 0.2568373794527501, 0.2560253798103544, 0.25655836159560724, 0.2564188526670358, 0.25711711828626804, 0.25706917335732743, 0.2566989519887412, 0.2570706153100775, 0.25658197357189, 0.2564417436669435, 0.2573954151670358, 0.25711639730989294, 0.25695435786960136, 0.2571403697743633, 0.2567450944767442, 0.2572562667266519, 0.25755853607189, 0.2568148489410299, 0.25811585080980065, 0.25746516963132154, 0.2577216569767442, 0.2573031301910299, 0.2571629002860834, 0.2573957756552233, 0.2577914114410299, 0.25772093600036916, 0.25795453234588406, 0.25809295980989294, 0.25774382700027687, 0.2571865122623662, 0.25788333592884827, 0.2575356450719823, 0.25816271427417864, 0.2578139419527501, 0.25767371204780365, 0.2583955896433186, 0.2580239263219823, 0.257999953857512, 0.258488235107512, 0.2587436409883721, 0.25837161717884827, 0.2585579895717977, 0.25876725296465486, 0.25885989842884827, 0.2589521834048542, 0.25830186271456257, 0.2590931342861757, 0.2587211104766519, 0.2588606194052233, 0.25858160154808046, 0.2589532648694168, 0.2590230193337025, 0.2593485401670358, 0.25893037386950907, 0.25902337982189], "end": "2016-01-25 08:26:05.870000", "learning_rate_per_epoch": [0.0001652522332733497, 8.262611663667485e-05, 5.5084077757783234e-05, 4.1313058318337426e-05, 3.305044810986146e-05, 2.7542038878891617e-05, 2.360746293561533e-05, 2.0656529159168713e-05, 1.836135925259441e-05, 1.652522405493073e-05, 1.5022930710983928e-05, 1.3771019439445809e-05, 1.271171095140744e-05, 1.1803731467807665e-05, 1.1016815733455587e-05, 1.0328264579584356e-05, 9.720719390315935e-06, 9.180679626297206e-06, 8.69748600962339e-06, 8.262612027465366e-06, 7.869153705541976e-06, 7.511465355491964e-06, 7.184879905253183e-06, 6.885509719722904e-06, 6.610089712921763e-06, 6.35585547570372e-06, 6.120453235780587e-06, 5.901865733903833e-06, 5.698353106708964e-06, 5.508407866727794e-06, 5.330717158358311e-06, 5.164132289792178e-06, 5.007643721910426e-06, 4.8603596951579675e-06, 4.721492587123066e-06, 4.590339813148603e-06, 4.4662765503744595e-06, 4.348743004811695e-06, 4.237236680637579e-06, 4.131306013732683e-06, 4.030542186228558e-06, 3.934576852770988e-06, 3.843075319309719e-06, 3.755732677745982e-06, 3.6722719869430875e-06, 3.5924399526265915e-06, 3.516005108394893e-06, 3.442754859861452e-06, 3.37249457516009e-06, 3.3050448564608814e-06, 3.2402399483544286e-06, 3.17792773785186e-06, 3.11796679852705e-06, 3.0602266178902937e-06, 3.004586233146256e-06, 2.9509328669519164e-06, 2.899162154790247e-06, 2.849176553354482e-06, 2.8008853405481204e-06, 2.754203933363897e-06, 2.7090529783890815e-06, 2.6653585791791556e-06, 2.623051386763109e-06, 2.582066144896089e-06, 2.542342144806753e-06, 2.503821860955213e-06, 2.46645140578039e-06, 2.4301798475789838e-06, 2.3949598926265026e-06, 2.360746293561533e-06, 2.327496304133092e-06, 2.2951699065743014e-06, 2.2637293568550376e-06, 2.2331382751872297e-06, 2.2033632376405876e-06, 2.1743715024058474e-06, 2.1461330561578507e-06, 2.1186183403187897e-06, 2.0918005247949623e-06, 2.0656530068663415e-06, 2.040151002802304e-06, 2.015271093114279e-06, 1.9909907678083982e-06, 1.967288426385494e-06, 1.9441440599621274e-06, 1.9215376596548595e-06, 1.8994510355696548e-06, 1.877866338872991e-06, 1.8567667439128854e-06, 1.8361359934715438e-06, 1.815958626139036e-06, 1.7962199763132958e-06, 1.7769058331396081e-06, 1.7580025541974464e-06, 1.7394971791873104e-06, 1.721377429930726e-06, 1.703631255622895e-06, 1.686247287580045e-06, 1.669214498178917e-06, 1.6525224282304407e-06, 1.6361607322323835e-06, 1.6201199741772143e-06, 1.6043906043705647e-06, 1.58896386892593e-06, 1.5738307865831302e-06, 1.558983399263525e-06, 1.5444134078279603e-06, 1.5301133089451469e-06, 1.5160755992837949e-06, 1.502293116573128e-06, 1.488758925916045e-06, 1.4754664334759582e-06, 1.4624091591031174e-06, 1.4495810773951234e-06, 1.4369759355759015e-06, 1.424588276677241e-06, 1.4124123026704183e-06, 1.4004426702740602e-06, 1.3886742635804694e-06, 1.3771019666819484e-06, 1.3657210047313129e-06, 1.3545264891945408e-06, 1.3435140999717987e-06, 1.3326792895895778e-06, 1.3220178516348824e-06, 1.3115256933815544e-06, 1.301198722103436e-06, 1.2910330724480445e-06, 1.281025106436573e-06, 1.2711710724033765e-06, 1.2614674460564856e-06, 1.2519109304776066e-06, 1.24249800137477e-06, 1.233225702890195e-06, 1.22409062441875e-06, 1.2150899237894919e-06, 1.2062207588314777e-06, 1.1974799463132513e-06, 1.1888649851243827e-06, 1.1803731467807665e-06, 1.1720017027982976e-06, 1.163748152066546e-06, 1.1556101071619196e-06, 1.1475849532871507e-06, 1.1396706440791604e-06, 1.1318646784275188e-06, 1.1241648962823092e-06, 1.1165691375936149e-06, 1.1090754696851945e-06, 1.1016816188202938e-06, 1.0943856523226714e-06, 1.0871857512029237e-06, 1.0800799827848095e-06, 1.0730665280789253e-06, 1.0661434544090298e-06, 1.0593091701593949e-06, 1.0525619700274547e-06, 1.0459002623974811e-06, 1.0393222282800707e-06, 1.0328265034331707e-06, 1.0264113825542154e-06, 1.020075501401152e-06, 1.0138173820450902e-06, 1.0076355465571396e-06, 1.0015287443820853e-06, 9.954953839041991e-07, 9.89534328255104e-07, 9.83644213192747e-07, 9.778239018487511e-07, 9.720720299810637e-07, 9.663873470344697e-07, 9.607688298274297e-07, 9.552152278047288e-07, 9.497255177848274e-07, 9.442985060559295e-07, 9.389331694364955e-07, 9.336284847449861e-07, 9.283833719564427e-07, 9.231968647327449e-07, 9.180679967357719e-07, 9.129958016274031e-07, 9.07979313069518e-07, 9.030176784108335e-07, 8.981099881566479e-07, 8.932553328122594e-07, 8.884529165698041e-07, 8.8370182993458e-07, 8.790012770987232e-07, 8.743504622543696e-07, 8.697485895936552e-07, 8.651949769955536e-07, 8.60688714965363e-07, 8.562292350688949e-07, 8.518156278114475e-07, 8.47447381602251e-07, 8.431236437900225e-07, 8.388438459405734e-07, 8.346072490894585e-07, 8.304132279590704e-07, 8.262612141152204e-07, 8.221504117500444e-07, 8.180803661161917e-07, 8.140504519360547e-07, 8.100599870886072e-07, 8.061084599830792e-07, 8.021953021852823e-07, 7.983200021044468e-07, 7.94481934462965e-07, 7.906805876700673e-07, 7.869153932915651e-07, 7.831859534235264e-07, 7.794916996317625e-07, 7.758321203255036e-07, 7.722067039139802e-07, 7.6861505249326e-07, 7.650566544725734e-07, 7.615310551045695e-07, 7.580377996418974e-07, 7.545764333372063e-07, 7.51146558286564e-07, 7.477476628992008e-07, 7.443794629580225e-07, 7.410414468722593e-07, 7.377332167379791e-07, 7.3445437465125e-07, 7.312045795515587e-07, 7.279834335349733e-07, 7.247905386975617e-07, 7.216254971353919e-07, 7.184879677879508e-07, 7.153776664381439e-07, 7.122941383386205e-07, 7.092370424288674e-07, 7.062061513352091e-07, 7.032010103102948e-07, 7.002213351370301e-07, 6.972668415983208e-07, 6.943371317902347e-07, 6.914319783390965e-07, 6.885509833409742e-07, 6.856939194221923e-07, 6.828605023656564e-07, 6.800503342674347e-07, 6.772632445972704e-07, 6.744989491380693e-07, 6.717570499858994e-07, 6.69037376610504e-07, 6.663396447947889e-07, 6.636636271650787e-07, 6.610089258174412e-07, 6.583754270650388e-07, 6.557628466907772e-07, 6.531709004775621e-07, 6.50599361051718e-07, 6.480480010395695e-07, 6.455165362240223e-07, 6.430047960748198e-07, 6.405125532182865e-07, 6.380395234373282e-07, 6.355855362016882e-07, 6.331503072942724e-07, 6.307337230282428e-07, 6.283354991865053e-07, 6.259554652388033e-07, 6.235933369680424e-07, 6.21249000687385e-07, 6.189222290231555e-07], "accuracy_valid": [0.1180258141942771, 0.14866693335843373, 0.1659715032003012, 0.17468997082078314, 0.17823000988328314, 0.18274661144578314, 0.18569688911897592, 0.18996935005647592, 0.1967449877635542, 0.19920698418674698, 0.20117040427334337, 0.2046898531626506, 0.20704007435993976, 0.20862698842243976, 0.20998005694653615, 0.21133312547063254, 0.21242146319653615, 0.21512760024472893, 0.21573795180722893, 0.21747782144201808, 0.21769107680722893, 0.2199089326054217, 0.22211649331701808, 0.22138407144201808, 0.22285921027861444, 0.22410050357680722, 0.22446671451430722, 0.22609480892319278, 0.2280376388365964, 0.2274066971009036, 0.22927893213478917, 0.2288921310240964, 0.2302349044615964, 0.2306011153990964, 0.230224609375, 0.22983780826430722, 0.23019372411521083, 0.2320556640625, 0.23341902767319278, 0.23354109798569278, 0.23439559017319278, 0.2330219314759036, 0.2346294357115964, 0.2348529861634036, 0.235107421875, 0.2353515625, 0.2365825607115964, 0.2365825607115964, 0.2366943359375, 0.2369487716490964, 0.2364501953125, 0.2381591796875, 0.2392681075865964, 0.2391460372740964, 0.2384033203125, 0.2391357421875, 0.2398784591490964, 0.2403667403990964, 0.2396240234375, 0.2398784591490964, 0.24171980892319278, 0.2412212325865964, 0.2410888671875, 0.2421875, 0.2420654296875, 0.2412109375, 0.24130212255271083, 0.241455078125, 0.2410785721009036, 0.241455078125, 0.24080354621611444, 0.24288903661521083, 0.24225809487951808, 0.24228898013930722, 0.24167862857680722, 0.24180069888930722, 0.24312288215361444, 0.24410973974021083, 0.24337731786521083, 0.24424210513930722, 0.24324495246611444, 0.24238016519201808, 0.24287874152861444, 0.24276696630271083, 0.24534073795180722, 0.242919921875, 0.2437744140625, 0.244140625, 0.24521866763930722, 0.2455951736634036, 0.24435388036521083, 0.24520837255271083, 0.24521866763930722, 0.24459802099021083, 0.24412003482680722, 0.24496423192771083, 0.2455951736634036, 0.2460834549134036, 0.2455951736634036, 0.24509659732680722, 0.2464599609375, 0.24558487857680722, 0.24581872411521083, 0.2464496658509036, 0.24570694888930722, 0.2469379471009036, 0.2469482421875, 0.24495393684111444, 0.247314453125, 0.24558487857680722, 0.24484216161521083, 0.24692765201430722, 0.2477924392884036, 0.24630700536521083, 0.24619523013930722, 0.24606286474021083, 0.2473041580384036, 0.24741593326430722, 0.2470600174134036, 0.2474262283509036, 0.2481689453125, 0.2481586502259036, 0.24740563817771083, 0.24679528661521083, 0.2469482421875, 0.24692765201430722, 0.24680558170180722, 0.2479248046875, 0.2477924392884036, 0.24717179263930722, 0.24874841161521083, 0.2481586502259036, 0.2486572265625, 0.24668351138930722, 0.2490234375, 0.24853515625, 0.2481586502259036, 0.2484027908509036, 0.2501323653990964, 0.2486572265625, 0.2501220703125, 0.248291015625, 0.2492572830384036, 0.24887048192771083, 0.2491352127259036, 0.24936905826430722, 0.2501323653990964, 0.24874841161521083, 0.2506309417356928, 0.25, 0.2506103515625, 0.2503765060240964, 0.2519737151731928, 0.25048828125, 0.2509868575865964, 0.25048828125, 0.2493793533509036, 0.2518516448606928, 0.2509765625, 0.2520854903990964, 0.2522075607115964, 0.2513427734375, 0.2506000564759036, 0.2506103515625, 0.2518310546875, 0.250732421875, 0.2513427734375, 0.2518413497740964, 0.2518413497740964, 0.2511089278990964, 0.2523296310240964, 0.2507118317018072, 0.2506000564759036, 0.2514545486634036, 0.2512001129518072, 0.2509765625, 0.2530723479856928, 0.2506309417356928, 0.2513427734375, 0.2510883377259036, 0.25271643213478917, 0.25271643213478917, 0.2523193359375, 0.2524619964231928, 0.2525634765625, 0.2509662674134036, 0.25321500847138556, 0.25149572900978917, 0.2519428299134036, 0.25406950065888556, 0.2536826995481928, 0.25284879753388556, 0.252197265625, 0.25344885400978917, 0.2519634200865964, 0.25283850244728917, 0.2525737716490964, 0.25333707878388556, 0.2530620528990964, 0.25296057275978917, 0.25320471338478917, 0.25430334619728917, 0.25406950065888556, 0.2542018660579819, 0.25419157097138556, 0.25518872364457834, 0.25283850244728917, 0.25491369775978917, 0.25382536003388556, 0.2529399825865964, 0.25454748682228917, 0.25369299463478917, 0.2531944182981928, 0.25344885400978917, 0.25382536003388556, 0.2535606292356928, 0.2560329207454819, 0.2533164886106928, 0.25541227409638556, 0.25357092432228917, 0.2537135848079819, 0.25357092432228917, 0.2531841232115964, 0.25431364128388556, 0.25320471338478917, 0.2529399825865964, 0.25357092432228917, 0.25406950065888556, 0.25455778190888556, 0.25358121940888556, 0.25381506494728917, 0.2534385589231928, 0.2542018660579819, 0.2541606857115964, 0.25393713525978917, 0.25283850244728917, 0.2553210890436747, 0.2543239363704819, 0.2549034026731928, 0.2543239363704819, 0.25332678369728917, 0.25345914909638556, 0.2524619964231928, 0.25506665333207834, 0.25406950065888556, 0.2532253035579819, 0.25309293815888556, 0.25345914909638556, 0.25369299463478917, 0.25419157097138556, 0.25494458301957834, 0.25283850244728917, 0.25344885400978917, 0.25406950065888556, 0.25421216114457834, 0.25382536003388556, 0.25393713525978917, 0.2536826995481928, 0.25406950065888556, 0.2529502776731928, 0.25396802051957834, 0.2534385589231928, 0.2540797957454819, 0.2548122176204819, 0.25358121940888556, 0.25443571159638556, 0.25357092432228917], "accuracy_test": 0.258675462372449, "start": "2016-01-24 09:59:22.870000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0], "accuracy_train_last": 0.25902337982189, "batch_size_eval": 1024, "accuracy_train_std": [0.010790455741305731, 0.012174939522519516, 0.013053011451020774, 0.013093811546772865, 0.01352125371150709, 0.012828085698434027, 0.013350645596717583, 0.014178071316614763, 0.014419464081898998, 0.014638745234217963, 0.015183434185581332, 0.014909342789844819, 0.014162750116599558, 0.014220511297529714, 0.013998651299065305, 0.014144119454849814, 0.013417578093289556, 0.013273996398109965, 0.012986620807841997, 0.012980407563376801, 0.01256626252336182, 0.012500309053681335, 0.01334597505741387, 0.012951136573468783, 0.013289174655974081, 0.013352876127215642, 0.013010194172303674, 0.012789506144835906, 0.012527732614106247, 0.013346080763473128, 0.012742949956086025, 0.011632783055787483, 0.01209848123223445, 0.012308344134437767, 0.01246387796799955, 0.01273531559829849, 0.011919593537798857, 0.012483455683336926, 0.011854779738674503, 0.010984187715456955, 0.01132840855516271, 0.01167936977227024, 0.010442103240636252, 0.011703814604843713, 0.010562844171506576, 0.010608454951186088, 0.01103096321866049, 0.010604327844832636, 0.010112998266791035, 0.010315794472823546, 0.010861927401756177, 0.010500856231291374, 0.010554137914913933, 0.01032981852836248, 0.009753761478518308, 0.010695153171738183, 0.010240356809301835, 0.01003478058513782, 0.010555432540000324, 0.011138539308144022, 0.010920321703026457, 0.011095481044144715, 0.011294865049761217, 0.01115271466629988, 0.011108134414938724, 0.010974696349428239, 0.011160118515343919, 0.011269221150879234, 0.01163523820749239, 0.011081676655102304, 0.011695327836138945, 0.011358572424384537, 0.011139274669132714, 0.011225305875711708, 0.01169803382125017, 0.011336214355010553, 0.011249982794478999, 0.01138096579293559, 0.011497681515778643, 0.011482324186510661, 0.011860652648532827, 0.01133528434872722, 0.011785505316896093, 0.011827502452986796, 0.012676785743861736, 0.012405180000557457, 0.01187665331950118, 0.012138101393569727, 0.01172388709072363, 0.01153121867158302, 0.011798030807676224, 0.012043557869992234, 0.012039089520546276, 0.012076976129657649, 0.011848357424169141, 0.011741399917533289, 0.011888995956775915, 0.012121947574017333, 0.011795463348053085, 0.012056849766301536, 0.012021640104214549, 0.0119701127348016, 0.01203332230384656, 0.011896495472889372, 0.012317281047100219, 0.012633540932367215, 0.011559811081825348, 0.012202995702131634, 0.011940391820327492, 0.011481852021511554, 0.012136022444119121, 0.012168024370972379, 0.01199331003586915, 0.012374955674100003, 0.011682854894944661, 0.01211794057504997, 0.01229913936432803, 0.012299403958555383, 0.012022267889582829, 0.011789003916391944, 0.011924886969529022, 0.01144178037307264, 0.011658540398452136, 0.011283408518462512, 0.01223597870321613, 0.011458210159069138, 0.011064934151042684, 0.011312799762798767, 0.011175151525090547, 0.01137333194524182, 0.011021101702889176, 0.01138345925520217, 0.011341211917231177, 0.011209189140516555, 0.011499897482587656, 0.011301238215439964, 0.010962311978229734, 0.01149635986935539, 0.0116020074127324, 0.011326940665266103, 0.011280657552738133, 0.011494953422849414, 0.011382338662713737, 0.01143856926255827, 0.01097426378651559, 0.01160749096808948, 0.011442791089688596, 0.010877751906771985, 0.010609165827678376, 0.010959779352680285, 0.011213310805555144, 0.010720552293341774, 0.011076588982281033, 0.01126857049104219, 0.01125665350194637, 0.010941963490360876, 0.011027840987003256, 0.011316377074229278, 0.011211389796297619, 0.011210517100017744, 0.011611942869320966, 0.011131062100529273, 0.011252667281107992, 0.01126316049778543, 0.010835079419221887, 0.011186628341206355, 0.010999531437474376, 0.011188014749395557, 0.011158869631011838, 0.010880260806040798, 0.011092582084170384, 0.01090863946999112, 0.010522577225253025, 0.010854508439779512, 0.010697155638476263, 0.010406022661769447, 0.010421960590508275, 0.010459786774435724, 0.011324703656940249, 0.010476747786106053, 0.010810183044808531, 0.010652934389831415, 0.010916777329759651, 0.01047121460252129, 0.010686235827048342, 0.010635345981263217, 0.010164923598438286, 0.011235216854297238, 0.010527193988245871, 0.010823337728044594, 0.010325973337613021, 0.010208179503991664, 0.010899515085250366, 0.010536892184304501, 0.010355149792791597, 0.010945218700154023, 0.010440806486864572, 0.010444241468535752, 0.010539898470902219, 0.009786624844029751, 0.009967642657469094, 0.010392633344354736, 0.010174239867727064, 0.009917333672682807, 0.009436800545209073, 0.010226377637047925, 0.01030147787879066, 0.010119548873853636, 0.010513695099727433, 0.010161405088762909, 0.010316608557417253, 0.010425359773162052, 0.009911191058162057, 0.010717966125139412, 0.010106978351826465, 0.010059386255535934, 0.010269939274996469, 0.010353539839315848, 0.01106561607239759, 0.010345998540665997, 0.010044757341310722, 0.009923561858926327, 0.009893092638200724, 0.010211944772092417, 0.010432120542223458, 0.010109945714738408, 0.009913444046447489, 0.01027059993631439, 0.010301268458896253, 0.01023945155502621, 0.009935793226885344, 0.010141692197179725, 0.010431106314013503, 0.010456041117578804, 0.010404418224298582, 0.010215155092873667, 0.01066291193345202, 0.010250750336254102, 0.010881165368480874, 0.010317985594253811, 0.010042453913322527, 0.01028536673587111, 0.01022394429419728, 0.010390743990316418, 0.01053258914643565, 0.010437738005493587, 0.010146954618224189, 0.010320941427368755, 0.01042827041115432, 0.010191682287223712, 0.010183254916855147, 0.010240628754164347, 0.010093694562034855, 0.010157170858068823, 0.0101026237079199, 0.010261527506226229, 0.010107806376253867, 0.010720132250200444, 0.010565275346299353, 0.010718759242786114, 0.010175363930597358, 0.010189111978137131, 0.010556373572280377, 0.010641826847605116, 0.010411699182325913, 0.01112246775547435, 0.010397003066561024], "accuracy_test_std": 0.010827158027640678, "error_valid": [0.8819741858057228, 0.8513330666415663, 0.8340284967996988, 0.8253100291792168, 0.8217699901167168, 0.8172533885542168, 0.8143031108810241, 0.8100306499435241, 0.8032550122364458, 0.800793015813253, 0.7988295957266567, 0.7953101468373494, 0.7929599256400602, 0.7913730115775602, 0.7900199430534638, 0.7886668745293675, 0.7875785368034638, 0.7848723997552711, 0.7842620481927711, 0.7825221785579819, 0.7823089231927711, 0.7800910673945783, 0.7778835066829819, 0.7786159285579819, 0.7771407897213856, 0.7758994964231928, 0.7755332854856928, 0.7739051910768072, 0.7719623611634037, 0.7725933028990963, 0.7707210678652108, 0.7711078689759037, 0.7697650955384037, 0.7693988846009037, 0.769775390625, 0.7701621917356928, 0.7698062758847892, 0.7679443359375, 0.7665809723268072, 0.7664589020143072, 0.7656044098268072, 0.7669780685240963, 0.7653705642884037, 0.7651470138365963, 0.764892578125, 0.7646484375, 0.7634174392884037, 0.7634174392884037, 0.7633056640625, 0.7630512283509037, 0.7635498046875, 0.7618408203125, 0.7607318924134037, 0.7608539627259037, 0.7615966796875, 0.7608642578125, 0.7601215408509037, 0.7596332596009037, 0.7603759765625, 0.7601215408509037, 0.7582801910768072, 0.7587787674134037, 0.7589111328125, 0.7578125, 0.7579345703125, 0.7587890625, 0.7586978774472892, 0.758544921875, 0.7589214278990963, 0.758544921875, 0.7591964537838856, 0.7571109633847892, 0.7577419051204819, 0.7577110198606928, 0.7583213714231928, 0.7581993011106928, 0.7568771178463856, 0.7558902602597892, 0.7566226821347892, 0.7557578948606928, 0.7567550475338856, 0.7576198348079819, 0.7571212584713856, 0.7572330336972892, 0.7546592620481928, 0.757080078125, 0.7562255859375, 0.755859375, 0.7547813323606928, 0.7544048263365963, 0.7556461196347892, 0.7547916274472892, 0.7547813323606928, 0.7554019790097892, 0.7558799651731928, 0.7550357680722892, 0.7544048263365963, 0.7539165450865963, 0.7544048263365963, 0.7549034026731928, 0.7535400390625, 0.7544151214231928, 0.7541812758847892, 0.7535503341490963, 0.7542930511106928, 0.7530620528990963, 0.7530517578125, 0.7550460631588856, 0.752685546875, 0.7544151214231928, 0.7551578383847892, 0.7530723479856928, 0.7522075607115963, 0.7536929946347892, 0.7538047698606928, 0.7539371352597892, 0.7526958419615963, 0.7525840667356928, 0.7529399825865963, 0.7525737716490963, 0.7518310546875, 0.7518413497740963, 0.7525943618222892, 0.7532047133847892, 0.7530517578125, 0.7530723479856928, 0.7531944182981928, 0.7520751953125, 0.7522075607115963, 0.7528282073606928, 0.7512515883847892, 0.7518413497740963, 0.7513427734375, 0.7533164886106928, 0.7509765625, 0.75146484375, 0.7518413497740963, 0.7515972091490963, 0.7498676346009037, 0.7513427734375, 0.7498779296875, 0.751708984375, 0.7507427169615963, 0.7511295180722892, 0.7508647872740963, 0.7506309417356928, 0.7498676346009037, 0.7512515883847892, 0.7493690582643072, 0.75, 0.7493896484375, 0.7496234939759037, 0.7480262848268072, 0.74951171875, 0.7490131424134037, 0.74951171875, 0.7506206466490963, 0.7481483551393072, 0.7490234375, 0.7479145096009037, 0.7477924392884037, 0.7486572265625, 0.7493999435240963, 0.7493896484375, 0.7481689453125, 0.749267578125, 0.7486572265625, 0.7481586502259037, 0.7481586502259037, 0.7488910721009037, 0.7476703689759037, 0.7492881682981928, 0.7493999435240963, 0.7485454513365963, 0.7487998870481928, 0.7490234375, 0.7469276520143072, 0.7493690582643072, 0.7486572265625, 0.7489116622740963, 0.7472835678652108, 0.7472835678652108, 0.7476806640625, 0.7475380035768072, 0.7474365234375, 0.7490337325865963, 0.7467849915286144, 0.7485042709902108, 0.7480571700865963, 0.7459304993411144, 0.7463173004518072, 0.7471512024661144, 0.747802734375, 0.7465511459902108, 0.7480365799134037, 0.7471614975527108, 0.7474262283509037, 0.7466629212161144, 0.7469379471009037, 0.7470394272402108, 0.7467952866152108, 0.7456966538027108, 0.7459304993411144, 0.7457981339420181, 0.7458084290286144, 0.7448112763554217, 0.7471614975527108, 0.7450863022402108, 0.7461746399661144, 0.7470600174134037, 0.7454525131777108, 0.7463070053652108, 0.7468055817018072, 0.7465511459902108, 0.7461746399661144, 0.7464393707643072, 0.7439670792545181, 0.7466835113893072, 0.7445877259036144, 0.7464290756777108, 0.7462864151920181, 0.7464290756777108, 0.7468158767884037, 0.7456863587161144, 0.7467952866152108, 0.7470600174134037, 0.7464290756777108, 0.7459304993411144, 0.7454422180911144, 0.7464187805911144, 0.7461849350527108, 0.7465614410768072, 0.7457981339420181, 0.7458393142884037, 0.7460628647402108, 0.7471614975527108, 0.7446789109563253, 0.7456760636295181, 0.7450965973268072, 0.7456760636295181, 0.7466732163027108, 0.7465408509036144, 0.7475380035768072, 0.7449333466679217, 0.7459304993411144, 0.7467746964420181, 0.7469070618411144, 0.7465408509036144, 0.7463070053652108, 0.7458084290286144, 0.7450554169804217, 0.7471614975527108, 0.7465511459902108, 0.7459304993411144, 0.7457878388554217, 0.7461746399661144, 0.7460628647402108, 0.7463173004518072, 0.7459304993411144, 0.7470497223268072, 0.7460319794804217, 0.7465614410768072, 0.7459202042545181, 0.7451877823795181, 0.7464187805911144, 0.7455642884036144, 0.7464290756777108], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.6558330135986696, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.00016525223721331435, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "nesterov_momentum", "nb_data_augmentation": 2, "learning_rate_decay_method": "lin", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 1.9630843818562245e-05, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.0748307329826976}, "accuracy_valid_max": 0.2560329207454819, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.25357092432228917, "loss_train": [2.642247438430786, 2.55688738822937, 2.520677328109741, 2.5025475025177, 2.48972487449646, 2.479872465133667, 2.4716224670410156, 2.4645912647247314, 2.4593353271484375, 2.4543817043304443, 2.4495880603790283, 2.4457507133483887, 2.441765308380127, 2.4390125274658203, 2.435513734817505, 2.432687282562256, 2.429781913757324, 2.427457094192505, 2.4245998859405518, 2.422327756881714, 2.4203720092773438, 2.418630838394165, 2.4166767597198486, 2.414869785308838, 2.4127860069274902, 2.4107303619384766, 2.4095542430877686, 2.4079976081848145, 2.406670093536377, 2.405421495437622, 2.403618335723877, 2.4025635719299316, 2.401742935180664, 2.399724245071411, 2.398820400238037, 2.3978147506713867, 2.396564245223999, 2.395197629928589, 2.394843578338623, 2.3932688236236572, 2.391867160797119, 2.391932964324951, 2.3903510570526123, 2.389392614364624, 2.3886077404022217, 2.3872928619384766, 2.3861870765686035, 2.3858203887939453, 2.3849833011627197, 2.3842406272888184, 2.3835957050323486, 2.3825058937072754, 2.382324457168579, 2.381580352783203, 2.3803582191467285, 2.3796610832214355, 2.3790886402130127, 2.378304958343506, 2.3781328201293945, 2.3770053386688232, 2.3760552406311035, 2.375743865966797, 2.375572443008423, 2.3744115829467773, 2.3736636638641357, 2.3732903003692627, 2.372927665710449, 2.3727023601531982, 2.371814012527466, 2.370487689971924, 2.3707637786865234, 2.3692104816436768, 2.3691258430480957, 2.3685784339904785, 2.3681325912475586, 2.3680272102355957, 2.3673171997070312, 2.3668057918548584, 2.3663628101348877, 2.366107702255249, 2.3658084869384766, 2.364924430847168, 2.3649518489837646, 2.364240884780884, 2.3639492988586426, 2.3626394271850586, 2.362621784210205, 2.36264967918396, 2.3613197803497314, 2.361518144607544, 2.361393451690674, 2.360917091369629, 2.360649585723877, 2.3600380420684814, 2.359530210494995, 2.358929395675659, 2.358872652053833, 2.358879804611206, 2.3575899600982666, 2.357736110687256, 2.3568801879882812, 2.3570563793182373, 2.3567771911621094, 2.356288433074951, 2.3555502891540527, 2.3558380603790283, 2.355363368988037, 2.3548336029052734, 2.3547661304473877, 2.3544363975524902, 2.3540163040161133, 2.3534462451934814, 2.3532474040985107, 2.352931261062622, 2.3525545597076416, 2.3526222705841064, 2.3522908687591553, 2.3517611026763916, 2.352092981338501, 2.351531744003296, 2.351038694381714, 2.3503756523132324, 2.3503236770629883, 2.3498387336730957, 2.3494045734405518, 2.3498754501342773, 2.3492276668548584, 2.348667860031128, 2.3487422466278076, 2.3484466075897217, 2.348008394241333, 2.3480751514434814, 2.3474080562591553, 2.347824811935425, 2.3471643924713135, 2.346266031265259, 2.3468029499053955, 2.345643997192383, 2.34604811668396, 2.3456032276153564, 2.3457138538360596, 2.345705986022949, 2.3454792499542236, 2.3453800678253174, 2.3442485332489014, 2.3439292907714844, 2.344374418258667, 2.3441686630249023, 2.344529628753662, 2.343658208847046, 2.342832088470459, 2.3434793949127197, 2.3430371284484863, 2.342444658279419, 2.342137575149536, 2.3419907093048096, 2.34212064743042, 2.3415520191192627, 2.3417880535125732, 2.341507911682129, 2.341533660888672, 2.340893268585205, 2.341344118118286, 2.3413076400756836, 2.3405590057373047, 2.3403594493865967, 2.3403940200805664, 2.3395652770996094, 2.3397161960601807, 2.339165210723877, 2.3396291732788086, 2.3388020992279053, 2.3385162353515625, 2.3389642238616943, 2.3386380672454834, 2.3384909629821777, 2.3378963470458984, 2.3380792140960693, 2.337664842605591, 2.338453531265259, 2.337233781814575, 2.3377814292907715, 2.3369462490081787, 2.3368537425994873, 2.3371119499206543, 2.3369622230529785, 2.336625099182129, 2.335840940475464, 2.336815595626831, 2.3364925384521484, 2.335871696472168, 2.3361947536468506, 2.3362667560577393, 2.335064172744751, 2.3352572917938232, 2.3354551792144775, 2.334955930709839, 2.335245132446289, 2.3349826335906982, 2.334486722946167, 2.334198236465454, 2.33396315574646, 2.3342928886413574, 2.3336668014526367, 2.333693265914917, 2.3339226245880127, 2.333625316619873, 2.333137273788452, 2.333096504211426, 2.3330564498901367, 2.3337042331695557, 2.332134962081909, 2.332310199737549, 2.3330800533294678, 2.3325741291046143, 2.332686424255371, 2.332618236541748, 2.332158327102661, 2.3317441940307617, 2.3319528102874756, 2.331636667251587, 2.3316779136657715, 2.3308818340301514, 2.331831693649292, 2.3308403491973877, 2.3319334983825684, 2.330988883972168, 2.331040382385254, 2.3308193683624268, 2.3305037021636963, 2.330393075942993, 2.330975294113159, 2.3302342891693115, 2.3303017616271973, 2.3299174308776855, 2.3302547931671143, 2.330221652984619, 2.329561948776245, 2.3301568031311035, 2.3297243118286133, 2.32942271232605, 2.328817129135132, 2.329211950302124, 2.3286166191101074, 2.3288867473602295, 2.328871250152588, 2.3284621238708496, 2.3284687995910645, 2.328688621520996, 2.3285701274871826, 2.3287084102630615, 2.3283114433288574, 2.3275647163391113, 2.327709436416626, 2.3280248641967773, 2.327777624130249, 2.327725648880005, 2.3274986743927, 2.327411413192749, 2.32773756980896, 2.3276922702789307, 2.3266921043395996, 2.327458381652832, 2.327468156814575, 2.3274667263031006, 2.3270423412323, 2.326645851135254], "accuracy_train_first": 0.12221612997185308, "model": "residualv5", "loss_std": [0.057632025331258774, 0.03843066841363907, 0.03662186115980148, 0.038106296211481094, 0.039506860077381134, 0.04094209149479866, 0.0414954274892807, 0.041762929409742355, 0.04288123920559883, 0.043737173080444336, 0.04421482980251312, 0.04378898814320564, 0.04467342048883438, 0.04484895244240761, 0.04471832141280174, 0.045198339968919754, 0.04559238255023956, 0.04679020494222641, 0.04641713947057724, 0.04629581794142723, 0.04640635475516319, 0.04723251983523369, 0.04737277701497078, 0.04789292439818382, 0.04764974117279053, 0.04811561852693558, 0.048223573714494705, 0.04847640544176102, 0.04838893562555313, 0.0488893948495388, 0.048475898802280426, 0.04898753762245178, 0.048327889293432236, 0.04829223081469536, 0.049130626022815704, 0.04893212392926216, 0.049775995314121246, 0.04982571303844452, 0.04974899813532829, 0.04925556853413582, 0.05021534487605095, 0.05030958354473114, 0.05022820830345154, 0.05041616037487984, 0.051030490547418594, 0.050469573587179184, 0.05108030140399933, 0.0513433963060379, 0.05098794400691986, 0.051168251782655716, 0.050992973148822784, 0.051149412989616394, 0.051181335002183914, 0.050820402801036835, 0.0522555410861969, 0.051894571632146835, 0.05158672481775284, 0.05187852308154106, 0.05193858966231346, 0.05159403756260872, 0.051599014550447464, 0.05190277099609375, 0.05210269242525101, 0.05254008248448372, 0.0527009479701519, 0.05214575305581093, 0.05216235667467117, 0.05181576684117317, 0.05198215693235397, 0.05235392600297928, 0.052440524101257324, 0.05271713808178902, 0.05274535343050957, 0.05207908898591995, 0.05265769734978676, 0.05303196609020233, 0.052709102630615234, 0.05304171144962311, 0.0529380738735199, 0.052630968391895294, 0.05301787704229355, 0.05299418792128563, 0.05227896198630333, 0.05310631915926933, 0.05340554937720299, 0.05315247178077698, 0.05271507427096367, 0.053301192820072174, 0.05333941802382469, 0.05337942764163017, 0.053826771676540375, 0.05369706451892853, 0.05303756147623062, 0.05394025146961212, 0.05324451997876167, 0.05374573916196823, 0.054427359253168106, 0.054345183074474335, 0.053712546825408936, 0.05406676232814789, 0.05371381714940071, 0.053982872515916824, 0.05422494560480118, 0.05369607359170914, 0.05395152047276497, 0.05375128611922264, 0.05424350127577782, 0.054036945104599, 0.054356519132852554, 0.05365252122282982, 0.05420226976275444, 0.05492858588695526, 0.054670415818691254, 0.05453022941946983, 0.05467664450407028, 0.054779861122369766, 0.054258573800325394, 0.054096512496471405, 0.05460153892636299, 0.05460692197084427, 0.05425799638032913, 0.05518924444913864, 0.05458070710301399, 0.05419577658176422, 0.054537467658519745, 0.05435578525066376, 0.054137323051691055, 0.05502823367714882, 0.05487605556845665, 0.05438133329153061, 0.05516473576426506, 0.054593123495578766, 0.0550810769200325, 0.05544748902320862, 0.05533920228481293, 0.054919157177209854, 0.05535011738538742, 0.055387042462825775, 0.055073413997888565, 0.054630015045404434, 0.05553979054093361, 0.054713331162929535, 0.05539758875966072, 0.055612556636333466, 0.05561656877398491, 0.05533284321427345, 0.05549120903015137, 0.0549207367002964, 0.05538928508758545, 0.055806756019592285, 0.056148067116737366, 0.055216800421476364, 0.05558815971016884, 0.05512790009379387, 0.05553922802209854, 0.055599719285964966, 0.055721934884786606, 0.056043557822704315, 0.0550466850399971, 0.05544188991189003, 0.05522194132208824, 0.055617038160562515, 0.0558411180973053, 0.055958010256290436, 0.056093018501996994, 0.05602584779262543, 0.054913703352212906, 0.055793315172195435, 0.05553460121154785, 0.05604756250977516, 0.05630789324641228, 0.05594167485833168, 0.05591785907745361, 0.055900607258081436, 0.05607644468545914, 0.05612359195947647, 0.0560910664498806, 0.056021224707365036, 0.05548916757106781, 0.05532870069146156, 0.056244950741529465, 0.0561312735080719, 0.05613024905323982, 0.05619603022933006, 0.056244608014822006, 0.055961724370718, 0.05616597831249237, 0.05575922131538391, 0.055356383323669434, 0.05616801232099533, 0.056597672402858734, 0.05636419355869293, 0.05625089630484581, 0.056390728801488876, 0.0563776008784771, 0.05618257820606232, 0.05626709386706352, 0.05572482943534851, 0.05565440282225609, 0.05672813206911087, 0.05669878423213959, 0.056099601089954376, 0.05674193799495697, 0.05593720078468323, 0.056312765926122665, 0.05615510046482086, 0.056790534406900406, 0.056685663759708405, 0.056434132158756256, 0.056774672120809555, 0.05711900070309639, 0.05642745643854141, 0.05647217482328415, 0.05645985156297684, 0.05625705048441887, 0.056239329278469086, 0.05678715929389, 0.0558108426630497, 0.056674085557460785, 0.0564793236553669, 0.05707671493291855, 0.0563400462269783, 0.056168053299188614, 0.05658867210149765, 0.05618258938193321, 0.05675233155488968, 0.056889694184064865, 0.05674159526824951, 0.056921008974313736, 0.05574611574411392, 0.05654028430581093, 0.057237520813941956, 0.057246606796979904, 0.057047199457883835, 0.05655183643102646, 0.056517742574214935, 0.05693066120147705, 0.056799814105033875, 0.056599490344524384, 0.056580379605293274, 0.05681980028748512, 0.056809499859809875, 0.05712364614009857, 0.0566343255341053, 0.05658005550503731, 0.056381955742836, 0.05623302981257439, 0.05712849646806717, 0.05706676468253136, 0.056806109845638275, 0.057150933891534805, 0.05730506777763367, 0.0567244291305542, 0.05692540481686592, 0.05640103295445442, 0.057301267981529236, 0.057170335203409195, 0.057210784405469894, 0.057768601924180984, 0.057371899485588074, 0.05684392526745796, 0.05712899938225746, 0.0569886639714241, 0.05765115097165108, 0.056542959064245224, 0.056771449744701385, 0.05677775666117668]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:13 2016", "state": "available"}], "summary": "68ee3395777cc351e889bb905def50c3"}