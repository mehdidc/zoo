{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 32, "nonlin": "rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "accuracy_valid_std": [0.028833321761261584, 0.019017216517321633, 0.021121648646412517, 0.020850062632832272, 0.02215298614569528, 0.024872120617131437, 0.025737613581912917, 0.029328133083418598, 0.02637447384210144, 0.026075043725275446, 0.027423438797735546, 0.025202382973769442, 0.027767231056738485, 0.024622917764136304, 0.025538823639467995, 0.025583704435589008, 0.024760526417062858, 0.02320619488467226, 0.022140861250251137, 0.021381809920630393, 0.023188528089646516, 0.022543031641178792, 0.02243248414502307, 0.0223845153250341, 0.022999903415178432, 0.02315252409839118, 0.023770879141696157, 0.024419729987269403, 0.023420628884837723, 0.02465541607820132, 0.02444757308843666, 0.02459963837659804, 0.023875527586059594, 0.024284608626621122, 0.022455071113515548, 0.02127109599210522, 0.02259697678423957, 0.0215126650433315, 0.020414791287188355, 0.024072223313581297, 0.023294188314723283, 0.02501671146424414, 0.022745406554180735, 0.022427002717306844, 0.024872662020088598, 0.022338279528175176, 0.023133638458981393, 0.02276881256900915, 0.02265009160070585, 0.0224173543105605, 0.020058545284510915, 0.022681268172590523, 0.0228488363040269, 0.021870815225355757, 0.021401148347846625, 0.020794721687331777, 0.018593836762451764, 0.019987877552955433, 0.01947164223282776, 0.02010474711039965, 0.018812767762825613, 0.018047352902743927, 0.01861725895464855, 0.019435289840008908, 0.01826615224281141, 0.01787884085840332, 0.017894224797487483, 0.018409273909861124, 0.01745056830857008, 0.016877218126018338, 0.0188732471940999, 0.018404697062599187, 0.016927706226804902, 0.01646190121650209, 0.01723601463083143, 0.017103422642408862, 0.017600107613314438, 0.01655437113282068, 0.01671178403364574, 0.01639807057475946, 0.016452988804399545, 0.0173106893501841, 0.017037024551788984, 0.01634661702117108, 0.0166027504523283, 0.017520470055783076, 0.017169692838398767, 0.016353907992157152, 0.016572963189866976, 0.017435214284281627, 0.015742796356046678, 0.015599927694611288, 0.01599316612829969, 0.016192867999147938, 0.016513122942272078, 0.01610618970234543, 0.016415028672105474, 0.01603184965175107, 0.015244353519662274, 0.015723827986312503, 0.01704964937857247, 0.015044262176644046, 0.015798915065793367, 0.015547787667867966, 0.016002909371028558, 0.016675322722156424, 0.015167366635244792, 0.014963898881732333, 0.014631013423465716, 0.014385178481023535, 0.016312906533165472, 0.016426074477341915, 0.014939123834844609, 0.016201469777159305, 0.015530434219593716, 0.01490717098031736, 0.01607144674801476, 0.014758385781581037, 0.01469362454417428, 0.014478987676251748, 0.015560483474054804, 0.01395644927480148, 0.015508604989453115, 0.014592217257716172, 0.014764132506757992, 0.014179492772359444, 0.015444478697419493, 0.014902702958737158, 0.014621757537684238, 0.014937640314445078, 0.014978297842455982, 0.014473824758442552, 0.014048596581207221, 0.015582465390860958, 0.013895521341359995, 0.014674943007110012, 0.01427405556606907, 0.013669492772174724, 0.013644898141823734, 0.013921641470595594, 0.014727979813532993, 0.014187182480585219, 0.014631816242059241, 0.014732872496689682, 0.014452266169609065, 0.014827907799784566, 0.01354343802469994, 0.01438062867392397, 0.0144395531948729, 0.013801955224709998, 0.014152205785303237, 0.013570579038986848, 0.013941164289794621, 0.014202656091878723, 0.01474837152818376, 0.01368150569028939, 0.015027232290499197, 0.014128241811482176, 0.013890378174347169, 0.014699561469988997, 0.014610316454088694, 0.013409580053057268, 0.013836701437047422, 0.013981895342601688, 0.014031493777717152, 0.012950279282524428, 0.01490861611053938, 0.014303575141722619, 0.013659661928408399, 0.01437948631522812, 0.012911446579206282, 0.013399783708036893, 0.014168720169547818, 0.013614160611829889, 0.013942304707633161, 0.014385241634463333, 0.012625673539485223, 0.013756940906424842, 0.013914024359253662, 0.014605504896566139, 0.013376926290836722, 0.014651209099787193, 0.012754711985832782, 0.0146050001719999, 0.013976061447136479, 0.014002028089323373, 0.01347979961022556, 0.01394292921772752, 0.013384098714360335, 0.012924242357371735, 0.014373435919125118, 0.013741010329309068, 0.012631090902519449, 0.014146895781520194, 0.012770135865542214, 0.012542142301188254, 0.013968092375101151, 0.014064976560308086, 0.012815956305457702, 0.013430289217477338, 0.014524220947351259, 0.013508676701123675, 0.013591301265880889, 0.014764528434445324, 0.013435494927312322, 0.013588380893171475, 0.013992375539187554, 0.014610488485549241, 0.012601925798576961, 0.013402341699856267, 0.014481271392569748, 0.013997593494743254, 0.014337734231440975, 0.013610731519362233, 0.013419483769950485, 0.013232285148957952, 0.013242462998207376, 0.013560111259158687, 0.013716497335966618, 0.01470356155974945, 0.014585990471992716, 0.014615042807392559, 0.013471912691587137, 0.013823954053999528, 0.014344197791960866, 0.014069965816752423, 0.013346704952477858, 0.014380900242457872, 0.013971384835891498, 0.013232285148957953, 0.013826121935149475, 0.013935490447340377, 0.013693048396305169, 0.014303593969037746, 0.013320446269823991, 0.01362151046743617, 0.01352340758301509, 0.012324864885654837, 0.013583534503638084, 0.014782568470510599, 0.013354218774863156, 0.01385873516828868, 0.012699569856729577, 0.014141248118460754, 0.01319613121319776, 0.014122861687487128, 0.013695027252111788, 0.014138463600744586, 0.013313627289252216, 0.013586333647782904, 0.014414019775896353, 0.013701937420583633, 0.013948975768654124, 0.011815383726360837, 0.013960278035499393, 0.014412441683174938, 0.013702714639878101, 0.012753079094988342, 0.014125397535533636, 0.012773390896694173, 0.013723648483984694, 0.013321605321508029, 0.013070429467445098, 0.013752906989354064, 0.013667089871073615, 0.01366774919170825, 0.012725837254135345, 0.014368658243680728, 0.013168580557566437, 0.013918488066496561, 0.013344256570439552, 0.013701751456024048, 0.014883994354813355, 0.013330550885883622, 0.013325465853541007, 0.012913010782996243, 0.013377265207850124, 0.01502388672606323, 0.013435725469043815, 0.01480956019123494, 0.014002020905989577], "moving_avg_accuracy_train": [0.03345894544227574, 0.0692352297174926, 0.10396292649357464, 0.13688037103967676, 0.16783834535020706, 0.19677942732612214, 0.22380739760915225, 0.24910902521742306, 0.2726266825886302, 0.29457146302508835, 0.3149935531797593, 0.3340637872224792, 0.35178957572637565, 0.3682728832596351, 0.3836866418490463, 0.3979822737604871, 0.4112063432998131, 0.4236357065185121, 0.43521744476177904, 0.4459409173283291, 0.45603600186556814, 0.46531685440026455, 0.47413679634811184, 0.48246289975708984, 0.49017964315970314, 0.49746393160651425, 0.5042897247634616, 0.510693030832012, 0.5165514455413542, 0.5219797316523628, 0.5271721087951275, 0.5320684264605114, 0.5366564739664998, 0.5409531274361751, 0.5449176997112453, 0.5487113541933323, 0.5522837172974394, 0.5556824587494508, 0.5587158575658124, 0.5617061529231109, 0.5643811427030128, 0.567004908393029, 0.5694987949473677, 0.57188984931891, 0.5740858679342228, 0.5762110942118137, 0.5781982026235504, 0.579949397813161, 0.5817741562599734, 0.5835538028859603, 0.5851344503636065, 0.586624498457783, 0.5881259049127614, 0.589539985788918, 0.5909103508762775, 0.5922435887560732, 0.5935504596931274, 0.5947987231495714, 0.596049863200801, 0.5971295304659923, 0.5981826472618165, 0.5992604804672977, 0.6002004115641634, 0.6012276390608478, 0.6021940685840728, 0.6031567529609, 0.6039697265262441, 0.6048757167981306, 0.6056492193154382, 0.6065220107929015, 0.6072819104368948, 0.6078753195570112, 0.6085533667472127, 0.6092216658409947, 0.6098697100992263, 0.6104621784292354, 0.6110118201631853, 0.6115249907677601, 0.6121519298773537, 0.6126371560652828, 0.6131667934891625, 0.613682994700416, 0.614182453022687, 0.614729477567456, 0.6151916448208617, 0.6155936805048885, 0.6159603792110442, 0.6163506456227195, 0.6168041198432086, 0.6171540097749546, 0.6175573384659254, 0.6179133948901894, 0.6183917755469807, 0.618782934803606, 0.6190257682381587, 0.6193557812768382, 0.6197365344176113, 0.62008375439547, 0.6203499656922649, 0.6206452152355337, 0.6209387695125526, 0.6212124131523826, 0.6214423442889255, 0.6217352767689478, 0.6219896514545484, 0.6222232029203892, 0.6224497113301315, 0.6226442683036614, 0.6229007497881716, 0.6231663882587362, 0.6234380510143963, 0.6237266532242338, 0.6239724082714118, 0.6241959850603189, 0.6244413099000788, 0.6247179418761101, 0.6250017518378623, 0.6251735114951151, 0.6253257339890145, 0.6254767211751998, 0.6256730274629955, 0.6258752797589163, 0.6260829195109686, 0.626299950124702, 0.6265279018580329, 0.6266122588263916, 0.626760223662191, 0.6269049096120018, 0.6271351444144598, 0.6272075692033571, 0.6273377475335751, 0.6274573052772183, 0.6275997844786401, 0.6275350284087292, 0.627737020417201, 0.627839902360577, 0.6279603978953295, 0.6281385983408925, 0.628259487260956, 0.6283148088663942, 0.6284318473826711, 0.6285698422771098, 0.6287009770797145, 0.6287796150675717, 0.628899109235187, 0.628999714588431, 0.6290948015575133, 0.6292175822106398, 0.6293025802591864, 0.6293814757493252, 0.6294571319880693, 0.6295948689207684, 0.6296840270256923, 0.6297410538808473, 0.6298132683409539, 0.6298735029109743, 0.6299975045370974, 0.6300743008661026, 0.6301247803229124, 0.6302236542078415, 0.630287064067373, 0.6303233147481219, 0.6303116543869587, 0.6303104967059687, 0.6303256947859256, 0.6303161215697914, 0.6302935547824136, 0.630408103304726, 0.6304392255081681, 0.6305252921138667, 0.6305469845363856, 0.630589723155929, 0.6306211764182708, 0.6306657964448639, 0.6307059544687976, 0.630772287576043, 0.6308715149023257, 0.6309051240710079, 0.6308958087442412, 0.6309175437382187, 0.6309069143470935, 0.6309252136319762, 0.6308719645729036, 0.6309519596530809, 0.6309495865121545, 0.6309032007603024, 0.6309102456598166, 0.6309095745741321, 0.6309556177684815, 0.6309667576112347, 0.6310744036708938, 0.6311853441639004, 0.6312502052290072, 0.6313039659388031, 0.6313733850633614, 0.6313730111599691, 0.6314261170207164, 0.6313925320870557, 0.6313972189277226, 0.6314501931116853, 0.6314351629570321, 0.6314844508845201, 0.6314705731525649, 0.6315139588628713, 0.6315995089783376, 0.6316834795286859, 0.6316869734109041, 0.6317272481882152, 0.6317472554949475, 0.6316955436555395, 0.6317861507310154, 0.6317398139144199, 0.6317632870437883, 0.6318564203756774, 0.6318309223315113, 0.6318568022167618, 0.6319126822456393, 0.6319467342787812, 0.6319238666371711, 0.631898635462103, 0.6319015040414464, 0.6319133863580936, 0.6319170689478286, 0.6319669223035995, 0.6319443249594984, 0.6319100725057689, 0.6319094722319362, 0.6318949810926295, 0.6319563798779771, 0.6319581603621709, 0.6320340594133939, 0.6320024592583225, 0.6320460987318535, 0.6320784348604216, 0.6320237959701712, 0.6320257742427554, 0.632092658854748, 0.6320435369626748, 0.6320528417312468, 0.6320402896836759, 0.6321010364051385, 0.6321905856865977, 0.6321641871458542, 0.6321405005568226, 0.6321842867933607, 0.6321074009169501, 0.6321265953317611, 0.6320950061312722, 0.6321061033805943, 0.6320579982335648, 0.632024040245295, 0.6320422340832148, 0.6320400794445039, 0.6320311287744168, 0.6320556252546717, 0.6320311691107107, 0.6320649261037555, 0.6322092396891625, 0.6322717286493714, 0.6322163255218834, 0.6320990694404869, 0.6320958094660303, 0.6320161455783051, 0.632023539187695, 0.6320650706682888, 0.6320954735543945, 0.632150737937604, 0.6321330826158351, 0.6321264573726625, 0.6321879239692832, 0.6321316367633849, 0.6321530218423528, 0.6321583175205668, 0.6321723842261975, 0.6322013203029317, 0.6321948106886592, 0.6321958914334238, 0.6321503971763403, 0.6321001877985457, 0.6321851355942264, 0.6321919422925095], "dataset": "Cifar10", "nb_examples_train": 42500, "seed": 605692009, "moving_var_accuracy_train": [0.010075509270982665, 0.02058744099275457, 0.029382813203822605, 0.03619655528245171, 0.04120246531490962, 0.04462049481684838, 0.04673304593374676, 0.0478212925770206, 0.04801688519338398, 0.04754935716968478, 0.04654797734928587, 0.045166244052354296, 0.043477451849882665, 0.041575001510018465, 0.03955575694369044, 0.03743946707504806, 0.03526940450417162, 0.03313286568395559, 0.031026809062179996, 0.028959063930931957, 0.026980354124164795, 0.025057526725685345, 0.023251896436787378, 0.0215506227749016, 0.01993149365608742, 0.018415892014065797, 0.016993625882652075, 0.015663284251854686, 0.014405845032828947, 0.013230457140472766, 0.01215005844995985, 0.01115081794508702, 0.010225187769833171, 0.009368820072196105, 0.008573398564894792, 0.007845585037370442, 0.007175882536961674, 0.006562257274384087, 0.0059888451223576175, 0.00547043740703678, 0.004987793799236319, 0.004550971736877642, 0.004151849794503078, 0.003788119084121814, 0.003452709655538835, 0.0031480879705636225, 0.0028688165720672123, 0.00260953507618953, 0.0023785492590734946, 0.00216919861218662, 0.00197476476900526, 0.0017972704820113639, 0.0016378314258976858, 0.0014920449058267208, 0.0013597415194979354, 0.00123976507674524, 0.001131159773885768, 0.0010320672514074329, 0.0009429486891168078, 0.0008591449528368563, 0.0007832119524239936, 0.0007153462769511378, 0.0006517628834577195, 0.0005960833620814487, 0.0005448809000835506, 0.0004987336609596788, 0.00045480862902524575, 0.0004167151314774977, 0.0003804283736282794, 0.0003492414209336428, 0.00031951430606074957, 0.00029073208490920996, 0.00026579660834754937, 0.00024323656062154132, 0.0002226925568050303, 0.00020358246962310094, 0.00018594317698208536, 0.00016971895590847368, 0.0001562845341418672, 0.00014277508080875025, 0.0001310222149348397, 0.00012031816665585248, 0.00011053147753143966, 0.00010217145245151276, 9.387669433744706e-05, 8.594371912478029e-05, 7.855955868216842e-05, 7.207437366268807e-05, 6.671768611425411e-05, 6.114772418186335e-05, 5.649701806031869e-05, 5.198830184962289e-05, 4.884910413978949e-05, 4.534124380220348e-05, 4.13378321144129e-05, 3.818422635425796e-05, 3.5670560306709886e-05, 3.318855969325632e-05, 3.0507519814801342e-05, 2.824131846852563e-05, 2.619275364367729e-05, 2.4247405853884303e-05, 2.229848021646279e-05, 2.0840917135483983e-05, 1.9339183748005217e-05, 1.789618195797231e-05, 1.656831829933043e-05, 1.5252158212939263e-05, 1.4318987158714324e-05, 1.3522162616237654e-05, 1.283415222992975e-05, 1.2300358126645036e-05, 1.1613882202901479e-05, 1.090237320745373e-05, 1.0353794379737428e-05, 1.0007142193230217e-05, 9.731360823415436e-06, 9.023737159810581e-06, 8.32990863266995e-06, 7.702091942932316e-06, 7.278708176291998e-06, 6.918991279510035e-06, 6.615120551249932e-06, 6.37752908180216e-06, 6.207434108178712e-06, 5.650735580356983e-06, 5.2827043560195076e-06, 4.942840137071447e-06, 4.925628701730107e-06, 4.480273981978493e-06, 4.1847641627057914e-06, 3.894934233020749e-06, 3.6881437152587285e-06, 3.3570694810455917e-06, 3.388569476319473e-06, 3.144974777142672e-06, 2.961149864486158e-06, 2.9508334672272693e-06, 2.787277299451786e-06, 2.5360938897609197e-06, 2.4057666294152476e-06, 2.336573284494024e-06, 2.257682984132024e-06, 2.0875700839269807e-06, 2.0073227803809174e-06, 1.8976834362548708e-06, 1.7892888778327703e-06, 1.7460357890889855e-06, 1.6364542244906128e-06, 1.5288292873199338e-06, 1.4274611567360875e-06, 1.4554582047268427e-06, 1.381454893316742e-06, 1.2725779638649194e-06, 1.1922545217146564e-06, 1.10568290037321e-06, 1.1335022398661007e-06, 1.0732311012176932e-06, 9.888415711342508e-07, 9.779418201096548e-07, 9.16334930670885e-07, 8.365284442965919e-07, 7.540992760690471e-07, 6.787014104896155e-07, 6.12910104150026e-07, 5.524439119393718e-07, 5.017828597784299e-07, 5.696968494760957e-07, 5.214444884523288e-07, 5.359671851552572e-07, 4.866055173923515e-07, 4.543842720574163e-07, 4.178496142591322e-07, 3.939831737916549e-07, 3.6909885838881584e-07, 3.7178970260137407e-07, 4.232252928722401e-07, 3.910689495605695e-07, 3.5274303241944903e-07, 3.2172041884632444e-07, 2.905652325629447e-07, 2.6452248375163496e-07, 2.635893960054074e-07, 2.948233720780667e-07, 2.653917210509691e-07, 2.582172907199271e-07, 2.3284223713042653e-07, 2.0956206662134738e-07, 2.076856416723094e-07, 1.8803394237416971e-07, 2.735196155779525e-07, 3.5693779091705827e-07, 3.5910663172647766e-07, 3.4920789381360645e-07, 3.5765823812211367e-07, 3.218936725436229e-07, 3.150863973006388e-07, 2.93729287491569e-07, 2.6455405702134335e-07, 2.63355028817832e-07, 2.3905267587614243e-07, 2.370111064530934e-07, 2.1504331880575422e-07, 2.1047986565433288e-07, 2.5530127939554607e-07, 2.9323063138803887e-07, 2.6401743316582376e-07, 2.5221420903646046e-07, 2.305954190368987e-07, 2.3160290614784636e-07, 2.8232939466981654e-07, 2.734203603526355e-07, 2.51037214538425e-07, 3.0399785066359854e-07, 2.794494179039096e-07, 2.575323922587311e-07, 2.598823516790503e-07, 2.443299851609951e-07, 2.2460334794017857e-07, 2.0787252290404405e-07, 1.8715932934068506e-07, 1.697141014467494e-07, 1.5286474450648974e-07, 1.5994648379037925e-07, 1.4854759505518745e-07, 1.4425191082806497e-07, 1.2982996270332654e-07, 1.1873690449861528e-07, 1.4079151162819842e-07, 1.2674089158105773e-07, 1.6591279621181442e-07, 1.58308644795457e-07, 1.5961741316647004e-07, 1.5306629874675616e-07, 1.6462834382218448e-07, 1.4820073150172313e-07, 1.7364262024397793e-07, 1.7799500074721064e-07, 1.609747091360872e-07, 1.462952233064915e-07, 1.6487717849194817e-07, 2.205611249315029e-07, 2.0477695901886222e-07, 1.8934875361658844e-07, 1.876689888464827e-07, 2.221050318847205e-07, 2.0321035873570995e-07, 1.9187022114981304e-07, 1.7379153951746799e-07, 1.7723933210230965e-07, 1.6989370359802737e-07, 1.558834748824732e-07, 1.4033690960599758e-07, 1.2702424910047906e-07, 1.197225220943329e-07, 1.1313319668190658e-07, 1.1207568822858093e-07, 2.8830581780301496e-07, 2.9461906735460095e-07, 2.9278271943809737e-07, 3.8724534511451677e-07, 3.4861645750418315e-07, 3.7087182682122416e-07, 3.342766332773912e-07, 3.1637274487242474e-07, 2.9305448973723416e-07, 2.9123640922724756e-07, 2.649181617853916e-07, 2.3882139023072376e-07, 2.4894253370894644e-07, 2.5256252626871616e-07, 2.3142216806401292e-07, 2.0853234912732422e-07, 1.8945996408028759e-07, 1.780496365032003e-07, 1.6062604855467065e-07, 1.445739557824189e-07, 1.487441070524871e-07, 1.5655853091392603e-07, 2.0584782974158962e-07, 1.856800270410923e-07], "duration": 128293.829348, "accuracy_train": [0.3345894544227575, 0.3912217881944445, 0.41651219747831303, 0.4331373719545958, 0.44646011414497966, 0.4572491651093577, 0.46705913015642303, 0.47682367369186046, 0.4842855989294943, 0.49207448695321154, 0.49879236457179776, 0.5056958936069582, 0.5113216722614433, 0.5166226510589701, 0.5224104691537468, 0.5266429609634551, 0.5302229691537468, 0.5354999754868033, 0.5394530889511813, 0.5424521704272794, 0.5468917627007198, 0.5488445272125323, 0.5535162738787376, 0.5573978304378922, 0.5596303337832226, 0.5630225276278147, 0.5657218631759874, 0.5683227854489664, 0.5692771779254338, 0.5708343066514396, 0.573903503080011, 0.5761352854489664, 0.577948901520395, 0.5796230086632521, 0.5805988501868771, 0.5828542445321152, 0.5844349852344038, 0.5862711318175526, 0.5860164469130675, 0.5886188111387965, 0.5884560507221299, 0.5906187996031745, 0.5919437739364156, 0.5934093386627907, 0.5938500354720377, 0.595338130710133, 0.5960821783291805, 0.5957101545196567, 0.5981969822812846, 0.5995706225198413, 0.5993602776624216, 0.600034931305371, 0.6016385630075674, 0.6022667136743264, 0.6032436366625139, 0.6042427296742341, 0.605312298126615, 0.6060330942575674, 0.6073101236618678, 0.6068465358527132, 0.6076606984242341, 0.6089609793166297, 0.6086597914359542, 0.6104726865310077, 0.6108919342930971, 0.611820912352344, 0.6112864886143411, 0.613029629245109, 0.6126107419712071, 0.6143771340900701, 0.614121007232835, 0.6132160016380583, 0.6146557914590255, 0.6152363576850314, 0.6157021084233112, 0.6157943933993171, 0.6159585957687339, 0.6161435262089332, 0.6177943818636951, 0.6170041917566446, 0.6179335303040789, 0.618328805601698, 0.6186775779231266, 0.6196526984703765, 0.6193511501015135, 0.6192120016611296, 0.6192606675664452, 0.6198630433277962, 0.6208853878276117, 0.6203030191606681, 0.6211872966846622, 0.621117902708564, 0.6226972014581026, 0.6223033681132337, 0.6212112691491326, 0.6223258986249538, 0.6231633126845699, 0.6232087341961978, 0.6227458673634183, 0.6233024611249538, 0.6235807580057217, 0.6236752059108527, 0.623511724517811, 0.6243716690891473, 0.6242790236249538, 0.6243251661129567, 0.624488287017811, 0.6243952810654301, 0.6252090831487633, 0.6255571344938169, 0.6258830158153378, 0.6263240731127722, 0.6261842036960134, 0.6262081761604835, 0.6266492334579181, 0.6272076296603912, 0.6275560414936324, 0.6267193484103912, 0.6266957364341086, 0.6268356058508674, 0.6274397840531561, 0.6276955504222038, 0.6279516772794389, 0.628253225648302, 0.6285794674580103, 0.6273714715416205, 0.6280919071843853, 0.628207083160299, 0.6292072576365817, 0.627859392303433, 0.6285093525055372, 0.6285333249700074, 0.628882097291436, 0.6269522237795312, 0.6295549484934477, 0.6287658398509597, 0.6290448577081026, 0.6297424023509597, 0.6293474875415282, 0.6288127033153378, 0.629485194029162, 0.629811796327058, 0.6298811903031561, 0.6294873569582872, 0.6299745567437246, 0.6299051627676264, 0.6299505842792543, 0.6303226080887782, 0.6300675626961055, 0.6300915351605758, 0.6301380381367663, 0.6308345013150609, 0.6304864499700074, 0.6302542955772426, 0.6304631984819121, 0.6304156140411591, 0.6311135191722038, 0.6307654678271503, 0.6305790954342008, 0.6311135191722038, 0.6308577528031561, 0.6306495708748615, 0.6302067111364895, 0.630300077577058, 0.6304624775055372, 0.6302299626245847, 0.6300904536960134, 0.6314390400055372, 0.6307193253391473, 0.6312998915651532, 0.630742216339055, 0.6309743707318198, 0.6309042557793466, 0.6310673766842008, 0.6310673766842008, 0.6313692855412514, 0.6317645608388704, 0.6312076065891473, 0.6308119708033407, 0.6311131586840163, 0.6308112498269657, 0.6310899071959211, 0.6303927230412514, 0.6316719153746769, 0.6309282282438169, 0.6304857289936324, 0.6309736497554448, 0.6309035348029716, 0.6313700065176264, 0.6310670161960134, 0.6320432182078258, 0.6321838086009597, 0.6318339548149686, 0.6317878123269657, 0.6319981571843853, 0.6313696460294389, 0.6319040697674418, 0.6310902676841086, 0.6314394004937246, 0.6319269607673496, 0.6312998915651532, 0.6319280422319121, 0.6313456735649686, 0.6319044302556294, 0.6323694600175341, 0.6324392144818198, 0.6317184183508674, 0.6320897211840163, 0.6319273212555372, 0.6312301371008674, 0.632601614410299, 0.6313227825650609, 0.6319745452081026, 0.63269462036268, 0.6316014399340163, 0.6320897211840163, 0.6324156025055372, 0.632253202577058, 0.63171805786268, 0.6316715548864895, 0.6319273212555372, 0.6320203272079181, 0.6319502122554448, 0.6324156025055372, 0.6317409488625877, 0.6316018004222038, 0.6319040697674418, 0.6317645608388704, 0.6325089689461055, 0.6319741847199151, 0.6327171508744002, 0.63171805786268, 0.6324388539936324, 0.6323694600175341, 0.6315320459579181, 0.6320435786960134, 0.63269462036268, 0.6316014399340163, 0.6321365846483943, 0.6319273212555372, 0.632647756898302, 0.6329965292197306, 0.631926600279162, 0.6319273212555372, 0.6325783629222038, 0.6314154280292543, 0.6322993450650609, 0.6318107033268734, 0.6322059786244925, 0.631625051910299, 0.6317184183508674, 0.6322059786244925, 0.6320206876961055, 0.6319505727436324, 0.6322760935769657, 0.6318110638150609, 0.6323687390411591, 0.6335080619578258, 0.6328341292912514, 0.6317176973744925, 0.6310437647079181, 0.6320664696959211, 0.6312991705887782, 0.6320900816722038, 0.6324388539936324, 0.6323690995293466, 0.6326481173864895, 0.6319741847199151, 0.6320668301841086, 0.6327411233388704, 0.631625051910299, 0.6323454875530639, 0.6322059786244925, 0.6322989845768734, 0.6324617449935401, 0.6321362241602068, 0.6322056181363049, 0.6317409488625877, 0.6316483033983943, 0.6329496657553525, 0.632253202577058], "end": "2016-01-25 10:08:10.036000", "learning_rate_per_epoch": [0.005207794718444347, 0.005085121840238571, 0.0049653383903205395, 0.004848376382142305, 0.004734169691801071, 0.004622653126716614, 0.004513763356953859, 0.004407438449561596, 0.004303618334233761, 0.004202243871986866, 0.004103257320821285, 0.004006602335721254, 0.003912223968654871, 0.0038200689014047384, 0.003730084514245391, 0.003642219817265868, 0.0035564249847084284, 0.003472651122137904, 0.0033908504992723465, 0.0033109767828136683, 0.003232984570786357, 0.0031568293925374746, 0.0030824681743979454, 0.0030098585411906242, 0.0029389592818915844, 0.0028697301167994738, 0.002802131697535515, 0.0027361256070435047, 0.002671674359589815, 0.0026087414007633924, 0.0025472906418144703, 0.002487287623807788, 0.0024286978878080845, 0.0023714883718639612, 0.0023156264796853065, 0.00226108031347394, 0.002207819139584899, 0.002155812457203865, 0.002105030929669738, 0.0020554454531520605, 0.0020070280879735947, 0.0019597511272877455, 0.0019135879119858146, 0.0018685120157897472, 0.0018244979437440634, 0.0017815206665545702, 0.001739555737003684, 0.0016985792899504304, 0.0016585681587457657, 0.0016194995259866118, 0.0015813511563465, 0.00154410139657557, 0.00150772905908525, 0.001472213538363576, 0.0014375345781445503, 0.0014036725042387843, 0.0013706081081181765, 0.0013383225305005908, 0.0013067974941805005, 0.0012760149547830224, 0.0012459575664252043, 0.0012166082160547376, 0.0011879501398652792, 0.0011599671561270952, 0.0011326433159410954, 0.0011059631360694766, 0.0010799114825204015, 0.0010544734541326761, 0.001029634615406394, 0.001005380880087614, 0.0009816985111683607, 0.0009585739462636411, 0.0009359940886497498, 0.0009139461326412857, 0.0008924175053834915, 0.0008713960414752364, 0.0008508697501383722, 0.0008308269316330552, 0.0008112562354654074, 0.0007921465439721942, 0.0007734870305284858, 0.000755267043132335, 0.0007374762208200991, 0.0007201044936664402, 0.0007031419663690031, 0.0006865789764560759, 0.0006704061524942517, 0.0006546142976731062, 0.0006391944480128586, 0.0006241378141567111, 0.0006094358395785093, 0.0005950801423750818, 0.0005810626316815615, 0.0005673753330484033, 0.0005540104466490448, 0.0005409603472799063, 0.0005282176425680518, 0.0005157751147635281, 0.0005036256625317037, 0.0004917624173685908, 0.0004801786271855235, 0.00046886768541298807, 0.000457823189208284, 0.0004470388521440327, 0.00043650856241583824, 0.0004262263246346265, 0.0004161862889304757, 0.00040638275095261633, 0.0003968101227656007, 0.0003874629910569638, 0.0003783360298257321, 0.0003694240585900843, 0.0003607220423873514, 0.00035222500446252525, 0.00034392811357975006, 0.00033582665491849184, 0.0003279160300735384, 0.00032019175705499947, 0.00031264941208064556, 0.00030528474599123, 0.00029809356783516705, 0.0002910717739723623, 0.0002842153771780431, 0.00027752050664275885, 0.00027098332066088915, 0.00026460012304596603, 0.00025836730492301285, 0.00025228128652088344, 0.0002463386335875839, 0.00024053595552686602, 0.0002348699636058882, 0.00022933744185138494, 0.00022393524704966694, 0.000218660308746621, 0.00021350961469579488, 0.00020848025451414287, 0.000203569361474365, 0.00019877415616065264, 0.00019409190281294286, 0.00018951993843074888, 0.00018505567277316004, 0.00018069655925501138, 0.00017644012405071408, 0.00017228396609425545, 0.00016822569887153804, 0.00016426302317995578, 0.0001603936980245635, 0.00015661551151424646, 0.00015292632451746613, 0.0001493240415584296, 0.00014580661081708968, 0.00014237203868106008, 0.0001390183751937002, 0.0001357436995021999, 0.00013254616351332515, 0.00012942394823767245, 0.0001263752783415839, 0.00012339842214714736, 0.00012049169163219631, 0.00011765342787839472, 0.00011488202289910987, 0.00011217589781153947, 0.00010953351738862693, 0.00010695338278310373, 0.00010443402425153181, 0.00010197400843026116, 9.957194561138749e-05, 9.722646063892171e-05, 9.493622928857803e-05, 9.269994188798591e-05, 9.051633242052048e-05, 8.838415669742972e-05, 8.630220690974966e-05, 8.426930435234681e-05, 8.22842848720029e-05, 8.034602069528773e-05, 7.845341315260157e-05, 7.660539267817512e-05, 7.480090425815433e-05, 7.30389219825156e-05, 7.131844176910818e-05, 6.963848863961175e-05, 6.799810944357887e-05, 6.63963655824773e-05, 6.483235483756289e-05, 6.330518226604909e-05, 6.181398930493742e-05, 6.035792102920823e-05, 5.8936151617672294e-05, 5.754786980105564e-05, 5.619228977593593e-05, 5.486864392878488e-05, 5.35761755600106e-05, 5.231415343587287e-05, 5.1081857236567885e-05, 4.9878588470164686e-05, 4.870366319664754e-05, 4.755641566589475e-05, 4.643619104172103e-05, 4.534235631581396e-05, 4.427428575581871e-05, 4.323137545725331e-05, 4.2213032429572195e-05, 4.121867459616624e-05, 4.0247741708299145e-05, 3.929968079319224e-05, 3.837394979200326e-05, 3.747002483578399e-05, 3.6587392969522625e-05, 3.572555215214379e-05, 3.488401125650853e-05, 3.406229370739311e-05, 3.3259933843510225e-05, 3.247647327953018e-05, 3.1711468182038516e-05, 3.0964481993578374e-05, 3.0235092708608136e-05, 2.952288559754379e-05, 2.882745502574835e-05, 2.814840445353184e-05, 2.748535007413011e-05, 2.6837913537747227e-05, 2.6205729227513075e-05, 2.558843516453635e-05, 2.498568210285157e-05, 2.439712807245087e-05, 2.382243656029459e-05, 2.3261283786268905e-05, 2.2713349608238786e-05, 2.2178321160026826e-05, 2.1655896489392035e-05, 2.114577728207223e-05, 2.064767431875225e-05, 2.0161303837085143e-05, 1.968639116967097e-05, 1.9222665287088603e-05, 1.876986243587453e-05, 1.832772613852285e-05, 1.7896003555506468e-05, 1.7474450942245312e-05, 1.7062828192138113e-05, 1.6660902474541217e-05, 1.6268444596789777e-05, 1.5885230823187158e-05, 1.5511042875004932e-05, 1.514566974947229e-05, 1.4788903172302525e-05, 1.4440540326177143e-05, 1.4100383850745857e-05, 1.376824002363719e-05, 1.3443919669953175e-05, 1.3127239071764052e-05, 1.281801814911887e-05, 1.2516081369540188e-05, 1.222125683852937e-05, 1.1933377209061291e-05, 1.165227877208963e-05, 1.1377801456546877e-05, 1.1109789738839027e-05, 1.0848090823856182e-05, 1.0592556463961955e-05, 1.0343042049498763e-05, 1.0099404789798427e-05, 9.861506441666279e-06, 9.629212399886455e-06, 9.402389878232498e-06, 9.180910637951456e-06, 8.964648259279784e-06, 8.753479960432742e-06, 8.547285688109696e-06, 8.34594902698882e-06, 8.149354471242987e-06, 7.957391062518582e-06, 7.769949661451392e-06, 7.586923402413959e-06, 7.408208148262929e-06, 7.2337029450864065e-06, 7.063308203214547e-06, 6.896927061461611e-06, 6.734465387125965e-06, 6.575830411748029e-06], "accuracy_valid": [0.34050116481551207, 0.3866849232868976, 0.41130341679216864, 0.429797804499247, 0.44290050828313254, 0.45452807323042166, 0.4649452301393072, 0.47355192253388556, 0.4778037932981928, 0.4871120223079819, 0.49288021225527107, 0.5005706419427711, 0.5054843397025602, 0.5112113493034638, 0.5205401684864458, 0.5246905591114458, 0.5270201901355422, 0.5330119305346386, 0.5348429852221386, 0.5373961666980422, 0.5409670910203314, 0.5415774425828314, 0.5475691829819277, 0.5500208843185241, 0.5512518825301205, 0.5529505718185241, 0.5571421427899097, 0.557152437876506, 0.5576510142131024, 0.5592585184487951, 0.5617102197853916, 0.5647825677710843, 0.5640501458960843, 0.5665121423192772, 0.5655252847326807, 0.5667356927710843, 0.5704286874058735, 0.5695536050451807, 0.5714964349585843, 0.5736334007906627, 0.5754644554781627, 0.5758512565888554, 0.576817524002259, 0.5777837914156627, 0.5787912391754518, 0.5759321465549698, 0.5772852150790663, 0.5787603539156627, 0.5803266778049698, 0.5810488045933735, 0.5812929452183735, 0.5822798028049698, 0.5822798028049698, 0.5843652932040663, 0.5827371987951807, 0.5842226327183735, 0.5846800287085843, 0.5854330407567772, 0.5846697336219879, 0.5870199548192772, 0.5860330972326807, 0.5876200112951807, 0.5867449289344879, 0.5899393472326807, 0.5890848550451807, 0.5909364999058735, 0.5887083490210843, 0.5890745599585843, 0.5895422510353916, 0.5909056146460843, 0.5918821771460843, 0.5932455407567772, 0.5938661874058735, 0.5944559487951807, 0.5951883706701807, 0.5947103845067772, 0.5943132883094879, 0.5946897943335843, 0.5948221597326807, 0.5967752847326807, 0.5983827889683735, 0.5968870599585843, 0.5965208490210843, 0.5994917168674698, 0.5972532708960843, 0.5991358010165663, 0.5998476327183735, 0.5994917168674698, 0.5995829019201807, 0.6013227715549698, 0.6003359139683735, 0.5993387612951807, 0.5998270425451807, 0.6010683358433735, 0.5993387612951807, 0.6008036050451807, 0.6021772637424698, 0.6016478021460843, 0.6009462655308735, 0.6018110528049698, 0.6005491693335843, 0.6014242516942772, 0.6037641778049698, 0.6035097420933735, 0.6031538262424698, 0.6009153802710843, 0.6021566735692772, 0.6035200371799698, 0.6038759530308735, 0.6020346032567772, 0.6012918862951807, 0.6028788003576807, 0.6030111657567772, 0.6031641213290663, 0.6032656014683735, 0.6030111657567772, 0.6036112222326807, 0.6033773766942772, 0.6033773766942772, 0.6033670816076807, 0.6033773766942772, 0.6049745858433735, 0.6042215737951807, 0.6044657144201807, 0.6044760095067772, 0.6033670816076807, 0.6027567300451807, 0.6043436441076807, 0.6022787438817772, 0.6034891519201807, 0.6042318688817772, 0.6021360833960843, 0.6042215737951807, 0.6053407967808735, 0.6055746423192772, 0.6048422204442772, 0.6032450112951807, 0.6045980798192772, 0.6047098550451807, 0.6038553628576807, 0.6042215737951807, 0.6049539956701807, 0.6063070641942772, 0.6054525720067772, 0.6047201501317772, 0.6056967126317772, 0.6049642907567772, 0.6058187829442772, 0.6043436441076807, 0.6042318688817772, 0.6047201501317772, 0.6060629235692772, 0.6056967126317772, 0.6047201501317772, 0.6054422769201807, 0.6044657144201807, 0.6034788568335843, 0.6049539956701807, 0.6048422204442772, 0.6050863610692772, 0.6054422769201807, 0.6039877282567772, 0.6051981362951807, 0.6063070641942772, 0.6055643472326807, 0.6060629235692772, 0.6061849938817772, 0.6052084313817772, 0.6049437005835843, 0.6061849938817772, 0.6049539956701807, 0.6044657144201807, 0.6051981362951807, 0.6060526284826807, 0.6054422769201807, 0.6062967691076807, 0.6069174157567772, 0.6055643472326807, 0.6051981362951807, 0.6053202066076807, 0.6064291345067772, 0.6058084878576807, 0.6058084878576807, 0.6074056970067772, 0.6046995599585843, 0.6054422769201807, 0.6056864175451807, 0.6060526284826807, 0.6066629800451807, 0.6049437005835843, 0.6067953454442772, 0.6062967691076807, 0.6050760659826807, 0.6060629235692772, 0.6065512048192772, 0.6055643472326807, 0.6058084878576807, 0.6053202066076807, 0.6047098550451807, 0.6064291345067772, 0.6057981927710843, 0.6060526284826807, 0.6055643472326807, 0.6054422769201807, 0.6075277673192772, 0.6076498376317772, 0.6056967126317772, 0.6066629800451807, 0.6072836266942772, 0.6058187829442772, 0.6056761224585843, 0.6057981927710843, 0.6055540521460843, 0.6065409097326807, 0.6066732751317772, 0.6060526284826807, 0.6067953454442772, 0.6061746987951807, 0.6056864175451807, 0.6055643472326807, 0.6066629800451807, 0.6059202630835843, 0.6061746987951807, 0.6064188394201807, 0.6065409097326807, 0.6066732751317772, 0.6053099115210843, 0.6051878412085843, 0.6061644037085843, 0.6060526284826807, 0.6087484704442772, 0.6067953454442772, 0.6059305581701807, 0.6075277673192772, 0.6049539956701807, 0.6061746987951807, 0.6080263436558735, 0.6075277673192772, 0.6059202630835843, 0.6067850503576807, 0.6065512048192772, 0.6082704842808735, 0.6076498376317772, 0.6073954019201807, 0.6071615563817772, 0.6056761224585843, 0.6077719079442772, 0.6051878412085843, 0.6062864740210843, 0.6075174722326807, 0.6051878412085843, 0.6062864740210843, 0.6067747552710843, 0.6064188394201807, 0.6051878412085843, 0.6061746987951807, 0.6075380624058735, 0.6072733316076807, 0.6060423333960843, 0.6058084878576807, 0.6062967691076807, 0.6066629800451807, 0.6064188394201807, 0.6066732751317772, 0.6071512612951807, 0.6065306146460843, 0.6061849938817772, 0.6062967691076807, 0.6058084878576807, 0.6064188394201807, 0.6060423333960843, 0.6059305581701807, 0.6050760659826807, 0.6066629800451807, 0.6077616128576807, 0.6082498941076807, 0.6056761224585843, 0.6061644037085843, 0.6053099115210843, 0.6086366952183735, 0.6066732751317772], "accuracy_test": 0.6155891262755102, "start": "2016-01-23 22:29:56.206000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0, 232.0, 233.0, 234.0, 235.0, 236.0, 237.0, 238.0, 239.0, 240.0, 241.0, 242.0, 243.0, 244.0, 245.0, 246.0, 247.0, 248.0, 249.0, 250.0, 251.0, 252.0, 253.0, 254.0, 255.0, 256.0, 257.0, 258.0, 259.0, 260.0, 261.0, 262.0, 263.0, 264.0, 265.0, 266.0, 267.0, 268.0, 269.0, 270.0, 271.0, 272.0, 273.0, 274.0, 275.0, 276.0, 277.0, 278.0, 279.0, 280.0], "accuracy_train_last": 0.632253202577058, "batch_size_eval": 1024, "accuracy_train_std": [0.016891513965874926, 0.01630653713475018, 0.017202603311201808, 0.016767493922731882, 0.017566661639161464, 0.016907892462617747, 0.01746208691196532, 0.016895256552752695, 0.014975296548397132, 0.016033582586009336, 0.016456484963494562, 0.016436578975882216, 0.01599296161662359, 0.015281103884031715, 0.01648369534644912, 0.01692474581415643, 0.017347315568300433, 0.01688050515326716, 0.017330932118344144, 0.017031776168485016, 0.017610236446809497, 0.01678393616865669, 0.016609547397372734, 0.01647226903437479, 0.01693258926516135, 0.017498525631659375, 0.0180993551569616, 0.01725919292339825, 0.01765628845338572, 0.016861665062299046, 0.017785774325408035, 0.016982790266866377, 0.017406026980243763, 0.017122288821525895, 0.0177031487147509, 0.017561189832524013, 0.017554136418471557, 0.01818743096026581, 0.017372950118165177, 0.018003039451902663, 0.017576906911997855, 0.018057285227985144, 0.017532014333756424, 0.016581678125709407, 0.017233346096342552, 0.017840193677956355, 0.017440871550458793, 0.017020711685088945, 0.017266394023111958, 0.01683430040249623, 0.01626443935285622, 0.01755760995527922, 0.01694061509053887, 0.017052790285867005, 0.01696452667770713, 0.016937857948964113, 0.01617050238674338, 0.01637565404219363, 0.016490248528647444, 0.016372121352037423, 0.0170923925229995, 0.016411038082823768, 0.01629044251960838, 0.01602912674799355, 0.01641346469058208, 0.016053689026337054, 0.01588194209465218, 0.01565717091245926, 0.016337053128822925, 0.016065515974666315, 0.01595450088197343, 0.016363102791283998, 0.015856603394682426, 0.016410233102213567, 0.015757563948555268, 0.016281173495834234, 0.015996439280928417, 0.016321553618571478, 0.016369325882990643, 0.01613469065150272, 0.016323626900530325, 0.01620085627193218, 0.016365808852155612, 0.016648404168070667, 0.016643186914863866, 0.01638151411742976, 0.01649832505310888, 0.016194178103768938, 0.01672353487560898, 0.016538792136774935, 0.01659585920061467, 0.016628142491768416, 0.01723838902063667, 0.016725297503186555, 0.016954829890606222, 0.017147914433720445, 0.01671362470508277, 0.016735949077300746, 0.016905474735394957, 0.016868906051195703, 0.01665611799103382, 0.01715553049981385, 0.016667382216062367, 0.016516183662741213, 0.016590680081078057, 0.01705679805464442, 0.01678414446334858, 0.01654942445815703, 0.016297228100016804, 0.01628390612689149, 0.01656974731437935, 0.01706626597444961, 0.017112077507579725, 0.016539439262650852, 0.016680675937024724, 0.01673479757998505, 0.01724493768574885, 0.016908552561545227, 0.017336922007391183, 0.016749881866499287, 0.01677409321736226, 0.016928482859004036, 0.01698859753222255, 0.01689443242273318, 0.016995564276520894, 0.016930866590334475, 0.017066803674205083, 0.016947937917833247, 0.016566434103542412, 0.016828952323513537, 0.017228042969877913, 0.016974725999818387, 0.01702621438308962, 0.016605507199146656, 0.01715956471928039, 0.01676560219415223, 0.016723579607921975, 0.01681163945783143, 0.01717332715856686, 0.01669407928338725, 0.016630557074534622, 0.016793686933648178, 0.016853668490289835, 0.016906619611890612, 0.017292534200974125, 0.017020933228917855, 0.017608958971240596, 0.0171911628779501, 0.017239185043258713, 0.016830565971872723, 0.017017761448938483, 0.016932376030322823, 0.017065548084489273, 0.017264017331883943, 0.016930771862752804, 0.016647647266547726, 0.01690632876599293, 0.01686999228229468, 0.01693363368787969, 0.017384420265671514, 0.016497002379525318, 0.016132083921415782, 0.016754608513322073, 0.016990983488660023, 0.017147641367095783, 0.016673308799473107, 0.016734078593122575, 0.01679992191974064, 0.01678064267071152, 0.01690942190598162, 0.0168246959678319, 0.016641392410425105, 0.016806482115152968, 0.017027608454106113, 0.016701780997735872, 0.016744650611577164, 0.01698321956638312, 0.016910396322514187, 0.017174323546979793, 0.017398505460121543, 0.01671027264554127, 0.01690839180956097, 0.016818973636887346, 0.01708274600157208, 0.01694732924377928, 0.016640795941709082, 0.017045328563036935, 0.017241971069025724, 0.017055327456304878, 0.016857198563772123, 0.016874529111070225, 0.01713318738766956, 0.01673596253859189, 0.017182019040468198, 0.01716112873838765, 0.01675840338720776, 0.016908195289605837, 0.01703977200286989, 0.016642597162228275, 0.016944709661287322, 0.01674615085951048, 0.016714551530552377, 0.016853865894703644, 0.016354070083372526, 0.016828739239790964, 0.017036264610270743, 0.016371831254137065, 0.017069229596149857, 0.01719241250813868, 0.017018839297950072, 0.01633469719073923, 0.01712941102959219, 0.016946284278105926, 0.016938874907838773, 0.01671259548702004, 0.016565612775390946, 0.01721786378977701, 0.01658537095320912, 0.017118793130732408, 0.016811911279297913, 0.017037186373217262, 0.016895907769637553, 0.01727830423642097, 0.01695071703154253, 0.017381276091980973, 0.017030490247922195, 0.016893416595286547, 0.017091173304297907, 0.016915266111202563, 0.016431890496755974, 0.017075290102938654, 0.017059000276450565, 0.016832280538261902, 0.01686647651870682, 0.016759914949601554, 0.01708075798201636, 0.016594895758068596, 0.017180221383619614, 0.016857237347584028, 0.01661889497178065, 0.016858958253762477, 0.016919930298029066, 0.01720896704154076, 0.01713420185161301, 0.016981180262820403, 0.017407781786212287, 0.016981726667679525, 0.017110954394230556, 0.016804993929645438, 0.016700270615604182, 0.01687988500947609, 0.016922138086811107, 0.01683280860064416, 0.016706646054131195, 0.016793436649705118, 0.01721441534513723, 0.017437942841619904, 0.016895881069219625, 0.01715372886629938, 0.016719934661236623, 0.017163815327798662, 0.01691387709155043, 0.016878029618314416, 0.01689298641656325, 0.01684980824619878, 0.01710824029486366, 0.017078662965545967, 0.01719888499011009, 0.017206947555026622, 0.017170793721663444, 0.017096663186914163, 0.016810800147270218, 0.01648440933865109, 0.016745835009966573, 0.016803495921157353, 0.017195711299737213, 0.016923136036623595, 0.01687351639632139, 0.01707899534388317, 0.016989684314280863, 0.016956347154724098], "accuracy_test_std": 0.013317656409236177, "error_valid": [0.6594988351844879, 0.6133150767131024, 0.5886965832078314, 0.570202195500753, 0.5570994917168675, 0.5454719267695783, 0.5350547698606928, 0.5264480774661144, 0.5221962067018072, 0.5128879776920181, 0.5071197877447289, 0.4994293580572289, 0.49451566029743976, 0.4887886506965362, 0.4794598315135542, 0.4753094408885542, 0.47297980986445776, 0.4669880694653614, 0.4651570147778614, 0.46260383330195776, 0.45903290897966864, 0.45842255741716864, 0.4524308170180723, 0.44997911568147586, 0.4487481174698795, 0.44704942818147586, 0.4428578572100903, 0.44284756212349397, 0.44234898578689763, 0.44074148155120485, 0.4382897802146084, 0.43521743222891573, 0.43594985410391573, 0.43348785768072284, 0.4344747152673193, 0.43326430722891573, 0.4295713125941265, 0.4304463949548193, 0.42850356504141573, 0.4263665992093373, 0.4245355445218373, 0.4241487434111446, 0.42318247599774095, 0.4222162085843373, 0.42120876082454817, 0.4240678534450302, 0.42271478492093373, 0.4212396460843373, 0.4196733221950302, 0.4189511954066265, 0.4187070547816265, 0.4177201971950302, 0.4177201971950302, 0.41563470679593373, 0.4172628012048193, 0.4157773672816265, 0.41531997129141573, 0.41456695924322284, 0.41533026637801207, 0.41298004518072284, 0.4139669027673193, 0.4123799887048193, 0.41325507106551207, 0.4100606527673193, 0.4109151449548193, 0.4090635000941265, 0.41129165097891573, 0.41092544004141573, 0.4104577489646084, 0.40909438535391573, 0.40811782285391573, 0.40675445924322284, 0.4061338125941265, 0.4055440512048193, 0.4048116293298193, 0.40528961549322284, 0.40568671169051207, 0.40531020566641573, 0.4051778402673193, 0.4032247152673193, 0.4016172110316265, 0.40311294004141573, 0.40347915097891573, 0.4005082831325302, 0.40274672910391573, 0.40086419898343373, 0.4001523672816265, 0.4005082831325302, 0.4004170980798193, 0.3986772284450302, 0.3996640860316265, 0.4006612387048193, 0.4001729574548193, 0.3989316641566265, 0.4006612387048193, 0.3991963949548193, 0.3978227362575302, 0.39835219785391573, 0.3990537344691265, 0.3981889471950302, 0.39945083066641573, 0.39857574830572284, 0.3962358221950302, 0.3964902579066265, 0.3968461737575302, 0.39908461972891573, 0.39784332643072284, 0.3964799628200302, 0.3961240469691265, 0.39796539674322284, 0.3987081137048193, 0.3971211996423193, 0.39698883424322284, 0.39683587867093373, 0.3967343985316265, 0.39698883424322284, 0.3963887777673193, 0.39662262330572284, 0.39662262330572284, 0.3966329183923193, 0.39662262330572284, 0.3950254141566265, 0.3957784262048193, 0.3955342855798193, 0.39552399049322284, 0.3966329183923193, 0.3972432699548193, 0.3956563558923193, 0.39772125611822284, 0.3965108480798193, 0.39576813111822284, 0.39786391660391573, 0.3957784262048193, 0.3946592032191265, 0.39442535768072284, 0.39515777955572284, 0.3967549887048193, 0.39540192018072284, 0.3952901449548193, 0.3961446371423193, 0.3957784262048193, 0.3950460043298193, 0.39369293580572284, 0.39454742799322284, 0.39527984986822284, 0.39430328736822284, 0.39503570924322284, 0.39418121705572284, 0.3956563558923193, 0.39576813111822284, 0.39527984986822284, 0.39393707643072284, 0.39430328736822284, 0.39527984986822284, 0.3945577230798193, 0.3955342855798193, 0.39652114316641573, 0.3950460043298193, 0.39515777955572284, 0.39491363893072284, 0.3945577230798193, 0.39601227174322284, 0.3948018637048193, 0.39369293580572284, 0.3944356527673193, 0.39393707643072284, 0.39381500611822284, 0.39479156861822284, 0.39505629941641573, 0.39381500611822284, 0.3950460043298193, 0.3955342855798193, 0.3948018637048193, 0.3939473715173193, 0.3945577230798193, 0.3937032308923193, 0.39308258424322284, 0.3944356527673193, 0.3948018637048193, 0.3946797933923193, 0.39357086549322284, 0.3941915121423193, 0.3941915121423193, 0.39259430299322284, 0.39530044004141573, 0.3945577230798193, 0.3943135824548193, 0.3939473715173193, 0.3933370199548193, 0.39505629941641573, 0.39320465455572284, 0.3937032308923193, 0.3949239340173193, 0.39393707643072284, 0.39344879518072284, 0.3944356527673193, 0.3941915121423193, 0.3946797933923193, 0.3952901449548193, 0.39357086549322284, 0.39420180722891573, 0.3939473715173193, 0.3944356527673193, 0.3945577230798193, 0.39247223268072284, 0.39235016236822284, 0.39430328736822284, 0.3933370199548193, 0.39271637330572284, 0.39418121705572284, 0.39432387754141573, 0.39420180722891573, 0.39444594785391573, 0.3934590902673193, 0.39332672486822284, 0.3939473715173193, 0.39320465455572284, 0.3938253012048193, 0.3943135824548193, 0.3944356527673193, 0.3933370199548193, 0.39407973691641573, 0.3938253012048193, 0.3935811605798193, 0.3934590902673193, 0.39332672486822284, 0.39469008847891573, 0.39481215879141573, 0.39383559629141573, 0.3939473715173193, 0.39125152955572284, 0.39320465455572284, 0.3940694418298193, 0.39247223268072284, 0.3950460043298193, 0.3938253012048193, 0.3919736563441265, 0.39247223268072284, 0.39407973691641573, 0.3932149496423193, 0.39344879518072284, 0.3917295157191265, 0.39235016236822284, 0.3926045980798193, 0.39283844361822284, 0.39432387754141573, 0.39222809205572284, 0.39481215879141573, 0.39371352597891573, 0.3924825277673193, 0.39481215879141573, 0.39371352597891573, 0.39322524472891573, 0.3935811605798193, 0.39481215879141573, 0.3938253012048193, 0.3924619375941265, 0.3927266683923193, 0.39395766660391573, 0.3941915121423193, 0.3937032308923193, 0.3933370199548193, 0.3935811605798193, 0.39332672486822284, 0.3928487387048193, 0.39346938535391573, 0.39381500611822284, 0.3937032308923193, 0.3941915121423193, 0.3935811605798193, 0.39395766660391573, 0.3940694418298193, 0.3949239340173193, 0.3933370199548193, 0.3922383871423193, 0.3917501058923193, 0.39432387754141573, 0.39383559629141573, 0.39469008847891573, 0.3913633047816265, 0.39332672486822284], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-3, 3], "momentum": 0.6846092232817533, "shear_range": [1, 1], "patience_check_each": 1, "learning_rate": 0.005333427464980889, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "optimization": "adadelta", "nb_data_augmentation": 3, "learning_rate_decay_method": "exp", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 2.5506819766320973e-10, "valid_ratio": 0.15, "rotation_range": [0, 0], "learning_rate_decay": 0.023555667871101527}, "accuracy_valid_max": 0.6087484704442772, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='sqrt', interval=['exp', 'none', 'sqrt', 'lin'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'adadelta', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-3, 3)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.6066732751317772, "loss_train": [2.4095981121063232, 1.8256299495697021, 1.7120126485824585, 1.6474051475524902, 1.6016114950180054, 1.5663361549377441, 1.5369038581848145, 1.5131678581237793, 1.4913190603256226, 1.4695327281951904, 1.4497162103652954, 1.433042287826538, 1.4172940254211426, 1.400382161140442, 1.3874725103378296, 1.3737766742706299, 1.3619720935821533, 1.3505522012710571, 1.3412615060806274, 1.3313953876495361, 1.320800542831421, 1.3123449087142944, 1.3054975271224976, 1.2973060607910156, 1.2903801202774048, 1.2843663692474365, 1.277637243270874, 1.2713370323181152, 1.2652947902679443, 1.2594858407974243, 1.2547688484191895, 1.2503424882888794, 1.2448054552078247, 1.2415860891342163, 1.236681342124939, 1.23281991481781, 1.2275636196136475, 1.2242224216461182, 1.2211899757385254, 1.2170504331588745, 1.2128665447235107, 1.2104828357696533, 1.2086622714996338, 1.2050392627716064, 1.2012553215026855, 1.1987311840057373, 1.1948076486587524, 1.19326651096344, 1.1897635459899902, 1.1883862018585205, 1.1847432851791382, 1.1832200288772583, 1.1814935207366943, 1.1790523529052734, 1.1763339042663574, 1.1742866039276123, 1.1721224784851074, 1.1702830791473389, 1.1688979864120483, 1.166212558746338, 1.1642889976501465, 1.1636967658996582, 1.161165475845337, 1.1598858833312988, 1.1581170558929443, 1.156622052192688, 1.1554487943649292, 1.1543512344360352, 1.1525863409042358, 1.1504913568496704, 1.1498419046401978, 1.1476614475250244, 1.146924376487732, 1.14595365524292, 1.1437851190567017, 1.1432130336761475, 1.1425402164459229, 1.1410425901412964, 1.1386111974716187, 1.1374623775482178, 1.1376508474349976, 1.1377812623977661, 1.1367778778076172, 1.1346564292907715, 1.1338717937469482, 1.1347852945327759, 1.132019281387329, 1.1306390762329102, 1.1285481452941895, 1.1297681331634521, 1.1292263269424438, 1.127970576286316, 1.1258020401000977, 1.126204013824463, 1.1254818439483643, 1.125866174697876, 1.1236552000045776, 1.124527931213379, 1.1218156814575195, 1.1220927238464355, 1.1218444108963013, 1.1215333938598633, 1.120498776435852, 1.1208420991897583, 1.1189066171646118, 1.1192837953567505, 1.1179441213607788, 1.1173301935195923, 1.1184977293014526, 1.1173169612884521, 1.116010308265686, 1.1158498525619507, 1.114160180091858, 1.1146305799484253, 1.113183617591858, 1.114288091659546, 1.1136419773101807, 1.1130361557006836, 1.1116929054260254, 1.1124926805496216, 1.1123005151748657, 1.1123056411743164, 1.1117253303527832, 1.1105116605758667, 1.1110769510269165, 1.1113873720169067, 1.1092753410339355, 1.109481692314148, 1.1098629236221313, 1.1094932556152344, 1.1090333461761475, 1.1092392206192017, 1.1082165241241455, 1.1081774234771729, 1.1083548069000244, 1.1075464487075806, 1.1064348220825195, 1.1072924137115479, 1.106490135192871, 1.107078194618225, 1.1067001819610596, 1.1051486730575562, 1.1056588888168335, 1.1052354574203491, 1.1045849323272705, 1.1061056852340698, 1.105215072631836, 1.1036311388015747, 1.1039495468139648, 1.1045993566513062, 1.1048403978347778, 1.104400396347046, 1.1049188375473022, 1.103922724723816, 1.104364037513733, 1.1046810150146484, 1.1046812534332275, 1.1018366813659668, 1.1019465923309326, 1.102796196937561, 1.1026643514633179, 1.1018108129501343, 1.1023648977279663, 1.1008973121643066, 1.1038984060287476, 1.101168155670166, 1.102355718612671, 1.1003602743148804, 1.1005690097808838, 1.1009761095046997, 1.1018108129501343, 1.102281928062439, 1.101163387298584, 1.1032353639602661, 1.1017916202545166, 1.1016104221343994, 1.100703477859497, 1.1003602743148804, 1.099973440170288, 1.1003016233444214, 1.1008381843566895, 1.101444959640503, 1.100285530090332, 1.1004343032836914, 1.099919080734253, 1.1002458333969116, 1.0997487306594849, 1.1001501083374023, 1.100267767906189, 1.1005562543869019, 1.0985572338104248, 1.0977833271026611, 1.0999184846878052, 1.098967432975769, 1.0993362665176392, 1.0982500314712524, 1.098860740661621, 1.098732352256775, 1.100158929824829, 1.0988283157348633, 1.0988855361938477, 1.1000347137451172, 1.0983338356018066, 1.0988850593566895, 1.0990989208221436, 1.0990231037139893, 1.0997997522354126, 1.0990285873413086, 1.0987730026245117, 1.0977541208267212, 1.0973759889602661, 1.0989545583724976, 1.0981124639511108, 1.0983744859695435, 1.0984721183776855, 1.0963718891143799, 1.0979951620101929, 1.097399353981018, 1.0972950458526611, 1.0983691215515137, 1.0993894338607788, 1.097745656967163, 1.0978809595108032, 1.097980260848999, 1.0983914136886597, 1.0988534688949585, 1.098738670349121, 1.0960845947265625, 1.0963109731674194, 1.0979714393615723, 1.096489429473877, 1.0985521078109741, 1.0963631868362427, 1.0986257791519165, 1.09696626663208, 1.0989681482315063, 1.0977368354797363, 1.0976269245147705, 1.0980000495910645, 1.0972367525100708, 1.0972212553024292, 1.0975371599197388, 1.0984339714050293, 1.0984485149383545, 1.0988926887512207, 1.0984582901000977, 1.097752571105957, 1.0976183414459229, 1.0988399982452393, 1.0976307392120361, 1.0983141660690308, 1.0981501340866089, 1.0969815254211426, 1.0978201627731323, 1.0982441902160645, 1.0984231233596802, 1.096398115158081, 1.097579002380371, 1.0961836576461792, 1.097374677658081, 1.0973807573318481, 1.097899079322815, 1.0978078842163086, 1.0976815223693848, 1.0976715087890625, 1.0962873697280884, 1.0963597297668457, 1.0974125862121582, 1.0978041887283325, 1.0981539487838745, 1.0965067148208618, 1.0975068807601929, 1.0971646308898926, 1.0982086658477783, 1.0973988771438599, 1.0967077016830444, 1.097012996673584, 1.0973740816116333, 1.0969326496124268, 1.0977997779846191, 1.0963069200515747], "accuracy_train_first": 0.3345894544227575, "model": "residualv3", "loss_std": [0.4905448853969574, 0.14423629641532898, 0.12378057092428207, 0.1165902242064476, 0.11430549621582031, 0.11175335943698883, 0.11205222457647324, 0.1116400957107544, 0.11169250309467316, 0.11117265373468399, 0.11329888552427292, 0.11354273557662964, 0.11317655444145203, 0.11282477527856827, 0.11297538876533508, 0.11464717239141464, 0.11524701863527298, 0.11555413156747818, 0.11535631865262985, 0.1173560619354248, 0.11559408158063889, 0.11797582358121872, 0.11766897141933441, 0.11779755353927612, 0.11806252598762512, 0.11886905878782272, 0.11853520572185516, 0.11764892935752869, 0.1190604642033577, 0.11855494976043701, 0.11697235703468323, 0.11947561055421829, 0.11822747439146042, 0.1189333125948906, 0.11916783452033997, 0.12034840136766434, 0.11990666389465332, 0.11968094855546951, 0.1199844628572464, 0.11929896473884583, 0.11951278895139694, 0.11886079609394073, 0.11939025670289993, 0.11986465007066727, 0.12050032615661621, 0.12087653577327728, 0.11937429755926132, 0.11956769227981567, 0.12136978656053543, 0.1205345168709755, 0.1198568046092987, 0.12086711078882217, 0.12168136984109879, 0.1208660826086998, 0.12200037389993668, 0.11986969411373138, 0.11952441930770874, 0.12063285708427429, 0.12042199820280075, 0.11975850909948349, 0.11963658779859543, 0.12088746577501297, 0.12155986577272415, 0.11962622404098511, 0.12097953259944916, 0.1197405681014061, 0.11955523490905762, 0.11934761703014374, 0.12029638886451721, 0.11938224732875824, 0.12158626317977905, 0.12295933812856674, 0.12051581591367722, 0.12088331580162048, 0.12043379992246628, 0.12028523534536362, 0.12190873175859451, 0.12096095085144043, 0.11993878334760666, 0.11913547664880753, 0.12126847356557846, 0.12180039286613464, 0.12003499269485474, 0.11986837536096573, 0.11986863613128662, 0.12052945792675018, 0.12012442946434021, 0.12014966458082199, 0.12179726362228394, 0.1198703721165657, 0.12224851548671722, 0.12149018794298172, 0.12023495137691498, 0.1208769902586937, 0.11835901439189911, 0.12111511826515198, 0.11952865123748779, 0.12035956233739853, 0.11959652602672577, 0.12091826647520065, 0.12043425440788269, 0.12120534479618073, 0.12025509774684906, 0.11987311393022537, 0.11934619396924973, 0.12021611630916595, 0.12078731507062912, 0.11949347704648972, 0.12035242468118668, 0.12061744183301926, 0.12011127173900604, 0.12038984894752502, 0.12031834572553635, 0.11975988745689392, 0.1204540953040123, 0.11993391811847687, 0.12005746364593506, 0.12036117911338806, 0.12189584225416183, 0.12105622887611389, 0.1197107806801796, 0.12005648761987686, 0.12068264931440353, 0.11906053125858307, 0.12103703618049622, 0.12044397741556168, 0.11937341094017029, 0.1200447753071785, 0.11963386833667755, 0.121340811252594, 0.12123176455497742, 0.12061047554016113, 0.11983615159988403, 0.12042874842882156, 0.12271158397197723, 0.12231838703155518, 0.12021499872207642, 0.11904174089431763, 0.12121418118476868, 0.12296031415462494, 0.12003844976425171, 0.12012052536010742, 0.1204332709312439, 0.1207718476653099, 0.1200229600071907, 0.12094017118215561, 0.12134251743555069, 0.11963952332735062, 0.11945594847202301, 0.12096778303384781, 0.11991904675960541, 0.12142912298440933, 0.12065406888723373, 0.12101864069700241, 0.12034204602241516, 0.12215995788574219, 0.12053228914737701, 0.11950218677520752, 0.11973469704389572, 0.12015099823474884, 0.12136219441890717, 0.12140005081892014, 0.12158621847629547, 0.12077097594738007, 0.11995377391576767, 0.1196432039141655, 0.12180648744106293, 0.1221017837524414, 0.12227664887905121, 0.12143854796886444, 0.1201729029417038, 0.1205187663435936, 0.12088605761528015, 0.12123134732246399, 0.12060382962226868, 0.12238463759422302, 0.12020687758922577, 0.12039105594158173, 0.12139023095369339, 0.11970411986112595, 0.11945167928934097, 0.12128846347332001, 0.1212824285030365, 0.12017212063074112, 0.12073162198066711, 0.12027466297149658, 0.11915794759988785, 0.12072160094976425, 0.12044250965118408, 0.12175009399652481, 0.12009148299694061, 0.11918440461158752, 0.12100313603878021, 0.12059205770492554, 0.12048106640577316, 0.11880055069923401, 0.12125945836305618, 0.11860289424657822, 0.11993234604597092, 0.11997838318347931, 0.12045253813266754, 0.1207125261425972, 0.1203119158744812, 0.11898956447839737, 0.11995083838701248, 0.12239225953817368, 0.11946474015712738, 0.11906881630420685, 0.12057806551456451, 0.12039308995008469, 0.12158584594726562, 0.11925408989191055, 0.12037655711174011, 0.12093836069107056, 0.11958197504281998, 0.11974600702524185, 0.12202471494674683, 0.12111420184373856, 0.12114383280277252, 0.12047552317380905, 0.1199917271733284, 0.1202203780412674, 0.12028658390045166, 0.12022845447063446, 0.11990126967430115, 0.12050221860408783, 0.12102773785591125, 0.11854738742113113, 0.12093174457550049, 0.1220429539680481, 0.11958959698677063, 0.12091923505067825, 0.11935067921876907, 0.11958666145801544, 0.12011352181434631, 0.11976402252912521, 0.12246762961149216, 0.12169457226991653, 0.12050066143274307, 0.12085948139429092, 0.11998315155506134, 0.12150656431913376, 0.12069406360387802, 0.12129765748977661, 0.12135539948940277, 0.12010584771633148, 0.12136732786893845, 0.1203991174697876, 0.12078355997800827, 0.11974628269672394, 0.12113624066114426, 0.12135039269924164, 0.12045862525701523, 0.12049321085214615, 0.12102095037698746, 0.12147195637226105, 0.12114429473876953, 0.12033300846815109, 0.11947601288557053, 0.1187167689204216, 0.12059289962053299, 0.1206846758723259, 0.1202363446354866, 0.12049043923616409, 0.12104576081037521, 0.11963485926389694, 0.11995768547058105, 0.12131217122077942, 0.12128035724163055, 0.12005774676799774, 0.1204674020409584, 0.12030661106109619, 0.1198524460196495, 0.1229453980922699, 0.11938092112541199, 0.12035132944583893, 0.12027353048324585, 0.1209086999297142, 0.1202203780412674, 0.11974198371171951, 0.11961234360933304]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:13 2016", "state": "available"}], "summary": "c258c50b6104ec5b87cd860d6bc8f307"}