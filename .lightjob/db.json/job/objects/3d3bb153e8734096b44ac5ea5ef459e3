{"content": {"hp_model": {"f0": 16, "f1": 16, "f2": 32, "f3": 64, "nonlin": "very_leaky_rectify", "nbg1": 5, "nbg3": 5, "nbg2": 5, "fs0": 3, "fs1": 3, "fs2": 3, "fs3": 3, "pg2": 2, "pg3": 2, "pg1": 2}, "loss_train": [1.548498272895813, 1.0774837732315063, 0.8852598667144775, 0.7715370655059814, 0.6944292187690735, 0.6362058520317078, 0.5895890593528748, 0.5505088567733765, 0.5165250897407532, 0.4843699634075165, 0.4610369801521301, 0.4356858432292938, 0.41448819637298584, 0.3968125879764557, 0.37856799364089966, 0.36167478561401367, 0.3458114266395569, 0.3310745656490326, 0.3185902535915375, 0.3070400059223175, 0.2931831181049347, 0.28449422121047974, 0.27192360162734985, 0.2628570795059204, 0.2530004382133484, 0.24425658583641052, 0.23674045503139496, 0.22652840614318848, 0.21952314674854279, 0.2130640298128128, 0.2047104388475418, 0.19850854575634003, 0.19451019167900085, 0.18578392267227173, 0.18098801374435425, 0.1752418726682663, 0.1688588559627533, 0.16408251225948334, 0.1619369089603424, 0.1557687371969223, 0.15110363066196442, 0.14901426434516907, 0.14179618656635284, 0.1388065665960312, 0.13528084754943848, 0.13149283826351166, 0.12828773260116577, 0.12822559475898743, 0.12325611710548401, 0.12027968466281891, 0.11564002931118011, 0.11322586983442307, 0.11038655787706375, 0.10799544304609299, 0.10538830608129501, 0.1043306291103363, 0.10269653797149658, 0.10086444765329361, 0.09867865592241287, 0.09250063449144363, 0.09399711340665817, 0.09124298393726349, 0.08808615803718567, 0.08646246790885925, 0.08688004314899445, 0.08381964266300201, 0.08133828639984131, 0.08237574994564056, 0.08118674904108047, 0.07877456396818161, 0.07687512040138245, 0.0750499814748764, 0.07612188905477524, 0.07254139333963394, 0.0721120834350586, 0.07178682833909988, 0.06805764883756638, 0.068703293800354, 0.06624776870012283, 0.06585884839296341, 0.06752858310937881, 0.06507615745067596, 0.06342275440692902, 0.06328818202018738, 0.060303423553705215, 0.06187164783477783, 0.0605570524930954, 0.06038729473948479, 0.060707010328769684, 0.059074126183986664, 0.05953271687030792, 0.05636140704154968, 0.05777202546596527, 0.055016666650772095, 0.05481067672371864, 0.05462731420993805, 0.05312950164079666, 0.05270479992032051, 0.05182097479701042, 0.05271003395318985, 0.04944619908928871, 0.05036015436053276, 0.049007121473550797, 0.048938997089862823, 0.049779728055000305, 0.04967845231294632, 0.04748458415269852, 0.0467238575220108, 0.045650631189346313, 0.04725410416722298, 0.04672955721616745, 0.04631159454584122, 0.047479040920734406, 0.04490657150745392, 0.04662139713764191, 0.044592905789613724, 0.042274169623851776, 0.04225432127714157, 0.044397927820682526, 0.041516080498695374, 0.043669577687978745, 0.04167911410331726, 0.042204566299915314, 0.0421493798494339, 0.04121968150138855, 0.041458990424871445, 0.04030493646860123, 0.03980981931090355, 0.04026562348008156, 0.03937503695487976, 0.03916241601109505, 0.03937695547938347, 0.03853440284729004, 0.03931884840130806, 0.04100736603140831, 0.03909270092844963, 0.03778688982129097, 0.036215316504240036, 0.037241026759147644, 0.036890458315610886, 0.03927864134311676, 0.03629675880074501, 0.03633299097418785, 0.03564515337347984, 0.03643171116709709, 0.03857596963644028, 0.03620390594005585, 0.03524411842226982, 0.036004189401865005, 0.03433169424533844, 0.03430629521608353, 0.03597012907266617, 0.03433650732040405, 0.033866267651319504, 0.03624539077281952, 0.03356640040874481, 0.03385726362466812, 0.03345220908522606, 0.03473158925771713, 0.03432166203856468, 0.03390570729970932, 0.03259245678782463, 0.03244351968169212, 0.032407041639089584, 0.03202548623085022, 0.03422435373067856, 0.034201331436634064, 0.033409297466278076, 0.033485930413007736, 0.03407295048236847, 0.029927389696240425, 0.0335695818066597, 0.030492383986711502, 0.03277766704559326, 0.03196810930967331, 0.031157951802015305, 0.03278070315718651, 0.03100193478167057, 0.030411336570978165, 0.029612772166728973, 0.031586453318595886, 0.031004158779978752, 0.02788642980158329, 0.03097020462155342, 0.030424287542700768, 0.03179892897605896, 0.028185326606035233, 0.02936609275639057, 0.029972082003951073, 0.031297992914915085, 0.03052630089223385, 0.02979748696088791, 0.02857309766113758, 0.02990599349141121, 0.029969941824674606, 0.029648179188370705, 0.029706921428442, 0.02768852189183235, 0.02910909429192543, 0.0291706882417202, 0.029377004131674767, 0.028253400698304176, 0.0319635383784771, 0.028527213260531425, 0.027076827362179756, 0.027618061751127243, 0.02877444587647915, 0.026436161249876022, 0.029322458431124687, 0.027867304161190987, 0.031207432970404625, 0.027383526787161827, 0.027600204572081566, 0.02799122780561447, 0.02823442779481411, 0.0286695659160614, 0.02603328600525856, 0.028510961681604385, 0.029172254726290703, 0.0291611198335886, 0.02713681571185589, 0.02791423350572586, 0.02769583836197853, 0.02744150720536709, 0.028348742052912712, 0.02659815177321434, 0.027315013110637665, 0.025338904932141304, 0.02869192697107792, 0.026417098939418793, 0.027990475296974182, 0.027606112882494926], "moving_avg_accuracy_train": [0.03613036118032484, 0.08488277645118122, 0.13239783476375044, 0.1860274024374769, 0.24064473374342465, 0.2945919228829249, 0.34167983774902516, 0.388003765340171, 0.4280168671710949, 0.4664416585997495, 0.5042970594329732, 0.5390947638578929, 0.5725840984378658, 0.6039984287657293, 0.6320248242381781, 0.6587876123823744, 0.68038911441587, 0.7031382517814997, 0.7237754160713268, 0.7389595539930793, 0.7556985841165658, 0.7722560602264116, 0.787957495720474, 0.7982157386272011, 0.8109562660645456, 0.8204281235677717, 0.8302616378075247, 0.8409204780065618, 0.8505995007404663, 0.8579017252176839, 0.8659104889673718, 0.8738927590421185, 0.8785683630809207, 0.8831063615538826, 0.8878205313116542, 0.8932466766912399, 0.8980836685078579, 0.9005935867715056, 0.9036405944599419, 0.9075453315890216, 0.9096112435897725, 0.9135743914772423, 0.9169320693295642, 0.9193309476621578, 0.9224291540852646, 0.9264660726791375, 0.9287115821113437, 0.9321923375157041, 0.9349087796939048, 0.9349869366543777, 0.9376983225270537, 0.939915319477929, 0.9422222227230117, 0.9441380364245477, 0.9462225947237688, 0.94724543967761, 0.9496191820932007, 0.9516532076707946, 0.9534489174096676, 0.9550000962032617, 0.9560519269472304, 0.957572994519211, 0.9589418471875372, 0.9595134362783073, 0.9607905513183429, 0.961744642354375, 0.962235950774899, 0.9628642123557701, 0.9633016924963929, 0.9641721161777245, 0.9637956808207956, 0.964856159948249, 0.9656594204415194, 0.9665266222581095, 0.9678813435513554, 0.9681612686450478, 0.9683970693829793, 0.9694275621839763, 0.9703154781751117, 0.9710076817707143, 0.971837639299623, 0.9727170264113273, 0.9731923266714035, 0.9741316296435674, 0.9744979495661154, 0.9738375206405576, 0.9740612985979582, 0.9747230061262668, 0.9756672791743544, 0.9756965636807838, 0.9760715118139052, 0.9765043683325423, 0.9769705609635737, 0.97724139690533, 0.9779036760386249, 0.977016462562208, 0.9774128445797967, 0.9778254640646926, 0.9787013788927656, 0.9794803295451557, 0.9800023847227922, 0.9803118351636266, 0.9805926657091872, 0.981040689651373, 0.9815694331862358, 0.9816616888628595, 0.9823074410325444, 0.9829769015423853, 0.9835864274964893, 0.9840746190837728, 0.9845046188194524, 0.9847962514315548, 0.9851773033717327, 0.9853226845667208, 0.9854418658493437, 0.9857816438846566, 0.9862362536402478, 0.9865338313262414, 0.9863621981186357, 0.9869122122722576, 0.9871561810367262, 0.9874802764747203, 0.9874232981939426, 0.987895104125748, 0.9880057983262684, 0.9880496916329458, 0.9882263072910797, 0.9883853334810379, 0.988442390497229, 0.9883518716856015, 0.9883867342932503, 0.988820325335363, 0.988875735844693, 0.9859429801127523, 0.9864117192288765, 0.9857570405345787, 0.9863861716370824, 0.9869617262733926, 0.987340144419863, 0.9874319658778858, 0.9877680824591634, 0.9881147291608754, 0.9881034794590736, 0.9883631440869942, 0.9885177511437802, 0.988824344257992, 0.9892350645940976, 0.9896977548977923, 0.9896120161258979, 0.9899463304728411, 0.9898984771124802, 0.9897391155988605, 0.9899026098794599, 0.9901706624700946, 0.9901049541099899, 0.9903504471287621, 0.9903644526016094, 0.9906653399307341, 0.9908175919864795, 0.9910150366568791, 0.9911324271864661, 0.9913309764690191, 0.99154916230426, 0.9918641481940814, 0.9919592623925304, 0.992140196272325, 0.9919938280212921, 0.9907391939156377, 0.9909747413764641, 0.9910355633697702, 0.9914111736994599, 0.991168007891437, 0.9915513001082457, 0.9900505275344366, 0.9905734695726596, 0.9910255522654028, 0.9906815117698519, 0.9911670041190755, 0.9912249840262433, 0.9914514439569523, 0.9917413244493615, 0.9921184382841872, 0.9898215906201742, 0.9900977451367374, 0.9902578924980636, 0.990695029922076, 0.9910186630905826, 0.9913796874065244, 0.9918580691123006, 0.9919677421117848, 0.9922967096411011, 0.9925136532603243, 0.9926462316462243, 0.992584118488754, 0.9928142099506021, 0.992981836834141, 0.9930698138650127, 0.9930839250749491, 0.99340583390674, 0.993630447688685, 0.9938419006876736, 0.9940345335355729, 0.9941311731879681, 0.9940181860775046, 0.9941514098054869, 0.9944270240332715, 0.9944518986013823, 0.9944951760031489, 0.9945271502183102, 0.9944584149572304, 0.9946265987591264, 0.9946152398129848, 0.9944957708162286, 0.9945696463751097, 0.9947034915959413, 0.9947100200030231, 0.9948275027122537, 0.9944311131541606, 0.9946299289220778, 0.9944391644524891, 0.9944884016155828, 0.9946536228004623, 0.9947628303859107, 0.9945820633068527, 0.9947960470428433, 0.994900276750473, 0.9950568985540156, 0.9952466502533852, 0.9952570275637794, 0.9953662764443062, 0.9953599687403517, 0.9953148003258496], "dataset": "Cifar10", "nb_examples_train": 42500, "moving_avg_accuracy_valid": [0.0354271578501506, 0.08414274284638552, 0.13074467596950298, 0.1830415080242846, 0.2355378443265248, 0.28805827864387235, 0.3337956430799369, 0.3784353335253318, 0.4166720489020908, 0.4524533097498335, 0.4885640181667929, 0.5210076210564389, 0.5521193966013974, 0.5816551390760468, 0.6078506532652042, 0.6321021207888343, 0.6519528144422551, 0.6721490992630897, 0.6902992825220218, 0.7037097604256931, 0.7183122230597052, 0.732714852175045, 0.7459956307000103, 0.7548384798570423, 0.7653443426676484, 0.7730254816313051, 0.7808306494885059, 0.7895694324782848, 0.7975239044224745, 0.8035210551135101, 0.8103000913566772, 0.8163553373038408, 0.8193982144827188, 0.8230798338759379, 0.826548894210106, 0.8306792316339748, 0.8345674337529568, 0.8360057393234444, 0.8384701773922294, 0.8412792566974342, 0.8426018734316818, 0.8458512458117816, 0.8484247655736004, 0.8501701443438006, 0.8526515121100983, 0.855376112875745, 0.8569594953287578, 0.859679514357629, 0.8611569989629053, 0.8604349243489943, 0.8626650341354803, 0.8640932549312696, 0.8657864861493625, 0.866947271834125, 0.8683053908009384, 0.8690119140325915, 0.8714717801406275, 0.8727416001969714, 0.8736372090967021, 0.8747016637800289, 0.8750584399377941, 0.8762168231654003, 0.8771271497438151, 0.8772210812773402, 0.8784216070445611, 0.8783555017335538, 0.877817873717578, 0.8777500770743594, 0.8776189064339415, 0.8779057439061346, 0.8771648330132621, 0.8774817822702943, 0.8781831051727829, 0.8789882827485015, 0.8803925653546754, 0.8807357448131837, 0.8803385104579948, 0.8808518167917134, 0.8813392360632197, 0.8818755696575754, 0.8829656800016823, 0.8839356017887882, 0.8841980327620178, 0.8848432297211323, 0.8848735610694257, 0.8837198657776186, 0.8842135959732002, 0.8846863381736964, 0.8853763898796702, 0.8859058101443387, 0.8855338261743325, 0.8857464450629233, 0.885892944899628, 0.8857653585704333, 0.8865906193530737, 0.885539802899694, 0.8854750333589716, 0.8858348683608004, 0.886464925152356, 0.8871072774695752, 0.8875134666089128, 0.8883215784852957, 0.8882889547105612, 0.8883318059921407, 0.8890539658955621, 0.8893285803658703, 0.8898534065819188, 0.8904712050427028, 0.890884857317047, 0.8910241812615471, 0.8912075194418683, 0.891373553312817, 0.8913287008053306, 0.8913534867394812, 0.891406238122009, 0.891560489121555, 0.8920228748856044, 0.8924888797069084, 0.892184980676353, 0.8927487562344707, 0.8932327696829363, 0.8936195536615553, 0.8933093619908063, 0.8938165870304305, 0.8942374979810019, 0.894375265737495, 0.8943415948207486, 0.8946164667769267, 0.8946888350653486, 0.8945921865926992, 0.8945937407120438, 0.8956643576988212, 0.8960266799296921, 0.8918948503685753, 0.8922058477300612, 0.8917502349544195, 0.8917002173418842, 0.8924691016223795, 0.8928629811815271, 0.8924921103977117, 0.892862363542805, 0.8932301534498197, 0.8928653635848829, 0.8930538660535783, 0.8931746901504042, 0.8939579070822764, 0.8944542532810518, 0.8944065065579918, 0.8942323456894666, 0.8951336416645712, 0.89508913927334, 0.8946594916298916, 0.8950093486604265, 0.8950078666840676, 0.8948865216101638, 0.8953022133874005, 0.8952501194018231, 0.8958522664883728, 0.8958600309445807, 0.8960817450470352, 0.8962049570257654, 0.8964399771364419, 0.8965325134495296, 0.8965994710654199, 0.8968428383884712, 0.8971330521493982, 0.8968703716991421, 0.8955912140943634, 0.8957970117361318, 0.8958744253497928, 0.8959542456160183, 0.895441175864281, 0.8961421695824462, 0.8939795657171986, 0.8944207998928432, 0.894879975315833, 0.8944610960542044, 0.8951837670398984, 0.8956063553679116, 0.8957893133458041, 0.8960048626682268, 0.8969486335079553, 0.8939922278943586, 0.8942246763210373, 0.8942334198617499, 0.8947123627965086, 0.8950670807243125, 0.8959093172584325, 0.8964577515905712, 0.8969981115971767, 0.8975220862055312, 0.8976456894260926, 0.8977956124356671, 0.8975622731894648, 0.8978151055467231, 0.8980202996230748, 0.8980981995365204, 0.8982496406427328, 0.8989037804941221, 0.8994304416954628, 0.8995972019781003, 0.8998755335969318, 0.9003457586163802, 0.9004464307780856, 0.9004780595846896, 0.9004281357798352, 0.9006691136175143, 0.900393594386787, 0.9003196140426113, 0.900299800840534, 0.9004619859014353, 0.9003201312495448, 0.9003257098979337, 0.9006481134939837, 0.9007134026246304, 0.9010570425956012, 0.9007814105781344, 0.8999657883456222, 0.9004269878902016, 0.9002265683745247, 0.9005222650291657, 0.9006042570409328, 0.9004736188462522, 0.9003814880421992, 0.900627130653642, 0.9005053826202808, 0.9008352625152558, 0.9008127125909139, 0.9006143126608888, 0.9001479315171643, 0.9001351385537009, 0.8997156453120356], "moving_var_accuracy_train": [0.011748626991186516, 0.03196494624474615, 0.04908757851829321, 0.07006399542630115, 0.08990507179452398, 0.10710725755954874, 0.11635197734152782, 0.12402993601460253, 0.12603637727632921, 0.1267209209157168, 0.12694611117434138, 0.12514942215610395, 0.12272829971597793, 0.11933721109391325, 0.11447279957312484, 0.10947174107907252, 0.10272419098209333, 0.09710948114180659, 0.09123156597695378, 0.08418343177909964, 0.07828684476646455, 0.07292551042597115, 0.06785177507254186, 0.06201368149308842, 0.05727320269821513, 0.0523533271894464, 0.047988276491232565, 0.044211946711606796, 0.04063390337019709, 0.03705041537401847, 0.03392263650780146, 0.031103822576937095, 0.028190191777392355, 0.025556513470918554, 0.023200872692372494, 0.021145772906258846, 0.019241764024139227, 0.01737428482893703, 0.01572041464872384, 0.014285595932276374, 0.012895448270602355, 0.011747262314143726, 0.010674002087769112, 0.009658393434283485, 0.008778944038216763, 0.008047720039997102, 0.007288328849488536, 0.006668536888204532, 0.006068094722351649, 0.005461340226710718, 0.004981370724194566, 0.004527469331096823, 0.004122618621226698, 0.0037433898383549677, 0.003408159304245136, 0.00307675928001701, 0.0028197952295154825, 0.002575051047016691, 0.002346567103511569, 0.0021335657940076726, 0.0019301663458325265, 0.0017579725302760512, 0.0015990390958967005, 0.0014420756131052171, 0.0013125472572240626, 0.0011894851388469874, 0.0010727090806389899, 0.0009689905861010791, 0.0008738140273519244, 0.0007932513610819369, 0.0007152015571752593, 0.000653802945275614, 0.0005942296975284926, 0.0005415750786919168, 0.0005039349988640897, 0.0004542467215003893, 0.0004093224672424319, 0.0003779474592343487, 0.0003472482665767397, 0.0003168357522789514, 0.0002913516425491855, 0.0002691763735243527, 0.000244291929206974, 0.00022780334694791875, 0.00020623072482402725, 0.00018953314963304348, 0.00017103052383770416, 0.00015786818313111688, 0.0001501062291221072, 0.00013510332445074781, 0.0001228582669284535, 0.0001122587231271484, 0.0001029888709374861, 9.335015280986085e-05, 8.796266038245638e-05, 8.625072411883317e-05, 7.903972004175924e-05, 7.266804159142533e-05, 7.230627850662631e-05, 7.053652772569432e-05, 6.593574942959877e-05, 6.02040106646328e-05, 5.48934017560481e-05, 5.1210590655388206e-05, 4.860565912078125e-05, 4.382169319752687e-05, 4.3192486659648855e-05, 4.2906834361810564e-05, 4.195984792416748e-05, 3.9908842364800415e-05, 3.758205608248083e-05, 3.458929669820764e-05, 3.2437172258406644e-05, 2.938367625927135e-05, 2.657314623649288e-05, 2.495487363237378e-05, 2.4319416538044483e-05, 2.2684447197052225e-05, 2.0681124098924134e-05, 2.1335651811690913e-05, 1.97377734528488e-05, 1.8709336783920874e-05, 1.6867621825852206e-05, 1.718426717884826e-05, 1.5576119315223152e-05, 1.4035846985040472e-05, 1.291300010281936e-05, 1.1849304054370731e-05, 1.0693673176803393e-05, 9.698048756449435e-06, 8.73918249351315e-06, 9.557274970365789e-06, 8.629180394227171e-06, 8.517576800388332e-05, 7.86356384343589e-05, 7.462951232582977e-05, 7.072881459048498e-05, 6.663730138584016e-05, 6.1262373889458e-05, 5.521201712189333e-05, 5.0707584615591e-05, 4.671830157630176e-05, 4.204761042078726e-05, 3.844968084964692e-05, 3.4819842842754485e-05, 3.2183852597618245e-05, 3.0483688088272422e-05, 2.9362060133643126e-05, 2.6492014353332457e-05, 2.484870766114808e-05, 2.2384446391913733e-05, 2.037456658093096e-05, 1.8577683340936196e-05, 1.7366584728956202e-05, 1.566878455334941e-05, 1.4644307498407214e-05, 1.3181642127993584e-05, 1.2678276578644764e-05, 1.1619075117088426e-05, 1.0808027186202708e-05, 9.85124929551311e-06, 9.220920724382952e-06, 8.727274180242771e-06, 8.747491759297221e-06, 7.954162980086858e-06, 7.453380301795837e-06, 6.900855255809826e-06, 2.0377730381872046e-05, 1.883930080040077e-05, 1.6988664554188094e-05, 1.655954617669535e-05, 1.543575805074805e-05, 1.5214398556868288e-05, 3.3963823565858685e-05, 3.302865658734031e-05, 3.156519977830837e-05, 2.9473954563688223e-05, 2.864788449771258e-05, 2.581335107465795e-05, 2.3693572869142723e-05, 2.20804918811433e-05, 2.115237629278189e-05, 6.651672138864288e-05, 6.055140110294309e-05, 5.472708558870666e-05, 5.097417917708568e-05, 4.681940710919625e-05, 4.331051340858742e-05, 4.103910357552019e-05, 3.704344671931099e-05, 3.431307876547928e-05, 3.130535169422643e-05, 2.833300978047449e-05, 2.5534431201405467e-05, 2.3457466808603554e-05, 2.13646090765079e-05, 1.9297807790505962e-05, 1.7369819147668224e-05, 1.656546489676562e-05, 1.536298056644598e-05, 1.4229093846832985e-05, 1.314015118895784e-05, 1.1910189071797448e-05, 1.0834064948795662e-05, 9.910395509193587e-06, 9.60302478129018e-06, 8.64829100040938e-06, 7.800318301901404e-06, 7.029487625627893e-06, 6.369059688106496e-06, 5.986725840277601e-06, 5.389214487166851e-06, 4.97874860912359e-06, 4.529992132011076e-06, 4.238223807065098e-06, 3.814785007249814e-06, 3.55752618923858e-06, 4.615895706202729e-06, 4.5100555217353094e-06, 4.3865697152790304e-06, 3.969731427816724e-06, 3.818440644431975e-06, 3.5439332504640277e-06, 3.4836305572581796e-06, 3.5473688549488993e-06, 3.2904064570270977e-06, 3.182139315428789e-06, 3.187976750608684e-06, 2.8701482726869793e-06, 2.6905513064855666e-06, 2.4218542599996004e-06, 2.1980305050173667e-06], "duration": 134484.53098, "accuracy_train": [0.36130361180324844, 0.5236545138888888, 0.5600333595768734, 0.6686935115010152, 0.7322007154969545, 0.7801166251384275, 0.7654710715439276, 0.8049191136604835, 0.7881347836494095, 0.8122647814576411, 0.844995666931986, 0.8522741036821706, 0.8739881096576227, 0.8867274017165007, 0.8842623834902179, 0.8996527056801403, 0.8748026327173312, 0.9078804880721669, 0.9095098946797711, 0.875616795288852, 0.9063498552279439, 0.9212733452150241, 0.9292704151670359, 0.8905399247877446, 0.925621013000646, 0.905674841096807, 0.9187632659653008, 0.9368500397978959, 0.9377107053456073, 0.9236217455126431, 0.9379893627145626, 0.9457331897148394, 0.9206487994301403, 0.9239483478105389, 0.9302480591315985, 0.9420819851075121, 0.9416165948574198, 0.9231828511443337, 0.9310636636558692, 0.9426879657507383, 0.9282044515965301, 0.9492427224644703, 0.9471511700004615, 0.9409208526555003, 0.9503130118932264, 0.9627983400239941, 0.9489211670011997, 0.9635191361549464, 0.9593567592977114, 0.9356903492986341, 0.962100795381137, 0.9598682920358066, 0.962984351928756, 0.9613803597383721, 0.9649836194167589, 0.9564510442621816, 0.970982863833518, 0.96995943786914, 0.9696103050595238, 0.9689607053456073, 0.9655184036429494, 0.9712626026670359, 0.9712615212024732, 0.9646577380952381, 0.9722845866786637, 0.9703314616786637, 0.9666577265596161, 0.9685185665836102, 0.9672390137619971, 0.9720059293097084, 0.9604077626084349, 0.9744004720953304, 0.9728887648809523, 0.9743314386074198, 0.9800738351905685, 0.9706805944882798, 0.9705192760243633, 0.9787019973929494, 0.9783067220953304, 0.977237514131137, 0.9793072570598007, 0.9806315104166666, 0.9774700290120893, 0.9825853563930418, 0.9777948288690477, 0.9678936603105389, 0.9760753002145626, 0.9806783738810447, 0.9841657366071429, 0.975960124238649, 0.9794460450119971, 0.9804000770002769, 0.9811662946428571, 0.979678920381137, 0.9838641882382798, 0.9690315412744556, 0.9809802827380952, 0.981539039428756, 0.9865846123454227, 0.9864908854166666, 0.9847008813215209, 0.983096889131137, 0.9831201406192323, 0.9850729051310447, 0.986328125, 0.9824919899524732, 0.9881192105597084, 0.9890020461309523, 0.9890721610834257, 0.9884683433693245, 0.9883746164405685, 0.9874209449404762, 0.9886067708333334, 0.9866311153216132, 0.9865144973929494, 0.9888396462024732, 0.9903277414405685, 0.9892120305001846, 0.9848174992501846, 0.9918623396548542, 0.9893518999169435, 0.9903971354166666, 0.9869104936669435, 0.9921413575119971, 0.9890020461309523, 0.9884447313930418, 0.9898158482142857, 0.9898165691906607, 0.9889559036429494, 0.9875372023809523, 0.9887004977620893, 0.992722644714378, 0.9893744304286637, 0.9595481785252861, 0.9906303712739941, 0.9798649322858989, 0.9920483515596161, 0.9921417180001846, 0.9907459077380952, 0.9882583590000923, 0.9907931316906607, 0.9912345494762828, 0.9880022321428571, 0.9907001257382798, 0.9899092146548542, 0.9915836822858989, 0.9929315476190477, 0.9938619676310447, 0.9888403671788483, 0.9929551595953304, 0.9894677968692323, 0.9883048619762828, 0.9913740584048542, 0.9925831357858066, 0.9895135788690477, 0.9925598842977114, 0.9904905018572352, 0.9933733258928571, 0.9921878604881875, 0.9927920386904762, 0.9921889419527501, 0.9931179200119971, 0.9935128348214286, 0.9946990212024732, 0.9928152901785714, 0.9937686011904762, 0.9906765137619971, 0.9794474869647471, 0.9930946685239018, 0.9915829613095238, 0.9947916666666666, 0.9889795156192323, 0.9950009300595238, 0.976543574370155, 0.9952799479166666, 0.9950942965000923, 0.987585147309893, 0.9955364352620893, 0.991746803190753, 0.9934895833333334, 0.9943502488810447, 0.9955124627976191, 0.9691499616440569, 0.9925831357858066, 0.99169921875, 0.9946292667381875, 0.9939313616071429, 0.99462890625, 0.9961635044642857, 0.9929547991071429, 0.9952574174049464, 0.9944661458333334, 0.9938394371193245, 0.9920251000715209, 0.9948850331072352, 0.9944904787859912, 0.9938616071428571, 0.993210925964378, 0.9963030133928571, 0.9956519717261905, 0.9957449776785714, 0.9957682291666666, 0.9950009300595238, 0.9930013020833334, 0.9953504233573275, 0.9969075520833334, 0.994675769714378, 0.9948846726190477, 0.9948149181547619, 0.9938397976075121, 0.9961402529761905, 0.9945130092977114, 0.9934205498454227, 0.9952345264050388, 0.9959080985834257, 0.9947687756667589, 0.9958848470953304, 0.9908636071313216, 0.9964192708333334, 0.9927222842261905, 0.9949315360834257, 0.996140613464378, 0.9957456986549464, 0.9929551595953304, 0.9967219006667589, 0.99583834411914, 0.9964664947858989, 0.9969544155477114, 0.9953504233573275, 0.9963495163690477, 0.9953031994047619, 0.9949082845953304], "end": "2016-02-02 23:08:29.594000", "epoch": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0, 61.0, 62.0, 63.0, 64.0, 65.0, 66.0, 67.0, 68.0, 69.0, 70.0, 71.0, 72.0, 73.0, 74.0, 75.0, 76.0, 77.0, 78.0, 79.0, 80.0, 81.0, 82.0, 83.0, 84.0, 85.0, 86.0, 87.0, 88.0, 89.0, 90.0, 91.0, 92.0, 93.0, 94.0, 95.0, 96.0, 97.0, 98.0, 99.0, 100.0, 101.0, 102.0, 103.0, 104.0, 105.0, 106.0, 107.0, 108.0, 109.0, 110.0, 111.0, 112.0, 113.0, 114.0, 115.0, 116.0, 117.0, 118.0, 119.0, 120.0, 121.0, 122.0, 123.0, 124.0, 125.0, 126.0, 127.0, 128.0, 129.0, 130.0, 131.0, 132.0, 133.0, 134.0, 135.0, 136.0, 137.0, 138.0, 139.0, 140.0, 141.0, 142.0, 143.0, 144.0, 145.0, 146.0, 147.0, 148.0, 149.0, 150.0, 151.0, 152.0, 153.0, 154.0, 155.0, 156.0, 157.0, 158.0, 159.0, 160.0, 161.0, 162.0, 163.0, 164.0, 165.0, 166.0, 167.0, 168.0, 169.0, 170.0, 171.0, 172.0, 173.0, 174.0, 175.0, 176.0, 177.0, 178.0, 179.0, 180.0, 181.0, 182.0, 183.0, 184.0, 185.0, 186.0, 187.0, 188.0, 189.0, 190.0, 191.0, 192.0, 193.0, 194.0, 195.0, 196.0, 197.0, 198.0, 199.0, 200.0, 201.0, 202.0, 203.0, 204.0, 205.0, 206.0, 207.0, 208.0, 209.0, 210.0, 211.0, 212.0, 213.0, 214.0, 215.0, 216.0, 217.0, 218.0, 219.0, 220.0, 221.0, 222.0, 223.0, 224.0, 225.0, 226.0, 227.0, 228.0, 229.0, 230.0, 231.0], "moving_var_accuracy_valid": [0.011295751620055385, 0.031525050451778364, 0.04791820694390414, 0.06774101403620804, 0.08576970055900837, 0.10201829469105286, 0.11064362377196404, 0.11751357906231373, 0.11892063878131184, 0.11855126255386851, 0.11843198565985363, 0.1160620734100177, 0.11316734926705485, 0.10970185509210865, 0.1049075142556069, 0.09970996592349342, 0.09328541967784172, 0.08762788699513607, 0.0818299606666178, 0.07526553285839974, 0.06965806680735923, 0.0645591816555296, 0.059690675194039276, 0.054425371505561565, 0.04997619273556288, 0.04550957252401766, 0.04150690107912762, 0.03804350792449691, 0.03480861974724531, 0.03165145012021969, 0.028899903099673278, 0.02633990682103172, 0.023789248052660177, 0.0215323121396029, 0.019487390342061508, 0.017692188492970468, 0.016059032685135928, 0.014471747922849193, 0.013079234225518169, 0.01184232914185272, 0.010673840062898853, 0.009701481844389973, 0.008790940695631223, 0.007939263749531291, 0.007200752048502752, 0.006547487887641945, 0.005915302998810331, 0.005390359230586091, 0.004870969954356937, 0.004388565484653737, 0.003994469443126394, 0.00361338083058748, 0.003277846035150052, 0.002962188242288594, 0.0026825698022118994, 0.0024188053976824998, 0.002231383329339429, 0.0020227569831849247, 0.0018277003225779217, 0.0016551278642758362, 0.0014907606808889997, 0.0013537612781180926, 0.0012258434006205987, 0.0011033384687554521, 0.0010059759809397566, 0.0009054177120550713, 0.0008174773358016235, 0.0007357709696849467, 0.0006623487243486207, 0.0005968543335328463, 0.0005421094407401556, 0.0004888026081499395, 0.0004443490316569414, 0.0004057489268472095, 0.00038292212090451286, 0.00034568985808074046, 0.0003125410284691472, 0.00028365827615235305, 0.00025743064645324, 0.000234276465327827, 0.00022154388385600452, 0.00020785622992832776, 0.00018769043707688715, 0.0001726679054136537, 0.000155409394788492, 0.0001518475707466822, 0.00013885673922627457, 0.00012698243199681753, 0.00011856973100939113, 0.00010923533025822723, 9.955714589787834e-05, 9.000829243416096e-05, 8.120062301013527e-05, 7.322706515169821e-05, 7.20338568708066e-05, 7.476840815196649e-05, 6.732932317741837e-05, 6.176172191654635e-05, 5.9158293770158554e-05, 5.6956012888074805e-05, 5.2745318151510187e-05, 5.334818957911766e-05, 4.802294941730717e-05, 4.323718056657344e-05, 4.360709684490352e-05, 3.9925105126137336e-05, 3.841157762698979e-05, 3.8005494307614805e-05, 3.574491871348432e-05, 3.2345127295735526e-05, 2.9413130561433356e-05, 2.671992272200994e-05, 2.4066036176659402e-05, 2.1664961641778958e-05, 1.9523509852828392e-05, 1.7785299205294245e-05, 1.7930974637924e-05, 1.809232161543896e-05, 1.7114281040847094e-05, 1.8263438856140895e-05, 1.854551613518669e-05, 1.8037381136715254e-05, 1.709961287646168e-05, 1.7705146756211283e-05, 1.7529126335388488e-05, 1.5947033294412124e-05, 1.4362533540681852e-05, 1.3606271517252534e-05, 1.2292778888049168e-05, 1.1147569344633264e-05, 1.0032834147752371e-05, 1.9345537324367006e-05, 1.8592480182779668e-05, 0.00017038137186356917, 0.00015421370890687268, 0.00014066058502813645, 0.00012661704237939642, 0.00011927598547259189, 0.00010874465688936142, 9.910809744501564e-05, 9.043107422357733e-05, 8.260539154253642e-05, 7.554249719832817e-05, 6.830804610483384e-05, 6.16086276557146e-05, 6.0968623751485334e-05, 5.7088997317685704e-05, 5.140061533198385e-05, 4.653354187191416e-05, 4.9191197597379564e-05, 4.428990200306928e-05, 4.15222856804497e-05, 3.847165658873727e-05, 3.46245106961489e-05, 3.1294581269180354e-05, 2.97203200252217e-05, 2.6772712072699572e-05, 2.7358670889991325e-05, 2.4623346382014032e-05, 2.2603426032857816e-05, 2.0479714154895554e-05, 1.8928852811207455e-05, 1.7113034253245572e-05, 1.5442080728852577e-05, 1.4430921541330092e-05, 1.374584563047948e-05, 1.2992270237952211e-05, 2.6419240814924858e-05, 2.415849075764959e-05, 2.1796577490105e-05, 1.9674261215197342e-05, 2.0076000225008243e-05, 2.2490929938672067e-05, 6.233353624666113e-05, 5.7852371001805965e-05, 5.396471252332593e-05, 5.01473797933951e-05, 4.983292199613128e-05, 4.6456857851274896e-05, 4.211243466121826e-05, 3.831934478866802e-05, 4.2503740891098285e-05, 0.00011691637417094523, 0.0001057110271934389, 9.514061251963274e-05, 8.769102828046733e-05, 8.005434872717042e-05, 7.843317526911092e-05, 7.329687969221543e-05, 6.85950921536425e-05, 6.420652745008166e-05, 5.7923374510271706e-05, 5.2333329238443334e-05, 4.759002114896309e-05, 4.3406336841958064e-05, 3.9444644638491036e-05, 3.555479574327533e-05, 3.220572584680538e-05, 3.283624376870623e-05, 3.2048967580815324e-05, 2.909435174952167e-05, 2.6882132984941982e-05, 2.618392380668493e-05, 2.365674538329829e-05, 2.1300074277633255e-05, 1.9192498326490284e-05, 1.779588135811385e-05, 1.669949084080773e-05, 1.5078799578646129e-05, 1.3574452687570557e-05, 1.2453743364629888e-05, 1.1389473708533712e-05, 1.0250806429540963e-05, 1.0161222495300641e-05, 9.183464280996137e-06, 9.32791371973512e-06, 9.078879429236695e-06, 1.4158148121827262e-05, 1.4656678488926328e-05, 1.3552522480410743e-05, 1.2984198836462032e-05, 1.1746283162758467e-05, 1.0725251887667354e-05, 9.729119464399576e-06, 9.29927015096725e-06, 8.50274638851636e-06, 8.631858455642786e-06, 7.773249101868917e-06, 7.350186981787766e-06, 8.572770624604218e-06, 7.716966501371383e-06, 8.529041069459786e-06], "accuracy_test": 0.5611985809948979, "start": "2016-02-01 09:47:05.063000", "learning_rate_per_epoch": [0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778, 0.0029495111666619778], "accuracy_train_first": 0.36130361180324844, "accuracy_train_last": 0.9949082845953304, "batch_size_eval": 1024, "accuracy_train_std": [0.014273711325290381, 0.01664370615348439, 0.017252996042191677, 0.01714856446465265, 0.019145627094905, 0.019034755431591163, 0.020122176504175665, 0.020155836999609992, 0.018040448309198924, 0.01936733954769085, 0.0193041926417107, 0.01808842073878499, 0.01708856761542222, 0.01873295315334793, 0.01825509194630908, 0.017275796270035237, 0.018059170501923655, 0.01779941666348699, 0.01779269665554824, 0.016838391936802147, 0.01732166206978464, 0.016628860084582593, 0.016062315548596072, 0.017629838509507154, 0.01569556758368635, 0.01616019702020178, 0.015538567495628763, 0.01510089367223617, 0.014298583136893294, 0.01476463666110746, 0.015801190911359755, 0.01336482955060129, 0.013223663300525781, 0.01467901487126292, 0.01491020629229566, 0.013918233653887538, 0.015411426382139616, 0.015379324595221101, 0.014115982160474229, 0.013762571436645468, 0.013390191577247029, 0.012700634541418955, 0.013968640535602204, 0.014173822954612756, 0.012643092330555127, 0.011542785431193508, 0.01139418034727289, 0.01097194148946152, 0.011984233055714026, 0.012053188193331179, 0.011114763545093245, 0.011863977520252094, 0.011320307604891403, 0.011287972667120378, 0.010704276614033245, 0.01235973260601046, 0.008845931277663368, 0.01047302020651502, 0.009071805791898905, 0.009066323347994844, 0.01042684433347694, 0.007929261510912606, 0.009668810050021978, 0.009756874090806637, 0.009757161290675567, 0.009372656424627241, 0.010108539198358905, 0.008907189586525824, 0.009839036774543081, 0.008490591772434069, 0.010063240469867805, 0.008708374368110642, 0.008997935355512448, 0.008160025009354413, 0.007361620111627624, 0.008714588950096674, 0.008886525725305839, 0.007262873480936458, 0.007430709075300418, 0.007824370485257456, 0.0069281412114119015, 0.006647038857385977, 0.007879020329491547, 0.006486001267527285, 0.008131674023798947, 0.006198607248916, 0.006568673691328493, 0.006385324856473073, 0.004995608055188024, 0.006113990154548652, 0.007456329026255891, 0.006076431343303538, 0.006545035773292355, 0.006452353819713323, 0.00618230176834015, 0.007942824429144455, 0.006840048771797254, 0.006069790217776105, 0.005195362977971264, 0.004599858996729253, 0.005677830972613986, 0.005490882412822261, 0.006549934046979864, 0.004705156341987569, 0.0053530965389084395, 0.0068909877118957345, 0.005259685543325335, 0.004490668434774772, 0.004940050955303238, 0.0044061899000571595, 0.004126527287916002, 0.005021298689543726, 0.005045947926731971, 0.00552340456473669, 0.005107468137489555, 0.005199413780507183, 0.003986413517660026, 0.004948274823311868, 0.005846032505147011, 0.0034740756293892314, 0.00460539445992029, 0.003934726159981093, 0.0052477335773813884, 0.0032110537257177643, 0.004746323024274171, 0.004214709356937213, 0.004116498507501996, 0.0043898405334455775, 0.004063701221567091, 0.0053437969948645315, 0.0050626216535890915, 0.0033375492998794216, 0.004145067749719393, 0.006089359559898612, 0.003819449772726423, 0.0063089701161270035, 0.0033401318927877665, 0.003021851099608076, 0.0034112397572718203, 0.0047347511740909315, 0.003729685020903218, 0.003353223746900221, 0.004466465009370011, 0.003885324844689836, 0.004174847426271779, 0.004055106881671965, 0.0032305346787497033, 0.0030907509010108265, 0.0042374711461780285, 0.003387048393181546, 0.003460858358254075, 0.0040188098365484546, 0.004176080480616091, 0.003356946159747211, 0.004393546949794469, 0.002787011440791811, 0.003982124507138478, 0.003419866303928268, 0.0035664951073921206, 0.003775915671279374, 0.002975841472946668, 0.0032250562904121076, 0.0028417275876886005, 0.00245943982017104, 0.003519894407194853, 0.0033010562730508377, 0.003471162887984771, 0.004905137387412047, 0.0033388047585814727, 0.00346220825807931, 0.003229530419460503, 0.0045681343757791515, 0.002559037273206986, 0.005599834600531471, 0.002438304080703852, 0.002863328746475846, 0.0038863188404392028, 0.0021005667411782, 0.002869526623552655, 0.0027262803584635143, 0.0030031293022933546, 0.0028115077922458774, 0.006032020148442406, 0.0031546962930759596, 0.0034707081233466834, 0.0029933586850820785, 0.0025884452169753725, 0.0027887249747831962, 0.0020704271874519855, 0.0037004946013916187, 0.0023787388251726802, 0.0029961055929770487, 0.0030400196322170085, 0.003095596703422754, 0.0023812324392641824, 0.0025908140389513993, 0.0026640970214662396, 0.003253086729857712, 0.002250595117871328, 0.002868615534547125, 0.0024280833333520293, 0.0023311863577928356, 0.0026718984974322658, 0.002818421818706629, 0.0019971964357031868, 0.002224014255998553, 0.002568369308246366, 0.003101438244146776, 0.0024621338787490714, 0.002955807549891052, 0.0020434870296428416, 0.0032668732185419584, 0.0030148287970808837, 0.0022668372421742354, 0.002090936213044863, 0.0031092188563592218, 0.0024350751394128425, 0.004048445818198489, 0.0020403097998958615, 0.0027473185371840137, 0.0025950332531947, 0.002314726512487211, 0.0021185627098879657, 0.003092692707810007, 0.002008634851507799, 0.00251330793146444, 0.0021516167731516845, 0.001626020172090725, 0.0023230580160753375, 0.002055752414152133, 0.0023848365708627394, 0.0022000867047944823], "accuracy_test_std": 0.012153782300697196, "error_valid": [0.645728421498494, 0.4774169921875, 0.44983792592243976, 0.3462870034826807, 0.29199512895331325, 0.2392578125, 0.2545680769954819, 0.21980745246611444, 0.23919751270707834, 0.2255153426204819, 0.1864396060805723, 0.18699995293674698, 0.16787462349397586, 0.1525231786521084, 0.15638971903237953, 0.14963467149849397, 0.16939094267695776, 0.14608433734939763, 0.1463490681475903, 0.1755959384412651, 0.15026561323418675, 0.13766148578689763, 0.13447736257530118, 0.16557587772966864, 0.14010289203689763, 0.1578442676957832, 0.14892283979668675, 0.13178152061370485, 0.1308858480798193, 0.14250458866716864, 0.1286885824548193, 0.12914744917168675, 0.15321589090737953, 0.1437855915850903, 0.14222956278237953, 0.13214773155120485, 0.13043874717620485, 0.15104951054216864, 0.13934987998870485, 0.13343902955572284, 0.1454945759600903, 0.12490440276731929, 0.12841355657003017, 0.13412144672439763, 0.12501617799322284, 0.12010248023343373, 0.1287900625941265, 0.11584031438253017, 0.1255456395896084, 0.14606374717620485, 0.11726397778614461, 0.12305275790662651, 0.11897443288780118, 0.12260565700301207, 0.11947153849774095, 0.12462937688253017, 0.10638942488704817, 0.11583001929593373, 0.11830231080572284, 0.11571824407003017, 0.12173057464231929, 0.11335772778614461, 0.11467991105045183, 0.12193353492093373, 0.11077366105045183, 0.12223944606551207, 0.12702077842620485, 0.1228600927146084, 0.12356162932981929, 0.11951271884412651, 0.1295033650225903, 0.11966567441641573, 0.11550498870481929, 0.11376511907003017, 0.10696889118975905, 0.11617564006024095, 0.12323659873870485, 0.11452842620481929, 0.11427399049322284, 0.11329742799322284, 0.10722332690135539, 0.10733510212725905, 0.11344008847891573, 0.10934999764683728, 0.11485345679593373, 0.1266633918486446, 0.11134283226656627, 0.11105898202183728, 0.10841314476656627, 0.10932940747364461, 0.11781402955572284, 0.11233998493975905, 0.11278855657003017, 0.11538291839231929, 0.10598203360316272, 0.12391754518072284, 0.11510789250753017, 0.11092661662274095, 0.10786456372364461, 0.10711155167545183, 0.10883083113704817, 0.10440541462725905, 0.11200465926204817, 0.11128253247364461, 0.10444659497364461, 0.10819988940135539, 0.10542315747364461, 0.10396860881024095, 0.10539227221385539, 0.10772190323795183, 0.10714243693524095, 0.10713214184864461, 0.10907497176204817, 0.10842343985316272, 0.10811899943524095, 0.10705125188253017, 0.10381565323795183, 0.10331707690135539, 0.11055011059864461, 0.10217726374246983, 0.10241110928087349, 0.10289939053087349, 0.10948236304593373, 0.10161838761295183, 0.10197430346385539, 0.10438482445406627, 0.10596144342996983, 0.10290968561746983, 0.10465985033885539, 0.10627764966114461, 0.10539227221385539, 0.09470008942018071, 0.10071241999246983, 0.14529161568147586, 0.10499517601656627, 0.11235028002635539, 0.10874994117093373, 0.10061093985316272, 0.10359210278614461, 0.11084572665662651, 0.10380535815135539, 0.10345973738704817, 0.11041774519954817, 0.10524961172816272, 0.10573789297816272, 0.09899314053087349, 0.10107863092996983, 0.10602321394954817, 0.10733510212725905, 0.09675469455948793, 0.10531138224774095, 0.10920733716114461, 0.10184193806475905, 0.10500547110316272, 0.10620558405496983, 0.10095656061746983, 0.10521872646837349, 0.09872840973268071, 0.10407008894954817, 0.10192282803087349, 0.10268613516566272, 0.10144484186746983, 0.10263465973268071, 0.10279791039156627, 0.10096685570406627, 0.10025502400225905, 0.10549375235316272, 0.11592120434864461, 0.10235080948795183, 0.10342885212725905, 0.10332737198795183, 0.10917645190135539, 0.09754888695406627, 0.12548386907003017, 0.10160809252635539, 0.10098744587725905, 0.10930881730045183, 0.09831219408885539, 0.10059034967996983, 0.10256406485316272, 0.10205519342996983, 0.09455742893448793, 0.13261542262801207, 0.10368328783885539, 0.10568788827183728, 0.10097715079066272, 0.10174045792545183, 0.09651055393448793, 0.09860633942018071, 0.09813864834337349, 0.09776214231927716, 0.10124188158885539, 0.10085508047816272, 0.10453778002635539, 0.09990940323795183, 0.10013295368975905, 0.10120070124246983, 0.10038738940135539, 0.09520896084337349, 0.09582960749246983, 0.09890195547816272, 0.09761948183358427, 0.09542221620858427, 0.09864751976656627, 0.09923728115587349, 0.10002117846385539, 0.09716208584337349, 0.10208607868975905, 0.10034620905496983, 0.09987851797816272, 0.09807834855045183, 0.10095656061746983, 0.09962408226656627, 0.09645025414156627, 0.09869899519954817, 0.09585019766566272, 0.10169927757906627, 0.10737481174698793, 0.09542221620858427, 0.10157720726656627, 0.09681646507906627, 0.09865781485316272, 0.10070212490587349, 0.10044768919427716, 0.09716208584337349, 0.10059034967996983, 0.09619581842996983, 0.09939023672816272, 0.10117128670933728, 0.10404949877635539, 0.09997999811746983, 0.10405979386295183], "tags": ["deepconvnets", "zoonormalized"], "hp": {"zoom_range": [1, 1], "translation_range": [-5, 5], "learning_rate_decay": 0.00018432527532955545, "discrete_learning_divide": 10.0, "shear_range": [1, 1], "patience_check_each": 1, "discrete_learning_rate_epsilon": 0.0001, "patience_threshold": 1, "do_flip": true, "batch_size": 64, "valid_ratio": 0.15, "learning_rate": 0.002949511101540916, "optimization": "rmsprop", "nb_data_augmentation": 4, "learning_rate_decay_method": "none", "max_epochs": 1000, "patience_nb_epochs": 50, "weight_decay": 0.0, "l2_decay": 1.3591044496186695e-07, "rotation_range": [0, 0], "momentum": 0.570771429051322}, "accuracy_valid_max": 0.9054425710655121, "code_": "from datetime import datetime\nimport matplotlib as mpl\nmpl.use('Agg')   # NOQA\nfrom lasagnekit.easy import BatchOptimizer, BatchIterator, get_batch_slice\nfrom lasagnekit.nnet.capsule import Capsule\nfrom lasagnekit.easy import iterate_minibatches\nfrom lasagne import updates\nfrom lasagnekit.updates import santa_sss\nupdates.santa_sss = santa_sss  # NOQA\nimport theano\nimport theano.tensor as T\n\nimport numpy as np\nimport json\n\nfrom skimage.io import imsave\nfrom lasagnekit.datasets.infinite_image_dataset import Transform\n\n\nclass MyBatchIterator(BatchIterator):\n\n    def __init__(self, nb_data_augmentation=1,  **transform_params):\n        super(MyBatchIterator, self).__init__()\n\n        self.nb_data_augmentation = nb_data_augmentation\n        self.transform_params = transform_params\n\n    def transform(self, batch_index, V):\n        assert self.batch_size is not None\n        assert self.nb_batches is not None\n\n        if isinstance(batch_index, T.TensorVariable):\n            batch_slice = get_batch_slice(batch_index,\n                                          self.batch_size)\n        else:\n            batch_slice = slice(batch_index * self.batch_size,\n                                (batch_index+1) * self.batch_size)\n\n        d = OrderedDict()\n        X = V[\"X\"][batch_slice]\n        y = V[\"y\"][batch_slice]\n\n        X_list = [X]\n        y_list = [y]\n        for i in range(self.nb_data_augmentation):\n            tr, _ = Transform(X.transpose(0, 2, 3, 1),\n                              np.random,\n                              **self.transform_params)\n            imsave(\"out.png\", (((tr[0] + 1) / 2.)))\n            X_transformed = tr.transpose((0, 3, 1, 2))\n            X_list.append(X_transformed)\n            y_list.append(y)\n        d[\"X\"] = np.concatenate(X_list, axis=0)\n        d[\"y\"] = np.concatenate(y_list, axis=0)\n        d[\"X\"], d[\"y\"] = shuffle(d[\"X\"], d[\"y\"])\n        return d\n\n\nif __name__ == \"__main__\":\n    from lasagnekit.datasets.cifar10 import Cifar10\n    from sklearn.utils import shuffle\n    from sklearn.cross_validation import train_test_split\n    from collections import OrderedDict\n\n    from lightexperiments.light import Light\n    from hp_toolkit.hp import (\n            Param, make_constant_param,\n            instantiate_random, instantiate_default\n    )\n    import argparse\n    import vgg  # NOQA\n    import vgg_small  # NOQA\n    import vgg_very_small  # NOQA\n    import spatially_sparse  # NOQA\n    import nin  # NOQA\n    import fully  # NOQA\n    import residual  # NOQA\n    import residualv2  # NOQA\n    import residualv3  # NOQA\n    import residualv4  # NOQA\n    import residualv5  # NOQA\n\n    parser = argparse.ArgumentParser(description='zoo')\n    parser.add_argument(\"--budget-hours\",\n                        default=np.inf,\n                        help=\"nb of maximum hours (defaut=inf)\")\n    parser.add_argument(\"--fast-test\", default=False, type=bool)\n    parser.add_argument(\"--model\", default=\"vgg\", type=str)\n    parser.add_argument(\"--default-model\", default=False, type=bool)\n\n    models = {\n        \"vgg\": vgg,\n        \"vgg_small\": vgg_small,\n        \"vgg_very_small\": vgg_very_small,\n        \"spatially_sparse\": spatially_sparse,\n        \"nin\": nin,\n        \"fully\": fully,\n        \"residual\": residual,\n        \"residualv2\": residualv2,\n        \"residualv3\": residualv3,\n        \"residualv4\": residualv4,\n        \"residualv5\": residualv5\n    }\n    args = parser.parse_args()\n    model_class = models[args.model]\n    budget_sec = args.budget_hours * 3600\n    begin = datetime.now()\n    seed = np.random.randint(0, 1000000000)\n    np.random.seed(seed)\n    fast_test = args.fast_test\n    np.random.seed(seed)\n    rng = np.random\n\n    if args.default_model is True:\n        instantiate = instantiate_default\n    else:\n        instantiate = instantiate_random\n\n    light = Light()\n    light.launch()\n    light.initials()\n    light.file_snapshot()\n    light.set_seed(seed)\n    light.tag(\"deepconvnets\")\n    light.tag(\"zoonormalized\")\n\n    data = Cifar10(batch_indexes=[1, 2, 3, 4, 5])\n    data.load()\n\n    data_test = Cifar10(batch_indexes=[6])\n    data_test.load()\n\n    light.set(\"dataset\", data.__class__.__name__)\n\n    hp = dict(\n        learning_rate=Param(initial=0.001, interval=[-4, -2], type='real', scale='log10'),\n        learning_rate_decay=Param(initial=0.05, interval=[0, 0.1], type='real'),\n        learning_rate_decay_method=Param(initial='discrete', interval=['exp', 'none', 'sqrt', 'lin', 'discrete'], type='choice'),\n        momentum=Param(initial=0.9, interval=[0.5, 0.99], type='real'),\n        #weight_decay=Param(initial=0, interval=[-10, -3], type='real', scale='log10'),\n        weight_decay=make_constant_param(0.),\n        discrete_learning_rate_epsilon=make_constant_param(1e-4),#NEW TO ADD\n        discrete_learning_divide=make_constant_param(10.),\n        l2_decay=Param(initial=0, interval=[-8, -4], type='real', scale='log10'),#NEW TO ADD\n        max_epochs=make_constant_param(1000),\n        batch_size=Param(initial=32,\n                         interval=[16, 32, 64, 128],\n                         type='choice'),\n        patience_nb_epochs=make_constant_param(50),\n        valid_ratio=make_constant_param(0.15),\n\n        patience_threshold=make_constant_param(1),\n        patience_check_each=make_constant_param(1),\n\n        optimization=Param(initial='adam',\n                           interval=['adam', 'nesterov_momentum', 'rmsprop'],\n                           type='choice'),\n        # data augmentation\n        nb_data_augmentation=Param(initial=1, interval=[0, 1, 2, 3, 4], type='choice'),\n        zoom_range=make_constant_param((1, 1)),\n        rotation_range=make_constant_param((0, 0)),\n        shear_range=make_constant_param((1, 1)),\n        translation_range=make_constant_param((-5, 5)),\n        do_flip=make_constant_param(True)\n\n    )\n\n    if fast_test is True:\n        instantiate = instantiate_default\n\n    default_params = {}\n    if fast_test is True:\n        default_params[\"max_epochs\"] = 1\n    hp = instantiate(hp, default_params=default_params)\n    light.set(\"hp\", hp)\n\n    hp_model = model_class.params\n    hp_model = instantiate(hp_model)\n    light.set(\"hp_model\", hp_model)\n\n    model = model_class.build_model(\n        input_width=data.img_dim[1],\n        input_height=data.img_dim[2],\n        output_dim=data.output_dim,\n        **hp_model)\n    light.set(\"model\", model_class.__name__)\n    print(model_class.__name__)\n    print(json.dumps(hp, indent=4))\n    print(json.dumps(hp_model, indent=4))\n\n    initial_lr = hp[\"learning_rate\"]\n\n    def evaluate(X, y, batch_size=None):\n        if batch_size is None:\n            batch_size = hp[\"batch_size\"]\n        accs = []\n        for mini_batch in iterate_minibatches(X.shape[0],\n                                              batch_size):\n            acc = (nnet.predict(X[mini_batch]) == y[mini_batch]).mean()\n            accs.append(acc)\n        return accs\n\n    class MyBatchOptimizer(BatchOptimizer):\n\n        def quitter(self, update_status):\n            quit = super(MyBatchOptimizer, self).quitter(update_status)\n            if (datetime.now() - begin).total_seconds() >= budget_sec:\n                print(\"Budget finished.quit.\")\n                quit = True\n            return quit\n\n        def iter_update(self, epoch, nb_batches, iter_update_batch):\n            start = datetime.now()\n            status = super(MyBatchOptimizer, self).iter_update(epoch,\n                                                               nb_batches,\n                                                               iter_update_batch)\n            duration = (datetime.now() - start).total_seconds()\n            status[\"duration\"] = duration\n            accs = evaluate(X_train, y_train, batch_size=self.batch_size_eval)\n            status[\"accuracy_train\"] = np.mean(accs)\n            status[\"accuracy_train_std\"] = np.std(accs)\n            accs = evaluate(X_valid, y_valid, batch_size=self.batch_size_eval)\n            status[\"accuracy_valid\"] = np.mean(accs)\n            status[\"accuracy_valid_std\"] = np.std(accs)\n\n            status[\"error_valid\"] = 1 - status[\"accuracy_valid\"]\n\n            status = self.add_moving_avg(\"accuracy_train\", status)\n            status = self.add_moving_var(\"accuracy_train\", status)\n            status = self.add_moving_avg(\"accuracy_valid\", status)\n            status = self.add_moving_var(\"accuracy_valid\", status)\n\n            for k, v in status.items():\n                light.append(k, float(v))\n\n            lr = self.learning_rate\n            lr_decay_method = hp[\"learning_rate_decay_method\"]\n            lr_decay = hp[\"learning_rate_decay\"]\n            cur_lr = lr.get_value()\n            t = status[\"epoch\"]\n\n            if lr_decay_method == \"exp\":\n                new_lr = cur_lr * (1 - lr_decay)\n            elif lr_decay_method == \"lin\":\n                new_lr = initial_lr / (1 + t)\n            elif lr_decay_method == \"sqrt\":\n                new_lr = initial_lr / np.sqrt(1 + t)\n            elif lr_decay_method == 'discrete':\n                eps = hp[\"discrete_learning_rate_epsilon\"]\n                div = hp[\"discrete_learning_divide\"]\n                if status[\"moving_var_accuracy_valid\"] <= eps:\n                    new_lr = cur_lr / div\n                else:\n                    new_lr = cur_lr\n            else:\n                new_lr = cur_lr\n\n            new_lr = np.array(new_lr, dtype=\"float32\")\n            lr.set_value(new_lr)\n\n            light.append(\"learning_rate_per_epoch\",\n                         float(self.learning_rate.get_value()))\n            return status\n\n        def add_moving_avg(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n            else:\n                old_avg = 0\n            avg = B * old_avg + (1 - B) * status[name]\n            status[\"moving_avg_\" + name] = avg\n            return status\n\n        def add_moving_var(self, name, status, B=0.9):\n            if len(self.stats) >= 2:\n                old_avg = self.stats[-2][\"moving_avg_\" + name]\n                old_var = self.stats[-2][\"moving_var_\" + name]\n            else:\n                old_avg = 0\n                old_var = 0\n            new_avg = B * old_avg + (1 - B) * status[name]\n            var = B * old_var + (1 - B) * (status[name] - old_avg) * (status[name] - new_avg)\n            status[\"moving_var_\" + name] = var\n            return status\n\n    learning_rate = theano.shared(np.array(hp[\"learning_rate\"],\n                                  dtype=\"float32\"))\n    momentum = hp[\"momentum\"]\n\n    optim_params = {\"learning_rate\": learning_rate}\n    if \"momentum\" in hp[\"optimization\"]:\n        optim_params[\"momentum\"] = hp[\"momentum\"]\n\n    batch_optimizer = MyBatchOptimizer(\n        verbose=1, max_nb_epochs=hp[\"max_epochs\"],\n        batch_size=hp[\"batch_size\"],\n        optimization_procedure=(getattr(updates, hp[\"optimization\"]),\n                                optim_params),\n        patience_stat=\"error_valid\",\n        patience_nb_epochs=hp[\"patience_nb_epochs\"],\n        patience_progression_rate_threshold=hp[\"patience_threshold\"],\n        patience_check_each=hp[\"patience_check_each\"],\n        verbose_stat_show=[\n            \"epoch\",\n            \"duration\",\n            \"accuracy_train\",\n            \"accuracy_train_std\",\n            \"accuracy_valid\",\n            \"accuracy_valid_std\",\n        ]\n    )\n    batch_size_eval = 1024\n    light.set(\"batch_size_eval\", batch_size_eval)\n    batch_optimizer.learning_rate = learning_rate\n    batch_optimizer.batch_size_eval = batch_size_eval\n\n    input_variables = OrderedDict()\n    input_variables[\"X\"] = dict(tensor_type=T.tensor4)\n    input_variables[\"y\"] = dict(tensor_type=T.ivector)\n    functions = dict(\n        predict=dict(\n            get_output=lambda model, X: (model.get_output(X, deterministic=True)[0]).argmax(axis=1),\n            params=[\"X\"]\n        )\n    )\n\n    def loss_function(model, tensors):\n        X = tensors[\"X\"]\n        y = tensors[\"y\"]\n        y_hat, = model.get_output(X)\n        if hp[\"weight_decay\"] > 0:\n            l1 = sum(T.abs_(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"weight_decay\"]\n        else:\n            l1 = 0\n\n        if hp[\"l2_decay\"] > 0:\n            l2 = sum(T.sqr(param).sum() for param in model.capsule.all_params_regularizable) * hp[\"l2_decay\"]\n        else:\n            l2 = 0\n\n        return T.nnet.categorical_crossentropy(y_hat, y).mean() + l1 + l2\n\n    batch_iterator = MyBatchIterator(hp[\"nb_data_augmentation\"],\n                                     zoom_range=hp[\"zoom_range\"],\n                                     rotation_range=hp[\"rotation_range\"],\n                                     shear_range=hp[\"shear_range\"],\n                                     translation_range=hp[\"translation_range\"],\n                                     do_flip=hp[\"do_flip\"])\n\n    nnet = Capsule(\n        input_variables, model,\n        loss_function,\n        functions=functions,\n        batch_optimizer=batch_optimizer,\n        batch_iterator=batch_iterator,\n    )\n\n    from sklearn.preprocessing import LabelEncoder\n\n    imshape = ([data.X.shape[0]] +\n               list(data.img_dim))\n    X = data.X.reshape(imshape).astype(np.float32)\n    y = data.y\n    label_encoder = LabelEncoder()\n    y = label_encoder.fit_transform(y)\n    y = y.astype(np.int32)\n\n    # rescaling to [-1, 1]\n    X_min = X.min(axis=(0, 2, 3))[None, :, None, None]\n    X_max = X.max(axis=(0, 2, 3))[None, :, None, None]\n    X = 2 * ((X - X_min) / (X_max - X_min)) - 1\n    X, y = shuffle(X, y)\n\n    if fast_test is True:\n        X = X[0:100]\n        y = y[0:100]\n\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=hp[\"valid_ratio\"])\n    light.set(\"nb_examples_train\", X_train.shape[0])\n    light.set(\"nb_examples_valid\", X_valid.shape[0])\n    try:\n        nnet.fit(X=X_train, y=y_train)\n    except KeyboardInterrupt:\n        print(\"interruption...\")\n\n    imshape = ([data_test.X.shape[0]] +\n               list(data_test.img_dim))\n    X_test = data_test.X.reshape(imshape).astype(np.float32)\n    X_test = 2 * ((X_test - X_min) / (X_max - X_min)) - 1\n    y_test = data_test.y\n    y_test = label_encoder.transform(y_test)\n    y_test = y_test.astype(np.int32)\n\n    accs = evaluate(X_test, y_test, batch_size_eval)\n    m, s = np.mean(accs), np.std(accs)\n    light.set(\"accuracy_test\", m)\n    light.set(\"accuracy_test_std\", s)\n    print(\"Test accuracy : {}+-{}\".format(m, s))\n\n    light.endings()  # save the duration\n\n    if fast_test is False:\n        light.store_experiment()  # update the DB\n    light.close()\n", "nb_examples_valid": 7500, "accuracy_valid_last": 0.8959402061370482, "accuracy_valid_std": [0.018010958192321628, 0.017910256754719026, 0.016085112469316962, 0.015295180421276566, 0.014250346212865805, 0.007689460814464659, 0.009843322455482613, 0.008804237924790894, 0.017849251015935954, 0.01784355987104911, 0.009101690154551008, 0.013581265547624895, 0.012981656907487423, 0.008034630741408446, 0.014147326871825091, 0.01232734377585474, 0.014925349685940713, 0.01187531406173718, 0.014900856686133576, 0.011986391212817376, 0.015744780471721294, 0.01338252443576779, 0.01374275822957885, 0.011492805698828983, 0.012628079335594256, 0.014347056057352965, 0.014900895879799212, 0.014040288387834627, 0.008712200886458995, 0.020454459211084818, 0.01211484603331611, 0.0201888293300877, 0.015316369054574815, 0.015154918910975966, 0.01620235464854823, 0.014100481659289975, 0.01371667490052436, 0.018065446492751894, 0.010042779733597336, 0.009288263321307165, 0.014621982393745282, 0.014311920245323509, 0.008943849399050725, 0.015694267145266557, 0.010653664430448398, 0.008758045231928325, 0.009318571333146286, 0.014134749215501483, 0.015589157479988198, 0.00963386403936984, 0.011099029094379098, 0.011156572193830617, 0.019099850430969807, 0.014813251170724009, 0.010472856780998477, 0.010475994956841199, 0.01307898717825007, 0.012873668135519474, 0.012745960060246326, 0.013991134461122573, 0.014812947956254926, 0.012031906104315544, 0.010494957750293374, 0.008263077827539574, 0.008907745298015893, 0.015616974213966262, 0.016957398245220887, 0.014659416509445109, 0.011880239351831556, 0.012179397000822111, 0.01871406946023618, 0.016489390532544015, 0.015328637695520298, 0.01411775078111693, 0.009863676757539047, 0.008911914261066675, 0.017066608636345005, 0.016243998488852336, 0.015077645158382428, 0.014580295925008164, 0.009602641721760246, 0.009975787783452292, 0.017899280695661858, 0.011559879243641281, 0.014067306576320432, 0.012387313023415345, 0.007372987872022116, 0.012173750205658685, 0.00840592582229514, 0.009595908761104133, 0.01320140205979761, 0.00904945175011481, 0.012216151929613346, 0.015122837296359725, 0.009676834109409616, 0.014669926242848463, 0.013518052515991544, 0.014918603992243795, 0.013062389681845882, 0.011352157798934987, 0.011499223772554811, 0.01102985367599715, 0.013989575459751432, 0.009946621585862946, 0.013401965569449947, 0.010339421262224955, 0.01147952937312091, 0.01393533181379239, 0.011576978811049578, 0.010918874386148848, 0.012818626414831561, 0.011811232719116865, 0.010398055352361234, 0.009877861733351402, 0.01369352860470589, 0.014855787171840615, 0.012684827709561279, 0.012930272035322049, 0.01442236456441233, 0.009470245913568808, 0.008642549348124274, 0.013118437171544256, 0.01631067285582414, 0.010474332696725656, 0.010774928526484722, 0.011360304640297587, 0.011337076089299921, 0.010138644700343329, 0.009205464596898189, 0.013926616611304668, 0.009730743694072572, 0.010862872310395198, 0.007270681776888656, 0.019423804881844267, 0.008731766957741544, 0.0067136271631965455, 0.0156650342505187, 0.010100293561877343, 0.01372809381395241, 0.013859480028195788, 0.010864307785634138, 0.011114205345618772, 0.011938484556246569, 0.0113009731920993, 0.006863096895112913, 0.008280928105330727, 0.008304681641953757, 0.011474537271089002, 0.012894709924962, 0.010285333054396363, 0.013321593549635143, 0.00989427551619368, 0.009281721789286717, 0.007827197732537598, 0.007717808358899444, 0.009768232976626776, 0.00933803860848347, 0.007816593124007, 0.012518748499042677, 0.009502859103444249, 0.008935521292898548, 0.009502003329060317, 0.010359572132523772, 0.0071564537514326974, 0.01004512109692435, 0.012089257802646169, 0.008908446553437364, 0.010523437920370155, 0.01026053798553262, 0.011995813448131916, 0.013811652839395153, 0.011048681966515804, 0.013103286019565123, 0.00958579774515231, 0.012696790552178238, 0.011562901144243083, 0.00831507374257595, 0.012268939285805025, 0.009793535897834967, 0.010912580001510725, 0.012160414027401256, 0.008636367281477045, 0.014714729787018418, 0.012027996080074023, 0.01519543614482665, 0.010297370171517136, 0.010989520634311996, 0.007510822196126412, 0.010146429258884072, 0.010936187341988991, 0.00844033511552039, 0.009658037434405742, 0.008660416720492944, 0.008527981727770683, 0.011427400373371805, 0.009214124922635748, 0.007536073996880255, 0.009647408042415213, 0.005869436998878832, 0.010264403957275986, 0.008816069849130765, 0.007280810440604017, 0.00926980041133742, 0.008178858379096935, 0.01059279201977663, 0.011142037231461833, 0.010946557545921774, 0.011032547177629502, 0.00796435611737353, 0.008772627834715609, 0.012739941199615603, 0.007646142538883028, 0.007773525430560429, 0.011785633719565028, 0.012735712878834753, 0.012288030265919474, 0.007897994269399232, 0.008699941790191705, 0.006279934453577261, 0.007488572156006583, 0.009293212417656266, 0.009216694514999941, 0.004149057010969863, 0.007010935923550312, 0.010535921159510407, 0.009521981760219234, 0.010212579232312146, 0.011154761885766473, 0.01805789476713688, 0.009719418038079842, 0.008474877798151887, 0.011005510759731076], "accuracy_valid": [0.35427157850150603, 0.5225830078125, 0.5501620740775602, 0.6537129965173193, 0.7080048710466867, 0.7607421875, 0.7454319230045181, 0.7801925475338856, 0.7608024872929217, 0.7744846573795181, 0.8135603939194277, 0.813000047063253, 0.8321253765060241, 0.8474768213478916, 0.8436102809676205, 0.850365328501506, 0.8306090573230422, 0.8539156626506024, 0.8536509318524097, 0.8244040615587349, 0.8497343867658133, 0.8623385142131024, 0.8655226374246988, 0.8344241222703314, 0.8598971079631024, 0.8421557323042168, 0.8510771602033133, 0.8682184793862951, 0.8691141519201807, 0.8574954113328314, 0.8713114175451807, 0.8708525508283133, 0.8467841090926205, 0.8562144084149097, 0.8577704372176205, 0.8678522684487951, 0.8695612528237951, 0.8489504894578314, 0.8606501200112951, 0.8665609704442772, 0.8545054240399097, 0.8750955972326807, 0.8715864434299698, 0.8658785532756024, 0.8749838220067772, 0.8798975197665663, 0.8712099374058735, 0.8841596856174698, 0.8744543604103916, 0.8539362528237951, 0.8827360222138554, 0.8769472420933735, 0.8810255671121988, 0.8773943429969879, 0.880528461502259, 0.8753706231174698, 0.8936105751129518, 0.8841699807040663, 0.8816976891942772, 0.8842817559299698, 0.8782694253576807, 0.8866422722138554, 0.8853200889495482, 0.8780664650790663, 0.8892263389495482, 0.8777605539344879, 0.8729792215737951, 0.8771399072853916, 0.8764383706701807, 0.8804872811558735, 0.8704966349774097, 0.8803343255835843, 0.8844950112951807, 0.8862348809299698, 0.893031108810241, 0.883824359939759, 0.8767634012612951, 0.8854715737951807, 0.8857260095067772, 0.8867025720067772, 0.8927766730986446, 0.892664897872741, 0.8865599115210843, 0.8906500023531627, 0.8851465432040663, 0.8733366081513554, 0.8886571677334337, 0.8889410179781627, 0.8915868552334337, 0.8906705925263554, 0.8821859704442772, 0.887660015060241, 0.8872114434299698, 0.8846170816076807, 0.8940179663968373, 0.8760824548192772, 0.8848921074924698, 0.889073383377259, 0.8921354362763554, 0.8928884483245482, 0.8911691688629518, 0.895594585372741, 0.8879953407379518, 0.8887174675263554, 0.8955534050263554, 0.8918001105986446, 0.8945768425263554, 0.896031391189759, 0.8946077277861446, 0.8922780967620482, 0.892857563064759, 0.8928678581513554, 0.8909250282379518, 0.8915765601468373, 0.891881000564759, 0.8929487481174698, 0.8961843467620482, 0.8966829230986446, 0.8894498894013554, 0.8978227362575302, 0.8975888907191265, 0.8971006094691265, 0.8905176369540663, 0.8983816123870482, 0.8980256965361446, 0.8956151755459337, 0.8940385565700302, 0.8970903143825302, 0.8953401496611446, 0.8937223503388554, 0.8946077277861446, 0.9052999105798193, 0.8992875800075302, 0.8547083843185241, 0.8950048239834337, 0.8876497199736446, 0.8912500588290663, 0.8993890601468373, 0.8964078972138554, 0.8891542733433735, 0.8961946418486446, 0.8965402626129518, 0.8895822548004518, 0.8947503882718373, 0.8942621070218373, 0.9010068594691265, 0.8989213690700302, 0.8939767860504518, 0.892664897872741, 0.9032453054405121, 0.894688617752259, 0.8907926628388554, 0.898158061935241, 0.8949945288968373, 0.8937944159450302, 0.8990434393825302, 0.8947812735316265, 0.9012715902673193, 0.8959299110504518, 0.8980771719691265, 0.8973138648343373, 0.8985551581325302, 0.8973653402673193, 0.8972020896084337, 0.8990331442959337, 0.899744975997741, 0.8945062476468373, 0.8840787956513554, 0.8976491905120482, 0.896571147872741, 0.8966726280120482, 0.8908235480986446, 0.9024511130459337, 0.8745161309299698, 0.8983919074736446, 0.899012554122741, 0.8906911826995482, 0.9016878059111446, 0.8994096503200302, 0.8974359351468373, 0.8979448065700302, 0.9054425710655121, 0.8673845773719879, 0.8963167121611446, 0.8943121117281627, 0.8990228492093373, 0.8982595420745482, 0.9034894460655121, 0.9013936605798193, 0.9018613516566265, 0.9022378576807228, 0.8987581184111446, 0.8991449195218373, 0.8954622199736446, 0.9000905967620482, 0.899867046310241, 0.8987992987575302, 0.8996126105986446, 0.9047910391566265, 0.9041703925075302, 0.9010980445218373, 0.9023805181664157, 0.9045777837914157, 0.9013524802334337, 0.9007627188441265, 0.8999788215361446, 0.9028379141566265, 0.897913921310241, 0.8996537909450302, 0.9001214820218373, 0.9019216514495482, 0.8990434393825302, 0.9003759177334337, 0.9035497458584337, 0.9013010048004518, 0.9041498023343373, 0.8983007224209337, 0.8926251882530121, 0.9045777837914157, 0.8984227927334337, 0.9031835349209337, 0.9013421851468373, 0.8992978750941265, 0.8995523108057228, 0.9028379141566265, 0.8994096503200302, 0.9038041815700302, 0.9006097632718373, 0.8988287132906627, 0.8959505012236446, 0.9000200018825302, 0.8959402061370482], "seed": 168591835, "model": "residualv3", "loss_std": [0.39359432458877563, 0.15429842472076416, 0.1383553445339203, 0.13128454983234406, 0.12671536207199097, 0.12224539369344711, 0.11902041733264923, 0.11623226851224899, 0.11197632551193237, 0.10768508166074753, 0.10714605450630188, 0.10632731765508652, 0.10333012044429779, 0.10084716230630875, 0.09817652404308319, 0.09392675757408142, 0.09159008413553238, 0.08967898786067963, 0.0882389023900032, 0.08819437772035599, 0.08380940556526184, 0.0812511220574379, 0.08048707991838455, 0.07635457068681717, 0.07437939196825027, 0.0723423957824707, 0.07191233336925507, 0.07011253386735916, 0.0670345351099968, 0.06840524077415466, 0.06591781973838806, 0.0633029043674469, 0.06481309980154037, 0.06179920583963394, 0.06009606271982193, 0.059215858578681946, 0.05757982283830643, 0.05331939831376076, 0.0531182661652565, 0.053546808660030365, 0.050499774515628815, 0.05273141339421272, 0.04926981031894684, 0.05065778270363808, 0.047991447150707245, 0.04782437905669212, 0.04635586217045784, 0.04756428673863411, 0.0449373684823513, 0.04445972666144371, 0.04123113304376602, 0.043194111436605453, 0.04059918597340584, 0.039851050823926926, 0.0384904108941555, 0.039181411266326904, 0.03815650939941406, 0.038978900760412216, 0.036583978682756424, 0.03490007296204567, 0.0358787439763546, 0.03528585657477379, 0.03463820368051529, 0.032426364719867706, 0.03360341861844063, 0.032413531094789505, 0.030989324674010277, 0.03183247521519661, 0.033290911465883255, 0.0315716452896595, 0.03126988559961319, 0.029923738911747932, 0.030634194612503052, 0.02975039929151535, 0.029768411070108414, 0.03047994151711464, 0.028373882174491882, 0.028973912820219994, 0.027806511148810387, 0.026863692328333855, 0.029393630102276802, 0.026313254609704018, 0.026231851428747177, 0.027239494025707245, 0.02588389813899994, 0.025755150243639946, 0.027256254106760025, 0.025787783786654472, 0.026605814695358276, 0.024411886930465698, 0.025710001587867737, 0.0246860533952713, 0.02560429647564888, 0.023548373952507973, 0.02488318458199501, 0.024215426295995712, 0.02408425882458687, 0.02341679111123085, 0.02175826020538807, 0.024556193500757217, 0.0223613902926445, 0.02274627611041069, 0.02133685164153576, 0.022471342235803604, 0.022360587492585182, 0.023214174434542656, 0.02067468874156475, 0.022130554541945457, 0.020677099004387856, 0.02208990603685379, 0.0213764738291502, 0.021135039627552032, 0.024032611399888992, 0.021145185455679893, 0.022423429414629936, 0.019877513870596886, 0.01950274407863617, 0.01943819597363472, 0.021028732880949974, 0.01961020939052105, 0.020135454833507538, 0.020081302151083946, 0.019065087661147118, 0.02000178024172783, 0.01955607533454895, 0.019585156813263893, 0.019941210746765137, 0.017909638583660126, 0.019471077248454094, 0.01895025186240673, 0.018995806574821472, 0.018870633095502853, 0.017748679965734482, 0.020989540964365005, 0.022284790873527527, 0.01864345371723175, 0.019432831555604935, 0.017017841339111328, 0.018285226076841354, 0.01802591234445572, 0.019470445811748505, 0.018369073048233986, 0.017447177320718765, 0.01749054528772831, 0.01736503653228283, 0.0212837103754282, 0.017377140000462532, 0.015701433643698692, 0.016269873827695847, 0.015727128833532333, 0.01539982296526432, 0.01801115833222866, 0.01706812158226967, 0.01750198006629944, 0.018032191321253777, 0.015265362337231636, 0.016625992953777313, 0.015533379279077053, 0.01688050664961338, 0.01807546056807041, 0.01594495214521885, 0.015541747212409973, 0.01613152027130127, 0.016457023099064827, 0.015751101076602936, 0.017537277191877365, 0.016802797093987465, 0.016091451048851013, 0.015458932146430016, 0.016808709129691124, 0.013752165250480175, 0.015936875715851784, 0.015125426463782787, 0.015638958662748337, 0.015458314679563046, 0.014650595374405384, 0.017234111204743385, 0.014473254792392254, 0.013223323971033096, 0.013657378032803535, 0.015138290822505951, 0.015020109713077545, 0.014263681136071682, 0.015619292855262756, 0.014850747771561146, 0.015366921201348305, 0.012802427634596825, 0.013729658909142017, 0.0141803789883852, 0.01573033072054386, 0.01504101324826479, 0.01327695045620203, 0.012614000588655472, 0.014255328103899956, 0.015210090205073357, 0.013710962608456612, 0.014725695364177227, 0.01270087156444788, 0.013284592889249325, 0.014416868798434734, 0.013698247261345387, 0.013065374456346035, 0.017267338931560516, 0.013591187074780464, 0.01250302791595459, 0.013135184533894062, 0.01373065821826458, 0.012515963986515999, 0.014760179445147514, 0.01357152871787548, 0.017429154366254807, 0.012565132230520248, 0.013572163879871368, 0.012449722737073898, 0.012939367443323135, 0.01451729517430067, 0.011182381771504879, 0.01519120205193758, 0.014528692699968815, 0.013622644357383251, 0.012782067991793156, 0.01301652379333973, 0.013377398252487183, 0.012509082444012165, 0.014490817673504353, 0.012808634899556637, 0.013018184341490269, 0.012118672020733356, 0.013636790215969086, 0.012325471267104149, 0.015579268336296082, 0.012960626743733883]}, "state": "available", "life": [{"dt": "Sun May 15 22:05:32 2016", "state": "available"}], "summary": "9c466fd0d79e1444a32c9e49756e2291"}